vide a valid media type as source filters can swap between the
    // IMemInputPin and IOverlay transports as and when they feel like it

    pHeader = HEADER(pvi);

    dwConnectWidth = DEFAULT_WIDTH;
    dwConnectHeight = DEFAULT_HEIGHT;

    pHeader->biWidth  = dwConnectWidth;
    pHeader->biHeight = dwConnectHeight;

    pHeader->biSize   = sizeof(BITMAPINFOHEADER);
    pHeader->biPlanes = 1;
    pHeader->biBitCount = 8;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMOutputPin::GetMediaType")));
    return hr;
}

// called after we have agreed a media type to actually set it
HRESULT COMOutputPin::SetMediaType(const CMediaType* pmt)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMOutputPin::SetMediaType")));

    CAutoLock cLock(m_pFilterLock);

    // make sure the mediatype is correct
    hr = CheckMediaType(pmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CheckMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // Set the base class media type (should always succeed)
    hr = CBaseOutputPin::SetMediaType(pmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseOutputPin::SetMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // tell the owning filter
    hr = m_pFilter->SetMediaType(m_dwPinId, pmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->SetMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMOutputPin::SetMediaType")));
    return hr;
}

// Complete Connect
HRESULT COMOutputPin::CompleteConnect(IPin *pReceivePin)
{
    HRESULT hr = NOERROR;
    DWORD dwAdvise = 0, dwInputPinCount = 0, i = 0;
    COLORKEY ColorKey;
    VIDEOINFOHEADER *pVideoInfoHeader = NULL;
    DDSURFACEDESC SurfaceDescP;
    COMInputPin *pInputPin = NULL;
    BOOL bDoDeletePrimSurface = TRUE;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMOutputPin::CompleteConnect")));

    CAutoLock cLock(m_pFilterLock);

    // get the connection mediatype dimensions and store them
    pVideoInfoHeader = (VIDEOINFOHEADER *) (m_mt.Format());
    ASSERT(pVideoInfoHeader);
    m_dwConnectWidth = (DWORD)abs(pVideoInfoHeader->bmiHeader.biWidth);
    m_dwConnectHeight = (DWORD)abs(pVideoInfoHeader->bmiHeader.biHeight);
    ASSERT(m_dwConnectWidth > 0 && m_dwConnectHeight > 0);

    // try to get the IOverlay interface	
    hr = pReceivePin->QueryInterface(IID_IOverlay, (void **)&m_pIOverlay);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, 1, TEXT("QueryInterface for IOverlay failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // get the renderer's window handle to subclass it later
    hr = m_pIOverlay->GetWindowHandle(&m_hwnd);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, 1, TEXT("m_pIOverlay->GetWindowHandle failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    m_hDC = ::GetDC(m_hwnd);
    ASSERT(m_hDC);

    if (m_bWindowDestroyed)
    {
	// subclass the window
        hr = SetNewWinProc();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("SetNewWinProc failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
	
        m_bWindowDestroyed = FALSE;
    }

    // set up the advise link
#ifdef DO_ADVISE_CLIPPING
    dwAdvise = ADVISE_CLIPPING | ADVISE_PALETTE;
#else
    dwAdvise = ADVISE_POSITION | ADVISE_PALETTE;
#endif
    hr = m_pIOverlay->Advise(m_pFilter, dwAdvise);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, 1, TEXT("m_pIOverlay->Advise failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    m_bAdvise = TRUE;

    hr = AttachWindowClipper();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, 1, TEXT("AttachWindowClipper failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    //
    // We want to know if the downstream filter we are connecting to can do MacroVision
    // copy protection. This will help us do copy protection in OverlayMixer on a
    // "if necessary" basis.
    // SIDE ADVANTAGE: Even if someone writes a custom Video Renderer filter that doesn't
    // do Macrovision, our copy protection will still work, because OverlayMixer will do it.
    // THE DISADVANTAGE: if someone puts in a filter between OverlayMixer and Video
    // Renderer then the following check will detect is as "no copy protection" from the
    // Video Renderer and will do it itself which may cause double activate leading to
    // failure on some display drivers.  But that doesn't happen anyway.
    //
    IKsPropertySet *pKsPS ;
    ULONG           ulTypeSupport ;
    PIN_INFO        pi ;
    pReceivePin->QueryPinInfo(&pi) ;
    if (pi.pFilter)
    {
        if (SUCCEEDED(pi.pFilter->QueryInterface(IID_IKsPropertySet, (LPVOID *)&pKsPS)))
        {
            DbgLog((LOG_TRACE, 5, TEXT("Filter of pin %s supports IKsPropertySet"), (LPCTSTR)CDisp(pReceivePin))) ;
            if ( S_OK == pKsPS->QuerySupported(
                                    AM_KSPROPSETID_CopyProt,
                                    AM_PROPERTY_COPY_MACROVISION,
                                    &ulTypeSupport)  &&
                 (ulTypeSupport & KSPROPERTY_SUPPORT_SET) )
            {
                DbgLog((LOG_TRACE, 1, TEXT("Filter for pin %s supports copy protection"),
                        (LPCTSTR)CDisp(pReceivePin))) ;
                m_pFilter->SetCopyProtect(FALSE) ;  // need NOT copy protect
            }
            else
            {
                DbgLog((LOG_TRACE, 1, TEXT("Filter for pin %s DOES NOT support copy protection"),
                        (LPCTSTR)CDisp(pReceivePin))) ;
                m_pFilter->SetCopyProtect(TRUE) ;   // need to copy protect -- redundant setting
            }

            pKsPS->Release() ;
        }
        else
        {
            DbgLog((LOG_TRACE, 1, TEXT("WARNING: Filter of pin %s doesn't support IKsPropertySet"),
                    (LPCTSTR)CDisp(pReceivePin))) ;
        }
        pi.pFilter->Release() ;   // must release it now
    }
    else
    {
        DbgLog((LOG_ERROR, 1, TEXT("ERROR: No pin info for Pin %s!!!"), (LPCTSTR)CDisp(pReceivePin))) ;
    }

    // call the base class
    hr = CBaseOutputPin::CompleteConnect(pReceivePin);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseOutputPin::CompleteConnect failed, hr = 0x%x"),
            hr));
        goto CleanUp;
    }

    // tell the owning filter
    hr = m_pFilter->CompleteConnect(m_dwPinId);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->CompleteConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // get the colorkey and use it if the upstream filter hasn't set it
    // already
    if (!m_pFilter->ColorKeySet()) {
        hr = m_pIOverlay->GetDefaultColorKey(&ColorKey);
        if (SUCCEEDED(hr)) {
            COMInputPin *pInputPin = (COMInputPin *)m_pFilter->GetPin(0);
            if (pInputPin) {
                pInputPin->SetColorKey(&ColorKey);
            }
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMOutputPin::CompleteConnect")));
    return hr;
}

HRESULT COMOutputPin::BreakConnect()
{
    HRESULT hr = NOERROR;
    DWORD dwInputPinCount = 0, i = 0;
    COMInputPin *pInputPin;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMOutputPin::BreakConnect")));

    CAutoLock cLock(m_pFilterLock);

    if (m_hDC)
    {
        ReleaseDC(m_hwnd, m_hDC);
        m_hDC = NULL;
    }

    if (!m_bWindowDestroyed)
    {
        SetOldWinProc();
	
	m_bWindowDestroyed = TRUE;
    }

    // release the IOverlay interface
    if (m_pIOverlay != NULL)
    {
        if (m_bAdvise)
        {
            m_pIOverlay->Unadvise();
            m_bAdvise = FALSE;
        }
        m_pIOverlay->Release();
        m_pIOverlay = NULL;
    }

    // Reset copy protection need flag on disconnect
    m_pFilter->SetCopyProtect(TRUE) ;   // need to copy protect

    // call the base class
    hr = CBaseOutputPin::BreakConnect();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseOutputPin::BreakConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // tell the owning filter
    hr = m_pFilter->BreakConnect(m_dwPinId);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->BreakConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMOutputPin::BreakConnect")));
    return hr;
}

// we don't use the memory based transport so all we care about
// is that the pin is connected.
HRESULT COMOutputPin::DecideBufferSize(IMemAllocator * pAllocator, ALLOCATOR_PROPERTIES * pProp)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMOutputPin::DecideBufferSize")));

    CAutoLock cLock(m_pFilterLock);

    if (!IsConnected())
    {
        DbgBreak("DecideBufferSize called when !m_pOutput->IsConnected()");
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMOutputPin::DecideBufferSize")));
    return hr;
}

struct MONITORDATA {
    HMONITOR hMonPB;
    BOOL fMsgShouldbeDrawn;
};

/*****************************Private*Routine******************************\
* MonitorEnumProc
*
* On Multi-Monitor systems make sure that the part of the window that is not
* on the primary monitor is black.
*
* History:
* Thu 06/03/1999 - StEstrop - Created
*
\**************************************************************************/
BOOL CALLBACK
MonitorEnumProc(
  HMONITOR hMonitor,        // handle to display monitor
  HDC hdc,                  // handle to monitor-appropriate device context
  LPRECT lprcMonitor,       // pointer to monitor intersection rectangle
  LPARAM dwData             // data passed from EnumDisplayMonitors
  )
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering ::MonitorEnumProc")));
    MONITORDATA* lpmd = (MONITORDATA*)dwData;

    if (lpmd->hMonPB != hMonitor) {
        FillRect(hdc, lprcMonitor, (HBRUSH)GetStockObject(BLACK_BRUSH));
        lpmd->fMsgShouldbeDrawn = TRUE;
    }
    DbgLog((LOG_TRACE, 5, TEXT("Leaving ::MonitorEnumProc")));
    return TRUE;
}


// our winproc
// All we are interested in is the WM_CLOSE event
extern "C" const TCHAR chMultiMonWarning[];
extern int GetRegistryDword(HKEY hk, const TCHAR *pKey, int iDefault);
LRESULT WINAPI COMOutputPin::NewWndProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam)
{
    LONG_PTR lNewUserData;
    DWORD errCode;
    WNDPROC hOldWinProc;
    COMOutputPin* pData = NULL;
    LRESULT lRetVal = 0;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMOutputPin::NewWndProc")));
    SetLastError(0);
    lNewUserData = GetWindowLongPtr(hWnd, GWLP_USERDATA);
    errCode = GetLastError();

    if (!lNewUserData && errCode != 0)
    {
	DbgLog((LOG_ERROR,0,TEXT("GetWindowLong failed, THIS SHOULD NOT BE HAPPENING!!!")));
        goto CleanUp;
    }

    pData = (COMOutputPin*)lNewUserData;
    ASSERT(pData);
    hOldWinProc = pData->m_hOldWinProc;
    if (!hOldWinProc) {
        goto CleanUp;
    }


    //
    // Look out for our special registered monitor changed message
    //
    if (message == pData->m_pFilter->m_MonitorChangeMsg) {
	lRetVal = pData->m_pFilter->OnDisplayChange(FALSE);
	goto CleanUp;
    }


    switch (message) {

    case WM_TIMER :
	pData->m_pFilter->OnTimer();
	break;

    case WM_SHOWWINDOW :
	// if show status is false, means window is being hidden
	pData->m_pFilter->OnShowWindow(hWnd, (BOOL)wParam);
	break;

#ifdef DEBUG
    case WM_DISPLAY_WINDOW_TEXT:
        SetWindowText(hWnd, pData->m_pFilter->m_WindowText);
        break;
#endif
    case WM_PAINT :
        pData->m_pFilter->OnDrawAll();

        if (GetSystemMetrics(SM_CMONITORS) > 1 ) {

            lRetVal = 0;

            PAINTSTRUCT ps;
            MONITORDATA md;

            md.hMonPB = pData->m_pFilter->GetCurrentMonitor(FALSE);
            md.fMsgShouldbeDrawn = FALSE;
            HDC hdc = BeginPaint(hWnd, &ps);
            EnumDisplayMonitors(hdc, NULL, MonitorEnumProc,(LPARAM)&md);

            if (md.fMsgShouldbeDrawn &&
                pData->m_pFilter->m_fMonitorWarning &&
                GetRegistryDword(HKEY_CURRENT_USER, chMultiMonWarning, 1)) {

                RECT rc;
                TCHAR sz[256];

                if (LoadString(g_hInst, IDS_HW_LIMIT, sz, 256)) {
                    GetClientRect(hWnd, &rc);
                    SetBkColor(hdc, RGB(0,0,0));
                    SetTextColor(hdc, RGB(255,255,0));
                    DrawText(hdc, sz, -1, &rc, DT_CENTER | DT_WORDBREAK);
                }
            }

            EndPaint(hWnd, &ps);

            // We goto CleanUp because we don't want the Video Renderer
            // window procedure calling BeginPaint/EndPaint

            goto CleanUp;
        }

        break;
	
        //
        // When we detect a display change we tell the filter about it
        // We don't pass this message on to the Video Renderer window
        // procedure because we don't want it starting the
        // reconnection procedure all over again.
        //
    case WM_DISPLAYCHANGE:
	lRetVal = pData->m_pFilter->OnDisplayChange(TRUE);
	goto CleanUp;
	
    default:
	break;
    }

    lRetVal = CallWindowProc(hOldWinProc, hWnd, message, wParam, lParam);

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMOutputPin::NewWndProc")));
    return lRetVal;
}


// function to subclass the renderers window
HRESULT COMOutputPin::SetNewWinProc()
{
    HRESULT hr = NOERROR;
    DWORD errCode;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMOutputPin::SetNewWinProc")));

    CAutoLock cLock(m_pFilterLock);

    ASSERT(m_hwnd);	

    SetLastError(0);
    m_lOldWinUserData = SetWindowLongPtr(m_hwnd, GWLP_USERDATA, (LONG_PTR)this);
    errCode = GetLastError();

    if (!m_lOldWinUserData && errCode != 0)
    {
	DbgLog((LOG_ERROR, 1, TEXT("SetNewWinProc->SetWindowLong failed, errCode = %d"), errCode));
        hr = E_FAIL;
        goto CleanUp;
    }
    else
    {
	DbgLog((LOG_TRACE, 2, TEXT("new WinUserData value = %d, old val was %d"), this, m_lOldWinUserData));
    }


    SetLastError(0);
    m_hOldWinProc = (WNDPROC)SetWindowLongPtr(m_hwnd, GWLP_WNDPROC, (LONG_PTR)NewWndProc);
    errCode = GetLastError();

    if (!m_hOldWinProc && errCode != 0)
    {
	DbgLog((LOG_ERROR,0,TEXT("SetNewWinProc->SetWindowLong failed, errCode = %d"), errCode));
        hr = E_FAIL;
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMOutputPin::SetNewWinProc")));
    return NOERROR;
}

//change back to the oldWinProc again
HRESULT COMOutputPin::SetOldWinProc()
{
    HRESULT hr = NOERROR;
    LONG_PTR lOldWinProc;
    DWORD errCode;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMOutputPin::SetOldWinProc")));

    CAutoLock cLock(m_pFilterLock);

    if (m_hOldWinProc)
    {
	SetLastError(0);
	lOldWinProc = SetWindowLongPtr(m_hwnd, GWLP_WNDPROC, (LONG_PTR)m_hOldWinProc);
	errCode = GetLastError();
	
	if (!lOldWinProc && errCode != 0)
	{
	    DbgLog((LOG_ERROR,0,TEXT("SetWindowLong failed, errCode = %d"), errCode));
	    hr = E_FAIL;
	    goto CleanUp;
	}
	else
	{
	    DbgLog((LOG_ERROR,0,TEXT("GOING BACK TO OLD WINPROC : NewWinProc->SetWindowLong succeeded")));
            m_hOldWinProc = 0;
	    goto CleanUp;
	}
    }
CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMOutputPin::SetOldWinProc")));
    return hr;
}

// release the clipper for the primary surface
DWORD COMOutputPin::ReleaseWindowClipper()
{
    AMTRACE((TEXT("COMOutputPin::ReleaseWindowClipper")));
    CAutoLock cLock(m_pFilterLock);
    DWORD dwRefCnt = 0;

    if (m_pDrawClipper)
    {
	dwRefCnt = m_pDrawClipper->Release();

        //
        // The ref should be 1 here not zero, this is because the
        // primary surface has a ref count on the clipper.  The
        // clipper will get released when the primary surface is
        // released
        //

        ASSERT(dwRefCnt == 1);
	m_pDrawClipper = NULL;
    }

    return dwRefCnt;
}

// Prepare the clipper for the primary surface
HRESULT COMOutputPin::AttachWindowClipper()
{
    HRESULT hr = NOERROR;
    LPDIRECTDRAW pDirectDraw = NULL;
    LPDIRECTDRAWSURFACE pPrimarySurface = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::AttachWindowClipper")));

    CAutoLock cLock(m_pFilterLock);

    // some asserts
    ASSERT(m_pDrawClipper == NULL);

    pDirectDraw = m_pFilter->GetDirectDraw();
    if (!pDirectDraw)
    {
	DbgLog((LOG_ERROR, 1, TEXT("pDirectDraw = NULL")));
        // if there is no primary surface that is ok
	hr = NOERROR;
        goto CleanUp;
    }

    pPrimarySurface = m_pFilter->GetPrimarySurface();
    if (!pPrimarySurface)
    {
	DbgLog((LOG_ERROR, 1, TEXT("pPrimarySurface = NULL")));
        // if there is no primary surface that is ok
	hr = NOERROR;
        goto CleanUp;
    }

    // Create the IDirectDrawClipper interface
    hr = pDirectDraw->CreateClipper((DWORD)0, &m_pDrawClipper, NULL);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, 1, TEXT("Function ClipPrepare, CreateClipper failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // Give the clipper the video window handle
    hr = m_pDrawClipper->SetHWnd((DWORD)0, m_hwnd);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, 1, TEXT("Function ClipPrepare, SetHWnd failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    //
    // Set Clipper
    // The primary surface AddRef's the clipper object, so we can
    // delete it here as we don't need to reference it anymore.
    //
    hr = pPrimarySurface->SetClipper(m_pDrawClipper);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR,0, TEXT("Function ClipPrepare, SetClipper failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

CleanUp:
    ReleaseWindowClipper();
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::AttachWindowClipper")));
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmixer\ominpin.cpp ===
// Copyright (c) 1998 - 1999  Microsoft Corporation.  All Rights Reserved.
#include <streams.h>
#include <ddraw.h>
#include <mmsystem.h>       // Needed for definition of timeGetTime
#include <limits.h>     // Standard data type limit definitions
#include <ks.h>
#include <ksproxy.h>
#include <bpcwrap.h>
#include <ddmmi.h>
#include <dvdmedia.h>
#include <amstream.h>
#include <dvp.h>
#include <ddkernel.h>
#include <vptype.h>
#include <vpconfig.h>
#include <vpnotify.h>
#include <vpobj.h>
#include <syncobj.h>
#include <mpconfig.h>
#include <ovmixpos.h>
#include <macvis.h>
#include <ovmixer.h>
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx
#include <malloc.h>
#ifdef PERF
#include <measure.h>
#endif

//
//   Flipping surface implementation
//
//   To allow decoders to hold on to surfaces for out of order decode
//   we flip directly to the surface pass on Receive rather than
//   use the default NULL target surface for Flip().
//
//   This works in the following way
//
//   The COMPinputPin::m_pDirectDrawSurface points to the FRONT buffer
//
//   When Receive is called we Flip() the front buffer and because we
//   do an explicit Flip() DirectDraw swaps the memory pointers for the
//   current Front buffer and the surface passed in which is then attached
//   to the front buffer.
//
//   The received buffer is then put at the back of the queue so (correctly)
//   the previous front buffer is now at the back of the queue to be handed
//   to the application
//
//   The allocator actually has one more buffer than was actually requested
//   so the previous front buffer won't actually be requested until the next
//   Receive and hence the previous Flip() has time to complete.
//

//  Video accelerator disable interface
const TCHAR szVideoAcc[] = TEXT("Video Acceleration");

extern "C"
const TCHAR szPropPage[] = TEXT("Property Pages");

extern "C"
const TCHAR chRegistryKey[] = TEXT("Software\\Microsoft\\Multimedia\\ActiveMovie Filters\\Overlay Mixer");

extern "C"
const TCHAR chMultiMonWarning[] = TEXT("MMon warn");

/******************************Public*Routine******************************\
* GetRegistryDword
*
*
*
\**************************************************************************/
int
GetRegistryDword(
    HKEY hk,
    const TCHAR *pKey,
    int iDefault
)
{
    HKEY hKey;
    LONG lRet;
    int  iRet = iDefault;

    lRet = RegOpenKeyEx(hk, chRegistryKey, 0, KEY_QUERY_VALUE, &hKey);
    if (lRet == ERROR_SUCCESS) {

        DWORD   dwType, dwLen;

        dwLen = sizeof(iRet);
        if (ERROR_SUCCESS != RegQueryValueEx(hKey, pKey, 0L, &dwType,
                                             (LPBYTE)&iRet, &dwLen)) {
            iRet = iDefault;
        }
        RegCloseKey(hKey);
    }
    return iRet;
}

/******************************Public*Routine******************************\
* SetRegistryDword
*
*
*
\**************************************************************************/
LONG
SetRegistryDword(
    HKEY hk,
    const TCHAR *pKey,
    int iRet
)
{
    HKEY hKey;
    LONG lRet;

    lRet = RegCreateKey(hk, chRegistryKey, &hKey);
    if (lRet == ERROR_SUCCESS) {

        lRet = RegSetValueEx(hKey, pKey, 0L, REG_DWORD,
                             (LPBYTE)&iRet, sizeof(iRet));
        RegCloseKey(hKey);
    }
    return lRet;
}

///////////////////////////////////////////
// CLASS CDDrawMediaSample implemented here
///////////////////////////////////////////

// constructor
CDDrawMediaSample::CDDrawMediaSample(TCHAR *pName, CBaseAllocator *pAllocator, HRESULT *phr, LPBYTE pBuffer, LONG length,
                                     bool bKernelFlip)
: CMediaSample(pName, pAllocator, phr, pBuffer, length)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering CDDrawMediaSample::Constructor")));

    m_pDirectDrawSurface = NULL;
    m_dwDDrawSampleSize  = 0;
    m_bSurfaceLocked     = FALSE;
    m_bKernelLock        = bKernelFlip;
    SetRect(&m_SurfaceRect, 0, 0, 0, 0);

    memset(&m_DibData, 0, sizeof(DIBDATA));
    m_bInit = FALSE;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving CDDrawMediaSample::Constructor")));
    return;
}

// destructor
CDDrawMediaSample::~CDDrawMediaSample(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::Destructor")));

    if (m_pDirectDrawSurface)
    {
        __try {
            m_pDirectDrawSurface->Release() ;  // release surface now
        }
        __except(EXCEPTION_EXECUTE_HANDLER) {
            ;
        }
        m_pDirectDrawSurface = NULL;
    }

    if (m_bInit)
    {
        if (m_DibData.hBitmap)
        {
            EXECUTE_ASSERT(DeleteObject(m_DibData.hBitmap));
        }
        if (m_DibData.hMapping)
        {
            EXECUTE_ASSERT(CloseHandle(m_DibData.hMapping));
        }
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::Destructor")));
    return;
}

HRESULT CDDrawMediaSample::SetDDrawSampleSize(DWORD dwDDrawSampleSize)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetDDrawSampleSize")));

    m_dwDDrawSampleSize = dwDDrawSampleSize;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetDDrawSampleSize")));
    return hr;
}

HRESULT CDDrawMediaSample::GetDDrawSampleSize(DWORD *pdwDDrawSampleSize)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetDDrawSampleSize")));

    if (!pdwDDrawSampleSize)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad Arguments, pdwDDrawSampleSize = NULL")));
        hr = E_POINTER;
        goto CleanUp;
    }

    *pdwDDrawSampleSize = m_dwDDrawSampleSize;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetDDrawSampleSize")));
    return hr;
}

HRESULT CDDrawMediaSample::SetDDrawSurface(LPDIRECTDRAWSURFACE pDirectDrawSurface)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetDDrawSampleSize")));

    if (pDirectDrawSurface)               // only if new surface is not NULL...
        pDirectDrawSurface->AddRef() ;    // ...add a ref count on it

    if (m_pDirectDrawSurface)             // if there was a surface already...
        m_pDirectDrawSurface->Release() ; // ... then release it now

    m_pDirectDrawSurface = pDirectDrawSurface;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetDDrawSampleSize")));
    return hr;
}

HRESULT CDDrawMediaSample::GetDDrawSurface(LPDIRECTDRAWSURFACE *ppDirectDrawSurface)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetDDrawSampleSize")));

    if (!ppDirectDrawSurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Bad Arguments, ppDirectDrawSurface = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    *ppDirectDrawSurface = m_pDirectDrawSurface;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetDDrawSampleSize")));
    return hr;
}
// overridden to expose IDirectDrawMediaSample
STDMETHODIMP CDDrawMediaSample::QueryInterface(REFIID riid, void **ppv)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CDDrawMediaSample::QueryInterface")));

    if (riid == IID_IDirectDrawMediaSample && m_pDirectDrawSurface)
    {
        hr = GetInterface((IDirectDrawMediaSample*)this, ppv);
#ifdef DEBUG
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface(IDirectDrawMediaSample*) failed, hr = 0x%x"), hr));
        }
#endif
    }
    else
    {
        hr = CMediaSample::QueryInterface(riid, ppv);
#ifdef DEBUG
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("CUnknown::NonDelegatingQueryInterface failed, hr = 0x%x"), hr));
        }
#endif
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving CDDrawMediaSample::QueryInterface")));
    return hr;
}

// Implement IDirectDrawMediaSample
STDMETHODIMP CDDrawMediaSample::GetSurfaceAndReleaseLock(IDirectDrawSurface **ppDirectDrawSurface,
                                                         RECT* pRect)
{
    HRESULT hr = NOERROR;
    BYTE *pBufferPtr;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CDDrawMediaSample::GetSurfaceAndReleaseLock")));

    // make sure the surface is locked
    if (!m_bSurfaceLocked)
    {
        DbgLog((LOG_ERROR, 4, TEXT("m_bSurfaceLocked is FALSE, can't unlock surface twice, returning E_UNEXPECTED")));
        goto CleanUp;

    }

    // make sure you have a direct draw surface pointer
    if (!m_pDirectDrawSurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface is NULL, returning E_FAIL")));
        hr = E_FAIL;
        goto CleanUp;

    }

    hr = GetPointer(&pBufferPtr);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetPointer() failed, hr = 0x%x"), hr));
        goto CleanUp;

    }

    ASSERT(m_pDirectDrawSurface);
    hr = m_pDirectDrawSurface->Unlock((LPVOID)pBufferPtr);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface->Unlock failed, hr = 0x%x"), hr));
        goto CleanUp;

    }

    // Can't do this to make the 829/848 work with the ovmixer. The reason is that those
    // drivers unlock the surface just after GetBuffer (to avoid the win16 lock), however
    // there is a bunch of code in the proxy which ASSERTS for a valid pointer value
    /*
    // update the pointer value, however keep the SampleSize around
    hr = SetPointer(NULL, 0);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("SetPointer() failed, hr = 0x%x"), hr));
        goto CleanUp;

    }
    */

    if (ppDirectDrawSurface)
        *ppDirectDrawSurface  = m_pDirectDrawSurface;
    if (pRect)
        *pRect = m_SurfaceRect;
    m_bSurfaceLocked = FALSE;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving CDDrawMediaSample::GetSurfaceAndReleaseLock")));
    return hr;
}

STDMETHODIMP CDDrawMediaSample::LockMediaSamplePointer(void)
{
    HRESULT hr = NOERROR;
    DWORD dwDDrawSampleSize = 0;
    DDSURFACEDESC ddSurfaceDesc;
    DWORD dwLockFlags = DDLOCK_WAIT;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CDDrawMediaSample::LockMediaSamplePointer")));

    // make sure the surface is locked
    if (m_bSurfaceLocked)
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_bSurfaceLocked is TRUE, can't lock surface twice, returning E_UNEXPECTED")));
        hr = E_UNEXPECTED;
        goto CleanUp;

    }

    // make sure you have a direct draw surface pointer
    if (!m_pDirectDrawSurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface is NULL, returning E_FAIL")));
        hr = E_FAIL;
        goto CleanUp;

    }

    // set the dwSize of ddSurfaceDesc
    INITDDSTRUCT(ddSurfaceDesc);

    // lock the surface - no need to grab the win16 lock
    ASSERT(m_pDirectDrawSurface);

    //  Using DDLOCK_NOSYSLOCK caused us to get DDERR_SURFACEBUSY on some of
    //  our blts to the primary for painting the color key so we've
    //  stopped using it for now.

    IDirectDrawSurface7 *pSurface7;
    if (m_bKernelLock && SUCCEEDED(m_pDirectDrawSurface->QueryInterface(
           IID_IDirectDrawSurface7,
           (void **)&pSurface7))) {
        pSurface7->Release();
        dwLockFlags |= DDLOCK_NOSYSLOCK;
    }
    hr = m_pDirectDrawSurface->Lock(
             NULL,
             &ddSurfaceDesc,
             dwLockFlags,
             (HANDLE)NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface->Lock() failed, hr = 0x%x"), hr));
        goto CleanUp;

    }

    hr = GetDDrawSampleSize(&dwDDrawSampleSize);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetDDrawSampleSize() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(dwDDrawSampleSize);


    // update the pointer value
    hr = SetPointer((BYTE*)ddSurfaceDesc.lpSurface, dwDDrawSampleSize);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("SetPointer() failed, hr = 0x%x"), hr));
        goto CleanUp;

    }

    m_bSurfaceLocked = TRUE;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving CDDrawMediaSample::LockMediaSamplePointer")));
    return hr;
}

// Set the shared memory DIB information
void CDDrawMediaSample::SetDIBData(DIBDATA *pDibData)
{
    ASSERT(pDibData);
    m_DibData = *pDibData;
    m_pBuffer = m_DibData.pBase;
    m_cbBuffer = m_dwDDrawSampleSize;
    m_bInit = TRUE;
}


// Retrieve the shared memory DIB data
DIBDATA *CDDrawMediaSample::GetDIBData()
{
    ASSERT(m_bInit == TRUE);
    return &m_DibData;
}


///////////////////////////////////////////
// CLASS COMInputAllocator implemented here
///////////////////////////////////////////

// constructor
COMInputAllocator::COMInputAllocator(COMInputPin *pPin, CCritSec *pLock, HRESULT *phr)
: CBaseAllocator(NAME("Video Allocator"), NULL, phr, TRUE, true)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::Constructor")));

    ASSERT(pPin != NULL && pLock != NULL);

    m_pPin = pPin;
    m_pFilterLock = pLock;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::Constructor")));

    //  REVIEW don't overwrite a failure code from CBaseAllocator
    return;
}

#ifdef DEBUG
// destructor
COMInputAllocator::~COMInputAllocator(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::Destructor")));
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::Destructor")));
    return;
}
#endif

// Override this to publicise IDirectDrawMediaSampleAllocator
STDMETHODIMP COMInputAllocator::NonDelegatingQueryInterface(REFIID riid, void **ppv)
{
    HRESULT hr;
    AM_RENDER_TRANSPORT amRenderTransport;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::NonDelegatingQueryInterface")));

    CAutoLock cLock(m_pFilterLock);

    // get the pins render transport
    m_pPin->GetRenderTransport(&amRenderTransport);

    if ((riid == IID_IDirectDrawMediaSampleAllocator) &&
        (amRenderTransport == AM_OVERLAY || amRenderTransport == AM_OFFSCREEN))
    {
        hr = GetInterface((IDirectDrawMediaSampleAllocator*)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("GetInterface((IDirectDrawMediaSampleAllocator*)this, ppv)  failed, hr = 0x%x"), hr));
        }
    }
    else
    {
        // call the base class
        hr = CBaseAllocator::NonDelegatingQueryInterface(riid, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("CBaseAllocator::NonDelegatingQueryInterface failed, hr = 0x%x"), hr));
        }
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::NonDelegatingQueryInterface")));
    return hr;
}

STDMETHODIMP COMInputAllocator::SetProperties(ALLOCATOR_PROPERTIES* pRequest, ALLOCATOR_PROPERTIES* pActual)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::SetProperties")));

    // call the base class
    hr = CBaseAllocator::SetProperties(pRequest, pActual);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseAllocator::SetProperties() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // tell the pin
    hr = m_pPin->OnSetProperties(pRequest, pActual);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pPin->AllocateSurfaces() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::SetProperties")));
    return hr;
}

// called when we receive a sample
HRESULT COMInputAllocator::GetBuffer(IMediaSample **ppSample, REFERENCE_TIME *pStartTime,
                                     REFERENCE_TIME *pEndTime, DWORD dwFlags)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::GetBuffer")));

    // call the base class
    IMediaSample *pSample = NULL;
    hr = CBaseAllocator::GetBuffer(&pSample,pStartTime,pEndTime,dwFlags);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseAllocator::GetBuffer() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // tell the pin
    hr = m_pPin->OnGetBuffer(&pSample, pStartTime, pEndTime, dwFlags);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pPin->OnGetBuffer() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::GetBuffer")));
    {
        //  REVIEW why lock?  There are no variables in the allocato
        //  accessed here
        CAutoLock cAllocatorLock(this);
        if (FAILED(hr))
        {
            if (pSample)
            {
                IMemAllocatorNotifyCallbackTemp* pNotifyTemp = m_pNotify;
                m_pNotify = NULL;
                pSample->Release();
                m_pNotify = pNotifyTemp;
            }
            *ppSample = NULL;
        }
        else
        {
            ASSERT(pSample != NULL);
            *ppSample = pSample;
        }
    }
    return hr;
}


// called when the sample is released
HRESULT COMInputAllocator::ReleaseBuffer(IMediaSample *pSample)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::ReleaseBuffer")));

    // unlock the sample first
    hr = ((CDDrawMediaSample*)pSample)->GetSurfaceAndReleaseLock(NULL, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pSample->GetSurfaceAndReleaseLock() failed, hr = 0x%x"), hr));
        // goto CleanUp;
        // if this happens we still have to release the sample to the free list, so don't bail out
    }

    {
        CAutoLock cAllocatorLock(this);

        // Copy of base class code - put at end of the list
        {
            CheckPointer(pSample,E_POINTER);
            ValidateReadPtr(pSample,sizeof(IMediaSample));
            BOOL bRelease = FALSE;
            {
                CAutoLock cal(this);

                /* Put back on the free list */

                CMediaSample **ppTail;
                for (ppTail = &m_lFree.m_List; *ppTail;
                    ppTail = &((CDDrawMediaSample *)(*ppTail))->Next()) {
                }
                *ppTail = (CMediaSample *)pSample;
                ((CDDrawMediaSample *)pSample)->Next() = NULL;
                m_lFree.m_nOnList++;

                if (m_lWaiting != 0) {
                    NotifySample();
                }

                // if there is a pending Decommit, then we need to complete it by
                // calling Free() when the last buffer is placed on the free list

                LONG l1 = m_lFree.GetCount();
                if (m_bDecommitInProgress && (l1 == m_lAllocated)) {
                    Free();
                    m_bDecommitInProgress = FALSE;
                    bRelease = TRUE;
                }
            }

            if (m_pNotify) {
                m_pNotify->NotifyRelease();
            }
            // For each buffer there is one AddRef, made in GetBuffer and released
            // here. This may cause the allocator and all samples to be deleted
            if (bRelease)
            {
                Release();
            }
        }
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::ReleaseBuffer")));
    return hr;
}

// allocate memory for the sample
HRESULT COMInputAllocator::Alloc()
{
    HRESULT hr = NOERROR;
    CDDrawMediaSample **ppSampleList = NULL;
    DWORD i;
    LONG lToAllocate;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::Alloc")));

    // call the base class
    hr = CBaseAllocator::Alloc();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseAllocator::Alloc() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // allocate memory for pointers

    lToAllocate = (m_pPin->m_RenderTransport == AM_OVERLAY  &&
                   m_pPin->m_dwBackBufferCount > 1 &&
                   !m_pPin->m_bSyncOnFill &&
                   m_pPin->m_bCanOverAllocateBuffers) ?
             m_lCount + 1 : m_lCount;

    // allocate memory for an array of pointers
    ppSampleList = new CDDrawMediaSample *[lToAllocate];
    if (!ppSampleList)
    {
        DbgLog((LOG_ERROR, 1, TEXT("new BYTE[m_lCount*sizeof(CDDrawMediaSample*)] failed")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    for (i = 0; i < (DWORD)(lToAllocate); i++)
    {
        // Create a new sample
        ppSampleList[i] = new CDDrawMediaSample(NAME("Sample"), this, (HRESULT *) &hr, NULL, (LONG) 0,
                                       DDKERNELCAPS_LOCK & m_pPin->m_pFilter->KernelCaps() ?
                                       true : false);

        //  REVIEW - actually hr can't be a failure
        //  so we don't need to delete ppSampleList[i] here
        if (FAILED(hr) || ppSampleList[i] == NULL)
        {
            if (SUCCEEDED(hr))
                hr = E_OUTOFMEMORY;
            DbgLog((LOG_ERROR, 1, TEXT("new CDDrawMediaSample failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // this cannot fail
        m_lFree.Add(ppSampleList[i]);
        m_lAllocated++;
    }

    ASSERT(m_lAllocated == lToAllocate);

    // tell the pin
    hr = m_pPin->OnAlloc(ppSampleList, lToAllocate);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pPin->OnAlloc(), hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    delete[] ppSampleList;
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::Alloc")));
    return hr;
}

void COMInputAllocator::Free(void)
{
    CDDrawMediaSample *pSample;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::Free")));

    /* Should never be deleting this unless all buffers are freed */
    //  REVIEW - might not be true if we failed to allocate a sample
    ASSERT(m_lAllocated == m_lFree.GetCount());

    /* Free up all the CMediaSamples */

    for (;;)
    {
        pSample = (CDDrawMediaSample *) m_lFree.RemoveHead();
        if (pSample != NULL)
        {
            delete pSample;
        }
        else
        {
            break;
        }
    }

    m_lAllocated = 0;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::Free")));
    return;
}


// function used to implement IDirectDrawMediaSampleAllocator.
// used to give a handle to the ddraw object used to allocate surfaces
STDMETHODIMP COMInputAllocator::GetDirectDraw(IDirectDraw **ppDirectDraw)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputAllocator::GetDirectDraw")));

    if (!ppDirectDraw)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of ppDirectDraw is invalid, ppDirectDraw = NULL")));
        hr = E_POINTER;
        goto CleanUp;

    }

    {
        //  REVIEW - why is the allocator locked - to protect m_pPin?
        //  bug m_pPin is not AddRef'd by us so in theory could go away
        //  anyway - better to addref if this is necessary
        //  who typically has a pointer to this object
        CAutoLock cAllocatorLock(this);
        *ppDirectDraw = m_pPin->GetDirectDraw();
        ASSERT(*ppDirectDraw);
    }


CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputAllocator::GetDirectDraw")));
    return hr;
}

/////////////////////////////////////
// CLASS COMInputPin implemented here
/////////////////////////////////////

// constructor
COMInputPin::COMInputPin(TCHAR *pObjectName, COMFilter *pFilter, CCritSec *pLock, BOOL bCreateVPObject, HRESULT *phr, LPCWSTR pPinName, DWORD dwPinNo)
: CBaseInputPin(pObjectName, pFilter, pLock, phr, pPinName)
{
    HRESULT hr = NOERROR;
    LPUNKNOWN pUnkOuter;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::Constructor")));

    m_cOurRef = 0;
    m_pFilterLock = pLock;
    m_dwPinId = dwPinNo;
    m_pFilter = pFilter;

    m_bVPSupported = FALSE;
    m_pIVPUnknown = NULL;
    m_pIVPObject = NULL;

    m_bIOverlaySupported = FALSE;
    m_pIOverlayNotify = NULL;
    m_dwAdviseNotify = ADVISE_NONE;

    m_pSyncObj = NULL;

    m_Medium.Set = GUID_NULL;
    m_Medium.Id = 0;
    m_Medium.Flags = 0;
    m_CategoryGUID = GUID_NULL;
    m_Communication = KSPIN_COMMUNICATION_SOURCE;
    m_bStreamingInKernelMode = FALSE;
    m_OvMixerOwner = AM_OvMixerOwner_Unknown;

    m_pDirectDrawSurface = NULL;
    m_pBackBuffer = NULL;
    m_RenderTransport = AM_OFFSCREEN;
    m_dwBackBufferCount = 0;
    m_dwDirectDrawSurfaceWidth = 0;
    m_dwMinCKStretchFactor = 0;
    m_bOverlayHidden = TRUE;
    m_bSyncOnFill = FALSE;
    m_bDontFlip = FALSE ;
    m_bDynamicFormatNeeded = TRUE;
    m_bNewPaletteSet = TRUE;
    m_dwUpdateOverlayFlags = 0;
    m_dwInterlaceFlags = 0;
    m_dwFlipFlag = 0;
    m_bConnected = FALSE;
    m_bUsingOurAllocator = FALSE;
    m_hMemoryDC = NULL;
    m_bCanOverAllocateBuffers = TRUE;
    m_hEndOfStream = NULL;
    m_UpdateOverlayNeededAfterReceiveConnection = false;
    SetReconnectWhenActive(true);

    if (m_dwPinId == 0) {
        m_StepEvent = CreateEvent(NULL, FALSE, FALSE, NULL);
    }
    else {
        m_StepEvent = NULL;
    }

    // -ve == normal playback
    // +ve == frames to skips
    //  0 == time to block
    m_lFramesToStep = -1;

#ifdef PERF
    m_PerfFrameFlipped = MSR_REGISTER(TEXT("Frame Drawn"));
    m_FrameReceived = MSR_REGISTER(TEXT("Sample Received"));
#endif


    // Set up buffer management stuff for WindowLess renderer
    ZeroMemory(&m_BackingDib, sizeof(m_BackingDib));
    m_BackingImageSize = 0L;

    memset(&m_WinInfo, 0, sizeof(WININFO));
    m_WinInfo.hClipRgn = CreateRectRgn(0, 0, 0, 0);

    if (m_dwPinId == 0)
        SetRect(&m_rRelPos, 0, 0, MAX_REL_NUM, MAX_REL_NUM);
    else
        SetRect(&m_rRelPos, 0, 0, 0, 0);


    // initialize with values such that using them before they are set
    // will cause bad things to happen
    m_dwZOrder = 0;
    m_dwInternalZOrder = (m_dwZOrder << 24) | m_dwPinId;
    m_dwBlendingParameter = MAX_BLEND_VAL;
    m_bStreamTransparent = FALSE;
    m_amAspectRatioMode = (m_dwPinId == 0) ? (AM_ARMODE_LETTER_BOX) : (AM_ARMODE_STRETCHED);
    m_bRuntimeNegotiationFailed = FALSE;

    m_bVideoAcceleratorSupported = FALSE;
    m_dwCompSurfTypes = 0;
    m_pCompSurfInfo = NULL;
    m_pIDDVAContainer = NULL;
    m_pIDDVideoAccelerator = NULL;
    m_pIVANotify = NULL;

    m_bDecimating = FALSE;
    m_lWidth = m_lHeight = 0L;

    if (bCreateVPObject)
    {
        // artifically increase the refcount since the following sequence might end up calling Release()
#ifdef DEBUG
        m_cRef++;
#endif
        m_cOurRef++;

        // this is the block we are trying to make safe by pumping up the ref-count
        {
            pUnkOuter = GetOwner();

            // create the VideoPort object
            hr = CoCreateInstance(CLSID_VPObject, pUnkOuter, CLSCTX_INPROC_SERVER,
                IID_IUnknown, (void**)&m_pIVPUnknown);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("CoCreateInstance(CLSID_VPObject) failed, hr = 0x%x"), hr));
                goto CleanUp;
            }

            // if you are QIing the inner object then you must decrease the refcount of your outer unknown
            hr = m_pIVPUnknown->QueryInterface(IID_IVPObject, (void**)&m_pIVPObject);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("m_pIVPUnknown->QueryInterface(IID_IVPObject) failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
            Release();

            hr = m_pIVPObject->SetObjectLock(m_pFilterLock);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("m_pIVPUnknown->SetObjectLock() failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
        }

        // restore the refcount
#ifdef DEBUG
        m_cRef--;
#endif
        m_cOurRef--;
    }

    m_pSyncObj = new CAMSyncObj(this, &m_pFilter->m_pClock, m_pFilterLock, &hr);
    if (!m_pSyncObj || FAILED(hr))
    {
        if (!FAILED(hr))
            hr = E_OUTOFMEMORY;
        DbgLog((LOG_ERROR, 1, TEXT("new CAMSyncObj failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    if (FAILED(hr))
    {
        *phr = hr;
    }
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::Constructor")));
    return;
}

// destructor
COMInputPin::~COMInputPin(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::Destructor")));

    CAutoLock cLock(m_pFilterLock);

    if (m_pIVPObject)
    {
        LPUNKNOWN  pUnkOuter = GetOwner();
        ASSERT(pUnkOuter);

        // call addref on yourselves before calling the inner object's release
        pUnkOuter->AddRef();
        m_pIVPObject->Release();
        m_pIVPObject = NULL;
    }

    // release the inner object
    if (m_pIVPUnknown)
    {
        m_pIVPUnknown->Release();
        m_pIVPUnknown = NULL;
    }

    if (m_pSyncObj)
    {
        delete m_pSyncObj;
        m_pSyncObj = NULL;
    }

    if (m_WinInfo.hClipRgn)
    {
        DeleteObject(m_WinInfo.hClipRgn);
        m_WinInfo.hClipRgn = NULL;
    }

    if (m_dwPinId == 0 && m_StepEvent != NULL) {
        CloseHandle(m_StepEvent);
    }

    DeleteDIB(&m_BackingDib);

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::Destructor")));
}

// overriden to expose IMediaPosition and IMediaSeeking control interfaces
STDMETHODIMP COMInputPin::NonDelegatingQueryInterface(REFIID riid, void **ppv)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::NonDelegatingQueryInterface")));

    CAutoLock cLock(m_pFilterLock);

    if (riid == IID_IVPControl)
    {
        hr = GetInterface((IVPControl*)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("GetInterface((IVPControl*)this, ppv)  failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (m_pIVPUnknown &&
         (riid == IID_IVPNotify || riid == IID_IVPNotify2 || riid == IID_IVPInfo))
    {
        hr = m_pIVPUnknown->QueryInterface(riid, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPUnknown->QueryInterface failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (riid == IID_IKsPin)
    {
        hr = GetInterface((IKsPin *)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface(IKsPin*) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (riid == IID_IKsPropertySet)
    {
        hr = GetInterface((IKsPropertySet *)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface(IKsPropertySet*) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (riid == IID_IMixerPinConfig)
    {
        hr = GetInterface((IMixerPinConfig*)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface((IMixerPinConfig*)this, ppv) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (riid == IID_IMixerPinConfig2)
    {
        hr = GetInterface((IMixerPinConfig2*)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface((IMixerPinConfig2*)this, ppv) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (riid == IID_IMixerPinConfig3)
    {
        hr = GetInterface((IMixerPinConfig3*)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface((IMixerPinConfig3*)this, ppv) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (riid == IID_IOverlay)
    {
        hr = GetInterface((IOverlay*)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface((IOverlay*)this, ppv) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (riid == IID_IPinConnection)
    {
        hr = GetInterface((IPinConnection*)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface((IPinConnection*)this, ppv) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (riid == IID_IAMVideoAccelerator &&
            0 != GetRegistryDword(HKEY_LOCAL_MACHINE, szVideoAcc, 1) &&
            m_pFilter &&
            !m_pFilter->IsFaultyMMaticsMoComp() )
    {
        hr = GetInterface((IAMVideoAccelerator*)this, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("GetInterface((IAMVideoAccelerator*)this, ppv) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

    else if (riid == IID_ISpecifyPropertyPages&& 0 != GetRegistryDword(HKEY_CURRENT_USER , szPropPage, 0)) {
        return GetInterface((ISpecifyPropertyPages *)this, ppv);
    }

    else
    {
        // call the base class
        hr = CBaseInputPin::NonDelegatingQueryInterface(riid, ppv);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::NonDelegatingQueryInterface failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::NonDelegatingQueryInterface")));
    return hr;
}

//
// NonDelegatingAddRef
//
// We need override this method so that we can do proper reference counting
// on our input pin. The base class CBasePin does not do any reference
// counting on the pin in RETAIL.
//
// Please refer to the comments for the NonDelegatingRelease method for more
// info on why we need to do this.
//
STDMETHODIMP_(ULONG) COMInputPin::NonDelegatingAddRef(void)
{
#ifdef DEBUG
    // Update the debug only variable maintained by the base class
    InterlockedIncrement(&m_cRef);
    ASSERT(m_cRef > 0);
#endif

    // Now update our reference count
    InterlockedIncrement(&m_cOurRef);
    ASSERT(m_cOurRef > 0);
    return m_pFilter->AddRef();

} // NonDelegatingAddRef


//
// NonDelegatingRelease
//
// CAMVPMemInputPin overrides this class so that we can take the pin out of our
// output pins list and delete it when its reference count drops to 1 and there
// is atleast two free pins.
//
// Note that CreateNextOutputPin holds a reference count on the pin so that
// when the count drops to 1, we know that no one else has the pin.
//
// Moreover, the pin that we are about to delete must be a free pin(or else
// the reference would not have dropped to 1, and we must have atleast one
// other free pin(as the filter always wants to have one more free pin)
//
// Also, since CBasePin::NonDelegatingAddRef passes the call to the owning
// filter, we will have to call Release on the owning filter as well.
//
// Also, note that we maintain our own reference count m_cOurRef as the m_cRef
// variable maintained by CBasePin is debug only.
//
STDMETHODIMP_(ULONG) COMInputPin::NonDelegatingRelease(void)
{
#ifdef DEBUG
    // Update the debug only variable in CBasePin
    InterlockedDecrement(&m_cRef);
    ASSERT(m_cRef >= 0);
#endif

    // Now update our reference count
    InterlockedDecrement(&m_cOurRef);
    ASSERT(m_cOurRef >= 0);

    // if the reference count on the object has gone to one, remove
    // the pin from our output pins list and physically delete it
    // provided there are atealst two free pins in the list(including
    // this one)

    // Also, when the ref count drops to 0, it really means that our
    // filter that is holding one ref count has released it so we
    // should delete the pin as well.

    if (m_cOurRef <= 1)
    {
        CAutoLock cLock(m_pFilterLock);

        // default forces pin deletion
        int n = 2;
        // if m_cOurRef is 0, then it means we have released the pin
        // in which case we should always delete the pin.
        if (m_cOurRef == 1)
        {
            // Walk the list of pins, looking for count of free pins
            n = 0;
            for (int i = 0; i < m_pFilter->GetInputPinCount(); i++)
            {
                if (!(m_pFilter->GetPin(i)->IsConnected()))
                {
                    n++;
                }
            }
        }

        // If there are two free pins and this pin is not the primary pin, delete this one.
        if (n >= 2  && !(m_dwPinId == 0))
        {
            DWORD dwFilterRefCount;
            m_cOurRef = 0;
#ifdef DEBUG
            m_cRef = 0;
#endif

            // COM rules say we must protect against re-entrancy.
            // If we are an aggregator and we hold our own interfaces
            // on the aggregatee, the QI for these interfaces will
            // addref ourselves. So after doing the QI we must release
            // a ref count on ourselves. Then, before releasing the
            // private interface, we must addref ourselves. When we do
            // this from the destructor here it will result in the ref
            // count going to 1 and then back to 0 causing us to
            // re-enter the destructor. Hence we add extra refcounts here
            // once we know we will delete the object. Since we delete the
            // pin, when the refcount drops to 1, we make the refcount 2 here
            m_cOurRef = 2;

            dwFilterRefCount = m_pFilter->Release();

            m_pFilter->DeleteInputPin(this);

            return dwFilterRefCount;
        }
    }
    return m_pFilter->Release();

} // NonDelegatingRelease


// --- ISpecifyPropertyPages ---

STDMETHODIMP COMInputPin::GetPages(CAUUID *pPages)
{
    pPages->cElems = 1;
    pPages->pElems = (GUID *) CoTaskMemAlloc(sizeof(GUID)*1);
    if (pPages->pElems == NULL) {
        return E_OUTOFMEMORY;
    }
    pPages->pElems[0] = CLSID_COMPinConfigProperties;

    return NOERROR;
}


// this function just tells whether each sample consists of one or two fields
BOOL DisplayingFields(DWORD dwInterlaceFlags)
{
   if ((dwInterlaceFlags & AMINTERLACE_IsInterlaced) &&
        (dwInterlaceFlags & AMINTERLACE_1FieldPerSample))
        return TRUE;
    else
        return FALSE;
}

// this function just tells whether each sample consists of one or two fields
HRESULT GetTypeSpecificFlagsFromMediaSample(IMediaSample *pSample, DWORD *pdwTypeSpecificFlags)
{
    HRESULT hr = NOERROR;
    IMediaSample2 *pSample2 = NULL;
    AM_SAMPLE2_PROPERTIES SampleProps;

    /* Check for IMediaSample2 */
    if (SUCCEEDED(pSample->QueryInterface(IID_IMediaSample2, (void **)&pSample2)))
    {
        hr = pSample2->GetProperties(sizeof(SampleProps), (PBYTE)&SampleProps);
        pSample2->Release();
        if (FAILED(hr))
        {
            return hr;
        }
        *pdwTypeSpecificFlags = SampleProps.dwTypeSpecificFlags;
    }
    else
    {
        *pdwTypeSpecificFlags = 0;
    }
    return hr;
}

BOOL CheckTypeSpecificFlags(DWORD dwInterlaceFlags, DWORD dwTypeSpecificFlags)
{
    // first determine which field do we want to display here
    if ((dwInterlaceFlags & AMINTERLACE_1FieldPerSample) &&
        ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_INTERLEAVED_FRAME))
    {
        return FALSE;
    }

    if ((!(dwInterlaceFlags & AMINTERLACE_1FieldPerSample)) &&
        (((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1) ||
           ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD2)))
    {
        return FALSE;
    }

    if (dwTypeSpecificFlags & AM_VIDEO_FLAG_REPEAT_FIELD)
    {
        return FALSE;
    }

    return TRUE;
}

// given the interlace flags and the type-specific flags, this function determines whether we
// are supposed to display the sample in bob-mode or not. It also tells us, which direct-draw flag
// are we supposed to use when flipping. When displaying an interleaved frame, it assumes we are
// talking about the field which is supposed to be displayed first.
BOOL NeedToFlipOddEven(DWORD dwInterlaceFlags, DWORD dwTypeSpecificFlags, DWORD *pdwFlipFlag)
{
    BOOL bDisplayField1 = TRUE;
    BOOL bField1IsOdd = TRUE;
    BOOL bNeedToFlipOddEven = FALSE;
    DWORD dwFlipFlag = 0;

    // if not interlaced content, mode is not bob
    if (!(dwInterlaceFlags & AMINTERLACE_IsInterlaced))
    {
        bNeedToFlipOddEven = FALSE;
        goto CleanUp;
    }

    // if sample have a single field, then check the field pattern
    if ((dwInterlaceFlags & AMINTERLACE_1FieldPerSample) &&
        (((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField1Only) ||
         ((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField2Only)))
    {
        bNeedToFlipOddEven = FALSE;
        goto CleanUp;
    }

    if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOnly) ||
        (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOrWeave) &&
         (!(dwTypeSpecificFlags & AM_VIDEO_FLAG_WEAVE))))
    {
        // first determine which field do we want to display here
        if (dwInterlaceFlags & AMINTERLACE_1FieldPerSample)
        {
            // if we are in 1FieldPerSample mode, check which field is it
            ASSERT(((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1) ||
                ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD2));
            bDisplayField1 = ((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_FIELD1);
        }
        else
        {
            // ok the sample is an interleaved frame
            ASSERT((dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD_MASK) == AM_VIDEO_FLAG_INTERLEAVED_FRAME);
            bDisplayField1 = (dwTypeSpecificFlags & AM_VIDEO_FLAG_FIELD1FIRST);
        }

        bField1IsOdd = (dwInterlaceFlags & AMINTERLACE_Field1First);

        // if we displaying field 1 and field 1 is odd or we are displaying field2 and field 2 is odd
        // then use DDFLIP_ODD. Exactly the opposite for DDFLIP_EVEN
        if ((bDisplayField1 && bField1IsOdd) || (!bDisplayField1 && !bField1IsOdd))
            dwFlipFlag = DDFLIP_ODD;
        else
            dwFlipFlag = DDFLIP_EVEN;

        bNeedToFlipOddEven = TRUE;
        goto CleanUp;
    }

CleanUp:
    if (pdwFlipFlag)
        *pdwFlipFlag = dwFlipFlag;
    return bNeedToFlipOddEven;
}

// given the interlace flags and the type-specific flags, this function determines whether we
// are supposed to display the sample in bob-mode or not. It also tells us, which direct-draw flag
// are we supposed to use when flipping. When displaying an interleaved frame, it assumes we are
// talking about the field which is supposed to be displayed first.
DWORD GetUpdateOverlayFlags(DWORD dwInterlaceFlags, DWORD dwTypeSpecificFlags)
{
    DWORD dwFlags = DDOVER_SHOW | DDOVER_KEYDEST;
    DWORD dwFlipFlag;

    if (NeedToFlipOddEven(dwInterlaceFlags, dwTypeSpecificFlags, &dwFlipFlag))
    {
        dwFlags |= DDOVER_BOB;
        if (!DisplayingFields(dwInterlaceFlags))
            dwFlags |= DDOVER_INTERLEAVED;
    }
    return dwFlags;
}

// this function checks if the InterlaceFlags are suitable or not
HRESULT COMInputPin::CheckInterlaceFlags(DWORD dwInterlaceFlags)
{
    HRESULT hr = NOERROR;


    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::CheckInterlaceFlags")));

    CAutoLock cLock(m_pFilterLock);

    if (dwInterlaceFlags & AMINTERLACE_UNUSED)
    {
        hr = VFW_E_TYPE_NOT_ACCEPTED;
        goto CleanUp;
    }

    // check that the display mode is one of the three allowed values
    if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) != AMINTERLACE_DisplayModeBobOnly) &&
        ((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) != AMINTERLACE_DisplayModeWeaveOnly) &&
        ((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) != AMINTERLACE_DisplayModeBobOrWeave))
    {
        hr = VFW_E_TYPE_NOT_ACCEPTED;
        goto CleanUp;
    }

    // if content is not interlaced, other bits are irrelavant, so we are done
    if (!(dwInterlaceFlags & AMINTERLACE_IsInterlaced))
    {
        goto CleanUp;
    }

    // samples are frames, not fields (so we can handle any display mode)
    if (!(dwInterlaceFlags & AMINTERLACE_1FieldPerSample))
    {
        goto CleanUp;
    }

    // can handle a stream of just field1 or field2, whatever the display mode
    if (((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField1Only) ||
        ((dwInterlaceFlags & AMINTERLACE_FieldPatternMask) == AMINTERLACE_FieldPatField2Only))
    {
        goto CleanUp;
    }

    // can handle only bob-mode for field samples
    if ((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOnly)
    {
        goto CleanUp;
    }

    // cannot handle only Weave mode or BobOrWeave mode for field samples
    if (((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeWeaveOnly) ||
         ((dwInterlaceFlags & AMINTERLACE_DisplayModeMask) == AMINTERLACE_DisplayModeBobOrWeave))
    {
        hr = VFW_E_TYPE_NOT_ACCEPTED;
        goto CleanUp;
    }

    // we should have covered all possible scenarios by now, so assert here
    ASSERT(1);

CleanUp:

    // we cannot handle bob mode with an offscreen surface or if the driver can't support it
    if (SUCCEEDED(hr))
    {
        LPDDCAPS pDirectCaps = m_pFilter->GetHardwareCaps();
        if ( pDirectCaps )
        {
            // call NeedToFlipOddEven with dwTypeSpecificFlags=0, to pretend that the
            // type-specific-flags is asking us to do bob-mode.
            if (((m_RenderTransport != AM_OVERLAY && m_RenderTransport != AM_VIDEOACCELERATOR) ||
                 (!((pDirectCaps->dwCaps2) & DDCAPS2_CANFLIPODDEVEN))) &&
                (NeedToFlipOddEven(dwInterlaceFlags, 0, NULL)))
            {
                hr = VFW_E_TYPE_NOT_ACCEPTED;
            }
        }
    }
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::CheckInterlaceFlags")));
    return hr;
}

// this function check if the mediatype on a dynamic format change is suitable.
// No lock is taken here. It is the callee's responsibility to maintain integrity!
HRESULT COMInputPin::DynamicCheckMediaType(const CMediaType* pmt)
{
    HRESULT hr = VFW_E_TYPE_NOT_ACCEPTED;
    BITMAPINFOHEADER *pNewHeader = NULL, *pOldHeader = NULL;
    DWORD dwOldInterlaceFlags = 0, dwNewInterlaceFlags = 0, dwCompareSize = 0;
    BOOL bOld1FieldPerSample = FALSE, bNew1FieldPerSample = FALSE;
    BOOL b1, b2;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::DynamicCheckMediaType")));

    // majortype and SubType are not allowed to change dynamically,
    // format type can change.
    if ((!(IsEqualGUID(pmt->majortype, m_mtNew.majortype))) ||
        (!(IsEqualGUID(pmt->subtype, m_mtNew.subtype))))
    {
        goto CleanUp;
    }

    // get the interlace flags of the new mediatype
    hr = GetInterlaceFlagsFromMediaType(pmt, &dwNewInterlaceFlags);
    if (FAILED(hr))
    {
        goto CleanUp;
    }

    // get the interlace flags of the new mediatype
    hr = GetInterlaceFlagsFromMediaType(&m_mtNew, &dwOldInterlaceFlags);
    if (FAILED(hr))
    {
        goto CleanUp;
    }

    //
    // There are several bugs in the following code !!
    // We goto CleanUp but hr has not been updated with a valid error code!!
    //

    bOld1FieldPerSample = (dwOldInterlaceFlags & AMINTERLACE_IsInterlaced) &&
        (dwOldInterlaceFlags & AMINTERLACE_1FieldPerSample);
    bNew1FieldPerSample = (dwNewInterlaceFlags & AMINTERLACE_IsInterlaced) &&
        (dwNewInterlaceFlags & AMINTERLACE_1FieldPerSample);


    // we do not allow dynamic format changes where you go from 1FieldsPerSample to
    // 2FieldsPerSample or vica-versa since that means reallocating the surfaces.
    if (bNew1FieldPerSample != bOld1FieldPerSample)
    {
        goto CleanUp;
    }

    pNewHeader = GetbmiHeader(pmt);
    if (!pNewHeader)
    {
        goto CleanUp;
    }

    pOldHeader = GetbmiHeader(&m_mtNew);
    if (!pNewHeader)
    {
        goto CleanUp;
    }

    dwCompareSize = FIELD_OFFSET(BITMAPINFOHEADER, biClrUsed);
    ASSERT(dwCompareSize < sizeof(BITMAPINFOHEADER));

    if (memcmp(pNewHeader, pOldHeader, dwCompareSize) != 0)
    {
        goto CleanUp;
    }

    hr = NOERROR;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::DynamicCheckMediaType")));
    return hr;
}


// check that the mediatype is acceptable. No lock is taken here. It is the callee's
// responsibility to maintain integrity!
HRESULT COMInputPin::CheckMediaType(const CMediaType* pmt)
{
    HRESULT hr = NOERROR;
    BOOL bAcceptableVPMediatype = FALSE, bAcceptableNonVPMediatype = FALSE;
    BITMAPINFOHEADER *pHeader = NULL;
    VIDEOINFOHEADER2 *pVideoInfoHeader2 = NULL;
    RECT rTempRect;
    DWORD dwInterlaceFlags;
    LPDDCAPS pDirectCaps = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::CheckMediaType")));

    if (m_RenderTransport == AM_OVERLAY ||
        m_RenderTransport == AM_OFFSCREEN ||
        m_RenderTransport == AM_VIDEOACCELERATOR)
    {
        pDirectCaps = m_pFilter->GetHardwareCaps();
        if (!pDirectCaps)
        {
            DbgLog((LOG_ERROR, 2, TEXT("no ddraw support, so not accepting this mediatype")));
            hr = VFW_E_TYPE_NOT_ACCEPTED;
            goto CleanUp;
        }
    }

    // check if the VP component likes this mediatype
    if (m_bVPSupported)
    {
        // check if the videoport object likes it
        hr = m_pIVPObject->CheckMediaType(pmt);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("m_pIVPObject->CheckMediaType failed, hr = 0x%x"), hr));
        }
        else
        {
            bAcceptableVPMediatype = TRUE;
            DbgLog((LOG_TRACE, 2, TEXT("m_pIVPObject->CheckMediaType succeeded, bAcceptableVPMediatype is TRUE")));
            goto CleanUp;
        }
    }

    // if subtype is overlay make sure we support IOverlay
    if (!m_bIOverlaySupported && pmt->subtype == MEDIASUBTYPE_Overlay)
    {
        DbgLog((LOG_TRACE, 2, TEXT("m_pIVPObject->CheckMediaType failed, Subtype = MEDIASUBTYPE_Overlay, however pin does not support IOverlay")));
        goto CleanUp;
    }

    // here we check if the header is ok, either by matching it with the connection mediatype
    // or examinining each field
    if (m_bConnected)
    {
        hr = DynamicCheckMediaType(pmt);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("DynamicCheckMediaType(const CMediaType* pmt) failed, hr = 0x%x"), hr));
            goto CleanUp;

        }
    }
    else
    {
        // make sure that the major type is appropriate
        if (pmt->majortype != MEDIATYPE_Video)
        {
            DbgLog((LOG_ERROR, 2, TEXT("pmt->majortype != MEDIATYPE_Video")));
            goto CleanUp;
        }

        if (MEDIASUBTYPE_HASALPHA(*pmt)) {

            DbgLog((LOG_ERROR, 1,
                    TEXT("CheckMediaType failed on Pin %d: Alpha formats ")
                    TEXT("not allowed by the OVMixer"), m_dwPinId));
            goto CleanUp;
        }

        pHeader = GetbmiHeader(pmt);
        if (!pHeader)
        {
            DbgLog((LOG_ERROR, 2, TEXT("pHeader is NULL")));
            goto CleanUp;
        }

        // make sure that the format type is appropriate
        if ((*pmt->FormatType() != FORMAT_VideoInfo || m_pFilter->OnlySupportVideoInfo2()) &&
            (*pmt->FormatType() != FORMAT_VideoInfo2))
        {
            DbgLog((LOG_ERROR, 2, TEXT("FormatType() != FORMAT_VideoInfo && FormatType() != FORMAT_VideoInfo2")));
            goto CleanUp;
        }

        // if the subtype is Overlay then we are not going to create any surfaces, therefore
        // we can skip these checks
        if (pmt->subtype != MEDIASUBTYPE_Overlay)
        {
            if (m_RenderTransport != AM_GDI && !IsSuitableVideoAcceleratorGuid(&pmt->subtype))
            {
                // Don't accept 4CC not supported by the driver
                if (pHeader->biCompression > BI_BITFIELDS)
                {
                    IDirectDraw *pDDraw = m_pFilter->GetDirectDraw();

                    //
                    // Only check the MoComp surface against the listed
                    // FOURCC's if the driver actually supports the
                    // MoComp interfaces.  This is because some drivers
                    // have hidden FOURCC surfaces that they don't report
                    // via calls to GetFourCCCodes.  This basically a
                    // hack for backward compatibility
                    //

                    if (pDDraw != NULL && m_pIDDVAContainer != NULL) {

                        DWORD dwCodes;
                        BOOL bFound = FALSE;
                        if (SUCCEEDED(pDDraw->GetFourCCCodes(&dwCodes, NULL))) {
                            LPDWORD pdwCodes = (LPDWORD)_alloca(dwCodes * sizeof(DWORD));
                            if (SUCCEEDED(pDDraw->GetFourCCCodes(&dwCodes, pdwCodes))) {
                                while (dwCodes--) {
                                    if (pdwCodes[dwCodes] == pHeader->biCompression) {
                                        bFound = TRUE;
                                        break;
                                    }
                                }
                                if (!bFound) {
                                    DbgLog((LOG_TRACE, 2, TEXT("4CC(%4.4s) not supported by driver"),
                                            &pHeader->biCompression));
                                    hr = VFW_E_TYPE_NOT_ACCEPTED;
                                    goto CleanUp;
                                }
                            }
                        }
                    }
                }
            }

            if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_VIDEOACCELERATOR)
            {
                FOURCCMap amFourCCMap(pmt->Subtype());

                ASSERT(pDirectCaps);
                if (!(pDirectCaps->dwCaps & DDCAPS_OVERLAY))
                {
                    DbgLog((LOG_ERROR, 2, TEXT("no overlay support in hardware, so not accepting this mediatype")));
                    goto CleanUp;
                }

#if 0
                //
                // This test below looks completely bogus for both AM_OVERLAY
                // and AM_VIDEOACCELERATOR render transports.  I'll remove it for now
                // see what breaks or starts working !!
                //
                // StEstrop 5th Feb 99.
                //

                // for the overlay surface case, we accept both RGB and YUV surfaces
                if ((pHeader->biCompression <= BI_BITFIELDS &&
                     m_pFilter->GetDisplay()->GetDisplayDepth() > pHeader->biBitCount) ||
                    (pHeader->biCompression > BI_BITFIELDS &&
                     pHeader->biCompression != amFourCCMap.GetFOURCC()))
                {
                    DbgLog((LOG_ERROR, 2, "Bit depth not suitable"));
                    goto CleanUp;
                }
#endif

            }
            else if (m_RenderTransport == AM_OFFSCREEN)
            {
                // since we create offscreen surfaces in system memory and ddraw cannot emulate
                // YUV to RGB conversion, we only accept RGB mediatypes in this scenario
                if (pHeader->biCompression > BI_BITFIELDS ||
                    m_pFilter->GetDisplay()->GetDisplayDepth() != pHeader->biBitCount)
                {
                    DbgLog((LOG_ERROR, 2, TEXT("Bit depth not suitable for RGB surfaces")));
                    goto CleanUp;
                }
            }
            else if (m_RenderTransport == AM_GDI)
            {
                hr = m_pFilter->GetDisplay()->CheckMediaType(pmt);
                if (FAILED(hr))
                {
                    goto CleanUp;
                }
            }
        }
    }

    // make sure the rcSource field is valid
    hr = GetSrcRectFromMediaType(pmt, &rTempRect);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 2, TEXT("GetSrcRectFromMediaType(&pmt, &rSrcRect) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // make sure the rcTarget field is valid
    hr = GetDestRectFromMediaType(pmt, &rTempRect);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 2, TEXT("GetDestRectFromMediaType(&pmt, &rSrcRect) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (*pmt->FormatType() == FORMAT_VideoInfo2)
    {
        pVideoInfoHeader2 = (VIDEOINFOHEADER2*)(pmt->pbFormat);

        dwInterlaceFlags = pVideoInfoHeader2->dwInterlaceFlags;

        hr = CheckInterlaceFlags(dwInterlaceFlags);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2, TEXT("CheckInterlaceFlags(dwInterlaceFlags) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
        // make sure the reserved fields are zero
        if (pVideoInfoHeader2->dwReserved1 != 0 ||
            pVideoInfoHeader2->dwReserved2 != 0)
        {
            DbgLog((LOG_ERROR, 2, TEXT("Format VideoInfoHeader2, reserved fields not validpmt, &rSrcRect) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

    // if we have so far things shoud be fine
    bAcceptableNonVPMediatype = TRUE;

//#define CHECK_REGISTRY
#ifdef CHECK_REGISTRY
    {
        HKEY hKey;
        CHAR szFourCC[5];
        if (pHeader->biCompression != BI_RGB &&
            pHeader->biCompression != BI_BITFIELDS &&
            !RegOpenKeyEx(HKEY_CURRENT_USER,
                          TEXT("Software\\Microsoft\\Multimedia\\ActiveMovie Filters\\Overlay Mixer"),
                          0,
                          KEY_QUERY_VALUE,
                          &hKey))
        {
            *(DWORD *)szFourCC = pHeader->biCompression;
            szFourCC[4] = '\0';
            DWORD dwType;
            DWORD dwValue;
            DWORD dwBufferSize = sizeof(dwValue);
            if (!RegQueryValueExA(hKey,
                                  szFourCC,
                                  NULL,
                                  &dwType,
                                  (PBYTE)&dwValue,
                                  &dwBufferSize))
            {
               if (dwValue == 0)
               {
                   DbgLog((LOG_ERROR, 1, TEXT("Surface type %hs disabled in registry"), szFourCC));
                   bAcceptableNonVPMediatype = FALSE;
               }
            }
            RegCloseKey(hKey);
        }
    }
#endif // CHECK_REGISTRY

CleanUp:
    if (!bAcceptableVPMediatype && !bAcceptableNonVPMediatype)
    {
        hr = VFW_E_TYPE_NOT_ACCEPTED;
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::CheckMediaType")));
    return hr;
}

// called after we have agreed a media type to actually set it
HRESULT COMInputPin::SetMediaType(const CMediaType* pmt)
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pHeader = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetMediaType")));

    CAutoLock cLock(m_pFilterLock);

    // make sure the mediatype is correct
    hr = CheckMediaType(pmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CheckMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    pHeader = GetbmiHeader(pmt);
    if (pHeader)
    {
        // store it in our mediatype as well
        m_mtNew = *pmt;

        // store the interlace flags since we use them again and again
        hr = GetInterlaceFlagsFromMediaType(&m_mtNew, &m_dwInterlaceFlags);
        ASSERT(SUCCEEDED(hr));

        // store the update overlay flags (give the type specific flag is WEAVE so that for BOB or WEAVE
        // mode, we not bob
        m_dwUpdateOverlayFlags = GetUpdateOverlayFlags(m_dwInterlaceFlags, AM_VIDEO_FLAG_WEAVE);
    }

    // Set the base class media type (should always succeed)
    hr = CBaseInputPin::SetMediaType(pmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::SetMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // check if this is videoport or an IOverlay connection
    if (m_bVPSupported)
    {
        hr = m_pIVPObject->CheckMediaType(pmt);
        if (SUCCEEDED(hr))
        {
            ASSERT(m_bVPSupported);
            m_RenderTransport = AM_VIDEOPORT;
            m_pFilter->SetDecimationUsage(DECIMATION_LEGACY);
            hr = m_pIVPObject->SetMediaType(pmt);
            ASSERT(SUCCEEDED(hr));
            DbgLog((LOG_TRACE, 2, TEXT("m_RenderTransport is AM_VIDEOPORT")));
        }
        hr = NOERROR;
    }

    if (m_bIOverlaySupported && pmt->subtype == MEDIASUBTYPE_Overlay)
    {
        m_RenderTransport = AM_IOVERLAY;
        DbgLog((LOG_TRACE, 2, TEXT("m_bIOverlaySupported is TRUE")));
    }

    if (m_bVideoAcceleratorSupported && IsSuitableVideoAcceleratorGuid((LPGUID)&pmt->subtype))
    {
        if (m_pIVANotify == NULL) {
            // get the IHWVideoAcceleratorNotify interface from the input pin
            hr = m_Connected->QueryInterface(IID_IAMVideoAcceleratorNotify, (void **)&m_pIVANotify);
        }
        if (SUCCEEDED(hr))
        {
            ASSERT(m_pIVANotify);
            /*  Check if motion comp is really supported */
            m_mtNewAdjusted = m_mtNew;
            m_RenderTransport = AM_VIDEOACCELERATOR;
            m_bSyncOnFill = FALSE;
            DbgLog((LOG_TRACE, 2, TEXT("this is a motion comp connection")));
        }
    }

    // tell the proxy not to allocate buffers if it is a videoport or overlay connection
    if (m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY  || m_RenderTransport == AM_VIDEOACCELERATOR)
    {
        SetStreamingInKernelMode(TRUE);
    }

    // tell the owning filter
    hr = m_pFilter->SetMediaType(m_dwPinId, pmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->SetMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }



CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetMediaType")));
    return hr;
}


HRESULT COMInputPin::CurrentAdjustedMediaType(CMediaType *pmt)
{
    ValidateReadWritePtr(pmt,sizeof(AM_MEDIA_TYPE));
    CAutoLock cLock(m_pFilterLock);

    /*  Copy constructor of m_mt allocates the memory */
    if (IsConnected())
    {
        *pmt = m_mtNewAdjusted;
        return S_OK;
    } else
    {
        pmt->InitMediaType();
        return VFW_E_NOT_CONNECTED;
    }
}

HRESULT COMInputPin::CopyAndAdjustMediaType(CMediaType *pmtTarget, CMediaType *pmtSource)
{
    BITMAPINFOHEADER *pHeader = NULL;

    ValidateReadWritePtr(pmtTarget,sizeof(AM_MEDIA_TYPE));
    ValidateReadWritePtr(pmtSource,sizeof(AM_MEDIA_TYPE));

    *pmtTarget = *pmtSource;

    if (m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY || m_RenderTransport == AM_GDI
        || m_RenderTransport == AM_VIDEOACCELERATOR)
        return NOERROR;

    ASSERT(m_dwDirectDrawSurfaceWidth);
    ASSERT(IsConnected());
    pHeader = GetbmiHeader(pmtTarget);
    if ( pHeader )
        pHeader->biWidth = (LONG)m_dwDirectDrawSurfaceWidth;

    return NOERROR;
}

#ifdef DEBUG
/*****************************Private*Routine******************************\
* VideoFormat2String
*
* Converts a video format block to a string - useful for debugging
*
* History:
* Tue 12/07/1999 - StEstrop - Created
*
\**************************************************************************/
void VideoFormat2String(
    LPTSTR szBuffer,
    const GUID* pFormatType,
    BYTE* pFormat,
    ULONG lFormatLength
    )
{
    if (!pFormat) {
        lstrcpy(szBuffer, TEXT("No format data specified"));
    }

    //
    // Video Format
    //
    if (IsEqualGUID(*pFormatType, FORMAT_VideoInfo) ||
        IsEqualGUID(*pFormatType, FORMAT_MPEGVideo)) {

        VIDEOINFO * pVideoFormat = (VIDEOINFO *) pFormat;

        wsprintf(szBuffer, TEXT("%4.4hs %dx%d, %d bits"),
                 (pVideoFormat->bmiHeader.biCompression == 0) ? "RGB " :
                 ((pVideoFormat->bmiHeader.biCompression == BI_BITFIELDS) ? "BITF" :
                 (LPSTR) &pVideoFormat->bmiHeader.biCompression),
                 pVideoFormat->bmiHeader.biWidth,
                 pVideoFormat->bmiHeader.biHeight,
                 pVideoFormat->bmiHeader.biBitCount);
    }
    else if (IsEqualGUID(*pFormatType, FORMAT_VideoInfo2) ||
             IsEqualGUID(*pFormatType, FORMAT_MPEG2Video)) {

        VIDEOINFOHEADER2 * pVideoFormat = (VIDEOINFOHEADER2 *) pFormat;

        wsprintf(szBuffer, TEXT("%4.4hs %dx%d, %d bits"),
                 (pVideoFormat->bmiHeader.biCompression == 0) ? "RGB " :
                 ((pVideoFormat->bmiHeader.biCompression == BI_BITFIELDS) ? "BITF" :
                 (LPSTR) &pVideoFormat->bmiHeader.biCompression ),
                 pVideoFormat->bmiHeader.biWidth,
                 pVideoFormat->bmiHeader.biHeight,
                 pVideoFormat->bmiHeader.biBitCount);

    }
    else {
        lstrcpy(szBuffer, TEXT("Unknown format"));
    }
}
#endif
// pConnector is the initiating connecting pin
// pmt is the media type we will exchange
// This function is also called while the graph is running when the
// up stream decoder filter wants to change the size of the
// decoded video.
//
// If the up stream decoder wants to change from one transport
// type to another, eg. from MoComp back to IMemInputPin then it
// should perform a dynamic filter reconnect via the IGraphConfig
// Reconnect method.
//
STDMETHODIMP COMInputPin::ReceiveConnection(IPin * pConnector, const AM_MEDIA_TYPE *pmt)
{
    HRESULT hr = NOERROR;
    COMInputAllocator * pAlloc = NULL;

    CAutoLock cLock(m_pFilterLock);

    CheckPointer(pmt, E_POINTER);
    CMediaType cmt(*pmt);

    if (m_Connected != pConnector || pConnector == NULL)
    {
        hr = CBaseInputPin::ReceiveConnection(pConnector, &cmt);
        goto CleanUp;
    }

#ifdef DEBUG
    DbgLog((LOG_TRACE, 2, TEXT("ReceiveConnection when connected")));
    if (pmt)
    {
        TCHAR   szFmt[128];
        VideoFormat2String(szFmt, &pmt->formattype, pmt->pbFormat, pmt->cbFormat);
        DbgLog((LOG_TRACE, 2, TEXT("Format is: %s"), szFmt));
    }
#endif

    //
    // We don't have an allocator when we are using MoComp
    //
    if (m_RenderTransport != AM_VIDEOACCELERATOR)
    {
        /*  Can only do this if the allocator can be reconfigured */
        pAlloc = (COMInputAllocator *)m_pAllocator;
        if (!pAlloc)
        {
            hr = E_FAIL;
            DbgLog((LOG_TRACE, 2, TEXT("ReceiveConnection: Failed because of no allocator")));
            goto CleanUp;
        }

        if (!pAlloc->CanFree())
        {
            hr = VFW_E_WRONG_STATE;
            DbgLog((LOG_TRACE, 2, TEXT("ReceiveConnection: Failed because allocator can't free")));
            goto CleanUp;
        }
    }


    m_bConnected = FALSE;

    hr = CheckMediaType(&cmt);
    if (FAILED(hr))
    {
        DbgLog((LOG_TRACE, 2, TEXT("ReceiveConnection: CheckMediaType failed")));
        goto CleanUp;
    }

    ALLOCATOR_PROPERTIES Props;
    if (m_RenderTransport != AM_VIDEOACCELERATOR)
    {
        pAlloc->Decommit();
        pAlloc->GetProperties(&Props);

    }
    else {
        VABreakConnect();
    }

    // release the ddraw surface
    if (m_pDirectDrawSurface)
    {
        m_pDirectDrawSurface->Release();
        m_pDirectDrawSurface = NULL;
    }


    // back buffers are not addref'd so just set them to NULL
    m_dwBackBufferCount = 0;
    m_dwDirectDrawSurfaceWidth = 0;
    SetMediaType(&cmt);

    if (m_RenderTransport != AM_VIDEOACCELERATOR)
    {
        ALLOCATOR_PROPERTIES PropsActual;
        Props.cbBuffer = pmt->lSampleSize;
        hr = pAlloc->SetProperties(&Props, &PropsActual);
        if (SUCCEEDED(hr))
        {
            hr = pAlloc->Commit();
        }
        else goto CleanUp;
    }
    else {
        hr = VACompleteConnect(pConnector, &cmt);
        if (FAILED(hr)) goto CleanUp;
    }

    hr = UpdateMediaType();
    ASSERT(SUCCEEDED(hr));

    m_bConnected = TRUE;
    m_UpdateOverlayNeededAfterReceiveConnection = true;


CleanUp:
    return hr;
}

HRESULT COMInputPin::CheckConnect(IPin * pReceivePin)
{
    HRESULT hr = NOERROR;
    PKSMULTIPLE_ITEM pMediumList = NULL;
    IKsPin *pIKsPin = NULL;
    PKSPIN_MEDIUM pMedium = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::CheckConnect")));

    CAutoLock cLock(m_pFilterLock);

    if (m_bVPSupported)
    {
        hr = pReceivePin->QueryInterface(IID_IKsPin, (void **)&pIKsPin);
        if (FAILED(hr))
        {
            goto CleanUp;
        }
        ASSERT(pIKsPin);

        hr = pIKsPin->KsQueryMediums(&pMediumList);
        if (FAILED(hr))
        {
            goto CleanUp;
        }
        ASSERT(pMediumList);
        pMedium = (KSPIN_MEDIUM *)(pMediumList+1);
        SetKsMedium((const KSPIN_MEDIUM *)pMedium);
        goto CleanUp;
    }

CleanUp:

    // call the base class
    hr = CBaseInputPin::CheckConnect(pReceivePin);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::CheckConnect failed, hr = 0x%x"), hr));
    }

    if (pIKsPin)
    {
        pIKsPin->Release();
        pIKsPin = NULL;
    }

    if (pMediumList)
    {
        CoTaskMemFree((void*)pMediumList);
        pMediumList = NULL;
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::CheckConnect")));
    return hr;
}

HRESULT COMInputPin::UpdateMediaType()
{
    HRESULT hr = NOERROR;
    long lEventParam1 = 0, lEventParam2 = 0;
    DWORD dwVideoWidth = 0, dwVideoHeight = 0, dwPictAspectRatioX = 0, dwPictAspectRatioY = 0;
    BITMAPINFOHEADER *pHeader = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::UpdateMediaType")));

    // store m_mtNew in m_mtNewAdjusted with the width of the mediatype adjusted
    CopyAndAdjustMediaType(&m_mtNewAdjusted, &m_mtNew);

    // get the native width and height from the mediatype
    pHeader = GetbmiHeader(&m_mtNewAdjusted);
    ASSERT(pHeader);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        hr = E_FAIL;
        goto CleanUp;
    }
    dwVideoWidth = abs(pHeader->biWidth);
    dwVideoHeight = abs(pHeader->biHeight);

    // get the picture aspect ratio from the mediatype
    hr = GetPictAspectRatio(&m_mtNewAdjusted, &dwPictAspectRatioX, &dwPictAspectRatioY);
    ASSERT(SUCCEEDED(hr));
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetPictAspectRatio failed, hr = 0x%x"), hr));
        hr = E_FAIL;
        goto CleanUp;
    }

    // sanity checks
    ASSERT(dwVideoWidth > 0);
    ASSERT(dwVideoHeight > 0);
    ASSERT(dwPictAspectRatioX > 0);
    ASSERT(dwPictAspectRatioY > 0);

    if (m_pFilter->m_pExclModeCallback) {
        m_pFilter->m_pExclModeCallback->OnUpdateSize(dwVideoWidth,
                                                      dwVideoHeight,
                                                      dwPictAspectRatioX,
                                                      dwPictAspectRatioY);
    }


CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::UpdateMediaType")));
    return hr;
}

// final connect
HRESULT COMInputPin::FinalConnect()
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::FinalConnect")));

    if (m_bConnected)
    {
        hr = E_FAIL;
        goto CleanUp;
    }

    // update the mediatype, tell the filter about the updated dimensions
    hr = UpdateMediaType();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("UpdateMediaType failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // tell the filter (might involve a reconnection with the output pin)
    hr = m_pFilter->CompleteConnect(m_dwPinId);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->CompleteConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if ( m_dwPinId == 0 &&
        (m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY)) {
        m_pFilter->m_fMonitorWarning = TRUE;
    }

    hr = m_pFilter->CreateInputPin(FALSE);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->CreateInputPin failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    m_bConnected = TRUE;

CleanUp:

//  if (SUCCEEDED(hr) && m_mt.pbFormat) {
//      DbgLog((LOG_TRACE, 1, TEXT("Display depth = %d"),
//              ((VIDEOINFOHEADER *)m_mt.pbFormat)->bmiHeader.biBitCount));
//  }
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::FinalConnect")));
    return hr;
}

// Complete Connect
HRESULT COMInputPin::CompleteConnect(IPin *pReceivePin)
{
    HRESULT hr = NOERROR;
    AMVPDATAINFO amvpDataInfo;
    BITMAPINFOHEADER *pHeader = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::CompleteConnect")));

    CAutoLock cLock(m_pFilterLock);

    //
    // Do we need to create a DIB back buffer ?
    // We only do this if the transport is AM_GDI and
    // we are "WindowLess"
    //
    if (m_RenderTransport == AM_GDI && m_pFilter->UsingWindowless()) {

        DeleteDIB(&m_BackingDib);

        m_BackingImageSize = 0L;
        BITMAPINFOHEADER *pHeader = GetbmiHeader(&m_mt);

        if (pHeader) {

            m_BackingImageSize = pHeader->biSizeImage;
            hr = CreateDIB(m_BackingImageSize, (BITMAPINFO*)pHeader, &m_BackingDib);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("CreateDIB in CompleteConnect failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
            ZeroMemory(m_BackingDib.pBase, pHeader->biSizeImage);
        }
    }

    if (m_RenderTransport == AM_VIDEOPORT)
    {
        //get videoport from BPC.

        m_pFilter->m_BPCWrap.TurnBPCOff();

        // tell the videoport object
        hr = m_pIVPObject->CompleteConnect(pReceivePin);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->CompleteConnect failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        m_bRuntimeNegotiationFailed = FALSE;
    }

    // call the base class
    hr = CBaseInputPin::CompleteConnect(pReceivePin);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::CompleteConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    if (m_RenderTransport == AM_VIDEOACCELERATOR)
    {
        // make sure the motion comp complete connect succeeds
        hr = VACompleteConnect(pReceivePin, &m_mt);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("VACompleteConnect failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // tell the sync object
        hr = m_pSyncObj->CompleteConnect(pReceivePin);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->CompleteConnect failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        hr = m_pFilter->CreateInputPin(FALSE);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->CreateInputPin failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // tell the owning filter
        hr = m_pFilter->CompleteConnect(m_dwPinId);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->CompleteConnect failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // call the base class
        hr = CBaseInputPin::CompleteConnect(pReceivePin);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::CompleteConnect failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        m_bConnected = TRUE;
    }
    else
    if (m_RenderTransport != AM_VIDEOPORT && m_RenderTransport != AM_IOVERLAY)
    {
        // tell the sync object
        hr = m_pSyncObj->CompleteConnect(pReceivePin);
        ASSERT(SUCCEEDED(hr));

        m_bDynamicFormatNeeded = TRUE;
        m_hMemoryDC = NULL;
    }
    else
    {
        // tell the proxy not to allocate buffers if it is a videoport or overlay connection
        SetStreamingInKernelMode(TRUE);

        hr = FinalConnect();
        ASSERT(SUCCEEDED(hr));
    }

    // the decoders can support a particular property set to tell the ovmixer to not to try to over-allocate
    // buffers incase they want complete control over the buffers etc
    {
        HRESULT hr1 = NOERROR;
        IKsPropertySet *pIKsPropertySet = NULL;
        DWORD dwVal = 0, dwBytesReturned = 0;


        hr1 = pReceivePin->QueryInterface(IID_IKsPropertySet, (void**)&pIKsPropertySet);
        if (SUCCEEDED(hr1))
        {
            ASSERT(pIKsPropertySet);

            if (!pIKsPropertySet)
            {
                DbgLog((LOG_ERROR, 1, TEXT("pIKsPropertySet == NULL, even though QI returned success")));
                goto CleanUp;
            }

            hr1 = pIKsPropertySet->Get(AM_KSPROPSETID_ALLOCATOR_CONTROL, AM_KSPROPERTY_ALLOCATOR_CONTROL_HONOR_COUNT,
                        NULL, 0, &dwVal, sizeof(dwVal), &dwBytesReturned);
            DbgLog((LOG_TRACE, 2, TEXT("pIKsPropertySet->Get(AM_KSPROPSETID_ALLOCATOR_CONTROL), hr1 = 0x%x, dwVal == %d, dwBytesReturned == %d"),
                hr1, dwVal, dwBytesReturned));


            // if the decoder supports this property
            // and its value is 1 and the decoder supports DDKERNELCAPS_FLIPOVERLAY,
            // than we will do exactly honour its request and the
            // and not make any attempt to allocate more in order to prevent tearing
            //
            if ((SUCCEEDED(hr1)) && (dwVal == 1) && (dwBytesReturned == sizeof(dwVal)) &&
                (DDKERNELCAPS_FLIPOVERLAY & m_pFilter->KernelCaps()))
            {
                DbgLog((LOG_TRACE, 2, TEXT("setting m_bCanOverAllocateBuffers == FALSE")));
                m_bCanOverAllocateBuffers = FALSE;
            }
            pIKsPropertySet->Release();
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::CompleteConnect")));
    return hr;
}

#if 0
HRESULT COMInputPin::GetMediaType(int iPosition,CMediaType *pMediaType)
{
    if (m_RenderTransport != AM_GDI) {
        return CBaseInputPin::GetMediaType(iPosition, pMediaType);
    }
    if (iPosition != 0) {
        return VFW_S_NO_MORE_ITEMS;
    }
    //  Return the display type
    CImageDisplay Display;

    //  Now create a media type
    if (!pMediaType->SetFormat((BYTE *)Display.GetDisplayFormat(),
                              sizeof(Display.GetDisplayFormat())))
    {
        return E_OUTOFMEMORY;
    }
    pMediaType->SetFormatType(&FORMAT_VideoInfo);
    pMediaType->SetType(&MEDIATYPE_Video);
    pMediaType->subtype = GetBitmapSubtype(&Display.GetDisplayFormat()->bmiHeader);
    return S_OK;
}
#endif

HRESULT COMInputPin::OnSetProperties(ALLOCATOR_PROPERTIES* pRequest, ALLOCATOR_PROPERTIES* pActual)
{
    HRESULT hr = NOERROR;

    IPin *pReceivePin = NULL;
    DDSURFACEDESC ddSurfaceDesc;
    IEnumMediaTypes *pEnumMediaTypes = NULL;
    CMediaType cMediaType;
    AM_MEDIA_TYPE *pNewMediaType = NULL, *pEnumeratedMediaType = NULL;
    ULONG ulFetched = 0;
    DWORD dwMaxBufferCount = 0;
    BOOL bFoundSuitableSurface = FALSE;
    BITMAPINFOHEADER *pHeader = NULL;
    LPDDCAPS pDirectCaps = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::OnSetProperties")));

    CAutoLock cLock(m_pFilterLock);

    // this function is only called after the base class CBaseAllocator::SetProperties() has been called
    // with the above parameters, so we don't have to do any parameter validation

    ASSERT(IsConnected());
    pReceivePin = CurrentPeer();
    ASSERT(pReceivePin);

    ASSERT(m_RenderTransport != AM_VIDEOPORT && m_RenderTransport != AM_IOVERLAY);
    ASSERT(m_RenderTransport != AM_IOVERLAY);
    ASSERT(m_RenderTransport != AM_VIDEOACCELERATOR);

    // we only care about the number of buffers requested, rest everything is ignored
    if (pRequest->cBuffers <= 0)
    {
        hr = E_FAIL;
        goto CleanUp;
    }

    if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN)
    {
        pDirectCaps = m_pFilter->GetHardwareCaps();
        if (!pDirectCaps) {
            hr = E_FAIL;
            goto CleanUp;
        }

        ASSERT(pDirectCaps);

        // if SetProperties is being called when we have already allocated the surfaces, we refuse any
        // requests for change in buffer count
        if (m_pDirectDrawSurface)
        {
            ASSERT(IsConnected());

            // the upstream filters request for multiple buffers is only met, when we are allocating flipping
            // overlay surfaces
            if (m_RenderTransport == AM_OVERLAY)
            {
                pActual->cBuffers = m_dwBackBufferCount + 1 - (m_bCanOverAllocateBuffers ? EXTRA_BUFFERS_TO_FLIP : 0);
                // if triplebuffered or less, it is just one buffer
                if (pActual->cBuffers <= 0)
                    pActual->cBuffers = 1;
            }
            else if (m_RenderTransport == AM_OFFSCREEN)
            {
                pActual->cBuffers = 1;
            }
            goto CleanUp;
        }

        // Find a media type enumerator for the output pin
        hr = pReceivePin->EnumMediaTypes(&pEnumMediaTypes);
        if (FAILED(hr))
        {
            goto CleanUp;
        }

        ASSERT(pEnumMediaTypes);
        pEnumMediaTypes->Reset();

        do
        {
            // in this loop, this is where we CleanUp
            if (m_pDirectDrawSurface)
            {
                m_pDirectDrawSurface->Release();
                m_pDirectDrawSurface = NULL;
            }
            dwMaxBufferCount = 0;
            m_dwBackBufferCount = 0;

            if (pNewMediaType)
            {
                DeleteMediaType(pNewMediaType);
                pNewMediaType = NULL;

            }

            // Get the next media type from the enumerator
            hr = pEnumMediaTypes->Next(1, &pEnumeratedMediaType, &ulFetched);
            if (FAILED(hr) || ulFetched != 1)
            {
                break;
            }

            ASSERT(pEnumeratedMediaType);
            cMediaType = *pEnumeratedMediaType;
            DeleteMediaType(pEnumeratedMediaType);

            // Find a hardware accellerated surface for this media type. We do a few checks first, to see the
            // format block is a VIDEOINFO or VIDEOINFO2 (so it's a video type), and that the format is sufficiently large. We
            // also check that the source filter can actually supply this type.
            if (((*cMediaType.FormatType() == FORMAT_VideoInfo &&
                cMediaType.FormatLength() >= sizeof(VIDEOINFOHEADER)) ||
                (*cMediaType.FormatType() == FORMAT_VideoInfo2 &&
                cMediaType.FormatLength() >= sizeof(VIDEOINFOHEADER2))) &&
                pReceivePin->QueryAccept(&cMediaType) == S_OK)
            {
                LONG lSrcWidth, lSrcHeight;
                LPBITMAPINFOHEADER pbmiHeader;

                if (m_RenderTransport == AM_OVERLAY) {

                    pbmiHeader = GetbmiHeader(&cMediaType);
                    if (!pbmiHeader) {
                        DbgLog((LOG_ERROR, 1, TEXT("MediaType does not have a BitmapInfoHeader attached - try another")));
                        hr = E_FAIL;
                        continue;
                    }

                    lSrcWidth =  pbmiHeader->biWidth;
                    lSrcHeight =  abs(pbmiHeader->biHeight);
                }
                // create ddraw surface
                dwMaxBufferCount = pRequest->cBuffers + (m_bCanOverAllocateBuffers ? EXTRA_BUFFERS_TO_FLIP : 0);
                hr = CreateDDrawSurface(&cMediaType, m_RenderTransport, &dwMaxBufferCount, &m_pDirectDrawSurface);
                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR, 1, TEXT("CreateDDrawSurface failed, hr = 0x%x"), hr));
                    continue;
                }
                else {
                    PaintDDrawSurfaceBlack(m_pDirectDrawSurface);
                }

                // get the surface description
                INITDDSTRUCT(ddSurfaceDesc);
                hr = m_pDirectDrawSurface->GetSurfaceDesc(&ddSurfaceDesc);
                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface->GetSurfaceDesc failed, hr = 0x%x"), hr));
                    continue;
                }

                // make a mediatype out of the surface description
                pNewMediaType = ConvertSurfaceDescToMediaType(&ddSurfaceDesc, TRUE, cMediaType);
                if (!pNewMediaType)
                {
                    DbgLog((LOG_ERROR, 1, TEXT("ConvertSurfaceDescToMediaType returned NULL")));
                    continue;
                }

                // store the mediatype (will be used to do a dynamic format change later)
                m_mtNew = *(CMediaType *)pNewMediaType;


                // free the temporary mediatype
                DeleteMediaType(pNewMediaType);
                pNewMediaType = NULL;

                // make sure the decoder likes this new mediatupe
                hr = pReceivePin->QueryAccept(&m_mtNew);
                if (hr != S_OK)
                {
                    DbgLog((LOG_ERROR, 1, TEXT("QueryAccept failed, hr = 0x%x"), hr));
                    continue;
                }

                bFoundSuitableSurface = TRUE;
                if (m_RenderTransport == AM_OVERLAY) {
                    m_lSrcWidth = lSrcWidth;
                    m_lSrcHeight = lSrcHeight;
                }
                break;
            }
        }
        while (TRUE);

        pEnumMediaTypes->Release();

        if (!bFoundSuitableSurface)
        {
            DbgLog((LOG_ERROR, 1, TEXT("Could not create a suitable directdraw surface")));
            hr = E_FAIL;
            goto CleanUp;
        }

        ASSERT(m_pDirectDrawSurface);

        // in the overlay surfaces case, we need to do the synchronize in GetBuffer
        m_bSyncOnFill = (m_RenderTransport == AM_OVERLAY && m_dwBackBufferCount == 0);

        // the upstream filters request for multiple buffers is only met, when we are allocating flipping
        // overlay surfaces
        if (m_RenderTransport == AM_OVERLAY)
        {
            pActual->cBuffers = m_dwBackBufferCount + 1 - (m_bCanOverAllocateBuffers ? EXTRA_BUFFERS_TO_FLIP : 0);
            // if triplebuffered or less, it is just equivalent to one buffer
            if (pActual->cBuffers <= 0)
                pActual->cBuffers = 1;
        }
        else if (m_RenderTransport == AM_OFFSCREEN)
        {
            pActual->cBuffers = 1;
        }

        // this is for those cards which do bilinear-filtering while doing a stretch blt.
        // We do source-colorkeying so that the hal resorts to pixel doubling.
        // SOURCE_COLOR_REF is the colorkey used.
        if ((m_RenderTransport == AM_OFFSCREEN) &&
            ((pDirectCaps->dwSVBFXCaps) & DDFXCAPS_BLTARITHSTRETCHY))
        {
            DDCOLORKEY DDColorKey;
            DWORD dwColorVal = 0;

            dwColorVal = DDColorMatch(m_pDirectDrawSurface, SOURCE_COLOR_REF, hr);
            if (FAILED(hr)) {
                dwColorVal = DDColorMatchOffscreen(m_pFilter->GetDirectDraw(), SOURCE_COLOR_REF, hr);
            }

            DDColorKey.dwColorSpaceLowValue = DDColorKey.dwColorSpaceHighValue = dwColorVal;

            // Tell the primary surface what to expect
            hr = m_pDirectDrawSurface->SetColorKey(DDCKEY_SRCBLT, &DDColorKey);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,1, TEXT("m_pDirectDrawSurface->SetColorKeyDDCKEY_SRCBLT, &DDColorKey) failed")));
                goto CleanUp;
            }
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::AllocateSurfaces")));
    return hr;
}


HRESULT COMInputPin::BreakConnect(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::BreakConnect")));

    CAutoLock cLock(m_pFilterLock);


    if (m_RenderTransport == AM_VIDEOPORT)
    {
        // tell the videoport object
        ASSERT(m_pIVPObject);
        hr = m_pIVPObject->BreakConnect();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->BreakConnect failed, hr = 0x%x"), hr));
        }
    }

    if (m_RenderTransport == AM_VIDEOACCELERATOR)
    {
        // break the motion comp connection
        hr = VABreakConnect();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("VABreakConnect failed, hr = 0x%x"), hr));
        }
    }

    if (m_RenderTransport == AM_IOVERLAY)
    {
        Unadvise();
    }
    else
    {
        // tell the sync object
        hr = m_pSyncObj->BreakConnect();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->BreakConnect failed, hr = 0x%x"), hr));
        }

        // release the ddraw surface
        if (m_pDirectDrawSurface)
        {
            m_pDirectDrawSurface->Release();
            m_pDirectDrawSurface = NULL;
        }

        // back buffers are not addref'd so just set them to NULL
        m_dwBackBufferCount = 0;
        m_dwDirectDrawSurfaceWidth = 0;

    }

    // if it is a videoport or ioverlay connection, set yourself for an overlay
    // connection the next time
    if (m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY || m_RenderTransport == AM_VIDEOACCELERATOR)
    {
        m_RenderTransport = AM_OVERLAY;
    }

    // initialize the behaviour to telling the proxy to allocate buffers
    SetStreamingInKernelMode(FALSE);

    m_bOverlayHidden = TRUE;
    m_bUsingOurAllocator = FALSE;
    m_bCanOverAllocateBuffers = TRUE;

    if (m_hMemoryDC)
    {
        EXECUTE_ASSERT(DeleteDC(m_hMemoryDC));
        m_hMemoryDC = NULL;
    }

    // call the base class
    hr = CBaseInputPin::BreakConnect();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::BreakConnect failed, hr = 0x%x"), hr));
    }

    // tell the owning filter
    hr = m_pFilter->BreakConnect(m_dwPinId);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->BreakConnect failed, hr = 0x%x"), hr));
    }

    const DWORD dwPinBit = (1 << m_dwPinId);
    if (m_pFilter->m_dwDDObjReleaseMask & dwPinBit) {

        m_pFilter->m_dwDDObjReleaseMask &= ~dwPinBit;
        if (!m_pFilter->m_dwDDObjReleaseMask) {
            m_pFilter->m_pOldDDObj->Release();
            m_pFilter->m_pOldDDObj = NULL;
        }
    }
    m_bConnected = FALSE;
//CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::BreakConnect")));
    return hr;
}

STDMETHODIMP COMInputPin::GetState(DWORD dwMSecs,FILTER_STATE *pState)
{
    CAutoLock cLock(m_pFilterLock);

    // if not connected or VideoPort Connection or IOverlay connection, then let the base class handle it
    // otherwise (overlay, offcreen, gdi, motion-comp) let the sync object handle it
    if (!IsConnected() || (m_RenderTransport == AM_VIDEOPORT) || (m_RenderTransport == AM_IOVERLAY))
    {
        return E_NOTIMPL;
    }
    else
    {
        ASSERT(m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN || m_RenderTransport == AM_GDI || m_RenderTransport == AM_VIDEOACCELERATOR);
        return m_pSyncObj->GetState(dwMSecs, pState);
    }
}

HRESULT COMInputPin::CompleteStateChange(FILTER_STATE OldState)
{
    CAutoLock cLock(m_pFilterLock);
    if (m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY)
        return S_OK;
    else
    {
        ASSERT(m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN || m_RenderTransport == AM_GDI || m_RenderTransport == AM_VIDEOACCELERATOR);
        return m_pSyncObj->CompleteStateChange(OldState);
    }
}

// transition from stop to pause state
HRESULT COMInputPin::Active(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::Active")));

    CAutoLock cLock(m_pFilterLock);
    m_hEndOfStream = NULL;

    if (m_RenderTransport == AM_VIDEOPORT)
    {
        if (m_bOverlayHidden) {
            m_bOverlayHidden = FALSE;
            // tell the videoport object
            hr = m_pIVPObject->Active();
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->Active failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
        }
    }
    else if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN || m_RenderTransport == AM_GDI || m_RenderTransport == AM_VIDEOACCELERATOR)

    {
        // tell the sync object
        hr = m_pSyncObj->Active();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->Active failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else
    {
        ASSERT(m_RenderTransport == AM_IOVERLAY);
        // only when all conections are in place can we be sure that this call
        // will succeed
        NotifyChange(ADVISE_DISPLAY_CHANGE);
    }

    // call the base class
    hr = CBaseInputPin::Active();
    // if it is a VP connection, this error is ok
    if ((m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY || m_RenderTransport == AM_VIDEOACCELERATOR) && hr == VFW_E_NO_ALLOCATOR)
    {
        hr = NOERROR;
    }

    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::Active failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::Active")));
    return hr;
}

// transition from pause to stop state
HRESULT COMInputPin::Inactive(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::Inactive")));

    CAutoLock cLock(m_pFilterLock);

    if (m_RenderTransport == AM_VIDEOPORT)
    {
        // tell the videoport object
        hr = m_pIVPObject->Inactive();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->Inactive failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // make sure that if there is a run time error, stop succeeds
        if (m_bRuntimeNegotiationFailed && hr == VFW_E_NOT_CONNECTED)
        {
            hr = NOERROR;
        }
    }
    else if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN || m_RenderTransport == AM_GDI || m_RenderTransport == AM_VIDEOACCELERATOR)
    {
        // tell the sync object
        hr = m_pSyncObj->Inactive();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->Inactive failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else
    {
        ASSERT(m_RenderTransport == AM_IOVERLAY);
    }

    // call the base class
    hr = CBaseInputPin::Inactive();

    // if it is a VP connection, this error is ok
    if ((m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY || m_RenderTransport == AM_VIDEOACCELERATOR) && hr == VFW_E_NO_ALLOCATOR)
    {
        hr = NOERROR;
    }

    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::Inactive failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::Inactive")));
    return hr;
}

// transition from pause to run state
HRESULT COMInputPin::Run(REFERENCE_TIME tStart)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::Run")));

    CAutoLock cLock(m_pFilterLock);

    m_bDontFlip = FALSE ;   // need to reset it to do the right things in this session

    if (m_RenderTransport == AM_VIDEOPORT)
    {
        // tell the videoport object
        hr = m_pIVPObject->Run(tStart);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->Run() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN || m_RenderTransport == AM_GDI || m_RenderTransport == AM_VIDEOACCELERATOR)
    {
        // tell the sync object
        hr = m_pSyncObj->Run(tStart);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->Run() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

    }
    else
    {
        ASSERT(m_RenderTransport == AM_IOVERLAY);
    }

    // call the base class
    hr = CBaseInputPin::Run(tStart);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::Run failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::Run")));
    m_trLastFrame = -1;
    return hr;
}

// transition from run to pause state
HRESULT COMInputPin::RunToPause(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::RunToPause")));

    CAutoLock cLock(m_pFilterLock);

    if (m_RenderTransport == AM_VIDEOPORT)
    {
        // tell the videoport object
        hr = m_pIVPObject->RunToPause();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->RunToPause() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN || m_RenderTransport == AM_GDI || m_RenderTransport == AM_VIDEOACCELERATOR)
    {
        // tell the sync object
        hr = m_pSyncObj->RunToPause();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->RunToPause() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else
    {
        ASSERT(m_RenderTransport == AM_IOVERLAY);
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::RunToPause")));
    return hr;
}


HRESULT COMInputPin::SetFrameStepMode(DWORD dwFramesToStep /* 1 for now */)
{
    CAutoLock cLock(m_pFilterLock);

    //
    // If we are on the wrong monitor fail the call
    //

    HMONITOR ID;
    if (m_pFilter->IsWindowOnWrongMonitor(&ID))
        return E_FAIL;

    long l = m_lFramesToStep;
    m_lFramesToStep = dwFramesToStep;

    //
    // If we are currently blocked on the frame step event
    // release the receive thread so that we can get another
    // frame
    //

    if (l == 0) {
        SetEvent(m_StepEvent);
    }

    return S_OK;
}

HRESULT COMInputPin::CancelFrameStepMode()
{
    CAutoLock cLock(m_pFilterLock);

    //
    // cancel any outstanding steps
    //

    if (m_lFramesToStep == 0) {
        SetEvent(m_StepEvent);
    }
    m_lFramesToStep = -1;

    return S_OK;
}


// signals start of flushing on the input pin
HRESULT COMInputPin::BeginFlush(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::BeginFlush")));

    CAutoLock cLock(m_pFilterLock);
    m_hEndOfStream = 0;

    if (m_bFlushing)
    {
        return E_FAIL;
    }

    if (m_dwPinId == 0) {
        CancelFrameStepMode();
    }

    // if the conection is VideoPort or IOverlay, we do not care about flushing
    if (m_RenderTransport != AM_VIDEOPORT && m_RenderTransport != AM_IOVERLAY)
    {
        ASSERT(m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN ||
               m_RenderTransport == AM_GDI || m_RenderTransport == AM_VIDEOACCELERATOR);

        // call the sync object
        hr = m_pSyncObj->BeginFlush();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->BeginFlush() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else
    {
        ASSERT(m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY);
    }


    // call the base class
    hr = CBaseInputPin::BeginFlush();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::BeginFlush() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::BeginFlush")));
    return hr;
}

// signals end of flushing on the input pin
HRESULT COMInputPin::EndFlush(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::EndFlush")));

    CAutoLock cLock(m_pFilterLock);

    if (!m_bFlushing)
    {
        return E_FAIL;
    }

    // if the conection is VideoPort or IOverlay, we do not care about flushing
    if (m_RenderTransport != AM_VIDEOPORT && m_RenderTransport != AM_IOVERLAY)
    {
        ASSERT(m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN || m_RenderTransport == AM_GDI || m_RenderTransport == AM_VIDEOACCELERATOR);

        // call the sync object
        hr = m_pSyncObj->EndFlush();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->EndFlush() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else
    {
        ASSERT(m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY);
    }

    // call the base class
    hr = CBaseInputPin::EndFlush();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CBaseInputPin::EndFlush() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::EndFlush")));
    return hr;
}

// Send a quality message if required - this is the hack version
// that just passes the lateness
void COMInputPin::DoQualityMessage()
{
    CAutoLock cLock(m_pFilterLock);

    if (m_pFilter->m_State == State_Running &&
        SampleProps()->dwSampleFlags & AM_SAMPLE_TIMEVALID)
    {
        CRefTime CurTime;
        if (S_OK == m_pFilter->StreamTime(CurTime))
        {
            const REFERENCE_TIME tStart = SampleProps()->tStart;
            Quality msg;
            msg.Proportion = 1000;
            msg.Type = CurTime > tStart ? Flood : Famine;
            msg.Late = CurTime - tStart;
            msg.TimeStamp = tStart;
            PassNotify(msg);

            if (m_trLastFrame > 0) {
                m_pSyncObj->m_AvgDelivery.NewFrame(CurTime - m_trLastFrame);
            }
            m_trLastFrame = CurTime;
        }
    }
}

BOOL
COMInputPin::DoFrameStepAndReturnIfNeeded()
{
    if (m_lFramesToStep == 0) {
        m_pFilterLock->Unlock();
        WaitForSingleObject(m_StepEvent, INFINITE);
        m_pFilterLock->Lock();
    }

    //
    // do we have frames to discard ?
    //

    if (m_lFramesToStep > 0) {
        m_lFramesToStep--;
        if (m_lFramesToStep > 0) {
            return TRUE;
        }
    }
    return FALSE;
}

// called when the upstream pin delivers us a sample
HRESULT COMInputPin::Receive(IMediaSample *pMediaSample)
{
    HRESULT hr = NOERROR;
    BOOL bNeedToFlipOddEven = FALSE;
    BOOL bDisplayingFields = FALSE;
    DWORD dwTypeSpecificFlags = 0;
    LPDIRECTDRAWSURFACE pPrimarySurface = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::Receive")));
#ifdef PERF
    {
        DWORD dwTypeSpecificFlags;
        GetTypeSpecificFlagsFromMediaSample(pMediaSample, &dwTypeSpecificFlags);
        Msr_Integer(m_FrameReceived, dwTypeSpecificFlags);
    }
#endif

    m_bReallyFlipped = FALSE;
    // if it is IOverlay connection, bail out
    if (m_RenderTransport == AM_IOVERLAY)
    {
        hr = VFW_E_NOT_SAMPLE_CONNECTION;
        goto CleanUp;
    }

    if (m_RenderTransport == AM_VIDEOPORT)
    {
        hr = VFW_E_NOT_SAMPLE_CONNECTION;
        goto CleanUp;
    }

    if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN)
    {
        // this will unlock the surface
        // unlock the sample first
        hr = ((CDDrawMediaSample*)pMediaSample)->GetSurfaceAndReleaseLock(NULL, NULL);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("pSample->GetSurfaceAndReleaseLock() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
        OnReleaseBuffer(pMediaSample);

        // if there is no primary surface (due to a display mode change), fail the receive call
        pPrimarySurface = m_pFilter->GetPrimarySurface();
        if (!pPrimarySurface)
        {
            hr = E_FAIL;
            goto CleanUp;
        }
    }

    //
    // Frame step hack-o-matic
    //
    // This code acts as a gate - for a frame step of N frames
    // it discards N-1 frames and then lets the Nth frame thru the
    // the gate to be renderer in the normal way i.e. at the correct
    // time.  The next time Receive is called the gate is shut and
    // the thread blocks.  The gate only opens again when the step
    // is cancelled or another frame step request comes in.
    //
    // StEstrop - Thu 10/21/1999
    //

    if (m_dwPinId == 0) {

        if (m_RenderTransport != AM_VIDEOACCELERATOR) {

            CAutoLock cLock(m_pFilterLock);
            if (DoFrameStepAndReturnIfNeeded()) {
                goto CleanUp;
            }

        }
        else {

            if (DoFrameStepAndReturnIfNeeded()) {
                goto CleanUp;
            }
        }
    }

    if (m_bSyncOnFill)
    {
        CAutoLock cLock(m_pFilterLock);

        // make sure the base class says it is ok (checks the flushing and
        // filter state)
        hr = CBaseInputPin::Receive(pMediaSample);
        if (hr != NOERROR)
        {
            hr = E_FAIL;
            goto CleanUp;
        }
        DoQualityMessage();

        // Has the type changed on a media sample. We do all rendering
        // synchronously on the source thread, which has a side effect
        // that only one buffer is ever outstanding. Therefore when we
        // have Receive called we can go ahead and change the format
        {
            if (SampleProps()->dwSampleFlags & AM_SAMPLE_TYPECHANGED)
            {
                SetMediaType((CMediaType *)SampleProps()->pMediaType);

                // store m_mtNew in m_mtNewAdjusted with the width of the mediatype adjusted
                UpdateMediaType();
                // make sure that the video frame gets updated by redrawing everything
                EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
            }
        }

        m_pSyncObj->SetRepaintStatus(TRUE);
        if (m_pSyncObj->GetRealState() == State_Paused)
        {
            m_pSyncObj->Ready();
        }

        if ((m_mtNewAdjusted.formattype != FORMAT_VideoInfo) &&
            (!CheckTypeSpecificFlags(m_dwInterlaceFlags, m_SampleProps.dwTypeSpecificFlags)))
        {
            DbgLog((LOG_ERROR, 1, TEXT("CheckTypeSpecificFlags failed")));
            hr = E_FAIL;
            goto CleanUp;
        }

        // assert that we are not in bob mode
        bNeedToFlipOddEven = NeedToFlipOddEven(m_dwInterlaceFlags, 0, NULL);
        ASSERT(!bNeedToFlipOddEven);

        hr = DoRenderSample(pMediaSample);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("DoRenderSample(pMediaSample) failed, hr = 0x%x"), hr));
            hr = E_FAIL;
            goto CleanUp;
        }

    }
    else
    {
        {
            CAutoLock cLock(m_pFilterLock);

            // make sure the base class says it is ok (checks the flushing and
            // filter state)
            hr = CBaseInputPin::Receive(pMediaSample);
            if (hr != NOERROR)
            {
                hr = E_FAIL;
                goto CleanUp;
            }
            DoQualityMessage();

            // Has the type changed on a media sample. We do all rendering
            // synchronously on the source thread, which has a side effect
            // that only one buffer is ever outstanding. Therefore when we
            // have Receive called we can go ahead and change the format
            {
                if (SampleProps()->dwSampleFlags & AM_SAMPLE_TYPECHANGED)
                {
                    SetMediaType((CMediaType *)SampleProps()->pMediaType);

                    // store m_mtNew in m_mtNewAdjusted with the width of the mediatype adjusted
                    UpdateMediaType();
                    // make sure that the video frame gets updated by redrawing everything
                    EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
                }
            }

        }

        if ((m_mtNewAdjusted.formattype != FORMAT_VideoInfo) &&
            (!CheckTypeSpecificFlags(m_dwInterlaceFlags, m_SampleProps.dwTypeSpecificFlags)))
        {
            DbgLog((LOG_ERROR, 1, TEXT("CheckTypeSpecificFlags failed")));
            hr = E_FAIL;
            goto CleanUp;
        }

        bNeedToFlipOddEven = NeedToFlipOddEven(m_dwInterlaceFlags, m_SampleProps.dwTypeSpecificFlags, &m_dwFlipFlag);
        bDisplayingFields = DisplayingFields(m_dwInterlaceFlags);

        // call the sync object
        // We're already locked if we using video acceleration
        if (m_RenderTransport == AM_VIDEOACCELERATOR) {
            m_pFilterLock->Unlock();
        }


        hr = m_pSyncObj->Receive(pMediaSample);
        if (m_RenderTransport == AM_VIDEOACCELERATOR) {
            m_pFilterLock->Lock();
        }

        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->Receive() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        if (bNeedToFlipOddEven && !bDisplayingFields)
        {
            REFERENCE_TIME StartSample, EndSample;
            hr = m_pSyncObj->GetSampleTimes(pMediaSample, &StartSample, &EndSample);
            if (SUCCEEDED(hr))
            {
                // NewStartSample = (OldStartSample+EndSample)/2
                StartSample = StartSample+EndSample;
                StartSample = StartSample >> 1;
                pMediaSample->SetTime(&StartSample, &EndSample);
            }
            if (m_dwFlipFlag == DDFLIP_ODD)
                m_dwFlipFlag2 = DDFLIP_EVEN;
            else if (m_dwFlipFlag == DDFLIP_EVEN)
                m_dwFlipFlag2 = DDFLIP_ODD;

            // call the sync object
            hr = m_pSyncObj->ScheduleSampleUsingMMThread(pMediaSample);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->ScheduleSampleUsingMMThread() failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
        }
    }

    //  Avoid pink flash
    if (m_UpdateOverlayNeededAfterReceiveConnection && m_dwPinId == 0)
    {
        //  Must be called with m_bConnected = TRUE
        EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
        m_UpdateOverlayNeededAfterReceiveConnection = false;
    }
    //
    // If this is the target frame for a Step operation, m_lFramesToStep
    // will be equal to 0.  In which case we have to send an
    // EC_STEP_COMPLETE to the filter graph manager so that it can
    // pause the graph.
    //

    if (m_dwPinId == 0 && m_lFramesToStep == 0) {
        EventNotify(EC_STEP_COMPLETE, FALSE, 0);
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::Receive")));
    return hr;
}


HRESULT COMInputPin::OnReceiveFirstSample(IMediaSample *pMediaSample)
{
    CAutoLock cLock(m_pFilterLock);

    DoRenderSample(pMediaSample);

    return NOERROR;
}

HRESULT COMInputPin::FlipOverlayToItself()
{
    //  No need to lock - the surface pointers should not change in the
    //  middle of a flip
    ASSERT(m_pDirectDrawSurface);
    return  m_pDirectDrawSurface->Flip(m_pDirectDrawSurface, m_dwFlipFlag2);
}



// COMInputPin::DrawGDISample
//
//
//
HRESULT COMInputPin::DrawGDISample(IMediaSample *pMediaSample)
{
    DIBDATA *pDibData = NULL;
    LPRGNDATA pBuffer = NULL;
    LPRECT pDestRect;
    HDC hTargetDC = (HDC)NULL;
    HRESULT hr = NOERROR;
    LPBITMAPINFOHEADER pbmiHeader = NULL;
    LPBYTE pSampleBits = NULL;
    DWORD dwTemp, dwBuffSize, dwRetVal;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::DrawGDISample")));

    hTargetDC = m_pFilter->GetDestDC();
    ASSERT(hTargetDC);

    if (m_pFilter->UsingWindowless())
    {
        if (pMediaSample)
        {
            pDibData = ((CDDrawMediaSample*)pMediaSample)->GetDIBData();
        }
        else
        {
            pDibData = &m_BackingDib;
        }


        if (!pDibData || !pDibData->pBase)
        {
            hr = E_FAIL;
            goto CleanUp;
        }

        if (!m_hMemoryDC)
        {
            EXECUTE_ASSERT(m_hMemoryDC = CreateCompatibleDC(hTargetDC));
            EXECUTE_ASSERT(SetStretchBltMode(hTargetDC,COLORONCOLOR));
            EXECUTE_ASSERT(SetStretchBltMode(m_hMemoryDC,COLORONCOLOR));
        }
    }
    else
    {
        pbmiHeader = GetbmiHeader(&m_mtNewAdjusted);
        ASSERT(pbmiHeader);

        hr = pMediaSample->GetPointer(&pSampleBits);
        if (FAILED(hr))
        {
            goto CleanUp;
        }
    }

    dwRetVal = GetRegionData(m_WinInfo.hClipRgn, 0, NULL);
    if (!dwRetVal)
        goto CleanUp;

    ASSERT(dwRetVal);
    dwBuffSize = dwRetVal;
    pBuffer = (LPRGNDATA) new char[dwBuffSize];
    if ( ! pBuffer )
    {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    dwRetVal = GetRegionData(m_WinInfo.hClipRgn, dwBuffSize, pBuffer);
    ASSERT(pBuffer->rdh.iType == RDH_RECTANGLES);

    for (dwTemp = 0; dwTemp < pBuffer->rdh.nCount; dwTemp++)
    {
        pDestRect = (LPRECT)((char*)pBuffer + pBuffer->rdh.dwSize + dwTemp*sizeof(RECT));
        ASSERT(pDestRect);

        if (IsRectEmpty(&m_WinInfo.DestClipRect))
        {
            continue;
        }

        CalcSrcClipRect(&m_WinInfo.SrcRect, &m_WinInfo.SrcClipRect,
                        &m_WinInfo.DestRect, pDestRect);

        ASSERT(OffsetRect(pDestRect, -m_WinInfo.TopLeftPoint.x, -m_WinInfo.TopLeftPoint.y));

        if (pDibData)
            FastDIBBlt(pDibData, hTargetDC, m_hMemoryDC, pDestRect, &m_WinInfo.SrcClipRect);
        else
            SlowDIBBlt(pSampleBits, pbmiHeader, hTargetDC, pDestRect, &m_WinInfo.SrcClipRect);

    }
    EXECUTE_ASSERT(GdiFlush());

CleanUp:
    if (pBuffer)
    {
        delete [] pBuffer;
        pBuffer = NULL;
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::DrawGDISample")));
    return hr;
}


// COMInputPin::DoRenderGDISample
//
// Renderering when the transport is GDI is pretty complex - hence
// we have a dedicated function to take care of it
//
HRESULT COMInputPin::DoRenderGDISample(IMediaSample *pMediaSample)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::DoRenderGDISample")));

    //
    // if we are in a pull model, don't draw anything in receive, just tell
    // the filter that we need to redraw.  Also, if we are not using our
    // allocator we need to save the image into the backing store.
    //
    if (pMediaSample)
    {
        if (m_pFilter->UsingWindowless())
        {
            m_bOverlayHidden = FALSE;

            if (!m_bUsingOurAllocator) {

                LPBYTE pSampleBits;
                hr = pMediaSample->GetPointer(&pSampleBits);
                if (SUCCEEDED(hr) && m_BackingDib.pBase) {
                    CopyMemory(m_BackingDib.pBase, pSampleBits, m_BackingImageSize);
                }
            }
            else {

                CDDrawMediaSample *pCDDrawMediaSample = (CDDrawMediaSample*)pMediaSample;

                DIBDATA DibTemp = *(pCDDrawMediaSample->GetDIBData());
                pCDDrawMediaSample->SetDIBData(&m_BackingDib);
                m_BackingDib = DibTemp;
            }

            // make sure that the video frame gets updated by redrawing everything
            EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
        }
        else
        {
            DrawGDISample(pMediaSample);
        }
    }
    else
    {
        //
        // If we are in Windowless mode we use the previous buffer if
        // we are using our allocator, otherwise we use the back buffer.
        //
        if (m_pFilter->UsingWindowless())
        {
            DrawGDISample(NULL);
        }

        //
        // We are not in Windowless mode so use the old code.
        //
        else
        {
            pMediaSample = m_pSyncObj->GetCurrentSample();
            if (pMediaSample)
            {
                DrawGDISample(pMediaSample);
                pMediaSample->Release();
            }
            else
            {
                m_pSyncObj->SendRepaint();
            }
        }
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::DoRenderGDISample")));
    return hr;
}


HRESULT COMInputPin::DoRenderSample(IMediaSample *pMediaSample)
{
    HRESULT hr = NOERROR;
    static DWORD dwFlags = 0;
    LPRGNDATA pBuffer = NULL;
    DWORD dwTemp, dwBuffSize = 0, dwRetVal = 0;
    LPRECT pDestRect = NULL;
    DWORD dwBlendingParameter = 1, dwTypeSpecificFlags = 0, dwUpdateOverlayFlags = 0;
    BOOL bDoReleaseSample = FALSE;


    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::DoRenderSample")));

    CAutoLock cLock(m_pFilterLock);

    hr = GetBlendingParameter(&dwBlendingParameter);
    ASSERT(SUCCEEDED(hr));

    if (dwBlendingParameter == 0)
        goto CleanUp;

    if ((m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_VIDEOACCELERATOR) && m_bSyncOnFill)
    {
        ; // do nothing
    }
    else if ((m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_VIDEOACCELERATOR) && !m_bSyncOnFill)
    {
        // using flipping surfaces
        ASSERT(m_pBackBuffer);

        if (! m_bDontFlip )   // don't flip if BltFast() failed
        {
            // For video accelerator stuff check the motion comp copmleted
            if (m_RenderTransport == AM_VIDEOACCELERATOR) {
                //  Wait until previous motion comp operation is complete
                IDirectDrawSurface4 *pSurface4;
                if (SUCCEEDED(m_pBackBuffer->QueryInterface(IID_IDirectDrawSurface4,
                    (void **)&pSurface4))) {
                    while (DDERR_WASSTILLDRAWING ==
                           m_pIDDVideoAccelerator->QueryRenderStatus(
                               pSurface4,
                               DDVA_QUERYRENDERSTATUSF_READ)) {
                        Sleep(1);
                    }
                    pSurface4->Release();
                }
            }
#ifdef PERF
            Msr_Note(m_PerfFrameFlipped);
#endif
#if defined(DEBUG) && !defined(_WIN64)
            extern int iFPSLog;
            if (iFPSLog) {
                static int FlipCounter;
                static DWORD time;
                FlipCounter++;

                if (0 == (FlipCounter % 60)) {

                    DWORD timeTaken = time;
                    time = timeGetTime();
                    timeTaken = time - timeTaken;

                    int f = (60 * 1000 * 1000) / timeTaken;

                    wsprintf(m_pFilter->m_WindowText,
                           TEXT("ActiveMovie Window: Flip Rate %d.%.3d / Sec"),
                           f / 1000, f % 1000 );

                    // Can't call SetWindowText on this thread
                    // because we would deadlock !!

                    PostMessage(m_pFilter->GetWindow(), WM_DISPLAY_WINDOW_TEXT, 0, 0);
                }
            }
#endif
            // do not wait for the flip to complete
            hr = m_pDirectDrawSurface->Flip(m_pBackBuffer, m_dwFlipFlag);
            m_bReallyFlipped = (hr == DD_OK || hr == DDERR_WASSTILLDRAWING);
        }

        hr = GetTypeSpecificFlagsFromMediaSample(pMediaSample, &dwTypeSpecificFlags);
        ASSERT(SUCCEEDED(hr));

        dwUpdateOverlayFlags = GetUpdateOverlayFlags(m_dwInterlaceFlags, dwTypeSpecificFlags);
        if (dwUpdateOverlayFlags != m_dwUpdateOverlayFlags)
        {
            m_dwUpdateOverlayFlags = dwUpdateOverlayFlags;
            // make sure that the video frame gets updated by redrawing everything
            EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
        }
    }
    else if (m_RenderTransport == AM_OFFSCREEN)
    {
        LPDIRECTDRAWSURFACE pPrimarySurface = m_pFilter->GetPrimarySurface();
        LPDDCAPS pDirectCaps;

        if ( ! pPrimarySurface )
        {
            hr = E_FAIL;
            goto CleanUp;
        }
        pDirectCaps = m_pFilter->GetHardwareCaps();
        if ( ! pDirectCaps )
        {
            hr = E_FAIL;
            goto CleanUp;
        }

        ASSERT(m_pDirectDrawSurface);

        // wait only if there is a sample
        if (pMediaSample)
            dwFlags = DDBLT_WAIT;

        // this is for those cards which do bilinear-filtering while doing a stretch blt.
        // We do source-colorkeying so that the hal resorts to pixel doubling.
        if ((pDirectCaps->dwSVBFXCaps) & DDFXCAPS_BLTARITHSTRETCHY)
            dwFlags |= DDBLT_KEYSRC;

        dwRetVal = GetRegionData(m_WinInfo.hClipRgn, 0, NULL);
        if (!dwRetVal)
            goto CleanUp;

        ASSERT(dwRetVal);
        dwBuffSize = dwRetVal;
        pBuffer = (LPRGNDATA) new char[dwBuffSize];
        ASSERT(pBuffer);

        dwRetVal = GetRegionData(m_WinInfo.hClipRgn, dwBuffSize, pBuffer);
        ASSERT(pBuffer->rdh.iType == RDH_RECTANGLES);


        // using offscreen surface
        for (dwTemp = 0; dwTemp < pBuffer->rdh.nCount; dwTemp++)
        {
            pDestRect = (LPRECT)((char*)pBuffer + pBuffer->rdh.dwSize + dwTemp*sizeof(RECT));
            ASSERT(pDestRect);

            if (IsRectEmpty(&m_WinInfo.DestClipRect))
            {
                continue;
            }

            CalcSrcClipRect(&m_WinInfo.SrcRect, &m_WinInfo.SrcClipRect,
                            &m_WinInfo.DestRect, pDestRect);

#if 0       //  Should do this later - right now we just see the
            //  old overlay contents instead of the key color which
            //  in many cases is worse

            //  We must draw the overlay now as this blt may contain
            //  lots of key color
            m_pFilter->m_apInput[0]->CheckOverlayHidden();
#endif

            // Draw the offscreen surface and wait for it to complete
            RECT TargetRect = *pDestRect;
            OffsetRect(&TargetRect,
                       -m_pFilter->m_lpCurrentMonitor->rcMonitor.left,
                       -m_pFilter->m_lpCurrentMonitor->rcMonitor.top);

            hr = pPrimarySurface->Blt(&TargetRect, m_pDirectDrawSurface,
                                      &m_WinInfo.SrcClipRect, dwFlags, NULL);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 0,  TEXT("pPrimarySurface->Blt() failed, hr = %d"), hr & 0xffff));
                goto CleanUp;
            }
        }
    }
    else if (m_RenderTransport == AM_GDI)
    {
        hr = DoRenderGDISample(pMediaSample);
    }

    if (m_bOverlayHidden)
    {
        m_bOverlayHidden = FALSE;
        // make sure that the video frame gets updated by redrawing everything
        EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
    }

CleanUp:
    if (pBuffer)
    {
        delete [] pBuffer;
        pBuffer = NULL;
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::DoRenderSample")));
    return hr;
}

// signals end of data stream on the input pin
STDMETHODIMP COMInputPin::EndOfStream(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::EndOfStream")));

    CAutoLock cLock(m_pFilterLock);
    if (m_hEndOfStream) {
        EXECUTE_ASSERT(SetEvent(m_hEndOfStream));
        return S_OK;
    }

    if (m_dwPinId == 0) {
        CancelFrameStepMode();
    }

    // Make sure we're streaming ok

    hr = CheckStreaming();
    if (hr != NOERROR)
    {
        DbgLog((LOG_ERROR, 1, TEXT("CheckStreaming() failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY)
    {
        // Pass EOS to the filter graph
        hr = m_pFilter->EventNotify(m_dwPinId, EC_COMPLETE, S_OK, 0);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->EventNotify failed, hr = 0x%x"), hr));
        }
    }
    else
    {
        // call the sync object
        hr = m_pSyncObj->EndOfStream();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->EndOfStream() failed, hr = 0x%x"), hr));
        }
    }


CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::EndOfStream")));
    return hr;
}

// signals end of data stream on the input pin
HRESULT COMInputPin::EventNotify(long lEventCode, long lEventParam1, long lEventParam2)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::EventNotify")));

    CAutoLock cLock(m_pFilterLock);

    if (lEventCode == EC_OVMIXER_VP_CONNECTED)
    {
        m_mtNew.majortype = MEDIATYPE_Video;
        m_mtNew.formattype = FORMAT_VideoInfo2;
        m_mtNew.ReallocFormatBuffer(sizeof(VIDEOINFOHEADER2));

        hr = m_pIVPObject->CurrentMediaType(&m_mtNew);
        ASSERT(SUCCEEDED(hr));

        hr = UpdateMediaType();
        ASSERT(SUCCEEDED(hr));

        goto CleanUp;
    }

    if (lEventCode == EC_OVMIXER_REDRAW_ALL || lEventCode == EC_REPAINT)
    {
        m_pFilter->EventNotify(m_dwPinId, lEventCode, lEventParam1, lEventParam2);
        goto CleanUp;
    }

    // WARNING : we are assuming here that the input pin will be the first pin to be created
    if (lEventCode == EC_COMPLETE && m_dwPinId == 0)
    {
        m_pFilter->EventNotify(m_dwPinId, lEventCode, lEventParam1, lEventParam2);
        goto CleanUp;
    }

    if (lEventCode == EC_ERRORABORT)
    {
        m_pFilter->EventNotify(m_dwPinId, lEventCode, lEventParam1, lEventParam2);
        m_bRuntimeNegotiationFailed = TRUE;
        goto CleanUp;
    }

    if (lEventCode == EC_STEP_COMPLETE) {
        m_pFilter->EventNotify(m_dwPinId, lEventCode, lEventParam1, lEventParam2);
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::EventNotify")));
    return hr;
}


/******************************Public*Routine******************************\
* GetCaptureInfo
*
*
*
* History:
* 3/12/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
COMInputPin::GetCaptureInfo(
    BOOL *lpCapturing,
    DWORD *lpdwWidth,
    DWORD *lpdwHeight,
    BOOL *lpInterleave
    )

{
    AMTRACE((TEXT("COMInputPin::GetCaptureInfo")));

    HRESULT hr = NOERROR;
    IKsPropertySet *pIKsPropertySet = NULL;
    DWORD dwVal[2], dwBytesReturned = 0;

    *lpCapturing = FALSE;

    if (!m_Connected) {

        DbgLog((LOG_TRACE, 1, TEXT("Input pin not connected!!")));
        hr = E_FAIL;
        goto CleanUp;
    }

#if defined(DEBUG)
    else {
        PIN_INFO PinInfo;
        hr = m_Connected->QueryPinInfo(&PinInfo);
        if (SUCCEEDED(hr)) {
            DbgLog((LOG_TRACE, 1, TEXT("Up stream pin name %ls"), PinInfo.achName));
            PinInfo.pFilter->Release();
        }
    }
#endif

    hr = m_Connected->QueryInterface(IID_IKsPropertySet,
                                     (void**)&pIKsPropertySet);
    if (SUCCEEDED(hr))
    {
        ASSERT(pIKsPropertySet);

        hr = pIKsPropertySet->Set(
                    AM_KSPROPSETID_ALLOCATOR_CONTROL,
                    AM_KSPROPERTY_ALLOCATOR_CONTROL_CAPTURE_CAPS,
                    NULL, 0,
                    lpInterleave, sizeof(*lpInterleave));

        if (SUCCEEDED(hr)) {
            hr = pIKsPropertySet->Get(
                        AM_KSPROPSETID_ALLOCATOR_CONTROL,
                        AM_KSPROPERTY_ALLOCATOR_CONTROL_CAPTURE_INTERLEAVE,
                        NULL, 0,
                        lpInterleave, sizeof(*lpInterleave), &dwBytesReturned);

            if (FAILED(hr) || dwBytesReturned != sizeof(*lpInterleave)) {
                *lpInterleave = FALSE;
            }
        }
        else {
            *lpInterleave = FALSE;
        }


        hr = pIKsPropertySet->Get(
                    AM_KSPROPSETID_ALLOCATOR_CONTROL,
                    AM_KSPROPERTY_ALLOCATOR_CONTROL_SURFACE_SIZE,
                    NULL, 0, dwVal, sizeof(dwVal), &dwBytesReturned);

        DbgLog((LOG_TRACE, 2,
                TEXT("pIKsPropertySet->Get(")
                TEXT("AM_KSPROPERTY_ALLOCATOR_CONTROL_SURFACE_SIZE),\n")
                TEXT("\thr = 0x%x, dwVal[0] == %d, dwVal[1] == %d, ")
                TEXT("dwBytesReturned == %d"),
                hr, dwVal[0], dwVal[1], dwBytesReturned));


        // if the decoder supports this property then we are capturing
        // and the intended capturing is size is given by
        // dwVal[0] and dwVal[1]
        //
        if (SUCCEEDED(hr) && dwBytesReturned == sizeof(dwVal))
        {
            *lpCapturing = TRUE;
            *lpdwWidth = dwVal[0];
            *lpdwHeight = dwVal[1];

            DbgLog((LOG_TRACE, 1,
                    TEXT("We are CAPTURING, intended size (%d, %d) interleave = %d"),
                    dwVal[0], dwVal[1], *lpInterleave));
        }

        pIKsPropertySet->Release();
    }

CleanUp:
    return hr;
}


/******************************Public*Routine******************************\
* GetDecimationUsage
*
*
*
* History:
* Thu 07/15/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
COMInputPin::GetDecimationUsage(
    DECIMATION_USAGE *lpdwUsage
    )
{
    return m_pFilter->QueryDecimationUsage(lpdwUsage);
}


// This overrides the CBaseInputPin virtual method to return our allocator
HRESULT COMInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetAllocator")));

    if (!ppAllocator)
    {
        DbgLog((LOG_ERROR, 1, TEXT("ppAllocator is NULL")));
        hr = E_POINTER;
        goto CleanUp;
    }

    {
        CAutoLock cLock(m_pFilterLock);

        // if vp connection, don't return any allocator
        if (m_RenderTransport == AM_VIDEOPORT || m_RenderTransport == AM_IOVERLAY || m_RenderTransport == AM_VIDEOACCELERATOR)
        {
            *ppAllocator = NULL;
            hr = VFW_E_NO_ALLOCATOR;
            goto CleanUp;
        }

        // if we don't have an allocator create one
        if (!m_pAllocator)
        {
            m_pAllocator = new COMInputAllocator(this, m_pFilterLock, &hr);
            if (!m_pAllocator || FAILED(hr))
            {
                // did not fail inside the destructor, so must be out of memory
                if (!FAILED(hr))
                    hr = E_OUTOFMEMORY;
                delete m_pAllocator;
                m_pAllocator = NULL;
                *ppAllocator = NULL;
                DbgLog((LOG_ERROR, 1, TEXT("new COMInputAllocator failed, hr = 0x%x"), hr));
                goto CleanUp;
            }

            /*  We AddRef() our own allocator */
            m_pAllocator->AddRef();
        }

        ASSERT(m_pAllocator != NULL);
        *ppAllocator = m_pAllocator;
        m_pAllocator->AddRef();
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetAllocator")));
    return hr;
} // GetAllocator

// This overrides the CBaseInputPin virtual method to return our allocator
HRESULT COMInputPin::NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::NotifyAllocator")));

    if (!pAllocator)
    {
        DbgLog((LOG_ERROR, 1, TEXT("ppAllocator is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    {
        CAutoLock cLock(m_pFilterLock);

        // if vp connection, don't care
        if (m_RenderTransport == AM_VIDEOPORT ||
            m_RenderTransport == AM_IOVERLAY ||
            m_RenderTransport == AM_VIDEOACCELERATOR)
        {
            goto CleanUp;
        }


        if (pAllocator != m_pAllocator)
        {
            // in the ddraw case, we insist on our own allocator
            if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN)
            {
                DbgLog((LOG_ERROR, 1, TEXT("pAllocator != m_pAllocator, not accepting the allocator")));
                hr = E_FAIL;
                goto CleanUp;
            }

            // since we have already handled the vp, ioverlay and ddraw case, this
            // must be the gdi case
            ASSERT(m_RenderTransport == AM_GDI);

            m_bUsingOurAllocator = FALSE;

            DbgLog((LOG_ERROR, 1, TEXT("pAllocator != m_pAllocator")));
        }
        else
        {
            m_bUsingOurAllocator = TRUE;
        }

        if (!m_bConnected)
        {
            hr = FinalConnect();
            ASSERT(SUCCEEDED(hr));
        }

    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::NotifyAllocator")));
    return hr;
} // NotifyAllocator

HRESULT COMInputPin::OnAlloc(CDDrawMediaSample **ppSampleList, DWORD dwSampleCount)
{
    HRESULT hr = NOERROR;
    DWORD i;
    LPDIRECTDRAWSURFACE pDDrawSurface = NULL, pBackBuffer = NULL;
    DDSCAPS ddSurfaceCaps;
    DWORD dwDDrawSampleSize = 0;
    BITMAPINFOHEADER *pHeader = NULL;
    DIBDATA DibData;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::OnAlloc")));

    CAutoLock cLock(m_pFilterLock);

    ASSERT(IsConnected());

    // get the image size
    pHeader = GetbmiHeader(&m_mtNew);
    if ( ! pHeader )
    {
        hr = E_FAIL;
        goto CleanUp;
    }
    dwDDrawSampleSize = pHeader->biSizeImage;
    ASSERT(dwDDrawSampleSize > 0);

    if (!ppSampleList)
    {
        DbgLog((LOG_ERROR, 1, TEXT("ppSampleList is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (m_RenderTransport == AM_OVERLAY ||
        m_RenderTransport == AM_OFFSCREEN)
    {
        ASSERT(m_pDirectDrawSurface);
        pDDrawSurface = m_pDirectDrawSurface;
    }

    for (i = 0; i < dwSampleCount; i++)
    {
        if (!ppSampleList[i])
        {
            DbgLog((LOG_ERROR, 1, TEXT("ppSampleList[%d] is NULL"), i));
            hr = E_INVALIDARG;
            goto CleanUp;
        }

        hr = ppSampleList[i]->SetDDrawSampleSize(dwDDrawSampleSize);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,  TEXT("ppSampleList[%d]->SetSampleSize failed, hr = 0x%x"), i, hr));
            goto CleanUp;
        }

        if (m_RenderTransport == AM_OVERLAY && !m_bSyncOnFill)
        {
            if (i == 0)
            {
                memset((void*)&ddSurfaceCaps, 0, sizeof(DDSCAPS));
                ddSurfaceCaps.dwCaps = DDSCAPS_FLIP | DDSCAPS_COMPLEX | DDSCAPS_OVERLAY;
            }
            // Get the back buffer surface
            hr = pDDrawSurface->GetAttachedSurface(&ddSurfaceCaps, &pBackBuffer);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 0,  TEXT("Function pDDrawSurface->GetAttachedSurface failed, hr = 0x%x"), hr));
                goto CleanUp;
            }

            ppSampleList[i]->SetDDrawSurface(pBackBuffer);
            pDDrawSurface = pBackBuffer;
            //
            // Surfaces returned by GetAttachedSurface() are supposed to be
            // Release()-ed; otherwise we leak ref count.  Here doing Release()
            // doesn't actually let go of the surface as it has already been
            // AddRef()-ed on the SetDDrawSurface() method above.
            //
            pBackBuffer->Release() ;
        }
        else if ((m_RenderTransport == AM_OVERLAY && m_bSyncOnFill)  ||
                 (m_RenderTransport == AM_OFFSCREEN))

        {
            ppSampleList[i]->SetDDrawSurface(pDDrawSurface);
            ASSERT(dwSampleCount == 1);
        }
        else if (m_RenderTransport == AM_GDI)
        {
            hr = CreateDIB(dwDDrawSampleSize, (BITMAPINFO*)pHeader, &DibData);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("CreateDIB(%d, DibData); failed, hr = 0x%x"), dwDDrawSampleSize, hr));
                goto CleanUp;
            }
            ppSampleList[i]->SetDIBData(&DibData);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("ppSampleList[%d]->SetDIBData(&DibData) failed, hr = 0x%x"), i, hr));
                goto CleanUp;
            }

        }
    }  // end of for (i < dwSampleCount) loop

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::OnAlloc")));
    return hr;
}

// sets the pointer to directdraw
HRESULT COMInputPin::OnGetBuffer(IMediaSample **ppSample, REFERENCE_TIME *pStartTime,
                                 REFERENCE_TIME *pEndTime, DWORD dwFlags)
{
    HRESULT hr = NOERROR;
    CDDrawMediaSample *pCDDrawMediaSample = NULL;
    LPDIRECTDRAWSURFACE pBackBuffer = NULL;
    DDSURFACEDESC ddSurfaceDesc;
    BOOL bWaitForDraw = FALSE;
    BOOL bPalettised = FALSE;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::OnGetBuffer")));

    ASSERT(m_RenderTransport != AM_VIDEOPORT);
    ASSERT(m_RenderTransport != AM_IOVERLAY);
    ASSERT(m_RenderTransport != AM_VIDEOACCELERATOR);

    pCDDrawMediaSample = (CDDrawMediaSample*)*ppSample;

    //
    // Check to see if we have moved FULLY onto another monitor.
    // If so, start the reconnection process.  We may want to check that
    // the new playback monitor actually supports an overlay before
    // we do this, otherwise all video playback will stop.
    //

    HMONITOR ID;

    if (m_dwPinId == 0 && m_pFilter->m_pOutput &&
        m_pFilter->IsWindowOnWrongMonitor(&ID)) {

        if (ID != 0 && !m_pFilter->m_fDisplayChangePosted) {

            CAutoLock l(&m_pFilter->m_csFilter);
            DbgLog((LOG_TRACE, 1, TEXT("Window is on a DIFFERENT MONITOR!\n")));
            DbgLog((LOG_TRACE, 1, TEXT("Reset the world!\n")));

            PostMessage(m_pFilter->GetWindow(), m_pFilter->m_MonitorChangeMsg, 0, 0);

            // once only, or performance suffers when switching
            m_pFilter->m_fDisplayChangePosted = TRUE;
        }
    }

    if (m_RenderTransport == AM_GDI &&
        m_pFilter->UsingWindowless() &&
        m_bUsingOurAllocator)
    {
        CAutoLock cLock(m_pFilterLock);

        // If the current sample requires the image from the previous sample
        // we have to copy it into the current sample.
        if (dwFlags & AM_GBF_NOTASYNCPOINT)
        {
            LONG lBytesToCopy = pCDDrawMediaSample->GetSize();
            DIBDATA DibTmp = *pCDDrawMediaSample->GetDIBData();

            if (m_BackingDib.pBase && DibTmp.pBase && lBytesToCopy)
            {
                CopyMemory(DibTmp.pBase, m_BackingDib.pBase, lBytesToCopy);
            }
        }

    }

    // we might have to do the synchronization right here
    {
        CAutoLock cLock(m_pFilterLock);
        CAutoLock cAllocatorLock(static_cast<CCritSec*>(static_cast<CBaseAllocator*>(m_pAllocator)));

        if (m_bSyncOnFill)
        {
            bWaitForDraw = m_pSyncObj->CheckReady();
            if (m_pSyncObj->GetRealState() == State_Running)
            {
                (*ppSample)->SetDiscontinuity((dwFlags & AM_GBF_PREVFRAMESKIPPED) != 0);
                (*ppSample)->SetTime(pStartTime,pEndTime);
                bWaitForDraw = m_pSyncObj->ScheduleSample(*ppSample);
                (*ppSample)->SetDiscontinuity(FALSE);
                (*ppSample)->SetTime(NULL,NULL);
            }

            // Store the interface if we wait
            if (bWaitForDraw == TRUE)
            {
                m_pSyncObj->SetCurrentSample(*ppSample);
            }
        }
    }

    // Have the sample scheduled for drawing. We might get blocked here, if
    // the state is paused and we have already got a sample
    if (bWaitForDraw)
    {
        hr = m_pSyncObj->WaitForRenderTime();
    }

    // we must wait for the rendering time without the objects locked so that
    // state changes can get in and release us in WaitForRenderTime. After we
    // return we must relock the objects.
    {
        CAutoLock cLock(m_pFilterLock);
        CAutoLock cAllocatorLock(static_cast<CCritSec*>(static_cast<CBaseAllocator*>(m_pAllocator)));

        m_pSyncObj->SetCurrentSample(NULL);
        // Did the state change while waiting
        if (hr == VFW_E_STATE_CHANGED)
        {
            DbgLog((LOG_TRACE, 5, TEXT("State has changed, exiting")));
            hr = VFW_E_STATE_CHANGED;
            goto CleanUp;
        }

        // the first sample must change formats
        if (m_bDynamicFormatNeeded)
        {
            hr = IsPalettised(&m_mtNew, &bPalettised);
            ASSERT(SUCCEEDED(hr));

            if (m_bNewPaletteSet && bPalettised && m_pFilter->GetDisplay()->IsPalettised())
            {
                if (m_pFilter->UsingWindowless()) {

                    RGBQUAD *pColours = NULL;
                    RGBQUAD *pColoursMT = NULL;

                    // get the palette entries from the Base Pin
                    // and copy them into the palette info in the mediatype
                    BITMAPINFOHEADER *pHeader = GetbmiHeader(&m_mt);
                    if (pHeader) {

                        pColours = (RGBQUAD *)GetColorInfo(&m_mtNew);
                        pColoursMT = (RGBQUAD *)GetColorInfo(&m_mt);

                        // Now copy the palette colours across
                        CopyMemory(pColours, pColoursMT,
                                   (pHeader->biClrUsed * sizeof(RGBQUAD)));
                    }
                    else hr = E_FAIL;
                }
                else {

                    RGBQUAD *pColours = NULL;
                    PALETTEENTRY *pPaletteEntries = NULL;
                    DWORD dwNumPaletteEntries = 0, dwCount = 0;

                    // get the palette entries from the filter
                    hr = m_pFilter->GetPaletteEntries(&dwNumPaletteEntries, &pPaletteEntries);
                    if (SUCCEEDED(hr))
                    {
                        ASSERT(dwNumPaletteEntries);
                        ASSERT(pPaletteEntries);

                        // get the pointer to the palette info in the mediatype
                        pColours = (RGBQUAD *)GetColorInfo(&m_mtNew);

                        // Now copy the palette colours across
                        for (dwCount = 0; dwCount < dwNumPaletteEntries; dwCount++)
                        {
                            pColours[dwCount].rgbRed = pPaletteEntries[dwCount].peRed;
                            pColours[dwCount].rgbGreen = pPaletteEntries[dwCount].peGreen;
                            pColours[dwCount].rgbBlue = pPaletteEntries[dwCount].peBlue;
                            pColours[dwCount].rgbReserved = 0;
                        }
                    }
                }
                m_bNewPaletteSet = FALSE;
            }

            SetMediaType(&m_mtNew);
            // store m_mtNew in m_mtNewAdjusted with the width of the mediatype adjusted
            CopyAndAdjustMediaType(&m_mtNewAdjusted, &m_mtNew);

            pCDDrawMediaSample->SetMediaType(&m_mtNew);
            m_bDynamicFormatNeeded = FALSE;
        }

        if (m_RenderTransport == AM_OVERLAY && !m_bSyncOnFill)
        {
            // if deocoder needs the last frame, copy it from the visible surface
            // to the back buffer
            if (dwFlags & AM_GBF_NOTASYNCPOINT)
            {
                hr = pCDDrawMediaSample->GetDDrawSurface(&pBackBuffer);
                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR, 1, TEXT("pCDDrawMediaSample->LockMediaSamplePointer failed, hr = 0x%x"), hr));
                    goto CleanUp;
                }

                // Finally copy the overlay to the back buffer
                if (!m_bDontFlip)   // if BltFast() hasn't already failed
                {
                    hr = pBackBuffer->BltFast((DWORD) 0, (DWORD) 0, m_pDirectDrawSurface, (RECT *) NULL,
                                              DDBLTFAST_WAIT |  DDBLTFAST_NOCOLORKEY) ;
                    if (FAILED(hr) && hr != DDERR_WASSTILLDRAWING)
                    {
                        DbgLog((LOG_ERROR, 1, TEXT("pBackBuffer->BltFast failed, hr = 0x%x"), hr));
                        // if BltFast fails, then stop using flipping, just use one overlay from now on
                        m_bSyncOnFill = FALSE;

                        //
                        // Make all the output go to the same overlay surface and stop flipping
                        //
                        m_bDontFlip = TRUE ;

                        CDDrawMediaSample  *pDDSample ;
                        for (pDDSample = (CDDrawMediaSample *)*ppSample ;
                             pDDSample ;
                             pDDSample = (CDDrawMediaSample *)pDDSample->Next())
                        {
                            hr = pDDSample->SetDDrawSurface(m_pDirectDrawSurface) ;
                            ASSERT(SUCCEEDED(hr)) ;
                        }
                    }

                    ASSERT(hr != DDERR_WASSTILLDRAWING);
                }  // end of if (!m_bDontFlip)
            }
        }

        if (m_RenderTransport == AM_OVERLAY || m_RenderTransport == AM_OFFSCREEN)
        {
            hr = pCDDrawMediaSample->LockMediaSamplePointer();
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("pCDDrawMediaSample->LockMediaSamplePointer failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
        }

    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::OnGetBuffer")));
    return hr;
}

// In case of flipping surfaces, gets the back buffer
HRESULT COMInputPin::OnReleaseBuffer(IMediaSample *pMediaSample)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::OnReleaseBuffer")));

    CAutoLock cLock(m_pFilterLock);

    if (m_RenderTransport == AM_OVERLAY && !m_bSyncOnFill)
    {
        hr = ((CDDrawMediaSample*)pMediaSample)->GetDDrawSurface(&m_pBackBuffer);
        ASSERT(SUCCEEDED(hr));
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::OnReleaseBuffer")));
    return hr;
}

/*****************************Private*Routine******************************\
* GetUpstreamFilterName
*
*
*
* History:
* Tue 11/30/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
COMInputPin::GetUpstreamFilterName(
    TCHAR* FilterName
    )
{
    PIN_INFO PinInfo;

    if (!m_Connected)
    {
        return VFW_E_NOT_CONNECTED;
    }

    HRESULT hr = m_Connected->QueryPinInfo(&PinInfo);
    if (SUCCEEDED(hr))
    {
        FILTER_INFO FilterInfo;
        hr = PinInfo.pFilter->QueryFilterInfo(&FilterInfo);
        if (SUCCEEDED(hr))
        {
            wsprintf(FilterName, TEXT("%ls"), FilterInfo.achName);
            if (FilterInfo.pGraph)
            {
                FilterInfo.pGraph->Release();
            }
        }
        PinInfo.pFilter->Release();
    }

    return hr;
}
HRESULT COMInputPin::CreateDDrawSurface(CMediaType *pMediaType, AM_RENDER_TRANSPORT amRenderTransport,
                                        DWORD *pdwMaxBufferCount, LPDIRECTDRAWSURFACE *ppDDrawSurface)
{
    HRESULT hr = NOERROR;
    DDSURFACEDESC SurfaceDesc;
    DWORD dwInterlaceFlags = 0, dwTotalBufferCount = 0, dwMinBufferCount = 0;
    DDSCAPS ddSurfaceCaps;
    BITMAPINFOHEADER *pHeader;
    FOURCCMap amFourCCMap(pMediaType->Subtype());
    LPDIRECTDRAW pDirectDraw = NULL;

    ASSERT(amRenderTransport != AM_VIDEOACCELERATOR);

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::CreateDDrawSurface")));

    CAutoLock cLock(m_pFilterLock);

    pDirectDraw = m_pFilter->GetDirectDraw();
    ASSERT(pDirectDraw);

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!ppDDrawSurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("ppDDrawSurface is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (amRenderTransport != AM_OFFSCREEN &&
        amRenderTransport != AM_OVERLAY)
    {
        DbgLog((LOG_ERROR, 1, TEXT("amRenderTransport = %d, not a valid value"),
            amRenderTransport));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pdwMaxBufferCount)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pdwMaxBufferCount is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    pHeader = GetbmiHeader(pMediaType);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    hr = GetInterlaceFlagsFromMediaType(pMediaType, &dwInterlaceFlags);
    ASSERT(SUCCEEDED(hr));

    // Set the surface description common to all kinds of surfaces
    INITDDSTRUCT(SurfaceDesc);
    SurfaceDesc.dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT;
    SurfaceDesc.dwWidth = abs(pHeader->biWidth);
    SurfaceDesc.dwHeight = abs(pHeader->biHeight);

//  if (DisplayingFields(dwInterlaceFlags))
//      SurfaceDesc.dwHeight = (DWORD)( ((float)(SurfaceDesc.dwHeight+1)) / 2.0 );

    if (amRenderTransport == AM_OFFSCREEN)
    {
        // store the caps and dimensions
        // try video memory first

        // It would be nice to use video memory because that way we can take
        // advantage of the h/w Blter, but Mediamatics ignore the stride
        // value when we QueryAccept them with this surface, resulting in unreadable
        // Sub-Pictures.  Therefore we restrict the usage to just the Teletext decoder.
        //
        hr = E_FAIL;
        TCHAR FilterName[MAX_FILTER_NAME];
        if (SUCCEEDED(GetUpstreamFilterName(FilterName)))
        {
            if (0 == lstrcmp(FilterName, TEXT("WST Decoder")))
            {
                LPDDCAPS pDirectCaps = m_pFilter->GetHardwareCaps();
                if (pDirectCaps->dwCaps & DDCAPS_BLTSTRETCH) {

                    SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN |
                                                 DDSCAPS_VIDEOMEMORY;

                    hr = m_pFilter->GetDirectDraw()->CreateSurface(&SurfaceDesc,
                                                                   ppDDrawSurface,
                                                                   NULL);
                }
            }
        }

        if (FAILED(hr))
        {
            //
            // Can't get any video memory - try system memory
            //
            SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN | DDSCAPS_SYSTEMMEMORY;
            hr = m_pFilter->GetDirectDraw()->CreateSurface(&SurfaceDesc, ppDDrawSurface, NULL);

            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,1,
                        TEXT("Function CreateSurface type %4.4hs failed, hr = 0x%x"),
                        &pHeader->biCompression, hr));
                goto CleanUp;
            }
        }

    }
    else
    {
        ASSERT(amRenderTransport == AM_OVERLAY);

        SurfaceDesc.dwFlags |= DDSD_PIXELFORMAT;

        // store the caps and dimensions
        SurfaceDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY | DDSCAPS_VIDEOMEMORY;

        // define the pixel format
        SurfaceDesc.ddpfPixelFormat.dwSize = sizeof(DDPIXELFORMAT);

        if (pHeader->biCompression <= BI_BITFIELDS &&
            m_pFilter->GetDisplay()->GetDisplayDepth() <= pHeader->biBitCount)
        {
            SurfaceDesc.ddpfPixelFormat.dwFourCC = BI_RGB;
            SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_RGB;
            SurfaceDesc.ddpfPixelFormat.dwRGBBitCount = pHeader->biBitCount;

            // Store the masks in the DDSURFACEDESC
            const DWORD *pBitMasks = GetBitMasks(pMediaType);
            ASSERT(pBitMasks);
            SurfaceDesc.ddpfPixelFormat.dwRBitMask = pBitMasks[0];
            SurfaceDesc.ddpfPixelFormat.dwGBitMask = pBitMasks[1];
            SurfaceDesc.ddpfPixelFormat.dwBBitMask = pBitMasks[2];
        }
        else if (pHeader->biCompression > BI_BITFIELDS &&
            pHeader->biCompression == amFourCCMap.GetFOURCC())
        {
            SurfaceDesc.ddpfPixelFormat.dwFourCC = pHeader->biCompression;
            SurfaceDesc.ddpfPixelFormat.dwFlags = DDPF_FOURCC;
            SurfaceDesc.ddpfPixelFormat.dwYUVBitCount = pHeader->biBitCount;
        }
        else
        {
            DbgLog((LOG_ERROR, 1, TEXT("Supplied mediatype not suitable for either YUV or RGB surfaces")));
            hr = E_FAIL;
            goto CleanUp;
        }

        if (NeedToFlipOddEven(dwInterlaceFlags, 0, NULL))
            dwMinBufferCount = 1;
        else
            dwMinBufferCount = 0;

        // Create the overlay surface

        // Don't flip for motion compensation surfaces
        // This bypasses a bug in the current ATI Rage Pro driver
        if (pHeader->biCompression == MAKEFOURCC('M', 'C', '1', '2'))
        {
            NOTE("Don't flip for motion compensation surfaces");
            *pdwMaxBufferCount = 1;

            dwMinBufferCount = 0;
        }

        //  Initialize hr in case dwMinBufferCount >= *pdwMaxBufferCount (was
        //  for Zoran in the motion comp case)
        hr = E_OUTOFMEMORY;
        for (dwTotalBufferCount = *pdwMaxBufferCount; dwTotalBufferCount > dwMinBufferCount; dwTotalBufferCount--)
        {
            if (dwTotalBufferCount > 1)
            {
                SurfaceDesc.dwFlags |= DDSD_BACKBUFFERCOUNT;
                SurfaceDesc.ddsCaps.dwCaps &= ~DDSCAPS_NONLOCALVIDMEM;
                SurfaceDesc.ddsCaps.dwCaps |= DDSCAPS_FLIP | DDSCAPS_COMPLEX | DDSCAPS_LOCALVIDMEM;
                SurfaceDesc.dwBackBufferCount = dwTotalBufferCount-1;
            }
            else
            {
                SurfaceDesc.dwFlags &= ~DDSD_BACKBUFFERCOUNT;
                SurfaceDesc.ddsCaps.dwCaps &= ~(DDSCAPS_FLIP | DDSCAPS_COMPLEX);
                SurfaceDesc.ddsCaps.dwCaps &= ~DDSCAPS_NONLOCALVIDMEM;
                SurfaceDesc.ddsCaps.dwCaps |= DDSCAPS_LOCALVIDMEM;
                SurfaceDesc.dwBackBufferCount = 0;
            }

            DbgLog((LOG_TRACE,2, TEXT("Creating surf with %#X DDObj"),pDirectDraw));
            hr = pDirectDraw->CreateSurface(&SurfaceDesc, ppDDrawSurface, NULL);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,1, TEXT("Function CreateSurface failed in Video memory, BackBufferCount = %d, hr = 0x%x"),
                    dwTotalBufferCount-1, hr));
            }
            if (SUCCEEDED(hr))
            {
                break;
            }

            SurfaceDesc.ddsCaps.dwCaps &= ~DDSCAPS_LOCALVIDMEM;
            SurfaceDesc.ddsCaps.dwCaps |= DDSCAPS_NONLOCALVIDMEM;

            hr = pDirectDraw->CreateSurface(&SurfaceDesc, ppDDrawSurface, NULL);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,1, TEXT("Function CreateSurface failed in AGP memory, BackBufferCount = %d, hr = 0x%x"),
                    dwTotalBufferCount-1, hr));
            }
            if (SUCCEEDED(hr))
            {
                break;
            }
        }

        // if failed to create an overlay surface, bail out
        if (FAILED(hr))
        {
#if defined(DEBUG)
            if (pHeader->biCompression > BI_BITFIELDS) {
                DbgLog((LOG_ERROR, 0, TEXT("Failed to create an overlay surface %4.4s"), &pHeader->biCompression));
            }
            else {
                DbgLog((LOG_ERROR, 0, TEXT("Failed to create an overlay surface RGB")));
            }
#endif
            DbgLog((LOG_ERROR, 0, TEXT("Failed to create an overlay surface")));
            goto CleanUp;
        }

        ASSERT(dwTotalBufferCount > 0);
        m_dwBackBufferCount = dwTotalBufferCount-1;
        *pdwMaxBufferCount = dwTotalBufferCount;
    }
    m_dwDirectDrawSurfaceWidth = SurfaceDesc.dwWidth;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::CreateDDrawSurface")));
    return hr;
}

HRESULT COMInputPin::OnDisplayChange()
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::OnDisplayChange")));

    CAutoLock cLock(m_pFilterLock);

    if (m_RenderTransport != AM_VIDEOPORT && m_RenderTransport != AM_IOVERLAY)
    {
        // notify the sync object about the change
        hr = m_pSyncObj->OnDisplayChange();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pSyncObj->OnDisplayChange failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::OnDisplayChange")));
    return hr;
}


// this function is used to restore the ddraw surface. In the videoport case, we just recreate
// the whole thing from scratch.
HRESULT COMInputPin::RestoreDDrawSurface()
{
    HRESULT hr = NOERROR;

    if (m_RenderTransport == AM_VIDEOPORT)
    {
        // stop the video
        m_pIVPObject->Inactive();
        // don't have to give up the IVPConfig interface here
        m_pIVPObject->BreakConnect(TRUE);
        // redo the connection process
        hr = m_pIVPObject->CompleteConnect(NULL, TRUE);
        goto CleanUp;
    }

    if (!m_pDirectDrawSurface)
    {
        goto CleanUp;
    }

    if (m_pDirectDrawSurface->IsLost() == DDERR_SURFACELOST)
    {
        hr = m_pDirectDrawSurface->Restore();
        if (FAILED(hr))
        {
            goto CleanUp;
        }
        // paint the ddraw surface black
        hr = PaintDDrawSurfaceBlack(m_pDirectDrawSurface);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0, TEXT("PaintDDrawSurfaceBlack FAILED, hr = 0x%x"), hr));
            // not being able to paint the ddraw surface black is not a fatal error
            hr = NOERROR;
        }
    }

CleanUp:
    return hr;
}


// Both the Src and the Dest rects go throught a series of transformations the order of which is
// significant.
// Initial Rect ----> Compensation for IVideoWindow rects ---> Compensation for local pin coords (m_rRelPos)
// ----> Compensation for aspect ratio ----> Compensation for cropping rect specified in the mediatype ---->
// Compensation for the interlaced video (only for src rect)

// the rcSource and rcTarget specified in the mediatype have to be transformed into the scaling/cropping
// matrices. This is because the zoom done by IBasicVideo should be applied only to the scaling matrix and
// not the cropping one.

HRESULT COMInputPin::CalcSrcDestRect(
    const DRECT *prdRelativeSrcRect,  //  This is the subset of the source
                                      //  defined by the IVideoWindow source
                                      //  rect scaled to a subset of 10000x10000
                                      //  assuming the whole source is 10000x10000
    const DRECT *prdDestRect,         //  This is the dest rect
                                      //  defined by IVideoWindow in dest units
    RECT *prAdjustedSrcRect,          //  This is the new source rect in source rect units
    RECT *prAdjustedDestRect,         //  This is the new dest rect in dest rect units
    RECT *prUncroppedDestRect         //  This is the uncropped dest
)
{
    HRESULT hr = NOERROR;
    DRECT  rdLocalSrcRect, rdLocalDestRect, rdCropMediaTypeRect, rdRelativeSrcClipRect, rdOldLocalSrcRect, rdOldLocalDestRect, rdRelPos;
    double dImageWidth = 0, dImageHeight = 0;
    double dPixelAspectRatio = 0.0, dTransformRatio = 0.0;
    AM_ASPECT_RATIO_MODE amAdjustedARMode = AM_ARMODE_STRETCHED;
    DWORD dwAdjustedPARatioX = 0, dwAdjustedPARatioY = 0;

    DbgLog((LOG_TRACE, 5,TEXT("Entering COMInputPin::CalcSrcDestRect")));

    SetRect(&rdLocalSrcRect, 0, 0, 0, 0);
    SetRect(&rdLocalDestRect, 0, 0, 0, 0);
    SetRect(&rdCropMediaTypeRect, 0, 0, 0, 0);
    SetRect(&rdRelativeSrcClipRect, 0, 0, 0, 0);
    SetRect(&rdOldLocalSrcRect, 0, 0, 0, 0);
    SetRect(&rdOldLocalDestRect, 0, 0, 0, 0);


    DbgLog((LOG_TRACE, 2, TEXT("m_dwPinId = %d"), m_dwPinId));
    DbgLogRectMacro((2, TEXT("prdRelativeSrcRect = "), prdRelativeSrcRect));
    DbgLogRectMacro((2, TEXT("prdDestRect = "), prdDestRect));

    SetRect(&rdRelPos, m_rRelPos.left, m_rRelPos.top, m_rRelPos.right, m_rRelPos.bottom);

    DbgLogRectMacro((2, TEXT("rdRelPos = "), &rdRelPos));

    // get the scale and crop rects from the current mediatype
    hr = GetScaleCropRectsFromMediaType(&m_mtNewAdjusted, &rdLocalSrcRect, &rdCropMediaTypeRect);
    ASSERT(SUCCEEDED(hr));

    DbgLogRectMacro((2, TEXT("rdScaledSrcRect = "), &rdLocalSrcRect));
    DbgLogRectMacro((2, TEXT("rdCropMediaTypeRect = "), &rdCropMediaTypeRect));

    // call this function to get the adjusted aspect ratio mode and the adjusted picture aspect ratio numbers
    hr = GetAdjustedModeAndAspectRatio(&amAdjustedARMode, &dwAdjustedPARatioX, &dwAdjustedPARatioY);
    if ( FAILED(hr) )
        return hr;

    dImageWidth = GetWidth(&rdLocalSrcRect);
    dImageHeight = GetHeight(&rdLocalSrcRect);

    // compute the pixel aspect ratio
    dPixelAspectRatio = ((double)dwAdjustedPARatioX / (double)dwAdjustedPARatioY) /
        (dImageWidth / dImageHeight);

    // Both the src and the dest rect depends upon two things, which portion of the total
    // video does the user want to see (determined by pRelativeSrcRect) and which
    // subrect of the destination is this pin outputting to (determined by m_rRelPos).
    // Since both rects are relative and their "base" is MAX_REL_NUM, we can take
    // their intersection
    IntersectRect(&rdRelativeSrcClipRect, &rdRelPos, prdRelativeSrcRect);

    // Clip the src rect in the same proportion as the intersection of the
    // RelativeSrcRect and m_rRelPos clips m_rRelPos
    CalcSrcClipRect(&rdLocalSrcRect, &rdLocalSrcRect, &rdRelPos, &rdRelativeSrcClipRect);

    // Clip the dest rect in the same proportion as the intersection of the
    // RelativeSrcRect and m_rRelPos clips RelativeSrcRect
    // if pRelativeSrcRect = {0, 0, 10000, 10000} then this operation is equivalent to
    // rLocalDestRect = CalcSubRect(pDestRect, &m_rRelPos);
    CalcSrcClipRect(prdDestRect, &rdLocalDestRect, prdRelativeSrcRect, &rdRelativeSrcClipRect);

    DbgLogRectMacro((2, TEXT("rdLocalSrcRect = "), &rdLocalSrcRect));
    DbgLogRectMacro((2, TEXT("rdLocalDestRect = "), &rdLocalDestRect));

    // if one dimension is zero, might as well as make the whole rect
    // empty. Then the callee can just check for that
    if ((GetWidth(&rdLocalSrcRect) < 1) || (GetHeight(&rdLocalSrcRect) < 1))
        SetRect(&rdLocalSrcRect, 0, 0, 0, 0);
    if ((GetWidth(&rdLocalDestRect) < 1) || (GetHeight(&rdLocalDestRect) < 1))
        SetRect(&rdLocalSrcRect, 0, 0, 0, 0);

    if (!IsRectEmpty(&rdLocalSrcRect) && !IsRectEmpty(&rdLocalDestRect))
    {
        if (amAdjustedARMode == AM_ARMODE_LETTER_BOX)
        {
            // compute the transform ratio
	    dTransformRatio = (GetWidth(&rdLocalSrcRect)/GetHeight(&rdLocalSrcRect))*dPixelAspectRatio;

            // if we are in letter-box then shrink the destination rect appropriately
            // Note that essedntially the ratio of the WidthTOHeightRatio of dest rect to the
            // WidthTOHeightRatio of src rect must always be the pixel aspect ratio
            TransformRect(&rdLocalDestRect, dTransformRatio, AM_SHRINK);
        }
        else if (amAdjustedARMode == AM_ARMODE_CROP)
        {
            // compute the transform ratio
            dTransformRatio = (GetWidth(&rdLocalDestRect)/GetHeight(&rdLocalDestRect))/dPixelAspectRatio;

            // if we are cropping, then we must shrink the source rectangle appropriately.
            // Note that essedntially the ratio of the WidthTOHeightRatio of dest rect to the
            // WidthTOHeightRatio of src rect must always be the pixel aspect ratio
            TransformRect(&rdLocalSrcRect, dTransformRatio, AM_SHRINK);
        }



        rdOldLocalSrcRect = rdLocalSrcRect;
        rdOldLocalDestRect = rdLocalDestRect;

        // now intersect the local src rect with the cropping rect specified by the mediatype
        IntersectRect(&rdLocalSrcRect, &rdLocalSrcRect, &rdCropMediaTypeRect);

        // Clip the dest rect in the same proportion as the intersection of the
        // rLocalSrcRect and rCropMediaTypeRect clips rLocalSrcRect
        CalcSrcClipRect(&rdLocalDestRect, &rdLocalDestRect, &rdOldLocalSrcRect, &rdLocalSrcRect);

        DbgLogRectMacro((2, TEXT("rdLocalSrcRect = "), &rdLocalSrcRect));
        DbgLogRectMacro((2, TEXT("rdLocalDestRect = "), &rdLocalDestRect));
    }

    if (DisplayingFields(m_dwInterlaceFlags) && !IsRectEmpty(&rdLocalSrcRect))
    {
        ScaleRect(&rdLocalSrcRect, GetWidth(&rdLocalSrcRect), GetHeight(&rdLocalSrcRect),
            GetWidth(&rdLocalSrcRect), GetHeight(&rdLocalSrcRect)/2.0);
    }

    if (prAdjustedSrcRect)
    {
        *prAdjustedSrcRect = MakeRect(rdLocalSrcRect);
    }
    if (prAdjustedDestRect)
    {
        *prAdjustedDestRect = MakeRect(rdLocalDestRect);
    }
    if (prUncroppedDestRect)
    {
        *prUncroppedDestRect = MakeRect(rdOldLocalDestRect);
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::CalcSrcDestRect")));

    return hr;
}


// informs the pin that the window has been closed
HRESULT COMInputPin::OnClipChange(LPWININFO pWinInfo)
{
    HRESULT hr = NOERROR;
    BOOL bAdvisePending = FALSE;
    LPDIRECTDRAWSURFACE pPrimarySurface = NULL;
    LPDDCAPS pDirectCaps = NULL;
    COLORKEY *pColorKey = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::OnClipChange")));

    {
        CAutoLock cLock(m_pFilterLock);

        if (m_RenderTransport == AM_OVERLAY ||
            m_RenderTransport == AM_OFFSCREEN ||
            m_RenderTransport == AM_VIDEOPORT ||
            m_RenderTransport == AM_IOVERLAY ||
            m_RenderTransport == AM_VIDEOACCELERATOR)
        {
            pPrimarySurface = m_pFilter->GetPrimarySurface();
            if ( NULL == pPrimarySurface )
            {
                DbgLog((LOG_ERROR, 2, TEXT("Could not get primary")));
                hr = E_FAIL;
                goto CleanUp;
            }

            pDirectCaps = m_pFilter->GetHardwareCaps();
            if ( NULL == pDirectCaps )
            {
                DbgLog((LOG_ERROR, 2, TEXT("Could not get DirectDraw caps")));
                hr = E_FAIL;
                goto CleanUp;
            }

            pColorKey = m_pFilter->GetColorKeyPointer();
            if ( NULL == pColorKey )
            {
                DbgLog((LOG_ERROR, 2, TEXT("Could not get color key")));
                hr = E_FAIL;
                goto CleanUp;
            }
        }

        if (m_RenderTransport == AM_OFFSCREEN || m_RenderTransport == AM_GDI)
        {
            if (m_bOverlayHidden)
            {
                DbgLog((LOG_TRACE, 2, TEXT("m_bOverlayHidden is TRUE")));
                goto CleanUp;
            }
            // make a copy of the WININFO so that we can modify it
            m_WinInfo.TopLeftPoint = pWinInfo->TopLeftPoint;
            m_WinInfo.SrcRect = pWinInfo->SrcRect;
            m_WinInfo.DestRect = pWinInfo->DestRect;
            m_WinInfo.SrcClipRect = pWinInfo->SrcClipRect;
            m_WinInfo.DestClipRect = pWinInfo->DestClipRect;
            CombineRgn(m_WinInfo.hClipRgn, pWinInfo->hClipRgn, NULL, RGN_COPY);

            DoRenderSample(NULL);
        }
        else if (m_RenderTransport == AM_OVERLAY ||
                 m_RenderTransport == AM_VIDEOPORT ||
                 m_RenderTransport == AM_VIDEOACCELERATOR)
        {

            // do not show the overlay if we have not received a frame yet
            if (m_bOverlayHidden)
            {
                COLORKEY blackColorKey;
                // we will use black on the rest of the region left
                blackColorKey.KeyType = CK_INDEX | CK_RGB;
                blackColorKey.PaletteIndex = 0;
                blackColorKey.LowColorValue = blackColorKey.HighColorValue = RGB(0,0,0);
                hr = m_pFilter->PaintColorKey(pWinInfo->hClipRgn, &blackColorKey);

                DbgLog((LOG_TRACE, 2, TEXT("m_bOverlayHidden is TRUE")));
                goto CleanUp;

            }
            // paint the colorkey in the region
            DbgLog((LOG_TRACE, 2, TEXT("Painting color key")));
            hr = m_pFilter->PaintColorKey(pWinInfo->hClipRgn, pColorKey);
            ASSERT(SUCCEEDED(hr));


            if (m_RenderTransport == AM_VIDEOPORT)
            {
                // tell the videoport object
                hr = m_pIVPObject->OnClipChange(pWinInfo);
                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->OnClipChange failed, hr = 0x%x"), hr));
                    goto CleanUp;
                }
                goto CleanUp;
            }

            if (!m_pDirectDrawSurface)
            {
                DbgLog((LOG_ERROR, 1, TEXT("OnClipChange, m_pDirectDrawSurface = NULL")));
                goto CleanUp;
            }

            // if the dest empty is empty just hide the overlay
            if (IsRectEmpty(&pWinInfo->DestClipRect))
            {
                hr = m_pFilter->CallUpdateOverlay(
                          m_pDirectDrawSurface,
                          NULL,
                          pPrimarySurface,
                          NULL,
                          DDOVER_HIDE);
                goto CleanUp;
            }

            // make a copy of the WININFO so that we can modify it
            m_WinInfo.SrcRect = pWinInfo->SrcRect;
            m_WinInfo.DestRect = pWinInfo->DestRect;
            m_WinInfo.SrcClipRect = pWinInfo->SrcClipRect;
            m_WinInfo.DestClipRect = pWinInfo->DestClipRect;
            CombineRgn(m_WinInfo.hClipRgn, pWinInfo->hClipRgn, NULL, RGN_COPY);

            //AdjustSourceSize(&m_WinInfo, m_dwMinCKStretchFactor);
            ApplyDecimation(&m_WinInfo);

            CalcSrcClipRect(&m_WinInfo.SrcRect, &m_WinInfo.SrcClipRect,
                            &m_WinInfo.DestRect, &m_WinInfo.DestClipRect,
                            TRUE);

            AlignOverlaySrcDestRects(pDirectCaps,
                                    &m_WinInfo.SrcClipRect,
                                    &m_WinInfo.DestClipRect);

            hr = m_pFilter->CallUpdateOverlay(
                                     m_pDirectDrawSurface,
                                     &m_WinInfo.SrcClipRect,
                                     pPrimarySurface,
                                     &m_WinInfo.DestClipRect,
                                     m_dwUpdateOverlayFlags,
                                     NULL);

        }
        else if (m_RenderTransport == AM_IOVERLAY)
        {
            BOOL bMaintainRatio = TRUE;

            // paint the colorkey in the region
            DbgLog((LOG_TRACE, 2, TEXT("Paint color key for IOverlay")));
            hr = m_pFilter->PaintColorKey(pWinInfo->hClipRgn, pColorKey);
            ASSERT(SUCCEEDED(hr));

            // make a copy of the WININFO so we can notify the client through IOverlayNotify
            m_WinInfo.SrcRect = pWinInfo->SrcRect;
            m_WinInfo.DestRect = pWinInfo->DestRect;
            m_WinInfo.SrcClipRect = pWinInfo->SrcClipRect;
            m_WinInfo.DestClipRect = pWinInfo->DestClipRect;
            CombineRgn(m_WinInfo.hClipRgn, pWinInfo->hClipRgn, NULL, RGN_COPY);

            CalcSrcClipRect(&m_WinInfo.SrcRect, &m_WinInfo.SrcClipRect,
                            &m_WinInfo.DestRect, &m_WinInfo.DestClipRect,
                            bMaintainRatio);

            bAdvisePending = TRUE;
        }
    }

    // make sure the call back happens without any filter lock
    if (bAdvisePending)
    {
        NotifyChange(ADVISE_POSITION | ADVISE_CLIPPING);
    }
CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::OnClipChange")));
    return hr;
}

// this function sets the position of the stream in the display window, assuming
// that the window coordinates are {0, 0, 10000, 10000}. Thus giving arguments
// (0, 0, 5000, 5000) will put the stream in the top-left quarter. Any value greater
// than 10000 is invalid.
STDMETHODIMP COMInputPin::SetRelativePosition(DWORD dwLeft, DWORD dwTop, DWORD dwRight, DWORD dwBottom)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetRelativePosition")));

    if (dwLeft > MAX_REL_NUM || dwTop > MAX_REL_NUM || dwRight > MAX_REL_NUM || dwBottom > MAX_REL_NUM ||
        dwRight < dwLeft || dwBottom < dwTop)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid arguments, dwLeft = %d, dwTop = %d, dwRight = %d, dwBottom = %d"),
            dwLeft, dwTop, dwRight, dwBottom));

        hr = E_INVALIDARG;
        goto CleanUp;
    }


    {
        CAutoLock cLock(m_pFilterLock);
        if (m_rRelPos.left != (LONG)dwLeft || m_rRelPos.top != (LONG)dwTop || m_rRelPos.right != (LONG)dwRight || m_rRelPos.bottom != (LONG)dwBottom)
        {
            m_rRelPos.left = dwLeft;
            m_rRelPos.top = dwTop;
            m_rRelPos.right = dwRight;
            m_rRelPos.bottom = dwBottom;

            // make sure that the video frame gets updated by redrawing everything
            EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetRelativePosition")));
    return hr;
}

// this function sets the position of the stream in the display window, assuming
// that the window coordinates are {0, 0, 10000, 10000}. Thus giving arguments
// (0, 0, 5000, 5000) will put the stream in the top-left quarter. Any value greater
// than 10000 is invalid.
STDMETHODIMP COMInputPin::GetRelativePosition(DWORD *pdwLeft, DWORD *pdwTop, DWORD *pdwRight, DWORD *pdwBottom)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetRelativePosition")));

    if (!pdwLeft || !pdwTop || !pdwRight || !pdwBottom)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid arguments, pdwLeft = 0x%x, pdwTop = 0x%x, pdwRight = 0x%x, pdwBottom = 0x%x"),
            pdwLeft, pdwTop, pdwRight, pdwBottom));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    {
        CAutoLock cLock(m_pFilterLock);
        *pdwLeft = m_rRelPos.left;
        *pdwTop = m_rRelPos.top;
        *pdwRight = m_rRelPos.right;
        *pdwBottom = m_rRelPos.bottom;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetRelativePosition")));
    return hr;
}

STDMETHODIMP COMInputPin::SetZOrder(DWORD dwZOrder)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetZOrder")));

    CAutoLock cLock(m_pFilterLock);

    if (dwZOrder != m_dwZOrder)
    {
        m_dwZOrder = dwZOrder;

        m_dwInternalZOrder = (m_dwZOrder << 24) | m_dwPinId;

        // make sure that the video frame gets updated by redrawing everything
        EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetZOrder")));
    return NOERROR;
}


STDMETHODIMP COMInputPin::GetZOrder(DWORD *pdwZOrder)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetZOrder")));

    if (pdwZOrder == NULL)
    {
        DbgLog((LOG_ERROR, 1, TEXT("Invalid arguments, pdwZOrder = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    {
        //  No need to lock - getting a DWORD is safe
        *pdwZOrder = m_dwZOrder;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetZOrder")));
    return hr;
}

STDMETHODIMP COMInputPin::SetColorKey(COLORKEY *pColorKey)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetColorKey")));

    CAutoLock cLock(m_pFilterLock);

    if (m_dwPinId != 0)
    {
        hr = E_NOTIMPL;
        DbgLog((LOG_ERROR, 1, TEXT("m_dwPinId != 0, returning E_NOTIMPL")));
        goto CleanUp;
    }

    // make sure the pin is connected
    if (!IsCompletelyConnected())
    {
        DbgLog((LOG_ERROR, 1, TEXT("pin not connected, exiting")));
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    // make sure that either the surface allocated is an overlay surface
    // or it is an IOverlay connection
    if (m_RenderTransport != AM_OVERLAY && m_RenderTransport != AM_VIDEOPORT &&
        m_RenderTransport != AM_IOVERLAY && m_RenderTransport != AM_VIDEOACCELERATOR)
    {
        DbgLog((LOG_ERROR, 1, TEXT("surface allocated not overlay && connection not videoport && connection not IOverlay, exiting")));
        hr = E_UNEXPECTED;
        goto CleanUp;
    }

    if (!IsStopped())
    {
        hr = VFW_E_NOT_STOPPED;
        DbgLog((LOG_ERROR, 1, TEXT("not stopped, returning VFW_E_NOT_STOPPED")));
        goto CleanUp;
    }

    //  Filter method checks pointers etc
    hr = m_pFilter->SetColorKey(pColorKey);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->SetColorKey(pColorKey) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
    NotifyChange(ADVISE_COLORKEY);

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetColorKey")));
    return hr;
}

STDMETHODIMP COMInputPin::GetColorKey(COLORKEY *pColorKey, DWORD *pColor)
{
    HRESULT hr = NOERROR;
    AM_RENDER_TRANSPORT amRenderTransport;
    COMInputPin *pPrimaryPin = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetColorKey")));

    CAutoLock cLock(m_pFilterLock);

    // make sure pointers are valid
    if (!pColorKey && !pColor) {
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // make sure the pin is connected
    if (!IsCompletelyConnected())
    {
        DbgLog((LOG_ERROR, 1, TEXT("pin not connected, exiting")));
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    // if this stream is being set up as transparent then make sure we can hande it.
    // make sure that in the primary pin either the surface allocated is an overlay surface
    // or it is an IOverlay connection
    pPrimaryPin = (COMInputPin *)m_pFilter->GetPin(0);
    ASSERT(pPrimaryPin);

    // make sure the primary pin is connected
    if (!pPrimaryPin->IsCompletelyConnected())
    {
        DbgLog((LOG_ERROR, 1, TEXT("pin not connected, exiting")));
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    // get the Render Transport of the primary pin
    pPrimaryPin->GetRenderTransport(&amRenderTransport);

    // make sure gettting the colorkey makes sense
    if (amRenderTransport != AM_OVERLAY &&
        amRenderTransport != AM_VIDEOPORT &&
        amRenderTransport != AM_IOVERLAY &&
        amRenderTransport != AM_VIDEOACCELERATOR)
    {
        DbgLog((LOG_ERROR, 1, TEXT("primary pin: surface allocated not overlay && connection not videoport && connection not IOverlay, exiting")));
        hr = E_UNEXPECTED;
        goto CleanUp;
    }

    hr = m_pFilter->GetColorKey(pColorKey, pColor);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->GetColorKey(pColorKey, pColor) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }


CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetColorKey")));
    return hr;
}


STDMETHODIMP COMInputPin::SetBlendingParameter(DWORD dwBlendingParameter)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetBlendingParameter")));

    CAutoLock cLock(m_pFilterLock);

    if (m_dwPinId == 0)
    {
        DbgLog((LOG_ERROR, 1, TEXT("this call not expected on the pin using the overlay surface")));
        hr = E_NOTIMPL;
        goto CleanUp;
    }

    if ( dwBlendingParameter > MAX_BLEND_VAL)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of dwBlendingParameteris invalid, dwBlendingParameter = %d"), dwBlendingParameter));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (dwBlendingParameter != 0 && dwBlendingParameter != MAX_BLEND_VAL)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of dwBlendingParameteris invalid, currently only valid values are 0 and MAX_BLEND_VAL, dwBlendingParameter = %d"), dwBlendingParameter));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (dwBlendingParameter != m_dwBlendingParameter)
    {
        m_dwBlendingParameter = dwBlendingParameter;
        // make sure that the video frame gets updated by redrawing everything
        EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetBlendingParameter")));
    return hr;
}

STDMETHODIMP COMInputPin::GetBlendingParameter(DWORD *pdwBlendingParameter)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetBlendingParameter")));

    if (!pdwBlendingParameter)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of pdwBlendingParameteris invalid, pdwBlendingParameter = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;

    }

    {
        CAutoLock cLock(m_pFilterLock);
        *pdwBlendingParameter = m_dwBlendingParameter;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetBlendingParameter")));
    return hr;
}

STDMETHODIMP COMInputPin::SetStreamTransparent(BOOL bStreamTransparent)
{
    HRESULT hr = NOERROR;
    AM_RENDER_TRANSPORT amRenderTransport;
    COMInputPin *pPrimaryPin = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetStreamTransparent")));

    CAutoLock cLock(m_pFilterLock);

    if (m_dwPinId == 0)
    {
        DbgLog((LOG_ERROR, 1, TEXT("this call not expected on the pin using the overlay surface")));
        hr = E_NOTIMPL;
        goto CleanUp;
    }

    // make sure the pin is connected
    if (!IsConnected())
    {
        DbgLog((LOG_ERROR, 1, TEXT("pin not connected, exiting")));
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    // if this stream is being set up as transparent then make sure we can hande it.
    // make sure that in the primary pin either the surface allocated is an overlay surface
    // or it is an IOverlay connection

    pPrimaryPin = (COMInputPin *)m_pFilter->GetPin(0);
    ASSERT(pPrimaryPin);

    // make sure the primary pin is connected
    if (!pPrimaryPin->IsCompletelyConnected())
    {
        DbgLog((LOG_ERROR, 1, TEXT("pin not connected, exiting")));
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    // get the Render Transport of the primary pin
    pPrimaryPin->GetRenderTransport(&amRenderTransport);

    // make sure we can handle transparent streams
    if (bStreamTransparent && amRenderTransport != AM_OVERLAY && amRenderTransport != AM_VIDEOPORT &&
        amRenderTransport != AM_IOVERLAY && amRenderTransport != AM_VIDEOACCELERATOR)
    {
        DbgLog((LOG_ERROR, 1, TEXT("primary pin: surface allocated not overlay && connection not videoport && connection not IOverlay, exiting")));
        hr = E_UNEXPECTED;
        goto CleanUp;
    }

    if (bStreamTransparent != m_bStreamTransparent)
    {
        m_bStreamTransparent = bStreamTransparent;

        // make sure that the video frame gets updated by redrawing everything
        EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetBlendingParameter")));
    return hr;
}

STDMETHODIMP COMInputPin::GetStreamTransparent(BOOL *pbStreamTransparent)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetStreamTransparent")));

    if (!pbStreamTransparent)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of pbStreamTransparent invalid, pbStreamTransparent = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;

    }

    {
        CAutoLock cLock(m_pFilterLock);
        *pbStreamTransparent = m_bStreamTransparent;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetStreamTransparent")));
    return hr;
}


STDMETHODIMP COMInputPin::SetAspectRatioMode(AM_ASPECT_RATIO_MODE amAspectRatioMode)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetAspectRatioMode")));

    if (amAspectRatioMode != AM_ARMODE_STRETCHED &&
        amAspectRatioMode != AM_ARMODE_LETTER_BOX &&
        amAspectRatioMode != AM_ARMODE_CROP &&
        amAspectRatioMode != AM_ARMODE_STRETCHED_AS_PRIMARY)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of amAspectRatioMode invalid, amAspectRatioMode = %d"), amAspectRatioMode));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    {
        CAutoLock cLock(m_pFilterLock);
        // can't set AM_ARMODE_STRETCHED_AS_PRIMARY on primary pin
        if (amAspectRatioMode == AM_ARMODE_STRETCHED_AS_PRIMARY &&
            m_dwPinId == 0)
        {
            DbgLog((LOG_ERROR, 1, TEXT("can't set AM_ARMODE_STRETCHED_AS_PRIMARY on primary pin")));
            hr = E_INVALIDARG;
            goto CleanUp;
        }

        if (amAspectRatioMode != m_amAspectRatioMode)
        {
            m_amAspectRatioMode = amAspectRatioMode;

            // make sure that the video frame gets updated by redrawing everything
            EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetAspectRatioMode")));
    return hr;

}

HRESULT COMInputPin::GetAdjustedModeAndAspectRatio(AM_ASPECT_RATIO_MODE* pamAdjustedARMode, DWORD *pdwAdjustedPARatioX,
                                                        DWORD *pdwAdjustedPARatioY)
{
    HRESULT hr = NOERROR;
    COMInputPin *pPrimaryPin = NULL;
    AM_ASPECT_RATIO_MODE amAdjustedARMode = AM_ARMODE_STRETCHED;
    DWORD dwAdjustedPARatioX = 1, dwAdjustedPARatioY = 1;
    CMediaType CurrentMediaType;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetAdjustedModeAndAspectRatio")));

    CAutoLock cLock(m_pFilterLock);

    if (m_amAspectRatioMode == AM_ARMODE_STRETCHED_AS_PRIMARY)
    {
        pPrimaryPin = (COMInputPin *)m_pFilter->GetPin(0);
        ASSERT(pPrimaryPin);
        hr = pPrimaryPin->GetAspectRatioMode(&amAdjustedARMode);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("pPrimaryPin->GetAspectRatioMode failed, hr = 0x%x"), hr));
            hr = E_FAIL;
            goto CleanUp;
        }
        hr = pPrimaryPin->CurrentAdjustedMediaType(&CurrentMediaType);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("pPrimaryPin->CurrentAdjustedMediaType() failed, hr = 0x%x"), hr));
            hr = E_FAIL;
            goto CleanUp;
        }
    }
    else
    {
        amAdjustedARMode = m_amAspectRatioMode;
        hr = CurrentAdjustedMediaType(&CurrentMediaType);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("pPrimaryPin->CurrentAdjustedMediaType() failed, hr = 0x%x"), hr));
            hr = E_INVALIDARG;
            goto CleanUp;
        }
    }

    hr = GetPictAspectRatio(&CurrentMediaType, &dwAdjustedPARatioX, &dwAdjustedPARatioY);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetPictAspectRatio() failed, hr = 0x%x"), hr));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (pamAdjustedARMode)
        *pamAdjustedARMode = amAdjustedARMode;
    if (pdwAdjustedPARatioX)
        *pdwAdjustedPARatioX = dwAdjustedPARatioX;
    if (pdwAdjustedPARatioY)
        *pdwAdjustedPARatioY = dwAdjustedPARatioY;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetAdjustedModeAndAspectRatio")));
    return hr;
}

STDMETHODIMP COMInputPin::GetAspectRatioMode(AM_ASPECT_RATIO_MODE* pamAspectRatioMode)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetAspectRatioMode")));

    if (!pamAspectRatioMode)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of pamAspectRatioMode is invalid, pamAspectRatioMode = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;

    }

    {
        CAutoLock cLock(m_pFilterLock);
        *pamAspectRatioMode = m_amAspectRatioMode;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetAspectRatioMode")));
    return hr;
}


STDMETHODIMP COMInputPin::GetOverlaySurface(
    LPDIRECTDRAWSURFACE *pOverlaySurface
    )
{
    HRESULT hr = S_OK;

    *pOverlaySurface = NULL;

    // if not connected, this function does not make much sense since the
    // surface wouldn't even have been allocated as yet

    if (!IsCompletelyConnected())
    {
        DbgLog((LOG_ERROR, 1, TEXT("pin not connected, exiting")));
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    // make sure the surface allocated is an overlay surface
    if (m_RenderTransport != AM_OVERLAY && m_RenderTransport != AM_VIDEOPORT &&
        m_RenderTransport != AM_VIDEOACCELERATOR)
    {
        DbgLog((LOG_ERROR, 1, TEXT("surface allocated is not overlay, exiting")));
        hr = E_UNEXPECTED;
        goto CleanUp;
    }

    // get the overlay surface
    if (m_RenderTransport == AM_VIDEOPORT)
    {
        ASSERT(m_pIVPObject);
        hr = m_pIVPObject->GetDirectDrawSurface(pOverlaySurface);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->GetDirectDrawSurface() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else
    {
        *pOverlaySurface = m_pDirectDrawSurface;
    }

CleanUp:
    return hr;
}


STDMETHODIMP COMInputPin::SetOverlaySurfaceColorControls(LPDDCOLORCONTROL pColorControl)
{
    HRESULT hr = NOERROR;
    LPDIRECTDRAWSURFACE pOverlaySurface = NULL;
    LPDIRECTDRAWCOLORCONTROL pIDirectDrawControl = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetOverlaySurfaceColorControls")));

    CAutoLock cLock(m_pFilterLock);

    // make sure the argument is valid
    if (!pColorControl)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of pColorControl is invalid, pColorControl = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    hr = GetOverlaySurface(&pOverlaySurface);
    if (FAILED(hr)) {
        goto CleanUp;
    }

    // get the IDirectDrawColorControl interface
    hr = pOverlaySurface->QueryInterface(IID_IDirectDrawColorControl, (void**)&pIDirectDrawControl);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface->QueryInterface(IID_IDirectDrawColorControl) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // use the interface to set the color controls
    hr = pIDirectDrawControl->SetColorControls(pColorControl);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pIDirectDrawControl->SetColorControls failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    if (pIDirectDrawControl)
    {
        pIDirectDrawControl->Release();
        pIDirectDrawControl = NULL;
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetOverlaySurfaceColorControls")));
    return hr;
}

STDMETHODIMP COMInputPin::GetOverlaySurfaceColorControls(LPDDCOLORCONTROL pColorControl)
{
    HRESULT hr = NOERROR;
    LPDIRECTDRAWSURFACE pOverlaySurface = NULL;
    LPDIRECTDRAWCOLORCONTROL pIDirectDrawControl = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetOverlaySurfaceColorControls")));

    CAutoLock cLock(m_pFilterLock);

    // make sure the argument is valid
    if (!pColorControl)
    {
        DbgLog((LOG_ERROR, 1, TEXT("value of pColorControl is invalid, pColorControl = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // if not connected, this function does not make much sense since the surface wouldn't even have been allocated
    // as yet
    if (!m_bConnected)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pin not connected, exiting")));
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    // make sure the surface allocated is an overlay surface
    if (m_RenderTransport != AM_OVERLAY && m_RenderTransport != AM_VIDEOPORT && m_RenderTransport != AM_VIDEOACCELERATOR)
    {
        DbgLog((LOG_ERROR, 1, TEXT("surface allocated is not overlay, exiting")));
        hr = E_UNEXPECTED;
        goto CleanUp;
    }

    // get the overlay surface
    if (m_RenderTransport == AM_VIDEOPORT)
    {
        ASSERT(m_pIVPObject);
        hr = m_pIVPObject->GetDirectDrawSurface(&pOverlaySurface);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pIVPObject->GetDirectDrawSurface() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else
    {
        pOverlaySurface = m_pDirectDrawSurface;
    }

    // get the IDirectDrawColorControl interface
    hr = pOverlaySurface->QueryInterface(IID_IDirectDrawColorControl, (void**)&pIDirectDrawControl);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDrawSurface->QueryInterface(IID_IDirectDrawColorControl) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // use the interface to set the color controls
    hr = pIDirectDrawControl->GetColorControls(pColorControl);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pIDirectDrawControl->SetColorControls failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    if (pIDirectDrawControl)
    {
        pIDirectDrawControl->Release();
        pIDirectDrawControl = NULL;
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetOverlaySurfaceColorControls")));
    return hr;
}

STDMETHODIMP COMInputPin::GetRenderTransport(AM_RENDER_TRANSPORT *pamRenderTransport)
{
    ASSERT(pamRenderTransport);
    *pamRenderTransport = m_RenderTransport;
    return NOERROR;
}


HRESULT COMInputPin::GetSourceAndDest(RECT *prcSource, RECT *prcDest, DWORD *dwWidth, DWORD *dwHeight)
{
    if (m_RenderTransport == AM_VIDEOPORT)
    {
        m_pIVPObject->GetRectangles(prcSource, prcDest);
    }
    else
    {
        *prcSource = m_WinInfo.SrcClipRect;
        *prcDest = m_WinInfo.DestClipRect;
    }

    CMediaType mt;
    HRESULT hr = CurrentAdjustedMediaType(&mt);

    if (SUCCEEDED(hr))
    {
        BITMAPINFOHEADER *pHeader = GetbmiHeader(&mt);
        if ( ! pHeader )
        {
            hr = E_FAIL;
        }
        else
        {
            *dwWidth = abs(pHeader->biWidth);
            *dwHeight = abs(pHeader->biHeight);
        }
    }

    return hr;
}

HRESULT COMInputPin::NotifyChange(DWORD dwAdviseChanges)
{
    HRESULT hr = NOERROR;
    IOverlayNotify *pIOverlayNotify = NULL;
    DWORD dwAdvisePending = ADVISE_NONE;
    RECT rcSource, rcDest;
    LPRGNDATA pBuffer = NULL;
    COLORKEY ColorKey;
    DWORD dwNumPaletteEntries = 0;
    PALETTEENTRY *pPaletteEntries = NULL;
    HMONITOR hMonitor = NULL;


    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::NotifyChange")));

    {
        CAutoLock cLock(m_pFilterLock);

        // Is there a notification client
        if (m_pIOverlayNotify == NULL)
        {
            DbgLog((LOG_TRACE, 2, TEXT("No client to Notify, m_pIOverlayNotify = NULL")));
            goto CleanUp;
        }

        ASSERT(m_RenderTransport == AM_IOVERLAY);

        // addref the interface pointer
        pIOverlayNotify = m_pIOverlayNotify;

        // do we need a position change notification
        if (dwAdviseChanges & m_dwAdviseNotify & ADVISE_POSITION)
        {
            rcSource = m_WinInfo.SrcRect;
            rcDest = m_WinInfo.DestRect;
            dwAdvisePending |= ADVISE_POSITION;
        }

        // do we need a clipping change notification
        if (dwAdviseChanges & m_dwAdviseNotify & ADVISE_CLIPPING)
        {
            DWORD dwRetVal = 0, dwBuffSize = 0;
            HRESULT hrLocal = NOERROR;

            rcSource = m_WinInfo.SrcRect;
            rcDest = m_WinInfo.DestRect;

            dwRetVal = GetRegionData(m_WinInfo.hClipRgn, 0, NULL);
            if (0 == dwRetVal)
            {
                        DbgLog((LOG_ERROR, 1, TEXT("GetRegionData failed")));
                        hrLocal = E_FAIL;
            }

            if (SUCCEEDED(hrLocal))
            {
                dwBuffSize = dwRetVal;
                pBuffer = (LPRGNDATA) CoTaskMemAlloc(dwBuffSize);
                if (NULL == pBuffer)
                {
                    DbgLog((LOG_ERROR, 1, TEXT("CoTaskMemAlloc failed, pBuffer = NULL")));
                    hrLocal = E_OUTOFMEMORY;
                }
            }
            if (SUCCEEDED(hrLocal))
            {
                dwRetVal = GetRegionData(m_WinInfo.hClipRgn, dwBuffSize, pBuffer);
                ASSERT(dwRetVal  &&  pBuffer->rdh.iType == RDH_RECTANGLES);
                dwAdvisePending |= ADVISE_CLIPPING;
            }
            else
            {
                hr = hrLocal;
            }
        }

        // do we need a colorkey change notification
        if (dwAdviseChanges & m_dwAdviseNotify & ADVISE_COLORKEY)
        {
            HRESULT hrLocal = NOERROR;
            dwAdvisePending |= ADVISE_COLORKEY;
            hrLocal = m_pFilter->GetColorKey(&ColorKey, NULL);
            ASSERT(SUCCEEDED(hrLocal));
        }

        // do we need a palette change notification
        if (dwAdviseChanges & m_dwAdviseNotify & ADVISE_PALETTE)
        {
            PALETTEENTRY *pTemp = NULL;
            HRESULT hrLocal = NOERROR;

            // get the palette entries from the filter
            hrLocal = m_pFilter->GetPaletteEntries(&dwNumPaletteEntries, &pTemp);
            if (FAILED(hrLocal))
            {
                DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->GetPaletteEntries failed, hr = 0x%x"), hr));
            }
            if (SUCCEEDED(hrLocal))
            {
                ASSERT(dwNumPaletteEntries);
                pPaletteEntries = (PALETTEENTRY*) CoTaskMemAlloc(dwNumPaletteEntries * sizeof(PALETTEENTRY));
                ASSERT(pPaletteEntries);
                if (!pPaletteEntries)
                {
                    DbgLog((LOG_ERROR, 1, TEXT("CoTaskMemAlloc failed, pPaletteEntries = NULL")));
                    hrLocal = E_OUTOFMEMORY;
                }
            }
            if (SUCCEEDED(hrLocal))
            {
                memcpy(pPaletteEntries, pTemp, (dwNumPaletteEntries * sizeof(PALETTEENTRY)));
                dwAdvisePending |= ADVISE_PALETTE;
            }
            else
            {
                hr = hrLocal;
            }
        }

        if (dwAdviseChanges & m_dwAdviseNotify & ADVISE_DISPLAY_CHANGE)
        {
            HWND hwnd = NULL;
            HRESULT hrLocal = NOERROR;

            hwnd = m_pFilter->GetWindow();
            if (hwnd)
            {
                hMonitor = MonitorFromWindow(hwnd, MONITOR_DEFAULTTONULL);
                if (!hMonitor)
                {
                    hrLocal = AmHresultFromWin32(GetLastError());
                    DbgLog((LOG_ERROR, 1, TEXT("MonitorFromWindow failed: %x"), hrLocal));
                }
            }
            else
            {
                hrLocal = E_FAIL;
            }

            if (SUCCEEDED(hrLocal))
            {
                dwAdvisePending |= ADVISE_DISPLAY_CHANGE;
            }
        }
    }

    {
        DWORD dwFlags = IsRectEmpty(&rcDest) ? DDOVER_HIDE : DDOVER_SHOW;

        // make sure that all callbacks are made without holding any filter locks
        if (dwAdvisePending & ADVISE_POSITION)
        {
            m_pFilter->CallUpdateOverlay(NULL, &rcSource, NULL, &rcDest, dwFlags, pIOverlayNotify);
        }
        if (dwAdvisePending & ADVISE_CLIPPING)
        {
            ASSERT(pBuffer);
            //  Call back to our exclusive mode client if there is one
            m_pFilter->CallUpdateOverlay(NULL, &rcSource, NULL, &rcDest, dwFlags, pIOverlayNotify, pBuffer);
        }
    }
    if (dwAdvisePending & ADVISE_COLORKEY)
    {
        pIOverlayNotify->OnColorKeyChange(&ColorKey);
    }
    if (dwAdvisePending & ADVISE_PALETTE)
    {
        ASSERT(pPaletteEntries);
        pIOverlayNotify->OnPaletteChange(dwNumPaletteEntries, pPaletteEntries);
    }
    if (dwAdvisePending & ADVISE_DISPLAY_CHANGE)
    {
        reinterpret_cast<IOverlayNotify2*>(pIOverlayNotify)->OnDisplayChange(hMonitor);
    }


CleanUp:
    if (pBuffer)
    {
        CoTaskMemFree(pBuffer);
        pBuffer = NULL;
    }
    if (pPaletteEntries)
    {
        CoTaskMemFree(pPaletteEntries);
        pPaletteEntries = NULL;
    }
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::NotifyChange")));
    return hr;
}

STDMETHODIMP COMInputPin::GetWindowHandle(HWND *pHwnd)
{
    AMTRACE((TEXT("COMInputPin::GetWindowHandle")));

    HRESULT hr = NOERROR;
    if (pHwnd) {
        *pHwnd = m_pFilter->GetWindow();
    }
    else hr = E_POINTER;

    return hr;
}

STDMETHODIMP COMInputPin::GetClipList(RECT *pSourceRect, RECT *pDestinationRect, RGNDATA **ppRgnData)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetClipList")));

    if (!pSourceRect || !pDestinationRect || !ppRgnData)
    {
        DbgLog((LOG_ERROR, 1, TEXT("invalid argument, pSourceRect or pDestinationRect or ppRgnData = NULL")));
        hr =  E_POINTER;
        goto CleanUp;
    }

    {
        LPRGNDATA pBuffer = NULL;
        DWORD dwRetVal = 0, dwBuffSize = 0;

        CAutoLock cLock(m_pFilterLock);

        dwRetVal = GetRegionData(m_WinInfo.hClipRgn, 0, NULL);
        if (!dwRetVal)
        {
            hr = E_FAIL;
            goto CleanUp;
        }

        dwBuffSize = dwRetVal;
        pBuffer = (LPRGNDATA) CoTaskMemAlloc(dwBuffSize);
        ASSERT(pBuffer);

        dwRetVal = GetRegionData(m_WinInfo.hClipRgn, dwBuffSize, pBuffer);
        ASSERT(pBuffer->rdh.iType == RDH_RECTANGLES);

        *pSourceRect = m_WinInfo.SrcRect;
        *pDestinationRect = m_WinInfo.DestRect;
        *ppRgnData = pBuffer;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetClipList")));
    return hr;
}


// This returns the current source and destination video rectangles. Source
// rectangles can be updated through this IBasicVideo interface as can the
// destination. The destination rectangle we store is in window coordinates
// and is typically updated when the window is sized. We provide a callback
// OnPositionChanged that notifies the source when either of these changes
STDMETHODIMP COMInputPin::GetVideoPosition(RECT *pSourceRect, RECT *pDestinationRect)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetVideoPosition")));

    if (!pSourceRect || !pDestinationRect)
    {
        DbgLog((LOG_ERROR, 1, TEXT("invalid argument, pSourceRect or pDestinationRect = NULL")));
        hr =  E_POINTER;
        goto CleanUp;
    }

    {
        CAutoLock cLock(m_pFilterLock);
        *pSourceRect = m_WinInfo.SrcRect;
        *pDestinationRect = m_WinInfo.DestRect;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetVideoPosition")));
    return hr;
}


// When we create a new advise link we must prime the newly connected object
// with the overlay information which includes the clipping information, any
// palette information for the current connection and the video colour key
// When we are handed the IOverlayNotify interface we hold a reference count
// on that object so that it won't go away until the advise link is stopped
STDMETHODIMP COMInputPin::Advise(IOverlayNotify *pOverlayNotify,DWORD dwAdviseNotify)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::Advise")));

    {
        CAutoLock cLock(m_pFilterLock);

        if (!pOverlayNotify)
        {
            DbgLog((LOG_ERROR, 1, TEXT("invalid argument, pOverlayNotify = NULL")));
            hr =  E_POINTER;
            goto CleanUp;
        }

        // Is there an advise link already defined
        if (m_pIOverlayNotify)
        {
            DbgLog((LOG_ERROR, 1, TEXT("Advise link already set")));
            hr = VFW_E_ADVISE_ALREADY_SET;
            goto CleanUp;
        }

        // Check they want at least one kind of notification
        if ((dwAdviseNotify & ADVISE_ALL) == 0)
        {
            DbgLog((LOG_ERROR, 1, TEXT("ADVISE_ALL failed")));
            hr = E_INVALIDARG;
        }

        // Initialise our overlay notification state
        // if the advise bits contain ADVISE_DISPLAY_CHANGE, then make sure to
        // QI the sink for IOverlayNotify2
        if (dwAdviseNotify & ADVISE_DISPLAY_CHANGE)
        {
            hr = pOverlayNotify->QueryInterface(IID_IOverlayNotify2, reinterpret_cast<PVOID*>(&m_pIOverlayNotify));
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("pOverlayNotify->QueryInterface(IID_IOverlayNotify2) failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
        }
        else
        {
            m_pIOverlayNotify = pOverlayNotify;
            m_pIOverlayNotify->AddRef();
        }
        m_dwAdviseNotify = dwAdviseNotify;
    }

    NotifyChange(ADVISE_ALL);

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::Advise")));
    return hr;
}


// Close the advise link. Remove the associated link with the source, we release
// the interface pointer the filter gave us during the advise link creation.
STDMETHODIMP COMInputPin::Unadvise()
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::Unadvise")));

    CAutoLock cLock(m_pFilterLock);

    // Do we already have an advise link setup
    if (m_pIOverlayNotify == NULL)
    {
        hr = VFW_E_NO_ADVISE_SET;
        goto CleanUp;
    }

    // Release the notification interface
    ASSERT(m_pIOverlayNotify);
    m_pIOverlayNotify->Release();
    m_pIOverlayNotify = NULL;
    m_dwAdviseNotify = ADVISE_NONE;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::Unadvise")));
    return hr;
}


STDMETHODIMP COMInputPin::GetDefaultColorKey(COLORKEY *pColorKey)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetDefaultColorKey")));
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetDefaultColorKey")));
    return E_NOTIMPL;
}

STDMETHODIMP COMInputPin::GetPalette(DWORD *pdwColors,PALETTEENTRY **ppPalette)
{
    HRESULT hr = NOERROR;
    PALETTEENTRY *pPaletteEntries = NULL;
    DWORD dwNumPaletteEntries = 0;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::GetPalette")));

    if (!pdwColors || !ppPalette)
    {
        DbgLog((LOG_ERROR, 1, TEXT("invalid pointer, pdwColors or ppPalette == NULL")));
        hr = E_POINTER;
        goto CleanUp;
    }

    // get the palette entries from the filter
    hr = m_pFilter->GetPaletteEntries(&dwNumPaletteEntries, &pPaletteEntries);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pFilter->GetPaletteEntries, hr = 0x%x"), hr));
        hr = VFW_E_NO_PALETTE_AVAILABLE;
        goto CleanUp;
    }

    ASSERT(dwNumPaletteEntries);
    ASSERT(pPaletteEntries);

    *pdwColors = dwNumPaletteEntries;

    // Allocate the memory for the system palette NOTE because the memory for
    // the palette is being passed over an interface to another object which
    // may or may not have been written in C++ we must use CoTaskMemAlloc

    *ppPalette = (PALETTEENTRY *) QzTaskMemAlloc(*pdwColors * sizeof(RGBQUAD));
    if (*ppPalette == NULL)
    {
        DbgLog((LOG_ERROR, 1, TEXT("No memory")));
        *pdwColors = 0;
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }
    memcpy(*ppPalette, pPaletteEntries, (*pdwColors * sizeof(RGBQUAD)));

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::GetPalette")));
    return hr;
}

STDMETHODIMP COMInputPin::SetPalette(DWORD dwColors,PALETTEENTRY *pPaletteColors)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::SetPalette")));
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::SetPalette")));
    return E_NOTIMPL;
}


STDMETHODIMP COMInputPin::Set(REFGUID guidPropSet, DWORD dwPropID, LPVOID pInstanceData, DWORD cbInstanceData,
                              LPVOID pPropData, DWORD cbPropData)
{
    CAutoLock cLock(m_pFilterLock);

    if (AMPROPSETID_NotifyOwner == guidPropSet)
    {
        if (AMPROPERTY_OvMixerOwner != dwPropID)
            return E_PROP_ID_UNSUPPORTED ;

        m_OvMixerOwner = *(AMOVMIXEROWNER *)pPropData;
    }
    else if (AM_KSPROPSETID_CopyProt == guidPropSet)
    {
        if (0 != GetPinId()  ||                         // on first in pin and
            dwPropID != AM_PROPERTY_COPY_MACROVISION)   // Macrovision prop set id only
            return E_PROP_ID_UNSUPPORTED ;

        if (pPropData == NULL)
            return E_INVALIDARG ;

        if (cbPropData < sizeof(DWORD))
            return E_INVALIDARG ;

        // Apply the Macrovision bits ONLY IF Overlay Mixer is supposed to,
        // i.e, we are playing back DVD in DDraw exclusive mode. Otherwise
        // Video Renderer is supposed to set the MV bits (two sets can fail
        // causing no playback).
        // If MV setting fails, return error.
        if (m_pFilter->NeedCopyProtect())
        {
            DbgLog((LOG_TRACE, 5, TEXT("OverlayMixer needs to copy protect")));
            if (! m_pFilter->m_MacroVision.SetMacroVision(*((LPDWORD)pPropData)) )
                return VFW_E_COPYPROT_FAILED ;
        }
        else
        {
            DbgLog((LOG_TRACE, 5, TEXT("OverlayMixer DOES NOT need to copy protect")));
        }
    }
    else
            return E_PROP_SET_UNSUPPORTED ;

    return S_OK ;
}


STDMETHODIMP COMInputPin::Get(REFGUID guidPropSet, DWORD dwPropID, LPVOID pInstanceData, DWORD cbInstanceData,
                              LPVOID pPropData, DWORD cbPropData, DWORD *pcbReturned)
{
    CAutoLock cLock(m_pFilterLock);

    if (guidPropSet == AMPROPSETID_NotifyOwner)
    {
        if (dwPropID != AMPROPERTY_OvMixerOwner)
            return E_PROP_ID_UNSUPPORTED;

        if (pPropData == NULL)
            return E_POINTER;

        if (cbPropData < sizeof(AMOVMIXEROWNER))
            return E_UNEXPECTED;

        *(AMOVMIXEROWNER*)pPropData = m_OvMixerOwner;
        if (pcbReturned!=NULL)
            *pcbReturned = sizeof(AMOVMIXEROWNER);
        return S_OK;
    }

    if (guidPropSet != AMPROPSETID_Pin)
        return E_PROP_SET_UNSUPPORTED;

    if (dwPropID != AMPROPERTY_PIN_CATEGORY && dwPropID != AMPROPERTY_PIN_MEDIUM)
        return E_PROP_ID_UNSUPPORTED;

    if (pPropData == NULL && pcbReturned == NULL)
        return E_POINTER;

    if (pcbReturned)
        *pcbReturned = ((dwPropID == AMPROPERTY_PIN_CATEGORY) ? sizeof(GUID) : sizeof (KSPIN_MEDIUM));

    if (pPropData == NULL)
        return S_OK;

    if (cbPropData < sizeof(GUID))
        return E_UNEXPECTED;

    if (dwPropID == AMPROPERTY_PIN_CATEGORY)
    {
        *(GUID *)pPropData = m_CategoryGUID;
    }
    else if (dwPropID == AMPROPERTY_PIN_MEDIUM)
    {
        *(KSPIN_MEDIUM *)pPropData = m_Medium;
    }


    return S_OK;
}


STDMETHODIMP COMInputPin::QuerySupported(REFGUID guidPropSet, DWORD dwPropID, DWORD *pTypeSupport)
{
    CAutoLock cLock(m_pFilterLock);

    if (AMPROPSETID_Pin == guidPropSet)
    {
        if (AMPROPERTY_PIN_CATEGORY != dwPropID && AMPROPERTY_PIN_MEDIUM != dwPropID )
            return E_PROP_ID_UNSUPPORTED ;

        if (pTypeSupport)
                *pTypeSupport = KSPROPERTY_SUPPORT_GET ;
    }
    else if (AM_KSPROPSETID_CopyProt == guidPropSet)
    {
        if (0 != GetPinId()  ||                         // only first in pin...
            AM_PROPERTY_COPY_MACROVISION != dwPropID)   // only MV prop set id
            return E_PROP_ID_UNSUPPORTED ;

        if (pTypeSupport)
            *pTypeSupport = KSPROPERTY_SUPPORT_SET ;
    }
    else
        return E_PROP_SET_UNSUPPORTED ;

    return S_OK ;
}


STDMETHODIMP COMInputPin::KsQueryMediums(PKSMULTIPLE_ITEM* pMediumList)
{
    PKSPIN_MEDIUM pMedium;

    CAutoLock cLock(m_pFilterLock);

    *pMediumList = reinterpret_cast<PKSMULTIPLE_ITEM>(CoTaskMemAlloc(sizeof(**pMediumList) + sizeof(*pMedium)));
    if (!*pMediumList)
    {
        return E_OUTOFMEMORY;
    }
    (*pMediumList)->Count = 1;
    (*pMediumList)->Size = sizeof(**pMediumList) + sizeof(*pMedium);
    pMedium = reinterpret_cast<PKSPIN_MEDIUM>(*pMediumList + 1);
    pMedium->Set   = m_Medium.Set;
    pMedium->Id    = m_Medium.Id;
    pMedium->Flags = m_Medium.Flags;

    // The following special return code notifies the proxy that this pin is
    // not available as a kernel mode connection
    return S_FALSE;
}


STDMETHODIMP COMInputPin::KsQueryInterfaces(PKSMULTIPLE_ITEM* pInterfaceList)
{
    PKSPIN_INTERFACE    pInterface;

    CAutoLock cLock(m_pFilterLock);

    *pInterfaceList = reinterpret_cast<PKSMULTIPLE_ITEM>(CoTaskMemAlloc(sizeof(**pInterfaceList) + sizeof(*pInterface)));
    if (!*pInterfaceList)
    {
        return E_OUTOFMEMORY;
    }
    (*pInterfaceList)->Count = 1;
    (*pInterfaceList)->Size = sizeof(**pInterfaceList) + sizeof(*pInterface);
    pInterface = reinterpret_cast<PKSPIN_INTERFACE>(*pInterfaceList + 1);
    pInterface->Set = AM_INTERFACESETID_Standard;
    pInterface->Id = KSINTERFACE_STANDARD_STREAMING;
    pInterface->Flags = 0;
    return NOERROR;
}

STDMETHODIMP COMInputPin::KsGetCurrentCommunication(KSPIN_COMMUNICATION* pCommunication, KSPIN_INTERFACE* pInterface, KSPIN_MEDIUM* pMedium)
{
    HRESULT hr = NOERROR;

    CAutoLock cLock(m_pFilterLock);

    if (!m_bStreamingInKernelMode)
        hr = S_FALSE;

    if (pCommunication != NULL)
    {
        *pCommunication = m_Communication;
    }
    if (pInterface != NULL)
    {
        pInterface->Set = AM_INTERFACESETID_Standard;
        pInterface->Id = KSINTERFACE_STANDARD_STREAMING;
        pInterface->Flags = 0;
    }
    if (pMedium != NULL)
    {
        *pMedium = m_Medium;
    }
    return hr;
}

void COMInputPin::CheckOverlayHidden()
{
    if (m_bOverlayHidden)
    {
        m_bOverlayHidden = FALSE;
        // make sure that the video frame gets updated by redrawing everything
        EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
    }
}

/******************************Public*Routine******************************\
* DynamicQueryAccept
*
* Do you accept this type change in your current state?
*
* History:
* Wed 12/22/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMInputPin::DynamicQueryAccept(
    const AM_MEDIA_TYPE *pmt
    )
{
    AMTRACE((TEXT("COMInputPin::DynamicQueryAccept")));
    CheckPointer(pmt, E_POINTER);

    CAutoLock cLock(m_pFilterLock);

    //
    // I want CheckMedia type to behave as though we aren't connected to
    // anything yet - hence the messing about with m_bConnected.
    //
    CMediaType cmt(*pmt);
    BOOL bConnected = m_bConnected;
    m_bConnected = FALSE;
    HRESULT  hr = CheckMediaType(&cmt);
    m_bConnected = bConnected;

    return hr;
}

/******************************Public*Routine******************************\
* NotifyEndOfStream
*
*
* Set event when EndOfStream receive - do NOT pass it on
* This condition is cancelled by a flush or Stop
*
* History:
* Wed 12/22/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMInputPin::NotifyEndOfStream(
    HANDLE hNotifyEvent
    )
{
    AMTRACE((TEXT("COMInputPin::NotifyEndOfStream")));
    CAutoLock cLock(m_pFilterLock);
    m_hEndOfStream = hNotifyEvent;
    return S_OK;
}

/******************************Public*Routine******************************\
* IsEndPin
*
* Are you an 'end pin'
*
* History:
* Wed 12/22/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMInputPin::IsEndPin()
{
    AMTRACE((TEXT("COMInputPin::IsEndPin")));
    return S_OK;
}

/******************************Public*Routine******************************\
* DynamicDisconnect
*
* Disconnect while running
*
* History:
* Wed 2/7/1999 - SyonB - Created
*
\**************************************************************************/
STDMETHODIMP
COMInputPin::DynamicDisconnect()
{
    AMTRACE((TEXT("COMInputPin::DynamicDisconnect")));
    CAutoLock l(m_pLock);
    return CBaseInputPin::DisconnectInternal();
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmixer\omfilter.cpp ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;


// known problems:

#include <streams.h>
#include <ddraw.h>
#include <ddmm.h>
#include <mmsystem.h>   // Needed for definition of timeGetTime
#include <limits.h>     // Standard data type limit definitions
#include <ddmmi.h>
#include <dciddi.h>
#include <dvdmedia.h>
#include <amstream.h>

#include <ks.h>
#include <ksproxy.h>
#include <bpcwrap.h>
#include <dvp.h>
#include <ddkernel.h>
#include <vptype.h>
#include <vpconfig.h>
#include <vpnotify.h>
#include <vpobj.h>
#include <syncobj.h>
#include <mpconfig.h>
#include <ovmixpos.h>

#ifdef FILTER_DLL
#include <initguid.h>
#endif // FILTER_DLL
#include <macvis.h>   // for Macrovision support
#include <ovmixer.h>
#include <mixerocx_i.c>
#include <initguid.h>
#include <malloc.h>
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx


extern "C" const TCHAR szPropPage[];
extern "C" const TCHAR chRegistryKey[];
extern int GetRegistryDword(HKEY hk, const TCHAR *pKey, int iDefault);

DEFINE_GUID(IID_IDirectDraw4,
            0x9c59509a,0x39bd,0x11d1,0x8c,0x4a,0x00,0xc0,0x4f,0xd9,0x30,0xc5);

DEFINE_GUID(IID_IDDrawNonExclModeVideo,
            0xec70205c,0x45a3,0x4400,0xa3,0x65,0xc4,0x47,0x65,0x78,0x45,0xc7);

AMOVIESETUP_MEDIATYPE sudPinOutputTypes[] =
{
    {
        &MEDIATYPE_Video,           // Major type
        &MEDIASUBTYPE_Overlay       // Minor type
    }
};
AMOVIESETUP_MEDIATYPE sudPinInputTypes[] =
{
    {
        &MEDIATYPE_Video,           // Major type
        &MEDIASUBTYPE_NULL          // Minor type
    }
};

AMOVIESETUP_PIN psudPins[] =
{
    {
        L"Input",               // Pin's string name
        FALSE,                  // Is it rendered
        FALSE,                  // Is it an output
        FALSE,                  // Allowed none
        TRUE,                   // Allowed many
        &CLSID_NULL,            // Connects to filter
        L"Output",              // Connects to pin
        NUMELMS(sudPinInputTypes), // Number of types
        sudPinInputTypes        // Pin information
    },
    {
        L"Output",              // Pin's string name
        FALSE,                  // Is it rendered
        TRUE,                   // Is it an output
        FALSE,                  // Allowed none
        FALSE,                  // Allowed many
        &CLSID_NULL,            // Connects to filter
        L"Input",               // Connects to pin
        NUMELMS(sudPinOutputTypes), // Number of types
        sudPinOutputTypes      // Pin information
    }
};

const AMOVIESETUP_FILTER sudOverlayMixer =
{
    &CLSID_OverlayMixer,    // Filter CLSID
    L"Overlay Mixer",       // Filter name
    MERIT_DO_NOT_USE,       // Filter merit
    0,                      // Number pins
    NULL                    // Pin details
};
const AMOVIESETUP_FILTER sudOverlayMixer2 =
{
    &CLSID_OverlayMixer2,    // Filter CLSID
    L"Overlay Mixer2",       // Filter name
    MERIT_UNLIKELY,         // Filter merit
    NUMELMS(psudPins),      // Number pins
    psudPins                // Pin details
};

#if defined(DEBUG) && !defined(_WIN64)
int     iOVMixerDump;
HFILE   DbgFile = HFILE_ERROR;
BOOL    fDbgInitialized;
int     iOpenCount = 0;
int     iFPSLog;
#endif

#ifdef FILTER_DLL
// List of class IDs and creator functions for the class factory. This
// provides the link between the OLE entry point in the DLL and an object
// being created. The class factory will call the static CreateInstance
//
//  Property set defines for notifying owner.
//
// {7B390654-9F74-11d1-AA80-00C04FC31D60}
//#define DO_INIT_GUID
DEFINE_GUID(AMPROPSETID_NotifyOwner,
            0x7b390654, 0x9f74, 0x11d1, 0xaa, 0x80, 0x0, 0xc0, 0x4f, 0xc3, 0x1d, 0x60);
//#undef DO_INIT_GUID

CFactoryTemplate g_Templates[] =
{
    { L"Overlay Mixer", &CLSID_OverlayMixer, COMFilter::CreateInstance, NULL, &sudOverlayMixer },
    { L"Overlay Mixer2", &CLSID_OverlayMixer2, COMFilter::CreateInstance2, NULL, &sudOverlayMixer2 },
    { L"VideoPort Object", &CLSID_VPObject, CAMVideoPort::CreateInstance, NULL, NULL },
    { L"", &CLSID_COMQualityProperties,COMQualityProperties::CreateInstance},
    { L"", &CLSID_COMPinConfigProperties,COMPinConfigProperties::CreateInstance},
    { L"", &CLSID_COMPositionProperties,COMPositionProperties::CreateInstance},
    { L"", &CLSID_COMVPInfoProperties,COMVPInfoProperties::CreateInstance}

};
int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);

// DllRegisterSever
HRESULT DllRegisterServer()
{
    return AMovieDllRegisterServer2(TRUE);
} // DllRegisterServer


// DllUnregisterServer
HRESULT DllUnregisterServer()
{
    return AMovieDllRegisterServer2(FALSE);
} // DllUnregisterServer

#endif // FILTER_DLL

#if defined(DEBUG) && !defined(_WIN64)
void OpenDbgFile()
{
    OFSTRUCT ofs;
    char    szFileName[MAX_PATH];

    ofs.cBytes = sizeof(ofs);
    GetProfileStringA("OVMixer", "FileName",
                      "c:\\OVMixer.log", szFileName, MAX_PATH);

    DbgFile = OpenFile(szFileName, &ofs, OF_READWRITE);

    if (DbgFile == HFILE_ERROR && ERROR_FILE_NOT_FOUND == GetLastError()) {
        DbgFile = _lcreat(szFileName, 0);
    }

    if (DbgFile != HFILE_ERROR) {
        _llseek(DbgFile, 0, FILE_END);
        DbgLog((LOG_TRACE, 0, TEXT(" ********* New Log ********* \r\n")));
    }
}

void InitDebug(void)
{
    iFPSLog = GetProfileIntA("OVMixer", "FPS", 0);

    if (!fDbgInitialized) {
        iOVMixerDump = GetProfileIntA("OVMixer", "Debug", 0);
        if (iOVMixerDump) {
            OpenDbgFile();
        }
        fDbgInitialized = TRUE;
    }
    if (iOVMixerDump) {
        iOpenCount++;
    }
}

void TermDebug(void)
{
    if (iOVMixerDump) {
        iOpenCount--;
        if (iOpenCount == 0) {
            _lclose(DbgFile);
            iOVMixerDump = 0;
            fDbgInitialized = FALSE;
        }
    }
}
#endif

// CreateInstance
// This goes in the factory template table to create new filter instances
CUnknown *COMFilter::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
#if defined(DEBUG) && !defined(_WIN64)
    InitDebug();
#endif
    return new COMFilter(NAME("VideoPort Mixer"), pUnk, phr, false);
} // CreateInstance

// CreateInstance2
// This goes in the factory template table to create new filter instances
CUnknown *COMFilter::CreateInstance2(LPUNKNOWN pUnk, HRESULT *phr)
{
#if defined(DEBUG) && !defined(_WIN64)
    InitDebug();
#endif
    return new COMFilter(NAME("VideoPort Mixer"), pUnk, phr, true);
} // CreateInstance


#pragma warning(disable:4355)


// Constructor
COMFilter::COMFilter(TCHAR *pName, LPUNKNOWN pUnk, HRESULT *phr, bool bOnlyVideoInfo2)
: CBaseFilter(pName, pUnk, &this->m_csFilter, CLSID_OverlayMixer, phr),
  m_BPCWrap(this),
  m_pIMixerOCXNotify(NULL),
  m_bWinInfoStored(FALSE),
  m_hDC(NULL),
  m_bOnlySupportVideoInfo2(bOnlyVideoInfo2),
  m_bExternalDirectDraw(FALSE),
  m_bExternalPrimarySurface(FALSE),
  m_MacroVision(this),
  m_pExclModeCallback(NULL),
  m_bColorKeySet(FALSE),
  m_pPosition(NULL),
  m_bOverlayVisible(FALSE),
  m_bCopyProtect(TRUE),
  m_dwKernelCaps(0),
  m_dwPinConfigNext(0),
  m_bHaveCheckedMMatics(FALSE),
  m_bIsFaultyMMatics(FALSE),
  m_dwOverlayFX(0)
{
    SetRectEmpty(&m_rcOverlaySrc);
    SetRectEmpty(&m_rcOverlayDest);

    HRESULT hr = NOERROR;
    ASSERT(phr != NULL);

    m_dwInputPinCount = 0;
    m_pOutput = NULL;
    m_dwMaxPinId = 0;

    m_hDirectDraw = NULL;
    m_pDirectDraw = NULL;
    m_pUpdatedDirectDraw = NULL;
    m_pPrimarySurface = NULL;
    m_pUpdatedPrimarySurface = NULL;
    m_bNeedToRecreatePrimSurface = FALSE;
    m_fDisplayChangePosted = FALSE;
    m_UsingIDDrawNonExclModeVideo = FALSE;
    m_UsingIDDrawExclModeVideo = FALSE;

    memset(&m_WinInfo, 0, sizeof(WININFO));
    m_dwAdjustedVideoWidth = 0;
    m_dwAdjustedVideoHeight = 0;

    m_bWindowless = FALSE;
    m_bUseGDI = FALSE;

    // palette info
    m_dwNumPaletteEntries = 0;
    m_lpDDrawInfo = NULL;

    //
    // Initialize DDraw the MMon structures
    //
    m_dwDDObjReleaseMask = 0;
    m_pOldDDObj = NULL;
    m_MonitorChangeMsg = RegisterWindowMessage(TEXT("OVMMonitorChange"));
    hr = LoadDDrawLibrary(m_hDirectDraw, m_lpfnDDrawCreate,
                          m_lpfnDDrawEnum, m_lpfnDDrawEnumEx);
    if (FAILED(hr)) {
        goto CleanUp;
    }

    hr = GetDDrawGUIDs(&m_dwDDrawInfoArrayLen, &m_lpDDrawInfo);
    if (FAILED(hr)) {
        goto CleanUp;
    }

    AMDDRAWGUID guid;

    hr = GetDefaultDDrawGUID(&guid);
    if (FAILED(hr)) {
        goto CleanUp;
    }

    if (FAILED(SetDDrawGUID(&guid))) {
        ZeroMemory(&guid, sizeof(guid));
        hr = SetDDrawGUID(&guid);
        if (FAILED(hr)) {
            goto CleanUp;
        }
        else {
            SetDefaultDDrawGUID(&guid);
        }
    }

    m_fMonitorWarning = (m_lpCurrentMonitor->ddHWCaps.dwMaxVisibleOverlays < 1);

    SetDecimationUsage(DECIMATION_DEFAULT);

    ZeroMemory(&m_ColorKey, sizeof(COLORKEY));
    m_ColorKey.KeyType |= (CK_INDEX | CK_RGB);
    m_ColorKey.PaletteIndex = DEFAULT_DEST_COLOR_KEY_INDEX;
    m_ColorKey.HighColorValue = m_ColorKey.LowColorValue = DEFAULT_DEST_COLOR_KEY_RGB;

    // artifically increase the refcount since creation of the pins might
    // end up calling Release() on the filter
    m_cRef++;

    // create the pins
    hr = CreatePins();
    if (FAILED(hr)) {

CleanUp:
        //  Only update the return code if we failed.  That way we don't
        //  lose a failure from (say) CBaseFilter's constructor
        *phr = hr;
    }
    else {

        // restore the ref-count of the filter.
        m_cRef--;
    }
}

COMFilter::~COMFilter()
{
    //  No need to lock - only 1 thread has a pointer to us

    if (m_pIMixerOCXNotify)
    {
        m_pIMixerOCXNotify->Release();
        m_pIMixerOCXNotify = NULL;
    }

    //  Release exclusive mode callback
    if (m_pExclModeCallback) {
        m_pExclModeCallback->Release();
        m_pExclModeCallback = NULL;
    }

    //  Release passthru
    if (m_pPosition) {
        m_pPosition->Release();
    }

    // release the primary surface
    ReleasePrimarySurface();

    // release directdraw, primary surface etc.
    ReleaseDirectDraw();

    // release the DDraw guid info
    CoTaskMemFree(m_lpDDrawInfo);

    // delete the pins
    DeletePins();

    m_BPCWrap.TurnBPCOn();

    // Decrement module load count
    if (m_hDirectDraw)
    {
        DbgLog((LOG_TRACE, 1, TEXT("Unloading ddraw library")));
        FreeLibrary(m_hDirectDraw);
        m_hDirectDraw = NULL;
    }
#if defined(DEBUG) && !defined(_WIN64)
    TermDebug();
#endif
}

// Creates the pins for the filter. Override to use different pins
HRESULT COMFilter::CreatePins()
{
    HRESULT hr = NOERROR;
    const WCHAR wszPinName[] = L"Input00";

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::CreatePins")));

    // create one input pin at this point (with VP Support)
    hr = CreateInputPin(TRUE);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CreateInputPin failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // Allocate the output pin
    m_pOutput = new COMOutputPin(NAME("OverlayMixer output pin"), this, &m_csFilter, &hr, L"Output",  m_dwMaxPinId);
    if (m_pOutput == NULL || FAILED(hr))
    {
        if (SUCCEEDED(hr))
            hr = E_OUTOFMEMORY;
        DbgLog((LOG_ERROR, 1, TEXT("Unable to create the output pin, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // increament the pin id counter
    m_dwMaxPinId++;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::CreatePins")));
    return hr;
}

// COMFilter::DeletePins
void COMFilter::DeletePins()
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::DeletePins")));

    //  Only called from the destructor so no need to lock
    //  If some other thread is trying to lock us on our lock we're in
    //  trouble anyway since we're going away

    delete m_pOutput;
    m_pOutput = NULL;

    // note that since CreateInputPin addrefs the mem pins, we have
    // to release them here. The NonDelegatingQueryRelease will call
    // DeleteInputPin, which would delete the pin.
    for (DWORD i = 1; i < m_dwInputPinCount; i++)
    {
        // while addrefing the pin, the filter has to increment its own ref-count inorder to avoid
        //  a ref-count less than zero etc
        AddRef();
        m_apInput[i]->Release();
    }

    if (m_dwInputPinCount > 0 && NULL != m_apInput[0]) {
        // while addrefing the pin, the filter has to increment its own ref-count inorder to avoid
        //  a ref-count less than zero etc
        AddRef();
        m_apInput[0]->Release();
        delete m_apInput[0];
        m_apInput[0] = NULL;
        m_dwInputPinCount--;
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::DeletePins")));
}


// CreateInputPin
HRESULT COMFilter::CreateInputPin(BOOL bVPSupported)
{
    HRESULT hr = NOERROR;
    WCHAR wszPinName[20];
    COMInputPin *pPin;
    LPDIRECTDRAWSURFACE pPrimarySurface = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::CreateInputPin")));

    ASSERT(m_dwInputPinCount <= MAX_PIN_COUNT);
    // make sure we are not exceeding the limit
    if (m_dwInputPinCount == MAX_PIN_COUNT)
        return NOERROR;

    // if it is an external primary surface, do not create any more input pins
    if (!m_UsingIDDrawNonExclModeVideo && m_bExternalPrimarySurface && m_dwInputPinCount == 1)
    {
        DbgLog((LOG_TRACE, 2, TEXT("m_bExternalPrimarySurface is true, so exiting funtion,")));
        return NOERROR;
    }

    // if we are using GDI, do not create any more input pins
    if (m_bUseGDI && m_dwInputPinCount == 1)
    {
        DbgLog((LOG_TRACE, 2, TEXT("m_bUseGDI is true, so exiting funtion,")));
        return NOERROR;
    }

    CAutoLock l(&m_csFilter);


    // create the pin
    wsprintfW(wszPinName, L"Input%d", m_dwMaxPinId);
    pPin = new COMInputPin(NAME("OverlayMixer Input pin"), this, &m_csFilter, bVPSupported, &hr, wszPinName, m_dwMaxPinId);
    if (pPin == NULL || FAILED(hr))
    {
        if (SUCCEEDED(hr)) {
            hr = E_OUTOFMEMORY;
        } else {
            delete pPin;
        }
        goto CleanUp;
    }


    DbgLog((LOG_TRACE, 3, TEXT("Created Pin, No = %d"), m_dwInputPinCount));

    // while addrefing the pin, the filter has to decrement its own ref-count inorder to avoid a
    // circular ref-count
    pPin->AddRef();
    Release();

    m_apInput[m_dwInputPinCount] = pPin;
    m_dwInputPinCount++;
    m_dwMaxPinId++;
    IncrementPinVersion();

    // pins do not support VideoPort or IOverlay connection by default.
    // Also there default RenderTransport is AM_OFFSCREEN, and default
    // AspectRatioMode is AspectRatioMode is AM_ARMODE_STRETCHED
    // therefore in the non-GDI case only the first pins parmameters need to be modified
    if (m_bUseGDI)
    {
        m_apInput[m_dwInputPinCount-1]->SetRenderTransport(AM_GDI);
    }
    else if (m_dwInputPinCount == 1)
    {
	m_apInput[m_dwInputPinCount-1]->SetRenderTransport(AM_OVERLAY);
	m_apInput[m_dwInputPinCount-1]->SetIOverlaySupported(TRUE);
        m_apInput[m_dwInputPinCount-1]->SetVPSupported(TRUE);
        m_apInput[m_dwInputPinCount-1]->SetVideoAcceleratorSupported(TRUE);
        m_apInput[m_dwInputPinCount-1]->SetAspectRatioMode(AM_ARMODE_LETTER_BOX);
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::CreateInputPin")));
    return hr;
} // CreateInputPin

// DeleteInputPin
void COMFilter::DeleteInputPin(COMInputPin *pPin)
{
    DWORD iPinCount;
    BOOL bPinFound = FALSE;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::DeleteInputPin")));

    CAutoLock l(&m_csFilter);

    // we don't delete the first pin
    for (iPinCount = 1; iPinCount < m_dwInputPinCount; iPinCount++)
    {
        if (bPinFound) {
            m_apInput[iPinCount - 1] = m_apInput[iPinCount];
        } else {
            if (m_apInput[iPinCount] == (COMInputPin*)pPin)
            {
                delete pPin;
                bPinFound = TRUE;
            }
        }
    }

    ASSERT(bPinFound);
    m_dwInputPinCount--;
    IncrementPinVersion();

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::DeleteInputPin")));
    return;
} // DeleteInputPin


// NonDelegatingQueryInterface
STDMETHODIMP COMFilter::NonDelegatingQueryInterface(REFIID riid, void **ppv)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::NonDelegatingQueryInterface")));
    ValidateReadWritePtr(ppv,sizeof(PVOID));

    if (riid == IID_IAMOverlayMixerPosition)
    {
        return GetInterface((IAMOverlayMixerPosition *) this, ppv);
    }
    if (riid == IID_IAMOverlayMixerPosition2)
    {
        return GetInterface((IAMOverlayMixerPosition2 *) this, ppv);
    }
    else if (riid == IID_IMixerOCX)
    {
        return GetInterface((IMixerOCX *) this, ppv);
    }
    else if (riid == IID_IDDrawExclModeVideo) {
        if (m_UsingIDDrawNonExclModeVideo) {
            return E_NOINTERFACE;
        } else {
            m_UsingIDDrawExclModeVideo = true;
            return GetInterface(static_cast<IDDrawExclModeVideo *>(this), ppv);
        }
    }
    else if (riid == IID_IDDrawNonExclModeVideo) {
        if (m_UsingIDDrawExclModeVideo) {
            return E_NOINTERFACE;
        } else {
            m_UsingIDDrawNonExclModeVideo = true;
            return GetInterface(static_cast<IDDrawNonExclModeVideo *>(this), ppv);
        }
    }
    else if (riid == IID_IAMVideoDecimationProperties)
    {
        return GetInterface((IAMVideoDecimationProperties *) this, ppv);
    }
    else if (riid == IID_IMediaPosition || riid == IID_IMediaSeeking)
    {
        // we should have an input pin by now
        ASSERT(m_apInput[0] != NULL);
        if (m_pPosition == NULL)
        {
            HRESULT hr = CreatePosPassThru(GetOwner(), FALSE, m_apInput[0], &m_pPosition);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("CreatePosPassThru failed, hr = 0x%x"), hr));
                return hr;
            }
        }
        return m_pPosition->QueryInterface(riid, ppv);
    }

    else if (riid == IID_ISpecifyPropertyPages && 0 != GetRegistryDword(HKEY_CURRENT_USER , szPropPage, 0))
    {
        return GetInterface((ISpecifyPropertyPages *)this, ppv);
    }
    else if (riid == IID_IQualProp) {
        return GetInterface((IQualProp *)this, ppv);
    }
    else if (riid == IID_IEnumPinConfig) {
        return GetInterface((IEnumPinConfig *)this, ppv);
    }
    else if (riid == IID_IAMOverlayFX) {
        return GetInterface((IAMOverlayFX *)this, ppv);
    }
    else if (riid == IID_IAMSpecifyDDrawConnectionDevice) {
        return GetInterface((IAMSpecifyDDrawConnectionDevice *)this, ppv);
    }
    else if (riid == IID_IKsPropertySet) {
        return GetInterface((IKsPropertySet *)this, ppv);
    }

    CAutoLock l(&m_csFilter);

    //
    if (riid == IID_IVPNotify || riid == IID_IVPNotify2 ||
        riid == IID_IVPInfo)

    {
        return m_apInput[0]->NonDelegatingQueryInterface(riid, ppv);
    }

    return CBaseFilter::NonDelegatingQueryInterface(riid, ppv);
}


// --- ISpecifyPropertyPages ---

STDMETHODIMP COMFilter::GetPages(CAUUID *pPages)
{
#if defined(DEBUG)
    pPages->cElems = 4+m_dwInputPinCount;
    pPages->pElems = (GUID *) CoTaskMemAlloc(sizeof(GUID)*(4+m_dwInputPinCount));
    if (pPages->pElems == NULL) {
        return E_OUTOFMEMORY;
    }

#define COM_QUAL
#ifdef COM_QUAL
    pPages->pElems[0]   = CLSID_COMQualityProperties;
#else
    pPages->pElems[0]   = CLSID_QualityProperties;
#endif

    pPages->pElems[1] = CLSID_COMPositionProperties;
    pPages->pElems[2] = CLSID_COMVPInfoProperties;
    pPages->pElems[3] = CLSID_COMDecimationProperties;

    // Add PinConfig page for all input pins first
    for (unsigned int i=0; i<m_dwInputPinCount; i++)
    {
        pPages->pElems[4+i] = CLSID_COMPinConfigProperties;
    }
#else
    pPages->cElems = 3+m_dwInputPinCount;
    pPages->pElems = (GUID *) CoTaskMemAlloc(sizeof(GUID)*(3+m_dwInputPinCount));
    if (pPages->pElems == NULL) {
        return E_OUTOFMEMORY;
    }

#define COM_QUAL
#ifdef COM_QUAL
    pPages->pElems[0]   = CLSID_COMQualityProperties;
#else
    pPages->pElems[0]   = CLSID_QualityProperties;
#endif

    pPages->pElems[1] = CLSID_COMPositionProperties;
    pPages->pElems[2] = CLSID_COMVPInfoProperties;

    // Add PinConfig page for all input pins first
    for (unsigned int i=0; i<m_dwInputPinCount; i++)
    {
        pPages->pElems[3+i] = CLSID_COMPinConfigProperties;
    }

#endif
    return NOERROR;
}

// IEnumPinConfig support

STDMETHODIMP COMFilter::Next(IMixerPinConfig3 **pPinConfig)
{
    HRESULT hr = m_apInput[m_dwPinConfigNext]->QueryInterface(IID_IMixerPinConfig3,
        (void **) pPinConfig);
    m_dwPinConfigNext++;
    m_dwPinConfigNext = m_dwPinConfigNext%m_dwInputPinCount;
    return hr;
}

// IQualProp property page support

STDMETHODIMP COMFilter::get_FramesDroppedInRenderer(int *cFramesDropped)
{
    COMInputPin *pPin = m_apInput[0];
    if (pPin && pPin->m_pSyncObj)
        return pPin->m_pSyncObj->get_FramesDroppedInRenderer(cFramesDropped);
    return S_FALSE;
}

STDMETHODIMP COMFilter::get_FramesDrawn(int *pcFramesDrawn)
{
    COMInputPin *pPin = m_apInput[0];
    if (pPin && pPin->m_pSyncObj)
        return pPin->m_pSyncObj->get_FramesDrawn(pcFramesDrawn);
    return S_FALSE;
}

STDMETHODIMP COMFilter::get_AvgFrameRate(int *piAvgFrameRate)
{
    COMInputPin *pPin = m_apInput[0];
    if (pPin && pPin->m_pSyncObj)
        return pPin->m_pSyncObj->get_AvgFrameRate(piAvgFrameRate);
    return S_FALSE;
}

STDMETHODIMP COMFilter::get_Jitter(int *piJitter)
{
    COMInputPin *pPin = m_apInput[0];
    if (pPin && pPin->m_pSyncObj)
        return pPin->m_pSyncObj->get_Jitter(piJitter);
    return S_FALSE;
}

STDMETHODIMP COMFilter::get_AvgSyncOffset(int *piAvg)
{
    COMInputPin *pPin = m_apInput[0];
    if (pPin && pPin->m_pSyncObj)
        return pPin->m_pSyncObj->get_AvgSyncOffset(piAvg);
    return S_FALSE;
}

STDMETHODIMP COMFilter::get_DevSyncOffset(int *piDev)
{
    COMInputPin *pPin = m_apInput[0];
    if (pPin && pPin->m_pSyncObj)
        return pPin->m_pSyncObj->get_DevSyncOffset(piDev);
    return S_FALSE;
}

int COMFilter::GetPinCount()
{
    if (m_pOutput)
        return m_dwInputPinCount + 1;
    else
        return m_dwInputPinCount;
}

// returns a non-addrefed CBasePin *
CBasePin* COMFilter::GetPin(int n)
{
    CBasePin *pRetPin = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetPin")));

    CAutoLock l(&m_csFilter);

    // check that the pin requested is within range
    if (n > (int)m_dwInputPinCount)
    {
        DbgLog((LOG_TRACE, 5, TEXT("Bad Pin Requested, n = %d, No. of Pins = %d"),
            n, m_dwInputPinCount+1));
        pRetPin = NULL;
        goto CleanUp;
    }

    // return the output pin
    if (n == (int)m_dwInputPinCount)
    {
        // if there is no output pin, we will return NULL which is the right
        // thing to do
        pRetPin = m_pOutput;
        goto CleanUp;
    }

    // return an input pin
    pRetPin = m_apInput[n];
    goto CleanUp;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetPin")));
    return pRetPin;
}


// the base classes inform the pins of every state transition except from
// run to pause. Overriding Pause to inform the input pins about that transition also
STDMETHODIMP COMFilter::Pause()
{
    HRESULT hr = NOERROR;
    DWORD i;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::Pause")));

    CAutoLock l(&m_csFilter);

    if (m_State == State_Paused)
    {
        return m_apInput[0]->CompleteStateChange(State_Paused);
    }

    if (m_apInput[0]->IsConnected() == FALSE)
    {
        m_State = State_Paused;
        return m_apInput[0]->CompleteStateChange(State_Paused);
    }

    if (m_State == State_Running)
    {
        // set the pointer to DirectDraw and the PrimarySurface on All the Input Pins
        for (i = 0; i < m_dwInputPinCount; i++)
        {
            hr = m_apInput[i]->RunToPause();
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("m_apInput[i]->RunToPause failed, i = %d, hr = 0x%x"),
                    i, hr));
                goto CleanUp;
            }
        }
    }

CleanUp:
    hr = CBaseFilter::Pause();
    if (FAILED(hr))
    {
        return hr;
    }


    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::Pause")));
    return m_apInput[0]->CompleteStateChange(State_Paused);
}


// Overridden the base class Stop() method just to stop MV.
STDMETHODIMP COMFilter::Stop()
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::Stop")));

    CAutoLock l(&m_csFilter) ;

    HRESULT  hr = NOERROR ;

#if 0  // OvMixer resets MV bit ONLY in the destructor
    //
    // Release the copy protection key now
    //
    if (! m_MacroVision.StopMacroVision() )
    {
        DbgLog((LOG_ERROR, 1, TEXT("WARNING: Stopping copy protection failed"))) ;
        // hr = E_UNEXPECTED ;
    }
#endif // #if 0

    hr = CBaseFilter::Stop() ;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::Stop")));

    return hr ;
}


HRESULT COMFilter::RecreatePrimarySurface(LPDIRECTDRAWSURFACE pDDrawSurface)
{
    HRESULT hr = NOERROR;
    LPDIRECTDRAW pDirectDraw = NULL;
    LPDIRECTDRAWSURFACE pPrimarySurface = NULL;
    LPDIRECTDRAWSURFACE3 pPrimarySurface3 = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::RecreatePrimarySurface")));

    // addref the new primary surface provided
    if (pDDrawSurface)
    {
        pDDrawSurface->AddRef() ;
    }
    else if (m_UsingIDDrawNonExclModeVideo) {
        pDDrawSurface = m_pUpdatedPrimarySurface;
        m_pUpdatedPrimarySurface = NULL;
    }

    // release the primary surface
    ReleasePrimarySurface();

    // if given a valid ddraw surface, make a copy of it (we have already addref'd it)
    // else allocate your own
    if (pDDrawSurface)
    {
        m_pPrimarySurface = pDDrawSurface;
    }
    else
    {
        // create a new primary surface
        hr = CreatePrimarySurface();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("CreatePrimarySurface() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // attach a window clipper
        if (m_pOutput && m_pOutput->IsConnected())
        {
            hr = m_pOutput->AttachWindowClipper();
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("m_pOutput->AttachWindowClipper() failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
        }
    }


    // Try for the IDirectDrawSurface3 interface. If it works, we're on DX5 at least
    hr = m_pPrimarySurface->QueryInterface(IID_IDirectDrawSurface3, (void**)&pPrimarySurface3);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDraw->CreateSurface failed, hr = 0x%x"), hr));
        hr = VFW_E_DDRAW_VERSION_NOT_SUITABLE;
        goto CleanUp;
    }

    // get the ddraw object this primary surface has been made of
    hr = pPrimarySurface3->GetDDInterface((void**)&pDirectDraw);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pPrimarySurface3->GetDDInterface failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // make sure this primary surface has been created by the same ddraw object that we have
    if (!m_pDirectDraw || !pDirectDraw || !(IsEqualObject(m_pDirectDraw, pDirectDraw)))
    {
        hr = E_FAIL;
        DbgLog((LOG_ERROR, 1, TEXT("pDirectDraw != m_pDirectDraw, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (m_DirectCaps.dwCaps & DDCAPS_OVERLAY)
    {
        BOOL bColorKeySet = m_bColorKeySet;
        hr = SetColorKey(&m_ColorKey);
        m_bColorKeySet = bColorKeySet;
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("SetColorKey() failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

    // by this point we should have a valid primary surface

CleanUp:
    // if anything fails, might as well as release everything
    if (FAILED(hr))
    {
        // release the primary surface
        ReleasePrimarySurface();
    }

    if (pPrimarySurface3)
    {
        pPrimarySurface3->Release();
        pPrimarySurface3 = NULL;
    }

    if (pDirectDraw)
    {
        pDirectDraw->Release();
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::RecreatePrimarySurface")));
    return hr;
}

int COMFilter::GetPinPosFromId(DWORD dwPinId)
{
    int iPinPos = -1;

    for (int i = 0; i < (int)m_dwInputPinCount; i++)
    {
        if (m_apInput[i]->GetPinId() == dwPinId)
        {
            iPinPos = i;
            break;
        }
    }

    if (m_pOutput && (m_pOutput->GetPinId() == dwPinId))
    {
        iPinPos = MAX_PIN_COUNT;
    }

    return iPinPos;
}

HRESULT COMFilter::CompleteConnect(DWORD dwPinId)
{
    HRESULT hr = NOERROR;
    int iPinPos = -1;
    CMediaType inPinMediaType, outPinMediaType;

    IPin *pPeerOutputPin = NULL;

    BOOL bNeededReconnection = FALSE;
    DWORD dwNewWidth = 0, dwNewHeight = 0, dwPictAspectRatioX = 0, dwPictAspectRatioY = 0;
    DRECT rdDim;
    RECT rDim;
    BITMAPINFOHEADER *pHeader = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::CompleteConnect")));

    CAutoLock l(&m_csFilter);

    iPinPos = GetPinPosFromId(dwPinId);
    ASSERT(iPinPos >= 0 && iPinPos <= MAX_PIN_COUNT);

    // we may need to recreate the primary surface here if this complete-connect
    // is a result of a reconnect due to a wm_displaychange
    if (iPinPos == 0 && m_bNeedToRecreatePrimSurface && !m_bUseGDI && m_pOutput && m_pOutput->IsConnected())
    {
        hr = RecreatePrimarySurface(NULL);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,1,TEXT("RecreatePrimarySurface failed, hr = 0x%x"), hr));
            hr = NOERROR;
        }
        m_bNeedToRecreatePrimSurface = FALSE;
    }


    if (iPinPos == 0)
    {
        // find the input pin connection mediatype
        hr = m_apInput[0]->CurrentAdjustedMediaType(&inPinMediaType);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,TEXT("CurrentAdjustedMediaType failed")));
            goto CleanUp;
        }

        pHeader = GetbmiHeader(&inPinMediaType);
        if (!pHeader)
        {
            hr = E_FAIL;
            goto CleanUp;
        }

        hr = ::GetPictAspectRatio(&inPinMediaType, &dwPictAspectRatioX, &dwPictAspectRatioY);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("GetPictAspectRatio failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
        ASSERT(dwPictAspectRatioX > 0);
        ASSERT(dwPictAspectRatioY > 0);

        // get the image dimensions and store them in the mediasample
        SetRect(&rdDim, 0, 0, abs(pHeader->biWidth), abs(pHeader->biHeight));
        TransformRect(&rdDim, ((double)dwPictAspectRatioX/(double)dwPictAspectRatioY), AM_STRETCH);
        rDim = MakeRect(rdDim);

        m_dwAdjustedVideoWidth = WIDTH(&rDim);
        m_dwAdjustedVideoHeight = HEIGHT(&rDim);

        SetRect(&m_WinInfo.SrcRect, 0, 0, m_dwAdjustedVideoWidth, m_dwAdjustedVideoHeight);
    }

    // reconnect the output pin based on the mediatype of the input pin
    if ((iPinPos == MAX_PIN_COUNT && m_apInput[0]->IsConnected()) ||
        (iPinPos == 0 && m_pOutput && m_pOutput->IsConnected()))
    {
        // find the renderer's pin
        pPeerOutputPin = m_pOutput->GetConnected();
        if (pPeerOutputPin == NULL)
        {
            DbgLog((LOG_ERROR,0,TEXT("ConnectedTo failed")));
            goto CleanUp;
        }
        ASSERT(pPeerOutputPin);

        // find the output pin connection mediatype
        hr = m_pOutput->ConnectionMediaType(&outPinMediaType);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,TEXT("ConnectionMediaType failed")));
            goto CleanUp;
        }

        pHeader = GetbmiHeader(&outPinMediaType);
        if (!pHeader)
        {
            hr = E_FAIL;
            goto CleanUp;
        }

        // compare the new values with the current ones.
        // See if we need to reconnect at all
        if (pHeader->biWidth != (LONG)m_dwAdjustedVideoWidth ||
            pHeader->biHeight != (LONG)m_dwAdjustedVideoHeight)
        {
            bNeededReconnection = TRUE;
        }

        // If we don't need reconnection, bail out
        if (bNeededReconnection)
        {

            // Ok we do need reconnection, set the right values
            pHeader->biWidth = m_dwAdjustedVideoWidth;
            pHeader->biHeight = m_dwAdjustedVideoHeight;
            if (outPinMediaType.formattype == FORMAT_VideoInfo)
            {
                SetRect(&(((VIDEOINFOHEADER*)(outPinMediaType.pbFormat))->rcSource), 0, 0, m_dwAdjustedVideoWidth, m_dwAdjustedVideoHeight);
                SetRect(&(((VIDEOINFOHEADER*)(outPinMediaType.pbFormat))->rcTarget), 0, 0, m_dwAdjustedVideoWidth, m_dwAdjustedVideoHeight);
            }
            else if (outPinMediaType.formattype == FORMAT_VideoInfo2)
            {
                SetRect(&(((VIDEOINFOHEADER2*)(outPinMediaType.pbFormat))->rcSource), 0, 0, m_dwAdjustedVideoWidth, m_dwAdjustedVideoHeight);
                SetRect(&(((VIDEOINFOHEADER2*)(outPinMediaType.pbFormat))->rcTarget), 0, 0, m_dwAdjustedVideoWidth, m_dwAdjustedVideoHeight);
            }


            // Query the upstream filter asking if it will accept the new media type.
            hr = pPeerOutputPin->QueryAccept(&outPinMediaType);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,0,TEXT("m_pVPDraw->QueryAccept failed")));
                goto CleanUp;
            }

            // Reconnect using the new media type.
            hr = ReconnectPin(pPeerOutputPin, &outPinMediaType);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,0,TEXT("m_pVPDraw->Reconnect failed")));
                goto CleanUp;
            }
        }
    }

CleanUp:

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::CompleteConnect")));
    hr = NOERROR;
    return hr;
}

HRESULT COMFilter::BreakConnect(DWORD dwPinId)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::BreakConnect")));

    CAutoLock l(&m_csFilter);

    if (dwPinId == 0) {
        m_bColorKeySet = FALSE;
    }

    int iPinPos = GetPinPosFromId(dwPinId);
    ASSERT(iPinPos >= 0 && iPinPos <= MAX_PIN_COUNT);

    hr = CanExclusiveMode();
    if (FAILED(hr))
    {
        DbgLog((LOG_TRACE, 5, TEXT("CanExclusiveMode failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // if atleast one pin is connected, we are not going to do anything
    hr = ConfirmPreConnectionState(dwPinId);
    if (FAILED(hr))
    {

        DbgLog((LOG_TRACE, 3, TEXT("filter not in preconnection state, hr = 0x%x"), hr));
        goto CleanUp;
    }


CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::BreakConnect")));
    return NOERROR;
}

HRESULT COMFilter::SetMediaType(DWORD dwPinId, const CMediaType *pmt)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::SetMediaType")));

    CAutoLock l(&m_csFilter);

    // make sure that the filter has created a direct-draw object and primary surface
    // successfully
    if (!m_bUseGDI)
    {
        LPDIRECTDRAW pDirectDraw = NULL;
        LPDIRECTDRAWSURFACE pPrimarySurface = NULL;

        pDirectDraw = GetDirectDraw();
        if (pDirectDraw) {
            pPrimarySurface = GetPrimarySurface();
        }

        if (!pDirectDraw || !pPrimarySurface)
        {
            DbgLog((LOG_ERROR, 1, TEXT("pDirectDraw = 0x%x, pPrimarySurface = 0x%x"), pDirectDraw, pPrimarySurface));
            hr = E_FAIL;
            goto CleanUp;
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::SetMediaType")));
    return hr;
}

// gets events notifications from pins
HRESULT COMFilter::EventNotify(DWORD dwPinId, long lEventCode, long lEventParam1, long lEventParam2)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMInputPin::EventNotify")));

    CAutoLock l(&m_csFilter);

    if (lEventCode == EC_COMPLETE)
    {
        if (m_pOutput)
        {
            IPin *pRendererPin = m_pOutput->CurrentPeer();

            //  Output pin may not be connected (for instance
            //  RenegotiateVPParameters can fail while connecting
            if (pRendererPin) {
                pRendererPin->EndOfStream();
            }
        }
        else
        {
            NotifyEvent(EC_COMPLETE,S_OK,0);
        }
    }
    else if (lEventCode == EC_OVMIXER_REDRAW_ALL)
    {
        if (!m_bWindowless)
        {
            // redraw all
            hr = OnDrawAll();
        }
        else
        {
            if (m_pIMixerOCXNotify)
                m_pIMixerOCXNotify->OnInvalidateRect(NULL);
        }
    }
    else
    {
        NotifyEvent(lEventCode, lEventParam1, lEventParam2);
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::EventNotify")));
    return hr;
}

HRESULT COMFilter::OnDisplayChangeBackEnd()
{
    AMTRACE((TEXT("COMFilter::OnDisplayChangeBackEnd")));

    HRESULT hr = NOERROR;
    IPin **ppPin = NULL;
    DWORD i;

    m_Display.RefreshDisplayType(m_lpCurrentMonitor->szDevice);
    m_fMonitorWarning = (m_lpCurrentMonitor->ddHWCaps.dwMaxVisibleOverlays < 1);

    // this ensures that the primary surface will be recreated on the next complete-connect
    // of the first input pin. This will ensure that the overlay surface (if any) is released
    // by then.
    m_bNeedToRecreatePrimSurface = TRUE;

    // The Overlay Mixer can have at most MAX_PIN_COUNT input pins.
    ASSERT(MAX_PIN_COUNT == NUMELMS(m_apInput));
    IPin* apPinLocal[MAX_PIN_COUNT];

    DWORD dwPinCount;
    ULONG AllocSize = sizeof(IPin*) * m_dwInputPinCount;
    ppPin = (IPin**)CoTaskMemAlloc(AllocSize);
    if (ppPin) {
        ZeroMemory(ppPin, AllocSize);

        // now tell each input pin to reconnect
        for (dwPinCount = 0, i = 0; i < m_dwInputPinCount; i++)
        {
            // notify each pin about the change
            hr = m_apInput[i]->OnDisplayChange();
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 1, TEXT("m_apInput[%d]->OnDisplayChange() failed"), i));
                continue;
            }

            // get IPin interface
            if (hr == S_OK) {
                hr = m_apInput[i]->QueryInterface(IID_IPin, (void**)&ppPin[dwPinCount]);
                ASSERT(SUCCEEDED(hr));
                ASSERT(ppPin[dwPinCount]);

                apPinLocal[dwPinCount] = ppPin[dwPinCount];

                dwPinCount++;
            }

            m_dwDDObjReleaseMask |= (1 << m_apInput[i]->m_dwPinId);
        }


        m_pOldDDObj = m_pDirectDraw;
        if (m_pOldDDObj)
            m_pOldDDObj->AddRef();
        ReleasePrimarySurface();
        ReleaseDirectDraw();

        //
        // Pass our input pin array as parameter on the event, we don't free
        // the allocated memory - this is done by the event processing
        // code in the Filter Graph.  ppPin cannot be accessed after it is passed
        // to the Filter Graph because the Filter Graph can release ppPin's 
        // memory at any time.
        //
        if (dwPinCount > 0) {
            NotifyEvent(EC_DISPLAY_CHANGED, (LONG_PTR)ppPin, (LONG_PTR)dwPinCount);
        }

        // Release the IPin interfaces
        for (i = 0; i < dwPinCount; i++) {
           apPinLocal[i]->Release();
        }
    }
    else hr = E_OUTOFMEMORY;

    return hr;
}

HRESULT COMFilter::OnDisplayChange(BOOL fRealDisplayChange)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::OnDisplayChange")));

    CAutoLock l(&m_csFilter);

    //
    // If we are being called as the result of a real display change
    // rather than the user moving the window onto another monitor
    // we need to refresh the array of DDraw device info.
    //
    if (fRealDisplayChange) {
        CoTaskMemFree(m_lpDDrawInfo);
        hr = GetDDrawGUIDs(&m_dwDDrawInfoArrayLen, &m_lpDDrawInfo);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 1, TEXT("Failed to enumerate DDraw devices")));
            return hr;
        }
    }
    m_fDisplayChangePosted = FALSE; // ok again


    //
    // Now we are just moving monitors check that the monitor that we are
    // moving to actually has an overlay that we can use.
    //
    if (!fRealDisplayChange) {

        HMONITOR hMon = DeviceFromWindow(GetWindow(), NULL, NULL);

        //
        // Are we actually moving monitors ?
        //

        if (hMon == m_lpCurrentMonitor->hMon) {
            return S_OK;
        }

        AMDDRAWMONITORINFO* p = m_lpDDrawInfo;
        for (; p < &m_lpDDrawInfo[m_dwDDrawInfoArrayLen]; p++) {
            if (hMon == p->hMon) {
                if (p->ddHWCaps.dwMaxVisibleOverlays < 1) {
                    m_fMonitorWarning = TRUE;
                    return S_OK;
                }
                break;
            }
        }
    }

    // reset which monitor we think we're on.  This may have changed
    // and initialze to use the new monitor
    GetCurrentMonitor();

    // let the common back end do the real work

    hr = OnDisplayChangeBackEnd();

    if (!fRealDisplayChange && SUCCEEDED(hr))
        PostMessage(GetWindow(), WM_SHOWWINDOW, TRUE, 0);

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMInputPin::OnDisplayChange")));
    return hr;
}

HRESULT COMFilter::OnTimer()
{
    HRESULT hr = NOERROR;
    DWORD i = 0;

    CAutoLock l(&m_csFilter);

    //  REVIEW - why would we get here and m_bUseGDI be TRUE?
    if (m_bUseGDI)
    {
        goto CleanUp;
    }

    if (!m_pPrimarySurface)
    {
        if (m_pDirectDraw)
        {
            hr = RecreatePrimarySurface(NULL);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,2,TEXT("In Ontimer, RecreatePrimarySurface failed, hr = 0x%x"), hr));
                goto CleanUp;
            }
            else
            {
                DbgLog((LOG_TRACE, 2, TEXT("In Ontimer, RecreatePrimarySurface succeeded")));
            }
        }
        else goto CleanUp;
    }
    else
    {
        ASSERT(m_pPrimarySurface);
        if (m_pPrimarySurface->IsLost() != DDERR_SURFACELOST)
        {
            goto CleanUp;
        }

        if (m_pDirectDraw) {
            LPDIRECTDRAW4 pDD4;
            if (S_OK == m_pDirectDraw->QueryInterface(IID_IDirectDraw4, (LPVOID *)&pDD4)) {
                pDD4->RestoreAllSurfaces();
                pDD4->Release();
            }
        }

        hr = m_pPrimarySurface->Restore();
        if (FAILED(hr))
            goto CleanUp;
    }

    for (i = 0; i < m_dwInputPinCount; i++)
    {
        hr = m_apInput[i]->RestoreDDrawSurface();
        if (FAILED(hr))
        {
            goto CleanUp;
        }
    }

    EventNotify(GetPinCount(), EC_NEED_RESTART, 0, 0);
    EventNotify(GetPinCount(), EC_OVMIXER_REDRAW_ALL, 0, 0);

CleanUp:

    return hr;
}

STDMETHODIMP COMFilter::GetState(DWORD dwMSecs,FILTER_STATE *pState)
{
    HRESULT hr = NOERROR;

    CAutoLock l(&m_csFilter);

    hr = m_apInput[0]->GetState(dwMSecs, pState);
    if (hr == E_NOTIMPL)
    {
        hr = CBaseFilter::GetState(dwMSecs, pState);
    }
    return hr;
}





// this function can be used to provide a ddraw object to the filter. A null argument
// to the filter forces it to allocate its own.
STDMETHODIMP COMFilter::SetDDrawObject(LPDIRECTDRAW pDDObject)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::SetDDrawObject(0x%lx)"), pDDObject));

    hr = CanExclusiveMode();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CanExclusiveMode failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // if atleast one pin is connected, just cache the ddraw object given
    hr = ConfirmPreConnectionState();
    if (FAILED(hr))
    {
        DbgLog((LOG_TRACE, 1, TEXT("filter not in preconnection state, hr = 0x%x"), hr));

#if 0   //
        // This is disabled because of a bug hit by the OvMixer test app that
        // sets the DDraw object and surface and then tries to reconnect the
        // pins to get those DDraw params to be used.
        // There are also a couple of asserts hit in the base classes due to the
        // way the output pin is deleted etc.
        //
        // The bug is in how InitDirectDraw() releases and resets m_pPrimarySurface
        // as well as m_pUpdatedPrimarySurface.  This causes OvMixer to use the
        // app-specified DDraw object but its own DDraw surface.  The fix for this
        // would be to not try to synch up these two interfaces in BreakConnect()
        // etc (that will also help in finding if the DDraw params are external
        // rather than using a BOOL as is done now).
        //

        // addref the new one
        if (pDDObject)
        {
            pDDObject->AddRef();
        }

        // release the old m_pUpdatedDirectDraw
        if (m_pUpdatedDirectDraw)
        {
            m_pUpdatedDirectDraw->Release();
        }

        m_pUpdatedDirectDraw = pDDObject;

        hr = NOERROR;
#endif // #if 0

        goto CleanUp;
    }

    // either addref the given ddraw object or allocate our own
    // if anything fails, InitDirectDraw does the cleanup, so that our state is consistent
    hr = InitDirectDraw(pDDObject);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("InitDirectDraw failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::SetDDrawObject")));
    return hr;
}


/******************************Public*Routine******************************\
* ChangeMonitor
*
* Allows an application to tell the OVMixer that it would like to change
* to displaying the video on a new monitor.  The OVMixer will only change
* to the new monitor if the monitor has the necessary hw available upon it.
*
* If we are connected thru VPE or IOveraly, then monitor changes are not
* possible.  If the new DDraw device does not support overlays then again
* we can not change monitors.
*
*
* History:
* Wed 11/17/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::ChangeMonitor(
    HMONITOR hMon,
    LPDIRECTDRAW pDDrawObject,
    LPDIRECTDRAWSURFACE pDDrawSurface
    )
{
    AMTRACE((TEXT("COMFilter::ChangeMonitor")));
    CAutoLock l(&m_csFilter);

    //
    // Validate the DDraw parameters
    //

    if (!(pDDrawObject && pDDrawSurface))
    {
        DbgLog((LOG_ERROR, 1, TEXT("ChangeMonitor: Either pDDrawObject or pDDrawSurface are invalid")));
        return E_POINTER;
    }

    //
    // Check for VPE and IOverlay - we can't change monitor with these
    //

    if (m_apInput[0]->m_RenderTransport == AM_VIDEOPORT ||
        m_apInput[0]->m_RenderTransport == AM_IOVERLAY)
    {
        DbgLog((LOG_ERROR, 1, TEXT("ChangeMonitor: Can't change monitor when using VideoPort or IOverlay")));
        return E_FAIL;
    }


    //
    // Are we actually moving monitors ?
    //

    if (hMon == m_lpCurrentMonitor->hMon)
    {
        DbgLog((LOG_ERROR, 1, TEXT("ChangeMonitor: Specified must be different to current monitor")));
        return E_INVALIDARG;
    }


    //
    // Now check that the specified hMonitor is valid and that the monitor that
    // we are moving to actually has an overlay that we can use.
    //

    AMDDRAWMONITORINFO* p = m_lpDDrawInfo;
    for (; p < &m_lpDDrawInfo[m_dwDDrawInfoArrayLen]; p++)
    {
        if (hMon == p->hMon)
        {
            if (p->ddHWCaps.dwMaxVisibleOverlays < 1)
            {
                DbgLog((LOG_ERROR, 1, TEXT("ChangeMonitor: Can't change to a monitor that has no overlays")));
                return E_FAIL;
            }
            break;
        }
    }


    if (p == &m_lpDDrawInfo[m_dwDDrawInfoArrayLen])
    {
        DbgLog((LOG_ERROR, 1, TEXT("ChangeMonitor: hMonitor parameter is not valid")));
        return E_INVALIDARG;
    }


    //
    // Everything looks OK so reset the current monitor that we are using,
    // save the passed DDraw Object and surface and call the backend code that
    // does the actual work
    //

    m_lpCurrentMonitor = p;
    m_pUpdatedDirectDraw = pDDrawObject;
    m_pUpdatedDirectDraw->AddRef();
    m_pUpdatedPrimarySurface = pDDrawSurface;
    m_pUpdatedPrimarySurface->AddRef();

    return OnDisplayChangeBackEnd();
}


/******************************Public*Routine******************************\
* DisplayModeChanged
*
*
*
* History:
* Tue 11/23/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::DisplayModeChanged(
    HMONITOR hMon,
    LPDIRECTDRAW pDDrawObject,
    LPDIRECTDRAWSURFACE pDDrawSurface
    )
{
    AMTRACE((TEXT("COMFilter::DisplayModeChanged")));
    //
    // Validate the DDraw parameters
    //

    if (!(pDDrawObject && pDDrawSurface))
    {
        DbgLog((LOG_ERROR, 1, TEXT("DisplayModeChanged: Either pDDrawObject or pDDrawSurface are invalid")));
        return E_POINTER;
    }

    DbgLog((LOG_TRACE, 1, TEXT("Display Mode Changed : - OLD monitor = %hs 0x%X"),
            m_lpCurrentMonitor->szDevice,
            hMon ));
    //
    // Refresh our display monitors array as the old array has become
    // invalid as a result of the DisplayMode change
    //
    CAutoLock l(&m_csFilter);
    CoTaskMemFree(m_lpDDrawInfo);
    HRESULT hr = GetDDrawGUIDs(&m_dwDDrawInfoArrayLen, &m_lpDDrawInfo);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 1, TEXT("Failed to enumerate DDraw devices")));
        return hr;
    }

    AMDDRAWMONITORINFO* p = m_lpDDrawInfo;
    for (; p < &m_lpDDrawInfo[m_dwDDrawInfoArrayLen]; p++)
    {
        if (hMon == p->hMon)
        {
            if (p->ddHWCaps.dwMaxVisibleOverlays < 1)
            {
                DbgLog((LOG_ERROR, 1, TEXT("DisplayModeChanged: This monitor has no overlays")));
                return E_FAIL;
            }
            break;
        }
    }


    if (p == &m_lpDDrawInfo[m_dwDDrawInfoArrayLen])
    {
        DbgLog((LOG_ERROR, 1, TEXT("DisplayModeChanged: hMon parameter is not valid")));
        return E_INVALIDARG;
    }

    //
    // Let the common back end code do the actual work
    //
    m_lpCurrentMonitor = p;
    m_pUpdatedDirectDraw = pDDrawObject;
    m_pUpdatedDirectDraw->AddRef();
    m_pUpdatedPrimarySurface = pDDrawSurface;
    m_pUpdatedPrimarySurface->AddRef();
    DbgLog((LOG_TRACE, 1, TEXT("Display Mode Changed : - NEW monitor = %hs 0x%X"),
            m_lpCurrentMonitor->szDevice,
            p->hMon ));
    return OnDisplayChangeBackEnd();
}

/******************************Public*Routine******************************\
* RestoreSurfaces
*
*
*
* History:
* Tue 11/23/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::RestoreSurfaces()
{
    AMTRACE((TEXT("COMFilter::RestoreSurfaces")));

    DWORD i;
    HRESULT hr = S_OK;
    CAutoLock l(&m_csFilter);

    LPDIRECTDRAW  pDD = GetDirectDraw();
    if (pDD) {
        LPDIRECTDRAW4 pDD4;
        if (S_OK == pDD->QueryInterface(IID_IDirectDraw4, (LPVOID *)&pDD4)) {
            pDD4->RestoreAllSurfaces();
            pDD4->Release();
        }
    }

    for (i = 0; i < m_dwInputPinCount; i++)
    {
        hr = m_apInput[i]->RestoreDDrawSurface();
        if (FAILED(hr))
        {
            return hr;
        }
    }

    EventNotify(GetPinCount(), EC_NEED_RESTART, 0, 0);
    EventNotify(GetPinCount(), EC_OVMIXER_REDRAW_ALL, 0, 0);

    return hr;
}

// gets the ddraw object currently being used by the overlay mixer. If the app has not
// set any ddraw object and the ovmixer has not yet allocated one, then *ppDDrawObject
// will be set to NULL and *pbUsingExternal will be set to FALSE. Otherwise *pbUsingExternal
// will be set to TRUE if the ovmixer is currently USING an app given ddraw object and FALSE
// othewise
STDMETHODIMP COMFilter::GetDDrawObject(LPDIRECTDRAW *ppDDrawObject, LPBOOL pbUsingExternal)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetDDrawObject")));

    hr = CanExclusiveMode();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CanExclusiveMode failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (!ppDDrawObject)
    {
        DbgLog((LOG_ERROR, 1, TEXT("invalid argument, ppDDrawObject == NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pbUsingExternal)
    {
        DbgLog((LOG_ERROR, 1, TEXT("invalid argument, ppDDrawObject == NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // make a copy of our ddraw object and addref it (if not NULL)
    *ppDDrawObject = m_pDirectDraw;
    if (m_pDirectDraw)
        m_pDirectDraw->AddRef();

    *pbUsingExternal = m_bExternalDirectDraw;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetDDrawObject")));
    return hr;

}



// this function can be used to provide a primary surface to the filter. A null argument
// to the filter forces it to allocate its own. This function makes sure that the surface
// provided exposes IDirectDrawSurface3, and is consistent with the ddraw object provided
// Furthermore, a non NULL argument provided here means that we are supposed to be windowless
// and are not supposed to touch the bits of the primary surface. So we stop painting the
// colorkey ourselves and expose only one input pin, which uses an overlay surface to do the
// rendering
STDMETHODIMP COMFilter::SetDDrawSurface(LPDIRECTDRAWSURFACE pDDrawSurface)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("COMFilter::SetDDrawSurface(0x%lx)"), pDDrawSurface));

    hr = CanExclusiveMode();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CanExclusiveMode failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // if atleast one pin is connected, just cache the ddraw surface given
    hr = ConfirmPreConnectionState();
    if (FAILED(hr))
    {
        DbgLog((LOG_TRACE, 1, TEXT("filter not in preconnection state, hr = 0x%x"), hr));

#if 0   //
        // This is disabled because of a bug hit by the OvMixer test app that
        // sets the DDraw object and surface and then tries to reconnect the
        // pins to get those DDraw params to be used.
        // There are also a couple of asserts hit in the base classes due to the
        // way the output pin is deleted etc.
        //
        // The bug is in how InitDirectDraw() releases and resets m_pPrimarySurface
        // as well as m_pUpdatedPrimarySurface.  This causes OvMixer to use the
        // app-specified DDraw object but its own DDraw surface.  The fix for this
        // would be to not try to synch up these two interfaces in BreakConnect()
        // etc (that will also help in finding if the DDraw params are external
        // rather than using a BOOL as is done now).
        //

        // addref the new one
        if (pDDrawSurface)
        {
            pDDrawSurface->AddRef();
        }

        // release the old m_pUpdatedPrimarySurface
        if (m_pUpdatedPrimarySurface)
        {
            m_pUpdatedPrimarySurface->Release();
        }

        m_pUpdatedPrimarySurface = pDDrawSurface;

        hr = NOERROR;
#endif // #if 0

        goto CleanUp;
    }

    // allocate a primary surface if the argument is NULL, otherwise addref the one
    // provided. Also set clipper, colorkey etc
    hr = RecreatePrimarySurface(pDDrawSurface);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("InitDirectDraw failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // if argument is not NULL, delete output pin
    if (pDDrawSurface)
    {
        // get rid of the output pin
        delete m_pOutput;
        m_pOutput = NULL;
        IncrementPinVersion();

        m_bExternalPrimarySurface = TRUE;
    }
    else
    {
        // create an outpin pin here
        if (!m_pOutput)
        {
            // Allocate the output pin
            m_pOutput = new COMOutputPin(NAME("OverlayMixer output pin"), this, &m_csFilter, &hr, L"Output",  m_dwMaxPinId);

            // if creation of output pin fails, it is catastrophic and there is nothing we can do about that
            if (!m_pOutput || FAILED(hr))
            {
                if (SUCCEEDED(hr))
                    hr = E_OUTOFMEMORY;

                DbgLog((LOG_ERROR, 1, TEXT("Unable to create the output pin, hr = 0x%x"), hr));
                goto CleanUp;
            }
            IncrementPinVersion();

            // increament the pin id counter
            m_dwMaxPinId++;
        }


        m_bExternalPrimarySurface = FALSE;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::SetDDrawSurface")));
    return hr;
}

// gets the ddraw surface currently being used by the overlay mixer. If the app has not
// set any ddraw surface and the ovmixer has not yet allocated one, then *ppDDrawSurface
// will be set to NULL and *pbUsingExternal will be set to FALSE. Otherwise *pbUsingExternal
// will be set to TRUE if the ovmixer is currently USING an app given ddraw surface and FALSE
// otherwise
STDMETHODIMP COMFilter::GetDDrawSurface(LPDIRECTDRAWSURFACE *ppDDrawSurface, LPBOOL pbUsingExternal)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetDDrawSurface")));

    hr = CanExclusiveMode();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CanExclusiveMode failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (!ppDDrawSurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("invalid argument, ppDDrawObject == NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pbUsingExternal)
    {
        DbgLog((LOG_ERROR, 1, TEXT("invalid argument, ppDDrawObject == NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    *ppDDrawSurface = m_pPrimarySurface;
    if (m_pPrimarySurface)
        m_pPrimarySurface->AddRef();

    *pbUsingExternal = m_bExternalPrimarySurface;

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetDDrawSurface")));
    return hr;
}

// this function is used to give a source and dest rect to the filter in
// the event that an external primary surface has been provided
STDMETHODIMP COMFilter::SetDrawParameters(LPCRECT prcSource, LPCRECT prcTarget)
{
    HRESULT hr = NOERROR;
    RECT ScreenRect;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::SetDrawParamters")));

    hr = CanExclusiveMode();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CanExclusiveMode failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // if it is not an external primary surface, we are not windowless, so calling this
    // function does not make sense
    if (!m_bExternalPrimarySurface)
    {
        hr = E_UNEXPECTED;
        DbgLog((LOG_ERROR, 1, TEXT("m_bExternalPrimarySurface is false, so exiting funtion,")));
        goto CleanUp;
    }

    if (!prcTarget)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_ERROR, 1, TEXT("NULL target rect pointer, so exiting funtion,")));
        goto CleanUp;
    }

    memset(&m_WinInfo, 0, sizeof(WININFO));

    if (prcSource)
    {
        m_WinInfo.SrcRect = *prcSource;
        if (!m_UsingIDDrawNonExclModeVideo) {
            ScaleRect(&m_WinInfo.SrcRect, (double)MAX_REL_NUM, (double)MAX_REL_NUM, (double)m_dwAdjustedVideoWidth, (double)m_dwAdjustedVideoHeight);
        }
    }
    else
    {
        SetRect(&m_WinInfo.SrcRect, 0, 0, m_dwAdjustedVideoWidth, m_dwAdjustedVideoHeight);
    }

    // make sure that the target rect specified by the app is within the screen coordinates
    // of the current monitor. Currently the ovmixer is not multimon aware and therefore the
    // macrovsion bits are only checked on the primary vga card. So essentially this is a
    // safeguard for dvd
    m_WinInfo.DestRect = *prcTarget;
    IntersectRect(&m_WinInfo.DestClipRect, prcTarget, &m_lpCurrentMonitor->rcMonitor);
    m_bWinInfoStored = TRUE;

    OnDrawAll();

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::SetDrawParamters")));
    return hr;
}

// Note that
// IAMDDrawExclusiveMode::GetVideoSize() is implemented as part of IMixerOCX interface.


LPDIRECTDRAW COMFilter::GetDirectDraw()
{
    HRESULT hr;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetDirectDraw")));

    CAutoLock l(&m_csFilter);

    ASSERT(!m_bUseGDI);
    if (!m_pDirectDraw)
    {
        hr = InitDirectDraw(NULL);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("Function InitDirectDraw failed, hr = 0x%x"), hr));
        }
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetDirectDraw")));
    ASSERT(m_pDirectDraw);
    return m_pDirectDraw;
}

LPDDCAPS COMFilter::GetHardwareCaps()
{
    HRESULT hr;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetHardwareCaps")));

    CAutoLock l(&m_csFilter);

    ASSERT(!m_bUseGDI);

    if (!m_pDirectDraw)
    {
        hr = InitDirectDraw(NULL);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("Function InitDirectDraw failed, hr = 0x%x"), hr));
        }
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetHardwareCaps")));

    if (m_pDirectDraw)
    {
        return &m_DirectCaps;
    }
    else
    {
        return NULL;
    }
}

LPDIRECTDRAWSURFACE COMFilter::GetPrimarySurface()
{
    HRESULT hr;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetPrimarySurface")));

    CAutoLock l(&m_csFilter);

    ASSERT(!m_bUseGDI);

    if (!m_pPrimarySurface && m_pDirectDraw)
    {
        // create the primary surface, set the colorkey on it etc
        hr = RecreatePrimarySurface(NULL);
        if (FAILED(hr))
        {
            hr = NOERROR;
            goto CleanUp;
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetPrimarySurface")));
    return m_pPrimarySurface;
}



/*****************************Private*Routine******************************\
* LoadDDrawLibrary
*
* Loads the DDraw library and tries to get pointer to DirectDrawCreate,
* DirectDrawEnum and DirectDrawEnumEx.
*
* History:
* Thu 08/26/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
LoadDDrawLibrary(
    HINSTANCE& hDirectDraw,
    LPDIRECTDRAWCREATE& lpfnDDrawCreate,
    LPDIRECTDRAWENUMERATEA& lpfnDDrawEnum,
    LPDIRECTDRAWENUMERATEEXA& lpfnDDrawEnumEx
    )
{
    UINT ErrorMode = SetErrorMode(SEM_NOOPENFILEERRORBOX);
    hDirectDraw = LoadLibrary(TEXT("DDRAW.DLL"));
    SetErrorMode(ErrorMode);

    if (!hDirectDraw) {
        return AmHresultFromWin32(ERROR_DLL_NOT_FOUND);
    }


    lpfnDDrawCreate = (LPDIRECTDRAWCREATE)GetProcAddress(
            hDirectDraw, "DirectDrawCreate");

    if (!lpfnDDrawCreate) {
        return AmHresultFromWin32(ERROR_PROC_NOT_FOUND);
    }


    lpfnDDrawEnum = (LPDIRECTDRAWENUMERATEA)GetProcAddress(
            hDirectDraw, "DirectDrawEnumerateA");
    if (!lpfnDDrawEnum) {
        return AmHresultFromWin32(ERROR_PROC_NOT_FOUND);
    }

    lpfnDDrawEnumEx = (LPDIRECTDRAWENUMERATEEXA)GetProcAddress(
            hDirectDraw, "DirectDrawEnumerateExA");

    return S_OK;

}

/*****************************Private*Routine******************************\
* CreateDirectDrawObject
*
*
*
* History:
* Fri 08/20/1999 - StEstrop - Created
*
\**************************************************************************/
HRESULT
CreateDirectDrawObject(
    const AMDDRAWGUID& GUID,
    LPDIRECTDRAW *ppDirectDraw,
    LPDIRECTDRAWCREATE lpfnDDrawCreate
    )
{
    UINT ErrorMode = SetErrorMode(SEM_FAILCRITICALERRORS);
    HRESULT hr = (*lpfnDDrawCreate)(GUID.lpGUID, ppDirectDraw, NULL);
    SetErrorMode(ErrorMode);
    return hr;
}


// This function is used to allocate the direct-draw related resources.
// This includes allocating the direct-draw service provider
HRESULT COMFilter::InitDirectDraw(LPDIRECTDRAW pDirectDraw)
{
    HRESULT hr = NOERROR;
    HRESULT hrFailure = VFW_E_DDRAW_CAPS_NOT_SUITABLE;
    DDSURFACEDESC SurfaceDescP;
    int i;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::InitDirectDraw")));

    CAutoLock l(&m_csFilter);

    // release the existing primary surface, since it might be inconsistent with the
    // new ddraw object
    ReleasePrimarySurface();

    // addref the new ddraw object
    if (pDirectDraw)
    {
        pDirectDraw->AddRef();
    }
    else if (m_UsingIDDrawNonExclModeVideo) {
        pDirectDraw = m_pUpdatedDirectDraw;
        m_pUpdatedDirectDraw = NULL;
    }

    // release the previous direct draw object if any
    ReleaseDirectDraw();

    // if given a valid ddraw object, make a copy of it (we have already addref'd it)
    // else allocate your own
    if (pDirectDraw)
    {
        m_pDirectDraw = pDirectDraw;
        m_bExternalDirectDraw = TRUE;
    }
    else
    {
        // Ask the loader to create an instance
        DbgLog((LOG_TRACE, 2, TEXT("Creating a DDraw device on %hs monitor"),
                m_lpCurrentMonitor->szDevice));

        //hr = LoadDirectDraw(m_achMonitor, &m_pDirectDraw, &m_hDirectDraw);
        hr = CreateDirectDrawObject(m_lpCurrentMonitor->guid,
                                    &m_pDirectDraw, m_lpfnDDrawCreate);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("Function InitDirectDraw, LoadDirectDraw failed")));
            hr = hrFailure;
            goto CleanUp;
        }

        m_bExternalDirectDraw = FALSE;
    }

    // Initialise our capabilities structures
    ASSERT(m_pDirectDraw);

    INITDDSTRUCT(m_DirectCaps);
    INITDDSTRUCT(m_DirectSoftCaps);

    // Load the hardware and emulation capabilities
    hr = m_pDirectDraw->GetCaps(&m_DirectCaps,&m_DirectSoftCaps);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDraw->GetCapsGetCaps failed")));
        hr = hrFailure;
        goto CleanUp;
    }

    // Get the kernel caps
    IDirectDrawKernel *pDDKernel;
    if (SUCCEEDED(m_pDirectDraw->QueryInterface(
            IID_IDirectDrawKernel, (void **)&pDDKernel))) {
        DDKERNELCAPS ddCaps;
        ddCaps.dwSize = sizeof(ddCaps);
        if (SUCCEEDED(pDDKernel->GetCaps(&ddCaps))) {
            m_dwKernelCaps = ddCaps.dwCaps;
        }
        pDDKernel->Release();
    }

    // make sure the caps are ok
    hr = CheckCaps();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CheckCaps failed")));
        goto CleanUp;
    }

    if (!m_bExternalDirectDraw)
    {
        // Set the cooperation level on the surface to be shared
        hr = m_pDirectDraw->SetCooperativeLevel(NULL, DDSCL_NORMAL);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pDirectDraw->SetCooperativeLevel failed")));
            hr = hrFailure;
            goto CleanUp;
        }
    }

    // if we have reached this point, we should have a valid ddraw object
    ASSERT(m_pDirectDraw);

CleanUp:

    // anything fails, might as well as release the whole thing
    if (FAILED(hr))
    {
        ReleaseDirectDraw();
    }
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::InitDirectDraw")));
    return hr;
}

HRESULT COMFilter::CheckCaps()
{
    HRESULT hr = NOERROR;
    DWORD dwMinStretch, dwMaxStretch;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::CheckCaps")));

    CAutoLock l(&m_csFilter);

    if (m_DirectCaps.dwCaps2 & DDCAPS2_VIDEOPORT)
    {
        DbgLog((LOG_TRACE, 1, TEXT("Device does support a Video Port")));
    }
    else
    {
        DbgLog((LOG_TRACE, 1, TEXT("Device does not support a Video Port")));
    }


    if(m_DirectCaps.dwCaps & DDCAPS_OVERLAY)
    {
        DbgLog((LOG_TRACE, 1, TEXT("Device does support Overlays")));
    }
    else
    {
        DbgLog((LOG_TRACE, 1, TEXT("Device does not support Overlays")));
    }

    // get all direct-draw capabilities
    if (m_DirectCaps.dwCaps & DDCAPS_OVERLAYSTRETCH)
    {
        DbgLog((LOG_TRACE, 1, TEXT("hardware can support overlay strecthing")));
    }
    else
    {
        DbgLog((LOG_TRACE, 1, TEXT("hardware can't support overlay strecthing")));
    }

    // get the alignment restriction on src boundary
    if (m_DirectCaps.dwCaps & DDCAPS_ALIGNBOUNDARYSRC)
    {
        DbgLog((LOG_TRACE, 1, TEXT("dwAlignBoundarySrc = %d"), m_DirectCaps.dwAlignBoundarySrc));
    }
    else
    {
        DbgLog((LOG_TRACE, 1, TEXT("No alignment restriction on BoundarySrc")));
    }

    // get the alignment restriction on dest boundary
    if (m_DirectCaps.dwCaps & DDCAPS_ALIGNBOUNDARYDEST)
    {
        DbgLog((LOG_TRACE, 1, TEXT("dwAlignBoundaryDest = %d"), m_DirectCaps.dwAlignBoundaryDest));
    }
    else
    {
        DbgLog((LOG_TRACE, 1, TEXT("No alignment restriction on BoundaryDest")));
    }

    // get the alignment restriction on src size
    if (m_DirectCaps.dwCaps & DDCAPS_ALIGNSIZESRC)
    {
        DbgLog((LOG_TRACE, 1, TEXT("dwAlignSizeSrc = %d"), m_DirectCaps.dwAlignSizeSrc));
    }
    else
    {
        DbgLog((LOG_TRACE, 1, TEXT("No alignment restriction on SizeSrc")));
    }

    // get the alignment restriction on dest size
    if (m_DirectCaps.dwCaps & DDCAPS_ALIGNSIZEDEST)
    {
        DbgLog((LOG_TRACE, 1, TEXT("dwAlignSizeDest = %d"), m_DirectCaps.dwAlignSizeDest));
    }
    else
    {
        DbgLog((LOG_TRACE, 1, TEXT("No alignment restriction on SizeDest")));
    }

    if (m_DirectCaps.dwMinOverlayStretch)
    {
        dwMinStretch = m_DirectCaps.dwMinOverlayStretch;
        DbgLog((LOG_TRACE, 1, TEXT("Min Stretch = %d"), dwMinStretch));
    }

    if (m_DirectCaps.dwMaxOverlayStretch)
    {
        dwMaxStretch = m_DirectCaps.dwMaxOverlayStretch;
        DbgLog((LOG_TRACE, 1, TEXT("Max Stretch = %d"), dwMaxStretch));
    }

    if ((m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKX))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver has DDFXCAPS_OVERLAYSHRINKX")));
    }

    if ((m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKXN))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver has DDFXCAPS_OVERLAYSHRINKXN")));
    }

    if ((m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKY))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver has DDFXCAPS_OVERLAYSHRINKY")));
    }

    if ((m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKYN))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver has DDFXCAPS_OVERLAYSHRINKYN")));
    }

    if ((m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSTRETCHX))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver has DDFXCAPS_OVERLAYSTRETCHX")));
    }

    if ((m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSTRETCHXN))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver has DDFXCAPS_OVERLAYSTRETCHXN")));
    }

    if ((m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSTRETCHY))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver has DDFXCAPS_OVERLAYSTRETCHY")));
    }

    if ((m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSTRETCHYN))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver has DDFXCAPS_OVERLAYSTRETCHYN")));
    }

    if ((m_DirectCaps.dwSVBFXCaps & DDFXCAPS_BLTARITHSTRETCHY))
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver uses arithmetic operations to blt from system to video")));
    }
    else
    {
        DbgLog((LOG_TRACE, 1, TEXT("Driver uses pixel-doubling to blt from system to video")));
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::CheckCaps")));
    return hr;
}


// this function is used to release the resources allocated by the function
// "InitDirectDraw". these include the direct-draw service provider and the
// primary surfaces
DWORD COMFilter::ReleaseDirectDraw()
{
    AMTRACE((TEXT("COMFilter::ReleaseDirectDraw")));
    DWORD dwRefCnt = 0;

    CAutoLock l(&m_csFilter);

    // Release any DirectDraw provider interface
    DbgLog((LOG_TRACE, 1, TEXT("Release DDObj 0x%p\n"), m_pDirectDraw));
    if (m_pDirectDraw)
    {
        //
        // Gross Hack ALERT !!
        //
        if (GetModuleHandle(TEXT("VBISURF.AX")) ||
            GetModuleHandle(TEXT("VBISURF.DLL"))) {

            //
            // In its wisdom, DDraw deletes all DDraw resources created in the
            // process when any DDraw Object in that process gets deleted -
            // regardless of whether this DDraw object created them or not.  This
            // only becomes a problem if the VBISURF filter is present in the
            // filter graph as it creates its own DDraw Object which it may
            // use after we delete ours.  This means that any surfaces, VP objects
            // that VBISURF creates get destroyed when we delete our DDraw object.
            //
            // The solution: leak the DDraw object !!
            //
        }
        else {
            dwRefCnt = m_pDirectDraw->Release();
        }
        m_pDirectDraw = NULL;
    }

    ZeroMemory(&m_DirectCaps, sizeof(DDCAPS));
    ZeroMemory(&m_DirectSoftCaps, sizeof(DDCAPS));

    return dwRefCnt;
}

// function to create the primary surface
HRESULT COMFilter::CreatePrimarySurface()
{
    HRESULT hr = E_FAIL;
    DDSURFACEDESC SurfaceDescP;
    DWORD dwInputPinCount = 0, i = 0;
    COMInputPin *pInputPin = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::CreatePrimarySurface")));

    CAutoLock l(&m_csFilter);
    if (m_pDirectDraw) {
        ASSERT(m_pPrimarySurface == NULL);

        // Create the primary surface
        INITDDSTRUCT(SurfaceDescP);
        SurfaceDescP.dwFlags = DDSD_CAPS;
        SurfaceDescP.ddsCaps.dwCaps = DDSCAPS_PRIMARYSURFACE;
        hr = m_pDirectDraw->CreateSurface(&SurfaceDescP, &m_pPrimarySurface, NULL);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 1, TEXT("Function CreatePrimarySurface failed, hr = 0x%x"), hr));
            m_pPrimarySurface = NULL;
        }
    }

    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::CreatePrimarySurface")));
    return hr;
}

// function to release the primary surface
DWORD COMFilter::ReleasePrimarySurface()
{
    AMTRACE((TEXT("COMFilter::ReleasePrimarySurface")));
    HRESULT hr = NOERROR;
    DWORD dwRefCount = 0;

    CAutoLock l(&m_csFilter);

    if (m_pPrimarySurface)
    {
        dwRefCount = m_pPrimarySurface->Release();
        m_pPrimarySurface = NULL;
    }

    return dwRefCount;
}


HRESULT ComputeSurfaceRefCount(LPDIRECTDRAWSURFACE pDDrawSurface)
{
    DWORD dwRefCount = 0;
    if (!pDDrawSurface)
    {
        DbgLog((LOG_TRACE, 5, TEXT("ComputeSurfaceRefCount, pDDrawSurface is NULL")));
        return NOERROR;
    }

    pDDrawSurface->AddRef();
    dwRefCount = pDDrawSurface->Release();
    DbgLog((LOG_TRACE, 5, TEXT("ComputeSurfaceRefCount, dwRefCount = %d"), dwRefCount));
    return NOERROR;
}

// this function is used to tell the filter, what the colorkey is. Also sets the
// colorkey on the primary surface
// The semantics is that in the palettized mode, if pColorKey->KeyType & CK_INDEX is
// set, that the index specified in the colorkey will be used otherwise the colorref
// will be used.
// if pColorKey->KeyType & CK_RGB is not set, the function returns E_INVALIDARG even
// if the mode is palettized right now, because we need teh colorref if the display mode
// changes.
HRESULT COMFilter::SetColorKey(COLORKEY *pColorKey)
{
    HRESULT hr = NOERROR;
    DDCOLORKEY DDColorKey;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::SetColorKey")));

    CAutoLock l(&m_csFilter);

#if defined(DEBUG)
    DbgLog((LOG_TRACE, 5, TEXT("Type       =0x%8.8X"), pColorKey->KeyType));
    switch (pColorKey->KeyType) {
    case CK_INDEX:
        DbgLog((LOG_TRACE, 5, TEXT("Invalid Key Type")));
        break;

    case CK_INDEX|CK_RGB:
        DbgLog((LOG_TRACE, 5, TEXT("Index  =0x%8.8X"), pColorKey->PaletteIndex));
        break;

    case CK_RGB:
        DbgLog((LOG_TRACE, 5, TEXT("LoColor=0x%8.8X"), pColorKey->LowColorValue));
        DbgLog((LOG_TRACE, 5, TEXT("HiColor=0x%8.8X"), pColorKey->HighColorValue));
        break;
    }
#endif

    // check for valid pointer
    if (!pColorKey)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pColorKey is NULL")));
        hr = E_POINTER;
        goto CleanUp;
    }

    // check for valid flags
    if (!(pColorKey->KeyType & CK_RGB))
    {
        DbgLog((LOG_ERROR, 1, TEXT("!(pColorKey->KeyType & CK_RGB)")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // check for primary surface
    if (!m_pPrimarySurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pPrimarySurface is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // check if the display is palettised on not
    if ((m_Display.IsPalettised()) &&
        (pColorKey->KeyType & CK_INDEX))
    {
        if ( (pColorKey->PaletteIndex > 255))
        {
            DbgLog((LOG_ERROR, 1, TEXT("pColorKey->PaletteIndex invalid")));
            hr = E_INVALIDARG;
            goto CleanUp;
        }

        DDColorKey.dwColorSpaceLowValue = pColorKey->PaletteIndex;
        DDColorKey.dwColorSpaceHighValue = pColorKey->PaletteIndex;
    }

    else

    {
        DWORD dwColorVal;
        dwColorVal = DDColorMatch(m_pPrimarySurface, pColorKey->LowColorValue, hr);

        if (FAILED(hr)) {
            dwColorVal = DDColorMatchOffscreen(m_pDirectDraw, pColorKey->LowColorValue, hr);
        }
        DDColorKey.dwColorSpaceLowValue = dwColorVal;
        DDColorKey.dwColorSpaceHighValue = dwColorVal;
    }


    // Tell the primary surface what to expect
    hr = m_pPrimarySurface->SetColorKey(DDCKEY_DESTOVERLAY, &DDColorKey);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0, TEXT("pPrimarySurface->SetColorKey failed")));
        goto CleanUp;
    }

    // store the colorkey
    m_ColorKey = *pColorKey;
    m_bColorKeySet = TRUE;

    // Notify color key changes
    if (m_pExclModeCallback) {
        m_pExclModeCallback->OnUpdateColorKey(&m_ColorKey,
                                              DDColorKey.dwColorSpaceLowValue);
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::SetColorKey")));
    return hr;
}

HRESULT COMFilter::GetColorKey(COLORKEY *pColorKey, DWORD *pColor)
{
    HRESULT hr =  NOERROR;
    DWORD dwColor = 0;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetColorKey")));

    CAutoLock l(&m_csFilter);

    ASSERT(pColorKey != NULL || pColor != NULL);

    if (pColorKey)
    {
        *pColorKey = m_ColorKey;
    }

    if (pColor)
    {
        if (!m_pPrimarySurface)
        {
            DbgLog((LOG_ERROR, 1, TEXT("m_pPrimarySurface = NULL, returning E_UNEXPECTED")));
            hr = E_UNEXPECTED;
            goto CleanUp;
        }

        if (m_Display.IsPalettised() && (m_ColorKey.KeyType & CK_INDEX))
        {
            dwColor = m_ColorKey.PaletteIndex;
        }
        else
        {
            dwColor = DDColorMatch(m_pPrimarySurface, m_ColorKey.LowColorValue, hr);
            if (FAILED(hr)) {
                dwColor = DDColorMatchOffscreen(m_pDirectDraw, m_ColorKey.LowColorValue, hr);
            }
        }

        *pColor = dwColor;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetColorKey")));
    return hr;
}

HRESULT COMFilter::PaintColorKey(HRGN hPaintRgn, COLORKEY *pColorKey)
{

    HRESULT hr = NOERROR;

    LPRGNDATA pBuffer = NULL;
    DWORD dwTemp, dwBuffSize = 0, dwRetVal = 0;
    LPRECT pDestRect;
    DDBLTFX ddFX;
    DWORD dwColorKey;
    HBRUSH hBrush = NULL;
    HDC hdc = NULL;

    CAutoLock l(&m_csFilter);

    ASSERT(pColorKey);

    // if it is an external primary surface, do not paint anything on the primary surface
    if (m_bExternalPrimarySurface)
    {
        DbgLog((LOG_TRACE, 2, TEXT("m_bExternalPrimarySurface is true, so exiting funtion,")));
        goto CleanUp;
    }

    if (m_bUseGDI)
    {
        hBrush = CreateSolidBrush(pColorKey->LowColorValue);
        if ( ! hBrush )
        {
            hr = E_OUTOFMEMORY;
            goto CleanUp;
        }

        hdc = GetDestDC();
        if ( ! hdc )
        {
            hr = E_OUTOFMEMORY;
            DeleteObject( hBrush );
            goto CleanUp;
        }

        OffsetRgn(hPaintRgn, -m_WinInfo.TopLeftPoint.x, -m_WinInfo.TopLeftPoint.y);
        FillRgn(hdc, hPaintRgn, hBrush);

        // Delete the GDI objects we created
        EXECUTE_ASSERT(DeleteObject(hBrush));

        goto CleanUp;
    }


    ASSERT(m_pPrimarySurface);

    dwRetVal = GetRegionData(hPaintRgn, 0, NULL);
    ASSERT(dwRetVal);
    dwBuffSize = dwRetVal;
    pBuffer = (LPRGNDATA) new char[dwBuffSize];
    if ( ! pBuffer )
        return S_OK;    // dont propagate error, since CleanUp does not

    dwRetVal = GetRegionData(hPaintRgn, dwBuffSize, pBuffer);
    ASSERT(pBuffer->rdh.iType == RDH_RECTANGLES);

    //ASSERT(dwBuffSize == (pBuffer->rdh.dwSize + pBuffer->rdh.nRgnSize));

    dwColorKey = DDColorMatch(m_pPrimarySurface, pColorKey->LowColorValue, hr);
    if (FAILED(hr)) {
        dwColorKey = DDColorMatchOffscreen(m_pDirectDraw, pColorKey->LowColorValue, hr);
    }

    // Peform a DirectDraw colorfill BLT.  DirectDraw will automatically
    // query the attached clipper object, handling occlusion.
    INITDDSTRUCT(ddFX);
    ddFX.dwFillColor = dwColorKey;

    for (dwTemp = 0; dwTemp < pBuffer->rdh.nCount; dwTemp++)
    {
        pDestRect = (LPRECT)((char*)pBuffer + pBuffer->rdh.dwSize + dwTemp*sizeof(RECT));
        ASSERT(pDestRect);

        RECT TargetRect = *pDestRect;
        OffsetRect(&TargetRect,
                   -m_lpCurrentMonitor->rcMonitor.left,
                   -m_lpCurrentMonitor->rcMonitor.top);

        hr = m_pPrimarySurface->Blt(&TargetRect, NULL, NULL,
                                    DDBLT_COLORFILL | DDBLT_WAIT, &ddFX);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0, TEXT("m_pPrimarySurface->Blt failed, hr = 0x%x"), hr));
            DbgLog((LOG_ERROR,0, TEXT("Destination Rect = {%d, %d, %d, %d}"),
                pDestRect->left, pDestRect->top, pDestRect->right, pDestRect->bottom));
            goto CleanUp;
        }
    }

CleanUp:
    delete [] pBuffer;
    // !!! return hr;
    return S_OK;
}

void COMFilter::GetPinsInZOrder(DWORD *pdwZOrder)
{
    BOOL bMisMatchFound;
    int i;
    DWORD temp;

    for (i = 0; i < (int)m_dwInputPinCount; i++)
    {
        pdwZOrder[i] = i;
    }

    do
    {
        bMisMatchFound = FALSE;

        for (i = 0; i < (int)m_dwInputPinCount-1; i++)
        {
            if (m_apInput[pdwZOrder[i + 1]]->GetInternalZOrder() <
                m_apInput[pdwZOrder[i]]->GetInternalZOrder())
            {
                temp = pdwZOrder[i+1];
                pdwZOrder[i+1] = pdwZOrder[i];
                pdwZOrder[i] = temp;
                bMisMatchFound = TRUE;
            }
        }
    }
    while (bMisMatchFound);
}

BOOL DellDVDPlayer()
{
    TCHAR szModuleName[MAX_PATH];
    static const TCHAR szDellPlayer[] = TEXT("viewdvd.exe");

    if (0 != GetModuleFileName((HMODULE)NULL, szModuleName, MAX_PATH))
    {
        TCHAR   szPathName[2 * MAX_PATH];
        TCHAR*  lpszFileName;

        if (0 != GetFullPathName(szModuleName, 2 * MAX_PATH,
                                 szPathName, &lpszFileName))
        {
            return 0 == lstrcmpi(lpszFileName, szDellPlayer);
        }
    }

    return FALSE;
}

HRESULT COMFilter::OnShowWindow(HWND hwnd, BOOL fShow)
{
    HRESULT hr = E_FAIL;

    RECT rcSrc = m_WinInfo.SrcRect, rcDest;

    if (fShow)
    {
        if (!DellDVDPlayer()) {

            // Restore the original destination rect
            IBasicVideo* Ibv = NULL;
            hr = GetBasicVideoFromOutPin(&Ibv);
            if (SUCCEEDED(hr))
            {
                hr = Ibv->GetDestinationPosition(&rcDest.left, &rcDest.top,
                                                 &rcDest.right, &rcDest.bottom);
                if (SUCCEEDED(hr))
                {
                    rcDest.right += rcDest.left;
                    rcDest.bottom += rcDest.top;
                    MapWindowPoints(hwnd, HWND_DESKTOP, (LPPOINT)&rcDest, 2);
                }
                Ibv->Release();
            }

            if (SUCCEEDED(hr))
            {
                hr = OnClipChange(&rcSrc, &rcDest, NULL);
            }

        }

        // else, we arn't connected to a Video Renderer so do nothing
        // which is what the original code would have done.
    }
    else
    {
        // make the dest empty
        SetRect(&rcDest, 0, 0, 0, 0);
        hr = OnClipChange(&rcSrc, &rcDest, NULL);
    }

    return hr;
}

HDC COMFilter::GetDestDC()
{
    if (m_pOutput)
        return m_pOutput->GetDC();
    else
        return m_hDC;
}

HWND COMFilter::GetWindow()
{
    if (m_pOutput)
        return m_pOutput->GetWindow();
    else
        return NULL;
}


HRESULT COMFilter::OnDrawAll()
{
    HRESULT hr = NOERROR;
    HRGN hMainRgn = NULL, hUncroppedMainRgn = NULL, hSubRgn = NULL, hBlackRgn = NULL;
    RECT rSubPinDestRect, rUncroppedDestRect;
    DRECT rdSrcRect, rdDestRect;
    DWORD i, j, dwInputPinCount = 0, dwBlendingParameter = 0, dwNextPinInZOrder = 0;
    int iRgnType = 0;
    COMInputPin *pPin;
    WININFO WinInfo;
    COLORKEY blackColorKey;
    BOOL bStreamTransparent = FALSE;
    DWORD pdwPinsInZOrder[MAX_PIN_COUNT];

    DbgLog((LOG_TRACE,2,TEXT("Entering OnDrawAll")));

    CAutoLock l(&m_csFilter);

    if (!m_bWinInfoStored)
    {
        goto CleanUp;
    }

    // if there is no primary surface in the non-GDI case, no point in going on
    if (!m_bUseGDI && !m_pPrimarySurface)
    {
        DbgLog((LOG_ERROR,2,TEXT("the Primary Surface is NULL")));
        goto CleanUp;
    }

    // we will use black on the rest of the region left
    blackColorKey.KeyType = CK_INDEX | CK_RGB;
    blackColorKey.PaletteIndex = 0;
    blackColorKey.LowColorValue = blackColorKey.HighColorValue = RGB(0,0,0);

    // make a region out of the destination clip rect
    hBlackRgn = CreateRectRgnIndirect(&m_WinInfo.DestClipRect);
    if (!hBlackRgn)
    {
        DbgLog((LOG_TRACE,5,TEXT("CreateRectRgnIndirect(&m_WinInfo.DestClipRect) failed")));
        goto CleanUp;
    }

    // the first pin has to be connected, otherwise bail out
    if (!m_apInput[0]->IsCompletelyConnected())
    {
        //  REVIEW - when can this happen?
        DbgLog((LOG_TRACE,5,TEXT("None of the input pins are connected")));

        // paint the remaining region black
        hr = PaintColorKey(hBlackRgn, &blackColorKey);
        ASSERT(SUCCEEDED(hr));

        //  REVIEW CleanUp will clean up hBlackRgn
        goto CleanUp;
    }

    ASSERT(!IsRectEmpty(&m_WinInfo.SrcRect));

    // copy m_WinInfo.SrcRect into rdDestRect
    SetRect(&rdSrcRect, m_WinInfo.SrcRect.left, m_WinInfo.SrcRect.top, m_WinInfo.SrcRect.right, m_WinInfo.SrcRect.bottom);
    ASSERT((m_dwAdjustedVideoWidth != 0) && (m_dwAdjustedVideoHeight != 0));
    ScaleRect(&rdSrcRect, (double)m_dwAdjustedVideoWidth, (double)m_dwAdjustedVideoHeight, (double)MAX_REL_NUM, (double)MAX_REL_NUM);

    // copy m_WinInfo.DestRect into rdDestRect
    SetRect(&rdDestRect, m_WinInfo.DestRect.left, m_WinInfo.DestRect.top, m_WinInfo.DestRect.right, m_WinInfo.DestRect.bottom);

    dwInputPinCount = m_dwInputPinCount;
    ASSERT(dwInputPinCount >= 1);

    // get the pointer to an array in which the pin numbers are stored in increasing z order
    // the number of elements in that array is the input pin count
    GetPinsInZOrder(pdwPinsInZOrder);

    for (i = 0; i < dwInputPinCount; i++)
    {
        ASSERT(hMainRgn == NULL);

        // get the pin number with the next lower most z order
        dwNextPinInZOrder = pdwPinsInZOrder[i];
        ASSERT( dwNextPinInZOrder <= dwInputPinCount);

        // get the corresponding pin
        pPin = m_apInput[dwNextPinInZOrder];
        ASSERT(pPin);

        // get the pin's blending parameter
        hr = pPin->GetBlendingParameter(&dwBlendingParameter);
        ASSERT(SUCCEEDED(hr));

        if ((!pPin->IsCompletelyConnected()) || (dwBlendingParameter == 0))
            continue;

        memset(&WinInfo, 0, sizeof(WININFO));

        WinInfo.TopLeftPoint = m_WinInfo.TopLeftPoint;

        // ask the pin about its rectangles
        pPin->CalcSrcDestRect(&rdSrcRect, &rdDestRect, &WinInfo.SrcRect, &WinInfo.DestRect, &rUncroppedDestRect);

        // make sure the rect is clipped within the m_WinInfo.DestClipRect
        IntersectRect(&WinInfo.DestClipRect, &WinInfo.DestRect, &m_WinInfo.DestClipRect);

        // make a region out of it
        hMainRgn = CreateRectRgnIndirect(&WinInfo.DestClipRect);
        if (!hMainRgn)
            continue;

        // make a region out of it
        hUncroppedMainRgn = CreateRectRgnIndirect(&rUncroppedDestRect);
        if (!hUncroppedMainRgn)
            //  REVIEW won't we leak hMainRgn here?
            continue;

        // Update the new black region by subtracting the main region from it
        iRgnType = CombineRgn(hBlackRgn, hBlackRgn, hUncroppedMainRgn, RGN_DIFF);
        if (iRgnType == ERROR)
        {
            DbgLog((LOG_ERROR,0, TEXT("CombineRgn(hBlackRgn, hNewPrimRgn, hBlackRgn, RGN_DIFF) FAILED")));
            goto CleanUp;
        }


        for (j = i+1; j < dwInputPinCount; j++)
        {
            ASSERT(hSubRgn == NULL);

            // get the pin number with the next lower most z order
            dwNextPinInZOrder = pdwPinsInZOrder[j];
            ASSERT( dwNextPinInZOrder <= dwInputPinCount);

            // assert that the z order of the sub pin is higher than that of the ain pin
            ASSERT(m_apInput[pdwPinsInZOrder[j]]->GetInternalZOrder() >
                   m_apInput[pdwPinsInZOrder[i]]->GetInternalZOrder());

            // get the sub pin
            pPin = m_apInput[dwNextPinInZOrder];
            ASSERT(pPin);

            // get the pin's blending parameter
            hr = pPin->GetBlendingParameter(&dwBlendingParameter);
            ASSERT(SUCCEEDED(hr));

            // check if the secondary stream is transparent. If it is, then we shouldn't
            // subtract its region from the main region
            hr = pPin->GetStreamTransparent(&bStreamTransparent);
            ASSERT(SUCCEEDED(hr));

            if ((!pPin->IsCompletelyConnected()) || (dwBlendingParameter == 0) || (bStreamTransparent))
                continue;

            // ask the pin about its destination rectangle, we are not interested in the
            // source rect
            pPin->CalcSrcDestRect(&rdSrcRect, &rdDestRect, NULL, &rSubPinDestRect, NULL);
            if (IsRectEmpty(&rSubPinDestRect))
                continue;

            // make sure the rect is clipped within the m_WinInfo.DestClipRect
            IntersectRect(&rSubPinDestRect, &rSubPinDestRect, &m_WinInfo.DestClipRect);

            // make a region out of it
            hSubRgn = CreateRectRgnIndirect(&rSubPinDestRect);

            //  REVIEW - presumably this can be NULL though right?
            ASSERT(hSubRgn);

            // adjust the primary region
            iRgnType = CombineRgn(hMainRgn, hMainRgn, hSubRgn, RGN_DIFF);
            if (iRgnType == ERROR)
            {
                // now the hNewPrimRgn might be in a bad state, bail out
                DbgLog((LOG_ERROR,0, TEXT("CombineRgn(hMainRgn, hMainRgn, hSubRgn, RGN_DIFF) FAILED, UNEXPECTED!!")));
            }

            DeleteObject(hSubRgn);
            hSubRgn = NULL;
        }

        WinInfo.hClipRgn = hMainRgn;

        DbgLog((LOG_TRACE, 2, TEXT("Printing WinInfo")));
        DbgLog((LOG_TRACE, 2, TEXT("SrcRect = %d, %d, %d, %d"), WinInfo.SrcRect.left,
            WinInfo.SrcRect.top, WinInfo.SrcRect.right, WinInfo.SrcRect.bottom));
        DbgLog((LOG_TRACE, 2, TEXT("DestRect = %d, %d, %d, %d"), WinInfo.DestRect.left,
            WinInfo.DestRect.top, WinInfo.DestRect.right, WinInfo.DestRect.bottom));

        // get the pin number from i
        dwNextPinInZOrder = pdwPinsInZOrder[i];
        ASSERT( dwNextPinInZOrder <= dwInputPinCount);

        // get the corresponding pin
        pPin = m_apInput[dwNextPinInZOrder];
        ASSERT(pPin);

        // ask the pin to draw its contents
        pPin->OnClipChange(&WinInfo);

        // should we delete hMainRgn here??
        if (hMainRgn)
        {
            DeleteObject(hMainRgn);
            hMainRgn = NULL;
        }

        if (hUncroppedMainRgn)
        {
            DeleteObject(hUncroppedMainRgn);
            hUncroppedMainRgn = NULL;
        }
    }

    // paint the remaining region black
    hr = PaintColorKey(hBlackRgn, &blackColorKey);
    ASSERT(SUCCEEDED(hr));
    DeleteObject(hBlackRgn);
    hBlackRgn = NULL;


CleanUp:
    if (hMainRgn)
    {
        DeleteObject(hMainRgn);
        hMainRgn = NULL;
    }

    if (hUncroppedMainRgn)
    {
        DeleteObject(hUncroppedMainRgn);
        hUncroppedMainRgn = NULL;
    }

    if (hSubRgn)
    {
        DeleteObject(hSubRgn);
        hSubRgn = NULL;
    }

    if (hBlackRgn)
    {
        DeleteObject(hBlackRgn);
        hBlackRgn = NULL;
    }

    return hr;
}

// gets the number and pointer to the palette enteries
HRESULT COMFilter::GetPaletteEntries(DWORD *pdwNumPaletteEntries, PALETTEENTRY **ppPaletteEntries)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetPaletteEntries")));

    if (!pdwNumPaletteEntries)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pdwNumPaletteEntries is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!ppPaletteEntries)
    {
        DbgLog((LOG_ERROR, 1, TEXT("ppPaletteEntries is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    {
        CAutoLock l(&m_csFilter);
        if (m_dwNumPaletteEntries == 0)
        {
            DbgLog((LOG_ERROR, 1, TEXT("no palette, returning E_FAIL, m_dwNumPaletteEntries = %d, m_pPaletteEntries = 0x%x"),
                m_dwNumPaletteEntries, m_pPaletteEntries));
            hr = E_FAIL;
            goto CleanUp;
        }

        *pdwNumPaletteEntries = m_dwNumPaletteEntries;
        *ppPaletteEntries = m_pPaletteEntries;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetPaletteEntries")));
    return hr;
}


STDMETHODIMP COMFilter::OnColorKeyChange(const COLORKEY *pColorKey)          // Defines new colour key
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::OnColorKeyChange")));
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::OnColorKeyChange")));

    return NOERROR;
}


STDMETHODIMP COMFilter::OnClipChange(const RECT* pSrcRect, const RECT* pDestRect,
                                     const RGNDATA * pRegionData)
{
    HRESULT hr = NOERROR;
    HWND hwnd;
    DbgLog((LOG_TRACE,5,TEXT("Entering OnClipChange")));

    {
        CAutoLock l(&m_csFilter);

        ASSERT(pSrcRect && pDestRect);
        hwnd = m_pOutput->GetWindow();

        // totally empty rectangles means that the window is in transition
        if (IsRectEmpty(pSrcRect))
        {
            DbgLog((LOG_TRACE,5,TEXT("the source rectangle is empty")));
            goto CleanUp;
        }

        // update the WinInfo
        ZeroMemory(&m_WinInfo, sizeof(WININFO));
        EXECUTE_ASSERT(ClientToScreen(hwnd, &(m_WinInfo.TopLeftPoint)));

        m_WinInfo.SrcRect = *pSrcRect;
        m_WinInfo.DestRect = *pDestRect;

        RECT rcClient;
        GetClientRect(hwnd, &rcClient);
        MapWindowRect(hwnd, HWND_DESKTOP, &rcClient);
        IntersectRect(&m_WinInfo.DestClipRect, &rcClient, &m_WinInfo.DestRect);
        IntersectRect(&m_WinInfo.DestClipRect, &m_lpCurrentMonitor->rcMonitor,
                      &m_WinInfo.DestClipRect);

        m_WinInfo.hClipRgn = NULL;
        m_bWinInfoStored = TRUE;

        // if the window is not visible, don't bother
        if (!m_pOutput || !(m_pOutput->GetWindow()) || !IsWindowVisible(m_pOutput->GetWindow()))
        {
            DbgLog((LOG_TRACE,5,TEXT("The window is not visible yet or the Priamry Surface is NULL")));
            goto CleanUp;
        }
    }

    InvalidateRect(hwnd, NULL, FALSE);
//    UpdateWindow(hwnd);

CleanUp:
    return hr;
}

STDMETHODIMP COMFilter::OnPaletteChange(DWORD dwColors, const PALETTEENTRY *pPalette)       // Array of palette colours
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT(" Entering COMFilter::OnPaletteChange")));

    CAutoLock l(&m_csFilter);

    ASSERT(dwColors);
    ASSERT(pPalette);

    m_dwNumPaletteEntries = dwColors;
    memcpy(m_pPaletteEntries, pPalette, (dwColors * sizeof(PALETTEENTRY)));

    // set the pointer to the Primary Surface on the input pins
    for (DWORD i = 0; i < m_dwInputPinCount; i++)
    {
        m_apInput[i]->NewPaletteSet();
    }

    DbgLog((LOG_TRACE, 5, TEXT(" Leaving COMFilter::OnPaletteChange")));
    return NOERROR;
}

HRESULT COMFilter::CanExclusiveMode()
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::CanExclusiveMode")));

    if (m_bWindowless)
    {
        ASSERT(m_bUseGDI);
        hr = E_UNEXPECTED;
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::CanExclusiveMode")));
    return hr;
}

HRESULT COMFilter::ConfirmPreConnectionState(DWORD dwExcludePinId)
{
    HRESULT hr = NOERROR;
    DWORD i = 0;

    // is the input pin already connected?
    for (i = 0; i < m_dwInputPinCount; i++)
    {
        if ((m_apInput[i]->GetPinId() != dwExcludePinId) && m_apInput[i]->IsConnected())
        {
            hr = VFW_E_ALREADY_CONNECTED;
            DbgLog((LOG_ERROR, 1, TEXT("m_apInput[i]->IsConnected() , i = %d, returning hr = 0x%x"), i, hr));
            goto CleanUp;
        }
    }

    // is the output pin already connected?
    if (m_pOutput && (m_pOutput->GetPinId() != dwExcludePinId) && m_pOutput->IsConnected())
    {
        hr = VFW_E_ALREADY_CONNECTED;
        DbgLog((LOG_ERROR, 1, TEXT("m_pOutput->IsConnected() , returning hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    return hr;
}

STDMETHODIMP COMFilter::OnPositionChange(const RECT *pSrcRect, const RECT *pDestRect)
{
    HRESULT hr = NOERROR;
    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::OnPositionChange")));
    hr = OnClipChange(pSrcRect, pDestRect, NULL);
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::OnPositionChange")));
    return hr;
}

STDMETHODIMP COMFilter::GetNativeVideoProps(LPDWORD pdwVideoWidth, LPDWORD pdwVideoHeight, LPDWORD pdwPictAspectRatioX, LPDWORD pdwPictAspectRatioY)
{
    HRESULT hr = NOERROR;
    CMediaType cMediaType;
    BITMAPINFOHEADER *pHeader = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetVideoSizeAndAspectRatio")));

    hr = CanExclusiveMode();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CanExclusiveMode failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (!pdwVideoWidth || !pdwVideoHeight || !pdwPictAspectRatioX || !pdwPictAspectRatioY)
    {
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!m_apInput[0]->IsConnected())
    {
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    hr = m_apInput[0]->CurrentAdjustedMediaType(&cMediaType);
    ASSERT(SUCCEEDED(hr));
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_paInput[0]->CurrentAdjustedMediaType failed, hr = 0x%x"), hr));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // get the native width and height from the mediatype
    pHeader = GetbmiHeader(&cMediaType);
    ASSERT(pHeader);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    *pdwVideoWidth = abs(pHeader->biWidth);
    *pdwVideoHeight = abs(pHeader->biHeight);

    // sanity checks
    ASSERT(*pdwVideoWidth > 0);
    ASSERT(*pdwVideoHeight > 0);

    // get the picture aspect ratio from the mediatype
    hr = ::GetPictAspectRatio(&cMediaType, pdwPictAspectRatioX, pdwPictAspectRatioY);
    ASSERT(SUCCEEDED(hr));
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("GetPictAspectRatio failed, hr = 0x%x"), hr));
        hr = E_FAIL;
        goto CleanUp;
    }

    // sanity checks
    ASSERT(*pdwPictAspectRatioX > 0);
    ASSERT(*pdwPictAspectRatioY > 0);

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetVideoSizeAndAspectRatio")));
    return hr;
}

//
//   Set callback interface for exclusive mode support
//
STDMETHODIMP COMFilter::SetCallbackInterface(IDDrawExclModeVideoCallback *pCallback, DWORD dwFlags)
{
    if (0 != dwFlags) {
        return E_INVALIDARG;
    }

    if (pCallback) {
        pCallback->AddRef();
    }
    if (m_pExclModeCallback) {
        m_pExclModeCallback->Release();
    }
    m_pExclModeCallback = pCallback;
    return S_OK;
}



/*****************************Private*Routine******************************\
* FormatSupported
*
*
*
* History:
* Mon 11/15/1999 - StEstrop - Created
*
\**************************************************************************/
bool
FormatSupported(
    DWORD dwFourCC
    )
{
    return dwFourCC == mmioFOURCC('Y', 'V', '1', '2') ||
           dwFourCC == mmioFOURCC('Y', 'U', 'Y', '2') ||
           dwFourCC == mmioFOURCC('U', 'Y', 'V', 'Y');
}


/******************************Public*Routine******************************\
* COMFilter::IsImageCaptureSupported
*
* Allow an app to determine ahead of time whether frame capture is possible
*
* History:
* Mon 11/15/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::IsImageCaptureSupported()
{
    AMTRACE((TEXT("COMFilter::IsImageCaptureSupported")));
    HRESULT hr = E_NOTIMPL;

    LPDIRECTDRAWSURFACE pOverlaySurface = NULL;
    CAutoLock l(&m_csFilter);

    CMediaType cMediaType;

    hr = m_apInput[0]->CurrentAdjustedMediaType(&cMediaType);
    if (SUCCEEDED(hr))
    {
        hr = m_apInput[0]->GetOverlaySurface(&pOverlaySurface);
        if (SUCCEEDED(hr))
        {
            DDSURFACEDESC ddsd;
            INITDDSTRUCT(ddsd);

            hr = pOverlaySurface->GetSurfaceDesc(&ddsd);
            if (SUCCEEDED(hr))
            {
                if (FormatSupported(ddsd.ddpfPixelFormat.dwFourCC))
                {
                    return S_OK;
                }
            }
        }
    }

    return S_FALSE;
}


/*****************************Private*Routine******************************\
* GetCurrentImage
*
*
*
* History:
* Wed 10/06/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::GetCurrentImage(
    YUV_IMAGE** lplpImage
    )
{
    AMTRACE((TEXT("COMFilter::GetCurrentImage")));
    HRESULT hr = E_NOTIMPL;

    LPDIRECTDRAWSURFACE pOverlaySurface = NULL;
    CAutoLock l(&m_csFilter);

    CMediaType cMediaType;

    hr = m_apInput[0]->CurrentAdjustedMediaType(&cMediaType);
    if (SUCCEEDED(hr)) {

        hr = m_apInput[0]->GetOverlaySurface(&pOverlaySurface);
        if (SUCCEEDED(hr)) {

            DDSURFACEDESC ddsd;
            INITDDSTRUCT(ddsd);

            hr = pOverlaySurface->GetSurfaceDesc(&ddsd);

            if (FAILED(hr) || !FormatSupported(ddsd.ddpfPixelFormat.dwFourCC))
            {
                return E_NOTIMPL;
            }


            DWORD dwImageSize = ddsd.dwHeight * ddsd.lPitch;

            YUV_IMAGE* lpImage =
                *lplpImage = (YUV_IMAGE*)CoTaskMemAlloc(
                    dwImageSize + sizeof(YUV_IMAGE));

            lpImage->lHeight     = ddsd.dwHeight;
            lpImage->lWidth      = ddsd.dwWidth;
            lpImage->lBitsPerPel = ddsd.ddpfPixelFormat.dwYUVBitCount;
            lpImage->lStride     = ddsd.lPitch;
            lpImage->dwFourCC    = ddsd.ddpfPixelFormat.dwFourCC;
            lpImage->dwImageSize = dwImageSize;

            GetPictAspectRatio(&cMediaType, (LPDWORD)&lpImage->lAspectX,
                               (LPDWORD)&lpImage->lAspectY);

            lpImage->dwFlags = DM_TOPDOWN_IMAGE;

            DWORD dwInterlaceFlags;
            GetInterlaceFlagsFromMediaType(&cMediaType, &dwInterlaceFlags);

            AM_RENDER_TRANSPORT amRT;
            m_apInput[0]->GetRenderTransport(&amRT);

            if (DisplayingFields(dwInterlaceFlags) || amRT == AM_VIDEOPORT) {
                lpImage->dwFlags |= DM_FIELD_IMAGE;
            }
            else {
                lpImage->dwFlags |= DM_FRAME_IMAGE;
            }

            INITDDSTRUCT(ddsd);
            while ((hr = pOverlaySurface->Lock(NULL, &ddsd, 0, NULL)) == DDERR_WASSTILLDRAWING)
                Sleep(1);

            if (hr == DD_OK)
            {
                LPBYTE lp = ((LPBYTE)lpImage) + sizeof(YUV_IMAGE);
                CopyMemory(lp, ddsd.lpSurface, dwImageSize);
                pOverlaySurface->Unlock(NULL);
            }
        }
    }

    return hr;
}

STDMETHODIMP COMFilter::GetVideoSize(LPDWORD pdwVideoWidth, LPDWORD pdwVideoHeight)
{
    HRESULT hr = NOERROR;
    CMediaType cMediaType;
    BITMAPINFOHEADER *pHeader = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::GetVideoSize")));

    if (!pdwVideoWidth || !pdwVideoHeight)
    {
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!m_apInput[0]->IsConnected())
    {
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    hr = m_apInput[0]->CurrentAdjustedMediaType(&cMediaType);
    ASSERT(SUCCEEDED(hr));
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_paInput[0]->CurrentAdjustedMediaType failed, hr = 0x%x"), hr));
        hr = E_FAIL;
        goto CleanUp;
    }

    // get the native width and height from the mediatype
    pHeader = GetbmiHeader(&cMediaType);
    ASSERT(pHeader);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        hr = E_FAIL;
        goto CleanUp;
    }

    *pdwVideoWidth = abs(pHeader->biWidth);
    *pdwVideoHeight = abs(pHeader->biHeight);

    // sanity checks
    ASSERT(*pdwVideoWidth > 0);
    ASSERT(*pdwVideoHeight > 0);

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::GetVideoSize")));
    return hr;
}

//  This is called by our container when they want us to draw
//  a frame
STDMETHODIMP COMFilter::OnDraw(HDC hdcDraw, LPCRECT prcDrawRect)
{
    HRESULT hr = NOERROR;

    m_hDC = hdcDraw;
    m_WinInfo.DestRect = *prcDrawRect;
    m_WinInfo.DestClipRect = *prcDrawRect;

    if (m_bWinInfoStored)
        OnDrawAll();
    m_hDC = NULL;

    return hr;
}

STDMETHODIMP COMFilter::SetDrawRegion(LPPOINT lpptTopLeftSC, LPCRECT prcDrawCC, LPCRECT prcClipCC)
{
    HRESULT hr = NOERROR;

    if (!prcDrawCC || !prcClipCC)
    {
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    memset(&m_WinInfo, 0, sizeof(WININFO));

#if 0
    if (lpptTopLeftSC)
    {
        m_WinInfo.TopLeftPoint = *lpptTopLeftSC;
    }
#endif

    SetRect(&m_WinInfo.SrcRect, 0, 0, m_dwAdjustedVideoWidth, m_dwAdjustedVideoHeight);
    m_WinInfo.DestRect = *prcDrawCC;
    m_WinInfo.DestClipRect = *prcClipCC;
    m_bWinInfoStored = TRUE;

CleanUp:
    return hr;
}



STDMETHODIMP COMFilter::Advise(IMixerOCXNotify *pmdns)
{
    HRESULT hr = NOERROR;

    if (!pmdns)
    {
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // Is there an advise link already defined
    if (m_pIMixerOCXNotify)
    {
        hr = VFW_E_ADVISE_ALREADY_SET;
        DbgLog((LOG_ERROR, 1, TEXT("m_pIMixerOCXNotify = 0x%x, returning hr = 0x%x"), m_pIMixerOCXNotify, hr));
        goto CleanUp;
    }

    hr = ConfirmPreConnectionState();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("filter not in preconnection state, hr = 0x%x"), hr));
        goto CleanUp;
    }

    m_pIMixerOCXNotify = pmdns;
    m_pIMixerOCXNotify->AddRef();

    // we know that we have only input pin. Ask it to use GDI and not to support
    // videoport or overlay connected. Also no aspect-ratio-correction needed
    ASSERT(m_apInput[0]);
    m_apInput[0]->SetRenderTransport(AM_GDI);
    m_apInput[m_dwInputPinCount-1]->SetIOverlaySupported(FALSE);
    m_apInput[m_dwInputPinCount-1]->SetVPSupported(FALSE);
    m_apInput[m_dwInputPinCount-1]->SetVideoAcceleratorSupported(FALSE);
    m_apInput[m_dwInputPinCount-1]->SetAspectRatioMode(AM_ARMODE_STRETCHED);

    // get rid of the output pin
    delete m_pOutput;
    m_pOutput = NULL;
    IncrementPinVersion();

    //  Right now windowless is synonymous with use GDI
    m_bWindowless = TRUE;
    m_bUseGDI = TRUE;

CleanUp:
    return hr;
}

STDMETHODIMP COMFilter::UnAdvise()
{
    HRESULT hr = NOERROR;

    if (m_pIMixerOCXNotify)
    {
        m_pIMixerOCXNotify->Release();
        m_pIMixerOCXNotify = NULL;
    }

    return hr;
}


// this is a function implemented solely to handle floating point rounding errors.
// dEpsilon defines the error margin. So if a floating point number is within I-e, I+e (inclusive)
// (I is an integer, e is dEpsilon), we return its floor as I itself, otherwise we go to the
// base defintion of myfloor
double myfloor(double dNumber, double dEpsilon)
{
    if (dNumber > dEpsilon)
        return myfloor(dNumber + dEpsilon);
    else if (dNumber < -dEpsilon)
        return myfloor(dNumber - dEpsilon);
    else
        return 0;
}

// have to define my own floor inorder to avoid pulling in the C runtime
double myfloor(double dNumber)
{
    // cast it to LONGLONG to get rid of the fraction
    LONGLONG llNumber = (LONGLONG)dNumber;

    if ((dNumber > 0) && ((double)llNumber > dNumber))
    {
        // need to push ccNumber towards zero (eg 5.7)
        return (double)(llNumber-1);
    }
    else if ((dNumber < 0) && ((double)llNumber < dNumber))
    {
        // need to push ccNumber towards zero (eg -5.7)
        return (double)(llNumber+1);
    }
    else
    {
        // numbers like 5.3 or -5.3
        return (double)(llNumber);
    }
}

// this is a function implemented solely to handle floating point rounding errors.
// dEpsilon defines the error margin. So if a floating point number is within I-e, I+e (inclusive)
// (I is an integer, e is dEpsilon), we return its ceil as I itself, otherwise we go to the
// base defintion of myceil
double myceil(double dNumber, double dEpsilon)
{
    if (dNumber > dEpsilon)
        return myceil(dNumber - dEpsilon);
    else if (dNumber < -dEpsilon)
        return myceil(dNumber + dEpsilon);
    else
        return 0;
}

// have to define my own ceil inorder to avoid pulling in the C runtime
double myceil(double dNumber)
{
    // cast it to LONGLONG to get rid of the fraction
    LONGLONG llNumber = (LONGLONG)dNumber;

    if ((dNumber > 0) && ((double)llNumber < dNumber))
    {
        // need to push ccNumber away from zero (eg 5.3)
        return (double)(llNumber+1);
    }
    else if ((dNumber < 0) && ((double)llNumber > dNumber))
    {
        // need to push ccNumber away from zero (eg -5.3)
        return (double)(llNumber-1);
    }
    else
    {
        // numbers like 5.7 or -5.7
        return (double)(llNumber);
    }
}

RECT CalcSubRect(const RECT *pRect, const RECT *pRelativeRect)
{
    long lDestWidth, lDestHeight;
    double dLeftFrac = 0.0, dRightFrac = 0.0, dTopFrac = 0.0, dBottomFrac = 0.0;
    RECT rSubRect;

    ASSERT(pRect);
    ASSERT(pRelativeRect);

    dLeftFrac = ((double)pRelativeRect->left) / ((double) MAX_REL_NUM);
    dTopFrac = ((double)pRelativeRect->top) / ((double) MAX_REL_NUM);
    dRightFrac = ((double)pRelativeRect->right) / ((double) MAX_REL_NUM);
    dBottomFrac = ((double)pRelativeRect->bottom) / ((double) MAX_REL_NUM);

    lDestWidth = pRect->right - pRect->left;
    lDestHeight = pRect->bottom - pRect->top;

    rSubRect.left = pRect->left + (long)(lDestWidth*dLeftFrac);
    rSubRect.right = pRect->left + (long)(lDestWidth*dRightFrac);
    rSubRect.top = pRect->top + (long)(lDestHeight*dTopFrac);
    rSubRect.bottom = pRect->top + (long)(lDestHeight*dBottomFrac);

    DbgLog((LOG_TRACE,2,TEXT("rSubRect = {%d, %d, %d, %d}"), rSubRect.left,
        rSubRect.top, rSubRect.right, rSubRect.bottom));

    return rSubRect;
}

void SetRect(DRECT *prdRect, LONG lLeft, LONG lTop, LONG lRight, LONG lBottom)
{
    ASSERT(prdRect);
    prdRect->left = (double)lLeft;
    prdRect->top = (double)lTop;
    prdRect->right = (double)lRight;
    prdRect->bottom = (double)lBottom;
}

// this function is only suitable for DRECTS whose coordinates are non-negative
RECT MakeRect(DRECT rdRect)
{
    RECT rRect;

    if (rdRect.left >= 0)
        rRect.left = (LONG)myceil(rdRect.left, EPSILON);
    else
        rRect.left = (LONG)myfloor(rdRect.left, EPSILON);

    if (rdRect.top >= 0)
        rRect.top = (LONG)myceil(rdRect.top, EPSILON);
    else
        rRect.top = (LONG)myfloor(rdRect.top, EPSILON);


    if (rdRect.right >= 0)
        rRect.right = (LONG)myfloor(rdRect.right, EPSILON);
    else
        rRect.right = (LONG)myceil(rdRect.right, EPSILON);


    if (rdRect.bottom >= 0)
        rRect.bottom = (LONG)myfloor(rdRect.bottom, EPSILON);
    else
        rRect.bottom = (LONG)myceil(rdRect.bottom, EPSILON);

    return rRect;
}

void DbgLogRect(DWORD dwLevel, LPCTSTR pszDebugString, const DRECT *prdRect)
{
    RECT rRect;
    rRect = MakeRect(*prdRect);
    DbgLogRect(dwLevel, pszDebugString, &rRect);
    return;
}

void DbgLogRect(DWORD dwLevel, LPCTSTR pszDebugString, const RECT *prRect)
{
    DbgLog((LOG_TRACE, dwLevel, TEXT("%s %d, %d, %d, %d"), pszDebugString, prRect->left, prRect->top, prRect->right, prRect->bottom));
    return;
}


double GetWidth(const DRECT *prdRect)
{
    ASSERT(prdRect);
    return (prdRect->right - prdRect->left);
}

double GetHeight(const DRECT *prdRect)
{
    ASSERT(prdRect);
    return (prdRect->bottom - prdRect->top);
}

BOOL IsRectEmpty(const DRECT *prdRect)
{
    BOOL bRetVal = FALSE;
    RECT rRect;

    ASSERT(prdRect);
    rRect = MakeRect(*prdRect);
    bRetVal = IsRectEmpty(&rRect);
    return bRetVal;
}

BOOL IntersectRect(DRECT *prdIRect, const DRECT *prdRect1, const DRECT *prdRect2)
{
    ASSERT(prdIRect);
    ASSERT(prdRect1);
    ASSERT(prdRect2);

    prdIRect->left = (prdRect1->left >= prdRect2->left) ? prdRect1->left : prdRect2->left;
    prdIRect->top = (prdRect1->top >= prdRect2->top) ? prdRect1->top : prdRect2->top;
    prdIRect->right = (prdRect1->right <= prdRect2->right) ? prdRect1->right : prdRect2->right;
    prdIRect->bottom = (prdRect1->bottom <= prdRect2->bottom) ? prdRect1->bottom : prdRect2->bottom;

    // if the two rects do not intersect, the above computations will result in a invalid rect
    if (prdIRect->right < prdIRect->left ||
        prdIRect->bottom < prdIRect->top)
    {
        SetRect(prdIRect, 0, 0, 0, 0);
        return FALSE;
    }
    return TRUE;
}

// just a helper function to scale a DRECT
void ScaleRect(DRECT *prdRect, double dOrigX, double dOrigY, double dNewX, double dNewY)
{
    ASSERT(prdRect);
    ASSERT(dOrigX > 0);
    ASSERT(dOrigY > 0);
    //ASSERT(dNewX > 0);
    //ASSERT(dNewY > 0);

    prdRect->left = prdRect->left * dNewX / dOrigX;
    prdRect->top = prdRect->top * dNewY / dOrigY;
    prdRect->right = prdRect->right * dNewX / dOrigX;
    prdRect->bottom = prdRect->bottom * dNewY / dOrigY;
}

// just a helper function to scale a RECT.
void ScaleRect(RECT *prRect, double dOrigX, double dOrigY, double dNewX, double dNewY)
{
    DRECT rdRect;

    ASSERT(prRect);
    ASSERT(dOrigX > 0);
    ASSERT(dOrigY > 0);
    //ASSERT(dNewX > 0);
    //ASSERT(dNewY > 0);

    SetRect(&rdRect, prRect->left, prRect->top, prRect->right, prRect->bottom);
    ScaleRect(&rdRect, dOrigX, dOrigY, dNewX, dNewY);
    *prRect = MakeRect(rdRect);
}

// just a helper function, to get the letterboxed or cropped rect
// Puts the transformed rectangle into pRect.
double TransformRect(DRECT *prdRect, double dPictAspectRatio, AM_TRANSFORM transform)
{
    double dWidth, dHeight, dNewWidth, dNewHeight;

    double dResolutionRatio = 0.0, dTransformRatio = 0.0;

    ASSERT(transform == AM_SHRINK || transform == AM_STRETCH);

    dNewWidth = dWidth = prdRect->right - prdRect->left;
    dNewHeight = dHeight = prdRect->bottom - prdRect->top;

    dResolutionRatio = dWidth / dHeight;
    dTransformRatio = dPictAspectRatio / dResolutionRatio;

    // shrinks one dimension to maintain the coorect aspect ratio
    if (transform == AM_SHRINK)
    {
        if (dTransformRatio > 1.0)
        {
            dNewHeight = dNewHeight / dTransformRatio;
        }
        else if (dTransformRatio < 1.0)
        {
            dNewWidth = dNewWidth * dTransformRatio;
        }
    }
    // stretches one dimension to maintain the coorect aspect ratio
    else if (transform == AM_STRETCH)
    {
        if (dTransformRatio > 1.0)
        {
            dNewWidth = dNewWidth * dTransformRatio;
        }
        else if (dTransformRatio < 1.0)
        {
            dNewHeight = dNewHeight / dTransformRatio;
        }
    }

    if (transform == AM_SHRINK)
    {
        ASSERT(dNewHeight <= dHeight);
        ASSERT(dNewWidth <= dWidth);
    }
    else
    {
        ASSERT(dNewHeight >= dHeight);
        ASSERT(dNewWidth >= dWidth);
    }

    // cut or add equal portions to the changed dimension

    prdRect->left += (dWidth - dNewWidth)/2.0;
    prdRect->right = prdRect->left + dNewWidth;

    prdRect->top += (dHeight - dNewHeight)/2.0;
    prdRect->bottom = prdRect->top + dNewHeight;

    return dTransformRatio;
}



// Just a helper function to calculate the part of the source rectangle
// that corresponds to the Clipped area of the destination rectangle
// Very useful for UpdateOverlay or blting functions.
HRESULT CalcSrcClipRect(const DRECT *prdSrcRect, DRECT *prdSrcClipRect,
                        const DRECT *prdDestRect, DRECT *prdDestClipRect)
{
    HRESULT hr = NOERROR;
    double dSrcToDestWidthRatio = 0.0, dSrcToDestHeightRatio = 0.0;
    DRECT rdSrcRect;

    DbgLog((LOG_TRACE,5,TEXT("Entering CalcSrcClipRect")));

    CheckPointer(prdDestRect, E_INVALIDARG);
    CheckPointer(prdDestClipRect, E_INVALIDARG);
    CheckPointer(prdSrcRect, E_INVALIDARG);
    CheckPointer(prdSrcClipRect, E_INVALIDARG);

    SetRect(&rdSrcRect, 0, 0, 0, 0);

    // initialize the prdSrcClipRect only if it is not the same as prdSrcRect
    if (prdSrcRect != prdSrcClipRect)
    {
        SetRect(prdSrcClipRect, 0, 0, 0, 0);
    }

    // Assert that none of the given rects are empty
    if (GetWidth(prdSrcRect) < 1 || GetHeight(prdSrcRect) < 1)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_ERROR,2,TEXT("prdSrcRect is invalid")));
        DbgLog((LOG_ERROR,2,TEXT("SrcRect = {%d, %d, %d, %d}"),
            prdSrcRect->left, prdSrcRect->top, prdSrcRect->right, prdSrcRect->bottom));
        goto CleanUp;
    }
    if (GetWidth(prdDestRect) < 1 || GetHeight(prdDestRect) < 1)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_TRACE,2,TEXT("pRect is NULL")));
        DbgLog((LOG_ERROR,2,TEXT("DestRect = {%d, %d, %d, %d}"),
            prdDestRect->left, prdDestRect->top, prdDestRect->right, prdDestRect->bottom));
        goto CleanUp;
    }

    // make a copy of the prdSrcRect incase prdSrcRect and prdSrcClipRect are the same pointers
    rdSrcRect = *prdSrcRect;

    // Assert that the dest clipping rect is not completely outside the dest rect
    if (IntersectRect(prdDestClipRect, prdDestRect, prdDestClipRect) == FALSE)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_TRACE,2,TEXT("IntersectRect of DestRect and DestClipRect returned FALSE")));
        goto CleanUp;
    }

    // Calculate the source to destination width and height ratios
    dSrcToDestWidthRatio = GetWidth(&rdSrcRect) / GetWidth(prdDestRect);
    dSrcToDestHeightRatio = GetHeight(&rdSrcRect) / GetHeight(prdDestRect);

    // From the dest section visible calculate the source required
    prdSrcClipRect->left = rdSrcRect.left + ((prdDestClipRect->left - prdDestRect->left) * dSrcToDestWidthRatio);
    prdSrcClipRect->right = rdSrcRect.left + ((prdDestClipRect->right - prdDestRect->left) * dSrcToDestWidthRatio);
    prdSrcClipRect->top = rdSrcRect.top + ((prdDestClipRect->top - prdDestRect->top) * dSrcToDestHeightRatio);
    prdSrcClipRect->bottom = rdSrcRect.top + ((prdDestClipRect->bottom - prdDestRect->top) * dSrcToDestHeightRatio);

    // Check we have a valid source rectangle
    if (IsRectEmpty(prdSrcClipRect))
    {
        DbgLog((LOG_TRACE,1,TEXT("SrcClipRect is empty, UNEXPECTED!!")));
    }

    DbgLog((LOG_TRACE,5,TEXT("DestRect = {%d, %d, %d, %d}"),
        prdDestRect->left, prdDestRect->top, prdDestRect->right, prdDestRect->bottom));
    DbgLog((LOG_TRACE,5,TEXT("DestClipRect = {%d, %d, %d, %d}"),
        prdDestClipRect->left, prdDestClipRect->top, prdDestClipRect->right, prdDestClipRect->bottom));
    DbgLog((LOG_TRACE,5,TEXT("SrcRect = {%d, %d, %d, %d}"),
        rdSrcRect.left, rdSrcRect.top, rdSrcRect.right, rdSrcRect.bottom));
    DbgLog((LOG_TRACE,5,TEXT("SrcClipRect = {%d, %d, %d, %d}"),
        prdSrcClipRect->left, prdSrcClipRect->top, prdSrcClipRect->right, prdSrcClipRect->bottom));

CleanUp:
    DbgLog((LOG_TRACE,5,TEXT("Leaving CalcSrcClipRect")));
    return hr;
}

// Just a helper function to calculate the part of the source rectangle
// that corresponds to the Clipped area of the destination rectangle
// Very useful for UpdateOverlay or blting functions.
HRESULT CalcSrcClipRect(const RECT *pSrcRect, RECT *pSrcClipRect,
                        const RECT *pDestRect, RECT *pDestClipRect,
                        BOOL bMaintainRatio)
{
    HRESULT hr = NOERROR;
    double dSrcToDestWidthRatio = 0.0, dSrcToDestHeightRatio = 0.0;
    RECT rSrcRect;

    DbgLog((LOG_TRACE,5,TEXT("Entering CalcSrcClipRect")));

    CheckPointer(pDestRect, E_INVALIDARG);
    CheckPointer(pDestClipRect, E_INVALIDARG);
    CheckPointer(pSrcRect, E_INVALIDARG);
    CheckPointer(pSrcClipRect, E_INVALIDARG);

    SetRect(&rSrcRect, 0, 0, 0, 0);

    // initialize the prdSrcClipRect only if it is not the same as prdSrcRect
    if (pSrcRect != pSrcClipRect)
    {
        SetRect(pSrcClipRect, 0, 0, 0, 0);
    }

    // Assert that none of the given rects are empty
    if (WIDTH(pSrcRect) == 0 || HEIGHT(pSrcRect) == 0)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_ERROR,2,TEXT("pSrcRect is invalid")));
        DbgLog((LOG_ERROR,2,TEXT("SrcRect = {%d, %d, %d, %d}"),
            pSrcRect->left, pSrcRect->top, pSrcRect->right, pSrcRect->bottom));
        goto CleanUp;
    }
    if (WIDTH(pDestRect) == 0 || HEIGHT(pDestRect) == 0)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_TRACE,2,TEXT("pRect is NULL")));
        DbgLog((LOG_ERROR,2,TEXT("DestRect = {%d, %d, %d, %d}"),
            pDestRect->left, pDestRect->top, pDestRect->right, pDestRect->bottom));
        goto CleanUp;
    }

    // make a copy of the pSrcRect incase pSrcRect and pSrcClipRect are the same pointers
    rSrcRect = *pSrcRect;
    // Assert that the dest clipping rect is not completely outside the dest rect
    if (IntersectRect(pDestClipRect,pDestRect, pDestClipRect) == FALSE)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_TRACE,2,TEXT("IntersectRect of DestRect and DestClipRect returned FALSE")));
        goto CleanUp;
    }

    // Calculate the source to destination width and height ratios
    dSrcToDestWidthRatio = ((double) (WIDTH(&rSrcRect))) / ((double) (WIDTH(pDestRect)));
    dSrcToDestHeightRatio = ((double) (HEIGHT(&rSrcRect))) / ((double) (HEIGHT(pDestRect)));

    // From the dest section visible calculate the source required
    if (bMaintainRatio)
    {
        DRECT rdSrcClipRect;
        rdSrcClipRect.left = (double)rSrcRect.left +
            ((double)(pDestClipRect->left - pDestRect->left)) * dSrcToDestWidthRatio;
        rdSrcClipRect.right = (double)rSrcRect.left +
            ((double)(pDestClipRect->right - pDestRect->left)) * dSrcToDestWidthRatio;
        rdSrcClipRect.top = (double)rSrcRect.top +
            ((double)(pDestClipRect->top - pDestRect->top)) * dSrcToDestHeightRatio;
        rdSrcClipRect.bottom = (double)rSrcRect.top +
            ((double)(pDestClipRect->bottom - pDestRect->top)) * dSrcToDestHeightRatio;
        *pSrcClipRect = MakeRect(rdSrcClipRect);
    }
    else
    {
        pSrcClipRect->left = rSrcRect.left +
            (LONG)(((double)(pDestClipRect->left - pDestRect->left)) * dSrcToDestWidthRatio);
        pSrcClipRect->right = rSrcRect.left +
            (LONG)(((double)(pDestClipRect->right - pDestRect->left)) * dSrcToDestWidthRatio);
        pSrcClipRect->top = rSrcRect.top +
            (LONG)(((double)(pDestClipRect->top - pDestRect->top)) * dSrcToDestHeightRatio);
        pSrcClipRect->bottom = rSrcRect.top +
            (LONG)(((double)(pDestClipRect->bottom - pDestRect->top)) * dSrcToDestHeightRatio);
    }

    // Check we have a valid source rectangle
    if (IsRectEmpty(pSrcClipRect))
    {
        DbgLog((LOG_TRACE,5,TEXT("SrcClipRect is empty, UNEXPECTED!!")));
    }

    DbgLog((LOG_TRACE,5,TEXT("DestRect = {%d, %d, %d, %d}"),
        pDestRect->left, pDestRect->top, pDestRect->right, pDestRect->bottom));
    DbgLog((LOG_TRACE,5,TEXT("DestClipRect = {%d, %d, %d, %d}"),
        pDestClipRect->left, pDestClipRect->top, pDestClipRect->right, pDestClipRect->bottom));
    DbgLog((LOG_TRACE,5,TEXT("SrcRect = {%d, %d, %d, %d}"),
        rSrcRect.left, rSrcRect.top, rSrcRect.right, rSrcRect.bottom));
    DbgLog((LOG_TRACE,5,TEXT("SrcClipRect = {%d, %d, %d, %d}"),
        pSrcClipRect->left, pSrcClipRect->top, pSrcClipRect->right, pSrcClipRect->bottom));

CleanUp:
    DbgLog((LOG_TRACE,5,TEXT("Leaving CalcSrcClipRect")));
    return hr;
}

HRESULT AlignOverlaySrcDestRects(LPDDCAPS pddDirectCaps, RECT *pSrcRect, RECT *pDestRect)
{
    HRESULT hr = NOERROR;
    DWORD dwNewSrcWidth = 0, dwTemp = 0;
    double dOldZoomFactorX = 0.0, dNewZoomFactorX = 0.0;

    DbgLog((LOG_TRACE, 5, TEXT("Entering COMFilter::AllignOverlaySrcDestRects")));

    if (!pSrcRect)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pSrcRect = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pDestRect)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pSrcRect = NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // Assert that none of the given rects are empty
    if (WIDTH(pSrcRect) == 0 || WIDTH(pDestRect) == 0)
    {
        hr = E_INVALIDARG;
        DbgLog((LOG_ERROR,2,TEXT("one of the rects is empty")));
        DbgLog((LOG_ERROR,2,TEXT("SrcRect = {%d, %d, %d, %d}"),
            pSrcRect->left, pSrcRect->top, pSrcRect->right, pSrcRect->bottom));
        DbgLog((LOG_ERROR,2,TEXT("DestRect = {%d, %d, %d, %d}"),
            pDestRect->left, pDestRect->top, pDestRect->right, pDestRect->bottom));
        goto CleanUp;
    }

    dOldZoomFactorX = ((double) WIDTH(pDestRect)) / ((double) WIDTH(pSrcRect));

    // align the dest boundary (remember we can only decrease the DestRect.left). Use of colorkey will make sure that
    // that we are clipped properly.
    if ((pddDirectCaps->dwCaps) & DDCAPS_ALIGNBOUNDARYDEST)
    {
        dwTemp = pDestRect->left & (pddDirectCaps->dwAlignBoundaryDest-1);
        pDestRect->left -= dwTemp;
        ASSERT(pDestRect->left >= 0);
    }

    // align the dest width (remember we can only increase the DestRect.right). Use of colorkey will make sure that
    // that we are clipped properly.
    if ((pddDirectCaps->dwCaps) & DDCAPS_ALIGNSIZEDEST)
    {
        dwTemp = (pDestRect->right - pDestRect->left) & (pddDirectCaps->dwAlignSizeDest-1);
        if (dwTemp != 0)
        {
            pDestRect->right += pddDirectCaps->dwAlignBoundaryDest - dwTemp;
        }
    }

    // align the src boundary (remember we can only increase the SrcRect.left)
    if ((pddDirectCaps->dwCaps) & DDCAPS_ALIGNBOUNDARYSRC)
    {
        dwTemp = pSrcRect->left & (pddDirectCaps->dwAlignBoundarySrc-1);
        if (dwTemp != 0)
        {
            pSrcRect->left += pddDirectCaps->dwAlignBoundarySrc - dwTemp;
        }
    }

    // align the src width (remember we can only decrease the SrcRect.right)
    if ((pddDirectCaps->dwCaps) & DDCAPS_ALIGNSIZESRC)
    {
        dwTemp = (pSrcRect->right - pSrcRect->left) & (pddDirectCaps->dwAlignSizeSrc-1);
        pSrcRect->right -= dwTemp;
    }

    // It is possible that one of the rects became empty at this point
    if (WIDTH(pSrcRect) == 0 || WIDTH(pDestRect) == 0)
    {
        DbgLog((LOG_ERROR,2,TEXT("one of the rects is empty")));
        DbgLog((LOG_ERROR,2,TEXT("SrcRect = {%d, %d, %d, %d}"),
            pSrcRect->left, pSrcRect->top, pSrcRect->right, pSrcRect->bottom));
        DbgLog((LOG_ERROR,2,TEXT("DestRect = {%d, %d, %d, %d}"),
            pDestRect->left, pDestRect->top, pDestRect->right, pDestRect->bottom));
        goto CleanUp;
    }

    dNewZoomFactorX = ((double) WIDTH(pDestRect)) / ((double) WIDTH(pSrcRect));

//    ASSERT(dNewZoomFactorX >= dOldZoomFactorX);

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving COMFilter::AllignOverlaySrcDestRects")));
    return hr;
}


// convert a RGB color to a pysical color.
// we do this by leting GDI SetPixel() do the color matching
// then we lock the memory and see what it got mapped to.
DWORD DDColorMatch(IDirectDrawSurface *pdds, COLORREF rgb, HRESULT& hr)
{
    COLORREF rgbT;
    HDC hdc;
    DWORD dw = CLR_INVALID;
    DDSURFACEDESC ddsd;

    hr = NOERROR;
    //  use GDI SetPixel to color match for us
    if (rgb != CLR_INVALID && pdds->GetDC(&hdc) == DD_OK)
    {
        rgbT = GetPixel(hdc, 0, 0);             // save current pixel value
        SetPixel(hdc, 0, 0, rgb);               // set our value
        pdds->ReleaseDC(hdc);
    }

    // now lock the surface so we can read back the converted color
    ddsd.dwSize = sizeof(ddsd);
    while ((hr = pdds->Lock(NULL, &ddsd, 0, NULL)) == DDERR_WASSTILLDRAWING)
        ;

    if (hr == DD_OK)
    {
        // get DWORD
        dw  = *(DWORD *)ddsd.lpSurface;

        // mask it to bpp
        if (ddsd.ddpfPixelFormat.dwRGBBitCount < 32)
            dw &= (1 << ddsd.ddpfPixelFormat.dwRGBBitCount)-1;
        pdds->Unlock(NULL);
    }

    //  now put the color that was there back.
    if (rgb != CLR_INVALID && pdds->GetDC(&hdc) == DD_OK)
    {
        SetPixel(hdc, 0, 0, rgbT);
        pdds->ReleaseDC(hdc);
    }

    return dw;
}

// convert a RGB color to a pysical color.
// we do this by leting GDI SetPixel() do the color matching
// then we lock the memory and see what it got mapped to.
DWORD DDColorMatchOffscreen(
    IDirectDraw *pdd,
    COLORREF rgb,
    HRESULT& hr
    )
{
    COLORREF rgbT;
    HDC hdc;
    DWORD dw = CLR_INVALID;
    DDSURFACEDESC ddsd;
    IDirectDrawSurface* pdds;

    hr = NOERROR;
    INITDDSTRUCT(ddsd);
    ddsd.dwFlags = DDSD_CAPS | DDSD_HEIGHT | DDSD_WIDTH;
    ddsd.ddsCaps.dwCaps = DDSCAPS_OFFSCREENPLAIN;
    ddsd.dwWidth = 16;
    ddsd.dwHeight = 16;
    hr = pdd->CreateSurface(&ddsd, &pdds, NULL);
    if (hr != DD_OK) {
        return 0;
    }

    //  use GDI SetPixel to color match for us
    if (rgb != CLR_INVALID && pdds->GetDC(&hdc) == DD_OK)
    {
        rgbT = GetPixel(hdc, 0, 0);             // save current pixel value
        SetPixel(hdc, 0, 0, rgb);               // set our value
        pdds->ReleaseDC(hdc);
    }

    // now lock the surface so we can read back the converted color
    INITDDSTRUCT(ddsd);
    while ((hr = pdds->Lock(NULL, &ddsd, 0, NULL)) == DDERR_WASSTILLDRAWING)
        ;

    if (hr == DD_OK)
    {
        // get DWORD
        dw  = *(DWORD *)ddsd.lpSurface;

        // mask it to bpp
        if (ddsd.ddpfPixelFormat.dwRGBBitCount < 32)
            dw &= (1 << ddsd.ddpfPixelFormat.dwRGBBitCount)-1;
        pdds->Unlock(NULL);
    }

    //  now put the color that was there back.
    if (rgb != CLR_INVALID && pdds->GetDC(&hdc) == DD_OK)
    {
        SetPixel(hdc, 0, 0, rgbT);
        pdds->ReleaseDC(hdc);
    }

    pdds->Release();

    hr = NOERROR;
    return dw;
}

BITMAPINFOHEADER *GetbmiHeader(const CMediaType *pMediaType)
{
    BITMAPINFOHEADER *pHeader = NULL;

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        goto CleanUp;
    }

    if (!(pMediaType->pbFormat))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType->pbFormat is NULL")));
        goto CleanUp;
    }

    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        pHeader = &(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->bmiHeader);
        goto CleanUp;
    }


    if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))

    {
        pHeader = &(((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->bmiHeader);
        goto CleanUp;
    }
CleanUp:
    return pHeader;
}

// Return the bit masks for the true colour VIDEOINFO or VIDEOINFO2 provided
const DWORD *GetBitMasks(const CMediaType *pMediaType)
{
    BITMAPINFOHEADER *pHeader = NULL;
    static DWORD FailMasks[] = {0,0,0};
    const DWORD *pdwBitMasks = NULL;

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        goto CleanUp;
    }

    pHeader = GetbmiHeader(pMediaType);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        goto CleanUp;
    }

    if (pHeader->biCompression != BI_RGB)
    {
        pdwBitMasks = (const DWORD *)((LPBYTE)pHeader + pHeader->biSize);
        goto CleanUp;

    }

    ASSERT(pHeader->biCompression == BI_RGB);
    switch (pHeader->biBitCount)
    {
    case 16:
        {
            pdwBitMasks = bits555;
            break;
        }
    case 24:
        {
            pdwBitMasks = bits888;
            break;
        }

    case 32:
        {
            pdwBitMasks = bits888;
            break;
        }
    default:
        {
            pdwBitMasks = FailMasks;
            break;
        }
    }

CleanUp:
    return pdwBitMasks;
}

// Return the pointer to the byte after the header
BYTE* GetColorInfo(const CMediaType *pMediaType)
{
    BITMAPINFOHEADER *pHeader = NULL;
    BYTE *pColorInfo = NULL;

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        goto CleanUp;
    }

    pHeader = GetbmiHeader(pMediaType);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        goto CleanUp;
    }

    pColorInfo = ((LPBYTE)pHeader + pHeader->biSize);

CleanUp:
    return pColorInfo;
}

// checks whether the mediatype is palettised or not
HRESULT IsPalettised(const CMediaType *pMediaType, BOOL *pPalettised)
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pHeader = NULL;

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pPalettised)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pPalettised is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    pHeader = GetbmiHeader(pMediaType);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        hr = E_FAIL;
        goto CleanUp;
    }

    if (pHeader->biBitCount <= iPALETTE)
        *pPalettised = TRUE;
    else
        *pPalettised = FALSE;

CleanUp:
    return hr;
}

HRESULT GetPictAspectRatio(const CMediaType *pMediaType, DWORD *pdwPictAspectRatioX, DWORD *pdwPictAspectRatioY)
{
    HRESULT hr = NOERROR;

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!(pMediaType->pbFormat))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType->pbFormat is NULL")));
        goto CleanUp;
    }

    if (!pdwPictAspectRatioX)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pdwPictAspectRatioX is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pdwPictAspectRatioY)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pdwPictAspectRatioY is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }


    if ((pMediaType->formattype == FORMAT_VideoInfo) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER)))
    {
        *pdwPictAspectRatioX = abs(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->bmiHeader.biWidth);
        *pdwPictAspectRatioY = abs(((VIDEOINFOHEADER*)(pMediaType->pbFormat))->bmiHeader.biHeight);
        goto CleanUp;
    }

    if ((pMediaType->formattype == FORMAT_VideoInfo2) &&
        (pMediaType->cbFormat >= sizeof(VIDEOINFOHEADER2)))
    {
        *pdwPictAspectRatioX = ((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->dwPictAspectRatioX;
        *pdwPictAspectRatioY = ((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->dwPictAspectRatioY;
        goto CleanUp;
    }

CleanUp:
    return hr;
}



// get the InterlaceFlags from the mediatype. If the format is VideoInfo, it returns
// the flags as zero.
HRESULT GetInterlaceFlagsFromMediaType(const CMediaType *pMediaType, DWORD *pdwInterlaceFlags)
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pHeader = NULL;

    DbgLog((LOG_TRACE, 5, TEXT("Entering GetInterlaceFlagsFromMediaType")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pdwInterlaceFlags)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pRect is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // get the header just to make sure the mediatype is ok
    pHeader = GetbmiHeader(pMediaType);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (pMediaType->formattype == FORMAT_VideoInfo)
    {
        *pdwInterlaceFlags = 0;
    }
    else if (pMediaType->formattype == FORMAT_VideoInfo2)
    {
        *pdwInterlaceFlags = ((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->dwInterlaceFlags;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving GetInterlaceFlagsFromMediaType")));
    return hr;
}


// get the rcSource from the mediatype
// if rcSource is empty, it means take the whole image
HRESULT GetSrcRectFromMediaType(const CMediaType *pMediaType, RECT *pRect)
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pHeader = NULL;
    LONG dwWidth = 0, dwHeight = 0;

    DbgLog((LOG_TRACE, 5, TEXT("Entering GetSrcRectFromMediaType")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pRect)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pRect is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    pHeader = GetbmiHeader(pMediaType);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    dwWidth = abs(pHeader->biWidth);
    dwHeight = abs(pHeader->biHeight);

    ASSERT((pMediaType->formattype == FORMAT_VideoInfo) || (pMediaType->formattype == FORMAT_VideoInfo2));

    if (pMediaType->formattype == FORMAT_VideoInfo)
    {
        *pRect = ((VIDEOINFOHEADER*)(pMediaType->pbFormat))->rcSource;
    }
    else if (pMediaType->formattype == FORMAT_VideoInfo2)
    {
        *pRect = ((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->rcSource;
    }

    DWORD dwInterlaceFlags;
    if (SUCCEEDED(GetInterlaceFlagsFromMediaType(pMediaType, &dwInterlaceFlags)) &&
       DisplayingFields(dwInterlaceFlags)) {

        // we do not check if pRect->right > dwWidth, because the dwWidth might be the
        // pitch at this time
        if (pRect->left < 0   ||
            pRect->top < 0    ||
            pRect->right < 0   ||
            (pRect->bottom / 2) > (LONG)dwHeight ||
            pRect->left > pRect->right ||
            pRect->top > pRect->bottom)
        {
            DbgLog((LOG_ERROR, 1, TEXT("rcSource of mediatype is invalid")));
            hr = E_INVALIDARG;
            goto CleanUp;
        }
    }
    else {
        // we do not check if pRect->right > dwWidth, because the dwWidth might be the
        // pitch at this time
        if (pRect->left < 0   ||
            pRect->top < 0    ||
            pRect->right < 0   ||
            pRect->bottom > (LONG)dwHeight ||
            pRect->left > pRect->right ||
            pRect->top > pRect->bottom)
        {
            DbgLog((LOG_ERROR, 1, TEXT("rcSource of mediatype is invalid")));
            hr = E_INVALIDARG;
            goto CleanUp;
        }
    }

    // An empty rect means the whole image, Yuck!
    if (IsRectEmpty(pRect))
        SetRect(pRect, 0, 0, dwWidth, dwHeight);

    // if either the width or height is zero then better set the whole
    // rect to be empty so that the callee can catch it that way
    if (WIDTH(pRect) == 0 || HEIGHT(pRect) == 0)
        SetRect(pRect, 0, 0, 0, 0);

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving GetSrcRectFromMediaType")));
    return hr;
}

// get the rcTarget from the mediatype, after converting it to base MAX_REL_NUM
// if rcTarget is empty, it means take the whole image
HRESULT GetDestRectFromMediaType(const CMediaType *pMediaType, RECT *pRect)
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pHeader = NULL;
    LONG dwWidth = 0, dwHeight = 0;

    DbgLog((LOG_TRACE, 5, TEXT("Entering GetDestRectFromMediaType")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (!pRect)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pRect is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    pHeader = GetbmiHeader(pMediaType);
    if (!pHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pHeader is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    dwWidth = abs(pHeader->biWidth);
    dwHeight = abs(pHeader->biHeight);

    ASSERT((pMediaType->formattype == FORMAT_VideoInfo) || (pMediaType->formattype == FORMAT_VideoInfo2));

    if (pMediaType->formattype == FORMAT_VideoInfo)
    {
        *pRect = ((VIDEOINFOHEADER*)(pMediaType->pbFormat))->rcTarget;
    }
    else if (pMediaType->formattype == FORMAT_VideoInfo2)
    {
        *pRect = ((VIDEOINFOHEADER2*)(pMediaType->pbFormat))->rcTarget;
    }

    DWORD dwInterlaceFlags;
    if (SUCCEEDED(GetInterlaceFlagsFromMediaType(pMediaType, &dwInterlaceFlags)) &&
       DisplayingFields(dwInterlaceFlags)) {

        // we do not check if pRect->right > dwWidth, because the dwWidth might be the
        // pitch at this time
        if (pRect->left < 0   ||
            pRect->top < 0    ||
            pRect->right < 0   ||
            (pRect->bottom / 2) > (LONG)dwHeight ||
            pRect->left > pRect->right ||
            pRect->top > pRect->bottom)
        {
            DbgLog((LOG_ERROR, 1, TEXT("rcTarget of mediatype is invalid")));
            SetRect(pRect, 0, 0, dwWidth, dwHeight);
            hr = E_INVALIDARG;
            goto CleanUp;
        }
    }
    else {
        // we do not check if pRect->right > dwWidth, because the dwWidth might be the
        // pitch at this time
        if (pRect->left < 0   ||
            pRect->top < 0    ||
            pRect->right < 0   ||
            pRect->bottom > (LONG)dwHeight ||
            pRect->left > pRect->right ||
            pRect->top > pRect->bottom)
        {
            DbgLog((LOG_ERROR, 1, TEXT("rcTarget of mediatype is invalid")));
            SetRect(pRect, 0, 0, dwWidth, dwHeight);
            hr = E_INVALIDARG;
            goto CleanUp;
        }
    }

    // An empty rect means the whole image, Yuck!
    if (IsRectEmpty(pRect))
        SetRect(pRect, 0, 0, dwWidth, dwHeight);

    // if either the width or height is zero then better set the whole
    // rect to be empty so that the callee can catch it that way
    if (WIDTH(pRect) == 0 || HEIGHT(pRect) == 0)
        SetRect(pRect, 0, 0, 0, 0);

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving GetDestRectFromMediaType")));
    return hr;
}

// this function computes scaling and cropping rects from the src/dest rects in the mediatype
//
// RobinSp:
//     The scaling rectangle is just the image of the full source
//     rectangle when transformed by the affine transform that takes
//     the actual media type's source rectangle into the
//     media type's destination rectangle:
//
//     This should be rewritten:
//     *prdScaledRect = XForm(rcSource, rcTarget)(0, 0, bmHeader.dwWidth, bmiHeader.dwHeight)
//
//     The cropping rectangle is exactly the destination rectangle so
//     I'm not sure what the code below is doing.
//
HRESULT GetScaleCropRectsFromMediaType(const CMediaType *pMediaType, DRECT *prdScaledRect, DRECT *prdCroppedRect)
{
    HRESULT hr = NOERROR;
    RECT rSrc, rTarget;
    DRECT rdScaled, rdCropped;
    DWORD dwImageWidth = 0, dwImageHeight = 0;
    double Sx = 0.0, Sy = 0.0;
    BITMAPINFOHEADER *pHeader = NULL;
    double dLeftFrac = 0.0, dRightFrac = 0.0, dTopFrac = 0.0, dBottomFrac = 0.0;

    DbgLog((LOG_TRACE, 5, TEXT("Entering GetScaleCropRectsFromMediaType")));

    if (!pMediaType)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pMediaType is NULL")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    SetRect(&rSrc, 0, 0, 0, 0);
    SetRect(&rTarget, 0, 0, 0, 0);
    SetRect(&rdScaled, 0, 0, 0, 0);
    SetRect(&rdCropped, 0, 0, 0, 0);

    // get the source rect from the current mediatype
    hr = GetSrcRectFromMediaType(pMediaType, &rSrc);
    ASSERT(SUCCEEDED(hr));

    DbgLogRectMacro((2, TEXT("rSrc = "), &rSrc));


    // get the dest specified by the mediatype
    hr = GetDestRectFromMediaType(pMediaType, &rTarget);
    if ( FAILED(hr) )
        goto CleanUp;

    DbgLogRectMacro((2, TEXT("rTarget = "), &rTarget));

    pHeader = GetbmiHeader(pMediaType);
    if ( NULL == pHeader )
    {
        hr = E_INVALIDARG;
        goto CleanUp;
    }
    dwImageWidth = abs(pHeader->biWidth);
    dwImageHeight = abs(pHeader->biHeight);

    Sx = ((double)(rTarget.right - rTarget.left)) / ((double)(rSrc.right - rSrc.left));
    Sy = ((double)(rTarget.bottom - rTarget.top)) / ((double)(rSrc.bottom - rSrc.top));

    DbgLog((LOG_ERROR, 2, TEXT("Sx * 1000 = %d"), (DWORD)(Sx*1000.0)));
    DbgLog((LOG_ERROR, 2, TEXT("Sy * 1000 = %d"), (DWORD)(Sy*1000.0)));

    rdScaled.left = rTarget.left - (double)rSrc.left * Sx;
    rdScaled.top = rTarget.top - (double)rSrc.top * Sy;
    rdScaled.right = rdScaled.left + (double)dwImageWidth * Sx;
    rdScaled.bottom = rdScaled.top  + (double)dwImageHeight * Sy;

    DbgLogRectMacro((2, TEXT("rdScaled = "), &rdScaled));

    dLeftFrac = ((double)rSrc.left) / ((double) dwImageWidth);
    dTopFrac = ((double)rSrc.top) / ((double) dwImageHeight);
    dRightFrac = ((double)rSrc.right) / ((double) dwImageWidth);
    dBottomFrac = ((double)rSrc.bottom) / ((double) dwImageHeight);

    rdCropped.left = rdScaled.left + GetWidth(&rdScaled)*dLeftFrac;
    rdCropped.right = rdScaled.left + GetWidth(&rdScaled)*dRightFrac;
    rdCropped.top = rdScaled.top + GetHeight(&rdScaled)*dTopFrac;
    rdCropped.bottom = rdScaled.top + GetHeight(&rdScaled)*dBottomFrac;

    DbgLogRectMacro((2, TEXT("rdCropped = "), &rdCropped));

    if (prdScaledRect)
    {
        *prdScaledRect = rdScaled;
    }

    if (prdCroppedRect)
    {
        *prdCroppedRect = rdCropped;
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving GetScaleCropRectsFromMediaType")));
    return hr;
}


// this also comes in useful when using the IEnumMediaTypes interface so
// that you can copy a media type, you can do nearly the same by creating
// a CMediaType object but as soon as it goes out of scope the destructor
// will delete the memory it allocated (this takes a copy of the memory)

AM_MEDIA_TYPE * WINAPI AllocVideoMediaType(const AM_MEDIA_TYPE * pmtSource, GUID formattype)
{
    DWORD dwFormatSize = 0;
    BYTE *pFormatPtr = NULL;
    AM_MEDIA_TYPE *pMediaType = NULL;
    HRESULT hr = NOERROR;

    if (formattype == FORMAT_VideoInfo)
        dwFormatSize = sizeof(VIDEOINFO);
    else if (formattype == FORMAT_VideoInfo2)
        dwFormatSize = sizeof(TRUECOLORINFO) + sizeof(VIDEOINFOHEADER2) + 4;    // actually this should be sizeof sizeof(VIDEOINFO2) once we define that

    pMediaType = (AM_MEDIA_TYPE *)CoTaskMemAlloc(sizeof(AM_MEDIA_TYPE));
    if (!pMediaType)
    {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    pFormatPtr = (BYTE *)CoTaskMemAlloc(dwFormatSize);
    if (!pFormatPtr)
    {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    if (pmtSource)
    {
        *pMediaType = *pmtSource;
        pMediaType->cbFormat = dwFormatSize;
        CopyMemory(pFormatPtr, pmtSource->pbFormat, pmtSource->cbFormat);
    }
    else
    {
        ZeroMemory(pMediaType, sizeof(*pMediaType));
        ZeroMemory(pFormatPtr, dwFormatSize);
        pMediaType->majortype = MEDIATYPE_Video;
        pMediaType->formattype = formattype;
        pMediaType->cbFormat = dwFormatSize;
    }
    pMediaType->pbFormat = pFormatPtr;

CleanUp:
    if (FAILED(hr))
    {
        if (pMediaType)
        {
            CoTaskMemFree((PVOID)pMediaType);
            pMediaType = NULL;
        }
        if (!pFormatPtr)
        {
            CoTaskMemFree((PVOID)pFormatPtr);
            pFormatPtr = NULL;
        }
    }
    return pMediaType;
}

// Helper function converts a DirectDraw surface to a media type.
// The surface description must have:
//  Height
//  Width
//  lPitch
//  PixelFormat

// Initialise our output type based on the DirectDraw surface. As DirectDraw
// only deals with top down display devices so we must convert the height of
// the surface returned in the DDSURFACEDESC into a negative height. This is
// because DIBs use a positive height to indicate a bottom up image. We also
// initialise the other VIDEOINFO fields although they're hardly ever needed

AM_MEDIA_TYPE *ConvertSurfaceDescToMediaType(const LPDDSURFACEDESC pSurfaceDesc, BOOL bInvertSize, CMediaType cMediaType)
{
    HRESULT hr = NOERROR;
    AM_MEDIA_TYPE *pMediaType = NULL;
    BITMAPINFOHEADER *pbmiHeader = NULL;
    int bpp = 0;

    if ((*cMediaType.FormatType() != FORMAT_VideoInfo ||
        cMediaType.FormatLength() < sizeof(VIDEOINFOHEADER)) &&
        (*cMediaType.FormatType() != FORMAT_VideoInfo2 ||
        cMediaType.FormatLength() < sizeof(VIDEOINFOHEADER2)))
    {
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    pMediaType = AllocVideoMediaType(&cMediaType, cMediaType.formattype);
    if (pMediaType == NULL)
    {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    pbmiHeader = GetbmiHeader((const CMediaType*)pMediaType);
    if (!pbmiHeader)
    {
        DbgLog((LOG_ERROR, 1, TEXT("pbmiHeader is NULL, UNEXPECTED!!")));
        hr = E_FAIL;
        goto CleanUp;
    }

    // Convert a DDSURFACEDESC into a BITMAPINFOHEADER (see notes later). The
    // bit depth of the surface can be retrieved from the DDPIXELFORMAT field
    // in the DDpSurfaceDesc-> The documentation is a little misleading because
    // it says the field is permutations of DDBD_*'s however in this case the
    // field is initialised by DirectDraw to be the actual surface bit depth

    pbmiHeader->biSize = sizeof(BITMAPINFOHEADER);

    if (pSurfaceDesc->dwFlags & DDSD_PITCH)
    {
        pbmiHeader->biWidth = pSurfaceDesc->lPitch;
        // Convert the pitch from a byte count to a pixel count.
        // For some weird reason if the format is not a standard bit depth the
        // width field in the BITMAPINFOHEADER should be set to the number of
        // bytes instead of the width in pixels. This supports odd YUV formats
        // like IF09 which uses 9bpp.
        int bpp = pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount;
        if (bpp == 8 || bpp == 16 || bpp == 24 || bpp == 32)
        {
            pbmiHeader->biWidth /= (bpp / 8);   // Divide by number of BYTES per pixel.
        }
    }
    else
    {
        pbmiHeader->biWidth = pSurfaceDesc->dwWidth;
        // BUGUBUG -- Do something odd here with strange YUV pixel formats?  Or does it matter?
    }

    pbmiHeader->biHeight = pSurfaceDesc->dwHeight;
    if (bInvertSize)
    {
        pbmiHeader->biHeight = -pbmiHeader->biHeight;
    }
    pbmiHeader->biPlanes        = 1;
    pbmiHeader->biBitCount      = (USHORT) pSurfaceDesc->ddpfPixelFormat.dwRGBBitCount;
    pbmiHeader->biCompression   = pSurfaceDesc->ddpfPixelFormat.dwFourCC;
    pbmiHeader->biClrUsed       = 0;
    pbmiHeader->biClrImportant  = 0;


    // For true colour RGB formats tell the source there are bit fields
    if (pbmiHeader->biCompression == BI_RGB)
    {
        if (pbmiHeader->biBitCount == 16 || pbmiHeader->biBitCount == 32)
        {
            pbmiHeader->biCompression = BI_BITFIELDS;
        }
    }

    if (pbmiHeader->biBitCount <= iPALETTE)
    {
        pbmiHeader->biClrUsed = 1 << pbmiHeader->biBitCount;
    }

    pbmiHeader->biSizeImage = DIBSIZE(*pbmiHeader);



    // The RGB bit fields are in the same place as for YUV formats
    if (pbmiHeader->biCompression != BI_RGB)
    {
        DWORD *pdwBitMasks = NULL;
        pdwBitMasks = (DWORD*)(::GetBitMasks((const CMediaType *)pMediaType));
        if ( ! pdwBitMasks )
        {
            hr = E_OUTOFMEMORY;
            goto CleanUp;
        }
        // GetBitMasks only returns the pointer to the actual bitmasks
        // in the mediatype if biCompression == BI_BITFIELDS
        pdwBitMasks[0] = pSurfaceDesc->ddpfPixelFormat.dwRBitMask;
        pdwBitMasks[1] = pSurfaceDesc->ddpfPixelFormat.dwGBitMask;
        pdwBitMasks[2] = pSurfaceDesc->ddpfPixelFormat.dwBBitMask;
    }

    // And finish it off with the other media type fields
    pMediaType->subtype = GetBitmapSubtype(pbmiHeader);
    pMediaType->lSampleSize = pbmiHeader->biSizeImage;

    // set the src and dest rects if necessary
    if (pMediaType->formattype == FORMAT_VideoInfo)
    {
        VIDEOINFOHEADER *pVideoInfo = (VIDEOINFOHEADER *)pMediaType->pbFormat;
        VIDEOINFOHEADER *pSrcVideoInfo = (VIDEOINFOHEADER *)cMediaType.pbFormat;

        // if the surface allocated is different than the size specified by the decoder
        // then use the src and dest to ask the decoder to clip the video
        if ((abs(pVideoInfo->bmiHeader.biHeight) != abs(pSrcVideoInfo->bmiHeader.biHeight)) ||
            (abs(pVideoInfo->bmiHeader.biWidth) != abs(pSrcVideoInfo->bmiHeader.biWidth)))
        {
            if (IsRectEmpty(&(pVideoInfo->rcSource)))
            {
                pVideoInfo->rcSource.left = pVideoInfo->rcSource.top = 0;
                pVideoInfo->rcSource.right = pSurfaceDesc->dwWidth;
                pVideoInfo->rcSource.bottom = pSurfaceDesc->dwHeight;
            }
            if (IsRectEmpty(&(pVideoInfo->rcTarget)))
            {
                pVideoInfo->rcTarget.left = pVideoInfo->rcTarget.top = 0;
                pVideoInfo->rcTarget.right = pSurfaceDesc->dwWidth;
                pVideoInfo->rcTarget.bottom = pSurfaceDesc->dwHeight;
            }
        }
    }
    else if (pMediaType->formattype == FORMAT_VideoInfo2)
    {
        VIDEOINFOHEADER2 *pVideoInfo2 = (VIDEOINFOHEADER2 *)pMediaType->pbFormat;
        VIDEOINFOHEADER2 *pSrcVideoInfo2 = (VIDEOINFOHEADER2 *)cMediaType.pbFormat;

        // if the surface allocated is different than the size specified by the decoder
        // then use the src and dest to ask the decoder to clip the video
        if ((abs(pVideoInfo2->bmiHeader.biHeight) != abs(pSrcVideoInfo2->bmiHeader.biHeight)) ||
            (abs(pVideoInfo2->bmiHeader.biWidth) != abs(pSrcVideoInfo2->bmiHeader.biWidth)))
        {
            if (IsRectEmpty(&(pVideoInfo2->rcSource)))
            {
                pVideoInfo2->rcSource.left = pVideoInfo2->rcSource.top = 0;
                pVideoInfo2->rcSource.right = pSurfaceDesc->dwWidth;
                pVideoInfo2->rcSource.bottom = pSurfaceDesc->dwHeight;
            }
            if (IsRectEmpty(&(pVideoInfo2->rcTarget)))
            {
                pVideoInfo2->rcTarget.left = pVideoInfo2->rcTarget.top = 0;
                pVideoInfo2->rcTarget.right = pSurfaceDesc->dwWidth;
                pVideoInfo2->rcTarget.bottom = pSurfaceDesc->dwHeight;
            }
        }
    }

CleanUp:
    if (FAILED(hr))
    {
        if (pMediaType)
        {
            FreeMediaType(*pMediaType);
            pMediaType = NULL;
        }
    }
    return pMediaType;
}


typedef HRESULT (*LPFNPAINTERPROC)(LPDIRECTDRAWSURFACE pDDrawSurface);

HRESULT YV12PaintSurfaceBlack(LPDIRECTDRAWSURFACE pDDrawSurface)
{
    HRESULT hr = NOERROR;
    DDSURFACEDESC ddsd;

    // now lock the surface so we can start filling the surface with black
    ddsd.dwSize = sizeof(ddsd);
    while ((hr = pDDrawSurface->Lock(NULL, &ddsd, 0, NULL)) == DDERR_WASSTILLDRAWING)
        Sleep(1);

    if (hr == DD_OK)
    {
        DWORD y;
        LPBYTE pDst = (LPBYTE)ddsd.lpSurface;
        LONG  OutStride = ddsd.lPitch;
        DWORD VSize = ddsd.dwHeight;
        DWORD HSize = ddsd.dwWidth;

        // Y Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x10);     // 1 line at a time
            pDst += OutStride;
        }

        HSize /= 2;
        VSize /= 2;
        OutStride /= 2;

        // Cb Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        // Cr Component
        for (y = 0; y < VSize; y++) {
            FillMemory(pDst, HSize, (BYTE)0x80);     // 1 line at a time
            pDst += OutStride;
        }

        pDDrawSurface->Unlock(NULL);
    }

    return hr;
}

HRESULT GDIPaintSurfaceBlack(LPDIRECTDRAWSURFACE pDDrawSurface)
{
    HRESULT hr;
    DDSURFACEDESC ddSurfaceDesc;
    RECT rc;
    HDC hdc;

    // get the surface description
    INITDDSTRUCT(ddSurfaceDesc);
    hr = pDDrawSurface->GetSurfaceDesc(&ddSurfaceDesc);
    if (FAILED(hr))
        return hr;

    // get the DC
    hr = pDDrawSurface->GetDC(&hdc);
    if (FAILED(hr)) {
        // Robin says NT 4.0 has a bug which means ReleaseDC must
        // be called even though GetDC failed.
        pDDrawSurface->ReleaseDC(hdc);
        return hr;
    }

    SetRect(&rc, 0, 0, ddSurfaceDesc.dwWidth, ddSurfaceDesc.dwHeight);
    FillRect(hdc, &rc, (HBRUSH)GetStockObject(BLACK_BRUSH));

    return pDDrawSurface->ReleaseDC(hdc);
}


HRESULT DX1PaintSurfaceBlack(LPDIRECTDRAWSURFACE pDDrawSurface)
{
    DWORD dwBlackColor;
    DDBLTFX ddFX;
    DDSURFACEDESC ddSurfaceDesc;
    HRESULT hr;

    // get the surface description
    INITDDSTRUCT(ddSurfaceDesc);
    hr = pDDrawSurface->GetSurfaceDesc(&ddSurfaceDesc);
    if (FAILED(hr))
        return hr;

    // compute the black value if the fourCC code is suitable, otherwise can't handle it
    switch (ddSurfaceDesc.ddpfPixelFormat.dwFourCC)
    {
    case mmioFOURCC('Y','V','1','2'):
        return YV12PaintSurfaceBlack(pDDrawSurface);

    case YUY2:
        dwBlackColor = 0x80108010;
        break;

    case UYVY:
        dwBlackColor = 0x10801080;
        break;

    default:
        DbgLog((LOG_ERROR, 1, TEXT("ddSurfaceDesc.ddpfPixelFormat.dwFourCC not one of the values in the table, so exiting function")));
        return E_FAIL;
    }

    INITDDSTRUCT(ddFX);
    ddFX.dwFillColor = dwBlackColor;
    return pDDrawSurface->Blt(NULL, NULL, NULL, DDBLT_COLORFILL, &ddFX);
}

#if 0

//JEFFNO: AlphaBlt has been removed from DX7...

HRESULT DX7PaintSurfaceBlack(LPDIRECTDRAWSURFACE pDDrawSurface)
{
    LPDIRECTDRAWSURFACE7 pDDSurf7 = NULL;
    HRESULT hr;

    hr = pDDrawSurface->QueryInterface(IID_IDirectDrawSurface7, (LPVOID *)&pDDSurf7);
    if (SUCCEEDED(hr) && pDDSurf7)
    {
        // AlphaBlend here.
        DDALPHABLTFX ddAlphaBltFX;

        ddAlphaBltFX.ddargbScaleFactors.alpha = 0;
        ddAlphaBltFX.ddargbScaleFactors.red   = 0;
        ddAlphaBltFX.ddargbScaleFactors.green = 0;
        ddAlphaBltFX.ddargbScaleFactors.blue  = 0;

        hr = pDDSurf7->AlphaBlt(NULL, NULL, NULL, DDABLT_NOBLEND, &ddAlphaBltFX);
        pDDSurf7->Release();
    }

    if (FAILED(hr)) {
        return DX1PaintSurfaceBlack(pDDrawSurface);
    }

    return hr;
}
#endif

// function used to fill the ddraw surface with black color.
HRESULT PaintDDrawSurfaceBlack(LPDIRECTDRAWSURFACE pDDrawSurface)
{
    HRESULT hr = NOERROR;
    LPDIRECTDRAWSURFACE *ppDDrawSurface = NULL;
    LPDIRECTDRAWSURFACE7 pDDSurf7 = NULL;
    DDSCAPS ddSurfaceCaps;
    DDSURFACEDESC ddSurfaceDesc;
    DWORD dwAllocSize;
    DWORD i = 0, dwTotalBufferCount = 1;
    LPFNPAINTERPROC lpfnPaintProc = NULL;

    DbgLog((LOG_TRACE, 5,TEXT("Entering CAMVideoPort::PaintDDrawSurfaceBlack")));


    // get the surface description
    INITDDSTRUCT(ddSurfaceDesc);
    hr = pDDrawSurface->GetSurfaceDesc(&ddSurfaceDesc);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("pDDrawSurface->GetSurfaceDesc failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (ddSurfaceDesc.ddpfPixelFormat.dwFlags & DDPF_RGB ) {

        lpfnPaintProc = GDIPaintSurfaceBlack;
    }
    else {

        // look to see if DX7 is available
#if 0
        //JEFFNO: DX7 no longer supports alphablt
        hr = pDDrawSurface->QueryInterface(IID_IDirectDrawSurface7, (LPVOID *)&pDDSurf7);
        if (SUCCEEDED(hr) && pDDSurf7)
        {
            lpfnPaintProc = DX7PaintSurfaceBlack;
            pDDSurf7->Release();
            pDDSurf7 = NULL;
        }
        else
#endif //0
        {
            lpfnPaintProc = DX1PaintSurfaceBlack;
        }
    }

    if (ddSurfaceDesc.dwFlags & DDSD_BACKBUFFERCOUNT)
    {
        dwTotalBufferCount = ddSurfaceDesc.dwBackBufferCount + 1;
    }

    if (dwTotalBufferCount == 1)
    {
        hr = (*lpfnPaintProc)(pDDrawSurface);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0, TEXT("pDDrawSurface->Blt failed, hr = 0x%x"), hr));
        }
        goto CleanUp;
    }

    dwAllocSize = dwTotalBufferCount*sizeof(LPDIRECTDRAWSURFACE);
    ppDDrawSurface = (LPDIRECTDRAWSURFACE*)_alloca(dwAllocSize);
    ZeroMemory((LPVOID)ppDDrawSurface, dwAllocSize);

    ZeroMemory((LPVOID)&ddSurfaceCaps, sizeof(DDSCAPS));
    ddSurfaceCaps.dwCaps = DDSCAPS_FLIP | DDSCAPS_COMPLEX | DDSCAPS_OVERLAY;
    for (i = 0; i < dwTotalBufferCount; i++)
    {
        DWORD dwNextEntry = (i+1) % dwTotalBufferCount;
        LPDIRECTDRAWSURFACE pCurrentDDrawSurface = NULL;

        if (i == 0)
            pCurrentDDrawSurface = pDDrawSurface;
        else
            pCurrentDDrawSurface = ppDDrawSurface[i];
        ASSERT(pCurrentDDrawSurface);


        // Get the back buffer surface and store it in the next (in the circular sense) entry
        hr = pCurrentDDrawSurface->GetAttachedSurface(&ddSurfaceCaps, &(ppDDrawSurface[dwNextEntry]));
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0, TEXT("Function pDDrawSurface->GetAttachedSurface failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        ASSERT(ppDDrawSurface[dwNextEntry]);

        // Peform a DirectDraw colorfill BLT
        hr = (*lpfnPaintProc)(ppDDrawSurface[dwNextEntry]);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0, TEXT("ppDDrawSurface[dwNextEntry]->Blt failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

CleanUp:
    if (ppDDrawSurface)
    {
        for (i = 0; i < dwTotalBufferCount; i++)
        {
            if (ppDDrawSurface[i])
            {
                ppDDrawSurface[i]->Release();
                ppDDrawSurface[i] = NULL;
            }
        }

        ppDDrawSurface = NULL;
    }

    DbgLog((LOG_TRACE, 5,TEXT("Leaving PaintDDrawSurfaceBlack")));
    return hr;
}


STDMETHODIMP COMFilter::GetScaledDest(RECT *prcSrc, RECT *prcDst)
{
    if (!m_apInput[0])
        return E_FAIL;

    DWORD dwImageWidth=0, dwImageHeight=0;
    RECT rcSource, rcDest;
    m_apInput[0]->GetSourceAndDest(&rcSource, &rcDest, &dwImageWidth, &dwImageHeight);

    if (IsRectEmpty(&rcSource))
        return E_FAIL;

    DbgLog((LOG_TRACE, 3, TEXT("Source rect: (%d,%d,%d,%d)"), rcSource.left, rcSource.top, rcSource.right, rcSource.bottom));
    DbgLog((LOG_TRACE, 3, TEXT("Dest rect: (%d,%d,%d,%d)"), rcDest.left, rcDest.top, rcDest.right, rcDest.bottom));
    DbgLog((LOG_TRACE, 3, TEXT("Image size: %dx%d"), dwImageWidth, dwImageHeight));


    // when there is no output pin we are in WindowLess mode, in which case
    // all co-ordinates should be in the Desktop co-ordinate space, otherwise
    // everything is in the Renderer Window co-ordinate space.

    if (m_pOutput) {

        ScreenToClient(m_pOutput->GetWindow(), (LPPOINT)&rcDest);
        ScreenToClient(m_pOutput->GetWindow(), (LPPOINT)&rcDest+1);

        DbgLog((LOG_TRACE, 3, TEXT("Client dest rect: (%d,%d,%d,%d)"), rcDest.left, rcDest.top, rcDest.right, rcDest.bottom));
    }


    //
    // Determine the source rectangle being displayed, take into account
    // that the decoder may be decimating the image given to the OVMixer.
    //

    long OrgSrcX = WIDTH(prcSrc);
    long OrgSrcY = HEIGHT(prcSrc);

    prcSrc->left = MulDiv(rcSource.left, OrgSrcX, dwImageWidth);
    prcSrc->right = MulDiv(rcSource.right, OrgSrcX, dwImageWidth);
    prcSrc->top = MulDiv(rcSource.top, OrgSrcY, dwImageHeight);
    prcSrc->bottom = MulDiv(rcSource.bottom, OrgSrcY, dwImageHeight);


    *prcDst = rcDest;

    return S_OK;
}

STDMETHODIMP COMFilter::GetOverlayRects(RECT *rcSrc, RECT *rcDest)
{
    HRESULT hr = S_OK;
    IOverlay *pIOverlay = NULL;
    hr = m_apInput[0]->QueryInterface(IID_IOverlay, (LPVOID *)&pIOverlay);
    if (SUCCEEDED(hr)) {
        pIOverlay->GetVideoPosition( rcSrc, rcDest);
        pIOverlay->Release();
    }
    return hr;
}

STDMETHODIMP COMFilter::GetVideoPortRects(RECT *rcSrc, RECT *rcDest)
{
    HRESULT hr = S_OK;
    IVPInfo *pIVPInfo = NULL;
    hr = QueryInterface(IID_IVPInfo, (LPVOID *)&pIVPInfo);
    if (SUCCEEDED(hr)) {
        pIVPInfo->GetRectangles( rcSrc, rcDest);
        pIVPInfo->Release();
    }
    return hr;
}

STDMETHODIMP COMFilter::GetBasicVideoRects(RECT *rcSrc, RECT *rcDest)
{
    HRESULT hr = S_OK;
    IBasicVideo* Ibv = NULL;
    hr = GetBasicVideoFromOutPin(&Ibv);
    if (SUCCEEDED(hr))
    {
        hr = Ibv->GetSourcePosition
            (&rcSrc->left, &rcSrc->top, &rcSrc->right, &rcSrc->bottom);
        if (SUCCEEDED(hr))
        {
            rcSrc->right += rcSrc->left;
            rcSrc->bottom += rcSrc->top;
        }

        hr = Ibv->GetDestinationPosition
            (&rcDest->left, &rcDest->top, &rcDest->right, &rcDest->bottom);
        if (SUCCEEDED(hr))
        {
            rcDest->right += rcDest->left;
            rcDest->bottom += rcDest->top;
        }
        Ibv->Release();
    }
    return hr;
}



HRESULT COMFilter::GetBasicVideoFromOutPin(IBasicVideo** pBasicVideo)
{
    HRESULT hr = E_FAIL;
    COMOutputPin* pOutPin = GetOutputPin();
    if (pOutPin)
    {
        IPin* IPeerPin = pOutPin->CurrentPeer();
        if (IPeerPin)
        {
            PIN_INFO PinInfo;
            hr = IPeerPin->QueryPinInfo(&PinInfo);
            if (SUCCEEDED(hr))
            {
                hr = PinInfo.pFilter->QueryInterface(IID_IBasicVideo, (LPVOID *)pBasicVideo);
                PinInfo.pFilter->Release();
            }
        }
    }
    return hr;
}


/******************************Public*Routine******************************\
* QueryOverlayFXCaps
*
* Returns the current effect caps for the DDraw Object currently in use.
*
* History:
* Tue 07/06/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::QueryOverlayFXCaps(
    DWORD *lpdwOverlayFXCaps
    )
{
    CAutoLock l(&m_csFilter);

    if (!lpdwOverlayFXCaps) {
        return E_POINTER;
    }

    LPDDCAPS lpCaps = GetHardwareCaps();
    if (lpCaps)
    {
        DWORD dwFlags = 0;

        if (lpCaps->dwFXCaps & DDFXCAPS_OVERLAYMIRRORLEFTRIGHT)
        {
            dwFlags |= AMOVERFX_MIRRORLEFTRIGHT;
        }

        if (lpCaps->dwFXCaps & DDFXCAPS_OVERLAYMIRRORUPDOWN)
        {
            dwFlags |= AMOVERFX_MIRRORUPDOWN;
        }

        if (lpCaps->dwFXCaps & DDFXCAPS_OVERLAYDEINTERLACE)
        {
            dwFlags |= AMOVERFX_DEINTERLACE;
        }

        *lpdwOverlayFXCaps = dwFlags;
        return S_OK;
    }

    return E_FAIL;
}


/******************************Public*Routine******************************\
* SetOverlayFX
*
* Validates that the user specified FX flags are valid, then
* updates the internal FX state and calls UpdateOverlay to reflect the
* new effect to the display.
*
* History:
* Tue 07/06/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::SetOverlayFX(
    DWORD dwOverlayFX
    )
{
    CAutoLock l(&m_csFilter);
    DWORD dwCaps;

    //
    // get the current overlay caps
    //

    if (S_OK == QueryOverlayFXCaps(&dwCaps))
    {
        //
        // check that the caller is asking us to do
        // something that is valid
        //

        dwCaps |= AMOVERFX_DEINTERLACE;    // deinterlacing is a hint
        if (dwOverlayFX != (dwOverlayFX & dwCaps))
        {
            return E_INVALIDARG;
        }

        m_dwOverlayFX = 0;
        if (dwOverlayFX & AMOVERFX_MIRRORLEFTRIGHT)
        {
            m_dwOverlayFX |= DDOVERFX_MIRRORLEFTRIGHT;
        }

        if (dwOverlayFX & AMOVERFX_MIRRORUPDOWN)
        {
            m_dwOverlayFX |= DDOVERFX_MIRRORUPDOWN;
        }
        if (dwOverlayFX & AMOVERFX_DEINTERLACE)
        {
            m_dwOverlayFX |= DDOVERFX_DEINTERLACE;
        }

        //
        // call UpdateOverlay to make the new FX flags take effect
        //
        return m_apInput[0]->ApplyOvlyFX();
    }

    return E_FAIL;
}

/******************************Public*Routine******************************\
* GetOverlayFX
*
* Returns the current overlay FX that is in use.
*
* History:
* Tue 07/06/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::GetOverlayFX(
    DWORD *lpdwOverlayFX
    )
{
    CAutoLock l(&m_csFilter);
    if (lpdwOverlayFX)
    {
        *lpdwOverlayFX = m_dwOverlayFX;
        return S_OK;
    }
    return E_POINTER;
}



//  Wrapper for UpdateOverlay - we track the overlay state and do
//  notifications and manage painting the color key

HRESULT COMFilter::CallUpdateOverlay(
                          IDirectDrawSurface *pSurface,
                          LPRECT prcSrcCall,
                          LPDIRECTDRAWSURFACE pDestSurface,
                          LPRECT prcDestCall,
                          DWORD dwFlags,
                          IOverlayNotify *pIOverlayNotify,
                          LPRGNDATA pBuffer)
{
#define CAPS_HACK
#ifdef CAPS_HACK
    if (!(m_DirectCaps.dwCaps2 & DDCAPS2_CANBOBINTERLEAVED) &&
        (dwFlags & (DDOVER_INTERLEAVED | DDOVER_BOB))==
         (DDOVER_INTERLEAVED | DDOVER_BOB)) {
        dwFlags &= ~(DDOVER_INTERLEAVED | DDOVER_BOB);
    }
#endif
    LPRECT prcSrc = prcSrcCall;
    LPRECT prcDest = prcDestCall;

    DbgLog((LOG_TRACE, 2, TEXT("UpdateOverlayFlags %8.8X"), dwFlags));

    //  Have we changed anything?
    DWORD dwUpdFlags = 0;
    BOOL bNewVisible = m_bOverlayVisible;

    if ((dwFlags & DDOVER_SHOW) && !m_bOverlayVisible ||
        (dwFlags & DDOVER_HIDE) && m_bOverlayVisible) {

        dwUpdFlags |= AM_OVERLAY_NOTIFY_VISIBLE_CHANGE;
        bNewVisible = !bNewVisible;

        //  If we're going invisible
        if (NULL == m_pExclModeCallback && !bNewVisible) {
            m_bOverlayVisible = FALSE;
            //  Here's where we should remove the overlay color
        }
    }

    if (prcSrc == NULL) {
        prcSrc = &m_rcOverlaySrc;
    } else if (!EqualRect(prcSrc, &m_rcOverlaySrc)) {
        dwUpdFlags |= AM_OVERLAY_NOTIFY_SOURCE_CHANGE;
    }

    if (prcDest == NULL) {
        prcDest = &m_rcOverlayDest;
    } else if (!EqualRect(prcDest, &m_rcOverlayDest)) {
        dwUpdFlags |= AM_OVERLAY_NOTIFY_DEST_CHANGE;
    }
    DbgLog((LOG_TRACE, 2, TEXT("CallUpadateOverlay flags (0x%8.8X)")
                          TEXT("dest (%d,%d,%d,%d)"),
                          dwFlags,
                          prcDest->left,
                          prcDest->top,
                          prcDest->right,
                          prcDest->bottom));

    if (dwUpdFlags != 0) {
        if (m_pExclModeCallback) {
            m_pExclModeCallback->OnUpdateOverlay(TRUE,     // Before
                                                 dwUpdFlags,
                                                 m_bOverlayVisible,
                                                 &m_rcOverlaySrc,
                                                 &m_rcOverlayDest,
                                                 bNewVisible,
                                                 prcSrc,
                                                 prcDest);
        }
    }

    HRESULT hr = S_OK;
    DDOVERLAYFX ddOVFX;
    DDOVERLAYFX* lpddOverlayFx;

    if (dwFlags & DDOVER_HIDE) {
        dwFlags &= ~DDOVER_DDFX;
        lpddOverlayFx = NULL;
    }
    else {
        INITDDSTRUCT(ddOVFX);
        dwFlags |= DDOVER_DDFX;
        lpddOverlayFx = &ddOVFX;
        lpddOverlayFx->dwDDFX = m_dwOverlayFX;
    }

    if (pSurface) {

        if (prcSrcCall && prcDestCall) {

            RECT rcSrc = *prcSrcCall;
            RECT rcDst = *prcDestCall;

            // shrinking horizontally and driver can't arbitrarly shrink in X ?
            if ((!(m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKX)) &&
                (WIDTH(&rcSrc) > WIDTH(&rcDst))) {

                rcSrc.right = rcSrc.left + WIDTH(&rcDst);
            }

            // shrinking vertically and driver can't arbitrarly shrink in Y ?
            if ((!(m_DirectCaps.dwFXCaps & DDFXCAPS_OVERLAYSHRINKY)) &&
                (HEIGHT(&rcSrc) > HEIGHT(&rcDst))) {

                rcSrc.bottom = rcSrc.top + HEIGHT(&rcDst);
            }

            RECT TargetRect = rcDst;
            OffsetRect(&TargetRect,
                       -m_lpCurrentMonitor->rcMonitor.left,
                       -m_lpCurrentMonitor->rcMonitor.top);

            hr = pSurface->UpdateOverlay(
                               &rcSrc,
                               pDestSurface,
                               &TargetRect,
                               dwFlags,
                               lpddOverlayFx);
        }
        else {

            if (prcDestCall) {

                RECT TargetRect = *prcDestCall;
                OffsetRect(&TargetRect,
                           -m_lpCurrentMonitor->rcMonitor.left,
                           -m_lpCurrentMonitor->rcMonitor.top);

                hr = pSurface->UpdateOverlay(
                                   prcSrcCall,
                                   pDestSurface,
                                   &TargetRect,
                                   dwFlags,
                                   lpddOverlayFx);
            }
            else {

                hr = pSurface->UpdateOverlay(
                                   prcSrcCall,
                                   pDestSurface,
                                   prcDestCall,
                                   dwFlags,
                                   lpddOverlayFx);

            }
        }
    } else {
        if (pIOverlayNotify) {
            if (pBuffer) {
                pIOverlayNotify->OnClipChange(prcSrcCall, prcDestCall, pBuffer);
            } else {
                pIOverlayNotify->OnPositionChange(prcSrcCall, prcDestCall);
            }
        }
    }

    //hr = pSurface->Flip(NULL, DDFLIP_WAIT);

    //  Notify afterwards
    if (dwUpdFlags != 0) {
        BOOL bOldVisible = m_bOverlayVisible;
        RECT rcOldSource = m_rcOverlaySrc;
        RECT rcOldDest   = m_rcOverlayDest;
        m_bOverlayVisible = bNewVisible;
        m_rcOverlaySrc    = *prcSrc;
        m_rcOverlayDest   = *prcDest;
        if (m_pExclModeCallback) {
            m_pExclModeCallback->OnUpdateOverlay(FALSE,    // After
                                                 dwUpdFlags,
                                                 bOldVisible,
                                                 &rcOldSource,
                                                 &rcOldDest,
                                                 bNewVisible,
                                                 prcSrc,
                                                 prcDest);
        } else {
            if (!bOldVisible && bNewVisible) {
                // Here's where we should draw the color key
            }
        }
    }

    return hr;
}


/******************************Public*Routine******************************\
* QueryDecimationUsage
*
*
*
* History:
* Wed 07/07/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::QueryDecimationUsage(
    DECIMATION_USAGE* lpUsage
    )
{
    if (lpUsage) {
        *lpUsage = m_dwDecimation;
        return S_OK;
    }
    return E_POINTER;
}


/******************************Public*Routine******************************\
* SetDecimationUsage
*
*
*
* History:
* Wed 07/07/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::SetDecimationUsage(
    DECIMATION_USAGE Usage
    )
{
    CAutoLock l(&m_csFilter);

    switch (Usage) {
    case DECIMATION_LEGACY:
    case DECIMATION_USE_DECODER_ONLY:
    case DECIMATION_USE_OVERLAY_ONLY:
    case DECIMATION_DEFAULT:
        break;

    case DECIMATION_USE_VIDEOPORT_ONLY:
        // only allow this mode if we are actually using a video port
        if (m_apInput[0]->m_RenderTransport == AM_VIDEOPORT) {
            break;
        }

        // else fall thru

    default:
        return E_INVALIDARG;
    }
    DECIMATION_USAGE dwOldUsage = m_dwDecimation;
    m_dwDecimation = Usage;


    if (dwOldUsage != m_dwDecimation) {
        EventNotify(GetPinCount(), EC_OVMIXER_REDRAW_ALL, 0, 0);
    }

    return S_OK;
}


// This function allocates a shared memory block for use by the upstream filter
// generating DIBs to render. The memory block is created in shared
// memory so that GDI doesn't have to copy the memory in BitBlt
HRESULT CreateDIB(LONG lSize, BITMAPINFO *pBitMapInfo, DIBDATA *pDibData)
{
    HRESULT hr = NOERROR;
    BYTE *pBase = NULL;            // Pointer to the actual image
    HANDLE hMapping = NULL;        // Handle to mapped object
    HBITMAP hBitmap = NULL;        // DIB section bitmap handle
    DWORD dwError = 0;

    AMTRACE((TEXT("CreateDIB")));

    // Create a file mapping object and map into our address space
    hMapping = CreateFileMapping(hMEMORY, NULL,  PAGE_READWRITE,  (DWORD) 0, lSize, NULL);           // No name to section
    if (hMapping == NULL)
    {
        dwError = GetLastError();
        hr = AmHresultFromWin32(dwError);
        goto CleanUp;
    }

    // create the DibSection
    hBitmap = CreateDIBSection((HDC)NULL, pBitMapInfo, DIB_RGB_COLORS,
        (void**) &pBase, hMapping, (DWORD) 0);
    if (hBitmap == NULL || pBase == NULL)
    {
        dwError = GetLastError();
        hr = AmHresultFromWin32(dwError);
        goto CleanUp;
    }

    // Initialise the DIB information structure
    pDibData->hBitmap = hBitmap;
    pDibData->hMapping = hMapping;
    pDibData->pBase = pBase;
    pDibData->PaletteVersion = PALETTE_VERSION;
    GetObject(hBitmap, sizeof(DIBSECTION), (void*)&(pDibData->DibSection));

CleanUp:
    if (FAILED(hr))
    {
        EXECUTE_ASSERT(CloseHandle(hMapping));
    }
    return hr;
}

// DeleteDIB
//
// This function just deletes DIB's created by the above CreateDIB function.
//
HRESULT DeleteDIB(DIBDATA *pDibData)
{
    if (!pDibData)
    {
        return E_INVALIDARG;
    }

    if (pDibData->hBitmap)
    {
        DeleteObject(pDibData->hBitmap);
    }

    if (pDibData->hMapping)
    {
        CloseHandle(pDibData->hMapping);
    }

    ZeroMemory(pDibData, sizeof(*pDibData));

    return NOERROR;
}


// function used to blt the data from the source to the target dc
void FastDIBBlt(DIBDATA *pDibData, HDC hTargetDC, HDC hSourceDC, RECT *prcTarget, RECT *prcSource)
{
    HBITMAP hOldBitmap = NULL;         // Store the old bitmap
    DWORD dwSourceWidth = 0, dwSourceHeight = 0, dwTargetWidth = 0, dwTargetHeight = 0;

    ASSERT(prcTarget);
    ASSERT(prcSource);

    dwSourceWidth = WIDTH(prcSource);
    dwSourceHeight = HEIGHT(prcSource);
    dwTargetWidth = WIDTH(prcTarget);
    dwTargetHeight = HEIGHT(prcTarget);

    hOldBitmap = (HBITMAP) SelectObject(hSourceDC, pDibData->hBitmap);


    // Is the destination the same size as the source
    if ((dwSourceWidth == dwTargetWidth) && (dwSourceHeight == dwTargetHeight))
    {
        // Put the image straight into the target dc
        BitBlt(hTargetDC, prcTarget->left, prcTarget->top, dwTargetWidth,
               dwTargetHeight, hSourceDC, prcSource->left, prcSource->top,
               SRCCOPY);
    }
    else
    {
        // Stretch the image when copying to the target dc
        StretchBlt(hTargetDC, prcTarget->left, prcTarget->top, dwTargetWidth,
            dwTargetHeight, hSourceDC, prcSource->left, prcSource->top,
            dwSourceWidth, dwSourceHeight, SRCCOPY);
    }

    // Put the old bitmap back into the device context so we don't leak
    SelectObject(hSourceDC, hOldBitmap);
}

// funtion used to transfer pixels from the DIB to the target dc
void SlowDIBBlt(BYTE *pDibBits, BITMAPINFOHEADER *pHeader, HDC hTargetDC, RECT *prcTarget, RECT *prcSource)
{
    DWORD dwSourceWidth = 0, dwSourceHeight = 0, dwTargetWidth = 0, dwTargetHeight = 0;

    ASSERT(prcTarget);
    ASSERT(prcSource);

    dwSourceWidth = WIDTH(prcSource);
    dwSourceHeight = HEIGHT(prcSource);
    dwTargetWidth = WIDTH(prcTarget);
    dwTargetHeight = HEIGHT(prcTarget);

    // Is the destination the same size as the source
    if ((dwSourceWidth == dwTargetWidth) && (dwSourceHeight == dwTargetHeight))
    {
        UINT uStartScan = 0, cScanLines = pHeader->biHeight;

        // Put the image straight into the target dc
        SetDIBitsToDevice(hTargetDC, prcTarget->left, prcTarget->top, dwTargetWidth,
            dwTargetHeight, prcSource->left, prcSource->top, uStartScan, cScanLines,
            pDibBits, (BITMAPINFO*) pHeader, DIB_RGB_COLORS);
    }
    else
    {
        // if the origin of bitmap is bottom-left, adjust soruce_rect_top
        // to be the bottom-left corner instead of the top-left.
        LONG lAdjustedSourceTop = (pHeader->biHeight > 0) ? (pHeader->biHeight - prcSource->bottom) :
            (prcSource->top);

        // stretch the image into the target dc
        StretchDIBits(hTargetDC, prcTarget->left, prcTarget->top, dwTargetWidth,
            dwTargetHeight, prcSource->left, lAdjustedSourceTop, dwSourceWidth, dwSourceHeight,
            pDibBits, (BITMAPINFO*) pHeader, DIB_RGB_COLORS, SRCCOPY);
    }

}


/******************************Public*Routine******************************\
* Set
*
* IKsPropertySet interface methods
*
* History:
* Mon 10/18/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::Set(
    REFGUID guidPropSet,
    DWORD dwPropID,
    LPVOID pInstanceData,
    DWORD cbInstanceData,
    LPVOID pPropData,
    DWORD cbPropData
    )
{
    AMTRACE((TEXT("COMFilter::Set")));

    if (guidPropSet != AM_KSPROPSETID_FrameStep)
    {
        return E_PROP_SET_UNSUPPORTED ;
    }

    if (dwPropID != AM_PROPERTY_FRAMESTEP_STEP &&
        dwPropID != AM_PROPERTY_FRAMESTEP_CANCEL &&
        dwPropID != AM_PROPERTY_FRAMESTEP_CANSTEP &&
        dwPropID != AM_PROPERTY_FRAMESTEP_CANSTEPMULTIPLE)
    {
        return E_PROP_ID_UNSUPPORTED;
    }

    switch (dwPropID) {
    case AM_PROPERTY_FRAMESTEP_STEP:

        if (cbPropData < sizeof(AM_FRAMESTEP_STEP)) {
            return E_INVALIDARG;
        }

        if (0 == ((AM_FRAMESTEP_STEP *)pPropData)->dwFramesToStep) {
            return E_INVALIDARG;
        }

        return m_apInput[0]->SetFrameStepMode(((AM_FRAMESTEP_STEP *)pPropData)->dwFramesToStep);

    case AM_PROPERTY_FRAMESTEP_CANCEL:
        return  m_apInput[0]->CancelFrameStepMode();

    case AM_PROPERTY_FRAMESTEP_CANSTEP:
    case AM_PROPERTY_FRAMESTEP_CANSTEPMULTIPLE:
        if (m_apInput[0]->m_RenderTransport == AM_VIDEOPORT ||
            m_apInput[0]->m_RenderTransport == AM_IOVERLAY) {

           return S_FALSE;
        }
        return S_OK;
    }

    return E_NOTIMPL;
}


/******************************Public*Routine******************************\
* Get
*
* IKsPropertySet interface methods
*
* History:
* Mon 10/18/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::Get(
    REFGUID guidPropSet,
    DWORD dwPropID,
    LPVOID pInstanceData,
    DWORD cbInstanceData,
    LPVOID pPropData,
    DWORD cbPropData,
    DWORD *pcbReturned
    )
{
    AMTRACE((TEXT("COMFilter::Get")));
    return E_NOTIMPL;
}


/******************************Public*Routine******************************\
* QuerySupported
*
* IKsPropertySet interface methods
*
* History:
* Mon 10/18/1999 - StEstrop - Created
*
\**************************************************************************/
STDMETHODIMP
COMFilter::QuerySupported(
    REFGUID guidPropSet,
    DWORD dwPropID,
    DWORD *pTypeSupport
    )
{
    AMTRACE((TEXT("COMFilter::QuerySupported")));

    if (guidPropSet != AM_KSPROPSETID_FrameStep)
    {
        return E_PROP_SET_UNSUPPORTED;
    }

    if (dwPropID != AM_PROPERTY_FRAMESTEP_STEP &&
        dwPropID != AM_PROPERTY_FRAMESTEP_CANCEL)
    {
        return E_PROP_ID_UNSUPPORTED;
    }

    if (pTypeSupport)
    {
        *pTypeSupport = KSPROPERTY_SUPPORT_SET ;
    }

    return S_OK;
}

//
//  More or less lifted from the w2k SFP code
//
static HRESULT GetFileVersion (const TCHAR* pszFile, // file
                       UINT64* pFileVersion )
{
    DWORD               dwSize, dwHandle;
    VS_FIXEDFILEINFO    *pFixedVersionInfo;
    DWORD               dwVersionInfoSize;
    DWORD               dwReturnCode;

    dwSize = GetFileVersionInfoSize( const_cast<TCHAR *>(pszFile), &dwHandle);

    HRESULT hr = S_OK;
    *pFileVersion = 0;

    // .txt and .inf, etc files might not have versions
    if( dwSize == 0 )
    {
        dwReturnCode = GetLastError();
        hr = E_FAIL;
    } else {
        LPVOID pVersionInfo= new BYTE [dwSize];

        if( NULL == pVersionInfo) {
            hr = E_OUTOFMEMORY;
        } else {
            if( !GetFileVersionInfo( const_cast<TCHAR *>(pszFile), dwHandle, dwSize, pVersionInfo ) ) {
                dwReturnCode = GetLastError();
                DbgLog((LOG_ERROR, 1,  TEXT("Error in GetFileVersionInfo for %s. ec=%d"),
                           pszFile, dwReturnCode));
                hr = E_FAIL;
            } else {
                if( !VerQueryValue( pVersionInfo,
                        TEXT("\\"), // we need the root block
                        (LPVOID *) &pFixedVersionInfo,
                        (PUINT)  &dwVersionInfoSize ) )
                {
                    dwReturnCode = GetLastError();
                    hr = E_FAIL;
                } else {
                    *pFileVersion =  pFixedVersionInfo->dwFileVersionMS;
                    *pFileVersion = UINT64(*pFileVersion)<<32;
                    *pFileVersion += pFixedVersionInfo->dwFileVersionLS;
                }
            }
            delete [] pVersionInfo;
        }
    }
    return hr;
}


// V5.00.00.38 to v.42 of the MMatics decoder try to use the MoComp interfaces incorrectly
// (it mixes the MoComp GetBuffer/Release with DisplayFrame())
// We'll deny them so that we don't crash / show black

BOOL COMFilter::IsFaultyMMaticsMoComp()
{
    if( !m_bHaveCheckedMMatics ) {
        m_bHaveCheckedMMatics = TRUE;

        // the connected pin doesn't tell us the correct version, so we'll see if
        // MMatics is running.  We don't expect it to be run concurrently with another decoder
        const TCHAR* pszDecoderName = TEXT( "DVD Express AV Decoder.dll");
        HMODULE hModule = GetModuleHandle( pszDecoderName );
        if( hModule ) {
            UINT64 ullVersion;
#define MAKE_VER_NUM( v1, v2, v3, v4 ) (((UINT64(v1) << 16 | (v2) )<<16 | (v3) ) << 16 | (v4) )

			TCHAR szFilename[1024];
			if( GetModuleFileName( hModule, szFilename, NUMELMS(szFilename) ) ) {
				if( SUCCEEDED( GetFileVersion( szFilename, &ullVersion ) )) {
					if( MAKE_VER_NUM( 5, 0, 0, 38 ) <=  ullVersion &&
														ullVersion <= MAKE_VER_NUM( 5, 0, 0, 42 ) )
					{
						// ASSERT( !"Bogus MMatics Version detected" );
						m_bIsFaultyMMatics = TRUE;
					}
				}
			}
        }
    }
    return m_bIsFaultyMMatics;
}

#if defined(DEBUG) && !defined(_WIN64)
void WINAPI
OVMixerDebugLog(
    DWORD Type,
    DWORD Level,
    const TCHAR *pFormat,
    ...
    )
{
    TCHAR szInfo[1024];
#if defined(UNICODE)
    char  szInfoA[1024];
#endif

    /* Format the variable length parameter list */

    if (Level > (DWORD)iOVMixerDump) {
        return;
    }

    va_list va;
    va_start(va, pFormat);

    wsprintf(szInfo, TEXT("OVMIXER (tid %x) : "), GetCurrentThreadId());
    wvsprintf(szInfo + lstrlen(szInfo), pFormat, va);

    lstrcat(szInfo, TEXT("\r\n"));


#if defined(UNICODE)
    wsprintfA(szInfoA, "%ls", szInfo);
    _lwrite(DbgFile, szInfoA, lstrlenA(szInfoA));
#else
    _lwrite(DbgFile, szInfo, lstrlen(szInfo));
#endif

    va_end(va);
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmixer\syncobj.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#ifndef __SYNC_OBJECT__
#define __SYNC_OBJECT__

class COMInputPin;

class CFrameAvg
{
    enum { nFrames = 8 };
    int   m_tFrame[nFrames];
    int   m_tTotal;
    int   m_iCurrent;

public:

    CFrameAvg()
    {
        Init();
    }
    void Init()
    {
        m_tTotal   = 0;
        m_iCurrent = 0;
        ZeroMemory(m_tFrame, sizeof(m_tFrame));
    }

    void NewFrame(REFERENCE_TIME tFrameTime)
    {
        if (tFrameTime > UNITS) {
            tFrameTime = UNITS;
        }
        if (tFrameTime < 0) {
            tFrameTime = 0;
        }
        int iNext = m_iCurrent == nFrames - 1 ? 0 : m_iCurrent + 1;
        m_tTotal -= m_tFrame[iNext];
        m_tTotal += (int)tFrameTime;
        m_tFrame[iNext] = (int)tFrameTime;
        m_iCurrent = iNext;
    }

    int Avg()
    {
        return m_tTotal / nFrames;
    }
};

class CAMSyncObj

{
public:
    CAMSyncObj(COMInputPin *pPin, IReferenceClock **ppClock, CCritSec *pLock, HRESULT *phr);
    ~CAMSyncObj();

    HRESULT CompleteConnect(IPin *pReceivePin);
    HRESULT BreakConnect();
    HRESULT NewSegment(REFERENCE_TIME tStart, REFERENCE_TIME tStop, double dRate);

    HRESULT Active();
    HRESULT Inactive();
    HRESULT Run(REFERENCE_TIME tStart);
    HRESULT RunToPause();
    HRESULT BeginFlush();
    HRESULT EndFlush();

    HRESULT EndOfStream();
    HRESULT Receive(IMediaSample *pMediaSample);
    HRESULT WaitForRenderTime();
    BOOL ScheduleSample(IMediaSample *pMediaSample);
    void SendRepaint();
    void SetRepaintStatus(BOOL bRepaint);
    HRESULT OnDisplayChange();

    // Permit access to the transition state
    void Ready() { m_evComplete.Set(); }
    void NotReady() { m_evComplete.Reset(); }
    BOOL CheckReady() { return m_evComplete.Check(); }

    STDMETHODIMP GetState(DWORD dwMSecs,FILTER_STATE *pState);
    FILTER_STATE GetRealState() { return m_State; }
    void SetCurrentSample(IMediaSample *pMediaSample);
    virtual IMediaSample *GetCurrentSample();
    HRESULT CompleteStateChange(FILTER_STATE OldState);
    HRESULT GetSampleTimes(IMediaSample *pMediaSample, REFERENCE_TIME *pStartTime,
	REFERENCE_TIME *pEndTime);

    static void CALLBACK CAMSyncObj::RenderSampleOnMMThread(UINT uID, UINT uMsg, DWORD_PTR dwUser, DWORD_PTR dw1, DWORD_PTR dw2);
    HRESULT CAMSyncObj::ScheduleSampleUsingMMThread(IMediaSample *pMediaSample);

private:
    // Return internal information about this pin
    BOOL IsEndOfStream() { return m_bEOS; }
    BOOL IsEndOfStreamDelivered() { return m_bEOSDelivered; }
    BOOL IsFlushing() { return m_bFlushing; }
    BOOL IsConnected() { return m_bConnected; }
    BOOL IsStreaming() { return m_bStreaming; }
    void SetAbortSignal(BOOL bAbort) { m_bAbort = bAbort; }
    virtual void OnReceiveFirstSample(IMediaSample *pMediaSample);
    CAMEvent *GetRenderEvent() { return &m_RenderEvent; }
    void SignalTimerFired() { m_dwAdvise = 0; }

    // These look after the handling of data samples
    virtual HRESULT PrepareReceive(IMediaSample *pMediaSample);
    void WaitForReceiveToComplete();
    virtual BOOL HaveCurrentSample();

    HRESULT SourceThreadCanWait(BOOL bCanWait);

    // Lots of end of stream complexities
    void ResetEndOfStreamTimer();
    HRESULT NotifyEndOfStream();
    virtual HRESULT SendEndOfStream();
    virtual HRESULT ResetEndOfStream();
    friend void CALLBACK EndOfStreamTimer(UINT uID, UINT uMsg, DWORD_PTR dwUser, DWORD_PTR dw1, DWORD_PTR dw2);
    void TimerCallback();

    // Rendering is based around the clock
    virtual HRESULT CancelNotification();
    virtual HRESULT ClearPendingSample();
    void CancelMMTimer();

#ifdef DEBUG
    // Debug only dump of the renderer state
    void DisplayRendererState();
#endif


private:
    COMInputPin         *m_pPin;
    IReferenceClock     **m_ppClock;		    // A pointer to the filter's clock
    CCritSec            *m_pFilterLock;		    // Critical section for interfaces
    CCritSec            m_SyncObjLock;		    // Controls access to internals

    // some state variables.
    FILTER_STATE        m_State;
    BOOL                m_bFlushing;
    BOOL                m_bConnected;
    BOOL                m_bTimerRunning;

    CRendererPosPassThru    *m_pPosition;		// Media seeking pass by object
    CAMEvent		    m_RenderEvent;		    // Used to signal timer events
    CAMEvent		    m_ThreadSignal;		    // Signalled to release worker thread
    CAMEvent		    m_evComplete;		    // Signalled when state complete

    DWORD               m_MMTimerId;		    // MMThread timer id
    DWORD_PTR           m_dwAdvise;			    // Timer advise cookie
    IMediaSample        *m_pMediaSample;		// Current image media sample
    IMediaSample        *m_pMediaSample2;		// Current image media sample for 2nd flip
    CRefTime            m_tStart;

    BOOL                m_bAbort;			    // Stop us from rendering more data
    BOOL                m_bStreaming;		    // Are we currently streaming
    BOOL                m_bRepaintStatus;		// Can we signal an EC_REPAINT
    BOOL                m_bInReceive;

    REFERENCE_TIME      m_SignalTime;		    // Time when we signal EC_COMPLETE
    BOOL                m_bEOS;			        // Any more samples in the stream
    BOOL                m_bEOSDelivered;		    // Have we delivered an EC_COMPLETE
    UINT                m_EndOfStreamTimer;		    // Used to signal end of stream

    CFrameAvg           m_AvgDuration;
#ifdef PERF
    // Performance logging identifiers
    int m_idTimeStamp;              // MSR_id for frame time stamp
    int m_idEarly;
    int m_idLate;
#endif

public:
    CFrameAvg           m_AvgDelivery;


// Added stuff to compute quality property page stats
private:
    // These member variables hold rendering statistics
    int m_cFramesDropped;           // cumulative frames dropped IN THE RENDERER
    int m_cFramesDrawn;             // Frames since streaming started seen BY THE
                                    // RENDERER (some may be dropped upstream)

    // Next two support average sync offset and standard deviation of sync offset.
    LONGLONG m_iTotAcc;                  // Sum of accuracies in mSec
    LONGLONG m_iSumSqAcc;           // Sum of squares of (accuracies in mSec)

    // Next two allow jitter calculation.  Jitter is std deviation of frame time.
    REFERENCE_TIME m_trLastDraw;    // Time of prev frame (for inter-frame times)
    LONGLONG m_iSumSqFrameTime;     // Sum of squares of (inter-frame time in mSec)
    LONGLONG m_iSumFrameTime;            // Sum of inter-frame times in mSec

    // To get performance statistics on frame rate, jitter etc, we need
    // to record the lateness and inter-frame time.  What we actually need are the
    // data above (sum, sum of squares and number of entries for each) but the data
    // is generated just ahead of time and only later do we discover whether the
    // frame was actually drawn or not.  So we have to hang on to the data
    int m_trLate;                   // hold onto frame lateness
    int m_trFrame;                  // hold onto inter-frame time

    int m_tStreamingStart;          // if streaming then time streaming started
                                    // else time of last streaming session
                                    // used for property page statistics
    // QualityProperty stats
    HRESULT GetStdDev(int nSamples, int *piResult, LONGLONG llSumSq, LONGLONG iTot);
    HRESULT OnStartStreaming();
    HRESULT OnStopStreaming();
    HRESULT ResetStreamingTimes();
    void OnRenderStart(IMediaSample *pMediaSample);
    void OnRenderEnd(IMediaSample *pMediaSample);
    void PreparePerformanceData(REFERENCE_TIME *ptrStart, REFERENCE_TIME *ptrEnd);
    void RecordFrameLateness(int trLate, int trFrame);

public:
    HRESULT get_FramesDroppedInRenderer(int *cFramesDropped);
    HRESULT get_FramesDrawn(int *pcFramesDrawn);
    HRESULT get_AvgFrameRate(int *piAvgFrameRate);
    HRESULT get_Jitter(int *piJitter);
    HRESULT get_AvgSyncOffset(int *piAvg);
    HRESULT get_DevSyncOffset(int *piDev);
};

#endif //__SYNC_OBJECT__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmixer\ovmixer.h ===
//--------------------------------------------------------------------------;
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;

#ifndef __OVMIXER__
#define __OVMIXER__

#include <mixerocx.h>
#include <videoacc.h>
#include <ddva.h>
#include <mpconfig3.h>
#include <ovmixpos2.h>
#include <ovmprop.h>
#include <ovmprop2.h>


#if defined(DEBUG) && !defined(_WIN64)

extern int  iOVMixerDump;
void WINAPI OVMixerDebugLog(DWORD Type,DWORD Level,const TCHAR *pFormat,...);

#undef DbgLog
#define DbgLog(_x_) if (iOVMixerDump) OVMixerDebugLog _x_ ; else DbgLogInfo _x_

#endif

#define VA_TRACE_LEVEL 2
#define VA_ERROR_LEVEL 2

extern const AMOVIESETUP_FILTER sudOverlayMixer;
extern const AMOVIESETUP_FILTER sudOverlayMixer2;

// Hack second CLSID - will only support VIDEOINFO2
DEFINE_GUID(CLSID_OverlayMixer2,
0xa0025e90, 0xe45b, 0x11d1, 0xab, 0xe9, 0x00, 0xa0, 0xc9,0x05, 0xf3, 0x75);

// a property set the decoders can support in order to ask the ovmixer not to
// overallocate buffers behinds the decoders back
// A503C5C0-1D1D-11d1-AD80-444553540000
DEFINE_GUID(AM_KSPROPSETID_ALLOCATOR_CONTROL,
0x53171960, 0x148e, 0x11d2, 0x99, 0x79, 0x00, 0x00, 0xc0, 0xcc, 0x16, 0xba);


//  Debug helper
#ifdef DEBUG
class CDispPixelFormat : public CDispBasic
{
public:
    CDispPixelFormat(const DDPIXELFORMAT *pFormat)
    {
        wsprintf(m_String, TEXT("  Flags(0x%8.8X) bpp(%d) 4CC(%4.4hs)"),
                 pFormat->dwFlags,
                 pFormat->dwRGBBitCount,
                 pFormat->dwFlags & DDPF_FOURCC ?
                     (CHAR *)&pFormat->dwFourCC : "None");
    }
    //  Implement cast to (LPCTSTR) as parameter to logger
    operator LPCTSTR()
    {
        return (LPCTSTR)m_pString;
    };
};
#endif // DEBUG


typedef enum
{
    // R O (if value == 1, then ovmixer will allocate exactly the number
    //      of buffers, the decoder specifies)
    AM_KSPROPERTY_ALLOCATOR_CONTROL_HONOR_COUNT = 0,

    // R O (returns 2 DWORD (cx and cy), then ovmixer will allocate surfaces
    //      of this size and will scale the video at the video port to this size
    //      no other scaling at the video port will occur regardless of the
    //      scaling abilities of the VGA chip)
    AM_KSPROPERTY_ALLOCATOR_CONTROL_SURFACE_SIZE = 1,

    // W I (informns a capture driver whether interleave capture is possible or
    //      not - a value of 1 means that interleaved capture is supported)
    AM_KSPROPERTY_ALLOCATOR_CONTROL_CAPTURE_CAPS = 2,

    // R O (if value == 1, then the ovmixer will turn on the DDVP_INTERLEAVE
    //      flag thus allowing interleaved capture of the video)
    AM_KSPROPERTY_ALLOCATOR_CONTROL_CAPTURE_INTERLEAVE = 3

} AM_KSPROPERTY_ALLOCATOR_CONTROL;


#define INITDDSTRUCT(_x_) \
    ZeroMemory(&(_x_), sizeof(_x_)); \
    (_x_).dwSize = sizeof(_x_);

PVOID AllocateDDStructures(int iSize, int nNumber);

#define MAX_PIN_COUNT                       10
#define DEFAULT_WIDTH                       320
#define DEFAULT_HEIGHT                      240
#define MAX_REL_NUM                         10000
#define MAX_BLEND_VAL                       255

#define EXTRA_BUFFERS_TO_FLIP               2

#define DDGFS_FLIP_TIMEOUT                  1
#define MIN_CK_STETCH_FACTOR_LIMIT          3000
#define SOURCE_COLOR_REF                    (RGB(0, 128, 128))          // A shade of green, color used for source-colorkeying to force the card to use pixel-doubling instead of arithmatic stretching
#define DEFAULT_DEST_COLOR_KEY_INDEX        253                         // magenta
#define DEFAULT_DEST_COLOR_KEY_RGB          (RGB(255, 0, 255))          // magenta
#define PALETTE_VERSION                     1

// these values are used to do sanity checking mostly
#define MAX_COMPRESSED_TYPES    10
#define MAX_COMPRESSED_BUFFERS  20

typedef struct _tag_SURFACE_INFO
{
    LPDIRECTDRAWSURFACE4    pSurface;
    LPVOID                  pBuffer;    // NULL if not locked
} SURFACE_INFO, *LPSURFACE_INFO;

typedef struct _tag_COMP_SURFACE_INFO
{
    DWORD                   dwAllocated;
    LPSURFACE_INFO          pSurfInfo;
} COMP_SURFACE_INFO, *LPCOMP_SURFACE_INFO;


/* -------------------------------------------------------------------------
** DDraw & MultiMon structures and typedefs
** -------------------------------------------------------------------------
*/
typedef HRESULT (WINAPI *LPDIRECTDRAWCREATE)(IID *,LPDIRECTDRAW *,LPUNKNOWN);
typedef HRESULT (WINAPI *LPDIRECTDRAWENUMERATEA)(LPDDENUMCALLBACKA,LPVOID);

enum {ACTION_COUNT_GUID, ACTION_FILL_GUID};
struct DDRAWINFO {
    DWORD               dwAction;
    DWORD               dwUser;
    const GUID*         lpGUID;
    LPDIRECTDRAWCREATE  lpfnDDrawCreate;
    AMDDRAWMONITORINFO* pmi;
};

HRESULT
LoadDDrawLibrary(
    HINSTANCE& hDirectDraw,
    LPDIRECTDRAWCREATE& lpfnDDrawCreate,
    LPDIRECTDRAWENUMERATEA& lpfnDDrawEnum,
    LPDIRECTDRAWENUMERATEEXA& lpfnDDrawEnumEx
    );

HRESULT
CreateDirectDrawObject(
    const AMDDRAWGUID& GUID,
    LPDIRECTDRAW *ppDirectDraw,
    LPDIRECTDRAWCREATE lpfnDDrawCreate
    );

/* -------------------------------------------------------------------------
** Pre-declare out classes.
** -------------------------------------------------------------------------
*/
class COMFilter;
class COMInputPin;
class COMOutputPin;
class CBPCWrap;
class CDispMacroVision;


/* -------------------------------------------------------------------------
** COMFilter class declaration
** -------------------------------------------------------------------------
*/
class COMFilter :
    public CBaseFilter,
    public IAMOverlayMixerPosition2,
    public IOverlayNotify,
    public IMixerOCX,
    public IDDrawNonExclModeVideo,
    public ISpecifyPropertyPages,
    public IQualProp,
    public IEnumPinConfig,
    public IAMVideoDecimationProperties,
    public IAMOverlayFX,
    public IAMSpecifyDDrawConnectionDevice,
    public IKsPropertySet
{
public:

    // the base classes do this, so have to do it
    friend class COMInputPin;
    friend class COMOutputPin;
    // COM stuff
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);
    static CUnknown *CreateInstance2(LPUNKNOWN, HRESULT *);
    COMFilter(TCHAR *pName,LPUNKNOWN pUnk,HRESULT *phr,
	      bool bSupportOnlyVIDEOINFO2);
    ~COMFilter();

    DECLARE_IUNKNOWN

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** ppv);

    //
    // --- ISpecifyPropertyPages ---
    //
    STDMETHODIMP GetPages(CAUUID *pPages);

    // IEnumPinConfig
    STDMETHODIMP Next(IMixerPinConfig3 **pPinConfig);

    // IQualProp property page support
    STDMETHODIMP get_FramesDroppedInRenderer(int *cFramesDropped);
    STDMETHODIMP get_FramesDrawn(int *pcFramesDrawn);
    STDMETHODIMP get_AvgFrameRate(int *piAvgFrameRate);
    STDMETHODIMP get_Jitter(int *piJitter);
    STDMETHODIMP get_AvgSyncOffset(int *piAvg);
    STDMETHODIMP get_DevSyncOffset(int *piDev);

    //
    // IKsPropertySet interface methods
    //
    STDMETHODIMP Set(REFGUID guidPropSet, DWORD PropID, LPVOID pInstanceData,
                     DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData);

    STDMETHODIMP Get(REFGUID guidPropSet, DWORD PropID, LPVOID pInstanceData,
                     DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData,
                     DWORD *pcbReturned);

    STDMETHODIMP QuerySupported(REFGUID guidPropSet,
                                DWORD PropID, DWORD *pTypeSupport);

    // IAMOverlayMixerPosition
    STDMETHODIMP GetScaledDest(RECT *prcSrc, RECT *prcDst);

    // IAMOverlayMixerPosition2
    STDMETHODIMP GetOverlayRects(RECT *src, RECT *dest);
    STDMETHODIMP GetVideoPortRects(RECT *src, RECT *dest);
    STDMETHODIMP GetBasicVideoRects(RECT *src, RECT *dest);

    // IsWindowOnWrongMonitor
    BOOL IsWindowOnWrongMonitor(HMONITOR *pID);

    virtual HRESULT SetMediaType(DWORD dwPinId, const CMediaType *pmt);
    virtual HRESULT CompleteConnect(DWORD dwPinId);
    virtual HRESULT BreakConnect(DWORD dwPinId);
    virtual HRESULT CheckMediaType(DWORD dwPinId, const CMediaType* mtIn) { return NOERROR; }
    virtual HRESULT EndOfStream(DWORD dwPinId) { return NOERROR; }
    int GetPinPosFromId(DWORD dwPinId);
    int GetPinCount();
    int GetInputPinCount() const { return m_dwInputPinCount; };
    CBasePin* GetPin(int n);
    COMOutputPin* GetOutputPin() {return m_pOutput;}
    STDMETHODIMP Pause();
    STDMETHODIMP Stop() ;
    STDMETHODIMP GetState(DWORD dwMSecs,FILTER_STATE *pState);
    HRESULT EventNotify(DWORD dwPinId, long lEventCode, long lEventParam1, long lEventParam2);
    HRESULT OnDisplayChangeBackEnd();
    HRESULT OnDisplayChange(BOOL fRealMsg);
    HRESULT OnTimer();
    HRESULT RecreatePrimarySurface(LPDIRECTDRAWSURFACE pDDrawSurface);
    HRESULT ConfirmPreConnectionState(DWORD dwExcludePinId = -1);
    HRESULT CanExclusiveMode();

    HRESULT GetPaletteEntries(DWORD *pdwNumPaletteEntries, PALETTEENTRY **ppPaletteEntries);
    HRESULT PaintColorKey(HRGN hPaintRgn, COLORKEY *pColorKey);
    HRESULT SetColorKey(COLORKEY *pColorKey);
    HRESULT GetColorKey(COLORKEY *pColorKey, DWORD *pColor);
    COLORKEY *GetColorKeyPointer() { return &m_ColorKey; }
    CImageDisplay* GetDisplay() { return &m_Display; }
    LPDIRECTDRAW GetDirectDraw();
    LPDIRECTDRAWSURFACE GetPrimarySurface();
    LPDDCAPS GetHardwareCaps();
    HRESULT OnShowWindow(HWND hwnd, BOOL fShow);
    HDC GetDestDC();
    HWND GetWindow();

    // currently being windowless is synonymous with having a pull-model, might change later
    BOOL UsingPullModel () { return m_bWindowless; }
    BOOL UsingWindowless() { return m_bWindowless; }

    void GetPinsInZOrder(DWORD *pdwZorder);
    HRESULT OnDrawAll();

    // IOverlayNotify methods
    STDMETHODIMP OnColorKeyChange(const COLORKEY *pColorKey);
    STDMETHODIMP OnPaletteChange(DWORD dwColors, const PALETTEENTRY *pPalette);
    STDMETHODIMP OnClipChange(const RECT *pSourceRect, const RECT *pDestinationRect, const RGNDATA *pRegionData);
    STDMETHODIMP OnPositionChange(const RECT *pSourceRect, const RECT *pDestinationRect);

    // IMixerOCX methods
    STDMETHODIMP OnDisplayChange(ULONG ulBitsPerPixel, ULONG ulScreenWidth, ULONG ulScreenHeight) { return E_NOTIMPL; }
    STDMETHODIMP GetAspectRatio(LPDWORD pdwPictAspectRatioX, LPDWORD pdwPictAspectRatioY) { return E_NOTIMPL; }
    STDMETHODIMP GetVideoSize(LPDWORD pdwVideoWidth, LPDWORD pdwVideoHeight);
    STDMETHODIMP GetStatus(LPDWORD *pdwStatus) { return E_NOTIMPL; }
    STDMETHODIMP OnDraw(HDC hdcDraw, LPCRECT prcDrawRect);
    STDMETHODIMP SetDrawRegion(LPPOINT lpptTopLeftSC, LPCRECT prcDrawCC, LPCRECT prcClipCC);
    STDMETHODIMP Advise(IMixerOCXNotify *pmdns);
    STDMETHODIMP UnAdvise();

    // IDDrawExclModeVideo interface methods
    STDMETHODIMP SetDDrawObject(LPDIRECTDRAW pDDrawObject);
    STDMETHODIMP GetDDrawObject(LPDIRECTDRAW *ppDDrawObject, LPBOOL pbUsingExternal);
    STDMETHODIMP SetDDrawSurface(LPDIRECTDRAWSURFACE pDDrawSurface);
    STDMETHODIMP GetDDrawSurface(LPDIRECTDRAWSURFACE *ppDDrawSurface, LPBOOL pbUsingExternal);
    STDMETHODIMP SetDrawParameters(LPCRECT prcSource, LPCRECT prcTarget);
    STDMETHODIMP GetNativeVideoProps(LPDWORD pdwVideoWidth, LPDWORD pdwVideoHeight, LPDWORD pdwPictAspectRatioX, LPDWORD pdwPictAspectRatioY);
    STDMETHODIMP SetCallbackInterface(IDDrawExclModeVideoCallback *pCallback, DWORD dwFlags);
    STDMETHODIMP GetCurrentImage(YUV_IMAGE** lplpImage);
    STDMETHODIMP IsImageCaptureSupported();
    STDMETHODIMP ChangeMonitor(HMONITOR hMonitor, LPDIRECTDRAW pDDrawObject, LPDIRECTDRAWSURFACE pDDrawSurface);
    STDMETHODIMP DisplayModeChanged(HMONITOR hMonitor, LPDIRECTDRAW pDDrawObject, LPDIRECTDRAWSURFACE pDDrawSurface);
    STDMETHODIMP RestoreSurfaces();

    // IAMVideoDecimationProperties
    STDMETHODIMP QueryDecimationUsage(DECIMATION_USAGE* lpUsage);
    STDMETHODIMP SetDecimationUsage(DECIMATION_USAGE Usage);

    // IAMOverlayFX interface methods
    STDMETHODIMP QueryOverlayFXCaps(DWORD *lpdwOverlayFXCaps);
    STDMETHODIMP SetOverlayFX(DWORD dwOveralyFX);
    STDMETHODIMP GetOverlayFX(DWORD *lpdwOverlayFX);

    // IAMPreferredDDrawDevice
    STDMETHODIMP SetDDrawGUID(const AMDDRAWGUID* lpGUID);
    STDMETHODIMP GetDDrawGUID(AMDDRAWGUID* lpGUID);
    STDMETHODIMP SetDefaultDDrawGUID(const AMDDRAWGUID* lpGUID);
    STDMETHODIMP GetDefaultDDrawGUID(AMDDRAWGUID* lpGUID);
    STDMETHODIMP GetDDrawGUIDs(LPDWORD lpdw, AMDDRAWMONITORINFO** lplpInfo);


    CBPCWrap    m_BPCWrap;

    bool OnlySupportVideoInfo2() const { return m_bOnlySupportVideoInfo2; }
    HMONITOR GetCurrentMonitor(BOOL fUpdate = TRUE);  // making public helps MV class

    BOOL ColorKeySet() const { return m_bColorKeySet; }

    BOOL OverlayVisible() const { return m_bOverlayVisible; }

    void CheckOverlayHidden();

    void      SetCopyProtect(BOOL bState)  { m_bCopyProtect = bState ; }
    BOOL      NeedCopyProtect(void)        { return m_bCopyProtect ; }

    DWORD KernelCaps() const { return m_dwKernelCaps;}
    BOOL    IsFaultyMMaticsMoComp();

private:
    // helper function to get IBaseVideo from outpun pin
    HRESULT GetBasicVideoFromOutPin(IBasicVideo** pBasicVideo);

    // override this if you want to supply your own pins
    virtual HRESULT CreatePins();
    virtual void DeletePins();
    HRESULT CreateInputPin(BOOL bVPSupported);
    void DeleteInputPin(COMInputPin *pPin);

    // ddraw related functions
    HRESULT InitDirectDraw(LPDIRECTDRAW pDirectDraw);

    DWORD ReleaseDirectDraw();
    HRESULT CreatePrimarySurface();
    DWORD ReleasePrimarySurface();
    HRESULT CheckSuitableVersion();
    HRESULT CheckCaps();

    HRESULT MatchGUID(const GUID* lpGUID, LPDWORD lpdwMatchID);
    HRESULT GetDDrawEnumFunction(LPDIRECTDRAWENUMERATEEXA* ppDrawEnumEx);

    // Wrapper for UpdateOverlay - tracks state and manages the color key
    HRESULT CallUpdateOverlay(IDirectDrawSurface *pSurface,
                              LPRECT prcSrc,
                              LPDIRECTDRAWSURFACE pDestSurface,
                              LPRECT prcDest,
                              DWORD dwFlags,
                              IOverlayNotify *pNotify = NULL,
                              LPRGNDATA pBuffer = NULL);


    CCritSec                m_csFilter;                         // filter wide lock
    DWORD                   m_dwInputPinCount;                  // number of input pins
    COMOutputPin            *m_pOutput;                         // output pin
    DWORD                   m_dwMaxPinId;                       // stores the id to be given to the pins
    IMixerOCXNotify         *m_pIMixerOCXNotify;
    BOOL                    m_bWindowless;

    // MultiMonitor stuff
    DWORD                   m_dwDDrawInfoArrayLen;
    AMDDRAWMONITORINFO*     m_lpDDrawInfo;
    AMDDRAWMONITORINFO*     m_lpCurrentMonitor;
    AMDDRAWGUID             m_ConnectionGUID;
    BOOL                    m_fDisplayChangePosted;
    BOOL                    m_fMonitorWarning;
    UINT                    m_MonitorChangeMsg;

    DWORD                   m_dwDDObjReleaseMask;
    LPDIRECTDRAW            m_pOldDDObj;            // Old DDraw object prior to a display change

    /*
    If an app calls IDDrawExclModeVideo::SetDdrawObject() on the filter in its PostConnection state, the
    filter just caches that ddraw object. m_pUpdatedDirectDraw represents the cached ddraw object. In
    PreConnection state, m_pDirectDraw and m_pUpdatedDirectDraw are always in sync. After all
    pins of the ovmixer have broken their connection, the filter checks to see if m_pUpdatedDirectDraw
    is different from m_pDirectDraw, and if they are, they are brought in sync again.

    Absolutely the same logic is used for m_pPrimarySurface and m_pUpdatedPrimarySurface
    */

    // ddraw stuff
    HINSTANCE                   m_hDirectDraw;      // Handle to the loaded library
    LPDIRECTDRAWCREATE          m_lpfnDDrawCreate;  // ptr to DirectDrawCreate
    LPDIRECTDRAWENUMERATEA      m_lpfnDDrawEnum;    // ptr to DirectDrawEnumA
    LPDIRECTDRAWENUMERATEEXA    m_lpfnDDrawEnumEx;  // ptr to DirectDrawEnumExA

    LPDIRECTDRAW            m_pDirectDraw;                      // DirectDraw service provider
    LPDIRECTDRAW            m_pUpdatedDirectDraw;               // Updated DirectDraw object
    DDCAPS                  m_DirectCaps;                       // Actual hardware capabilities
    DDCAPS                  m_DirectSoftCaps;                   // Emulted capabilities
    DWORD                   m_dwKernelCaps;                     // Kernel caps
    LPDIRECTDRAWSURFACE     m_pPrimarySurface;                  // primary surface
    LPDIRECTDRAWSURFACE     m_pUpdatedPrimarySurface;           // primary surface
    IDDrawExclModeVideoCallback *m_pExclModeCallback;           // callback to exclusive mode client
    bool                    m_UsingIDDrawNonExclModeVideo;
    bool                    m_UsingIDDrawExclModeVideo;

    // FX flags for the DDOVERLAYFX structure
    DWORD                   m_dwOverlayFX;

    // track overlay state
    BOOL                    m_bOverlayVisible;
    RECT                    m_rcOverlaySrc;
    RECT                    m_rcOverlayDest;

    //
    CImageDisplay           m_Display;
    COLORKEY                m_ColorKey;
    BOOL                    m_bColorKeySet;
    BOOL                    m_bNeedToRecreatePrimSurface;
    BOOL                    m_bUseGDI;
    BOOL                    m_bExternalPrimarySurface;
    BOOL                    m_bExternalDirectDraw;

    // IOverlayNotify and IMixerOCX related members
    WININFO                 m_WinInfo;
    BOOL                    m_bWinInfoStored;
    HDC                     m_hDC;
    DWORD                   m_dwNumPaletteEntries;

    // adjusted video size paramters
    DWORD                   m_dwAdjustedVideoWidth;
    DWORD                   m_dwAdjustedVideoHeight;

    // Pins
    COMInputPin            *m_apInput[MAX_PIN_COUNT];           // Array of input pin pointers

    // Space to store palette
    PALETTEENTRY            m_pPaletteEntries[iPALETTE_COLORS];

    // Hack - only support videoinfo2
    const bool              m_bOnlySupportVideoInfo2;

    CDispMacroVision        m_MacroVision ;  // MV support as an object
    BOOL                    m_bCopyProtect ; // Is MV support to be done in OvMixer?

    // Support IMediaSeeking
    IUnknown                *m_pPosition;

    // Support IEnumPinConfig
    DWORD                   m_dwPinConfigNext;


    // Support IAMVideoDecimationProperties
    DECIMATION_USAGE        m_dwDecimation;
#ifdef DEBUG
#define WM_DISPLAY_WINDOW_TEXT  (WM_USER+7837)
    TCHAR                   m_WindowText[80];
#endif
    // Hack for MMatics misused MoComp interfaces v38..v42
    BOOL                    m_bHaveCheckedMMatics;
    BOOL                    m_bIsFaultyMMatics;
};


class CDDrawMediaSample : public CMediaSample, public IDirectDrawMediaSample
{
public:

    CDDrawMediaSample(TCHAR *pName, CBaseAllocator *pAllocator, HRESULT *phr, LPBYTE pBuffer, LONG length,
                      bool bKernelLock);
    ~CDDrawMediaSample();

    /* Note the media sample does not delegate to its owner */
    STDMETHODIMP QueryInterface(REFIID riid, void **ppv);
    STDMETHODIMP_(ULONG) AddRef() { return CMediaSample::AddRef(); }
    STDMETHODIMP_(ULONG) Release() { return CMediaSample::Release(); }

    void SetDIBData(DIBDATA *pDibData);
    DIBDATA *GetDIBData();

    HRESULT SetDDrawSampleSize(DWORD dwDDrawSampleSize);
    HRESULT GetDDrawSampleSize(DWORD *pdwDDrawSampleSize);
    HRESULT SetDDrawSurface(LPDIRECTDRAWSURFACE pDirectDrawSurface);
    HRESULT GetDDrawSurface(LPDIRECTDRAWSURFACE *ppDirectDrawSurface);

    // methods belonging to IDirectDrawMediaSample
    STDMETHODIMP GetSurfaceAndReleaseLock(IDirectDrawSurface **ppDirectDrawSurface, RECT* pRect);
    STDMETHODIMP LockMediaSamplePointer(void);
	
    /*  Hack to get at the list */
    CMediaSample         * &Next() { return m_pNext; }
private:
    DIBDATA                 m_DibData;                      // Information about the DIBSECTION
    LPDIRECTDRAWSURFACE     m_pDirectDrawSurface;           // pointer to the direct draw surface
    DWORD                   m_dwDDrawSampleSize;            // ddraw sample size
    bool                    m_bInit;                        // Is the DIB information setup
    bool                    m_bSurfaceLocked;               // specifies whether surface is locked or not
    bool                    m_bKernelLock;                  // lock with no sys lock
    RECT                    m_SurfaceRect;                  // the part of the surface that is locked
};


class COMInputAllocator : public CBaseAllocator, public IDirectDrawMediaSampleAllocator
{
    friend class COMInputPin;
public:

    COMInputAllocator(COMInputPin *pPin, CCritSec *pLock, HRESULT *phr);             // Return code
#ifdef DEBUG
    ~COMInputAllocator();
#endif // DEBUG
    DECLARE_IUNKNOWN

    STDMETHODIMP COMInputAllocator::NonDelegatingQueryInterface(REFIID riid, void **ppv);

    STDMETHODIMP SetProperties(ALLOCATOR_PROPERTIES* pRequest, ALLOCATOR_PROPERTIES* pActual);
    STDMETHODIMP GetBuffer(IMediaSample **ppSample, REFERENCE_TIME *pStartTime,
	REFERENCE_TIME *pEndTime, DWORD dwFlags);
    STDMETHODIMP ReleaseBuffer(IMediaSample *pMediaSample);

    // function to implement IDirectDrawMediaSampleAllocator
    STDMETHODIMP GetDirectDraw(IDirectDraw **ppDirectDraw);
	
    //  Check all samples are returned
    BOOL CanFree() const
    {
	return m_lFree.GetCount() == m_lAllocated;
    }
protected:
    void Free();
    HRESULT Alloc();

private:
    COMInputPin             *m_pPin;
    CCritSec                *m_pFilterLock;                 // Critical section for interfaces
};

class COMInputPin :
public CBaseInputPin,
public IMixerPinConfig3,
public IOverlay,
public IVPControl,
public IKsPin,
public IKsPropertySet,
public IAMVideoAccelerator,
public ISpecifyPropertyPages,
public IPinConnection
{
public:
    COMInputPin(TCHAR *pObjectName, COMFilter *pFilter, CCritSec *pLock,
	BOOL bVPSupported, HRESULT *phr, LPCWSTR pPinName, DWORD dwPinNo);
    ~COMInputPin();
    friend class COMInputAllocator;
    friend class COMFilter;

    DECLARE_IUNKNOWN

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void **ppv);
    STDMETHODIMP_(ULONG) NonDelegatingAddRef();
    STDMETHODIMP_(ULONG) NonDelegatingRelease();

    //
    // --- ISpecifyPropertyPages ---
    //
    STDMETHODIMP GetPages(CAUUID *pPages);

    // Override ReceiveConnection to allow format changes while running
    STDMETHODIMP ReceiveConnection(IPin * pConnector, const AM_MEDIA_TYPE *pmt);

    // connection related functions
    HRESULT CheckConnect(IPin * pReceivePin);
    HRESULT CompleteConnect(IPin *pReceivePin);
    HRESULT BreakConnect();
//  HRESULT GetMediaType(int iPosition,CMediaType *pMediaType);
    HRESULT CheckInterlaceFlags(DWORD dwInterlaceFlags);
    HRESULT DynamicCheckMediaType(const CMediaType* pmt);
    HRESULT CheckMediaType(const CMediaType* mtOut);
    HRESULT SetMediaType(const CMediaType *pmt);
    HRESULT FinalConnect();
    HRESULT UpdateMediaType();

    // streaming functions
    HRESULT Active();
    HRESULT Inactive();
    HRESULT Run(REFERENCE_TIME tStart);
    HRESULT RunToPause();
    STDMETHODIMP BeginFlush();
    STDMETHODIMP EndFlush();
    STDMETHODIMP Receive(IMediaSample *pMediaSample);
    STDMETHODIMP EndOfStream(void);
    STDMETHODIMP GetState(DWORD dwMSecs,FILTER_STATE *pState);
    HRESULT CompleteStateChange(FILTER_STATE OldState);
    HRESULT OnReceiveFirstSample(IMediaSample *pMediaSample);
    HRESULT DoRenderSample(IMediaSample *pMediaSample);
    HRESULT FlipOverlayToItself();
    HRESULT CalcSrcDestRect(const DRECT *prdRelativeSrcRect, const DRECT *prdDestRect, RECT *pAdjustedSrcRect, RECT *pAdjustedDestRect, RECT *prUncroppedDestRect);

    // allocator related functions
    BOOL UsingOurAllocator() { return m_bUsingOurAllocator; }
    STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);
    STDMETHODIMP NotifyAllocator(IMemAllocator *pAllocator,BOOL bReadOnly);
    HRESULT OnSetProperties(ALLOCATOR_PROPERTIES* pRequest, ALLOCATOR_PROPERTIES* pActual);
    HRESULT OnAlloc(CDDrawMediaSample **ppSampleList, DWORD dwSampleCount);
    HRESULT OnGetBuffer(IMediaSample **ppSample, REFERENCE_TIME *pStartTime,
	REFERENCE_TIME *pEndTime, DWORD dwFlags);
    HRESULT OnReleaseBuffer(IMediaSample *pIMediaSample);
    HRESULT CreateDDrawSurface(CMediaType *pMediaType, AM_RENDER_TRANSPORT amRenderTransport,
	DWORD *dwMaxBufferCount, LPDIRECTDRAWSURFACE *ppDDrawSurface);

    // some helper fnctions
    BOOL IsCompletelyConnected() { return m_bConnected; }
    DWORD GetPinId() { return m_dwPinId; }
    DWORD GetInternalZOrder() { return m_dwInternalZOrder; }
    HRESULT CurrentAdjustedMediaType(CMediaType *pmt);
    HRESULT CopyAndAdjustMediaType(CMediaType *pmtTarget, CMediaType *pmtSource);
    IPin *CurrentPeer() { return m_Connected; }
    void DoQualityMessage();
    HRESULT GetAdjustedModeAndAspectRatio(AM_ASPECT_RATIO_MODE* pamAdjustedARMode,
	DWORD *pdwAdjustedPARatioX, DWORD *pdwAdjustedPARatioY);
    void SetRenderTransport(AM_RENDER_TRANSPORT amRenderTransport) { ASSERT(amRenderTransport != AM_VIDEOPORT); ASSERT(amRenderTransport != AM_IOVERLAY); m_RenderTransport = amRenderTransport; }
    void SetVPSupported(BOOL bVPSupported) { ASSERT(m_pIVPObject); m_bVPSupported = bVPSupported; }
    void SetIOverlaySupported(BOOL bIOverlaySupported) { m_bIOverlaySupported = bIOverlaySupported; }
    void SetVideoAcceleratorSupported(BOOL bVideoAcceleratorSupported) { m_bVideoAcceleratorSupported = bVideoAcceleratorSupported; }
    HRESULT NewPaletteSet() { m_bDynamicFormatNeeded = TRUE; m_bNewPaletteSet = TRUE; NotifyChange(ADVISE_PALETTE); return NOERROR; }
    HRESULT GetSourceAndDest(RECT *prcSource, RECT *prcDest, DWORD *dwWidth, DWORD *dwHeight);

    // functions used to handle window/display changes
    HRESULT OnClipChange(LPWININFO pWinInfo);
    HRESULT OnDisplayChange();
    HRESULT RestoreDDrawSurface();

    // functions belonging to IPinConnection
    // Do you accept this type change in your current state?
    STDMETHODIMP DynamicQueryAccept(const AM_MEDIA_TYPE *pmt);

    //  Set event when EndOfStream receive - do NOT pass it on
    //  This condition is cancelled by a flush or Stop
    STDMETHODIMP NotifyEndOfStream(HANDLE hNotifyEvent);

    //  Are you an 'end pin'
    STDMETHODIMP IsEndPin();
    STDMETHODIMP DynamicDisconnect();

    // functions belonging to IMixerPinConfig
    STDMETHODIMP SetRelativePosition(DWORD dwLeft, DWORD dwTop, DWORD dwRight, DWORD dwBottom);
    STDMETHODIMP GetRelativePosition(DWORD *pdwLeft, DWORD *pdwTop, DWORD *pdwRight, DWORD *pdwBottom);
    STDMETHODIMP SetZOrder(DWORD dwZOrder);
    STDMETHODIMP GetZOrder(DWORD *pdwZOrder);
    STDMETHODIMP SetColorKey(COLORKEY *pColorKey);
    STDMETHODIMP GetColorKey(COLORKEY *pColorKey, DWORD *pColor);
    STDMETHODIMP SetBlendingParameter(DWORD dwBlendingParameter);
    STDMETHODIMP GetBlendingParameter(DWORD *pdwBlendingParameter);
    STDMETHODIMP SetStreamTransparent(BOOL bStreamTransparent);
    STDMETHODIMP GetStreamTransparent(BOOL *pbStreamTransparent);
    STDMETHODIMP SetAspectRatioMode(AM_ASPECT_RATIO_MODE amAspectRatioMode);
    STDMETHODIMP GetAspectRatioMode(AM_ASPECT_RATIO_MODE* pamAspectRatioMode);

    // functions added in IMixerPinConfig2
    STDMETHODIMP SetOverlaySurfaceColorControls(LPDDCOLORCONTROL pColorControl);
    STDMETHODIMP GetOverlaySurfaceColorControls(LPDDCOLORCONTROL pColorControl);

    // Helper for GetOverlaySurfaceControls and GetCurrentImage;
    STDMETHODIMP GetOverlaySurface(LPDIRECTDRAWSURFACE *pOverlaySurface);

    // functions added in IMixerPinConfig3
    STDMETHODIMP GetRenderTransport(AM_RENDER_TRANSPORT *pamRenderTransport);

    // functions belonging to IOverlay
    STDMETHODIMP GetWindowHandle(HWND *pHwnd);
    STDMETHODIMP Advise(IOverlayNotify *pOverlayNotify, DWORD dwInterests);
    STDMETHODIMP Unadvise();
    STDMETHODIMP GetClipList(RECT *pSourceRect, RECT *pDestinationRect, RGNDATA **ppRgnData);
    STDMETHODIMP GetVideoPosition(RECT *pSourceRect, RECT *pDestinationRect);
    STDMETHODIMP GetDefaultColorKey(COLORKEY *pColorKey);
    STDMETHODIMP GetColorKey(COLORKEY *pColorKey) {
        if (!pColorKey) {
            return E_POINTER;
        }
        return m_pFilter->GetColorKey(pColorKey, NULL);
    }
    STDMETHODIMP GetPalette(DWORD *pdwColors,PALETTEENTRY **ppPalette);
    STDMETHODIMP SetPalette(DWORD dwColors, PALETTEENTRY *pPaletteColors);
    // helper function used in implementation of IOverlay
    HRESULT NotifyChange(DWORD dwAdviseChanges);

    // functions belonging to IVPControl
    STDMETHODIMP EventNotify(long lEventCode, long lEventParam1, long lEventParam2);
    STDMETHODIMP_(LPDIRECTDRAW) GetDirectDraw() { return m_pFilter->GetDirectDraw(); }
    STDMETHODIMP_(LPDIRECTDRAWSURFACE) GetPrimarySurface() { return m_pFilter->GetPrimarySurface(); }
    STDMETHODIMP_(LPDDCAPS) GetHardwareCaps() { return m_pFilter->GetHardwareCaps(); }
    STDMETHODIMP CallUpdateOverlay(IDirectDrawSurface *pSurface,
                              LPRECT prcSrc,
                              LPDIRECTDRAWSURFACE pDestSurface,
                              LPRECT prcDest,
                              DWORD dwFlags)
    {
        return m_pFilter->CallUpdateOverlay(pSurface,
                                            prcSrc,
                                            pDestSurface,
                                            prcDest,
                                            dwFlags);
    }

    STDMETHODIMP GetCaptureInfo(BOOL *lpCapturing,
                                DWORD *lpdwWidth,DWORD *lpdwHeight,
                                BOOL *lpInterleave);

    STDMETHODIMP GetVideoDecimation(IDecimateVideoImage** lplpDVI);
    STDMETHODIMP GetDecimationUsage(DECIMATION_USAGE *lpdwUsage);

    STDMETHODIMP CropSourceRect(LPWININFO pWinInfo,
                                DWORD dwMinZoomFactorX,
                                DWORD dwMinZoomFactorY);

    STDMETHODIMP SetFrameStepMode(DWORD dwFramesToStep);
    STDMETHODIMP CancelFrameStepMode();

    HRESULT ApplyOvlyFX()
    {
        return m_pFilter->CallUpdateOverlay(
                 m_pDirectDrawSurface,
                 &m_WinInfo.SrcClipRect,
                 m_pFilter->GetPrimarySurface(),
                 &m_WinInfo.DestClipRect,
                 DDOVER_KEYDEST);
    }

    // helper functions
    void SetKsMedium   (const KSPIN_MEDIUM *pMedium)    {m_Medium = *pMedium;}
    void SetKsCategory (const GUID *pCategory)  {m_CategoryGUID = *pCategory;}
    void SetStreamingInKernelMode (BOOL bStreamingInKernelMode)  {m_bStreamingInKernelMode = bStreamingInKernelMode;}

    // IKsPropertySet implementation
    STDMETHODIMP Set(REFGUID guidPropSet, DWORD dwPropID, LPVOID pInstanceData, DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData);
    STDMETHODIMP Get(REFGUID guidPropSet, DWORD dwPropID, LPVOID pInstanceData, DWORD cbInstanceData, LPVOID pPropData, DWORD cbPropData, DWORD *pcbReturned);
    STDMETHODIMP QuerySupported(REFGUID guidPropSet, DWORD dwPropID, DWORD *pTypeSupport);

    // IKsPin implementation
    virtual STDMETHODIMP KsQueryMediums(PKSMULTIPLE_ITEM *pMediumList);
    virtual STDMETHODIMP KsQueryInterfaces(PKSMULTIPLE_ITEM *pInterfaceList);
    STDMETHODIMP KsCreateSinkPinHandle(KSPIN_INTERFACE& Interface, KSPIN_MEDIUM& Medium)
	{ return E_UNEXPECTED; }
    STDMETHODIMP KsGetCurrentCommunication(KSPIN_COMMUNICATION *pCommunication,
	KSPIN_INTERFACE *pInterface, KSPIN_MEDIUM *pMedium);
    STDMETHODIMP KsPropagateAcquire()
	{ return NOERROR; }
    STDMETHODIMP KsDeliver(IMediaSample *pSample, ULONG Flags)
	{ return E_UNEXPECTED; }
    STDMETHODIMP KsMediaSamplesCompleted(PKSSTREAM_SEGMENT StreamSegment)
	{ return E_UNEXPECTED; }
    STDMETHODIMP_(IMemAllocator*) KsPeekAllocator(KSPEEKOPERATION Operation)
	{ return NULL; }
    STDMETHODIMP KsReceiveAllocator( IMemAllocator *pMemAllocator)
	{ return E_UNEXPECTED; }
    STDMETHODIMP KsRenegotiateAllocator()
	{ return E_UNEXPECTED; }
    STDMETHODIMP_(LONG) KsIncrementPendingIoCount()
	{ return E_UNEXPECTED; }
    STDMETHODIMP_(LONG) KsDecrementPendingIoCount()
	{ return E_UNEXPECTED; }
    STDMETHODIMP KsQualityNotify(ULONG Proportion, REFERENCE_TIME TimeDelta)
	{ return E_UNEXPECTED; }
    STDMETHODIMP_(REFERENCE_TIME) KsGetStartTime()
	{ return E_UNEXPECTED; }

    void CheckOverlayHidden();

    // helper functions to handle video accelerator comp
    HRESULT GetInfoFromCookie(DWORD dwCookie, LPCOMP_SURFACE_INFO *ppCompSurfInfo, LPSURFACE_INFO *ppSurfInfo);
    SURFACE_INFO *SurfaceInfoFromTypeAndIndex(DWORD dwTypeIndex, DWORD dwBufferIndex);
    BOOL IsSuitableVideoAcceleratorGuid(const GUID * pGuid);
    HRESULT InitializeUncompDataInfo(BITMAPINFOHEADER *pbmiHeader);
    HRESULT AllocateVACompSurfaces(LPDIRECTDRAW pDirectDraw, BITMAPINFOHEADER *pbmiHeader);
    HRESULT AllocateMCUncompSurfaces(LPDIRECTDRAW pDirectDraw, BITMAPINFOHEADER *pbmiHeader);
    HRESULT CreateVideoAcceleratorObject();
    HRESULT VACompleteConnect(IPin *pReceivePin, const CMediaType *pMediaType);
    HRESULT VABreakConnect();
    HRESULT CheckValidMCConnection();

    // IAMVideoAccelerator implementation
    STDMETHODIMP GetVideoAcceleratorGUIDs(LPDWORD pdwNumGuidsSupported, LPGUID pGuidsSupported);
    STDMETHODIMP GetUncompFormatsSupported(const GUID * pGuid, LPDWORD pdwNumFormatsSupported, LPDDPIXELFORMAT pFormatsSupported);
    STDMETHODIMP GetInternalMemInfo(const GUID * pGuid, const AMVAUncompDataInfo *pamvaUncompDataInfo, LPAMVAInternalMemInfo pamvaInternalMemInfo);
    STDMETHODIMP GetCompBufferInfo(const GUID * pGuid, const AMVAUncompDataInfo *pamvaUncompDataInfo, LPDWORD pdwNumTypesCompBuffers,  LPAMVACompBufferInfo pamvaCCompBufferInfo);
    STDMETHODIMP GetInternalCompBufferInfo(LPDWORD pdwNumTypesCompBuffers,  LPAMVACompBufferInfo pamvaCCompBufferInfo);
    STDMETHODIMP BeginFrame(const AMVABeginFrameInfo *pamvaBeginFrameInfo);
    STDMETHODIMP EndFrame(const AMVAEndFrameInfo *pEndFrameInfo);
    STDMETHODIMP GetBuffer(
        DWORD dwTypeIndex,
        DWORD dwBufferIndex,
        BOOL bReadOnly,
        LPVOID *ppBuffer,
        LPLONG lpStride);
    STDMETHODIMP ReleaseBuffer(DWORD dwTypeIndex, DWORD dwBufferIndex);
    STDMETHODIMP Execute(
        DWORD dwFunction,
        LPVOID lpPrivateInputData,
        DWORD cbPrivateInputData,
        LPVOID lpPrivateOutputData,
        DWORD cbPrivateOutputData,
        DWORD dwNumBuffers,
        const AMVABUFFERINFO *pAMVABufferInfo);
    STDMETHODIMP QueryRenderStatus(
        DWORD dwTypeIndex,
        DWORD dwBufferIndex,
        DWORD dwFlags);
    STDMETHODIMP DisplayFrame(DWORD dwFlipToIndex, IMediaSample *pMediaSample);

private:
    LONG                    m_cOurRef;                      // We maintain reference counting
    CCritSec                *m_pFilterLock;                 // Critical section for interfaces
    DWORD                   m_dwPinId;
    COMFilter               *m_pFilter;

    // VideoPort related stuff
    BOOL                    m_bVPSupported;
    LPUNKNOWN               m_pIVPUnknown;
    IVPObject               *m_pIVPObject;

    BOOL                    m_bIOverlaySupported;
    IOverlayNotify          *m_pIOverlayNotify;
    DWORD_PTR               m_dwAdviseNotify;

    // Synchronization stuff
    CAMSyncObj              *m_pSyncObj;

    // variables to implement IKsPin and IKsPropertySet
    KSPIN_MEDIUM           m_Medium;
    GUID                    m_CategoryGUID;
    KSPIN_COMMUNICATION    m_Communication;
    BOOL                    m_bStreamingInKernelMode;
    AMOVMIXEROWNER          m_OvMixerOwner;

#ifdef PERF
    int                     m_PerfFrameFlipped;
    int                     m_FrameReceived;
#endif

    // ddraw stuff
    LPDIRECTDRAWSURFACE     m_pDirectDrawSurface;
    LPDIRECTDRAWSURFACE     m_pBackBuffer;
    AM_RENDER_TRANSPORT     m_RenderTransport;
    DWORD                   m_dwBackBufferCount;
    DWORD                   m_dwDirectDrawSurfaceWidth;
    DWORD                   m_dwMinCKStretchFactor;
    BYTE                    m_bOverlayHidden;
    BYTE                    m_bSyncOnFill;
    BYTE                    m_bDontFlip ;
    BYTE                    m_bDynamicFormatNeeded;
    BYTE                    m_bNewPaletteSet;
    CMediaType              m_mtNew;
    CMediaType              m_mtNewAdjusted;
    DWORD                   m_dwUpdateOverlayFlags;
    DWORD                   m_dwInterlaceFlags;
    DWORD                   m_dwFlipFlag;
    DWORD                   m_dwFlipFlag2;
    BOOL                    m_bConnected;
    BOOL                    m_bUsingOurAllocator;
    HDC                     m_hMemoryDC;
    BOOL                    m_bCanOverAllocateBuffers;

    // window info related stuff
    WININFO                 m_WinInfo;
    RECT                    m_rRelPos;
    bool                    m_UpdateOverlayNeededAfterReceiveConnection;

    // variables to store the current aspect ratio and blending parameter
    DWORD                   m_dwZOrder;
    DWORD                   m_dwInternalZOrder;
    DWORD                   m_dwBlendingParameter;
    BOOL                    m_bStreamTransparent;
    AM_ASPECT_RATIO_MODE    m_amAspectRatioMode;
    BOOL                    m_bRuntimeNegotiationFailed;

    // Track frame delivery for QM
    REFERENCE_TIME          m_trLastFrame;

    // Backing DIB for Windowless renderer
    DIBDATA                 m_BackingDib;
    LONG                    m_BackingImageSize;


    HRESULT DrawGDISample(IMediaSample *pMediaSample);
    HRESULT DoRenderGDISample(IMediaSample *pMediaSample);

    // motion comp related variables
    BOOL                    m_bReallyFlipped;
    BOOL                    m_bVideoAcceleratorSupported;
    GUID                    m_mcGuid;
    DDVAUncompDataInfo      m_ddUncompDataInfo;
    DDVAInternalMemInfo     m_ddvaInternalMemInfo;
    DWORD                   m_dwCompSurfTypes;
    LPCOMP_SURFACE_INFO     m_pCompSurfInfo;
    IDDVideoAcceleratorContainer  *m_pIDDVAContainer;
    IDirectDrawVideoAccelerator   *m_pIDDVideoAccelerator;
    IAMVideoAcceleratorNotify     *m_pIVANotify;

    // Decimation related functions and variables
    HRESULT QueryDecimationOnPeer(long lWidth, long lHeight);

    enum {
        DECIMATION_NOT_SUPPORTED,   // decimation not supported
        DECIMATING_SIZE_SET,        // decimation image size changed
        DECIMATING_SIZE_NOTSET,     // decimation size didn't change
        DECIMATING_SIZE_RESET,      // decimation has been reset
    };

    HRESULT ResetDecimationIfSet();
    HRESULT TryDecoderDecimation(LPWININFO pWinInfo);
    BOOL    BeyondOverlayCaps(DWORD ScaleFactor);
    void    ApplyDecimation(LPWININFO pWinInfo);
    DWORD   GetOverlayStretchCaps();
    BOOL    Running();
    HRESULT GetUpstreamFilterName(TCHAR* FilterName);

    BOOL m_bDecimating;
    LONG m_lWidth, m_lHeight;
    LONG m_lSrcWidth, m_lSrcHeight;

    // Frame Step Stuff
    BOOL DoFrameStepAndReturnIfNeeded();
    HANDLE      m_StepEvent;		    // Used to signal timer events
    LONG        m_lFramesToStep;    // -ve == normal pb
                                    // +ve == frames to skips
                                    //   0 == time to block
    // IPinConnection stuff
    HANDLE      m_hEndOfStream;

};


class COMOutputPin : public CBaseOutputPin
{
public:
    COMOutputPin(TCHAR *pObjectName, COMFilter *pFilter, CCritSec *pLock,
	HRESULT *phr, LPCWSTR pPinName, DWORD dwPinNo);
    ~COMOutputPin();

    DECLARE_IUNKNOWN

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** ppv);

    HRESULT CompleteConnect(IPin *pReceivePin);
    HRESULT BreakConnect();
    HRESULT CheckMediaType(const CMediaType* mtOut);
    HRESULT GetMediaType(int iPosition,CMediaType *pmtOut);
    HRESULT SetMediaType(const CMediaType *pmt);

    HRESULT Active() { return NOERROR; }                                                                // override this as we don't have any allocator
    HRESULT Inactive() { return NOERROR; }                                                              // override this as we don't have any allocator
    HRESULT DecideBufferSize(IMemAllocator * pAlloc, ALLOCATOR_PROPERTIES * pProp);
    HRESULT DecideAllocator(IMemInputPin * pPin, IMemAllocator ** pAlloc) { return NOERROR; }           // override this as we don't have any allocator

    IPin *CurrentPeer() { return m_Connected; }
    DWORD GetPinId() { return m_dwPinId; }

    HWND GetWindow() { return m_hwnd; }
    HDC GetDC() { return m_hDC; }

    // functions related to subclassing and clipping to the renderer's window
    HRESULT SetNewWinProc();
    HRESULT SetOldWinProc();
    static LRESULT WINAPI NewWndProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam);
    HRESULT AttachWindowClipper();
    DWORD ReleaseWindowClipper();

private:
    CCritSec                *m_pFilterLock;
    IUnknown                *m_pPosition;
    DWORD                   m_dwPinId;
    COMFilter               *m_pFilter;
    IOverlay                *m_pIOverlay;
    BOOL                    m_bAdvise;

    // related to subclassing the renderer's window
    BOOL                    m_bWindowDestroyed;
    LONG_PTR                m_lOldWinUserData;
    WNDPROC                 m_hOldWinProc;

    LPDIRECTDRAWCLIPPER     m_pDrawClipper;                 // Used to handle the clipping
    HWND                    m_hwnd;
    HDC                     m_hDC;
    DWORD                   m_dwConnectWidth;
    DWORD                   m_dwConnectHeight;


};

BOOL
IsDecimationNeeded(
    DWORD ScaleFactor
    );

DWORD
GetCurrentScaleFactor(
    LPWININFO pWinInfo,
    DWORD* lpxScaleFactor = (DWORD*)NULL,
    DWORD* lpyScaleFactor = (DWORD*)NULL
    );

#endif //__OVMIXER__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmixer\omva.cpp ===
/******************************Module*Header*******************************\
* Module Name: omva.cpp
*
* Overlay mixer video accelerator functionality
*
* Copyright (c) 1998 - 1999  Microsoft Corporation.  All Rights Reserved.
\**************************************************************************/

#include <streams.h>
#include <ddraw.h>
#include <mmsystem.h>       // Needed for definition of timeGetTime
#include <limits.h>     // Standard data type limit definitions
#include <ks.h>
#include <ksproxy.h>
#include <bpcwrap.h>
#include <ddmmi.h>
#include <dvdmedia.h>
#include <amstream.h>
#include <dvp.h>
#include <ddkernel.h>
#include <vptype.h>
#include <vpconfig.h>
#include <vpnotify.h>
#include <vpobj.h>
#include <syncobj.h>
#include <mpconfig.h>
#include <ovmixpos.h>
#include <macvis.h>
#include <ovmixer.h>
#include "MultMon.h"  // our version of multimon.h include ChangeDisplaySettingsEx
#include <malloc.h>


//
//  Check if a media subtype GUID is a video accelerator type GUID
//
//  This function calls the DirectDraw video accelerator container
//  to list the video accelerator GUIDs and checks to see if the
//  Guid passed in is a supported video accelerator GUID.
//
//  We should only do this if the upstream pin support IVideoAccleratorNotify
//  since otherwise they may be trying to use the GUID without the
//  video accelerator interface
//
BOOL COMInputPin::IsSuitableVideoAcceleratorGuid(const GUID * pGuid)
{
    HRESULT hr = NOERROR;
    LPDIRECTDRAW pDirectDraw = NULL;
    DWORD dwNumGuidsSupported = 0, i = 0;
    LPGUID pGuidsSupported = NULL;
    BOOL bMatchFound = FALSE;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::IsSuitableVideoAcceleratorGuid")));

    ASSERT(pGuid);

    if (!m_pIDDVAContainer)
    {
        pDirectDraw = m_pFilter->GetDirectDraw();
        ASSERT(pDirectDraw);

        hr = pDirectDraw->QueryInterface(IID_IDDVideoAcceleratorContainer, (void**)&m_pIDDVAContainer);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pDirectDraw->QueryInterface(IID_IVideoAcceleratorContainer) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
        else
        {
            DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("pDirectDraw->QueryInterface(IID_IVideoAcceleratorContainer) succeeded")));
        }
    }

    ASSERT(m_pIDDVAContainer);

    // get the guids supported by the vga

    // find the number of guids supported
    hr = m_pIDDVAContainer->GetVideoAcceleratorGUIDs(&dwNumGuidsSupported, NULL);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIDDVAContainer->GetVideoAcceleratorGUIDs failed, hr = 0x%x"), hr));
	goto CleanUp;
    }
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("%d Motion comp GUIDs supported")));
    ASSERT(dwNumGuidsSupported);
    if (0 == dwNumGuidsSupported)
    {
        goto CleanUp;
    }

    // allocate the necessary memory
    pGuidsSupported = (LPGUID) _alloca(dwNumGuidsSupported*sizeof(GUID));

    // get the guids proposed
    hr = m_pIDDVAContainer->GetVideoAcceleratorGUIDs(&dwNumGuidsSupported, pGuidsSupported);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIDDVAContainer->GetVideoAcceleratorGUIDs failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    for (i = 0; i < dwNumGuidsSupported; i++)
    {
        if (*pGuid == pGuidsSupported[i])
        {
            bMatchFound = TRUE;
            break;
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("%s %s suitable video accelerator GUID"),
           (LPCTSTR)CDisp(*pGuid), bMatchFound ? TEXT("is") : TEXT("is not")));
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::IsSuitableVideoAcceleratorGuid")));
    return bMatchFound;
}

// initialize the m_ddUncompDataInfo struct
// get the uncompressed pixel format by choosing the first of all formats supported by the vga
HRESULT COMInputPin::InitializeUncompDataInfo(BITMAPINFOHEADER *pbmiHeader)
{
    HRESULT hr = NOERROR;

    AMVAUncompBufferInfo amvaUncompBufferInfo;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::InitializeUncompDataInfo")));

    // find the number of entries to be proposed
    hr = m_pIVANotify->GetUncompSurfacesInfo(&m_mcGuid, &amvaUncompBufferInfo);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIVANotify->GetUncompSurfacesInfo failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    // initialize the m_ddUncompDataInfo structure
    // We choose the first pixel format since we don't care
    // provided we can make a surface (which we assume we can)
    INITDDSTRUCT(m_ddUncompDataInfo);
    m_ddUncompDataInfo.dwUncompWidth       = pbmiHeader->biWidth;
    m_ddUncompDataInfo.dwUncompHeight      = pbmiHeader->biHeight;
    m_ddUncompDataInfo.ddUncompPixelFormat = amvaUncompBufferInfo.ddUncompPixelFormat;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Uncompressed buffer pixel format %s"),
           (LPCTSTR)CDispPixelFormat(&amvaUncompBufferInfo.ddUncompPixelFormat)));

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::InitializeUncompDataInfo")));
    return hr;
}


HRESULT COMInputPin::AllocateVACompSurfaces(LPDIRECTDRAW pDirectDraw, BITMAPINFOHEADER *pbmiHeader)
{
    HRESULT hr = NOERROR;
    DWORD i = 0, j = 0;
    LPDDVACompBufferInfo pddCompSurfInfo = NULL;
    DDSURFACEDESC2 SurfaceDesc2;
    LPDIRECTDRAWSURFACE4 pSurface4 = NULL;
    LPDIRECTDRAW4 pDirectDraw4 = NULL;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::AllocateVACompSurfaces")));

    ASSERT(pDirectDraw);
    ASSERT(pbmiHeader);

    // get the compressed buffer info

    // find the number of entries to be proposed
    hr = m_pIDDVAContainer->GetCompBufferInfo(&m_mcGuid, &m_ddUncompDataInfo, &m_dwCompSurfTypes, NULL);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pIVANotify->GetCompBufferInfo failed, hr = 0x%x"), hr));
	goto CleanUp;
    }
    if (!m_dwCompSurfTypes)
    {
        hr = E_FAIL;
        goto CleanUp;
    }

    // allocate the necessary memory
    pddCompSurfInfo = (DDVACompBufferInfo *)_alloca(sizeof(DDVACompBufferInfo) * m_dwCompSurfTypes);

    // memset the allocated memory to zero
    memset(pddCompSurfInfo, 0, m_dwCompSurfTypes*sizeof(DDVACompBufferInfo));

    // set the right size of all the structs
    for (i = 0; i < m_dwCompSurfTypes; i++)
    {
        pddCompSurfInfo[i].dwSize = sizeof(DDVACompBufferInfo);
    }

    // get the entries proposed
    hr = m_pIDDVAContainer->GetCompBufferInfo(&m_mcGuid, &m_ddUncompDataInfo, &m_dwCompSurfTypes, pddCompSurfInfo);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("GetCompBufferInfo failed, hr = 0x%x"), hr));
	goto CleanUp;
    }
    //  Dump the formats
#ifdef DEBUG

#endif

    hr = pDirectDraw->QueryInterface(IID_IDirectDraw4, (void**)&pDirectDraw4);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pDirectDraw->QueryInterface(IID_IDirectDraw4) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // Set the surface description common to all kinds of surfaces
    INITDDSTRUCT(SurfaceDesc2);
    SurfaceDesc2.dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT | DDSD_PIXELFORMAT;

    // allocate memory for storing comp_surface_info
    m_pCompSurfInfo = new COMP_SURFACE_INFO[m_dwCompSurfTypes + 1];
    if (!m_pCompSurfInfo)
    {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // memset the allocated memory to zero
    memset(m_pCompSurfInfo, 0, (m_dwCompSurfTypes+1)*sizeof(COMP_SURFACE_INFO));

    // allocate the compressed surfaces
    for (i = 1; i <= m_dwCompSurfTypes; i++)
    {
        DWORD dwAlloc = pddCompSurfInfo[i-1].dwNumCompBuffers;
        if (dwAlloc == 0) {
            continue;
        }

        ASSERT(pddCompSurfInfo[i-1].dwNumCompBuffers);

        // allocate memory for storing surface_info for surfaces of this type
        m_pCompSurfInfo[i].pSurfInfo = new SURFACE_INFO[dwAlloc];
        if (!m_pCompSurfInfo[i].pSurfInfo)
        {
            hr = E_OUTOFMEMORY;
            goto CleanUp;
        }

        // memset the allocated memory to zero
        memset(m_pCompSurfInfo[i].pSurfInfo, 0, dwAlloc*sizeof(SURFACE_INFO));

        // intialize the pddCompSurfInfo[i-1] struct
        dwAlloc = m_pCompSurfInfo[i].dwAllocated = pddCompSurfInfo[i-1].dwNumCompBuffers;

        SurfaceDesc2.ddsCaps = pddCompSurfInfo[i-1].ddCompCaps;
        SurfaceDesc2.dwWidth = pddCompSurfInfo[i-1].dwWidthToCreate;
        SurfaceDesc2.dwHeight = pddCompSurfInfo[i-1].dwHeightToCreate;
        memcpy(&SurfaceDesc2.ddpfPixelFormat, &pddCompSurfInfo[i-1].ddPixelFormat, sizeof(DDPIXELFORMAT));

        // create the surfaces, storing surfaces handles for each
        for (j = 0; j < dwAlloc; j++)
        {
            hr = pDirectDraw4->CreateSurface(&SurfaceDesc2, &m_pCompSurfInfo[i].pSurfInfo[j].pSurface, NULL);
	    if (FAILED(hr))
	    {
		DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("Function CreateSurface failed, hr = 0x%x"), hr));
                goto CleanUp;
	    }
        }
    }

CleanUp:

    if (pDirectDraw4)
    {
        pDirectDraw4->Release();
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::AllocateVACompSurfaces")));
    return hr;

}

// allocate the uncompressed buffer
HRESULT COMInputPin::AllocateMCUncompSurfaces(LPDIRECTDRAW pDirectDraw, BITMAPINFOHEADER *pbmiHeader)
{
    HRESULT hr = NOERROR;
    AMVAUncompBufferInfo amUncompBufferInfo;
    DDSURFACEDESC2 SurfaceDesc2;
    LPDIRECTDRAWSURFACE4 pSurface4 = NULL;
    LPDIRECTDRAW4 pDirectDraw4 = NULL;
    DDSCAPS2 ddSurfaceCaps;
    DWORD i = 0, dwTotalBufferCount = 0;
    SURFACE_INFO *pSurfaceInfo;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::AllocateMCUncompSurfaces")));

    ASSERT(pDirectDraw);
    ASSERT(pbmiHeader);

    // get the uncompressed surface info from the decoder
    memset(&amUncompBufferInfo, 0, sizeof(AMVAUncompBufferInfo));
    hr = m_pIVANotify->GetUncompSurfacesInfo(&m_mcGuid, &amUncompBufferInfo);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,  TEXT("m_pIVANotify->GetUncompSurfacesInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    hr = pDirectDraw->QueryInterface(IID_IDirectDraw4, (void**)&pDirectDraw4);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pDirectDraw->QueryInterface(IID_IDirectDraw4) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // Set the surface description common to all kinds of surfaces
    memset((LPVOID)&SurfaceDesc2, 0, sizeof(DDSURFACEDESC2));
    SurfaceDesc2.dwSize = sizeof(DDSURFACEDESC2);
    SurfaceDesc2.dwFlags = DDSD_CAPS | DDSD_WIDTH | DDSD_HEIGHT | DDSD_PIXELFORMAT;

    // store the caps and dimensions
    SurfaceDesc2.ddsCaps.dwCaps = DDSCAPS_OVERLAY | DDSCAPS_VIDEOMEMORY;
    SurfaceDesc2.dwWidth = pbmiHeader->biWidth;
    SurfaceDesc2.dwHeight = pbmiHeader->biHeight;

    // define the pixel format
    SurfaceDesc2.ddpfPixelFormat = m_ddUncompDataInfo.ddUncompPixelFormat;

    if (amUncompBufferInfo.dwMinNumSurfaces > amUncompBufferInfo.dwMaxNumSurfaces) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,
                TEXT("dwMinNumSurface > dwMaxNumSurfaces")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    if (amUncompBufferInfo.dwMinNumSurfaces == 0) {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("dwMinNumSurface == 0")));
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    for (dwTotalBufferCount = max(amUncompBufferInfo.dwMaxNumSurfaces,3);
         dwTotalBufferCount >= amUncompBufferInfo.dwMinNumSurfaces;
         dwTotalBufferCount--)
    {
        // CleanUp stuff from the last loop
        if (pSurface4)
        {
            pSurface4->Release();
            pSurface4 = NULL;
        }

	if (dwTotalBufferCount > 1)
	{
	    SurfaceDesc2.dwFlags |= DDSD_BACKBUFFERCOUNT;
	    SurfaceDesc2.ddsCaps.dwCaps |= DDSCAPS_FLIP | DDSCAPS_COMPLEX | DDSCAPS_LOCALVIDMEM;
	    SurfaceDesc2.dwBackBufferCount = dwTotalBufferCount-1;
	}
	else
	{
	    SurfaceDesc2.dwFlags &= ~DDSD_BACKBUFFERCOUNT;
	    SurfaceDesc2.ddsCaps.dwCaps &= ~(DDSCAPS_FLIP | DDSCAPS_COMPLEX);
	    SurfaceDesc2.dwBackBufferCount = 0;
	}

	hr = pDirectDraw4->CreateSurface(&SurfaceDesc2, &pSurface4, NULL);
	if (FAILED(hr))
	{
	    DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("Function CreateSurface failed in Video memory, BackBufferCount = %d, hr = 0x%x"), dwTotalBufferCount-1, hr));
	}

        if (SUCCEEDED(hr))
        {
	    break;
        }
    }

    if (FAILED(hr))
        goto CleanUp;

    ASSERT(pSurface4);

    // store the complex surface in m_pDirectDrawSurface
    hr = pSurface4->QueryInterface(IID_IDirectDrawSurface, (void**)&m_pDirectDrawSurface);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pSurface4->QueryInterface(IID_IDirectDrawSurface) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(m_pDirectDrawSurface);

    m_dwBackBufferCount = SurfaceDesc2.dwBackBufferCount;

    ASSERT(m_pCompSurfInfo && NULL == m_pCompSurfInfo[0].pSurfInfo);
    m_pCompSurfInfo[0].pSurfInfo = new SURFACE_INFO[m_dwBackBufferCount + 1];
    if (NULL == m_pCompSurfInfo[0].pSurfInfo)
    {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // memset the allcated memory to zero
    memset(m_pCompSurfInfo[0].pSurfInfo, 0, (m_dwBackBufferCount+1)*sizeof(SURFACE_INFO));

    pSurfaceInfo = m_pCompSurfInfo[0].pSurfInfo;
    m_pCompSurfInfo[0].dwAllocated = m_dwBackBufferCount + 1;
    // initalize the m_ppUncompSurfaceList
    pSurfaceInfo->pSurface = pSurface4;
    pSurface4 = NULL;

    for (i = 0; i < m_dwBackBufferCount; i++)
    {
        memset((void*)&ddSurfaceCaps, 0, sizeof(DDSCAPS2));
        ddSurfaceCaps.dwCaps = DDSCAPS_FLIP | DDSCAPS_COMPLEX | DDSCAPS_OVERLAY;

        // Get the back buffer surface
        // New version of DirectX now requires DDSCAPS2 (header file
        // bug)
        // Note that this AddRef's the surface so we should be sure to
        // release them
	hr = pSurfaceInfo[i].pSurface->GetAttachedSurface(&ddSurfaceCaps, &pSurfaceInfo[i+1].pSurface);
	if (FAILED(hr))
	{
	    DbgLog((LOG_ERROR, VA_ERROR_LEVEL,  TEXT("Function pDDrawSurface->GetAttachedSurface failed, hr = 0x%x"), hr));
	    goto CleanUp;
	}
    }

    //  Pass back number of surfaces actually allocated
    hr = m_pIVANotify->SetUncompSurfacesInfo(
             min(dwTotalBufferCount, amUncompBufferInfo.dwMaxNumSurfaces));

CleanUp:

    if (pSurface4)
    {
        pSurface4->Release();
        pSurface4 = NULL;
    }

    if (pDirectDraw4)
    {
        pDirectDraw4->Release();
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::AllocateMCUncompSurfaces")));
    return hr;
}

// create the motion comp object, using the misc data from the decoder
HRESULT COMInputPin::CreateVideoAcceleratorObject()
{
    HRESULT hr = NOERROR;
    DWORD dwSizeMiscData = 0;
    LPVOID pMiscData = NULL;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::CreateVideoAcceleratorObject")));

    // get the data to be passed from the decoder
    hr = m_pIVANotify->GetCreateVideoAcceleratorData(&m_mcGuid, &dwSizeMiscData, &pMiscData);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIVANotify->GetCreateVideoAcceleratorData failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    // ask the vga for the motion comp object
    m_pIDDVideoAccelerator = NULL;
    hr = m_pIDDVAContainer->CreateVideoAccelerator(&m_mcGuid, &m_ddUncompDataInfo, pMiscData, dwSizeMiscData, &m_pIDDVideoAccelerator, NULL);

    //  Free motion comp data
    CoTaskMemFree(pMiscData);

    if (FAILED(hr) || !m_pIDDVideoAccelerator)
    {
        if (SUCCEEDED(hr)) {
            hr = E_FAIL;
        }
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIDDVAContainer->CreateVideoAcceleratorideo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::CreateVideoAcceleratorObject")));
    return hr;
}



HRESULT COMInputPin::VACompleteConnect(IPin *pReceivePin, const CMediaType *pMediaType)
{
    HRESULT hr = NOERROR;
    BITMAPINFOHEADER *pbmiHeader = NULL;
    DWORD dwNumUncompFormats = 0;
    LPDIRECTDRAW pDirectDraw = NULL;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::VACompleteConnect")));

    ASSERT(m_pIDDVAContainer);
    ASSERT(pReceivePin);
    ASSERT(pMediaType);
    pbmiHeader = GetbmiHeader(pMediaType);
    if ( ! pbmiHeader )
    {
        hr = E_FAIL;
        goto CleanUp;
    }

    pDirectDraw = m_pFilter->GetDirectDraw();
    ASSERT(pDirectDraw);

    // save the decoder's guid
    m_mcGuid = pMediaType->subtype;

    // initialize the get the uncompressed formats supported by the vga
    hr = InitializeUncompDataInfo(pbmiHeader);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,   TEXT("InitializeUncompDataInfo failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    // get the internal memory info
#if 0
    memset(&m_ddvaInternalMemInfo, 0, sizeof(DDVAInternalMemInfo));
    m_ddvaInternalMemInfo.dwSize = sizeof(DDVAInternalMemInfo);
    hr = m_pIDDVAContainer->GetInternalMemInfo(&m_mcGuid, &m_ddUncompDataInfo, &m_ddvaInternalMemInfo);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,  TEXT("m_pIDDVAContainer->GetInternalMemInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
#endif


    // allocate compressed buffers
    hr = AllocateVACompSurfaces(pDirectDraw, pbmiHeader);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,  TEXT("AllocateVACompSurfaces failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // allocate uncompressed buffers
    hr = AllocateMCUncompSurfaces(pDirectDraw, pbmiHeader);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,  TEXT("AllocateMCUncompSurfaces failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // create the motion comp object
    hr = CreateVideoAcceleratorObject();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL,  TEXT("CreateVideoAcceleratorObject failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::VACompleteConnect")));
    return hr;
}

HRESULT COMInputPin::VABreakConnect()
{
    HRESULT hr = NOERROR;
    DWORD i = 0, j = 0;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::VABreakConnect")));

    if (m_pCompSurfInfo)
    {
        for (i = 0; i < m_dwCompSurfTypes + 1; i++)
        {
            DWORD dwAlloc = m_pCompSurfInfo[i].dwAllocated;

            if (!m_pCompSurfInfo[i].pSurfInfo)
                continue;

            // release the compressed surfaces
            for (j = 0; j < dwAlloc; j++)
            {
                if (m_pCompSurfInfo[i].pSurfInfo[j].pSurface)
                {
                    //  Unlock if necessary
                    if (m_pCompSurfInfo[i].pSurfInfo[j].pBuffer) {
                        m_pCompSurfInfo[i].pSurfInfo[j].pSurface->Unlock(NULL);
                    }
                    m_pCompSurfInfo[i].pSurfInfo[j].pSurface->Release();
                }
            }
            delete [] m_pCompSurfInfo[i].pSurfInfo;
        }
        delete [] m_pCompSurfInfo;
        m_pCompSurfInfo = NULL;
    }
    m_dwCompSurfTypes = 0;

    if (m_pIDDVideoAccelerator)
    {
        m_pIDDVideoAccelerator->Release();
        m_pIDDVideoAccelerator = NULL;
    }

    if (m_pIDDVAContainer)
    {
        m_pIDDVAContainer->Release();
        m_pIDDVAContainer = NULL;
    }

    if (m_pIVANotify)
    {
        m_pIVANotify->Release();
        m_pIVANotify = NULL;
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::VABreakConnect")));
    return hr;
}




// pdwNumGuidsSupported is an IN OUT paramter
// pGuidsSupported is an IN OUT paramter
// if pGuidsSupported is NULL,  pdwNumGuidsSupported should return back with the
// number of uncompressed pixel formats supported
// Otherwise pGuidsSupported is an array of *pdwNumGuidsSupported structures

STDMETHODIMP COMInputPin::GetVideoAcceleratorGUIDs(LPDWORD pdwNumGuidsSupported, LPGUID pGuidsSupported)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::GetVideoAcceleratorGUIDs")));

    CAutoLock cLock(m_pFilterLock);

    if (!m_pIDDVAContainer)
    {
        IDirectDraw *pDirectDraw;
        pDirectDraw = m_pFilter->GetDirectDraw();
        ASSERT(pDirectDraw);

        hr = pDirectDraw->QueryInterface(IID_IDDVideoAcceleratorContainer, (void**)&m_pIDDVAContainer);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pDirectDraw->QueryInterface(IID_IVideoAcceleratorContainer) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
        else
        {
            DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("pDirectDraw->QueryInterface(IID_IVideoAcceleratorContainer) succeeded")));
        }
    }

    ASSERT(m_pIDDVAContainer);

    hr = m_pIDDVAContainer->GetVideoAcceleratorGUIDs(pdwNumGuidsSupported, pGuidsSupported);

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::GetVideoAcceleratorGUIDs")));
    return hr;
}

// pGuid is an IN parameter
// pdwNumFormatsSupported is an IN OUT paramter
// pFormatsSupported is an IN OUT paramter (caller should make sure to set the size of EACH struct)
// if pFormatsSupported is NULL,  pdwNumFormatsSupported should return back with
// the number of uncompressed pixel formats supported
// Otherwise pFormatsSupported is an array of *pdwNumFormatsSupported structures

STDMETHODIMP COMInputPin::GetUncompFormatsSupported(const GUID * pGuid, LPDWORD pdwNumFormatsSupported,
                                                    LPDDPIXELFORMAT pFormatsSupported)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::GetUncompFormatsSupported")));

    CAutoLock cLock(m_pFilterLock);

    if (!m_pIDDVAContainer)
    {
        hr = E_FAIL;
        goto CleanUp;
    }

    hr = m_pIDDVAContainer->GetUncompFormatsSupported((GUID *)pGuid, pdwNumFormatsSupported, pFormatsSupported);

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::GetUncompFormatsSupported")));
    return hr;
}

// pGuid is an IN parameter
// pddvaUncompDataInfo is an IN parameter
// pddvaInternalMemInfo is an IN OUT parameter (caller should make sure to set the size of struct)
// currently only gets info about how much scratch memory will the hal allocate for its private use

STDMETHODIMP COMInputPin::GetInternalMemInfo(const GUID * pGuid, const AMVAUncompDataInfo *pamvaUncompDataInfo,
                                             LPAMVAInternalMemInfo pamvaInternalMemInfo)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::GetInternalMemInfo")));

    CAutoLock cLock(m_pFilterLock);

    if (!m_pIDDVAContainer)
    {
        hr = E_FAIL;
        goto CleanUp;
    }

    DDVAUncompDataInfo ddvaDataInfo;
    INITDDSTRUCT(ddvaDataInfo);

    ddvaDataInfo.dwUncompWidth       = pamvaUncompDataInfo->dwUncompWidth;
    ddvaDataInfo.dwUncompHeight      = pamvaUncompDataInfo->dwUncompHeight;
    ddvaDataInfo.ddUncompPixelFormat = pamvaUncompDataInfo->ddUncompPixelFormat;

    DDVAInternalMemInfo ddvaInternalMemInfo;
    INITDDSTRUCT(ddvaInternalMemInfo);

    //  Unfortunately the ddraw header files don't use const
    hr = m_pIDDVAContainer->GetInternalMemInfo(
             (GUID *)pGuid,
             &ddvaDataInfo,
             &ddvaInternalMemInfo);

    if (SUCCEEDED(hr)) {
        pamvaInternalMemInfo->dwScratchMemAlloc =
            ddvaInternalMemInfo.dwScratchMemAlloc;
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::GetInternalMemInfo")));
    return hr;
}

// pGuid is an IN parameter
// pddvaUncompDataInfo is an IN parameter
// pdwNumTypesCompBuffers is an IN OUT paramter
// pddvaCompBufferInfo is an IN OUT paramter (caller should make sure to set the size of EACH struct)
// if pddvaCompBufferInfo is NULL,  pdwNumTypesCompBuffers should return back with the number of types of
// compressed buffers
// Otherwise pddvaCompBufferInfo is an array of *pdwNumTypesCompBuffers structures

STDMETHODIMP COMInputPin::GetCompBufferInfo(const GUID * pGuid, const AMVAUncompDataInfo *pamvaUncompDataInfo,
                                            LPDWORD pdwNumTypesCompBuffers,  LPAMVACompBufferInfo pamvaCompBufferInfo)
{
    HRESULT hr = NOERROR;
    DDVACompBufferInfo *pddvaCompBufferInfo = NULL; // Stays NULL if pamvaComBufferInfo is NULL

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::GetCompBufferInfo")));

    CAutoLock cLock(m_pFilterLock);

    if (!m_pIDDVAContainer)
    {
        hr = E_FAIL;
        goto CleanUp;
    }

    DDVAUncompDataInfo ddvaDataInfo;
    INITDDSTRUCT(ddvaDataInfo);
    ddvaDataInfo.dwUncompWidth       = pamvaUncompDataInfo->dwUncompWidth;
    ddvaDataInfo.dwUncompHeight      = pamvaUncompDataInfo->dwUncompHeight;
    ddvaDataInfo.ddUncompPixelFormat = pamvaUncompDataInfo->ddUncompPixelFormat;


    if (pamvaCompBufferInfo) {
        pddvaCompBufferInfo = (DDVACompBufferInfo *)
            _alloca(sizeof(DDVACompBufferInfo) * (*pdwNumTypesCompBuffers));
        for (DWORD j = 0; j < *pdwNumTypesCompBuffers; j++) {
            INITDDSTRUCT(pddvaCompBufferInfo[j]);
        }
    }

    hr = m_pIDDVAContainer->GetCompBufferInfo(
              (GUID *)pGuid,
              &ddvaDataInfo,
              pdwNumTypesCompBuffers,
              pddvaCompBufferInfo);

    if ((SUCCEEDED(hr) || hr == DDERR_MOREDATA) && pamvaCompBufferInfo) {

        for (DWORD i = 0; i < *pdwNumTypesCompBuffers; i++) {
            DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Compressed buffer type(%d) %d buffers width(%d) height(%d) bytes(%d)"),
                    i,
                    pddvaCompBufferInfo[i].dwNumCompBuffers,
                    pddvaCompBufferInfo[i].dwWidthToCreate,
                    pddvaCompBufferInfo[i].dwHeightToCreate,
                    pddvaCompBufferInfo[i].dwBytesToAllocate));


            pamvaCompBufferInfo[i].dwNumCompBuffers     = pddvaCompBufferInfo[i].dwNumCompBuffers;
            pamvaCompBufferInfo[i].dwWidthToCreate      = pddvaCompBufferInfo[i].dwWidthToCreate;
            pamvaCompBufferInfo[i].dwHeightToCreate     = pddvaCompBufferInfo[i].dwHeightToCreate;
            pamvaCompBufferInfo[i].dwBytesToAllocate    = pddvaCompBufferInfo[i].dwBytesToAllocate;
            pamvaCompBufferInfo[i].ddCompCaps           = pddvaCompBufferInfo[i].ddCompCaps;
            pamvaCompBufferInfo[i].ddPixelFormat        = pddvaCompBufferInfo[i].ddPixelFormat;
        }
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::GetCompBufferInfo")));
    return hr;
}


HRESULT COMInputPin::CheckValidMCConnection()
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::CheckValidMCConnection")));

    // if not connected, this function does not make much sense
    if (!IsCompletelyConnected())
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pin not connected, exiting")));
	hr = VFW_E_NOT_CONNECTED;
	goto CleanUp;
    }

    if (m_RenderTransport != AM_VIDEOACCELERATOR)
    {
        hr = VFW_E_INVALIDSUBTYPE;
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::CheckValidMCConnection")));
    return hr;
}

STDMETHODIMP COMInputPin::GetInternalCompBufferInfo(LPDWORD pdwNumTypesCompBuffers,  LPAMVACompBufferInfo pamvaCompBufferInfo)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::GetInternalCompBufferInfo")));

    CAutoLock cLock(m_pFilterLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    ASSERT(m_pIDDVAContainer);

    DDVACompBufferInfo ddvaCompBufferInfo;
    INITDDSTRUCT(ddvaCompBufferInfo);

    AMVAUncompDataInfo amvaUncompDataInfo;
    amvaUncompDataInfo.dwUncompWidth         = m_ddUncompDataInfo.dwUncompWidth;
    amvaUncompDataInfo.dwUncompHeight        = m_ddUncompDataInfo.dwUncompHeight;
    amvaUncompDataInfo.ddUncompPixelFormat   = m_ddUncompDataInfo.ddUncompPixelFormat;
    hr = GetCompBufferInfo(&m_mcGuid, &amvaUncompDataInfo, pdwNumTypesCompBuffers, pamvaCompBufferInfo);

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Leaving COMInputPin::GetInternalCompBufferInfo")));
    return hr;
}

STDMETHODIMP COMInputPin::BeginFrame(const AMVABeginFrameInfo *pamvaBeginFrameInfo)
{
    HRESULT hr = NOERROR;
    DDVABeginFrameInfo ddvaBeginFrameInfo;
    SURFACE_INFO *pSurfInfo;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::BeginFrame")));

    CAutoLock cLock(m_pFilterLock);

    if (!pamvaBeginFrameInfo)
    {
        hr = E_POINTER;
        goto CleanUp;
    }

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("BeginFrame index %d"), pamvaBeginFrameInfo->dwDestSurfaceIndex));

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
	goto CleanUp;
    }


    INITDDSTRUCT(ddvaBeginFrameInfo);

    pSurfInfo = SurfaceInfoFromTypeAndIndex(
                             0xFFFFFFFF,
                             pamvaBeginFrameInfo->dwDestSurfaceIndex);
    if (pSurfInfo == NULL) {
        hr = E_INVALIDARG;
        goto CleanUp;
    }
    ddvaBeginFrameInfo.pddDestSurface = pSurfInfo->pSurface;

    ddvaBeginFrameInfo.dwSizeInputData  = pamvaBeginFrameInfo->dwSizeInputData;
    ddvaBeginFrameInfo.pInputData       = pamvaBeginFrameInfo->pInputData;
    ddvaBeginFrameInfo.dwSizeOutputData = pamvaBeginFrameInfo->dwSizeOutputData;
    ddvaBeginFrameInfo.pOutputData      = pamvaBeginFrameInfo->pOutputData;

    ASSERT(m_pIDDVideoAccelerator);
    hr = m_pIDDVideoAccelerator->BeginFrame(&ddvaBeginFrameInfo);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIDDVideoAccelerator->BeginFrame failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("leaving COMInputPin::BeginFrame returnd 0x%8.8X"), hr));
    return hr;
}

// end a frame, the pMiscData is passed directly to the hal
// only valid to call this after the pins are connected

STDMETHODIMP COMInputPin::EndFrame(const AMVAEndFrameInfo *pEndFrameInfo)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::EndFrame")));

    CAutoLock cLock(m_pFilterLock);

    if (NULL == pEndFrameInfo) {
        hr = E_POINTER;
        goto CleanUp;
    }

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    ASSERT(m_pIDDVideoAccelerator);

    DDVAEndFrameInfo ddvaEndFrameInfo;
    INITDDSTRUCT(ddvaEndFrameInfo);
    ddvaEndFrameInfo.dwSizeMiscData = pEndFrameInfo->dwSizeMiscData;
    ddvaEndFrameInfo.pMiscData      = pEndFrameInfo->pMiscData;

    hr = m_pIDDVideoAccelerator->EndFrame(&ddvaEndFrameInfo);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIDDVideoAccelerator->EndFrame failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("leaving COMInputPin::EndFrame returned 0x%8.8X"), hr));
    return hr;
}

//  Get surface into structure given buffer type and buffer index
SURFACE_INFO *COMInputPin::SurfaceInfoFromTypeAndIndex(DWORD dwTypeIndex, DWORD dwBufferIndex)
{
    LPCOMP_SURFACE_INFO pCompSurfInfo;

    // make sure that type-index is less than the number of types
    if ((DWORD)(dwTypeIndex + 1) > m_dwCompSurfTypes)
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("dwTypeIndex is invalid, dwTypeIndex = %d, m_dwCompSurfTypes = %d"),
            dwTypeIndex, m_dwCompSurfTypes));
        return NULL;
    }


    // cache the pointer to the list they are interested in
    // Add 1 to allow for uncompressed surfaces
    pCompSurfInfo = m_pCompSurfInfo + (DWORD)(dwTypeIndex + 1);
    ASSERT(pCompSurfInfo);
    if (dwBufferIndex >= pCompSurfInfo->dwAllocated)
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("dwBufferIndex is invalid, dwBufferIndex = %d, dwAllocated = %d"),
            dwBufferIndex, pCompSurfInfo->dwAllocated));
        return NULL;
    }
    ASSERT(pCompSurfInfo->dwAllocated != 0);

    // get the pointer to the next available unlocked buffer info struct
    return pCompSurfInfo->pSurfInfo + dwBufferIndex;

}

//  Cycle through the compressed buffers
STDMETHODIMP COMInputPin::GetBuffer(
    DWORD dwTypeIndex,
    DWORD dwBufferIndex,
    BOOL bReadOnly,
    LPVOID *ppBuffer,
    LPLONG lpStride)
{
    HRESULT hr = NOERROR;
    LPSURFACE_INFO pSurfInfo = NULL;
    DDSURFACEDESC2 ddsd;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::GetBuffer type %d, index %d"),
            dwTypeIndex, dwBufferIndex));

    CAutoLock cLock(m_pFilterLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    if (ppBuffer == NULL || lpStride == NULL) {
        hr = E_POINTER;
        goto CleanUp;
    }

    pSurfInfo = SurfaceInfoFromTypeAndIndex(dwTypeIndex, dwBufferIndex);

    if (pSurfInfo == NULL) {
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    // Check buffer not already locked
    if (pSurfInfo->pBuffer != NULL)
    {
        hr = HRESULT_FROM_WIN32(ERROR_BUSY);
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("No more free buffers left or the decoder is releasing buffers out of order, returning E_UNEXPECTED")));
        goto CleanUp;
    }

    //  Wait until previous motion comp operation is complete
    while (DDERR_WASSTILLDRAWING ==
           m_pIDDVideoAccelerator->QueryRenderStatus(
               pSurfInfo->pSurface,
               bReadOnly ? DDVA_QUERYRENDERSTATUSF_READ : 0)) {
        Sleep(1);
    }
    //  Now lock the surface
    INITDDSTRUCT(ddsd);
    for (; ; )
    {
        hr = pSurfInfo->pSurface->Lock(NULL, &ddsd, DDLOCK_NOSYSLOCK, NULL);
        if (hr == DDERR_WASSTILLDRAWING)
        {
            DbgLog((LOG_TRACE, 1, TEXT("Compressed surface is busy")));
            Sleep(1);
        }
        else
        {
            break;
        }
    }

    if (dwBufferIndex == 0xFFFFFFFF && !bReadOnly) {
        //  Check if surface is being displayed
    }

    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pSurfInfo->pSurface->Lock failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    pSurfInfo->pBuffer = ddsd.lpSurface;
    *ppBuffer = ddsd.lpSurface;
    *lpStride = ddsd.lPitch;

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("leaving COMInputPin::GetBuffer returned 0x%8.8X"), hr));
    return hr;
}


//  unlock a compressed buffer
STDMETHODIMP COMInputPin::ReleaseBuffer(DWORD dwTypeIndex, DWORD dwBufferIndex)
{
    HRESULT hr = NOERROR;
    LPSURFACE_INFO pSurfInfo;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::ReleaseBuffer type %d, index %d"),
           dwTypeIndex, dwBufferIndex));

    CAutoLock cLock(m_pFilterLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    pSurfInfo = SurfaceInfoFromTypeAndIndex(dwTypeIndex, dwBufferIndex);
    if (NULL == pSurfInfo)
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("GetInfoFromCookie failed, hr = 0x%x"), hr));
        hr = E_INVALIDARG;
        goto CleanUp;
    }
    // make sure there is a valid buffer pointer and it is the same as
    // what we have cached
    if (NULL == pSurfInfo->pBuffer)
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pBuffer is not valid, pBuffer = 0x%x, pSurfInfo->pBuffer = 0x%x"), pSurfInfo->pBuffer, pSurfInfo->pSurface));
        hr = HRESULT_FROM_WIN32(ERROR_NOT_LOCKED);
        goto CleanUp;
    }

    //  For some reason IDirectDrawSurface4 wants an LPRECT here
    //  I hope NULL is OK
    hr = pSurfInfo->pSurface->Unlock(NULL);
    if (SUCCEEDED(hr))
    {
        pSurfInfo->pBuffer = NULL;
    }
    else
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("pSurfInfo->pSurface->Unlock failed, hr = 0x%x"), hr));
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("leaving COMInputPin::ReleaseBuffer returned 0x%8.8X"), hr));
    return hr;
}


//  Perform a decode operation
STDMETHODIMP COMInputPin::Execute(
        DWORD dwFunction,
        LPVOID lpPrivateInputData,
        DWORD cbPrivateInputData,
        LPVOID lpPrivateOutputData,
        DWORD cbPrivateOutputData,
        DWORD dwNumBuffers,
        const AMVABUFFERINFO *pamvaBufferInfo
)
{
    HRESULT hr = NOERROR;
    DWORD i = 0;
    DDVABUFFERINFO *pddvaBufferInfo = NULL;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::Execute")));

    CAutoLock cLock(m_pFilterLock);


    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    pddvaBufferInfo = (DDVABUFFERINFO *)_alloca(sizeof(DDVABUFFERINFO) * dwNumBuffers);

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Execute Function %d, %d buffers :"),
            dwFunction, dwNumBuffers));
    for (i = 0; i < dwNumBuffers; i++)
    {
        DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("    Type(%d) Index(%d) offset(%d) size(%d)"),
                pamvaBufferInfo[i].dwTypeIndex,
                pamvaBufferInfo[i].dwBufferIndex,
                pamvaBufferInfo[i].dwDataOffset,
                pamvaBufferInfo[i].dwDataSize));

        LPSURFACE_INFO pSurfInfo =
            SurfaceInfoFromTypeAndIndex(
                pamvaBufferInfo[i].dwTypeIndex,
                pamvaBufferInfo[i].dwBufferIndex);

        if (pSurfInfo == NULL)
        {
            DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("GetInfoFromCookie failed, hr = 0x%x, i = %d"), hr, i));
            hr = E_INVALIDARG;
            goto CleanUp;
        }

        INITDDSTRUCT(pddvaBufferInfo[i]);
        pddvaBufferInfo[i].dwDataOffset   = pamvaBufferInfo[i].dwDataOffset;
        pddvaBufferInfo[i].dwDataSize     = pamvaBufferInfo[i].dwDataSize;
        pddvaBufferInfo[i].pddCompSurface = pSurfInfo->pSurface;
    }

    ASSERT(m_pIDDVideoAccelerator);


    hr = m_pIDDVideoAccelerator->Execute(
             dwFunction,
             lpPrivateInputData,
             cbPrivateInputData,
             lpPrivateOutputData,
             cbPrivateOutputData,
             dwNumBuffers,
             pddvaBufferInfo);

    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIDDVideoAccelerator->Execute failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("leaving COMInputPin::Execute returned 0x%8.8X"), hr));
    return hr;
}

// QueryRenderStatus of a particular (possibly a set of) macro block
// dwNumBlocks is an IN parameter
// pdwCookies is an IN parameter which is array (of length dwNumBlocks) of cookies which server as
// identifiers for the corresponding members of pddvaMacroBlockInfo
// pddvaMacroBlockInfo is an IN parameter which is array (of length dwNumBlocks) of structures
// only valid to call this after the pins are connected
STDMETHODIMP COMInputPin::QueryRenderStatus(
        DWORD dwTypeIndex,
        DWORD dwBufferIndex,
        DWORD dwFlags)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("Entering COMInputPin::QueryRenderStatus - type(%d), buffer(%d), flags(0x%8.8X)"),
            dwTypeIndex, dwBufferIndex, dwFlags));

    CAutoLock cLock(m_pFilterLock);

    LPSURFACE_INFO pSurfInfo =
        SurfaceInfoFromTypeAndIndex(dwTypeIndex, dwBufferIndex);

    if (pSurfInfo == NULL) {
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
	goto CleanUp;
    }

    hr = m_pIDDVideoAccelerator->QueryRenderStatus(pSurfInfo->pSurface, dwFlags);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("m_pIDDVideoAccelerator->QueryRenderStatus failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("leaving COMInputPin::QueryRenderStatus returned 0x%8.8X"), hr));
    if (hr == DDERR_WASSTILLDRAWING) {
        hr = E_PENDING;
    }
    return hr;
}

STDMETHODIMP COMInputPin::DisplayFrame(DWORD dwFlipToIndex, IMediaSample *pMediaSample)
{
    HRESULT hr = NOERROR;
    DWORD dwNumUncompFrames = m_dwBackBufferCount + 1, dwFlipFromIndex = 0, i = 0;
    SURFACE_INFO *pSurfInfo;

    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("leaving COMInputPin::DisplayFrame - index %d"), dwFlipToIndex));

    CAutoLock cLock(m_pFilterLock);

    // make sure that we have a valid motion-comp connection
    hr = CheckValidMCConnection();
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR, VA_ERROR_LEVEL, TEXT("CheckValidMCConnection failed, hr = 0x%x"), hr));
	goto CleanUp;
    }
    pSurfInfo = SurfaceInfoFromTypeAndIndex(
                             0xFFFFFFFF,
                             dwFlipToIndex);
    if (pSurfInfo == NULL) {
        hr = E_INVALIDARG;
        goto CleanUp;
    }

    for (i = 0; i < dwNumUncompFrames; i++)
    {
        if (IsEqualObject(m_pCompSurfInfo[0].pSurfInfo[i].pSurface, m_pDirectDrawSurface))
        {
            dwFlipFromIndex = i;
        }
    }

    pSurfInfo->pSurface->QueryInterface(
        IID_IDirectDrawSurface, (void **)&m_pBackBuffer);
    m_pBackBuffer->Release();

    hr = Receive(pMediaSample);
    if (FAILED(hr))
    {
        goto CleanUp;
    }


    if (FAILED(hr)) {
        //  Should we poll if we got DDERR_WASSTINGDRAWING?
        goto CleanUp;
    }

    //  DirectDraw switches the memory under the pointers
    //  so mimic that in our list
    if (m_bReallyFlipped) {

        LPDIRECTDRAWSURFACE4 pTempSurface;

        // we should have successfully called flip by this point, swap the two
        pTempSurface = m_pCompSurfInfo[0].pSurfInfo[dwFlipToIndex].pSurface;
        m_pCompSurfInfo[0].pSurfInfo[dwFlipToIndex].pSurface = m_pCompSurfInfo[0].pSurfInfo[dwFlipFromIndex].pSurface;
        m_pCompSurfInfo[0].pSurfInfo[dwFlipFromIndex].pSurface = pTempSurface;
    }

CleanUp:
    if (SUCCEEDED(hr))
    {
        if (m_bOverlayHidden)
        {
	    m_bOverlayHidden = FALSE;
	    // make sure that the video frame gets updated by redrawing everything
	    EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
        }
    }
    DbgLog((LOG_TRACE, VA_TRACE_LEVEL, TEXT("leaving COMInputPin::DisplayFrame return 0x%8.8X"), hr));
    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmixer\vpobj.cpp ===
// Copyright (c) 1998 - 1999  Microsoft Corporation.  All Rights Reserved.
#include <streams.h>
#include <ddraw.h>
#include <mmsystem.h>	    // Needed for definition of timeGetTime
#include <limits.h>	    // Standard data type limit definitions
#include <dvdmedia.h>
#include <ks.h>
#include <ksproxy.h>
#include <bpcwrap.h>
#include <amstream.h>
#include <dvp.h>
#include <ddkernel.h>
#include <vptype.h>
#include <vpconfig.h>
#include <vpnotify.h>
#include <vpobj.h>
#include <syncobj.h>
#include <macvis.h>
#include <ovmixer.h>


/******************************Public*Routine******************************\
* CreateInstance
*
* This goes in the factory template table to create new VPObject instances
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
CUnknown *CAMVideoPort::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    AMTRACE((TEXT("CAMVideoPort::CreateInstance")));
    *phr = NOERROR;

    CAMVideoPort *pVPObject = new CAMVideoPort(pUnk, phr);
    if (FAILED(*phr))
    {
        if (pVPObject)
        {
            delete pVPObject;
            pVPObject = NULL;
        }
    }

    return pVPObject;
}

/******************************Public*Routine******************************\
* CAMVideoPort
*
* constructor
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
CAMVideoPort::CAMVideoPort(LPUNKNOWN pUnk, HRESULT *phr)
    : CUnknown(NAME("VP Object"), pUnk)
{
    AMTRACE((TEXT("CAMVideoPort::Constructor")));

    m_bConnected = FALSE;
    m_pIVPConfig = NULL;

    m_bVPSyncMaster = FALSE;

    InitVariables();

    // if you are QIing the outer object then you must decrease the refcount of
    // your outer unknown.  This is to avoid a circular ref-count. We are
    // guaranteed that the lifetime of the inner object is entirely contained
    // within the outer object's lifetime.

    *phr = pUnk->QueryInterface(IID_IVPControl, (void**)&m_pIVPControl);
    if (SUCCEEDED(*phr))
    {
        pUnk->Release();
    }
    else {
        DbgLog((LOG_ERROR, 0,
                TEXT("pUnk->QueryInterface(IID_IVPControl) failed, hr = 0x%x"),
                *phr));
    }
}

/******************************Public*Routine******************************\
* ~CAMVideoPort
*
* destructor
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
CAMVideoPort::~CAMVideoPort()
{
    AMTRACE((TEXT("CAMVideoPort::Destructor")));

    if (m_bConnected)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("Destructor called without calling breakconnect")));
        BreakConnect();
    }

    m_pIVPControl = NULL;
}

/******************************Public*Routine******************************\
* CAMVideoPort::NonDelegatingQueryInterface
*
* overridden to expose IVPNotify and IVPObject
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::NonDelegatingQueryInterface(REFIID riid, void **ppv)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CAMVideoPort::NonDelegatingQueryInterface")));

    if (riid == IID_IVPNotify)
    {
        hr = GetInterface((IVPNotify*)this, ppv);
#if defined(DEBUG)
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2,
                    TEXT("GetInterface(IVPNotify*) failed, hr = 0x%x"), hr));
        }
#endif
    }
    else if (riid == IID_IVPNotify2)
    {
        hr = GetInterface((IVPNotify2*)this, ppv);
#if defined(DEBUG)
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2,
                    TEXT("GetInterface(IVPNotify2*) failed, hr = 0x%x"), hr));
        }
#endif
    }
    else if (riid == IID_IVPObject)
    {
        hr = GetInterface((IVPObject*)this, ppv);
#if defined(DEBUG)
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2,
                    TEXT("GetInterface(IVPObject*) failed, hr = 0x%x"), hr));
        }
#endif
    }
    else if (riid == IID_IVPInfo)
    {
        hr = GetInterface((IVPInfo*)this, ppv);
#if defined(DEBUG)
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2,
                    TEXT("GetInterface(IVPInfo*) failed, hr = 0x%x"), hr));
        }
#endif
    }

    else
    {
        hr = CUnknown::NonDelegatingQueryInterface(riid, ppv);
#if defined(DEBUG)
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 2,
                    TEXT("CUnknown::NonDelegatingQueryInterface")
                    TEXT(" failed, hr = 0x%x"), hr));
        }
#endif
    }

    return hr;
}


/*****************************Private*Routine******************************\
* CAMVideoPort::InitVariables
*
* this function only initializes those variables which are supposed to be reset
* on RecreateVideoport
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
void CAMVideoPort::InitVariables()
{
    AMTRACE((TEXT("CAMVideoPort::InitVariables")));
    ZeroMemory(&m_rcDest, sizeof(RECT));
    ZeroMemory(&m_rcSource, sizeof(RECT));

    // image dimensions
    m_lImageWidth = 0;
    m_lImageHeight = 0;
    m_lDecoderImageHeight = 0;
    m_lDecoderImageWidth = 0;

    // Capturing information
    m_fCapturing = FALSE;
    m_fCaptureInterleaved = FALSE;
    m_cxCapture = 0;
    m_cyCapture = 0;

    // overlay surface related stuff
    m_pOverlaySurface = NULL;       // DirectDraw overlay surface
    m_dwBackBufferCount = 0;
    m_dwOverlaySurfaceWidth = 0;
    m_dwOverlaySurfaceHeight = 0;
    m_dwOverlayFlags = 0;

    // vp variables to store flags, current state etc
    m_bStart = FALSE;
    m_VPState = AMVP_VIDEO_STOPPED; // current state: running, stopped
    m_CurrentMode = AMVP_MODE_WEAVE;
    m_StoredMode = m_CurrentMode;
    m_CropState = AMVP_NO_CROP;
    m_dwPixelsPerSecond = 0;
    m_bVSInterlaced = FALSE;
    m_bGarbageLine = FALSE;

    // vp data structures
    m_dwVideoPortId = 0;
    m_pDVP = NULL;
    m_pVideoPort = NULL;
    ZeroMemory(&m_svpInfo, sizeof(DDVIDEOPORTINFO));
    ZeroMemory(&m_sBandwidth, sizeof(DDVIDEOPORTBANDWIDTH));
    ZeroMemory(&m_vpCaps, sizeof(DDVIDEOPORTCAPS));
    ZeroMemory(&m_ddConnectInfo, sizeof(DDVIDEOPORTCONNECT));
    ZeroMemory(&m_VPDataInfo, sizeof(AMVPDATAINFO));

    // All the pixel formats (Video/VBI)
    m_pddVPInputVideoFormat = NULL;
    m_pddVPOutputVideoFormat = NULL;

    // can we support the different modes
    m_bCanWeave = FALSE;
    m_bCanBobInterleaved = FALSE;
    m_bCanBobNonInterleaved = FALSE;
    m_bCanSkipOdd = FALSE;
    m_bCanSkipEven = FALSE;
    m_bCantInterleaveHalfline = FALSE;

    // decimation parameters
    m_ulDeciStepX = 0;
    m_dwDeciNumX = m_dwDeciDenX = 1000;
    m_ulDeciStepY = 0;
    m_dwDeciNumY = m_dwDeciDenY = 1000;
    m_DecimationModeX = DECIMATE_NONE;
    m_DecimationModeY = DECIMATE_NONE;

    m_bVPDecimating = FALSE;
    m_bDecimating = FALSE;
    m_lWidth = 0;
    m_lHeight = 0;

    // variables to store the current aspect ratio
    m_dwPictAspectRatioX = 1;
    m_dwPictAspectRatioY = 1;
}

/******************************Public*Routine******************************\
* CAMVideoPort::GetDirectDrawSurface
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP
CAMVideoPort::GetDirectDrawSurface(LPDIRECTDRAWSURFACE *ppDirectDrawSurface)
{
    AMTRACE((TEXT("CAMVideoPort::SetVPSyncMaster")));
    HRESULT hr = NOERROR;

    CAutoLock cObjectLock(m_pMainObjLock);

    if (!ppDirectDrawSurface || !m_bConnected)
    {
        // make sure the argument is valid
        if (!ppDirectDrawSurface) {
            DbgLog((LOG_ERROR, 1,
                    TEXT("value of ppDirectDrawSurface is invalid,")
                    TEXT(" ppDirectDrawSurface = NULL")));
            hr = E_INVALIDARG;
        }
        else {
            // not connected, this function does not make much sense since the
            // surface wouldn't even have been allocated as yet
            DbgLog((LOG_ERROR, 1, TEXT("not connected, exiting")));
            hr = VFW_E_NOT_CONNECTED;
        }
    }
    else {
        *ppDirectDrawSurface = m_pOverlaySurface;
    }

    return hr;
}


/******************************Public*Routine******************************\
* CAMVideoPort::SetObjectLock
*
* sets the pointer to the lock, which would be used to synchronize calls
* to the object.  It is the callee's responsiblility to synchronize this call
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::SetObjectLock(CCritSec *pMainObjLock)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CAMVideoPort::SetObjectLock")));

    if (!pMainObjLock)
    {
        DbgLog((LOG_ERROR, 0, TEXT("pMainObjLock is NULL")));
        hr = E_INVALIDARG;
    }
    else {
        m_pMainObjLock = pMainObjLock;
    }

    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::SetMediaType
*
* check that the mediatype is acceptable
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::SetMediaType(const CMediaType* pmt)
{
    AMTRACE((TEXT("CAMVideoPort::SetMediaType")));

    CAutoLock cObjectLock(m_pMainObjLock);
    HRESULT hr =  CheckMediaType(pmt);

#if defined(DEBUG)
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1, TEXT("CheckMediaType failed, hr = 0x%x"), hr));
    }
#endif

    return hr;
}


/******************************Public*Routine******************************\
* CAMVideoPort::CheckMediaType
*
* check that the mediatype is acceptable. No lock is taken here.
* It is the callee's responsibility to maintain integrity!
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::CheckMediaType(const CMediaType* pmt)
{
    AMTRACE((TEXT("CAMVideoPort::CheckMediaType")));

    // get the hardware caps
    LPDDCAPS pDirectCaps = m_pIVPControl->GetHardwareCaps();
    ASSERT(pDirectCaps);

    HRESULT hr = VFW_E_TYPE_NOT_ACCEPTED;

    // the hardware must support overlay and also it must  support
    // videoports, otherwise fail checkmediatype

    if ((pDirectCaps->dwCaps & DDCAPS_OVERLAY) &&
        (pDirectCaps->dwCaps2 & DDCAPS2_VIDEOPORT))
    {
        // Make sure that the major and sub-types match

        if ((pmt->majortype == MEDIATYPE_Video) &&
            (pmt->subtype == MEDIASUBTYPE_VPVideo) &&
            (pmt->formattype == FORMAT_None))
        {
            hr = NOERROR;
        }

    }

#if defined(DEBUG)
    else {
        DbgLog((LOG_ERROR, 2,
                TEXT("no overlay or VPE support in hardware,")
                TEXT("so not accepting this mediatype")));
    }
#endif

    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::RecreateVideoPort
\**************************************************************************/
HRESULT CAMVideoPort::RecreateVideoPort()
{
    AMTRACE((TEXT("CAMVideoPort::RecreateVideoPort")));

    HRESULT hr = NOERROR;
    BOOL bCanWeave = FALSE;
    BOOL bCanBobInterleaved = FALSE;
    BOOL bCanBobNonInterleaved = FALSE;
    BOOL bTryDoubleHeight = FALSE, bPreferBuffers = FALSE;
    DWORD dwMaxOverlayBuffers;
    HRESULT hrFailure = VFW_E_VP_NEGOTIATION_FAILED;
    LPDIRECTDRAW pDirectDraw = NULL;
    LPDDCAPS pDirectCaps = NULL;
    int i = 0;

    CAutoLock cObjectLock(m_pMainObjLock);

    InitVariables();

    pDirectDraw = m_pIVPControl->GetDirectDraw();
    ASSERT(pDirectDraw);

    pDirectCaps = m_pIVPControl->GetHardwareCaps();
    ASSERT(pDirectCaps);

    ASSERT(m_pIVPConfig);

    // allocate the necessary memory for input Video format
    m_pddVPInputVideoFormat = new DDPIXELFORMAT;
    if (m_pddVPInputVideoFormat == NULL)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("m_pddVPInputVideoFormat == NULL : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // allocate the necessary memory for output Video format
    m_pddVPOutputVideoFormat = new DDPIXELFORMAT;
    if (m_pddVPOutputVideoFormat == NULL)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("m_pddVPOutputVideoFormat == NULL : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // Init all of them to zero
    ZeroMemory(m_pddVPInputVideoFormat,  sizeof(DDPIXELFORMAT));
    ZeroMemory(m_pddVPOutputVideoFormat, sizeof(DDPIXELFORMAT));

    // create the VP container
    ASSERT(m_pDVP == NULL);
    ASSERT(pDirectDraw);

    hr = pDirectDraw->QueryInterface(IID_IDDVideoPortContainer, (LPVOID *)&m_pDVP);
    if (FAILED(hr))
    {
	DbgLog((LOG_ERROR,0,
               TEXT("pDirectDraw->QueryInterface(IID_IDDVideoPortContainer)")
               TEXT(" failed, hr = 0x%x"), hr));
        hr = hrFailure;
        goto CleanUp;
    }


    // Get the Video Port caps
    DDVIDEOPORTCAPS vpCaps;
    INITDDSTRUCT(vpCaps);
    hr = m_pDVP->EnumVideoPorts(0, &vpCaps, this, CAMVideoPort::EnumCallback);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("m_pDVP->EnumVideoPorts failed, hr = 0x%x"), hr));
        hr = hrFailure;
        goto CleanUp;
    }

    // negotiate the connection parameters
    // get/set connection info happens here
    hr = NegotiateConnectionParamaters();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("NegotiateConnectionParamaters failed, hr = 0x%x"), hr));
        hr = hrFailure;
        goto CleanUp;
    }

    //
    // Determine if we are capturing and if we are what the intended
    // capture image size is, first determine if the video port
    // supports interleaving interlaced fields in memory
    //

    BOOL fInterleave;
    if (m_vpCaps.dwFX & DDVPFX_INTERLEAVE) {
        fInterleave = TRUE;
    }
    else {
        fInterleave = FALSE;
    }

    m_pIVPControl->GetCaptureInfo(&m_fCapturing, &m_cxCapture,
                                  &m_cyCapture, &fInterleave);

#if 0
    //
    // Until Marlene implements the AM_KSPROPERTY_ALLOCATOR_CONTROL_SURFACE_SIZE
    // stuff I will read the same values from win.ini.
    //
    m_fCapturing = GetProfileIntA("OVMixer", "Capturing", 0);
    if (m_fCapturing) {
        m_cxCapture = GetProfileIntA("OVMixer", "cx", 320);
        m_cyCapture = GetProfileIntA("OVMixer", "cy", 240);

        if (m_cxCapture == 640 && m_cyCapture == 480) {
            fInterleave = GetProfileIntA("OVMixer", "interleave", 1);
        }

    }
#endif

    m_fCaptureInterleaved = fInterleave;

#if defined(DEBUG)
    if (m_fCapturing) {

        ASSERT(m_cxCapture > 0);
        ASSERT(m_cyCapture > 0);
        DbgLog((LOG_TRACE, 1,
                TEXT("We are CAPTURING, intended size (%d, %d)"),
                m_cxCapture, m_cyCapture));
    }
#endif


    for (i = 0; i < 2; i++)
    {
        AMVPSIZE amvpSize;
        DWORD dwNewWidth = 0;

        ZeroMemory(&amvpSize, sizeof(AMVPSIZE));

        // get the rest of the data parameters
        hr = GetDataParameters();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("GetDataParameters failed, hr = 0x%x"), hr));
            hr = hrFailure;
            goto CleanUp;
        }

        // create the video port
        hr = CreateVideoPort();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("CreateVideoPort failed, hr = 0x%x"), hr));
            hr = hrFailure;
            goto CleanUp;
        }

        // check if we need to crop at videoport or overlay or neither
        hr = DetermineCroppingRestrictions();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("DetermineCroppingRestrictions FAILED, hr = 0x%x"),
                    hr));
            hr = hrFailure;
            goto CleanUp;
        }


        m_lImageWidth  = WIDTH(&m_VPDataInfo.amvpDimInfo.rcValidRegion);
        m_lImageHeight = HEIGHT(&m_VPDataInfo.amvpDimInfo.rcValidRegion);

        m_lDecoderImageWidth = m_lImageWidth;
        m_lDecoderImageHeight = m_lImageHeight;

        if (m_fCapturing) {

            if (m_lImageWidth != m_cxCapture ||
                m_lImageHeight != m_cyCapture) {

                DbgLog((LOG_TRACE, 1,
                        TEXT("Adjust Decoder Image size to CaptureSize")));
            }

            m_lImageWidth = m_cxCapture;
            m_lImageHeight = m_cyCapture;
        }

        m_dwPictAspectRatioX = m_VPDataInfo.dwPictAspectRatioX;
        m_dwPictAspectRatioY = m_VPDataInfo.dwPictAspectRatioY;

        // negotiate the pixel format
        hr = NegotiatePixelFormat();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("NegotiatePixelFormat Failed, hr = 0x%x"), hr));
            hr = hrFailure;
            goto CleanUp;
        }

        // check the vp caps
        hr = CheckDDrawVPCaps();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("CheckDDrawVPCaps FAILED, hr = 0x%x"), hr));
            // CheckDDrawVPCaps already returns a "proper" error code
            goto CleanUp;
        }

        if (i == 0)
        {
            dwNewWidth = m_VPDataInfo.amvpDimInfo.dwFieldWidth;
            if (m_sBandwidth.dwCaps == DDVPBCAPS_SOURCE &&
                m_sBandwidth.dwYInterpAndColorkey < 900)
            {
                dwNewWidth = MulDiv(dwNewWidth,
                                    m_sBandwidth.dwYInterpAndColorkey, 1000);
            }
            else if (m_sBandwidth.dwCaps == DDVPBCAPS_DESTINATION &&
                     m_sBandwidth.dwYInterpAndColorkey > 1100)
            {
                dwNewWidth = MulDiv(dwNewWidth, 1000,
                                    m_sBandwidth.dwYInterpAndColorkey);
            }

            // VGA can't handle the bandwidth, ask decoder to down-scale
            if (dwNewWidth != m_VPDataInfo.amvpDimInfo.dwFieldWidth)
            {
                amvpSize.dwWidth = dwNewWidth;
                amvpSize.dwHeight = m_VPDataInfo.amvpDimInfo.dwFieldHeight;

                DbgLog((LOG_TRACE,1,
                        TEXT("SetScalingFactors to (%d, %d)"),
                        amvpSize.dwWidth, amvpSize.dwHeight));

                hr = m_pIVPConfig->SetScalingFactors(&amvpSize);
                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR,0,
                            TEXT("m_pIVPConfig->SetScalingFactors")
                            TEXT("failed, hr = 0x%x"), hr));
                    break;
                }
                else
                {
                    // release the videoport
                    ASSERT(m_pVideoPort);
                    m_pVideoPort->Release();
                    m_pVideoPort = NULL;

                    // initialize relevant structs
                    ZeroMemory(&m_sBandwidth, sizeof(DDVIDEOPORTBANDWIDTH));
                    ZeroMemory(&m_VPDataInfo, sizeof(AMVPDATAINFO));
                    ZeroMemory(m_pddVPInputVideoFormat,  sizeof(DDPIXELFORMAT));
                    ZeroMemory(m_pddVPOutputVideoFormat, sizeof(DDPIXELFORMAT));

                    // initialize decimation parameters
                    m_ulDeciStepX = 0;
                    m_dwDeciNumX = m_dwDeciDenX = 1000;
                    m_DecimationModeX = DECIMATE_NONE;

                    m_ulDeciStepY = 0;
                    m_dwDeciNumY = m_dwDeciDenY = 1000;
                    m_DecimationModeY = DECIMATE_NONE;
                }
            }
            else
            {
                DbgLog((LOG_ERROR,0,TEXT("no need to scale at the decoder")));
                break;
            }
        }
    }



    // iniitalize the DDVideoPortInfo structure
    hr = InitializeVideoPortInfo();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("InitializeVideoPortInfo FAILED, hr = 0x%x"), hr));
        hr = hrFailure;
        goto CleanUp;
    }

#ifdef DEBUG
    if (m_bVSInterlaced)
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_bVSInterlaced = TRUE")));
    }
    else
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_bVSInterlaced = FALSE")));
    }

    if (m_vpCaps.dwCaps & DDVPCAPS_AUTOFLIP)
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("m_vpCaps.dwCaps & DDVPCAPS_AUTOFLIP = TRUE")));
    }
    else
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("m_vpCaps.dwCaps & DDVPCAPS_AUTOFLIP = FALSE")));
    }

    if (m_vpCaps.dwFX & DDVPFX_INTERLEAVE)
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("m_vpCaps.dwFX & DDVPFX_INTERLEAVE = TRUE")));
    }
    else
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("m_vpCaps.dwFX & DDVPFX_INTERLEAVE = FALSE")));
    }

    if (m_bCantInterleaveHalfline)
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_bCantInterleaveHalfline = TRUE")));
    }
    else
    {
        DbgLog((LOG_ERROR, 1, TEXT("m_bCantInterleaveHalfline = FALSE")));
    }

    if (pDirectCaps->dwCaps2 & DDCAPS2_CANBOBINTERLEAVED)
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("pDirectCaps->dwCaps2 & DDCAPS2_CANBOBINTERLEAVED = TRUE")));
    }
    else
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("pDirectCaps->dwCaps2 & DDCAPS2_CANBOBINTERLEAVED")
                TEXT(" = FALSE")));
    }

    if (pDirectCaps->dwCaps2 & DDCAPS2_CANBOBNONINTERLEAVED)
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("pDirectCaps->dwCaps2 & DDCAPS2_CANBOBNONINTERLEAVED")
                TEXT(" = TRUE")));
    }
    else
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("pDirectCaps->dwCaps2 & DDCAPS2_CANBOBNONINTERLEAVED")
                TEXT(" = FALSE")));
    }

#endif

    // can Weave only if content is non-interlaced (cause of motion
    // artifacts otherwise) and if videoport is capable of flipping and
    // supports interleaved data and if certain halfline scenarios do not
    // preclude interleaving
    //
    if ((!m_bVSInterlaced) &&
        (m_vpCaps.dwCaps & DDVPCAPS_AUTOFLIP) &&
        (m_vpCaps.dwFX & DDVPFX_INTERLEAVE) &&
        (!m_bCantInterleaveHalfline))
    {
        bCanWeave = TRUE;
    }

    // can BobNonInterleaved only if content is interlaced and if videoport is
    // capable of flipping, is capable of bobing interleaved data and supports
    // interleaved data and if certain halfline scenarios do not preclude
    // interleaving
    //
    if ((m_bVSInterlaced) &&
        (m_vpCaps.dwCaps & DDVPCAPS_AUTOFLIP) &&
        (pDirectCaps->dwCaps2 & DDCAPS2_CANBOBINTERLEAVED) &&
        (m_vpCaps.dwFX & DDVPFX_INTERLEAVE) &&
        (!m_bCantInterleaveHalfline))
    {
        bCanBobInterleaved = TRUE;
    }

    // can BobInterleaved only if content is interlaced and if videoport is
    // capable of flipping and is capable of bobing non-interleaved data.
    //
    if ((m_bVSInterlaced) &&
        (m_vpCaps.dwCaps & DDVPCAPS_AUTOFLIP) &&
        (pDirectCaps->dwCaps2 & DDCAPS2_CANBOBNONINTERLEAVED))
    {
        bCanBobNonInterleaved = TRUE;
    }

    // this just means that we would perfer higher number of
    // buffers instead of more height in the event of a conflict
    // (in cases like 2buffer, 1height versus 1buffer, 2height)
    //
    bPreferBuffers = TRUE;

    // we will try to allocate surface of double the field height only if
    // either mode weave or bob-interleaved are possible
    //
    bTryDoubleHeight = bCanWeave || bCanBobInterleaved;
    dwMaxOverlayBuffers = 1;

    // we will try to allocate multiple buffers only if either mode weave or
    // bob-interleaved or bob-non-interleaved are possible
    //
    if (bCanWeave || bCanBobInterleaved || bCanBobNonInterleaved)
    {
        //try to allocate min(m_vpCaps.dwNumAutoFlipSurfaces,
        // m_vpCaps.dwNumPreferredAutoflip) buffers
        //
        ASSERT(m_vpCaps.dwFlags & DDVPD_AUTOFLIP);
        if (m_vpCaps.dwFlags & DDVPD_PREFERREDAUTOFLIP)
        {
            dwMaxOverlayBuffers = min(m_vpCaps.dwNumAutoFlipSurfaces,
                                      m_vpCaps.dwNumPreferredAutoflip);
        }
        else
        {
            dwMaxOverlayBuffers = min(m_vpCaps.dwNumAutoFlipSurfaces, 3);
        }
    }

    // create the overlay surface
    hr = CreateVPOverlay(bTryDoubleHeight, dwMaxOverlayBuffers, bPreferBuffers);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0, TEXT("CreateVPOverlay FAILED, hr = 0x%x"), hr));
        hr = VFW_E_OUT_OF_VIDEO_MEMORY;
        goto CleanUp;
    }

    // tell the upstream filter the valid data location on the ddraw surface
    hr = SetSurfaceParameters();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("SetSurfaceParameters FAILED, hr = 0x%x"), hr));
        hr = VFW_E_OUT_OF_VIDEO_MEMORY;
        goto CleanUp;
    }

    // paint the overlay surface black
    hr = PaintDDrawSurfaceBlack(m_pOverlaySurface);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("PaintDDrawSurfaceBlack FAILED, hr = 0x%x"), hr));
        // not being able to paint the ddraw surface black is not a fatal error
        hr = NOERROR;
    }

    // attach the overlay surface to the videoport
    hr = m_pVideoPort->SetTargetSurface(m_pOverlaySurface, DDVPTARGET_VIDEO);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pVideoPort->SetTargetSurface failed, hr = 0x%x"), hr));
        hr = hrFailure;
        goto CleanUp;
    }

    ASSERT(m_pddVPInputVideoFormat);
    ASSERT(m_pddVPOutputVideoFormat);
    if (!(EqualPixelFormats(m_pddVPInputVideoFormat, m_pddVPOutputVideoFormat)))
    {
        m_svpInfo.dwVPFlags |= DDVP_CONVERT;
    }
    else
    {
        m_svpInfo.dwVPFlags &= ~DDVP_CONVERT;
    }

    // determine which modes are possible now
    // depends upon the height, number of back buffers etc
    hr = DetermineModeRestrictions();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("DetermineModeRestrictions FAILED, hr = 0x%x"), hr));
        hr = hrFailure;
        goto CleanUp;
    }

    // inform the decoder of the ddraw kernel handle, videoport id and surface
    // kernel handle
    hr = SetDDrawKernelHandles();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("SetDDrawKernelHandles failed, hr = 0x%x"), hr));
        hr = hrFailure;
        goto CleanUp;
    }

    m_bConnected = TRUE;

    hr = m_pIVPControl->EventNotify(EC_OVMIXER_VP_CONNECTED, 0, 0);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPControl->EventNotify(EC_OVMIXER_VP_CONNECTED,")
                TEXT(" 0, 0) failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::CompleteConnect
*
* supposed to be called when the host connects with the decoder
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP
CAMVideoPort::CompleteConnect(IPin *pReceivePin, BOOL bRenegotiating)
{
    AMTRACE((TEXT("CAMVideoPort::CompleteConnect")));

    HRESULT hr = NOERROR;

    CAutoLock cObjectLock(m_pMainObjLock);

    if (!bRenegotiating)
    {
        InitVariables();

        ASSERT(m_pIVPConfig == NULL);
        hr = pReceivePin->QueryInterface(IID_IVPConfig, (void **)&m_pIVPConfig);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,  TEXT("QueryInterface(IID_IVPConfig) failed, hr = 0x%x"), hr));
            hr = VFW_E_NO_TRANSPORT;
            goto CleanUp;
        }
    }

    ASSERT(m_pIVPConfig);

    hr = RecreateVideoPort();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0, TEXT("RecreateVideoPort failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

CleanUp:
    return hr;
}

HRESULT CAMVideoPort::StopUsingVideoPort()
{
    AMTRACE((TEXT("CAMVideoPort::StopUsingVideoPort")));

    HRESULT hr = NOERROR;
    unsigned long ulCount;

    CAutoLock cObjectLock(m_pMainObjLock);

    // delete the input Video pixelformat
    if (m_pddVPInputVideoFormat)
    {
        delete [] m_pddVPInputVideoFormat;
        m_pddVPInputVideoFormat = NULL;
    }

    // delete the output Video pixelformat
    if (m_pddVPOutputVideoFormat)
    {
        delete [] m_pddVPOutputVideoFormat;
        m_pddVPOutputVideoFormat = NULL;
    }

    // release the videoport
    if (m_pVideoPort)
    {
        hr = m_pVideoPort->StopVideo();
        ulCount = m_pVideoPort->Release();
        m_pVideoPort = NULL;
    }

    // release the videoport container
    if (m_pDVP)
    {
        ulCount = m_pDVP->Release();
        m_pDVP = NULL;
    }

    // Release the DirectDraw overlay surface
    if (m_pOverlaySurface)
    {
        m_pOverlaySurface->Release();
        m_pOverlaySurface = NULL;
    }

    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::BreakConnect
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP
CAMVideoPort::BreakConnect(BOOL bRenegotiating)
{
    AMTRACE((TEXT("CAMVideoPort::BreakConnect")));

    HRESULT hr = NOERROR;
    unsigned long ulCount;

    CAutoLock cObjectLock(m_pMainObjLock);

    hr = StopUsingVideoPort();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0, TEXT("StopUsingVideoPort failed, hr = 0x%x"), hr));
    }
    if (!bRenegotiating)
    {
        // release the IVPConfig interface
        if (m_pIVPConfig)
        {
            m_pIVPConfig->Release();
            m_pIVPConfig = NULL;
        }
    }

    m_bConnected = FALSE;

    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::Active()
*
*
* transition from Stop to Pause.
* We do not need to to anything unless this is the very first time we are
* showing the overlay
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::Active()
{
    AMTRACE((TEXT("CAMVideoPort::Active")));

    CAutoLock cObjectLock(m_pMainObjLock);
    HRESULT hr = NOERROR;

    ASSERT(m_bConnected);
    ASSERT(m_VPState == AMVP_VIDEO_STOPPED);

    if (!m_bConnected)
    {
        hr = VFW_E_NOT_CONNECTED;
        goto CleanUp;
    }

    // make sure that a frame is visible by making an update overlay call
    m_bStart = TRUE;

    // make sure that the video frame gets updated by redrawing everything
    hr = m_pIVPControl->EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPControl->EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0)")
                TEXT(" failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // now stop the video, so the user will just see a still frame
    hr = m_pVideoPort->StopVideo();

#if defined(DEBUG)
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pVideoPort->StopVideo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
#endif

CleanUp:
    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::Inactive()
*
* transition (from Pause or Run) to Stop
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::Inactive()
{

    AMTRACE((TEXT("CAMVideoPort::Inactive")));

    HRESULT hr = NOERROR;
    CAutoLock cObjectLock(m_pMainObjLock);

    if (m_bConnected) {

        // Inactive is also called when going from pause to stop, in which case the
        // VideoPort would have already been stopped in the function RunToPause

        if (m_VPState == AMVP_VIDEO_RUNNING) {

            // stop the VideoPort
            hr = m_pVideoPort->StopVideo();
            if (SUCCEEDED(hr)) {
                m_VPState = AMVP_VIDEO_STOPPED;
            }
            else {
                DbgLog((LOG_ERROR,0,
                        TEXT("m_pVideoPort->StopVideo failed, hr = 0x%x"), hr));
            }
        }
    }
    else {
        hr = VFW_E_NOT_CONNECTED;
    }

    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::Run
*
* transition from Pause to Run. We just start the VideoPort.
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::Run(REFERENCE_TIME /* tStart */)
{
    AMTRACE((TEXT("CAMVideoPort::Run")));

    CAutoLock cObjectLock(m_pMainObjLock);

    ASSERT(m_bConnected);
    ASSERT(m_VPState == AMVP_VIDEO_STOPPED);
    HRESULT hr;

    if (m_bConnected)
    {
        // An UpdateOverlay is needed here. One example is, when we are
        // clipping video in Stop/Pause state since we can't do scaling
        // on the videoport. As soon as the user hits play, we should stop
        // clipping the video.

        m_bStart = TRUE;

        // make sure that the video frame gets updated by redrawing everything
        hr = m_pIVPControl->EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
        if (SUCCEEDED(hr))
        {
            m_VPState = AMVP_VIDEO_RUNNING;
        }
        else {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pIVPControl->EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0)")
                    TEXT(" failed, hr = 0x%x"), hr));
        }
    }
    else {
        hr = VFW_E_NOT_CONNECTED;
    }

    return hr;
}


/******************************Public*Routine******************************\
* CAMVideoPort::RunToPause()
*
* transition from Run to Pause. We just stop the VideoPort
* Note that transition from Run to Stop is caught by Inactive
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::RunToPause()
{

    AMTRACE((TEXT("CAMVideoPort::RunToPause")));

    CAutoLock cObjectLock(m_pMainObjLock);

    ASSERT(m_bConnected);
    //ASSERT(m_VPState == AMVP_VIDEO_RUNNING);

    HRESULT hr;
    if (m_bConnected)
    {
        // stop the VideoPort
        hr = m_pVideoPort->StopVideo();
        if (SUCCEEDED(hr)) {

            m_VPState = AMVP_VIDEO_STOPPED;
        }
        else {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pVideoPort->StopVideo failed, hr = 0x%x"), hr));
        }

    }
    else {
        hr = VFW_E_NOT_CONNECTED;
    }

    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::CurrentMediaType
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::CurrentMediaType(AM_MEDIA_TYPE *pMediaType)
{
    AMTRACE((TEXT("CAMVideoPort::CurrentMediaType")));

    CAutoLock cObjectLock(m_pMainObjLock);
    HRESULT hr;
    VIDEOINFOHEADER2 *pVideoInfoHeader2;
    BITMAPINFOHEADER *pHeader;

    if (m_bConnected) {

        if (pMediaType) {

            pVideoInfoHeader2 = (VIDEOINFOHEADER2*)(pMediaType->pbFormat);
            ZeroMemory(pVideoInfoHeader2, sizeof(VIDEOINFOHEADER2));

            pHeader = GetbmiHeader((CMediaType*)pMediaType);
            if (pHeader) {
                pHeader->biWidth = m_VPDataInfo.amvpDimInfo.rcValidRegion.right -
                                   m_VPDataInfo.amvpDimInfo.rcValidRegion.left;
                pHeader->biHeight = 2*(m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom -
                                       m_VPDataInfo.amvpDimInfo.rcValidRegion.top);


                pVideoInfoHeader2->dwPictAspectRatioX = m_VPDataInfo.dwPictAspectRatioX;
                pVideoInfoHeader2->dwPictAspectRatioY = m_VPDataInfo.dwPictAspectRatioY;
                hr = NOERROR;
            }
            else {
                hr = E_INVALIDARG;
                DbgLog((LOG_ERROR, 2, TEXT("pHeader is NULL")));
            }
        }
        else {
            hr = E_INVALIDARG;
            DbgLog((LOG_ERROR, 2, TEXT("pMediaType is NULL")));
        }
    }
    else {
        hr = VFW_E_NOT_CONNECTED;
    }

    return hr;
}

/******************************Public*Routine******************************\
* CAMVideoPort::GetRectangles
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::GetRectangles(RECT *prcSource, RECT *prcDest)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CAMVideoPort::GetRectangles")));

    if (prcSource && prcDest) {

        // adjust the source to be bigger to take into account the decimation
        // that's happening
        //
        prcSource->left   = MulDiv(m_rcSource.left,  m_dwDeciDenX, m_dwDeciNumX);
        prcSource->right  = MulDiv(m_rcSource.right, m_dwDeciDenX, m_dwDeciNumX);
        prcSource->top    = MulDiv(m_rcSource.top,   m_dwDeciDenY, m_dwDeciNumY);
        prcSource->bottom = MulDiv(m_rcSource.bottom,m_dwDeciDenY, m_dwDeciNumY);

        *prcDest = m_rcDest;
    }
    else {
        hr = E_INVALIDARG;
        DbgLog((LOG_ERROR, 2, TEXT("prcSource or prcDest is NULL")));
    }

    return hr;
}


STDMETHODIMP CAMVideoPort::GetCropState(AMVP_CROP_STATE *pCropState)
{
    *pCropState = m_CropState;
    return NOERROR;
}

STDMETHODIMP CAMVideoPort::GetPixelsPerSecond(DWORD* pPixelPerSec)
{
    *pPixelPerSec = m_dwPixelsPerSecond;
    return NOERROR;
}

STDMETHODIMP CAMVideoPort::GetVPDataInfo(AMVPDATAINFO* pVPDataInfo)
{
    *pVPDataInfo = m_VPDataInfo;
    return NOERROR;
}

STDMETHODIMP CAMVideoPort::GetVPInfo(DDVIDEOPORTINFO* pVPInfo)
{
    *pVPInfo = m_svpInfo;
    return NOERROR;
}

STDMETHODIMP CAMVideoPort::GetVPBandwidth(DDVIDEOPORTBANDWIDTH* pVPBandwidth)
{
    *pVPBandwidth = m_sBandwidth;
    return NOERROR;
}

STDMETHODIMP CAMVideoPort::GetVPCaps(DDVIDEOPORTCAPS* pVPCaps)
{
    *pVPCaps = m_vpCaps;
    return NOERROR;
}

STDMETHODIMP CAMVideoPort::GetVPInputFormat(LPDDPIXELFORMAT* pVPFormat)
{
    *pVPFormat = m_pddVPInputVideoFormat;
    return NOERROR;
}

STDMETHODIMP CAMVideoPort::GetVPOutputFormat(LPDDPIXELFORMAT* pVPFormat)
{
    *pVPFormat = m_pddVPOutputVideoFormat;
    return NOERROR;
}


/******************************Public*Routine******************************\
* CAMVideoPort::OnClipChange
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::OnClipChange(LPWININFO pWinInfo)
{
    AMTRACE((TEXT("CAMVideoPort::OnClipChange")));

    HRESULT hr = NOERROR;
    LPVPDRAWFLAGS pvpDrawFlags = NULL;
    WININFO CopyWinInfo;
    AMVP_MODE tryMode;
    LPDIRECTDRAWSURFACE pPrimarySurface = NULL;


    CAutoLock cObjectLock(m_pMainObjLock);

    pPrimarySurface = m_pIVPControl->GetPrimarySurface();
    ASSERT(pPrimarySurface);

    if (!m_pOverlaySurface)
    {
        DbgLog((LOG_ERROR, 1, TEXT("OnClipChange, m_pOverlaySurface = NULL")));
        goto CleanUp;
    }

    // if the dest empty is empty just hide the overlay
    if (IsRectEmpty(&pWinInfo->DestClipRect))
    {
        hr = m_pIVPControl->CallUpdateOverlay(m_pOverlaySurface,
                                              NULL,
                                              pPrimarySurface,
                                              NULL,
                                              DDOVER_HIDE);
        goto CleanUp;
    }

    // make a copy of the WININFO so that we can modify it
    CopyWinInfo = *pWinInfo;

    // if there is no overlay surface, can't do anything!
    ASSERT(m_pOverlaySurface);

    // allocate the draw flags structure
    pvpDrawFlags = new VPDRAWFLAGS;
    if (pvpDrawFlags == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("pvpDrawFlags is NULL, Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // initialize the draw flags structure
    pvpDrawFlags->bUsingColorKey = TRUE;
    pvpDrawFlags->bDoUpdateVideoPort = FALSE;
    pvpDrawFlags->bDoTryAutoFlipping = TRUE;
    pvpDrawFlags->bDoTryDecimation = TRUE;

    // if the videoport is not running (the graph has been paused/stopped,
    // then we can't do any mode changes etc. We cannot really decimate video,
    // however we can just clip the video from the upper-left corner.
    if (m_VPState == AMVP_VIDEO_STOPPED && !m_bStart)
    {
        pvpDrawFlags->bDoUpdateVideoPort = FALSE;
        hr = DrawImage(&CopyWinInfo, m_StoredMode, pvpDrawFlags);

        // problem case, if we fail here there is really nothing more
        // we can do. We cannot try different modes for example.
        if (FAILED(hr))
        {
            DbgLog((LOG_TRACE, 1,
                    TEXT("DrawImage Failed, m_VPState = Stopped,")
                    TEXT(" mode = %d, hr = 0x%x"),
                    m_StoredMode, hr));
        }
        goto CleanUp;
    }


    if (m_StoredMode != m_CurrentMode)
    {
        pvpDrawFlags->bDoUpdateVideoPort = TRUE;
        m_StoredMode = m_CurrentMode;
    }

    tryMode = m_CurrentMode;

    if (tryMode == AMVP_MODE_WEAVE)
    {
        if (m_bCanWeave)
            hr = DrawImage(&CopyWinInfo, tryMode, pvpDrawFlags);
        if (!m_bCanWeave || FAILED(hr))
        {
            tryMode = AMVP_MODE_BOBINTERLEAVED;
            pvpDrawFlags->bDoUpdateVideoPort = TRUE;
        }
    }

    if (tryMode == AMVP_MODE_BOBINTERLEAVED)
    {
        if (m_bCanBobInterleaved)
            hr = DrawImage(&CopyWinInfo, tryMode, pvpDrawFlags);
        if (!m_bCanBobInterleaved || FAILED(hr))
        {
            tryMode = AMVP_MODE_BOBNONINTERLEAVED;
            pvpDrawFlags->bDoUpdateVideoPort = TRUE;
        }
    }

    if (tryMode == AMVP_MODE_BOBNONINTERLEAVED)
    {
        if (m_bCanBobNonInterleaved)
            hr = DrawImage(&CopyWinInfo, tryMode, pvpDrawFlags);
        if (!m_bCanBobNonInterleaved || FAILED(hr))
        {
            tryMode = AMVP_MODE_SKIPODD;
            pvpDrawFlags->bDoUpdateVideoPort = TRUE;
        }
    }

    if (tryMode == AMVP_MODE_SKIPODD)
    {
        if (m_bCanSkipOdd)
            hr = DrawImage(&CopyWinInfo, tryMode, pvpDrawFlags);
        if (!m_bCanSkipOdd || FAILED(hr))
        {
            tryMode = AMVP_MODE_SKIPEVEN;
            pvpDrawFlags->bDoUpdateVideoPort = TRUE;
        }
    }

    if (tryMode == AMVP_MODE_SKIPEVEN)
    {
        if (m_bCanSkipEven)
            hr = DrawImage(&CopyWinInfo, tryMode, pvpDrawFlags);
    }

    // save the last mode we tried
    m_StoredMode = tryMode;

    // change the current mode to somethig that succeeded
    if (SUCCEEDED(hr) && tryMode != m_CurrentMode)
    {
        m_CurrentMode = tryMode;
    }

    // problem case we have tried everything and it still fails!!!
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("DrawImage Failed, m_VPState = Stopped,")
                TEXT(" mode = %d, hr = 0x%x"),
                tryMode, hr));
    }

CleanUp:
    if (pvpDrawFlags)
    {
        delete pvpDrawFlags;
        pvpDrawFlags = NULL;
    }

    return hr;
}



/*****************************Private*Routine******************************\
* CAMVideoPort::NegotiateConnectionParamaters
*
* this functions negotiates the connection parameters with
* the decoder.
* Since this function might be called during renegotiation, the
* existing connection parameters are passed in as input and if
* possible, we try to use the same parameters.
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::NegotiateConnectionParamaters()
{
    AMTRACE((TEXT("CAMVideoPort::NegotiateConnectionParamaters")));

    HRESULT hr = NOERROR;
    LPDDVIDEOPORTCONNECT lpddProposedConnect = NULL;
    DWORD dwNumProposedEntries = 0;
    DDVIDEOPORTSTATUS ddVPStatus = { sizeof(DDVIDEOPORTSTATUS)};
    LPDDVIDEOPORTCONNECT lpddVideoPortConnect = NULL;
    DWORD dwNumVideoPortEntries = 0;
    BOOL bIntersectionFound = FALSE;
    DWORD i, j;


    CAutoLock cObjectLock(m_pMainObjLock);

    ASSERT(m_pIVPConfig);
    ASSERT(m_pDVP);

    // find the number of entries to be proposed
    hr = m_pIVPConfig->GetConnectInfo(&dwNumProposedEntries, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetConnectInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(dwNumProposedEntries);

    // allocate the necessary memory
    lpddProposedConnect = new DDVIDEOPORTCONNECT[dwNumProposedEntries];
    if (lpddProposedConnect == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiateConnectionParamaters : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // memset the allocated memory to zero
    ZeroMemory(lpddProposedConnect,
               dwNumProposedEntries*sizeof(DDVIDEOPORTCONNECT));

    // set the right size in each of the structs.
    for (i = 0; i < dwNumProposedEntries; i++)
    {
        lpddProposedConnect[i].dwSize = sizeof(DDVIDEOPORTCONNECT);
    }

    // get the entries proposed
    hr = m_pIVPConfig->GetConnectInfo(&dwNumProposedEntries, lpddProposedConnect);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetConnectInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // get the status of the video port
    hr = m_pDVP->QueryVideoPortStatus(m_dwVideoPortId, &ddVPStatus);
    if (FAILED(hr))
    {
        //  Some cards don't implement this so just crash on
        ddVPStatus.bInUse = FALSE;
        DbgLog((LOG_ERROR, 0,
                TEXT("m_pDVP->QueryVideoPortStatus failed, hr = 0x%x"), hr));
//	goto CleanUp;
    }

    // find the number of entries supported by the videoport
    hr = m_pDVP->GetVideoPortConnectInfo(m_dwVideoPortId, &dwNumVideoPortEntries, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("m_pDVP->GetVideoPortConnectInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(dwNumVideoPortEntries);

    // allocate the necessary memory
    lpddVideoPortConnect = new DDVIDEOPORTCONNECT[dwNumVideoPortEntries];
    if (lpddVideoPortConnect == NULL)
    {
        DbgLog((LOG_ERROR,0,
                TEXT("NegotiateConnectionParamaters : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // memset the allocated memory to zero
    ZeroMemory(lpddVideoPortConnect,
               dwNumVideoPortEntries*sizeof(DDVIDEOPORTCONNECT));

    // set the right size in each of the structs.
    for (i = 0; i < dwNumVideoPortEntries; i++)
    {
        lpddVideoPortConnect[i].dwSize = sizeof(DDVIDEOPORTCONNECT);
    }

    // get the entries supported by the videoport
    hr = m_pDVP->GetVideoPortConnectInfo(0, &dwNumVideoPortEntries,
                                         lpddVideoPortConnect);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pDVP->GetVideoPortConnectInfo failed, hr = 0x%x"), hr));
        hr = E_FAIL;
        goto CleanUp;
    }

    // check if the video port is not already in use
    if (!ddVPStatus.bInUse)
    {

        // take the first element of the intersection of the two lists and
        // set that value on the decoder
        for (i = 0; i < dwNumProposedEntries && !bIntersectionFound; i++)
        {
            for (j = 0; j < dwNumVideoPortEntries && !bIntersectionFound; j++)
            {
                if ((lpddProposedConnect[i].dwPortWidth ==
                     lpddVideoPortConnect[j].dwPortWidth)
                  && IsEqualIID(lpddProposedConnect[i].guidTypeID,
                                lpddVideoPortConnect[j].guidTypeID))
                {
                    m_ddConnectInfo = lpddVideoPortConnect[j];
                    hr = m_pIVPConfig->SetConnectInfo(i);
                    if (FAILED(hr))
                    {
                        DbgLog((LOG_ERROR,0,
                                TEXT("m_pIVPConfig->SetConnectInfo")
                                TEXT(" failed, hr = 0x%x"), hr));
                        goto CleanUp;
                    }

                    bIntersectionFound = TRUE;
                }
            }
        }
    }
    else
    {
        // take the first element of the list matching the current status
        for (i = 0; i < dwNumProposedEntries && !bIntersectionFound; i++)
        {
            if ((lpddProposedConnect[i].dwPortWidth ==
                 ddVPStatus.VideoPortType.dwPortWidth)
              && IsEqualIID(lpddProposedConnect[i].guidTypeID,
                            ddVPStatus.VideoPortType.guidTypeID))
            {

                for (j = 0; j < dwNumVideoPortEntries && !bIntersectionFound; j++)
                {
                    if ((lpddProposedConnect[i].dwPortWidth ==
                         lpddVideoPortConnect[j].dwPortWidth)
                      && IsEqualIID(lpddProposedConnect[i].guidTypeID,
                                    lpddVideoPortConnect[j].guidTypeID))
                    {
                        m_ddConnectInfo = lpddVideoPortConnect[j];
                        bIntersectionFound = TRUE;
                    }
                }
                break;
            }
        }
    }

    if (!bIntersectionFound)
    {
        hr = E_FAIL;

        goto CleanUp;
    }

    // cleanup
CleanUp:
    delete [] lpddProposedConnect;
    delete [] lpddVideoPortConnect;
    return hr;
}


/*****************************Private*Routine******************************\
* CAMVideoPort::EnumCallback
*
* This is a callback for the EnumVideoPorts method and saves the capabilites
* the video port.
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CALLBACK
CAMVideoPort::EnumCallback(LPDDVIDEOPORTCAPS lpCaps, LPVOID lpContext )
{
    AMTRACE((TEXT("CAMVideoPort::EnumCallback")));
    HRESULT hr = NOERROR;
    CAMVideoPort* pAMVideoPort = (CAMVideoPort*)lpContext;


    if (pAMVideoPort) {
        if (lpCaps) {
            CopyMemory(&(pAMVideoPort->m_vpCaps), lpCaps, sizeof(DDVIDEOPORTCAPS));
        }
    }
    else
    {
        DbgLog((LOG_ERROR,0,
                TEXT("lpContext = NULL, THIS SHOULD NOT BE HAPPENING!!!")));
        hr = E_FAIL;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* CAMVideoPort::GetDataParameters
*
*
* this functions gets various data parameters from the decoder
* parameters include dimensions, double-clock, vact etc
* Also maximum pixel rate the decoder will output
* this happens after the connnection parameters have been set-up
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::GetDataParameters()
{
    AMTRACE((TEXT("CAMVideoPort::GetDataParameters")));

    HRESULT hr = NOERROR;
    DWORD dwMaxPixelsPerSecond = 0;
    AMVPSIZE amvpSize;

    CAutoLock cObjectLock(m_pMainObjLock);


    // set the size of the struct
    m_VPDataInfo.dwSize = sizeof(AMVPDATAINFO);

    // get the VideoPort data information
    hr = m_pIVPConfig->GetVPDataInfo(&m_VPDataInfo);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetVPDataInfo failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    /*
    if (m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom > m_VPDataInfo.amvpDimInfo.dwFieldHeight)
    m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom = m_VPDataInfo.amvpDimInfo.dwFieldHeight;
    */

    // if decoder says data is not interlaced
    if (!(m_VPDataInfo.bDataIsInterlaced))
    {
        // this flag does not mean anything
        if (m_VPDataInfo.bFieldPolarityInverted)
        {
            hr = E_FAIL;
            goto CleanUp;
        }

        // these don't mean anything either
        if ((m_VPDataInfo.lHalfLinesOdd != 0) ||
            (m_VPDataInfo.lHalfLinesEven != 0))
        {
            hr = E_FAIL;
            goto CleanUp;
        }
    }

    amvpSize.dwWidth = m_VPDataInfo.amvpDimInfo.dwFieldWidth;
    amvpSize.dwHeight = m_VPDataInfo.amvpDimInfo.dwFieldHeight;

    // get the maximum pixel rate the decoder will output
    hr = m_pIVPConfig->GetMaxPixelRate(&amvpSize, &dwMaxPixelsPerSecond);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetMaxPixelRate failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    m_dwPixelsPerSecond = dwMaxPixelsPerSecond;



    CleanUp:
    DbgLog((LOG_TRACE, 5,TEXT("Leaving CAMVideoPort::GetDataParameters")));
    return hr;
}

/*****************************Private*Routine******************************\
* CAMVideoPort::EqualPixelFormats
*
* this is just a helper function used by the "NegotiatePixelFormat"
* function. Just compares two pixel-formats to see if they are the
* same. We can't use a memcmp because of the fourcc codes.
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
BOOL
CAMVideoPort::EqualPixelFormats(
    LPDDPIXELFORMAT lpFormat1,
    LPDDPIXELFORMAT lpFormat2)
{
    AMTRACE((TEXT("CAMVideoPort::EqualPixelFormats")));
    BOOL bRetVal = FALSE;

    CAutoLock cObjectLock(m_pMainObjLock);

    if (lpFormat1->dwFlags & lpFormat2->dwFlags & DDPF_RGB)
    {
        if (lpFormat1->dwRGBBitCount == lpFormat2->dwRGBBitCount &&
            lpFormat1->dwRBitMask == lpFormat2->dwRBitMask &&
            lpFormat1->dwGBitMask == lpFormat2->dwGBitMask &&
            lpFormat1->dwBBitMask == lpFormat2->dwBBitMask)
        {
            bRetVal = TRUE;
        }
    }
    else if (lpFormat1->dwFlags & lpFormat2->dwFlags & DDPF_FOURCC)
    {
        if (lpFormat1->dwFourCC == lpFormat2->dwFourCC)
        {
            bRetVal = TRUE;
        }
    }

    return bRetVal;
}


/*****************************Private*Routine******************************\
* CAMVideoPort::GetBestFormat
*
* this function takes a list of inputformats and returns the
* "best" input and output format according to some criterion.
* It also checks if the output formats is suitable by trying
* to allocate a small surface and checking to see if the call
* succeeds. Since this is before the overlay surface has been
* created, that should be a ok. Right now the criterion just
* includes bestbendwidth, or if not that then just the first
* suitable one in the list.
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT
CAMVideoPort::GetBestFormat(
    DWORD dwNumInputFormats,
    LPDDPIXELFORMAT lpddInputFormats,
    BOOL bGetBestBandwidth,
    LPDWORD lpdwBestEntry,
    LPDDPIXELFORMAT lpddBestOutputFormat)
{
    LPDDPIXELFORMAT lpddOutputFormats = NULL;
    DWORD dwNumOutputFormats = 0;
    HRESULT hr = NOERROR;

    DDVIDEOPORTBANDWIDTH sBandwidth;
    DWORD dwColorkey;
    DWORD dwOverlay;
    DWORD dwType;
    BOOL bOutputFormatSuitable = FALSE;
    DWORD i, j;

    AMTRACE((TEXT("CAMVideoPort::GetBestFormat")));

    CAutoLock cObjectLock(m_pMainObjLock);

    // check all the pointers here
    ASSERT(dwNumInputFormats);
    CheckPointer(lpddInputFormats, E_INVALIDARG);
    CheckPointer(lpdwBestEntry, E_INVALIDARG);
    CheckPointer(lpddBestOutputFormat, E_INVALIDARG);

    // initialize dwType so that is different from DDVPBCAPS_SOURCE and
    // DDVPBCAPS_DESTINATION
    //
    if (DDVPBCAPS_SOURCE >= DDVPBCAPS_DESTINATION)
        dwType = DDVPBCAPS_SOURCE + 1;
    else
        dwType = DDVPBCAPS_DESTINATION + 1;

    for (i = 0; i < dwNumInputFormats; i++)
    {
        // no clean-up is neccesary at this point, so it is safe to use
        // this macro
        CheckPointer(lpddInputFormats+i, E_INVALIDARG);

        // find the number of entries supported by the videoport
        hr = m_pVideoPort->GetOutputFormats(lpddInputFormats + i,
                                            &dwNumOutputFormats,
                                            NULL, DDVPFORMAT_VIDEO);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pVideoPort->GetOutputFormats failed, hr = 0x%x"),
                    hr));
            goto CleanUp;
        }
        ASSERT(dwNumOutputFormats);

        // allocate the necessary memory
        lpddOutputFormats = new DDPIXELFORMAT[dwNumOutputFormats];
        if (lpddOutputFormats == NULL)
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("new failed, failed to allocate memnory for ")
                    TEXT("lpddOutputFormats in NegotiatePixelFormat")));
            hr = E_OUTOFMEMORY;
            goto CleanUp;
        }

        // memset the allocated memory to zero
        ZeroMemory(lpddOutputFormats, dwNumOutputFormats*sizeof(DDPIXELFORMAT));

        // set the right size in each of the structs.
        for (j = 0; j < dwNumOutputFormats; j++)
        {
            lpddOutputFormats[j].dwSize = sizeof(DDPIXELFORMAT);
        }

        // get the entries supported by the videoport
        hr = m_pVideoPort->GetOutputFormats(lpddInputFormats + i,
                                            &dwNumOutputFormats,
                                            lpddOutputFormats,
                                            DDVPFORMAT_VIDEO);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pVideoPort->GetOutputFormats failed, hr = 0x%x"),
                    hr));
            goto CleanUp;
        }


        for (j = 0; j < dwNumOutputFormats; j++)
        {
            bOutputFormatSuitable = FALSE;
            LPDDPIXELFORMAT lpTempOutFormat = lpddOutputFormats+j;

            // check if output format is suitable
            {
                DDSURFACEDESC ddsdDesc;
                ddsdDesc.dwSize = sizeof(DDSURFACEDESC);
                ddsdDesc.dwFlags = DDSD_CAPS | DDSD_HEIGHT |
                                   DDSD_WIDTH | DDSD_PIXELFORMAT;

                memcpy(&ddsdDesc.ddpfPixelFormat,
                       lpTempOutFormat, sizeof(DDPIXELFORMAT));

                ddsdDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY |
                                          DDSCAPS_VIDEOMEMORY |
                                          DDSCAPS_VIDEOPORT;

                // the actual overlay surface created might be of different
                // dimensions, however we are just testing the pixel format
                ddsdDesc.dwWidth = m_lImageWidth;
                ddsdDesc.dwHeight = m_lImageHeight;

                /*
                ASSERT(pDirectDraw);
                hr = pDirectDraw->CreateSurface(&ddsdDesc, &m_pOverlaySurface, NULL);
                if (!FAILED(hr))
                {
                m_pOverlaySurface->Release();
                bOutputFormatSuitable = TRUE;
                }
                */
                m_pOverlaySurface = NULL;

                bOutputFormatSuitable = TRUE;
            }


            if (bOutputFormatSuitable)
            {
                if (!bGetBestBandwidth)
                {
                    if (dwType != DDVPBCAPS_SOURCE &&
                        dwType != DDVPBCAPS_DESTINATION)
                    {
                        sBandwidth.dwSize = sizeof(DDVIDEOPORTBANDWIDTH);

                        // do the first get_bandwidth just to get the type,
                        // can input 0 for the height and the width
                        hr = m_pVideoPort->GetBandwidthInfo(lpTempOutFormat,
                                                            0, 0, DDVPB_TYPE,
                                                            &sBandwidth);
                        if (FAILED(hr))
                        {
                            DbgLog((LOG_ERROR,0,
                            TEXT("m_pVideoPort->GetBandwidthInfo failed,")
                            TEXT(" hr = 0x%x"), hr));
                            //    goto CleanUp;
                        }
                        dwType = sBandwidth.dwCaps;

                        ASSERT(dwType == DDVPBCAPS_SOURCE ||
                               dwType == DDVPBCAPS_DESTINATION);

                        if (dwType == DDVPBCAPS_SOURCE)
                        {
                            dwOverlay = dwColorkey = (DWORD)0;
                        }
                        if (dwType == DDVPBCAPS_DESTINATION)
                        {
                            dwOverlay = dwColorkey = (DWORD) -1;
                        }
                    }
                    else if (dwType == DDVPBCAPS_SOURCE)
                    {
                        hr = m_pVideoPort->GetBandwidthInfo(lpTempOutFormat,
                                    m_VPDataInfo.amvpDimInfo.dwFieldWidth,
                                    m_VPDataInfo.amvpDimInfo.dwFieldHeight,
                                    DDVPB_OVERLAY, &sBandwidth);

                        if (FAILED(hr))
                        {
                            goto CleanUp;
                        }
                        if (dwOverlay < sBandwidth.dwOverlay ||
                            dwColorkey < sBandwidth.dwColorkey)
                        {
                            dwOverlay = sBandwidth.dwOverlay;
                            dwColorkey = sBandwidth.dwColorkey;
                            *lpdwBestEntry = i;

                            memcpy(lpddBestOutputFormat,
                                   lpTempOutFormat, sizeof(DDPIXELFORMAT));
                        }
                    }
                    else
                    {
                        ASSERT(dwType == DDVPBCAPS_DESTINATION);
                        hr = m_pVideoPort->GetBandwidthInfo(lpTempOutFormat,
                            m_VPDataInfo.amvpDimInfo.dwFieldWidth,
                            m_VPDataInfo.amvpDimInfo.dwFieldHeight,
                            DDVPB_VIDEOPORT, &sBandwidth);

                        if (FAILED(hr))
                        {
                            goto CleanUp;
                        }
                        if (dwOverlay > sBandwidth.dwOverlay ||
                            dwColorkey > sBandwidth.dwColorkey)
                        {
                            dwOverlay = sBandwidth.dwOverlay;
                            dwColorkey = sBandwidth.dwColorkey;
                            *lpdwBestEntry = i;
                            memcpy(lpddBestOutputFormat,
                                   lpTempOutFormat, sizeof(DDPIXELFORMAT));
                        }
                    }
                } // end of "if (bGetBestBandwidth)"
                else
                {
                    *lpdwBestEntry = i;
                    memcpy(lpddBestOutputFormat,
                           lpTempOutFormat, sizeof(DDPIXELFORMAT));
                    goto CleanUp;
                }
            } // end of "if (bOutputFormatSuitable)"

        } // end of the inner for loop


        // delete the mem allocated in the outer for loop
        delete [] lpddOutputFormats;
        lpddOutputFormats = NULL;

    } // end of outer for loop

    if (!FAILED(hr))
    {
        ASSERT(*lpdwBestEntry);
    }

    CleanUp:
    delete [] lpddOutputFormats;
    lpddOutputFormats = NULL;
    return hr;
}

/*****************************Private*Routine******************************\
* CAMVideoPort::NegotiatePixelFormat
*
* this function is used to negotiate the pixelformat with the decoder.
* It asks the decoder fot a list of input formats, intersects that list
* with the one the deocoder supports (while maintaining the order) and
* then calls "GetBestFormat" on that list to get the "best" input and
* output format. After that it calls "SetPixelFormat" on the decoder in
* order to inform the decoder of the decision.
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::NegotiatePixelFormat()
{
    HRESULT hr = NOERROR;

    LPDDPIXELFORMAT lpddProposedFormats = NULL;
    DWORD dwNumProposedEntries = 0;
    LPDDPIXELFORMAT lpddVPInputFormats = NULL;
    DWORD dwNumVPInputEntries = 0;
    LPDDPIXELFORMAT lpddIntersectionFormats = NULL;
    DWORD dwNumIntersectionEntries = 0;
    DWORD dwBestEntry, dwMaxIntersectionEntries = 0;
    DWORD i = 0, j = 0;

    AMTRACE((TEXT("CAMVideoPort::NegotiatePixelFormat")));

    CAutoLock cObjectLock(m_pMainObjLock);

    // find the number of entries to be proposed
    hr = m_pIVPConfig->GetVideoFormats(&dwNumProposedEntries, NULL);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetVideoFormats failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(dwNumProposedEntries);

    // allocate the necessary memory
    lpddProposedFormats = new DDPIXELFORMAT[dwNumProposedEntries];
    if (lpddProposedFormats == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiatePixelFormat : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // memset the allocated memory to zero
    ZeroMemory(lpddProposedFormats, dwNumProposedEntries*sizeof(DDPIXELFORMAT));

    // set the right size of all the structs
    for (i = 0; i < dwNumProposedEntries; i++)
    {
        lpddProposedFormats[i].dwSize = sizeof(DDPIXELFORMAT);
    }

    // get the entries proposed
    hr = m_pIVPConfig->GetVideoFormats(&dwNumProposedEntries, lpddProposedFormats);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pIVPConfig->GetVideoFormats failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // find the number of entries supported by the videoport
    hr = m_pVideoPort->GetInputFormats(&dwNumVPInputEntries,
                                       NULL, DDVPFORMAT_VIDEO);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pVideoPort->GetInputFormats failed, hr = 0x%x"), hr));
        goto CleanUp;
    }
    ASSERT(dwNumVPInputEntries);

    // allocate the necessary memory
    lpddVPInputFormats = new DDPIXELFORMAT[dwNumVPInputEntries];
    if (lpddVPInputFormats == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiatePixelFormat : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // memset the allocated memory to zero
    ZeroMemory(lpddVPInputFormats, dwNumVPInputEntries*sizeof(DDPIXELFORMAT));

    // set the right size of all the structs
    for (i = 0; i < dwNumVPInputEntries; i++)
    {
        lpddVPInputFormats[i].dwSize = sizeof(DDPIXELFORMAT);
    }

    // get the entries supported by the videoport
    hr = m_pVideoPort->GetInputFormats(&dwNumVPInputEntries,
                                       lpddVPInputFormats, DDVPFORMAT_VIDEO);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("m_pVideoPort->GetInputFormats failed, hr = 0x%x"), hr));
        hr = E_FAIL;
        goto CleanUp;
    }

    // calculate the maximum number of elements in the interesection
    dwMaxIntersectionEntries = (dwNumProposedEntries >= dwNumVPInputEntries) ?
                               (dwNumProposedEntries) : (dwNumVPInputEntries);

    // allocate the necessary memory
    lpddIntersectionFormats = new DDPIXELFORMAT[dwMaxIntersectionEntries];
    if (lpddIntersectionFormats == NULL)
    {
        DbgLog((LOG_ERROR,0,TEXT("NegotiatePixelFormat : Out of Memory")));
        hr = E_OUTOFMEMORY;
        goto CleanUp;
    }

    // memset the allocated memory to zero
    // no need to set the size of the structs here, as we will memcpy them anyway
    ZeroMemory(lpddIntersectionFormats, dwMaxIntersectionEntries*sizeof(DDPIXELFORMAT));

    // find the intersection of the two lists
    dwNumIntersectionEntries = 0;
    for (i = 0; i < dwNumProposedEntries; i++)
    {
        for (j = 0; j < dwNumVPInputEntries; j++)
        {
            if (EqualPixelFormats(lpddProposedFormats+i, lpddVPInputFormats+j))
            {
                memcpy((lpddIntersectionFormats+dwNumIntersectionEntries),
                       (lpddProposedFormats+i), sizeof(DDPIXELFORMAT));
                dwNumIntersectionEntries++;
                ASSERT(dwNumIntersectionEntries <= dwMaxIntersectionEntries);
            }
        }
    }

    // the number of entries in the intersection is zero!!
    // Return failure.
    if (dwNumIntersectionEntries == 0)
    {
        ASSERT(i == dwNumProposedEntries);
        ASSERT(j == dwNumVPInputEntries);
        hr = E_FAIL;
        goto CleanUp;
    }

    // call GetBestFormat with whatever search criterion you want
    hr = GetBestFormat(dwNumIntersectionEntries,
                       lpddIntersectionFormats, TRUE, &dwBestEntry,
                       m_pddVPOutputVideoFormat);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,TEXT("GetBestFormat failed, hr = 0x%x"), hr));
        goto CleanUp;
    }


    // cache the input format
    memcpy(m_pddVPInputVideoFormat, lpddIntersectionFormats + dwBestEntry,
           sizeof(DDPIXELFORMAT));

    // set the format the decoder is supposed to be using
    for (i = 0; i < dwNumProposedEntries; i++)
    {
        if (EqualPixelFormats(lpddProposedFormats+i, m_pddVPInputVideoFormat))
        {
            hr = m_pIVPConfig->SetVideoFormat(i);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,0,
                        TEXT("m_pIVPConfig->SetVideoFormat failed, hr = 0x%x"),
                        hr));
                goto CleanUp;
            }
            break;
        }
    }

    // we are sure that the chosen input format is in the input list
    ASSERT(i < dwNumProposedEntries);

CleanUp:
    // cleanup
    delete [] lpddProposedFormats;
    delete [] lpddVPInputFormats;
    delete [] lpddIntersectionFormats;
    return hr;
}


/*****************************Private*Routine******************************\
* CAMVideoPort::CreateVideoPort
*
* Displays the Create Video Port dialog and calls DDRAW to actually
* create the port.
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::CreateVideoPort()
{
    HRESULT hr = NOERROR;
    DDVIDEOPORTDESC svpDesc;
    DWORD dwTemp = 0, dwOldVal = 0;
    DWORD lHalfLinesOdd = 0, lHalfLinesEven = 0;
    AMTRACE((TEXT("CAMVideoPort::CreateVideoPort")));

    CAutoLock cObjectLock(m_pMainObjLock);

    INITDDSTRUCT(svpDesc);

    // if the decoder can send double clocked data and the videoport
    // supports it, then set that property. This field is only valid
    // with an external signal.
    if (m_VPDataInfo.bEnableDoubleClock &&
        m_ddConnectInfo.dwFlags & DDVPCONNECT_DOUBLECLOCK)
    {
        svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_DOUBLECLOCK;
    }
    else
    {
        svpDesc.VideoPortType.dwFlags &= ~DDVPCONNECT_DOUBLECLOCK;
    }

    // if the decoder can give an external activation signal and the
    // videoport supports it, then set that property. This field is
    // only valid with an external signal.
    if (m_VPDataInfo.bEnableVACT &&
        m_ddConnectInfo.dwFlags & DDVPCONNECT_VACT)
    {
        svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_VACT;
    }
    else
    {
        svpDesc.VideoPortType.dwFlags &= ~DDVPCONNECT_VACT;
    }

    // if the decoder can send interlaced data and the videoport
    // supports it, then set that property.
    if (m_VPDataInfo.bDataIsInterlaced)
    {
        svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_INTERLACED;
        m_bVSInterlaced = TRUE;
    }
    else
    {
        svpDesc.VideoPortType.dwFlags &= ~DDVPCONNECT_INTERLACED;
        m_bVSInterlaced = FALSE;
    }

    // handle the VREF stuff here
    if (m_ddConnectInfo.dwFlags & DDVPCONNECT_DISCARDSVREFDATA)
    {
        m_VPDataInfo.amvpDimInfo.rcValidRegion.top -=
                m_VPDataInfo.dwNumLinesInVREF;

        if (m_VPDataInfo.amvpDimInfo.rcValidRegion.top < 0)
            m_VPDataInfo.amvpDimInfo.rcValidRegion.top = 0;
    }

    // handle the halfline stuff here
    lHalfLinesOdd = m_VPDataInfo.lHalfLinesOdd;
    lHalfLinesEven = m_VPDataInfo.lHalfLinesEven;

    // reset both the halfline and the invert polarity bits
    svpDesc.VideoPortType.dwFlags &= ~DDVPCONNECT_HALFLINE;
    svpDesc.VideoPortType.dwFlags &= ~DDVPCONNECT_INVERTPOLARITY;

    // if halflines are being reported assert that the data is interlaced
    if (lHalfLinesOdd != 0 || lHalfLinesEven != 0)
    {
        ASSERT(m_VPDataInfo.bDataIsInterlaced);
    }

    // whenever halflines exist, make sure to set the tell the hal
    if (((lHalfLinesOdd ==  1 || lHalfLinesEven ==  1) && (m_ddConnectInfo.dwFlags & DDVPCONNECT_HALFLINE)) ||
        ((lHalfLinesOdd == -1 || lHalfLinesEven == -1) && (!(m_ddConnectInfo.dwFlags & DDVPCONNECT_HALFLINE))))
    {
        svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_HALFLINE;
    }

    // In this case, the video is forced to move down one line
    // case 2 in scott's document
    if ((lHalfLinesOdd == 0) &&
        (lHalfLinesEven == 1) &&
        (m_ddConnectInfo.dwFlags & DDVPCONNECT_HALFLINE))
    {
        m_VPDataInfo.amvpDimInfo.rcValidRegion.top += 1;
        m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom += 2;
        m_bGarbageLine = TRUE;

        // if the deocder is already not inverting fields and if the VGA supports
        // inverting polarities, then ask the VGA to invert polarities othwise ask
        // decoder to invert polarities.
        if (m_ddConnectInfo.dwFlags & DDVPCONNECT_INVERTPOLARITY)
        {
            svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_INVERTPOLARITY;
        }
        else
        {
            hr = m_pIVPConfig->SetInvertPolarity();
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,0,
                        TEXT("m_pIVPConfig->SetInvertPolarity failed, hr = 0x%x"),
                        hr));
                goto CleanUp;
            }
        }
    }
    // case 3 and 5 in scott's document
    else if ((lHalfLinesOdd == 1) &&
             (lHalfLinesEven == 0))
    {
        // case 5 (just shift by one, do not reverse polarities
        m_VPDataInfo.amvpDimInfo.rcValidRegion.top += 1;
        m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom += 2;
        m_bGarbageLine = TRUE;
        m_bCantInterleaveHalfline = TRUE;


        // case 3 (shift by one and reverse polarities)
        if (!(m_ddConnectInfo.dwFlags & DDVPCONNECT_HALFLINE))
        {
            // if the deocder is already not inverting fields and if the
            // VGA supports inverting polarities, then ask the VGA to invert
            // polarities othwise ask decoder to invert polarities.
            //
            if (m_ddConnectInfo.dwFlags & DDVPCONNECT_INVERTPOLARITY)
            {
                svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_INVERTPOLARITY;
            }
            else
            {
                hr = m_pIVPConfig->SetInvertPolarity();
                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR,0,
                            TEXT("m_pIVPConfig->SetInvertPolarity failed,")
                            TEXT(" hr = 0x%x"),
                            hr));
                    goto CleanUp;
                }
            }
        }
    }
    // case 4 in scott's document
    else if ((lHalfLinesOdd == 0) &&
             (lHalfLinesEven == -1) &&
             (!(m_ddConnectInfo.dwFlags & DDVPCONNECT_HALFLINE)))
    {
        m_VPDataInfo.amvpDimInfo.rcValidRegion.top += 0;
        m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom += 1;
        m_bGarbageLine = TRUE;
    }
    else if (((lHalfLinesOdd ==  0) && (lHalfLinesEven ==  0)) ||
             ((lHalfLinesOdd == -1) && (lHalfLinesEven ==  0) && (m_ddConnectInfo.dwFlags & DDVPCONNECT_HALFLINE)) ||
             ((lHalfLinesOdd ==  0) && (lHalfLinesEven == -1) && (m_ddConnectInfo.dwFlags & DDVPCONNECT_HALFLINE)) || // opposite of case 4
             ((lHalfLinesOdd ==  0) && (lHalfLinesEven ==  1) && (!(m_ddConnectInfo.dwFlags & DDVPCONNECT_HALFLINE)))) // opposite of case 2
    {
        // if the deocder is already inverting fields and if the VGA supports
        // inverting polarities, then ask the VGA to invert polarities
        // othwise ask decoder to invert polarities.
        if (m_VPDataInfo.bFieldPolarityInverted)
        {
            if (m_ddConnectInfo.dwFlags & DDVPCONNECT_INVERTPOLARITY)
            {
                svpDesc.VideoPortType.dwFlags |= DDVPCONNECT_INVERTPOLARITY;
            }
            else
            {
                hr = m_pIVPConfig->SetInvertPolarity();
                if (FAILED(hr))
                {
                    DbgLog((LOG_ERROR,0,
                            TEXT("m_pIVPConfig->SetInvertPolarity failed,")
                            TEXT(" hr = 0x%x"), hr));
                    goto CleanUp;
                }
            }
        }
    }
    else
    {
        // Potential bug : workaround for current BPC driver
        // hr = E_FAIL; // we can't handle these cases, FAIL
        // goto CleanUp;
    }

    if (m_VPDataInfo.amvpDimInfo.dwFieldHeight <
        (DWORD)m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom)
    {
        m_VPDataInfo.amvpDimInfo.dwFieldHeight =
            m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom;
    }

    if ((m_vpCaps.dwFlags & DDVPD_WIDTH) &&
        (m_VPDataInfo.amvpDimInfo.dwFieldWidth > m_vpCaps.dwMaxWidth))
    {
        m_VPDataInfo.amvpDimInfo.dwFieldWidth = m_vpCaps.dwMaxWidth;
    }

    if ((m_vpCaps.dwFlags & DDVPD_WIDTH) &&
        (m_VPDataInfo.amvpDimInfo.dwVBIWidth > m_vpCaps.dwMaxVBIWidth))
    {
        m_VPDataInfo.amvpDimInfo.dwVBIWidth = m_vpCaps.dwMaxVBIWidth;
    }

    if ((m_vpCaps.dwFlags & DDVPD_HEIGHT) &&
        (m_VPDataInfo.amvpDimInfo.dwFieldHeight > m_vpCaps.dwMaxHeight))
    {
        m_VPDataInfo.amvpDimInfo.dwFieldHeight = m_vpCaps.dwMaxHeight;
    }

    if (m_VPDataInfo.amvpDimInfo.rcValidRegion.right >
        (LONG)m_VPDataInfo.amvpDimInfo.dwFieldWidth)
    {
        m_VPDataInfo.amvpDimInfo.rcValidRegion.right =
                (LONG)m_VPDataInfo.amvpDimInfo.dwFieldWidth;
    }

    if (m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom >
        (LONG)m_VPDataInfo.amvpDimInfo.dwFieldHeight)
    {
        m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom =
            (LONG)m_VPDataInfo.amvpDimInfo.dwFieldHeight;
    }

    // fill up the fields of the description struct
    svpDesc.dwFieldWidth = m_VPDataInfo.amvpDimInfo.dwFieldWidth;
    svpDesc.dwVBIWidth = m_VPDataInfo.amvpDimInfo.dwVBIWidth;
    svpDesc.dwFieldHeight = m_VPDataInfo.amvpDimInfo.dwFieldHeight;

    svpDesc.dwMicrosecondsPerField = m_VPDataInfo.dwMicrosecondsPerField;
    svpDesc.dwMaxPixelsPerSecond = m_dwPixelsPerSecond;
    svpDesc.dwVideoPortID = m_dwVideoPortId;
    svpDesc.VideoPortType.dwSize = sizeof(DDVIDEOPORTCONNECT);
    svpDesc.VideoPortType.dwPortWidth = m_ddConnectInfo.dwPortWidth;
    memcpy(&svpDesc.VideoPortType.guidTypeID, &m_ddConnectInfo.guidTypeID, sizeof(GUID));

    DbgLog((LOG_TRACE, 3, TEXT("svpDesc")));
    DbgLog((LOG_TRACE, 3, TEXT("dwFieldWidth = %u"), svpDesc.dwFieldWidth));
    DbgLog((LOG_TRACE, 3, TEXT("dwVBIWidth   = %u"), svpDesc.dwVBIWidth));
    DbgLog((LOG_TRACE, 3, TEXT("dwFieldHeight= %u"), svpDesc.dwFieldHeight));
    DbgLog((LOG_TRACE, 3, TEXT("dwMicrosecondsPerField= %u"), svpDesc.dwMicrosecondsPerField));
    DbgLog((LOG_TRACE, 3, TEXT("dwMaxPixelsPerSecond= %u"), svpDesc.dwMaxPixelsPerSecond));
    DbgLog((LOG_TRACE, 3, TEXT("dwVideoPortID= %u"), svpDesc.dwVideoPortID));
    DbgLog((LOG_TRACE, 3, TEXT("dwSize= %u"), svpDesc.VideoPortType.dwSize));
    DbgLog((LOG_TRACE, 3, TEXT("dwPortWidth= %u"), svpDesc.VideoPortType.dwPortWidth));

    // create the videoport. The first parameter is dwFlags, reserved for
    // future use by ddraw. The last parameter is pUnkOuter, again must be
    // NULL.
    //
    // use the DDVPCREATE_VIDEOONLY flag only if the hal is capable of
    // streaming VBI on a seperate surface
    //
    if (m_vpCaps.dwCaps & DDVPCAPS_VBIANDVIDEOINDEPENDENT)
    {
        hr = m_pDVP->CreateVideoPort(DDVPCREATE_VIDEOONLY, &svpDesc,
                                     &m_pVideoPort, NULL);

        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("m_pDVP->CreateVideoPort(DDVPCREATE_VIDEOONLY)")
                    TEXT(" failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    else
    {
        hr = m_pDVP->CreateVideoPort(0, &svpDesc, &m_pVideoPort, NULL);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("m_pDVP->CreateVideoPort(0) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
    }

    CleanUp:
    return hr;
}


/*****************************Private*Routine******************************\
* CAMVideoPort::DetermineCroppingRestrictions
*
*
* this function is used to check the cropping restrictions at the
* videoport and at the overlay. This function also decides where
* the cropping should be done (at videoport or at overlay).
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::DetermineCroppingRestrictions()
{
    AMTRACE((TEXT("CAMVideoPort::DetermineCroppingRestrictions")));
    HRESULT hr = NOERROR;

    BOOL bVideoPortCanCrop = TRUE, bOverlayCanCrop = TRUE;
    DWORD dwTemp = 0, dwOldVal = 0;
    DWORD dwCropOriginX = 0, dwCropOriginY = 0;
    DWORD dwCropWidth = 0, dwCropHeight=0;
    LPDDCAPS pDirectCaps = NULL;


    CAutoLock cObjectLock(m_pMainObjLock);

    pDirectCaps = m_pIVPControl->GetHardwareCaps();
    ASSERT(pDirectCaps);

    // cache the cropping paramters
    dwCropOriginX = m_VPDataInfo.amvpDimInfo.rcValidRegion.left;
    dwCropOriginY = m_VPDataInfo.amvpDimInfo.rcValidRegion.top;
    dwCropWidth = (DWORD)(m_VPDataInfo.amvpDimInfo.rcValidRegion.right -
                          m_VPDataInfo.amvpDimInfo.rcValidRegion.left);
    dwCropHeight = (DWORD)(m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom -
                           m_VPDataInfo.amvpDimInfo.rcValidRegion.top);


    // Align the left boundary
    if (bVideoPortCanCrop && (m_vpCaps.dwFlags & DDVPD_ALIGN))
    {
        dwTemp = dwCropOriginX & (m_vpCaps.dwAlignVideoPortCropBoundary-1);
        if (dwTemp != 0)
        {
            dwOldVal = dwCropOriginX;
            dwCropOriginX = dwCropOriginX +
                            m_vpCaps.dwAlignVideoPortCropBoundary - dwTemp;

            m_VPDataInfo.amvpDimInfo.rcValidRegion.left = dwCropOriginX;
            dwCropWidth = (DWORD)(m_VPDataInfo.amvpDimInfo.rcValidRegion.right -
                                  m_VPDataInfo.amvpDimInfo.rcValidRegion.left);
            DbgLog((LOG_TRACE,2,
                    TEXT("Alligning the left cropping boundary from %d to %d"),
                    dwOldVal, dwCropOriginX));
        }
    }

    // Align the width
    if (bVideoPortCanCrop && (m_vpCaps.dwFlags & DDVPD_ALIGN))
    {
        dwTemp = dwCropWidth & (m_vpCaps.dwAlignVideoPortCropWidth-1);
        if (dwTemp != 0)
        {
            dwOldVal = dwCropOriginX;
            dwCropWidth = dwCropWidth - dwTemp;
            m_VPDataInfo.amvpDimInfo.rcValidRegion.right =
                dwCropWidth + (DWORD)(m_VPDataInfo.amvpDimInfo.rcValidRegion.left);
            DbgLog((LOG_TRACE,2,
                    TEXT("Alligning the width of cropping rect from %d to %d"),
                    dwOldVal, dwCropWidth));
        }
    }

    // determine if we can do without any cropping at all
    if (dwCropOriginX == 0 && dwCropOriginY == 0 &&
        dwCropWidth == m_VPDataInfo.amvpDimInfo.dwFieldWidth &&
        dwCropHeight == m_VPDataInfo.amvpDimInfo.dwFieldHeight)
    {
        // hurray we are home free!!!
        DbgLog((LOG_TRACE,1, TEXT("No cropping necessary")));
        m_CropState = AMVP_NO_CROP;
        goto CleanUp;
    }

    // determine if the videoport can do the cropping for us

    // Can the videoport crop in the X direction
    if (bVideoPortCanCrop && (m_vpCaps.dwFlags & DDVPD_FX))
    {
        if (dwCropWidth != m_VPDataInfo.amvpDimInfo.dwFieldWidth &&
            (m_vpCaps.dwFX & DDVPFX_CROPX) == 0)
        {
            DbgLog((LOG_ERROR,1, TEXT("VideoPort can't crop, DDVPFX_CROPX == 0")));
            bVideoPortCanCrop = FALSE;
        }
    }

    // Can the videoport crop in the Y direction
    if (bVideoPortCanCrop && (m_vpCaps.dwFlags & DDVPD_FX))
    {
        if (dwCropHeight != m_VPDataInfo.amvpDimInfo.dwFieldHeight &&
            (m_vpCaps.dwFX & DDVPFX_CROPY) == 0 &&
            (m_vpCaps.dwFX & DDVPFX_CROPTOPDATA) == 0)
        {
            DbgLog((LOG_ERROR,1, TEXT("VideoPort can't crop, DDVPFX_CROPY == 0")));
            bVideoPortCanCrop = FALSE;
        }
    }


    // ok, so the videoport can crop for us. So no need to crop at the
    // overlay surface.
    if (bVideoPortCanCrop)
    {
        DbgLog((LOG_TRACE,2, TEXT("Cropping would be done at the videoport")));
        m_CropState = AMVP_CROP_AT_VIDEOPORT;
        goto CleanUp;
    }

    // determine if the overlay can do the cropping for us

    // Is left boundary alligned
    if (bOverlayCanCrop && (pDirectCaps->dwCaps & DDCAPS_ALIGNBOUNDARYDEST))
    {
        dwTemp = dwCropOriginX & (pDirectCaps->dwAlignBoundaryDest-1);
        if (dwTemp != 0)
        {
            DbgLog((LOG_ERROR,1,
                    TEXT("Overlay can't crop, Align = %d, Crop.left = %d"),
                    dwTemp, dwCropOriginX));
            bOverlayCanCrop = FALSE;
        }
    }
    if (bOverlayCanCrop && (pDirectCaps->dwCaps & DDCAPS_ALIGNBOUNDARYSRC))
    {
        dwTemp = dwCropOriginX & (pDirectCaps->dwAlignBoundarySrc-1);
        if (dwTemp != 0)
        {
            DbgLog((LOG_ERROR,1,
                    TEXT("Overlay can't crop, Align = %d, Crop.left = %d"),
                    dwTemp, dwCropOriginX));
            bOverlayCanCrop = FALSE;
        }
    }

    // Is Width alligned
    if (bOverlayCanCrop && (pDirectCaps->dwCaps & DDCAPS_ALIGNSIZEDEST))
    {
        dwTemp = dwCropWidth & (pDirectCaps->dwAlignSizeDest -1);
        if (dwTemp != 0)
        {
            DbgLog((LOG_ERROR,1,
                    TEXT("Overlay can't crop, Align = %d, Crop.Width = %d"),
                    dwTemp, dwCropWidth));
            bOverlayCanCrop = FALSE;
        }
    }
    if (bOverlayCanCrop && (pDirectCaps->dwCaps & DDCAPS_ALIGNSIZESRC))
    {
        dwTemp = dwCropWidth & (pDirectCaps->dwAlignSizeSrc -1);
        if (dwTemp != 0)
        {
            DbgLog((LOG_ERROR,1,
                    TEXT("Overlay can't crop, Align = %d, Crop.Width = %d"),
                    dwTemp, dwCropWidth));
            bOverlayCanCrop = FALSE;
        }
    }

    // ok, the videoport was unsuitable but the overlay came through
    // this means more pain for me, no!!!
    if (bOverlayCanCrop)
    {
        DbgLog((LOG_ERROR,1,
                TEXT("Cropping would be done at the overlay")));
        m_CropState = AMVP_CROP_AT_OVERLAY;
    }

    if (!bOverlayCanCrop && m_CropState == AMVP_CROP_AT_OVERLAY)
    {
        // neither the videoport nor the overlay is suitable, bail out
        hr = E_FAIL;
        goto CleanUp;
    }

    CleanUp:
    return hr;
}


/*****************************Private*Routine******************************\
* CAMVideoPort::CreateVPOverlay
*
* this function is used to allocate an overlay surface to attach to the
* videoport.
* The allocation order it tries is just in decreasing amount of memory
* required. Theres is one ambiguity, which is resolved by bPreferBuffers
* (3 buffers, double height)
* (2 buffers, double height)
* (3 buffers, single height)
* (2 buffers, single height) OR (1 buffer , double height) (depends upon bPreferBuffers)
* (1 buffer , single height).
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/

HRESULT
CAMVideoPort::CreateVPOverlay(
    BOOL bTryDoubleHeight,
    DWORD dwMaxBuffers,
    BOOL bPreferBuffers)
{
    DDSURFACEDESC ddsdDesc;
    HRESULT hr = NOERROR;
    DWORD dwMaxHeight = 0, dwMinHeight = 0, dwCurHeight = 0, dwCurBuffers = 0;
    LPDIRECTDRAW pDirectDraw = NULL;

    AMTRACE((TEXT("CAMVideoPort::CreateVPOverlay")));

    CAutoLock cObjectLock(m_pMainObjLock);

    pDirectDraw = m_pIVPControl->GetDirectDraw();
    ASSERT(pDirectDraw);

    // initialize the fields of ddsdDesc
    ddsdDesc.dwSize = sizeof(DDSURFACEDESC);
    ddsdDesc.dwFlags = DDSD_CAPS |
                       DDSD_HEIGHT |
                       DDSD_WIDTH |
                       DDSD_PIXELFORMAT;

    memcpy(&ddsdDesc.ddpfPixelFormat, m_pddVPOutputVideoFormat,
           sizeof(DDPIXELFORMAT));

    ddsdDesc.ddsCaps.dwCaps = DDSCAPS_OVERLAY |
                              DDSCAPS_VIDEOMEMORY |
                              DDSCAPS_VIDEOPORT;
    ddsdDesc.dwWidth = m_lImageWidth;

    dwMaxHeight = dwMinHeight = m_lImageHeight;

    // we will try to allocate double height surface, only if the decoder is
    // sending interlaced data, and the videoport supports interlaced data
    // and can interleave interlaced data in memory and bTryDoubleHeight is true
    if (bTryDoubleHeight)
    {
        dwMaxHeight = 2 * m_lImageHeight;
    }
    else
    {
        // make sure that bPreferBuffers is TRUE here, since it is a single
        // height case making it FALSE would not make any sense
        bPreferBuffers = TRUE;
    }

    // we will only try to allocate more than one buffer, if the videoport
    // is cabable of autoflipping
    if (dwMaxBuffers > 1)
    {
        ddsdDesc.dwFlags |= DDSD_BACKBUFFERCOUNT;
        ddsdDesc.ddsCaps.dwCaps |= DDSCAPS_COMPLEX | DDSCAPS_FLIP;

        for (dwCurHeight = dwMaxHeight;
             !m_pOverlaySurface && dwCurHeight >= dwMinHeight; dwCurHeight /= 2)
        {
            for (dwCurBuffers = dwMaxBuffers;
                 !m_pOverlaySurface &&  dwCurBuffers >= 2; dwCurBuffers--)
            {

                // if the case is (2 buffers, single height) but we prefer
                // more height rather than more buffers, then postpone this
                // case. We will come to it eventually, if the other cases fail.
                if (!bPreferBuffers &&
                    dwCurBuffers == 2 &&
                    dwCurHeight == m_lImageHeight)
                {
                    continue;
                }

                ddsdDesc.dwHeight = dwCurHeight;
                ddsdDesc.dwBackBufferCount = dwCurBuffers-1;

                hr = pDirectDraw->CreateSurface(&ddsdDesc,
                                                &m_pOverlaySurface, NULL);
                if (SUCCEEDED(hr))
                {
                    m_dwBackBufferCount = dwCurBuffers-1;
                    m_dwOverlaySurfaceHeight = ddsdDesc.dwHeight;
                    m_dwOverlaySurfaceWidth = ddsdDesc.dwWidth;
                    goto CleanUp;
                }
            }
        }
    }

    // we should only reach this point when attempt to allocate multiple buffers
    // failed or no autoflip available or bPreferBuffers is FALSE


    // case (1 buffer, double height)
    if (dwMaxHeight == 2*m_lImageHeight)
    {
        ddsdDesc.dwHeight = 2*m_lImageHeight;
        ddsdDesc.dwFlags &= ~DDSD_BACKBUFFERCOUNT;
        ddsdDesc.ddsCaps.dwCaps &= ~(DDSCAPS_COMPLEX | DDSCAPS_FLIP);
        ddsdDesc.dwBackBufferCount = 0;

        hr = pDirectDraw->CreateSurface(&ddsdDesc, &m_pOverlaySurface, NULL);
        if (SUCCEEDED(hr))
        {
            m_dwBackBufferCount = 0;
            m_dwOverlaySurfaceHeight = ddsdDesc.dwHeight;
            m_dwOverlaySurfaceWidth = ddsdDesc.dwWidth;
            goto CleanUp;
        }
    }

    // case (2 buffer, single height) only if you prefer height to buffers
    if (bPreferBuffers && (dwMaxBuffers > 1) &&
        (m_vpCaps.dwCaps & DDVPCAPS_AUTOFLIP))
    {
        ddsdDesc.dwFlags |= DDSD_BACKBUFFERCOUNT;
        ddsdDesc.ddsCaps.dwCaps |= DDSCAPS_COMPLEX | DDSCAPS_FLIP;

        ddsdDesc.dwHeight = 2*m_lImageHeight;
        ddsdDesc.dwBackBufferCount = 1;

        hr = pDirectDraw->CreateSurface(&ddsdDesc, &m_pOverlaySurface, NULL);
        if (SUCCEEDED(hr))
        {
            m_dwBackBufferCount = 1;
            m_dwOverlaySurfaceHeight = ddsdDesc.dwHeight;
            m_dwOverlaySurfaceWidth = ddsdDesc.dwWidth;
            goto CleanUp;
        }
    }

    // case (1 buffer, single height)
    {
        ddsdDesc.dwHeight = m_lImageHeight;
        ddsdDesc.dwFlags &= ~DDSD_BACKBUFFERCOUNT;
        ddsdDesc.ddsCaps.dwCaps &= ~(DDSCAPS_COMPLEX | DDSCAPS_FLIP);
        ddsdDesc.dwBackBufferCount = 0;
        hr = pDirectDraw->CreateSurface(&ddsdDesc, &m_pOverlaySurface, NULL);
        if (SUCCEEDED(hr))
        {
            m_dwBackBufferCount = 0;
            m_dwOverlaySurfaceHeight = ddsdDesc.dwHeight;
            m_dwOverlaySurfaceWidth = ddsdDesc.dwWidth;
            goto CleanUp;
        }
    }

    ASSERT(!m_pOverlaySurface);
    DbgLog((LOG_ERROR,0,  TEXT("Unable to create overlay surface")));

    CleanUp:
    if (SUCCEEDED(hr))
    {
        DbgLog((LOG_TRACE, 1,
                TEXT("Created an Overlay Surface of Width=%d,")
                TEXT(" Height=%d, Total-No-of-Buffers=%d"),
                m_dwOverlaySurfaceWidth, m_dwOverlaySurfaceHeight,
                m_dwBackBufferCount+1));
    }

    return hr;
}

/*****************************Private*Routine******************************\
* CAMVideoPort::SetSurfaceParameters
*
* SetSurfaceParameters used to tell the decoder where the
* valid data is on the surface
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::SetSurfaceParameters()
{
    HRESULT hr = NOERROR;
    DWORD dwPitch = 0;
    DDSURFACEDESC ddSurfaceDesc;

    AMTRACE((TEXT("CAMVideoPort::SetSurfaceParameters")));

    CAutoLock cObjectLock(m_pMainObjLock);

    // get the surface description
    INITDDSTRUCT(ddSurfaceDesc);
    hr = m_pOverlaySurface->GetSurfaceDesc(&ddSurfaceDesc);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 1,
                TEXT("m_pOverlaySurface->GetSurfaceDesc failed, hr = 0x%x"),
                hr));
    }
    else
    {
        ASSERT(ddSurfaceDesc.dwFlags & DDSD_PITCH);
        dwPitch = (ddSurfaceDesc.dwFlags & DDSD_PITCH) ?
                    ddSurfaceDesc.lPitch :
                    ddSurfaceDesc.dwWidth;
    }

    hr = m_pIVPConfig->SetSurfaceParameters(dwPitch, 0, 0);

    // right now the proxy maps ERROR_SET_NOT_FOUND to an HRESULT and
    // returns that failure code if the driver does not implement a function
    //
    if (hr == E_NOTIMPL || hr == (HRESULT_FROM_WIN32(ERROR_SET_NOT_FOUND)))
    {
        hr = NOERROR;
        DbgLog((LOG_TRACE, 5,TEXT("SetSurfaceParamters not implemented")));
        goto CleanUp;
    }

    if (FAILED(hr))
    {
        DbgLog((LOG_TRACE, 5,TEXT("SetSurfaceParamters failed, hr = 0x%x"), hr));
    }

CleanUp:
    return hr;
}



/*****************************Private*Routine******************************\
* CAMVideoPort::InitializeVideoPortInfo
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::InitializeVideoPortInfo()
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CAMVideoPort::InitializeVideoPortInfo")));

    CAutoLock cObjectLock(m_pMainObjLock);

    // initialize the DDVIDEOPORTINFO struct to be passed to start-video
    INITDDSTRUCT(m_svpInfo);
    m_svpInfo.lpddpfInputFormat = m_pddVPInputVideoFormat;

    if (m_CropState == AMVP_CROP_AT_VIDEOPORT)
    {
        m_svpInfo.rCrop = m_VPDataInfo.amvpDimInfo.rcValidRegion;
        m_svpInfo.dwVPFlags |= DDVP_CROP;

        // use the VBI height only if the hal is capable of streaming
        // VBI on a seperate surface
        if (m_vpCaps.dwCaps & DDVPCAPS_VBIANDVIDEOINDEPENDENT)
        {
            m_svpInfo.dwVBIHeight = m_VPDataInfo.amvpDimInfo.rcValidRegion.top;
        }
    }
    else
    {
        m_svpInfo.dwVPFlags &= ~DDVP_CROP;
    }

    if (m_bVPSyncMaster)
    {
        m_svpInfo.dwVPFlags |= DDVP_SYNCMASTER;
    }
    else
    {
        m_svpInfo.dwVPFlags &= ~DDVP_SYNCMASTER;
    }

    return hr;
}


/*****************************Private*Routine******************************\
* CAMVideoPort::CheckDDrawVPCaps
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::CheckDDrawVPCaps()
{
    HRESULT hr = NOERROR;
    BOOL bAlwaysColorkey;

    AMTRACE((TEXT("CAMVideoPort::CheckDDrawVPCaps")));

    CAutoLock cObjectLock(m_pMainObjLock);

    // Determine if we should always colorkey, or only when we need to.
    // At issue is the fact that some overlays cannot colorkey and Y
    // interpolate at the same time.  If not, we will only colorkey when
    // we have to.
    m_sBandwidth.dwSize = sizeof(DDVIDEOPORTBANDWIDTH);
    hr = m_pVideoPort->GetBandwidthInfo(m_pddVPOutputVideoFormat,
                                        m_lImageWidth, m_lImageHeight,
                                        DDVPB_TYPE, &m_sBandwidth);

    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("m_pVideoPort->GetBandwidthInfo FAILED, hr = 0x%x"), hr));
        goto CleanUp;
    }

    if (m_sBandwidth.dwCaps == DDVPBCAPS_SOURCE)
    {
        hr = m_pVideoPort->GetBandwidthInfo(m_pddVPOutputVideoFormat,
                                            m_lImageWidth, m_lImageHeight,
                                            DDVPB_OVERLAY, &m_sBandwidth);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("m_pVideoPort->GetBandwidthInfo FAILED, hr = 0x%x"),
                    hr));
            goto CleanUp;
        }
        // store the caps info in this struct itself
        m_sBandwidth.dwCaps = DDVPBCAPS_SOURCE;
        if (m_sBandwidth.dwYInterpAndColorkey < m_sBandwidth.dwYInterpolate  &&
            m_sBandwidth.dwYInterpAndColorkey < m_sBandwidth.dwColorkey)
        {
            bAlwaysColorkey = FALSE;
        }
        else
        {
            bAlwaysColorkey = TRUE;
        }
    }
    else
    {
        ASSERT(m_sBandwidth.dwCaps == DDVPBCAPS_DESTINATION);


        DWORD dwImageHeight = m_lImageHeight;
        if (m_fCaptureInterleaved) {
            dwImageHeight /= 2;
        }

        hr = m_pVideoPort->GetBandwidthInfo(m_pddVPOutputVideoFormat,
                                            m_lImageWidth, dwImageHeight,
                                            DDVPB_VIDEOPORT, &m_sBandwidth);
        if (hr != DD_OK)
        {
            DbgLog((LOG_ERROR, 0,
                    TEXT("GetBandwidthInfo FAILED, hr = 0x%x"), hr));
            goto CleanUp;
        }
        // store the caps info in this struct itself
        m_sBandwidth.dwCaps = DDVPBCAPS_DESTINATION;
        if (m_sBandwidth.dwYInterpAndColorkey > m_sBandwidth.dwYInterpolate &&
            m_sBandwidth.dwYInterpAndColorkey > m_sBandwidth.dwColorkey)
        {
            bAlwaysColorkey = FALSE;
        }
        else
        {
            bAlwaysColorkey = TRUE;
        }
    }

    // determine the decimation properties in the x direction

    // Data can be arbitrarily shrunk
    if (m_vpCaps.dwFX & DDVPFX_PRESHRINKX) {

        m_DecimationModeX = DECIMATE_ARB;
    }

    // Data can be shrunk in increments of 1/x in the X direction
    // (where x is specified in the DDVIDEOPORTCAPS.dwPreshrinkXStep
    else if (m_vpCaps.dwFX & DDVPFX_PRESHRINKXS) {

        m_DecimationModeX = DECIMATE_INC;
        m_ulDeciStepX = m_vpCaps.dwPreshrinkXStep;

        DbgLog((LOG_TRACE, 1,
                TEXT("preshrink X increment %d"), m_vpCaps.dwPreshrinkXStep));
    }

    // Data can be binary shrunk (1/2, 1/4, 1/8, etc.)
    else if (m_vpCaps.dwFX & DDVPFX_PRESHRINKXB) {

        m_DecimationModeX = DECIMATE_BIN;
    }

    // no scaling at all supported !!
    else {

        m_DecimationModeX = DECIMATE_NONE;
    }

    // determine the decimation properties in the y direction

    // Data can be arbitrarily shrunk
    if (m_vpCaps.dwFX & DDVPFX_PRESHRINKY)
    {
        m_DecimationModeY = DECIMATE_ARB;
    }

    // Data can be shrunk in increments of 1/x in the Y direction
    // (where x is specified in the DDVIDEOPORTCAPS.dwPreshrinkYStep
    else if (m_vpCaps.dwFX & DDVPFX_PRESHRINKYS)
    {
        m_DecimationModeY = DECIMATE_INC;
        m_ulDeciStepX = m_vpCaps.dwPreshrinkYStep;
    }

    // Data can be binary shrunk (1/2, 1/4, 1/8, etc.)
    else if (m_vpCaps.dwFX & DDVPFX_PRESHRINKYB)
    {
        m_DecimationModeY = DECIMATE_BIN;
    }

    else {
        m_DecimationModeY = DECIMATE_NONE;
    }

CleanUp:
    return hr;
}




/*****************************Private*Routine******************************\
* CAMVideoPort::DetermineModeRestrictions
*
* Determine if we can bob(interleaved/non), weave, or skip fields
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::DetermineModeRestrictions()
{
    AMTRACE((TEXT("CAMVideoPort::DetermineModeRestrictions")));
    HRESULT hr = NOERROR;
    LPDDCAPS pDirectCaps = NULL;

    CAutoLock cObjectLock(m_pMainObjLock);

    pDirectCaps = m_pIVPControl->GetHardwareCaps();
    ASSERT(pDirectCaps);

    m_bCanWeave = FALSE;
    m_bCanBobInterleaved = FALSE;
    m_bCanBobNonInterleaved = FALSE;
    m_bCanSkipOdd = FALSE;
    m_bCanSkipEven = FALSE;

    // this is just a policy. Don't weave interlaced content cause of
    // motion artifacts
    if ((!m_bVSInterlaced) &&
        m_dwOverlaySurfaceHeight >= m_lImageHeight * 2 &&
        m_dwBackBufferCount > 0)
    {
        m_bCanWeave = TRUE;
        DbgLog((LOG_TRACE, 1, TEXT("Can Weave")));
    }

    if (m_bVSInterlaced &&
        m_dwOverlaySurfaceHeight >= m_lImageHeight * 2 &&
        pDirectCaps->dwCaps2 & DDCAPS2_CANBOBINTERLEAVED)
    {
        m_bCanBobInterleaved = TRUE;
        DbgLog((LOG_TRACE, 1, TEXT("Can Bob Interleaved")));
    }

    if (m_bVSInterlaced &&
        m_dwBackBufferCount > 0 &&
        pDirectCaps->dwCaps2 & DDCAPS2_CANBOBNONINTERLEAVED)
    {
        m_bCanBobNonInterleaved = TRUE;
        DbgLog((LOG_TRACE, 1, TEXT("Can Bob NonInterleaved")));
    }

    if (m_vpCaps.dwCaps & DDVPCAPS_SKIPODDFIELDS)
    {
        m_bCanSkipOdd = TRUE;
        DbgLog((LOG_TRACE, 1, TEXT("Can Skip Odd")));
    }

    if (m_vpCaps.dwCaps & DDVPCAPS_SKIPEVENFIELDS)
    {
        m_bCanSkipEven = TRUE;
        DbgLog((LOG_TRACE, 1, TEXT("Can Skip Even")));
    }

    return hr;
}

/*****************************Private*Routine******************************\
* SurfaceCounter
*
* This routine is appropriate as a callback for
* IDirectDrawSurface2::EnumAttachedSurfaces()
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT WINAPI
SurfaceCounter(
    LPDIRECTDRAWSURFACE lpDDSurface,
    LPDDSURFACEDESC lpDDSurfaceDesc,
    LPVOID lpContext
    )
{
    DWORD *dwCount = (DWORD *)lpContext;

    (*dwCount)++;

    return DDENUMRET_OK;
}

/*****************************Private*Routine******************************\
* SurfaceKernelHandle
*
*
* This routine is appropriate as a callback for
* IDirectDrawSurface2::EnumAttachedSurfaces().  The context parameter is a
* block of storage where the first DWORD element is the count of the remaining
* DWORD elements in the block.
*
* Each time this routine is called, it will increment the count, and put a
* kernel handle in the next available slot.
*
* It is assumed that the block of storage is large enough to hold the total
* number of kernel handles. The ::SurfaceCounter callback is one way to
* assure this (see above).
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT WINAPI
SurfaceKernelHandle(
    LPDIRECTDRAWSURFACE lpDDSurface,
    LPDDSURFACEDESC lpDDSurfaceDesc,
    LPVOID lpContext
    )
{
    IDirectDrawSurfaceKernel *pDDSK = NULL;
    DWORD *pdwKernelHandleCount = (DWORD *)lpContext;
    ULONG_PTR *pKernelHandles = ((ULONG_PTR *)(pdwKernelHandleCount))+1;
    HRESULT hr;

    AMTRACE((TEXT("::SurfaceKernelHandle")));

    // get the IDirectDrawKernel interface
    hr = lpDDSurface->QueryInterface(IID_IDirectDrawSurfaceKernel,
                                     (LPVOID *)&pDDSK);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("QueryInterface for IDirectDrawSurfaceKernel failed,")
                TEXT(" hr = 0x%x"), hr));
        goto CleanUp;
    }

    // get the kernel handle, using the first element of the context
    // as an index into the array
    ASSERT(pDDSK);
    hr = pDDSK->GetKernelHandle(pKernelHandles + *pdwKernelHandleCount);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("GetKernelHandle from IDirectDrawSurfaceKernel failed,")
                TEXT(" hr = 0x%x"), hr));
        goto CleanUp;
    }
    (*pdwKernelHandleCount)++;

    hr = DDENUMRET_OK;

    CleanUp:
    // release the kernel ddraw surface handle
    if (pDDSK)
    {
        pDDSK->Release();
        pDDSK = NULL;
    }

    return hr;
}

/*****************************Private*Routine******************************\
* CAMVideoPort::SetDDrawKernelHandles
*
* this function is used to inform the decoder of the various ddraw
* kernel handle using IVPConfig interface
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::SetDDrawKernelHandles()
{
    HRESULT hr = NOERROR, hrFailure = NOERROR;
    IDirectDrawKernel *pDDK = NULL;
    IDirectDrawSurfaceKernel *pDDSK = NULL;
    DWORD *pdwKernelHandleCount = 0;
    DWORD dwCount = 0;
    ULONG_PTR dwDDKernelHandle = 0;
    LPDIRECTDRAW pDirectDraw = NULL;

    AMTRACE((TEXT("CAMVideoPort::SetDDrawKernelHandles")));

    CAutoLock cObjectLock(m_pMainObjLock);

    pDirectDraw = m_pIVPControl->GetDirectDraw();
    ASSERT(pDirectDraw);

    // get the IDirectDrawKernel interface
    hr = pDirectDraw->QueryInterface(IID_IDirectDrawKernel, (LPVOID *)&pDDK);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("QueryInterface for IDirectDrawKernel failed, hr = 0x%x"),
                hr));
        goto CleanUp;
    }

    // get the kernel handle
    ASSERT(pDDK);
    hr = pDDK->GetKernelHandle(&dwDDKernelHandle);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("GetKernelHandle from IDirectDrawKernel failed, hr = 0x%x"),
                hr));
        goto CleanUp;
    }

    // set the kernel handle to directdraw using IVPConfig
    ASSERT(m_pIVPConfig);
    ASSERT(dwDDKernelHandle);
    hr = m_pIVPConfig->SetDirectDrawKernelHandle(dwDDKernelHandle);
    if (FAILED(hr))
    {
        hrFailure = hr;
        DbgLog((LOG_ERROR,0,
                TEXT("IVPConfig::SetDirectDrawKernelHandle failed, hr = 0x%x"),
                hr));
        goto CleanUp;
    }

    // set the VidceoPort Id using IVPConfig
    ASSERT(m_pIVPConfig);
    hr = m_pIVPConfig->SetVideoPortID(m_dwVideoPortId);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("IVPConfig::SetVideoPortID failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // Count the attached surfaces
    dwCount = 1; // includes the surface we already have a pointer to
    hr = m_pOverlaySurface->EnumAttachedSurfaces((LPVOID)&dwCount,
                                                  SurfaceCounter);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0,
                TEXT("EnumAttachedSurfaces failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // Allocate a buffer to hold the count and surface handles (count + array of handles)
    // pdwKernelHandleCount is also used as a pointer to the count followed by the array
    //
    pdwKernelHandleCount = (DWORD *)CoTaskMemAlloc(
            sizeof(ULONG_PTR) + dwCount*sizeof(ULONG_PTR));

    if (pdwKernelHandleCount == NULL)
    {
        DbgLog((LOG_ERROR,0,
                TEXT("Out of memory while retrieving surface kernel handles")));
        goto CleanUp;
    }

    {
        // handle array is right after the DWORD count
        ULONG_PTR *pKernelHandles = ((ULONG_PTR *)(pdwKernelHandleCount))+1;

        // Initialize the array with the handle for m_pOverlaySurface
        *pdwKernelHandleCount = 0;
        hr = SurfaceKernelHandle(m_pOverlaySurface, NULL,
                                (PVOID)pdwKernelHandleCount);
        if (hr != DDENUMRET_OK)
        {
            goto CleanUp;
        }

        hr = m_pOverlaySurface->EnumAttachedSurfaces(
                                    (LPVOID)pdwKernelHandleCount,
                                    SurfaceKernelHandle);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("EnumAttachedSurfaces failed, hr = 0x%x"), hr));
            goto CleanUp;
        }

        // set the kernel handle to the overlay surface using IVPConfig
        ASSERT(m_pIVPConfig);
        hr = m_pIVPConfig->SetDDSurfaceKernelHandles(*pdwKernelHandleCount,
                                                     pKernelHandles);
        if (FAILED(hr))
        {
            hrFailure = hr;
            DbgLog((LOG_ERROR,0,
                    TEXT("IVPConfig::SetDirectDrawKernelHandles failed,")
                    TEXT(" hr = 0x%x"), hr));
            goto CleanUp;
        }
    }
    CleanUp:
    // release the kernel ddraw handle
    if (pDDK)
    {
        pDDK->Release();
        pDDK = NULL;
    }

    if (pdwKernelHandleCount)
    {
        CoTaskMemFree(pdwKernelHandleCount);
        pdwKernelHandleCount = NULL;
    }

    return hrFailure;
}



/*****************************Private*Routine******************************\
* CAMVideoPort::DrawImage
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::DrawImage(
    LPWININFO pWinInfo,
    AMVP_MODE mode,
    LPVPDRAWFLAGS pvpDrawFlags
    )
{
    HRESULT hr = NOERROR;
    BOOL bUpdateVideoReqd = FALSE;
    BOOL bYInterpolating = FALSE;
    WININFO CopyWinInfo;
    BOOL bMaintainRatio = TRUE;
    LPDIRECTDRAWSURFACE pPrimarySurface = NULL;
    LPDDCAPS pDirectCaps = NULL;

    AMTRACE((TEXT("CAMVideoPort::DrawImage")));

    CAutoLock cObjectLock(m_pMainObjLock);

    pPrimarySurface = m_pIVPControl->GetPrimarySurface();
    ASSERT(pPrimarySurface);

    pDirectCaps = m_pIVPControl->GetHardwareCaps();
    ASSERT(pDirectCaps);

    CopyWinInfo = *pWinInfo;

    if (mode == AMVP_MODE_BOBNONINTERLEAVED || mode == AMVP_MODE_BOBINTERLEAVED)
        bYInterpolating = TRUE;

    if (pvpDrawFlags->bDoTryAutoFlipping && m_dwBackBufferCount > 0)
        m_svpInfo.dwVPFlags |= DDVP_AUTOFLIP;
    else
        m_svpInfo.dwVPFlags &= ~DDVP_AUTOFLIP;

    if (pvpDrawFlags->bDoTryDecimation)
    {
        BOOL bSrcSizeChanged = FALSE;
        hr = SetUpMode(&CopyWinInfo, mode);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("SetUpMode failed, mode = %d, hr = 0x%x"), mode, hr));
            goto CleanUp;
        }

        bSrcSizeChanged = ApplyDecimation(&CopyWinInfo,
                                          pvpDrawFlags->bUsingColorKey,
                                          bYInterpolating);

        if (bSrcSizeChanged || pvpDrawFlags->bDoUpdateVideoPort)
            bUpdateVideoReqd = TRUE;
    }
    else
    {
        hr = SetUpMode(&CopyWinInfo, mode);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("SetUpMode failed, mode = %d, hr = 0x%x"), mode, hr));
            goto CleanUp;
        }
    }

    if (m_fCapturing) {
        if (m_fCaptureInterleaved) {
            m_svpInfo.dwVPFlags |= DDVP_INTERLEAVE;
            m_dwOverlayFlags &= ~DDOVER_BOB;
        }
        else {
            m_svpInfo.dwVPFlags &= ~DDVP_INTERLEAVE;
        }
    }

    // no point making any videoport calls, if the video is stopped
    if (m_VPState == AMVP_VIDEO_RUNNING || m_bStart)
    {
        if (m_bStart)
        {
            DWORD dwSignalStatus;

            hr = m_pVideoPort->StartVideo(&m_svpInfo);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR, 0,
                        TEXT("StartVideo failed, mode = %d, hr = 0x%x"),
                        mode, hr));
                goto CleanUp;
            }
            DbgLog((LOG_ERROR,0, TEXT("StartVideo DONE!!!")));

            // check if the videoport is receiving a signal.
            hr = m_pVideoPort->GetVideoSignalStatus(&dwSignalStatus);
            if ((SUCCEEDED(hr)) && (dwSignalStatus == DDVPSQ_SIGNALOK))
            {
                m_pVideoPort->WaitForSync(DDVPWAIT_END, 0, 0);
            }
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,0,
                        TEXT("m_pVideoPort->GetVideoSignalStatus() failed,")
                        TEXT(" hr = 0x%x"), hr));
                hr = NOERROR;
            }


            m_bStart = FALSE;
        }
        else if (bUpdateVideoReqd)
        {
            DbgLog((LOG_TRACE,1, TEXT("UpdateVideo (%d, %d)"),
                    m_svpInfo.dwPrescaleWidth, m_svpInfo.dwPrescaleHeight));

            hr = m_pVideoPort->UpdateVideo(&m_svpInfo);
            if (FAILED(hr))
            {
                DbgLog((LOG_ERROR,0,
                        TEXT("UpdateVideo failed, mode = %d, hr = 0x%x"),
                        mode, hr));
                goto CleanUp;
            }
        }
    }

    CalcSrcClipRect(&CopyWinInfo.SrcRect, &CopyWinInfo.SrcClipRect,
                    &CopyWinInfo.DestRect, &CopyWinInfo.DestClipRect,
                    bMaintainRatio);

    AlignOverlaySrcDestRects(pDirectCaps, &CopyWinInfo.SrcClipRect,
                             &CopyWinInfo.DestClipRect);

    // should we colour key ??
    if (pvpDrawFlags->bUsingColorKey)
        m_dwOverlayFlags |= DDOVER_KEYDEST;
    else
        m_dwOverlayFlags &= ~DDOVER_KEYDEST;

    m_rcSource = CopyWinInfo.SrcClipRect;


    if (!(m_svpInfo.dwVPFlags & DDVP_INTERLEAVE))
    {
        m_rcSource.top *= 2;
        m_rcSource.bottom *= 2;
    }

    m_rcDest = CopyWinInfo.DestClipRect;

    // Position the overlay with the current source and destination
    if (IsRectEmpty(&CopyWinInfo.DestClipRect))
    {
        hr = m_pIVPControl->CallUpdateOverlay(m_pOverlaySurface,
                                              NULL,
                                              pPrimarySurface,
                                              NULL,
                                              DDOVER_HIDE);
        goto CleanUp;
    }

    hr = m_pIVPControl->CallUpdateOverlay(m_pOverlaySurface,
                                          &CopyWinInfo.SrcClipRect,
                                          pPrimarySurface,
                                          &CopyWinInfo.DestClipRect,
                                          m_dwOverlayFlags);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("m_pOverlaySurface->UpdateOverlay failed,")
                TEXT(" hr = 0x%x, mode = %d"),
                hr, mode));

        DbgLog((LOG_ERROR, 0, TEXT("SourceClipRect = %d, %d, %d, %d"),
                CopyWinInfo.SrcClipRect.left, CopyWinInfo.SrcClipRect.top,
                CopyWinInfo.SrcClipRect.right, CopyWinInfo.SrcClipRect.bottom));

        DbgLog((LOG_ERROR, 0, TEXT("DestinationClipRect = %d, %d, %d, %d"),
                CopyWinInfo.DestClipRect.left, CopyWinInfo.DestClipRect.top,
                CopyWinInfo.DestClipRect.right, CopyWinInfo.DestClipRect.bottom));

        goto CleanUp;
    }
    else
    {
        // spew some more debug info
        DbgLog((LOG_TRACE, 5, TEXT("UpdateOverlay succeeded, mode = %d"), mode));

        DbgLog((LOG_TRACE, 3, TEXT("Source Rect = %d, %d, %d, %d"),
                CopyWinInfo.SrcClipRect.left, CopyWinInfo.SrcClipRect.top,
                CopyWinInfo.SrcClipRect.right, CopyWinInfo.SrcClipRect.bottom));
        DbgLog((LOG_TRACE, 3, TEXT("Destination Rect = %d, %d, %d, %d"),
                CopyWinInfo.DestClipRect.left, CopyWinInfo.DestClipRect.top,
                CopyWinInfo.DestClipRect.right, CopyWinInfo.DestClipRect.bottom));

    }

    CleanUp:
    return hr;
}

/*****************************Private*Routine******************************\
* CAMVideoPort::SetUpMode
*
* This function is designed to be called everytime on an update-overlay call
* not just when the mode changes. This is basically to keep the code simple.
* Certain functions are supposed to be called in sequence,
* (SetUpMode, followedby AdjustSourceSize followedby SetDisplayRects).
* I just call them all everytime, eventhough it is possible to optimize on
* that. The logic is that since UpdateOverlay is so expensive, this is no
* performance hit.
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
HRESULT CAMVideoPort::SetUpMode(LPWININFO pWinInfo, int mode)
{
    HRESULT hr = NOERROR;

    AMTRACE((TEXT("CAMVideoPort::SetUpMode")));

    CAutoLock cObjectLock(m_pMainObjLock);

    CheckPointer(pWinInfo, E_INVALIDARG);

    if (mode != AMVP_MODE_WEAVE &&
        mode != AMVP_MODE_BOBINTERLEAVED &&
        mode != AMVP_MODE_BOBNONINTERLEAVED &&
        mode != AMVP_MODE_SKIPODD &&
        mode != AMVP_MODE_SKIPEVEN)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("SetUpMode failed, mode value not valid, mode = %d"),
                mode));
        hr = E_FAIL;
        goto CleanUp;
    }

    if (mode == AMVP_MODE_WEAVE && !m_bCanWeave)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("SetUpMode failed, Can't do mode AMVP_MODE_WEAVE")));
        hr = E_FAIL;
        goto CleanUp;
    }
    if (mode == AMVP_MODE_BOBINTERLEAVED && !m_bCanBobInterleaved)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("SetUpMode failed, Can't do mode AMVP_MODE_BOBINTERLEAVED")));
        hr = E_FAIL;
        goto CleanUp;
    }
    if (mode == AMVP_MODE_BOBNONINTERLEAVED && !m_bCanBobNonInterleaved)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("SetUpMode failed, Can't do mode AMVP_MODE_BOBNONINTERLEAVED")));
        hr = E_FAIL;
        goto CleanUp;
    }
    if (mode == AMVP_MODE_SKIPODD && !m_bCanSkipOdd)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("SetUpMode failed, Can't do mode AMVP_MODE_SKIPODD")));
        hr = E_FAIL;
        goto CleanUp;
    }
    if (mode == AMVP_MODE_SKIPEVEN && !m_bCanSkipEven)
    {
        DbgLog((LOG_ERROR, 0,
                TEXT("SetUpMode failed, Can't do mode AMVP_MODE_SKIPEVEN")));
        hr = E_FAIL;
        goto CleanUp;
    }

    // Determine if we should interleave this or not.
    // If we are doing weave, we certainly need to interleave.
    // Bob doesn't really care one way or the other (since it only
    // displays one field at a time), but interleaved makes it much
    // easier to switch from bob to weave.
    if (mode == AMVP_MODE_BOBINTERLEAVED ||
        mode == AMVP_MODE_WEAVE)
    {
        m_svpInfo.dwVPFlags |= DDVP_INTERLEAVE;

        DbgLog((LOG_TRACE, 3, TEXT("Setting VPflag interleaved")));
    }
    else
    {
        pWinInfo->SrcRect.top /= 2;
        pWinInfo->SrcRect.bottom /= 2;
        m_svpInfo.dwVPFlags &= ~DDVP_INTERLEAVE;
    }

    // if there is a garbage line at the top, we must clip it.
    // At this point the source rect is set up for a frame, so increment by 2
    // since we incremented the cropping rect height by 1, decrement the bottom
    // as well
    if (m_bGarbageLine)
    {
        pWinInfo->SrcRect.top += 1;
        pWinInfo->SrcRect.bottom -= 1;
        DbgLog((LOG_TRACE, 3,
                TEXT("m_bGarbageLine is TRUE, incrementing SrcRect.top")));
    }

    DbgLog((LOG_TRACE, 3,
            TEXT("New Source Rect after garbage line and frame/")
            TEXT("field correction= {%d, %d, %d, %d}"),
            pWinInfo->SrcRect.left, pWinInfo->SrcRect.top,
            pWinInfo->SrcRect.right, pWinInfo->SrcRect.bottom));


    if (mode == AMVP_MODE_SKIPODD)
    {
        m_svpInfo.dwVPFlags |= DDVP_SKIPODDFIELDS;
        DbgLog((LOG_TRACE, 3, TEXT("Setting VPflag SkipOddFields")));
    }
    else
    {
        m_svpInfo.dwVPFlags &= ~DDVP_SKIPODDFIELDS;
    }

    if (mode == AMVP_MODE_SKIPEVEN)
    {
        m_svpInfo.dwVPFlags |= DDVP_SKIPEVENFIELDS;
        DbgLog((LOG_TRACE, 3, TEXT("Setting VPflag SkipEvenFields")));
    }
    else
    {
        m_svpInfo.dwVPFlags &= ~DDVP_SKIPEVENFIELDS;
    }


    // set up the update-overlay flags
    m_dwOverlayFlags = DDOVER_SHOW;
    if ((mode == AMVP_MODE_BOBNONINTERLEAVED ||
         mode == AMVP_MODE_BOBINTERLEAVED)
      && (m_VPState == AMVP_VIDEO_RUNNING || m_bStart))
    {
        m_dwOverlayFlags |= DDOVER_BOB;
        DbgLog((LOG_TRACE,2, TEXT("setting overlay flag DDOVER_BOB")));
    }
    else
        m_dwOverlayFlags &= ~DDOVER_BOB;

    // set the autoflip flag only if the VideoPort is (or going to be) started
    if ((m_svpInfo.dwVPFlags & DDVP_AUTOFLIP) &&
        (m_VPState == AMVP_VIDEO_RUNNING || m_bStart))
    {
        m_dwOverlayFlags |= DDOVER_AUTOFLIP;
        DbgLog((LOG_TRACE,2, TEXT("setting overlay flag DDOVER_AUTOFLIP")));
    }
    else
        m_dwOverlayFlags &= ~DDOVER_AUTOFLIP;

    CleanUp:
    return hr;
}


/******************************Public*Routine******************************\
* CAMVideoPort::RenegotiateVPParameters
*
* this function is used to redo the whole videoport connect process,
* while the graph maybe be running.
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::RenegotiateVPParameters()
{
    HRESULT hr = NOERROR;
    AMVP_STATE vpOldState;

    AMTRACE((TEXT("CAMVideoPort::RenegotiateVPParameters")));

    CAutoLock cObjectLock(m_pMainObjLock);

    // don't return an error code if not connected
    if (!m_bConnected)
    {
        hr = NOERROR;
        goto CleanUp;
    }

    // store the old state, we will need to restore it later
    vpOldState = m_VPState;

    if (m_VPState == AMVP_VIDEO_RUNNING)
    {
        m_pIVPControl->CallUpdateOverlay(NULL, NULL, NULL, NULL, DDOVER_HIDE);

        // stop the VideoPort, however even we get an error here,
        // it is ok, just go on
        hr = m_pVideoPort->StopVideo();
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pVideoPort->StopVideo failed, hr = 0x%x"), hr));
            hr = NOERROR;
        }

        m_VPState = AMVP_VIDEO_STOPPED;
    }

    // release everything
    BreakConnect(TRUE);

    // redo the connection process
    hr = CompleteConnect(NULL, TRUE);
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0, TEXT("CompleteConnect failed, hr = 0x%x"), hr));
        goto CleanUp;
    }

    // if the video was previously running, make sure that a frame is
    // visible by making an update overlay call
    if (vpOldState == AMVP_VIDEO_RUNNING)
    {
        m_bStart = TRUE;

        // make sure that the video frame gets updated by redrawing everything
        hr = m_pIVPControl->EventNotify(EC_OVMIXER_REDRAW_ALL, 0, 0);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0,
                    TEXT("m_pIVPControl->EventNotify(EC_OVMIXER_REDRAW_ALL,")
                    TEXT(" 0, 0) failed, hr = 0x%x"), hr));
            goto CleanUp;
        }
        m_VPState = AMVP_VIDEO_RUNNING;
        m_pIVPControl->CallUpdateOverlay(NULL, NULL, NULL, NULL, DDOVER_SHOW);
    }

CleanUp:
    if (FAILED(hr))
    {
        hr = VFW_E_VP_NEGOTIATION_FAILED;
        if (m_pOverlaySurface)
        {
            LPDIRECTDRAWSURFACE pPrimarySurface = m_pIVPControl->GetPrimarySurface();
            ASSERT(pPrimarySurface);
            m_pIVPControl->CallUpdateOverlay(m_pOverlaySurface, NULL,
                                             pPrimarySurface, NULL,
                                             DDOVER_HIDE);
        }
        BreakConnect(TRUE);

        m_pIVPControl->EventNotify(EC_COMPLETE, S_OK, 0);
        m_pIVPControl->EventNotify(EC_ERRORABORT, hr, 0);
    }

    return hr;
}


/******************************Public*Routine******************************\
* CAMVideoPort::SetDeinterlaceMode
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::SetDeinterlaceMode(AMVP_MODE mode)
{
    AMTRACE((TEXT("CAMVideoPort::SetMode")));
    return E_NOTIMPL;
}

/******************************Public*Routine******************************\
* CAMVideoPort::GetDeinterlaceMode
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::GetDeinterlaceMode(AMVP_MODE *pMode)
{
    AMTRACE((TEXT("CAMVideoPort::GetMode")));
    return E_NOTIMPL;
}


/******************************Public*Routine******************************\
* CAMVideoPort::SetVPSyncMaster
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::SetVPSyncMaster(BOOL bVPSyncMaster)
{
    HRESULT hr = NOERROR;
    AMTRACE((TEXT("CAMVideoPort::SetVPSyncMaster")));

    CAutoLock cObjectLock(m_pMainObjLock);

    // if value has not changed, no need to do anything
    if (m_bVPSyncMaster != bVPSyncMaster)
    {
        // store the new value
        m_bVPSyncMaster = bVPSyncMaster;

        // if not connected, connection process will take care of updating the
        // m_svpInfo struct
        if (!m_bConnected)
            goto CleanUp;

        // update the m_svpInfo struct
        if (m_bVPSyncMaster) {
            m_svpInfo.dwVPFlags |= DDVP_SYNCMASTER;
        }
        else {
            m_svpInfo.dwVPFlags &= ~DDVP_SYNCMASTER;
        }

        // if video is stopped currently, no need to do anything else
        if (m_VPState == AMVP_VIDEO_STOPPED)
            goto CleanUp;

        // Call UpdateVideo to make sure the change is reflected immediately
        hr = m_pVideoPort->UpdateVideo(&m_svpInfo);
        if (FAILED(hr))
        {
            DbgLog((LOG_ERROR,0, TEXT("UpdateVideo failed, hr = 0x%x"), hr));
        }
    }

CleanUp:
    return hr;
}


/******************************Public*Routine******************************\
* CAMVideoPort::GetVPSyncMaster
*
*
*
* History:
* Thu 09/09/1999 - StEstrop - Added this comment and cleaned up the code
*
\**************************************************************************/
STDMETHODIMP CAMVideoPort::GetVPSyncMaster(BOOL *pbVPSyncMaster)
{
    HRESULT hr = NOERROR;
    AMTRACE((TEXT("CAMVideoPort::SetVPSyncMaster")));

    CAutoLock cObjectLock(m_pMainObjLock);

    if (pbVPSyncMaster) {
        *pbVPSyncMaster = m_bVPSyncMaster;
    }
    else {
        hr = E_INVALIDARG;
    }

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmprop\ovmprop.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Video renderer property pages, Anthony Phillips, January 1996

#include <streams.h>
#include <dvp.h>
#include <vptype.h>
#include <vpinfo.h>
#include <mpconfig3.h>
#include <ovmixpos2.h>
#include <ovmprop.h>
#include <resource.h>
#include <atlbase.h>


// Helper function to print data of a rectangle to an edit field
void SetDlgItemRect(HWND hwnd, int id, const RECT& rect, BOOL valid)
{
    TCHAR temp[64];

    if ( valid) {
        wsprintf(temp, TEXT("%d, %d, %d, %d"),
            rect.left, rect.top,
            rect.right, rect.bottom);
        SetDlgItemText( hwnd, id, temp );
    }
    else
        SetDlgItemText( hwnd, id, TEXT("") );
}

// This class implements a property page dialog for the overlay mixer. We
// expose certain statistics from the quality management implementation. In
// particular we have two edit fields that show the number of frames we have
// actually drawn and the number of frames that we dropped. The number of
// frames we dropped does NOT represent the total number dropped in any play
// back sequence (as expressed through MCI status frames skipped) since the
// quality management protocol may have negotiated with the source filter for
// it to send fewer frames in the first place. Dropping frames in the source
// filter is nearly always a more efficient mechanism when we are flooded


// Constructor

COMQualityProperties::COMQualityProperties(LPUNKNOWN pUnk,HRESULT *phr) :
    CBasePropertyPage(NAME("Quality Page"),pUnk,IDD_IQUALITY,IDS_TITLE_QUALITY),
    m_pIQualProp(NULL)
{
    ASSERT(phr);
}


// Create a quality properties object

CUnknown *COMQualityProperties::CreateInstance(LPUNKNOWN lpUnk, HRESULT *phr)
{
    CUnknown *punk = new COMQualityProperties(lpUnk, phr);
    if (punk == NULL)
    {
        *phr = E_OUTOFMEMORY;
    }
    return punk;
}


// Give us the filter to communicate with

HRESULT COMQualityProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pIQualProp == NULL);

    // Ask the renderer for it's IQualProp interface

    HRESULT hr = pUnknown->QueryInterface(IID_IQualProp,(void **)&m_pIQualProp);
    if (FAILED(hr))
        return hr;

    ASSERT(m_pIQualProp);

    return hr;
}


// Release any IQualProp interface we have

HRESULT COMQualityProperties::OnDisconnect()
{
    // Release the interface

    if (m_pIQualProp == NULL) {
        return E_UNEXPECTED;
    }

    m_pIQualProp->Release();
    m_pIQualProp = NULL;
    return NOERROR;
}


// Set the text fields in the property page

HRESULT COMQualityProperties::OnActivate()
{
    Reset();
    return NOERROR;
}


// Initialise the property page fields

void COMQualityProperties::SetEditFieldData()
{
    ASSERT(m_pIQualProp);
    TCHAR buffer[50];

    SetDlgItemInt(m_Dlg, IDD_QDROPPED, m_iDropped, FALSE);
    SetDlgItemInt(m_Dlg, IDD_QDRAWN, m_iDrawn, FALSE);

    wsprintf(buffer,TEXT("%d.%02d"), m_iFrameRate/100, m_iFrameRate%100);
    SetDlgItemText(m_Dlg, IDD_QAVGFRM, buffer);

    SetDlgItemInt(m_Dlg, IDD_QJITTER, m_iFrameJitter, TRUE);
    SetDlgItemInt(m_Dlg, IDD_QSYNCAVG, m_iSyncAvg, TRUE);
    SetDlgItemInt(m_Dlg, IDD_QSYNCDEV, m_iSyncDev, TRUE);
}


//
// OnReceiveMessage
//
// Override CBasePropertyPage method.
// Handles the messages for our property window
//
INT_PTR COMQualityProperties::OnReceiveMessage(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
    const UINT uTimerID = 0x61901; // random number to identify the timer
    switch (uMsg)
    {
        case WM_INITDIALOG:
        {
            // Set a timer to go off every 1/2 second
            SetTimer(m_Dlg, 0x61901, 500, NULL);
            break;
        }

        case WM_DESTROY:
        {
            KillTimer(m_hwnd, 0x61901);
            break;
        }

        case WM_TIMER:
        {
            Reset();
            break;
        }

    } // switch
    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
} // OnReceiveMessage


void COMQualityProperties::Reset()
{
    ASSERT(m_pIQualProp);

    m_pIQualProp->get_FramesDroppedInRenderer(&m_iDropped);
    m_pIQualProp->get_FramesDrawn(&m_iDrawn);
    m_pIQualProp->get_AvgFrameRate(&m_iFrameRate);
    m_pIQualProp->get_Jitter(&m_iFrameJitter);
    m_pIQualProp->get_AvgSyncOffset(&m_iSyncAvg);
    m_pIQualProp->get_DevSyncOffset(&m_iSyncDev);
    SetEditFieldData();
}


//
// CreateInstance
//
// Override CClassFactory method.
// Set lpUnk to point to an IUnknown interface on a new COMPositionProperties object
// Part of the COM object instantiation mechanism
//
CUnknown * WINAPI COMPositionProperties::CreateInstance(LPUNKNOWN lpunk, HRESULT *phr)
{
    CUnknown *punk = new COMPositionProperties(lpunk, phr);
    if (punk == NULL)
    {
        *phr = E_OUTOFMEMORY;
    }
    return punk;
} // CreateInstance


//
// COMPositionProperties::Constructor
//
// Constructs and initialises an COMPositionProperties object
//
COMPositionProperties::COMPositionProperties(LPUNKNOWN pUnk, HRESULT *phr)
    : CBasePropertyPage(NAME("Overlay Mixer Property Page"),pUnk,
        IDD_IOVMIXERPOS, IDS_TITLE_MIXPOS)
    , m_pIMixerPinConfig3(NULL)
    , m_pIAMOverlayMixerPosition2(NULL)
    , m_hDlg(HWND(NULL))

{
    ASSERT(phr);

} // (constructor) COMPositionProperties


HRESULT COMPositionProperties::OnActivate()
{
    Reset();
    return NOERROR;
}


BOOL COMPositionProperties::OnInitDialog(HWND hwnd, HWND hwndFocus, LPARAM lParam)
{
    m_hDlg = hwnd;
    return TRUE;
}


void COMPositionProperties::OnCommand(HWND hwnd, int id, HWND hwndCtl, UINT codeNotify)
{
    switch(id)
    {
    case IDC_RESET:
        Reset();
    }
}


//
// OnReceiveMessage
//
// Override CBasePropertyPage method.
// Handles the messages for our property window
//
INT_PTR COMPositionProperties::OnReceiveMessage(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
    switch (uMsg)
    {
        HANDLE_MSG(hwnd, WM_COMMAND,    OnCommand);
        HANDLE_MSG(hwnd, WM_INITDIALOG, OnInitDialog);
    } // switch

    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
} // OnReceiveMessage


void COMPositionProperties::Reset()
{
    ASSERT(m_pIMixerPinConfig3);
    ASSERT(m_pIAMOverlayMixerPosition2);

    HRESULT hr = S_FALSE;
    RECT src, dest;

    AM_RENDER_TRANSPORT renderTransport;
    hr = m_pIMixerPinConfig3->GetRenderTransport( &renderTransport);
    if ( S_OK == hr) {
        switch (renderTransport) {
        case AM_VIDEOPORT:
            hr = m_pIAMOverlayMixerPosition2->GetVideoPortRects( &src, &dest);
            SetDlgItemText(m_hDlg, IDC_INPIN_RECTS, TEXT("Primary Input Pin -- VideoPort"));
            break;
        default:
            hr = m_pIAMOverlayMixerPosition2->GetOverlayRects( &src, &dest);
            SetDlgItemText(m_hDlg, IDC_INPIN_RECTS, TEXT("Primary Input Pin -- Overlay"));
            break;
        }
        SetDlgItemRect(m_hDlg, IDC_INPIN_SRC, src, SUCCEEDED(hr));
        SetDlgItemRect(m_hDlg, IDC_INPIN_DEST, dest, SUCCEEDED(hr));

    }

    hr = m_pIAMOverlayMixerPosition2->GetBasicVideoRects(&src, &dest);
    SetDlgItemRect(m_hDlg, IDC_BASIC_VID_SRC, src, SUCCEEDED(hr));
    SetDlgItemRect(m_hDlg, IDC_BASIC_VID_DEST, dest, SUCCEEDED(hr));
}

//
// OnConnect
//
// Override CBasePropertyPage method.
// Notification of which object this property page should display.
// We query the object for the IID_IAMOverlayMixerPosition2 interface.
//
// If cObjects == 0 then we must release the interface.
HRESULT COMPositionProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pIMixerPinConfig3 == NULL);
    ASSERT(m_pIAMOverlayMixerPosition2 == NULL);

    // QueryInterface for the Primary InputPin's IMixerPinConfig3 interface
    CComPtr<IBaseFilter> pFilter = NULL;
    CComPtr<IEnumPins> pEnumPins = NULL;
    CComPtr<IPin> pPin = NULL;

    HRESULT hr = pUnknown->QueryInterface(IID_IBaseFilter, (void**) &pFilter);
    if (FAILED(hr)) return hr;

    hr = pFilter->EnumPins(&pEnumPins);
    if (FAILED(hr)) return hr;
    pEnumPins->Reset();
    hr = pEnumPins->Next(1, &pPin, NULL);
    if (FAILED(hr)) return hr;

    if (pPin) {
        hr = pPin->QueryInterface(IID_IMixerPinConfig3,
        (void **) &m_pIMixerPinConfig3);
        if (FAILED(hr))
            return hr;
    }


    // QueryInterface for IAMOverlayMixerPosition2
    hr = pUnknown->QueryInterface(IID_IAMOverlayMixerPosition2,
        (void **) &m_pIAMOverlayMixerPosition2);

    if (FAILED(hr)) {
        m_pIMixerPinConfig3->Release();
        return hr;
    }

    ASSERT(m_pIMixerPinConfig3);
    ASSERT(m_pIAMOverlayMixerPosition2);

    return hr;

} // OnConnect


//
// OnDisconnect
//
// Override CBasePropertyPage method.
// Release the private interface.
//
HRESULT COMPositionProperties::OnDisconnect()
{
    // Release of Interface

    if (m_pIMixerPinConfig3) {
        m_pIMixerPinConfig3->Release();
        m_pIMixerPinConfig3 = NULL;
    }

    if (m_pIAMOverlayMixerPosition2) {
        m_pIAMOverlayMixerPosition2->Release();
        m_pIAMOverlayMixerPosition2 = NULL;
    }

    return NOERROR;

} // OnDisconnect



#if defined(DEBUG)
//
// CreateInstance
//
// Override CClassFactory method.
// Set lpUnk to point to an IUnknown interface on a new COMDecimationProperties object
// Part of the COM object instantiation mechanism
//
CUnknown * WINAPI COMDecimationProperties::CreateInstance(LPUNKNOWN lpunk, HRESULT *phr)
{
    CUnknown *punk = new COMDecimationProperties(lpunk, phr);
    if (punk == NULL)
    {
        *phr = E_OUTOFMEMORY;
    }
    return punk;
}


//
// COMDecimationProperties::Constructor
//
// Constructs and initialises an COMDecimationProperties object
//
COMDecimationProperties::COMDecimationProperties(LPUNKNOWN pUnk, HRESULT *phr) :
    CBasePropertyPage(NAME("Overlay Mixer Property Page"),pUnk,
                      IDD_DECIMATION_USAGE, IDS_TITLE_DECIMATION),
    m_pIAMVDP(NULL),
    m_pIAMSDC(NULL),
    m_hDlg(HWND(NULL))

{
    ASSERT(phr);

}


HRESULT COMDecimationProperties::OnActivate()
{
    //Reset();
    return NOERROR;
}

extern "C" const TCHAR chMultiMonWarning[];
extern int GetRegistryDword(HKEY hk, const TCHAR *pKey, int iDefault);
extern LONG SetRegistryDword(HKEY hk, const TCHAR *pKey, int iSet);

BOOL COMDecimationProperties::OnInitDialog(HWND hwnd, HWND hwndFocus, LPARAM lParam)
{
    m_hDlg = hwnd;

    static const struct {int id; DECIMATION_USAGE val;} map[] = {
        IDS_DECIMATION_LEGACY, DECIMATION_LEGACY,
        IDS_DECIMATION_USE_DECODER_ONLY, DECIMATION_USE_DECODER_ONLY,
        IDS_DECIMATION_USE_VIDEOPORT_ONLY, DECIMATION_USE_VIDEOPORT_ONLY,
        IDS_DECIMATION_USE_OVERLAY_ONLY, DECIMATION_USE_OVERLAY_ONLY,
        IDS_DEFAULT_DECIMATION, DECIMATION_DEFAULT
    };

    DECIMATION_USAGE dwDecimation;
    m_pIAMVDP->QueryDecimationUsage(&m_dwUsage);
    int iSel = -1;

    HWND hwndCombo = GetDlgItem(hwnd, IDC_DECIMATION_OPTIONS);
    DWORD i;

    for (i = 0; i < (sizeof(map) / sizeof(map[0])); i++) {

        TCHAR sz[128];
        int idx;

        LoadString(g_hInst, map[i].id, sz, 128);
        idx = ComboBox_AddString(hwndCombo, sz);
        ComboBox_SetItemData(hwndCombo, idx, map[i].val);

        if (map[i].val == m_dwUsage) {
            iSel = idx;
        }
    }
    ComboBox_SetCurSel(hwndCombo, iSel);


    m_pIAMSDC->GetDDrawGUID(&m_GUID);
    m_pIAMSDC->GetDDrawGUIDs(&m_dwCount, &m_lpMonInfo);
    iSel = -1;

    hwndCombo = GetDlgItem(hwnd, IDC_DDRAW_DEVICE);
    for (i = 0; i < m_dwCount; i++) {

        int     idx;
        TCHAR   sz[128];

        wsprintf(sz, TEXT("%hs : %hs"), m_lpMonInfo[i].szDevice,
                 m_lpMonInfo[i].szDescription);

        idx = ComboBox_AddString(hwndCombo, sz);
        ComboBox_SetItemData(hwndCombo, idx, &m_lpMonInfo[i]);

        if (m_GUID.lpGUID) {
            if (IsEqualGUID(m_GUID.GUID, m_lpMonInfo[i].guid.GUID)) {
                iSel = i;
            }
        }
        else {
            if (m_GUID.lpGUID == m_lpMonInfo[i].guid.lpGUID) {
                iSel = i;
            }
        }

    }
    ComboBox_SetCurSel(hwndCombo, iSel);


    DWORD chk;
    if (GetRegistryDword(HKEY_CURRENT_USER, chMultiMonWarning, 1)) {
        chk = BST_CHECKED;
        m_MMonWarn = TRUE;
    }
    else {
        chk = BST_UNCHECKED;
        m_MMonWarn = FALSE;
    }

    Button_SetCheck(GetDlgItem(hwnd, IDC_MMWARNING), chk);

    return TRUE;
}


void
COMDecimationProperties::OnCommand(
    HWND hwnd,
    int id,
    HWND hwndCtl,
    UINT codeNotify
    )
{
    switch(id) {
    case IDC_DECIMATION_OPTIONS:
        if (codeNotify == CBN_SELCHANGE) {

            int idx = ComboBox_GetCurSel(hwndCtl);
            DECIMATION_USAGE dwUsage =
                (DECIMATION_USAGE)ComboBox_GetItemData(hwndCtl, idx);

            if (dwUsage != m_dwUsage) {
                m_dwUsage = dwUsage;
                m_bDirty = TRUE;
                if (m_pPageSite) {
                    m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
                }
            }
        }
        break;

    case IDC_DDRAW_DEVICE:
        if (codeNotify == CBN_SELCHANGE) {

            int idx = ComboBox_GetCurSel(hwndCtl);
            AMDDRAWMONITORINFO* lpMi =
                (AMDDRAWMONITORINFO*)ComboBox_GetItemData(hwndCtl, idx);

            m_bDirty = FALSE;

            if (m_GUID.lpGUID) {
                if (lpMi->guid.lpGUID) {
                    if (!IsEqualGUID(m_GUID.GUID, lpMi->guid.GUID)) {
                        m_GUID.GUID = lpMi->guid.GUID;
                        m_bDirty = TRUE;
                    }
                }
                else {
                    m_GUID.lpGUID = NULL;
                    m_bDirty = TRUE;
                }
            }
            else {
                if (lpMi->guid.lpGUID) {
                    m_GUID.lpGUID = &m_GUID.GUID;
                    m_GUID.GUID = lpMi->guid.GUID;
                    m_bDirty = TRUE;
                }
            }

            if (m_bDirty && m_pPageSite) {
                m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
            }
        }
        break;

    case IDC_MAKE_DEFAULT:
        {
            hwndCtl = GetDlgItem(hwnd, IDC_DDRAW_DEVICE);
            int idx = ComboBox_GetCurSel(hwndCtl);
            if (idx != CB_ERR) {
                AMDDRAWMONITORINFO* lpMi =
                    (AMDDRAWMONITORINFO*)ComboBox_GetItemData(hwndCtl, idx);
                m_pIAMSDC->SetDefaultDDrawGUID(&lpMi->guid);

            }
        }
        break;

    case IDC_MMWARNING:
        if (codeNotify == BN_CLICKED) {
            BOOL fWarn = (Button_GetCheck(hwndCtl) == BST_CHECKED);
            if (fWarn != GetRegistryDword(HKEY_CURRENT_USER, chMultiMonWarning, 1)) {
                m_MMonWarn = fWarn;
                m_bDirty = TRUE;
            }

            if (m_bDirty && m_pPageSite) {
                m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
            }
        }
    }
}


//
// OnApplyChanges
//
// Override CBasePropertyPage method.
// Process changes in IID_IAMVideoDecimationProperties properties
// and reset m_bDirty bit
//
HRESULT COMDecimationProperties::OnApplyChanges()
{
    HRESULT hr = m_pIAMVDP->SetDecimationUsage(m_dwUsage);
    if (SUCCEEDED(hr)) {
        hr = m_pIAMSDC->SetDDrawGUID(&m_GUID);
    }

    SetRegistryDword(HKEY_CURRENT_USER, chMultiMonWarning, (DWORD)m_MMonWarn);

    m_bDirty = FALSE;
    return hr;
}

void
COMDecimationProperties::OnDestroy(
    HWND hwnd
    )
{
    CoTaskMemFree(m_lpMonInfo);
}

//
// OnReceiveMessage
//
// Override CBasePropertyPage method.
// Handles the messages for our property window
//
INT_PTR
COMDecimationProperties::OnReceiveMessage(
    HWND hwnd,
    UINT uMsg,
    WPARAM wParam,
    LPARAM lParam
    )
{
    switch (uMsg) {
    HANDLE_MSG(hwnd, WM_COMMAND,    OnCommand);
    HANDLE_MSG(hwnd, WM_INITDIALOG, OnInitDialog);
    HANDLE_MSG(hwnd, WM_DESTROY,    OnDestroy);
    } // switch

    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


//
// OnConnect
//
// Override CBasePropertyPage method.
// Notification of which object this property page should display.
// We query the object for the IID_IAMOverlayMixerPosition2 interface.
//
// If cObjects == 0 then we must release the interface.
HRESULT COMDecimationProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pIAMVDP == NULL);

    HRESULT hr = pUnknown->QueryInterface(IID_IAMVideoDecimationProperties,
                                          (void**)&m_pIAMVDP);

    if (SUCCEEDED(hr)) {
        hr = pUnknown->QueryInterface(IID_IAMSpecifyDDrawConnectionDevice,
                                      (void**)&m_pIAMSDC);
        if (FAILED(hr)) {
            m_pIAMVDP->Release();
            m_pIAMVDP = NULL;
        }
    }

    return hr;

} // OnConnect


//
// OnDisconnect
//
// Override CBasePropertyPage method.
// Release the private interface.
//
HRESULT COMDecimationProperties::OnDisconnect()
{
    // Release of Interface

    if (m_pIAMVDP) {
        m_pIAMVDP->Release();
        m_pIAMVDP = NULL;
    }

    if (m_pIAMSDC) {
        m_pIAMSDC->Release();
        m_pIAMSDC = NULL;
    }

    return NOERROR;

} // OnDisconnect
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmixer\syncobj.cpp ===
// Copyright (c) 1998 - 1999  Microsoft Corporation.  All Rights Reserved.
#include <streams.h>
#include <ddraw.h>
#include <mmsystem.h>	    // Needed for definition of timeGetTime
#include <limits.h>	    // Standard data type limit definitions
#include <ks.h>
#include <ksproxy.h>
#include <bpcwrap.h>
#include <ddmmi.h>
#include <amstream.h>
#include <dvp.h>
#include <ddkernel.h>
#include <vptype.h>
#include <vpconfig.h>
#include <vpnotify.h>
#include <vpobj.h>
#include <syncobj.h>
#include <mpconfig.h>
#include <ovmixpos.h>
#include <macvis.h>
#include <ovmixer.h>

#include <measure.h>        // Used for time critical log functions

// constructor
CAMSyncObj::CAMSyncObj(COMInputPin *pPin, IReferenceClock **ppClock, CCritSec *pLock, HRESULT *phr) :
m_evComplete(TRUE),
m_ThreadSignal(TRUE),
m_bTimerRunning( FALSE )
{
#ifdef PERF
    m_idTimeStamp       = MSR_REGISTER(TEXT("Frame time stamp"));
    m_idEarly           = MSR_REGISTER(TEXT("Earliness"));
    m_idLate            = MSR_REGISTER(TEXT("Lateness"));
#endif
    ResetStreamingTimes();

    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::Constructor")));

    m_pPin = pPin;
    m_ppClock = ppClock;
    m_pFilterLock = pLock;

    // some state variables.
    m_State = State_Stopped;
    m_bFlushing = FALSE;
    m_bConnected = FALSE;

    m_pPosition = NULL;
    m_dwAdvise = 0;
    m_pMediaSample = NULL;
    m_pMediaSample2 = NULL;
    m_tStart = 0;

    m_bAbort = FALSE;
    m_bStreaming = FALSE;
    m_bRepaintStatus = TRUE;
    m_bInReceive = FALSE;

    m_SignalTime = 0;
    m_bEOS = FALSE;
    m_bEOSDelivered = FALSE;
    m_EndOfStreamTimer = 0;

    m_MMTimerId = 0;

    *phr = hr;
    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::Constructor")));
    return;
}

// destructor
CAMSyncObj::~CAMSyncObj(void)
{
    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::Destructor")));
    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::Destructor")));
    return;
}

// check that the mediatype is acceptable
// Complete Connect
HRESULT CAMSyncObj::CompleteConnect(IPin *pReceivePin)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::CompleteConnect")));

    SetRepaintStatus(TRUE);
    m_bAbort = FALSE;

    // record the connection status using an internal variable
    m_bConnected = TRUE;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::CompleteConnect")));
    return hr;
}

HRESULT CAMSyncObj::BreakConnect(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::BreakConnect")));

    SetRepaintStatus(FALSE);
    ResetEndOfStream();
    ClearPendingSample();
    m_bAbort = FALSE;

    // record the connection status using an internal variable
    m_bConnected = FALSE;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::BreakConnect")));
    return hr;
}

// notifies us of the start/stop/rate applying to the data about to be received
HRESULT CAMSyncObj::NewSegment(REFERENCE_TIME tStart, REFERENCE_TIME tStop, double dRate)
{
    ASSERT(1);
    return NOERROR;
}

// transition from stop to pause state
HRESULT CAMSyncObj::Active(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::Active")));

    ASSERT(IsFlushing() == FALSE);

    // Enable EC_REPAINT events again
    SetRepaintStatus(TRUE);
    ASSERT(m_bStreaming == FALSE);
    SourceThreadCanWait(TRUE);
    CancelNotification();
    ResetEndOfStreamTimer();

    // There should be no outstanding advise
    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);
    ASSERT(IsFlushing() == FALSE);

    // When we come out of a stopped state we must clear any image we were
    // holding onto for frame refreshing. Since renderers see state changes
    // first we can reset ourselves ready to accept the source thread data
    // Paused or running after being stopped causes the current position to
    // be reset so we're not interested in passing end of stream signals
    m_bAbort = FALSE;
    ClearPendingSample();

    hr = CompleteStateChange(State_Stopped);

    // record the state using an internal variable
    m_State = State_Paused;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::Active")));
    return hr;
}

// transition from pause to stop state
HRESULT CAMSyncObj::Inactive(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::Inactive")));

    if (m_pPosition)
    {
        m_pPosition->ResetMediaTime();
    }

    // hold on to the sample if we are using our allocator
    if (!(m_pPin->UsingOurAllocator()))
    {
        ClearPendingSample();
    }

    // Cancel any scheduled rendering
    SetRepaintStatus(TRUE);
    m_bStreaming = FALSE;
    SourceThreadCanWait(FALSE);
    ResetEndOfStream();
    CancelNotification();

    // There should be no outstanding clock advise
    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);

    Ready();
    WaitForReceiveToComplete();
    m_bAbort = FALSE;

    // record the state using an internal variable
    m_State = State_Stopped;
    m_bFlushing = FALSE;

    if ( m_bTimerRunning ) {
        timeEndPeriod(1);
        m_bTimerRunning = FALSE;
    }
    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::Inactive")));
    return hr;
}

// transition from pause to run state
HRESULT CAMSyncObj::Run(REFERENCE_TIME tStart)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::Run")));

    Ready();


    // Allow the source thread to wait
    ASSERT(IsFlushing() == FALSE);
    SourceThreadCanWait(TRUE);
    SetRepaintStatus(FALSE);

    // There should be no outstanding advise
    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);
    ASSERT(IsFlushing() == FALSE);

    {
        CAutoLock cObjLock(&m_SyncObjLock);
        ASSERT(!m_bStreaming);

        // Reset the streaming times ready for running
        m_bStreaming = TRUE;
        OnStartStreaming();

        m_tStart = tStart;

        // record the state using an internal variable
        m_State = State_Running;

        if ( !m_bTimerRunning ) {
            timeBeginPeriod(1);
            m_bTimerRunning = TRUE;
        }

        // If we have an EOS and no data then deliver it now
        if (m_pMediaSample == NULL)
        {
            hr = SendEndOfStream();
            goto CleanUp;
        }

        // Have the data rendered
        ASSERT(m_pMediaSample);
        //m_RenderEvent.Set();
        ScheduleSample(m_pMediaSample);
}

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::Run")));
    return hr;
}

// transition from run to pause state
HRESULT CAMSyncObj::RunToPause(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::RunToPause")));

    ASSERT(IsFlushing() == FALSE);

    // Enable EC_REPAINT events again
    SetRepaintStatus(TRUE);
    m_bStreaming = FALSE;
    OnStopStreaming();

    SourceThreadCanWait(TRUE);
    CancelNotification();
    ResetEndOfStreamTimer();

    // There should be no outstanding advise
    ASSERT(CancelNotification() == S_FALSE);
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
    ASSERT(m_EndOfStreamTimer == 0);
    ASSERT(IsFlushing() == FALSE);

    if( m_bTimerRunning ) {
        timeEndPeriod(1);
        m_bTimerRunning = FALSE;
    }

    hr = CompleteStateChange(State_Running);

    // record the state using an internal variable
    m_State = State_Paused;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::RunToPause")));
    return hr;
}


// Signals start of flushing on the input pin - we do the final reset end of
// stream with the renderer lock unlocked but with the interface lock locked
// We must do this because we call timeKillEvent, our timer callback method
// has to take the renderer lock to serialise our state. Therefore holding a
// renderer lock when calling timeKillEvent could cause a deadlock condition
HRESULT CAMSyncObj::BeginFlush(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::BeginFlush")));

    CAutoLock cLock(m_pFilterLock);
    {
        CancelNotification();
        CAutoLock cObjLock(&m_SyncObjLock);

        // If paused then report state intermediate until we get some data
        if (m_State == State_Paused)
        {
            NotReady();
        }

        SourceThreadCanWait(FALSE);
        ClearPendingSample();
        //  Wait for Receive to complete
        WaitForReceiveToComplete();
    }
    hr = ResetEndOfStream();

    // record the flusing status using an internal variable
    ASSERT(!m_bFlushing);
    m_bFlushing = TRUE;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::BeginFlush")));
    return hr;
}


// end flushing the data
HRESULT CAMSyncObj::EndFlush(void)
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::EndFlush")));

    CAutoLock cLock(m_pFilterLock);
    CAutoLock cObjLock(&m_SyncObjLock);

    // Reset the current sample media time
    if (m_pPosition)
        m_pPosition->ResetMediaTime();

    // There should be no outstanding advise
    ASSERT(CancelNotification() == S_FALSE);
    SourceThreadCanWait(TRUE);

    // record the flusing status using an internal variable
    ASSERT(m_bFlushing);
    m_bFlushing = FALSE;

    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::EndFlush")));
    return hr;
}


// tell the state
STDMETHODIMP CAMSyncObj::GetState(DWORD dwMSecs,FILTER_STATE *pState)
{
    CheckPointer(pState,E_POINTER);

    if ((m_State == State_Paused) && (WaitDispatchingMessages(m_evComplete, dwMSecs) == WAIT_TIMEOUT))
    {
        *pState = m_State;
        return VFW_S_STATE_INTERMEDIATE;
    }
    *pState = m_State;
    return NOERROR;
}

// called when we receive a sample
HRESULT CAMSyncObj::Receive(IMediaSample *pSample)
{
    HRESULT hr = NOERROR;
    CheckPointer(pSample,E_POINTER);
    AM_MEDIA_TYPE *pMediaType;
    HANDLE WaitObjects[] = { m_ThreadSignal, m_RenderEvent };
    DWORD Result = WAIT_TIMEOUT;
    BOOL bSampleRendered = FALSE;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::Receive")));

    // It may return VFW_E_SAMPLE_REJECTED code to say don't bother
    hr = PrepareReceive(pSample);
    ASSERT(m_bInReceive == SUCCEEDED(hr));
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,0, TEXT("PrepareReceive failed, hr = 0x%x"), hr));
        if (hr == VFW_E_SAMPLE_REJECTED)
        {
            hr = NOERROR;
            goto CleanUp;
        }
        goto CleanUp;
    }

    // we might have to draw the first sample immediately
    if (m_State == State_Paused)
    {
        // no need to use InterlockedExchange
        m_bInReceive = FALSE;
        {
            // We must hold both these locks
            CAutoLock cLock(m_pFilterLock);
            if (m_State == State_Stopped)
                return NOERROR;
            m_bInReceive = TRUE;
            CAutoLock cObjLock(&m_SyncObjLock);
            OnReceiveFirstSample(pSample);
            bSampleRendered = TRUE;
        }
        Ready();
    }

    // Having set an advise link with the clock we sit and wait. We may be
    // awoken by the clock firing or by a state change. The rendering call
    // will lock the critical section and check we can still render the data
    hr = WaitForRenderTime();
    if (FAILED(hr))
    {
        DbgLog((LOG_ERROR,1, TEXT("WaitForRenderTime failed, hr = 0x%x"), hr));
        m_bInReceive = FALSE;
        hr = NOERROR;
        goto CleanUp;
    }

    //  Set this here and poll it until we work out the locking correctly
    //  It can't be right that the streaming stuff grabs the interface
    //  lock - after all we want to be able to wait for this stuff
    //  to complete
    m_bInReceive = FALSE;

    {
        // We must hold both these locks
        CAutoLock cLock(m_pFilterLock);
        {
            CAutoLock cObjLock(&m_SyncObjLock);

            // Deal with this sample

            if (m_bStreaming && !bSampleRendered && m_pMediaSample)
            {
                OnRenderStart(m_pMediaSample);
                m_pPin->DoRenderSample(m_pMediaSample);
                OnRenderEnd(m_pMediaSample);
            }

            ClearPendingSample();
            SendEndOfStream();
        }
        CancelNotification();
    }

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::Receive")));
    return hr;
}



// just render the sample
void CAMSyncObj::OnReceiveFirstSample(IMediaSample *pMediaSample)
{
    m_pPin->OnReceiveFirstSample(pMediaSample);
}

// Called when the source delivers us a sample. We go through a few checks to
// make sure the sample can be rendered. If we are running (streaming) then we
// have the sample scheduled with the reference clock, if we are not streaming
// then we have received an sample in paused mode so we can complete any state
// transition. On leaving this function everything will be unlocked so an app
// thread may get in and change our state to stopped (for example) in which
// case it will also signal the thread event so that our wait call is stopped

HRESULT CAMSyncObj::PrepareReceive(IMediaSample *pMediaSample)
{
    HRESULT hr = NOERROR;

    CAutoLock cLock(m_pFilterLock);
    CAutoLock cObjLock(&m_SyncObjLock);

    m_bInReceive = TRUE;

    if (m_State == State_Stopped)
    {
        m_bInReceive = FALSE;
        return E_FAIL;
    }

    ASSERT(m_State == State_Paused || m_State == State_Running);
//  ASSERT(IsFlushing() == FALSE);
    ASSERT(IsConnected() == TRUE);
    ASSERT(m_pMediaSample == NULL);

    // Return an error if we already have a sample waiting for rendering
    // source pins must serialise the Receive calls - we also check that
    // no data is being sent after the source signalled an end of stream
    if (m_pMediaSample || m_bEOS || m_bAbort)
    {
        Ready();
        m_bInReceive = FALSE;
        return E_UNEXPECTED;
    }

    // Store the media times from this sample
    if (m_pPosition)
        m_pPosition->RegisterMediaTime(pMediaSample);

    // Schedule the next sample if we are streaming
    if ((m_bStreaming == TRUE) && (ScheduleSample(pMediaSample) == FALSE))
    {
        ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));
        ASSERT(CancelNotification() == S_FALSE);
        m_bInReceive = FALSE;
        return VFW_E_SAMPLE_REJECTED;
    }

    // Store the sample end time for EC_COMPLETE handling
    // m_SignalTime = m_pPin->SampleProps()->tStop;

    // BEWARE we sometimes keep the sample even after returning the thread to
    // the source filter such as when we go into a stopped state (we keep it
    // to refresh the device with) so we must AddRef it to keep it safely. If
    // we start flushing the source thread is released and any sample waiting
    // will be released otherwise GetBuffer may never return (see BeginFlush)
    m_pMediaSample = pMediaSample;
    m_pMediaSample->AddRef();

    if (m_bStreaming == FALSE)
    {
        SetRepaintStatus(TRUE);
    }
    return NOERROR;
}

// Wait until the clock sets the timer event or we're otherwise signalled. We
// set an arbitrary timeout for this wait and if it fires then we display the
// current renderer state on the debugger. It will often fire if the filter's
// left paused in an application however it may also fire during stress tests
// if the synchronisation with application seeks and state changes is faulty

#define RENDER_TIMEOUT 10000

HRESULT CAMSyncObj::WaitForRenderTime()
{
    HANDLE WaitObjects[] = { m_ThreadSignal, m_RenderEvent };
    DWORD Result = WAIT_TIMEOUT;

    // Wait for either the time to arrive or for us to be stopped

    while (Result == WAIT_TIMEOUT)
    {
    Result = WaitForMultipleObjects(2,WaitObjects,FALSE,RENDER_TIMEOUT);

#ifdef DEBUG
    if (Result == WAIT_TIMEOUT) DisplayRendererState();
#endif

    }

    // We may have been awoken without the timer firing

    if (Result == WAIT_OBJECT_0)
    {
    return VFW_E_STATE_CHANGED;
    }

    SignalTimerFired();
    return NOERROR;
}


// Poll waiting for Receive to complete.  This really matters when
// Receive may set the palette and cause window messages
// The problem is that if we don't really wait for a renderer to
// stop processing we can deadlock waiting for a transform which
// is calling the renderer's Receive() method because the transform's
// Stop method doesn't know to process window messages to unblock
// the renderer's Receive processing
void CAMSyncObj::WaitForReceiveToComplete()
{
    for (;;)
    {
        if (!m_bInReceive)
        {
            break;
        }

        MSG msg;
        //  Receive all interthread sendmessages
        PeekMessage(&msg, NULL, WM_NULL, WM_NULL, PM_NOREMOVE);

        Sleep(1);
    }

    // If the wakebit for QS_POSTMESSAGE is set, the PeekMessage call
    // above just cleared the changebit which will cause some messaging
    // calls to block (waitMessage, MsgWaitFor...) now.
    // Post a dummy message to set the QS_POSTMESSAGE bit again
    if (HIWORD(GetQueueStatus(QS_POSTMESSAGE)) & QS_POSTMESSAGE)
    {
        //  Send dummy message
        PostThreadMessage(GetCurrentThreadId(), WM_NULL, 0, 0);
    }
}

void CALLBACK CAMSyncObj::RenderSampleOnMMThread(UINT uID, UINT uMsg, DWORD_PTR dwUser, DWORD_PTR dw1, DWORD_PTR dw2)
{
    CAMSyncObj *thisPtr = (CAMSyncObj*)dwUser;
    CAutoLock cObjLock(&thisPtr->m_SyncObjLock);

    //  Check this particular one is active (since timeKillEvent is broken)
    //  on Windows 9x
    if (thisPtr->m_pMediaSample2 && uID == thisPtr->m_MMTimerId) {
        // Deal with this sample
        if (thisPtr->m_bStreaming)
        {
            thisPtr->m_pPin->FlipOverlayToItself();
        }
        thisPtr->m_pMediaSample2->Release();
        thisPtr->m_pMediaSample2 = NULL;
    }

}

HRESULT CAMSyncObj::ScheduleSampleUsingMMThread(IMediaSample *pMediaSample)
{
    HRESULT hr = NOERROR, hrFailure = NOERROR;
    REFERENCE_TIME StartSample, EndSample;
    LONG lDelay = 0, lResolution = 1;

    // Is someone pulling our leg
    if (pMediaSample == NULL)
    {
        hr = E_FAIL;
        hrFailure = hr;
        goto CleanUp;
    }

    // Get the next sample due up for rendering.  If there aren't any ready
    // then GetNextSampleTimes returns an error.  If there is one to be done
    // then it succeeds and yields the sample times. If it is due now then
    // it returns S_OK other if it's to be done when due it returns S_FALSE
    hr = GetSampleTimes(pMediaSample, &StartSample, &EndSample);
    if (FAILED(hr))
    {
        hr = E_FAIL;
    }

    // If we don't have a reference clock then we cannot set up the advise
    // time so we simply set the event indicating an image to render. This
    // will cause us to run flat out without any timing or synchronisation
    if (SUCCEEDED(hr) && (hr != S_OK))
    {
        lDelay = (LONG)ConvertToMilliseconds(EndSample - StartSample);
        DbgLog((LOG_ERROR, 1, TEXT("lDelay = %d"), lDelay));
    }

    // if delay is less than or equal to zero or for some reason we couldnot compute the delay
    // just draw the sample immediately
    if (lDelay > 0)
    {
        CancelMMTimer();

        m_pMediaSample2 = pMediaSample;
        m_pMediaSample2->AddRef();

        {
            //  Make sure the timer id is set before the callback looks at it
            CAutoLock cObjLock(&m_SyncObjLock);
            m_MMTimerId = CompatibleTimeSetEvent(lDelay, lResolution, RenderSampleOnMMThread, (DWORD_PTR)this, TIME_ONESHOT);
        }
        if (!m_MMTimerId)
        {
            ClearPendingSample();
            hr = E_FAIL;
            hrFailure = hr;
            goto CleanUp;
        }
    }
    else if (m_bStreaming)
    {
        m_pPin->FlipOverlayToItself();
        goto CleanUp;
    }

CleanUp:
    return hrFailure;
}

// Responsible for setting up one shot advise links with the clock
// Return FALSE if the sample is to be dropped (not drawn at all)
// Return TRUE if the sample is to be drawn and in this case also
// arrange for m_RenderEvent to be set at the appropriate time
BOOL CAMSyncObj::ScheduleSample(IMediaSample *pMediaSample)
{
    REFERENCE_TIME StartSample, EndSample;

    // Is someone pulling our leg
    if (pMediaSample == NULL)
    {
        return FALSE;
    }

    // Get the next sample due up for rendering.  If there aren't any ready
    // then GetNextSampleTimes returns an error.  If there is one to be done
    // then it succeeds and yields the sample times. If it is due now then
    // it returns S_OK other if it's to be done when due it returns S_FALSE
    HRESULT hr = GetSampleTimes(pMediaSample, &StartSample, &EndSample);
    if (FAILED(hr))
    {
        return FALSE;
    }

    // Log the duration
    m_AvgDuration.NewFrame(EndSample - StartSample);

    // If we don't have a reference clock then we cannot set up the advise
    // time so we simply set the event indicating an image to render. This
    // will cause us to run flat out without any timing or synchronisation
    if (hr == S_OK)
    {
        EXECUTE_ASSERT(SetEvent((HANDLE) m_RenderEvent));
        return TRUE;
    }

    ASSERT(m_dwAdvise == 0);
    ASSERT((*m_ppClock));
    ASSERT(WAIT_TIMEOUT == WaitForSingleObject((HANDLE)m_RenderEvent,0));

    // Schedule immediately if we skipped a frame or the decoder
    // isn't decoding as fast as it needs to to keep up
    int AvgFrame = m_AvgDelivery.Avg();
    int AvgDuration = m_AvgDuration.Avg();
    DbgLog((LOG_TRACE, 4, TEXT("AvgFrame = %d, AvgDuration = %d"),
        AvgFrame / 10000, AvgDuration / 10000));
    int iEarly = 8 * 10000;
    if (S_OK == pMediaSample->IsDiscontinuity()) {
        iEarly = 60 * 10000;
    } else {
        if (AvgFrame > (AvgDuration + AvgDuration / 16)) {
            if (AvgFrame > (AvgDuration + AvgDuration / 2)) {
                iEarly = 60 * 10000;
            } else {
                iEarly = 40 * 10000;
            }
        }
    }

    // We do have a valid reference clock interface so we can ask it to
    // set an event when the image comes due for rendering. We pass in
    // the reference time we were told to start at and also the current
    // stream time which is the offset from the start reference time
#ifdef PERF
    Msr_Integer(m_idTimeStamp, (int)((StartSample)>>32));   // high order 32 bits
    Msr_Integer(m_idTimeStamp, (int)(StartSample));         // low order 32 bits
    Msr_Integer(m_idEarly,     (int)(iEarly));              // earliness
#endif

    hr = (*m_ppClock)->AdviseTime(
        (REFERENCE_TIME) m_tStart, StartSample - iEarly,
        (HEVENT)(HANDLE) m_RenderEvent, &m_dwAdvise);                       // Advise cookie
    if (SUCCEEDED(hr))
    {
        return TRUE;
    }

    // We could not schedule the next sample for rendering despite the fact
    // we have a valid sample here. This is a fair indication that either
    // the system clock is wrong or the time stamp for the sample is duff

    ASSERT(m_dwAdvise == 0);
    return FALSE;
}

// Retrieves the sample times for this samples (note the sample times are
// passed in by reference not value). We return S_FALSE to say schedule this
// sample according to the times on the sample. We also return S_OK in
// which case the object should simply render the sample data immediately
HRESULT CAMSyncObj::GetSampleTimes(IMediaSample *pMediaSample, REFERENCE_TIME *pStartTime,
                                   REFERENCE_TIME *pEndTime)
{
    ASSERT(m_dwAdvise == 0);
    ASSERT(pMediaSample);

    // If the stop time for this sample is before or the same as start time,
    // then just ignore it (release it) and schedule the next one in line
    // Source filters should always fill in the start and end times properly!
    if (SUCCEEDED(pMediaSample->GetTime(pStartTime, pEndTime)))
    {
        if (*pEndTime < *pStartTime)
        {
            return VFW_E_START_TIME_AFTER_END;
        }
    }
    else
    {
        // no time set in the sample... draw it now?
        return S_OK;
    }

    // Can't synchronise without a clock so we return S_OK which tells the
    // caller that the sample should be rendered immediately without going
    // through the overhead of setting a timer advise link with the clock
    if ((*m_ppClock) == NULL)
    {
        return S_OK;
    }

    PreparePerformanceData(pStartTime, pEndTime);
    return S_FALSE;
}

// Cancel our MM timer
void CAMSyncObj::CancelMMTimer()
{
    // kill the MMthread timer as well
    if (m_MMTimerId)
    {
        timeKillEvent(m_MMTimerId);
        m_MMTimerId = 0;
        CAutoLock cObjLock(&m_SyncObjLock);
        if (m_pMediaSample2)
        {
            // timeKillEvent is broken in Windows 9x - it doesn't wait
            // for the callback to complete
            m_pMediaSample2->Release();
            m_pMediaSample2 = NULL;
        }
    }
}

// Cancel any notification currently scheduled. This is called by the owning
// window object when it is told to stop streaming. If there is no timer link
// outstanding then calling this is benign otherwise we go ahead and cancel
// We must always reset the render event as the quality management code can
// signal immediate rendering by setting the event without setting an advise
// link. If we're subsequently stopped and run the first attempt to setup an
// advise link with the reference clock will find the event still signalled

HRESULT CAMSyncObj::CancelNotification()
{
    ASSERT(m_dwAdvise == 0 || *m_ppClock);
    DWORD_PTR dwAdvise = m_dwAdvise;

    CancelMMTimer();

    // Have we a live advise link

    if (m_dwAdvise) {
        (*m_ppClock)->Unadvise(m_dwAdvise);
        SignalTimerFired();
        ASSERT(m_dwAdvise == 0);
    }

    // Clear the event and return our status

    m_RenderEvent.Reset();
    return (dwAdvise ? S_OK : S_FALSE);
}

// Checks if there is a sample waiting at the renderer
BOOL CAMSyncObj::HaveCurrentSample()
{
    CAutoLock cObjLock(&m_SyncObjLock);
    return (m_pMediaSample == NULL ? FALSE : TRUE);
}

// we may no longer be able to draw the current image type properly, so we
// set the abort flag to be true
HRESULT CAMSyncObj::OnDisplayChange()
{
    HRESULT hr = NOERROR;

    DbgLog((LOG_TRACE, 5, TEXT("Entering CAMSyncObj::OnDisplayChange")));

    // Ignore if we are not connected yet
    CAutoLock cObjLock(&m_SyncObjLock);
    if (!m_pPin->IsConnected())
    {
        hr = S_FALSE;
        goto CleanUp;
    }

    m_bAbort = TRUE;
    ClearPendingSample();

CleanUp:
    DbgLog((LOG_TRACE, 5, TEXT("Leaving CAMSyncObj::OnDisplayChange")));
    return hr;
}

// If we're pausing and we have no samples we don't complete the transition
// to State_Paused and we return S_FALSE. However if the m_bAbort flag has
// been set then all samples are rejected so there is no point waiting for
// one. If we do have a sample then return NOERROR. We will only ever return
// VFW_S_STATE_INTERMEDIATE from GetState after being paused with no sample
// (calling GetState after either being stopped or Run will NOT return this)
HRESULT CAMSyncObj::CompleteStateChange(FILTER_STATE OldState)
{
    // Allow us to be paused when disconnected
    if (IsConnected() == FALSE)
    {
        Ready();
        return S_OK;
    }

    // Have we run off the end of stream
    if (IsEndOfStream() == TRUE)
    {
        Ready();
        return S_OK;
    }

    // Make sure we get fresh data after being stopped
    if (HaveCurrentSample() == TRUE)
    {
        if (OldState != State_Stopped)
        {
            Ready();
            return S_OK;
        }
    }
    NotReady();
    return S_FALSE;
}

// Returns the current sample waiting at the video renderer. We AddRef the
// sample before returning so that should it come due for rendering the
// person who called this method will hold the remaining reference count
// that will stop the sample being added back onto the allocator free list
IMediaSample *CAMSyncObj::GetCurrentSample()
{
    CAutoLock cObjLock(&m_SyncObjLock);
    if (m_pMediaSample)
    {
        m_pMediaSample->AddRef();
    }
    return m_pMediaSample;
}

void CAMSyncObj::SetCurrentSample(IMediaSample *pMediaSample)
{
    if (pMediaSample)
    {
        m_pMediaSample = pMediaSample;
        m_pMediaSample->AddRef();
    }
    else if (m_pMediaSample)
    {
        m_pMediaSample->Release();
        m_pMediaSample = NULL;
    }
}
// This is called when we stop or are inactivated to clear the pending sample
// We release the media sample interface so that they can be allocated to the
// source filter again, unless of course we are changing state to inactive in
// which case GetBuffer will return an error. We must also reset the current
// media sample to NULL so that we know we do not currently have an image
HRESULT CAMSyncObj::ClearPendingSample()
{
    CAutoLock cObjLock(&m_SyncObjLock);
    if (m_pMediaSample)
    {
        m_pMediaSample->Release();
        m_pMediaSample = NULL;
    }
    return NOERROR;
}


// This is called whenever we change states, we have a manual reset event that
// is signalled whenever we don't won't the source filter thread to wait in us
// (such as in a stopped state) and likewise is not signalled whenever it can
// wait (during paused and running) this function sets or resets the thread
// event. The event is used to stop source filter threads waiting in Receive
HRESULT CAMSyncObj::SourceThreadCanWait(BOOL bCanWait)
{
    if (bCanWait == TRUE)
    {
        m_ThreadSignal.Reset();
    }
    else
    {
        m_ThreadSignal.Set();
    }
    return NOERROR;
}

void CAMSyncObj::SetRepaintStatus(BOOL bRepaint)
{
    CAutoLock cObjLock(&m_SyncObjLock);
    m_bRepaintStatus = bRepaint;
}

// Signal an EC_REPAINT to the filter graph. This can be used to have data
// sent to us. For example when a video window is first displayed it may
// not have an image to display, at which point it signals EC_REPAINT. The
// filtergraph will either pause the graph if stopped or if already paused
// it will call put_CurrentPosition of the current position. Setting the
// current position to itself has the stream flushed and the image resent

#define RLOG(_x_) DbgLog((LOG_TRACE,1,TEXT(_x_)));

void CAMSyncObj::SendRepaint()
{
    CAutoLock cObjLock(&m_SyncObjLock);

    // We should not send repaint notifications when...
    //    - An end of stream has been notified
    //    - Our input pin is being flushed
    //    - The input pin is not connected
    //    - We have aborted a video playback
    //    - There is a repaint already sent

    if ((m_bAbort == FALSE) &&
        (IsConnected() == TRUE) &&
        (IsFlushing() == FALSE) &&
        (IsEndOfStream() == FALSE) &&
        (m_bRepaintStatus == TRUE))
    {
        m_pPin->EventNotify(EC_REPAINT,0,0);
        SetRepaintStatus(FALSE);
        RLOG("Sending repaint");
    }
}


// Called when the input pin receives an EndOfStream notification. If we have
// not got a sample, then notify EC_COMPLETE now. If we have samples, then set
// m_bEOS and check for this on completing samples. If we're waiting to pause
// then complete the transition to paused state by setting the state event
HRESULT CAMSyncObj::EndOfStream()
{
    HRESULT hr = NOERROR;

    CAutoLock cLock(m_pFilterLock);
    CAutoLock cObjLock(&m_SyncObjLock);

    // Ignore these calls if we are stopped
    if (m_State == State_Stopped)
    {
        return NOERROR;
    }

    // If we have a sample then wait for it to be rendered
    m_bEOS = TRUE;
    if (m_pMediaSample)
    {
        return NOERROR;
    }

    // If we are waiting for pause then we are now ready since we cannot now
    // carry on waiting for a sample to arrive since we are being told there
    // won't be any. This sets an event that the GetState function picks up
    Ready();

    // Only signal completion now if we are running otherwise queue it until
    // we do run in StartStreaming. This is used when we seek because a seek
    // causes a pause where early notification of completion is misleading
    if (m_bStreaming)
    {
        SendEndOfStream();
    }

    return hr;
}

// If we are at the end of the stream signal the filter graph but do not set
// the state flag back to FALSE. Once we drop off the end of the stream we
// leave the flag set (until a subsequent ResetEndOfStream). Each sample we
// get delivered will update m_SignalTime to be the last sample's end time.
// We must wait this long before signalling end of stream to the filtergraph

#define TIMEOUT_DELIVERYWAIT 50
#define TIMEOUT_RESOLUTION 10

HRESULT CAMSyncObj::SendEndOfStream()
{
    ASSERT(CritCheckIn(&m_SyncObjLock));
    if (m_bEOS == FALSE || m_bEOSDelivered || m_EndOfStreamTimer)
    {
        return NOERROR;
    }

    // If there is no clock then signal immediately
    if ((*m_ppClock) == NULL)
    {
        return NotifyEndOfStream();
    }

    // How long into the future is the delivery time
    REFERENCE_TIME Signal = m_tStart + m_SignalTime;
    REFERENCE_TIME CurrentTime;
    (*m_ppClock)->GetTime(&CurrentTime);
    LONG Delay = LONG((Signal - CurrentTime) / 10000);

    // Dump the timing information to the debugger
    NOTE1("Delay until end of stream delivery %d",Delay);
    NOTE1("Current %s",(LPCTSTR)CDisp((LONGLONG)CurrentTime));
    NOTE1("Signal %s",(LPCTSTR)CDisp((LONGLONG)Signal));

    // Wait for the delivery time to arrive
    if (Delay < TIMEOUT_DELIVERYWAIT)
    {
        return NotifyEndOfStream();
    }

    // Signal a timer callback on another worker thread
    m_EndOfStreamTimer = CompatibleTimeSetEvent((UINT) Delay,
                                                TIMEOUT_RESOLUTION, 
                                                EndOfStreamTimer,
                                                DWORD_PTR(this),
                                                TIME_ONESHOT);
    if (m_EndOfStreamTimer == 0)
    {
        return NotifyEndOfStream();
    }
    return NOERROR;
}

// uID is Timer identifier, uMsg is not cuurently used, dwUser is User
// information, dw1 and dw2 are windows reserved
void CALLBACK EndOfStreamTimer(UINT uID, UINT uMsg, DWORD_PTR dwUser,
                               DWORD_PTR dw1, DWORD_PTR dw2)
{
    CAMSyncObj *pAMSyncObj = (CAMSyncObj *) dwUser;
    NOTE1("EndOfStreamTimer called (%d)",uID);
    pAMSyncObj->TimerCallback();
}

//  Do the timer callback work
void CAMSyncObj::TimerCallback()
{
    //  Lock for synchronization (but don't hold this lock when calling
    //  timeKillEvent)
    CAutoLock cObjLock(&m_SyncObjLock);

    // See if we should signal end of stream now
    if (m_EndOfStreamTimer)
    {
        m_EndOfStreamTimer = 0;
        SendEndOfStream();
    }
}

// Signals EC_COMPLETE to the filtergraph manager
HRESULT CAMSyncObj::NotifyEndOfStream()
{
    CAutoLock cObjLock(&m_SyncObjLock);
    ASSERT(m_bEOS == TRUE);
    ASSERT(m_bEOSDelivered == FALSE);
    ASSERT(m_EndOfStreamTimer == 0);

    // Has the filter changed state
    if (m_bStreaming == FALSE)
    {
        ASSERT(m_EndOfStreamTimer == 0);
        return NOERROR;
    }

    // Reset the end of stream timer
    m_EndOfStreamTimer = 0;

    // If we've been using the IMediaPosition interface, set it's start
    // and end media "times" to the stop position by hand.  This ensures
    // that we actually get to the end, even if the MPEG guestimate has
    // been bad or if the quality management dropped the last few frames
    if (m_pPosition)
        m_pPosition->EOS();
    m_bEOSDelivered = TRUE;
    NOTE("Sending EC_COMPLETE...");
    m_pPin->EventNotify(EC_COMPLETE,S_OK,0);
    return NOERROR;
}


// Reset the end of stream flag, this is typically called when we transfer to
// stopped states since that resets the current position back to the start so
// we will receive more samples or another EndOfStream if there aren't any. We
// keep two separate flags one to say we have run off the end of the stream
// (this is the m_bEOS flag) and another to say we have delivered EC_COMPLETE
// to the filter graph. We need the latter otherwise we can end up sending an
// EC_COMPLETE every time the source changes state and calls our EndOfStream
HRESULT CAMSyncObj::ResetEndOfStream()
{
    ResetEndOfStreamTimer();
    CAutoLock cObjLock(&m_SyncObjLock);

    m_bEOS = FALSE;
    m_bEOSDelivered = FALSE;
    m_SignalTime = 0;

    return NOERROR;
}

// Kills any outstanding end of stream timer
void CAMSyncObj::ResetEndOfStreamTimer()
{
    ASSERT(CritCheckOut(&m_SyncObjLock));
    if (m_EndOfStreamTimer)
    {
        timeKillEvent(m_EndOfStreamTimer);
        m_EndOfStreamTimer = 0;
    }
}



#ifdef DEBUG
// Dump the current renderer state to the debug terminal. The hardest part of
// the renderer is the window where we unlock everything to wait for a clock
// to signal it is time to draw or for the application to cancel everything
// by stopping the filter. If we get things wrong we can leave the thread in
// WaitForRenderTime with no way for it to ever get out and we will deadlock

void CAMSyncObj::DisplayRendererState()
{
    TCHAR DebugString[128];
    wsprintf(DebugString,TEXT("\n\nTimed out in WaitForRenderTime\n"));
    OutputDebugString(DebugString);

    // No way should this be signalled at this point

    BOOL bSignalled = m_ThreadSignal.Check();
    wsprintf(DebugString,TEXT("Signal sanity check %d\n"),bSignalled);
    OutputDebugString(DebugString);

    // Now output the current renderer state variables

    wsprintf(DebugString,TEXT("Filter state %d\n"),m_State);
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("Abort flag %d\n"),m_bAbort);
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("Streaming flag %d\n"),m_bStreaming);
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("Clock advise link %d\n"),m_dwAdvise);
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("Current media sample %x\n"),m_pMediaSample);
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("EOS signalled %d\n"),m_bEOS);
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("EOS delivered %d\n"),m_bEOSDelivered);
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("Repaint status %d\n"),m_bRepaintStatus);
    OutputDebugString(DebugString);

    // Output the delayed end of stream timer information

    wsprintf(DebugString,TEXT("End of stream timer %x\n"),m_EndOfStreamTimer);
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("Deliver time %s\n"),CDisp((LONGLONG)m_SignalTime));
    OutputDebugString(DebugString);

    // Should never timeout during a flushing state

    BOOL bFlushing = IsFlushing();
    wsprintf(DebugString,TEXT("Flushing sanity check %d\n"),bFlushing);
    OutputDebugString(DebugString);

    // Display the time we were told to start at
    wsprintf(DebugString,TEXT("Last run time %s\n"),CDisp((LONGLONG)m_tStart.m_time));
    OutputDebugString(DebugString);

    // Have we got a reference clock
    if ((*m_ppClock) == NULL)
        return;

    // Get the current time from the wall clock

    CRefTime CurrentTime,StartTime,EndTime;
    (*m_ppClock)->GetTime((REFERENCE_TIME*) &CurrentTime);
    CRefTime Offset = CurrentTime - m_tStart;

    // Display the current time from the clock

    wsprintf(DebugString,TEXT("Clock time %s\n"),CDisp((LONGLONG)CurrentTime.m_time));
    OutputDebugString(DebugString);
    wsprintf(DebugString,TEXT("Time difference %dms\n"),Offset.Millisecs());
    OutputDebugString(DebugString);

    // Do we have a sample ready to render
    if (m_pMediaSample == NULL) return;

    m_pMediaSample->GetTime((REFERENCE_TIME*)&StartTime, (REFERENCE_TIME*)&EndTime);
    wsprintf(DebugString,TEXT("Next sample stream times (Start %d End %d ms)\n"),
        StartTime.Millisecs(),EndTime.Millisecs());
    OutputDebugString(DebugString);

    // Calculate how long it is until it is due for rendering
    CRefTime Wait = (m_tStart + StartTime) - CurrentTime;
    wsprintf(DebugString,TEXT("Wait required %d ms\n"),Wait.Millisecs());
    OutputDebugString(DebugString);
}
#endif


// update the statistics:
// m_iTotAcc, m_iSumSqAcc, m_iSumSqFrameTime, m_iSumFrameTime, m_cFramesDrawn
// Note that because the properties page reports using these variables,
// 1. We need to be inside a critical section
// 2. They must all be updated together.  Updating the sums here and the count
// elsewhere can result in imaginary jitter (i.e. attempts to find square roots
// of negative numbers) in the property page code.

void CAMSyncObj::RecordFrameLateness(int trLate, int trFrame)
{
    // Record how timely we are.
    int tLate = trLate/10000;

    // This is a hack - we can get frames that are ridiculously late
    // especially (at start-up) and they sod up the statistics.
    // So ignore things that are more than 1 sec off.
    if (tLate>1000 || tLate<-1000) {
        if (m_cFramesDrawn<=1) {
            tLate = 0;
        } else if (tLate>0) {
            tLate = 1000;
        } else {
            tLate = -1000;
        }
    }
    // The very first frame often has a bogus time, so I'm just
    // not going to count it into the statistics.   ???
    if (m_cFramesDrawn>1) {
        m_iTotAcc += tLate;
        m_iSumSqAcc += (tLate*tLate);
    }

    // calculate inter-frame time.  Doesn't make sense for first frame
    // second frame suffers from bogus first frame stamp.
    if (m_cFramesDrawn>2) {
        int tFrame = trFrame/10000;    // convert to mSec else it overflows
        // This is a hack.  It can overflow anyway (a pause can cause
        // a very long inter-frame time) and it overflows at 2**31/10**7
        // or about 215 seconds i.e. 3min 35sec
        if (tFrame>1000||tFrame<0) tFrame = 1000;
        m_iSumSqFrameTime += tFrame*tFrame;
        ASSERT(m_iSumSqFrameTime>=0);
        m_iSumFrameTime += tFrame;
    }
    ++m_cFramesDrawn;

} // RecordFrameLateness


// Implementation of IQualProp interface needed to support the property page
// This is how the property page gets the data out of the scheduler. We are
// passed into the constructor the owning object in the COM sense, this will
// either be the video renderer or an external IUnknown if we're aggregated.
// We initialise our CUnknown base class with this interface pointer. Then
// all we have to do is to override NonDelegatingQueryInterface to expose
// our IQualProp interface. The AddRef and Release are handled automatically
// by the base class and will be passed on to the appropriate outer object

HRESULT CAMSyncObj::get_FramesDroppedInRenderer(int *pcFramesDropped)
{
    CheckPointer(pcFramesDropped,E_POINTER);
    CAutoLock cObjLock(&m_SyncObjLock);
    *pcFramesDropped = m_cFramesDropped;
    return NOERROR;
} // get_FramesDroppedInRenderer


// Set *pcFramesDrawn to the number of frames drawn since
// streaming started.

HRESULT CAMSyncObj::get_FramesDrawn( int *pcFramesDrawn)
{
    CheckPointer(pcFramesDrawn,E_POINTER);
    CAutoLock cObjLock(&m_SyncObjLock);
    *pcFramesDrawn = m_cFramesDrawn;
    return NOERROR;
} // get_FramesDrawn


// Set iAvgFrameRate to the frames per hundred secs since
// streaming started.  0 otherwise.

HRESULT CAMSyncObj::get_AvgFrameRate( int *piAvgFrameRate)
{
    CheckPointer(piAvgFrameRate,E_POINTER);
    CAutoLock cObjLock(&m_SyncObjLock);

    int t;
    if (m_bStreaming) {
	t = timeGetTime()-m_tStreamingStart;
    } else {
	t = m_tStreamingStart;
    }

    if (t<=0) {
	*piAvgFrameRate = 0;
	ASSERT(m_cFramesDrawn == 0);
    } else {
	// i is frames per hundred seconds
	*piAvgFrameRate = MulDiv(100000, m_cFramesDrawn, t);
    }
    return NOERROR;
} // get_AvgFrameRate


// Set *piAvg to the average sync offset since streaming started
// in mSec.  The sync offset is the time in mSec between when the frame
// should have been drawn and when the frame was actually drawn.

HRESULT CAMSyncObj::get_AvgSyncOffset( int *piAvg)
{
    CheckPointer(piAvg,E_POINTER);
    CAutoLock cObjLock(&m_SyncObjLock);

    if (NULL==*m_ppClock) {
	*piAvg = 0;
	return NOERROR;
    }

    // Note that we didn't gather the stats on the first frame
    // so we use m_cFramesDrawn-1 here
    if (m_cFramesDrawn<=1) {
	*piAvg = 0;
    } else {
	*piAvg = (int)(m_iTotAcc / (m_cFramesDrawn-1));
    }
    return NOERROR;
} // get_AvgSyncOffset


// To avoid dragging in the maths library - a cheap
// approximate integer square root.
// We do this by getting a starting guess which is between 1
// and 2 times too large, followed by THREE iterations of
// Newton Raphson.  (That will give accuracy to the nearest mSec
// for the range in question - roughly 0..1000)
//
// It would be faster to use a linear interpolation and ONE NR, but
// who cares.  If anyone does - the best linear interpolation is
// to approximates sqrt(x) by
// y = x * (sqrt(2)-1) + 1 - 1/sqrt(2) + 1/(8*(sqrt(2)-1))
// 0r y = x*0.41421 + 0.59467
// This minimises the maximal error in the range in question.
// (error is about +0.008883 and then one NR will give error .0000something
// (Of course these are integers, so you can't just multiply by 0.41421
// you'd have to do some sort of MulDiv).
// Anyone wanna check my maths?  (This is only for a property display!)

static int isqrt(int x)
{
    int s = 1;
    // Make s an initial guess for sqrt(x)
    if (x > 0x40000000) {
       s = 0x8000;     // prevent any conceivable closed loop
    } else {
	while (s*s<x) {    // loop cannot possible go more than 31 times
	    s = 2*s;       // normally it goes about 6 times
	}
	// Three NR iterations.
	if (x==0) {
	   s= 0; // Wouldn't it be tragic to divide by zero whenever our
		 // accuracy was perfect!
	} else {
	    s = (s*s+x)/(2*s);
	    if (s>=0) s = (s*s+x)/(2*s);
	    if (s>=0) s = (s*s+x)/(2*s);
	}
    }
    return s;
}

//
//  Do estimates for standard deviations for per-frame
//  statistics
//
HRESULT CAMSyncObj::GetStdDev(
    int nSamples,
    int *piResult,
    LONGLONG llSumSq,
    LONGLONG iTot
)
{
    CheckPointer(piResult,E_POINTER);
    CAutoLock cObjLock(&m_SyncObjLock);

    if (NULL==*m_ppClock) {
	*piResult = 0;
	return NOERROR;
    }

    // If S is the Sum of the Squares of observations and
    //    T the Total (i.e. sum) of the observations and there were
    //    N observations, then an estimate of the standard deviation is
    //      sqrt( (S - T**2/N) / (N-1) )

    if (nSamples<=1) {
	*piResult = 0;
    } else {
	LONGLONG x;
	// First frames have bogus stamps, so we get no stats for them
	// So we need 2 frames to get 1 datum, so N is cFramesDrawn-1

	// so we use m_cFramesDrawn-1 here
	x = llSumSq - llMulDiv(iTot, iTot, nSamples, 0);
	x = x / (nSamples-1);
	ASSERT(x>=0);
	*piResult = isqrt((LONG)x);
    }
    return NOERROR;
}

// Set *piDev to the standard deviation in mSec of the sync offset
// of each frame since streaming started.

HRESULT CAMSyncObj::get_DevSyncOffset( int *piDev)
{
    // First frames have bogus stamps, so we get no stats for them
    // So we need 2 frames to get 1 datum, so N is cFramesDrawn-1
    return GetStdDev(m_cFramesDrawn - 1,
		     piDev,
		     m_iSumSqAcc,
		     m_iTotAcc);
} // get_DevSyncOffset


// Set *piJitter to the standard deviation in mSec of the inter-frame time
// of frames since streaming started.

HRESULT CAMSyncObj::get_Jitter( int *piJitter)
{
    // First frames have bogus stamps, so we get no stats for them
    // So second frame gives bogus inter-frame time
    // So we need 3 frames to get 1 datum, so N is cFramesDrawn-2
    return GetStdDev(m_cFramesDrawn - 2,
		     piJitter,
		     m_iSumSqFrameTime,
		     m_iSumFrameTime);
} // get_Jitter


// Reset all times controlling streaming.

HRESULT CAMSyncObj::ResetStreamingTimes()
{
    m_trLastDraw = -1000;     // set up as first frame since ages (1 sec) ago
    m_tStreamingStart = timeGetTime();
    m_cFramesDrawn = 0;
    m_cFramesDropped = 0;
    m_iTotAcc = 0;
    m_iSumSqAcc = 0;
    m_iSumSqFrameTime = 0;
    m_trFrame = 0;          // hygeine - not really needed
    m_trLate = 0;           // hygeine - not really needed
    m_iSumFrameTime = 0;

    return NOERROR;
} // ResetStreamingTimes


// Reset all times controlling streaming. Note that we're now streaming. We
// don't need to set the rendering event to have the source filter released
// as it is done during the Run processing. When we are run we immediately
// release the source filter thread and draw any image waiting (that image
// may already have been drawn once as a poster frame while we were paused)

HRESULT CAMSyncObj::OnStartStreaming()
{
    ResetStreamingTimes();
    return NOERROR;
} // OnStartStreaming


// Called at end of streaming.  Fixes times for property page report

HRESULT CAMSyncObj::OnStopStreaming()
{
    m_tStreamingStart = timeGetTime()-m_tStreamingStart;
    return NOERROR;
} // OnStopStreaming


// Called just before we start drawing.  All we do is to get the current clock
// time (from the system) and return.  We have to store the start render time
// in a member variable because it isn't used until we complete the drawing
// The rest is just performance logging.

void CAMSyncObj::OnRenderStart(IMediaSample *pMediaSample)
{
    RecordFrameLateness(m_trLate, m_trFrame);

#ifdef PERF
    REFERENCE_TIME trStart, trEnd, m_trRenderStart;
    pMediaSample->GetTime(&trStart, &trEnd);

    (*m_ppClock)->GetTime(&m_trRenderStart);
    Msr_Integer(0, (int)m_trRenderStart);
    REFERENCE_TIME trStream;
    trStream = m_trRenderStart-m_tStart;     // convert reftime to stream time
    Msr_Integer(0,(int)trStream);

    const int trLate = (int)(trStream - trStart);
    Msr_Integer(m_idLate, trLate/10000);  // dump in mSec
#endif

} // OnRenderStart


// Called directly after drawing an image.  We calculate the time spent in the
// drawing code and if this doesn't appear to have any odd looking spikes in
// it then we add it to the current average draw time.  Measurement spikes may
// occur if the drawing thread is interrupted and switched to somewhere else.

void CAMSyncObj::OnRenderEnd(IMediaSample *pMediaSample)
{
} // OnRenderEnd


//  Helper function for clamping time differences
int inline TimeDiff(REFERENCE_TIME rt)
{
    if (rt < - (50 * UNITS)) {
        return -(50 * UNITS);
    } else
    if (rt > 50 * UNITS) {
        return 50 * UNITS;
    } else return (int)rt;
}


// We are called with a valid IMediaSample image to compute sample time
// and lateness.  There must be a reference clock in operation.

void CAMSyncObj::PreparePerformanceData(REFERENCE_TIME *ptrStart, REFERENCE_TIME *ptrEnd)
{

    // Don't call us unless there's a clock interface to synchronise with
    ASSERT(*m_ppClock);

    // Get reference times (current and late)
    REFERENCE_TIME trRealStream;    // the real time now expressed as stream time.
    (*m_ppClock)->GetTime(&trRealStream);
    trRealStream -= m_tStart;       // convert to stream time (this is a reftime)

    // trTrueLate>0 -- frame is late
    // trTrueLate<0 -- frame is early
    int trTrueLate = TimeDiff(trRealStream - *ptrStart);

    int trFrame;
    {
	REFERENCE_TIME tr = trRealStream - m_trLastDraw; // Cd be large - 4 min pause!
	if (tr>10000000) {
	    tr = 10000000;          // 1 second - arbitrarily.
	}
	trFrame = int(tr);
    }

    if (trTrueLate<=0) {
        // We are going to wait
        trFrame = TimeDiff(*ptrStart-m_trLastDraw);
        m_trLastDraw = *ptrStart;
    } else {
        // trFrame is already = trRealStream-m_trLastDraw;
        m_trLastDraw = trRealStream;
    }

    m_trLate = trTrueLate;
    m_trFrame = trFrame;

} // PreparePerformanceData
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmixer\vpobj.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;
#ifndef __VP_OBJECT__
#define __VP_OBJECT__

#include <vpinfo.h>


/* Temporary definitions while waiting DX5A integration
*/
#ifndef DDVPCREATE_VBIONLY
#define DDVPCREATE_VBIONLY                      0x00000001l
#endif

#ifndef DDVPCREATE_VIDEOONLY
#define DDVPCREATE_VIDEOONLY                    0x00000002l
#endif

// NOTE these two flags below have the same value but thats ok
#ifndef DDCAPS2_CANFLIPODDEVEN
// Driver supports bob using software without using a video port
#define DDCAPS2_CANFLIPODDEVEN                  0x00002000l
#endif

#ifndef DDVPCAPS_VBIANDVIDEOINDEPENDENT
 // Indicates that the VBI and video  can  be controlled by an
 // independent processes.
#define DDVPCAPS_VBIANDVIDEOINDEPENDENT         0x00002000l
#endif

#ifndef DDVPD_PREFERREDAUTOFLIP
// Optimal number of autoflippable surfaces for hardware
#define DDVPD_PREFERREDAUTOFLIP 0x00000080l
#endif

#define EC_OVMIXER_REDRAW_ALL 0x100
#define EC_OVMIXER_VP_CONNECTED 0x101


typedef struct _VPDRAWFLAGS
{
    BOOL bUsingColorKey;
    BOOL bDoUpdateVideoPort;
    BOOL bDoTryAutoFlipping;
    BOOL bDoTryDecimation;
} VPDRAWFLAGS, *LPVPDRAWFLAGS;

typedef struct _WININFO
{
    POINT TopLeftPoint;
    RECT SrcRect;
    RECT DestRect;
    RECT SrcClipRect;
    RECT DestClipRect;
    HRGN hClipRgn;
} WININFO, *LPWININFO;

// this in a way defines the error margin
#define EPSILON 0.0001

#ifdef DEBUG
    #define DbgLogRectMacro(_x_) DbgLogRect _x_
#else
    #define DbgLogRectMacro(_x_)
#endif

extern double myfloor(double dNumber, double dEpsilon);
extern double myfloor(double fNumber);
extern double myceil(double dNumber, double dEpsilon);
extern double myceil(double fNumber);
extern RECT CalcSubRect(const RECT *pRect, const RECT *pRelativeRect);
extern void SetRect(DRECT *prdRect, LONG lLeft, LONG lTop, LONG lRight, LONG lBottom);
extern RECT MakeRect(DRECT rdRect);
extern void DbgLogRect(DWORD dwLevel, LPCTSTR pszDebugString, const DRECT *prdRect);
extern void DbgLogRect(DWORD dwLevel, LPCTSTR pszDebugString, const RECT *prRect);
extern double GetWidth(const DRECT *prdRect);
extern double GetHeight(const DRECT *prdRect);
extern BOOL IsRectEmpty(const DRECT *prdRect);
extern BOOL IntersectRect(DRECT *prdIRect, const DRECT *prdRect1, const DRECT *prdRect2);
void ScaleRect(DRECT *prdRect, double dOrigX, double dOrigY, double dNewX, double dNewY);
void ScaleRect(RECT *prRect, double dOrigX, double dOrigY, double dNewX, double dNewY);
extern double TransformRect(DRECT *pRect, double dPictAspectRatio, AM_TRANSFORM transform);
extern HRESULT CalcSrcClipRect(const DRECT *prdSrcRect, DRECT *prdSrcClipRect, const DRECT *prdDestRect, DRECT *prdDestClipRect);
extern HRESULT CalcSrcClipRect(const RECT *prSrcRect, RECT *prSrcClipRect, const RECT *prDestRect, RECT *prDestClipRect, BOOL bMaintainRatio = FALSE);
extern HRESULT AlignOverlaySrcDestRects(LPDDCAPS pddDirectCaps, RECT *pSrcRect, RECT *pDestRect);

extern DWORD DDColorMatch(IDirectDrawSurface *pdds, COLORREF rgb, HRESULT& hr);
extern DWORD DDColorMatchOffscreen(IDirectDraw *pdds, COLORREF rgb, HRESULT& hr);

extern AM_MEDIA_TYPE * WINAPI AllocVideoMediaType(const AM_MEDIA_TYPE * pmtSource, GUID formattype);
extern AM_MEDIA_TYPE *ConvertSurfaceDescToMediaType(const LPDDSURFACEDESC pSurfaceDesc, BOOL bInvertSize, CMediaType cMediaType);
extern BITMAPINFOHEADER *GetbmiHeader(const CMediaType *pMediaType);
extern const DWORD *GetBitMasks(const CMediaType *pMediaType);
extern BYTE* GetColorInfo(const CMediaType *pMediaType);
extern HRESULT IsPalettised(const CMediaType *pMediaType, BOOL *pPalettised);
extern HRESULT GetPictAspectRatio(const CMediaType *pMediaType, DWORD *pdwPictAspectRatioX, DWORD *pdwPictAspectRatioY);
extern HRESULT GetSrcRectFromMediaType(const CMediaType *pMediaType, RECT *pRect);
extern HRESULT GetDestRectFromMediaType(const CMediaType *pMediaType, RECT *pRect);
extern HRESULT GetScaleCropRectsFromMediaType(const CMediaType *pMediaType, DRECT *prdScaledRect, DRECT *prdCroppedRect);
extern HRESULT GetInterlaceFlagsFromMediaType(const CMediaType *pMediaType, DWORD *pdwInterlaceFlags);
extern BOOL DisplayingFields(DWORD dwInterlacedFlags);
extern BOOL NeedToFlipOddEven(DWORD dwInterlacedFlags, DWORD dwTypeSpecificFlags, DWORD *pdwFlipFlag);
extern DWORD GetUpdateOverlayFlags(DWORD dwInterlaceFlags, DWORD dwTypeSpecificFlags);
extern BOOL CheckTypeSpecificFlags(DWORD dwInterlaceFlags, DWORD dwTypeSpecificFlags);
extern HRESULT GetTypeSpecificFlagsFromMediaSample(IMediaSample *pSample, DWORD *pdwTypeSpecificFlags);
extern HRESULT ComputeSurfaceRefCount(LPDIRECTDRAWSURFACE pDDrawSurface);
extern HRESULT PaintDDrawSurfaceBlack(LPDIRECTDRAWSURFACE pDDrawSurface);
extern HRESULT CreateDIB(LONG lSize, BITMAPINFO *pBitMapInfo, DIBDATA *pDibData);
extern HRESULT DeleteDIB(DIBDATA *pDibData);
extern void FastDIBBlt(DIBDATA *pDibData, HDC hTargetDC, HDC hSourceDC, RECT *prcTarget, RECT *prcSource);
extern void SlowDIBBlt(BYTE *pDibBits, BITMAPINFOHEADER *pHeader, HDC hTargetDC, RECT *prcTarget, RECT *prcSource);

DECLARE_INTERFACE_(IVPObject, IUnknown)
{
    STDMETHOD (GetDirectDrawSurface)(THIS_
                                     LPDIRECTDRAWSURFACE *ppDirectDrawSurface
                                    ) PURE;

    STDMETHOD (SetObjectLock)(THIS_
                              CCritSec *pMainObjLock
                             ) PURE;

    STDMETHOD (SetMediaType)(THIS_
                             const CMediaType* pmt
                            ) PURE;


    STDMETHOD (CheckMediaType)(THIS_
                               const CMediaType* pmt
                              ) PURE;


    STDMETHOD (CompleteConnect)(THIS_
                                IPin *pReceivePin,
                                BOOL bRenegotiating = FALSE
                               ) PURE;

    STDMETHOD (BreakConnect)(THIS_
                             BOOL bRenegotiating = FALSE
                            ) PURE;

    STDMETHOD (Active)(THIS_
                      ) PURE;

    STDMETHOD (Inactive)(THIS_
                        ) PURE;

    STDMETHOD (Run)(THIS_
                    REFERENCE_TIME tStart
                   ) PURE;

    STDMETHOD (RunToPause)(THIS_
                          ) PURE;

    STDMETHOD (OnClipChange)(THIS_
                             LPWININFO pWinInfo
                            ) PURE;

    STDMETHOD (CurrentMediaType)(THIS_
                                    AM_MEDIA_TYPE *pmt
                                   ) PURE;

    STDMETHOD (GetRectangles) (THIS_ RECT *prcSource, RECT *prcDest) PURE;
};


DECLARE_INTERFACE_(IVPControl, IUnknown)
{
    STDMETHOD (EventNotify)(THIS_
                            long lEventCode,
                            long lEventParam1,
                            long lEventParam2
                           ) PURE;

    STDMETHOD_(LPDIRECTDRAW, GetDirectDraw) (THIS_
                                            ) PURE;

    STDMETHOD_(LPDIRECTDRAWSURFACE, GetPrimarySurface) (THIS_
                                                       ) PURE;

    STDMETHOD_(LPDDCAPS, GetHardwareCaps) (THIS_
                                          ) PURE;

    STDMETHOD(CallUpdateOverlay)(THIS_
                              IDirectDrawSurface *pSurface,
                              LPRECT prcSrc,
                              LPDIRECTDRAWSURFACE pDestSurface,
                              LPRECT prcDest,
                              DWORD dwFlags) PURE;

    STDMETHOD(GetCaptureInfo)(THIS_
                             BOOL *lpCapturing,
                             DWORD *lpdwWidth,
                             DWORD *lpdwHeight,
                             BOOL *lpInterleaved) PURE;

    STDMETHOD(GetVideoDecimation)(THIS_
                                  IDecimateVideoImage** lplpDVI) PURE;

    STDMETHOD(GetDecimationUsage)(THIS_
                                  DECIMATION_USAGE *lpdwUsage) PURE;

    STDMETHOD(CropSourceRect)(THIS_
                              LPWININFO pWinInfo,
                              DWORD dwMinZoomFactorX,
                              DWORD dwMinZoomFactorY) PURE;
};


class CAMVideoPort : public CUnknown, public IVPNotify2, public IVPObject, public IVPInfo
{

public:
    static CUnknown* CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);
    CAMVideoPort(LPUNKNOWN pUnk, HRESULT *phr);
    ~CAMVideoPort();

    DECLARE_IUNKNOWN

    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** ppv);

    // IVPObject Interface to the outside world
    STDMETHODIMP GetDirectDrawSurface(LPDIRECTDRAWSURFACE *ppDirectDrawSurface);
    STDMETHODIMP SetObjectLock(CCritSec *pMainObjLock);
    STDMETHODIMP SetMediaType(const CMediaType* pmt);
    STDMETHODIMP CheckMediaType(const CMediaType* pmt);
    STDMETHODIMP CompleteConnect(IPin *pReceivePin, BOOL bRenegotiating = FALSE);
    STDMETHODIMP BreakConnect(BOOL bRenegotiating = FALSE);
    STDMETHODIMP Active();
    STDMETHODIMP Inactive();
    STDMETHODIMP Run(REFERENCE_TIME tStart);
    STDMETHODIMP RunToPause();
    STDMETHODIMP OnClipChange(LPWININFO pWinInfo);
    STDMETHODIMP CurrentMediaType(AM_MEDIA_TYPE *pmt);
    STDMETHODIMP GetRectangles(RECT *prcSource, RECT *prcDest);

    // Methods belonging to IVPInfo
    STDMETHODIMP GetCropState(AMVP_CROP_STATE *pCropState);
    STDMETHODIMP GetPixelsPerSecond(DWORD* pPixelPerSec);
    STDMETHODIMP GetVPInfo(DDVIDEOPORTINFO* pVPInfo);
    STDMETHODIMP GetVPBandwidth(DDVIDEOPORTBANDWIDTH* pVPBandwidth);
    STDMETHODIMP GetVPCaps(DDVIDEOPORTCAPS* pVPCaps);
    STDMETHODIMP GetVPDataInfo(AMVPDATAINFO* pVPDataInfo);
    STDMETHODIMP GetVPInputFormat(LPDDPIXELFORMAT* pVPFormat);
    STDMETHODIMP GetVPOutputFormat(LPDDPIXELFORMAT* pVPFormat);

    // IVPNotify functions here
    STDMETHODIMP RenegotiateVPParameters();
    STDMETHODIMP SetDeinterlaceMode(AMVP_MODE mode);
    STDMETHODIMP GetDeinterlaceMode(AMVP_MODE *pMode);

    // functions added in IVPNotify2 here
    STDMETHODIMP SetVPSyncMaster(BOOL bVPSyncMaster);
    STDMETHODIMP GetVPSyncMaster(BOOL *pbVPSyncMaster);

private:
    // used to initialize all class member variables.
    // It is called from the contructor as well as CompleteConnect
    void InitVariables();


    // All these functions are called from within CompleteConnect
    HRESULT NegotiateConnectionParamaters();
    static HRESULT CALLBACK EnumCallback (LPDDVIDEOPORTCAPS lpCaps, LPVOID lpContext);
    HRESULT GetDataParameters();
    HRESULT NegotiatePixelFormat();
    BOOL    EqualPixelFormats(LPDDPIXELFORMAT lpFormat1, LPDDPIXELFORMAT lpFormat2);
    HRESULT GetBestFormat(DWORD dwNumInputFormats, LPDDPIXELFORMAT lpddInputFormats,
    BOOL    bGetBestBandwidth, LPDWORD lpdwBestEntry, LPDDPIXELFORMAT lpddBestOutputFormat);
    HRESULT CreateVideoPort();
    HRESULT DetermineCroppingRestrictions();
    HRESULT CreateVPOverlay(BOOL bTryDoubleHeight, DWORD dwMaxBuffers, BOOL bPreferBuffers);
    HRESULT SetSurfaceParameters();
    HRESULT InitializeVideoPortInfo();
    HRESULT CheckDDrawVPCaps();
    HRESULT DetermineModeRestrictions();
    HRESULT SetDDrawKernelHandles();

    // All these functions are called fro within OnClipChange
    HRESULT DrawImage(LPWININFO pWinInfo, AMVP_MODE mode, LPVPDRAWFLAGS pvpDrawFlags);
    HRESULT SetUpMode(LPWININFO pWinInfo, int mode);


    // Decimation functions
    BOOL
    ApplyDecimation(
        LPWININFO pWinInfo,
        BOOL bColorKeying,
        BOOL bYInterpolating
        );

    HRESULT
    TryVideoPortDecimation(
        LPWININFO pWinInfo,
        DWORD dwMinZoomFactorX,
        DWORD dwMinZoomFactorY,
        BOOL* lpUpdateRequired
        );

    HRESULT
    TryDecoderDecimation(
        LPWININFO pWinInfo
        );

    void
    GetMinZoomFactors(
        LPWININFO pWinInfo,
        BOOL bColorKeying,
        BOOL bYInterpolating,
        LPDWORD lpMinX, LPDWORD lpMinY);


    BOOL
    Running();

    BOOL
    BeyondOverlayCaps(
        DWORD ScaleFactor,
        DWORD dwMinZoomFactorX,
        DWORD dwMinZoomFactorY
        );

    BOOL
    ResetVPDecimationIfSet();

    void
    ResetDecoderDecimationIfSet();

    void CropSourceSize(LPWININFO pWinInfo, DWORD dwMinZoomFactorX, DWORD dwMinZoomFactorY);
    BOOL AdjustSourceSize(LPWININFO pWinInfo, DWORD dwMinZoomFactorX, DWORD dwMinZoomFactorY);
    BOOL AdjustSourceSizeForCapture(LPWININFO pWinInfo, DWORD dwMinZoomFactorX, DWORD dwMinZoomFactorY);
    BOOL AdjustSourceSizeWhenStopped(LPWININFO pWinInfo,  DWORD dwMinZoomFactorX, DWORD dwMinZoomFactorY);
    BOOL CheckVideoPortAlignment(DWORD dwWidth);

    BOOL
    VideoPortDecimationBackend(
        LPWININFO pWinInfo,
        DWORD dwDexNumX,
        DWORD dwDexDenX,
        DWORD dwDexNumY,
        DWORD dwDexDenY
        );

public:
    HRESULT StopUsingVideoPort();
    HRESULT RecreateVideoPort();

private:

    // Critical sections
    CCritSec                *m_pMainObjLock;                // Lock given by controlling object
    CCritSec                m_VPObjLock;                    // VP object wide lock
    IVPControl              *m_pIVPControl;

    // window information related stuff
    BOOL                    m_bStoredWinInfoSet;
    WININFO                 m_StoredWinInfo;

    // image dimensions
    DWORD                   m_lImageWidth;
    DWORD                   m_lImageHeight;
    DWORD                   m_lDecoderImageWidth;
    DWORD                   m_lDecoderImageHeight;

    // info relating to capturing
    BOOL                    m_fCapturing;
    BOOL                    m_fCaptureInterleaved;
    DWORD                   m_cxCapture;
    DWORD                   m_cyCapture;

    // overlay surface related stuff
    LPDIRECTDRAWSURFACE     m_pOverlaySurface;
    DWORD                   m_dwBackBufferCount;
    DWORD                   m_dwOverlaySurfaceWidth;
    DWORD                   m_dwOverlaySurfaceHeight;
    DWORD                   m_dwOverlayFlags;
    BOOL                    m_bOverlayHidden;

    // vp variables to store flags, current state etc
    IVPConfig               *m_pIVPConfig;
    BOOL                    m_bStart;

    BOOL                    m_bConnected;

    AMVP_STATE              m_VPState;
    AMVP_MODE               m_CurrentMode;
    AMVP_MODE               m_StoredMode;
    AMVP_CROP_STATE         m_CropState;
    DWORD                   m_dwPixelsPerSecond;
    BOOL                    m_bVSInterlaced;
    BOOL                    m_bGarbageLine;
    BOOL                    m_bVPSyncMaster;

    // vp data structures
    DWORD                   m_dwVideoPortId;
    LPDDVIDEOPORTCONTAINER  m_pDVP;
    LPDIRECTDRAWVIDEOPORT   m_pVideoPort;
    DDVIDEOPORTINFO         m_svpInfo;
    DDVIDEOPORTBANDWIDTH    m_sBandwidth;
    DDVIDEOPORTCAPS         m_vpCaps;
    DDVIDEOPORTCONNECT      m_ddConnectInfo;
    AMVPDATAINFO            m_VPDataInfo;

    // All the pixel formats (Video)
    LPDDPIXELFORMAT         m_pddVPInputVideoFormat;
    LPDDPIXELFORMAT         m_pddVPOutputVideoFormat;

    // can we support the different modes
    BOOL                    m_bCanWeave;
    BOOL                    m_bCanBobInterleaved;
    BOOL                    m_bCanBobNonInterleaved;
    BOOL                    m_bCanSkipOdd;
    BOOL                    m_bCanSkipEven;
    BOOL                    m_bCantInterleaveHalfline;

    // decimation parameters
    enum DECIMATE_MODE {DECIMATE_NONE, DECIMATE_ARB, DECIMATE_BIN, DECIMATE_INC};
#if defined(DEBUG)
    // BOOL CheckVideoPortScaler();
    BOOL CheckVideoPortScaler(
        DECIMATE_MODE DecimationMode,
        DWORD ImageSize,
        DWORD PreScaleSize,
        ULONG ulDeciStep);
#endif
    DECIMATE_MODE           m_DecimationModeX;
    DWORD                   m_ulDeciStepX;
    DWORD                   m_dwDeciNumX;
    DWORD                   m_dwDeciDenX;

    DECIMATE_MODE           m_DecimationModeY;
    DWORD                   m_ulDeciStepY;
    DWORD                   m_dwDeciNumY;
    DWORD                   m_dwDeciDenY;

    BOOL                    m_bVPDecimating;
    BOOL                    m_bDecimating;
    LONG                    m_lWidth;
    LONG                    m_lHeight;

    // variables to store the current aspect ratio
    DWORD                   m_dwPictAspectRatioX;
    DWORD                   m_dwPictAspectRatioY;


    RECT                    m_rcSource;
    RECT                    m_rcDest;
};

DWORD MulABC_DivDE(DWORD A, DWORD B, DWORD C, DWORD D, DWORD E);

#endif //__VP_OBJECT__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmprop\ovmprop.h ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.
// Video renderer property pages, Anthony Phillips, January 1996

#ifndef __OVMPROP__
#define __OVMPROP__


// {565DCEF2-AFC5-11d2-8853-0000F80883E3}
DEFINE_GUID(CLSID_COMQualityProperties,
0x565dcef2, 0xafc5, 0x11d2, 0x88, 0x53, 0x0, 0x0, 0xf8, 0x8, 0x83, 0xe3);

class COMQualityProperties : public CBasePropertyPage
{
public:

    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);

private:

    COMQualityProperties(LPUNKNOWN lpUnk, HRESULT *phr);

    void SetEditFieldData();
    void Reset();
    void OnCommand(HWND hwnd, int id, HWND hwndCtl, UINT codeNotify);

    INT_PTR OnReceiveMessage(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();

    // IQualProp Interface
    IQualProp *m_pIQualProp;        // Interface held on the renderer

    // local data
    int m_iDropped;                 // Number of frames dropped
    int m_iDrawn;                   // Count of images drawn
    int m_iSyncAvg;                 // Average sync value
    int m_iSyncDev;                 // And standard deviation
    int m_iFrameRate;               // Total frame rate average
    int m_iFrameJitter;             // Measure of frame jitter

};  // class COMQualityProperties


// {0E681C52-CD03-11d2-8853-0000F80883E3}
DEFINE_GUID(CLSID_COMPositionProperties,
0xe681c52, 0xcd03, 0x11d2, 0x88, 0x53, 0x0, 0x0, 0xf8, 0x8, 0x83, 0xe3);

class COMPositionProperties : public CBasePropertyPage
{
public:

    static CUnknown * WINAPI CreateInstance(LPUNKNOWN lpunk, HRESULT *phr);

private:

    COMPositionProperties(LPUNKNOWN lpunk, HRESULT *phr);

    void Reset();
    void OnCommand(HWND hwnd, int id, HWND hwndCtl, UINT codeNotify);
    BOOL OnInitDialog(HWND hwnd, HWND hwndFocus, LPARAM lParam);

    INT_PTR OnReceiveMessage(HWND hwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();

    // IMixerPinConfig3 interface
    IMixerPinConfig3* m_pIMixerPinConfig3;

    // IAMOverlayMixerPosition2 interface
    IAMOverlayMixerPosition2* m_pIAMOverlayMixerPosition2;

    // local data
    HWND m_hDlg;

};  // class COMPositionProperties


#if defined(DEBUG)
// f902b640-14b5-11d3-9eca-00104bde5
DEFINE_GUID(CLSID_COMDecimationProperties,
0xf902b640, 0x14b5, 0x11d3, 0x9e, 0xca, 0x00, 0x10, 0x4b, 0xde, 0x51, 0x6a);

class COMDecimationProperties : public CBasePropertyPage
{
public:
    static CUnknown * WINAPI CreateInstance(LPUNKNOWN lpunk, HRESULT *phr);

private:

    COMDecimationProperties(LPUNKNOWN lpunk, HRESULT *phr);

    void OnCommand(HWND hwnd, int id, HWND hwndCtl, UINT codeNotify);
    void OnDestroy(HWND hwnd);
    BOOL OnInitDialog(HWND hwnd, HWND hwndFocus, LPARAM lParam);

    INT_PTR OnReceiveMessage(HWND hwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
    HRESULT OnApplyChanges();

    // IAMVideoDecimationProperties interface
    IAMVideoDecimationProperties* m_pIAMVDP;

    IAMSpecifyDDrawConnectionDevice* m_pIAMSDC;

    // local data
    HWND                m_hDlg;
    DECIMATION_USAGE    m_dwUsage;
    DWORD               m_dwCount;
    AMDDRAWMONITORINFO* m_lpMonInfo;
    AMDDRAWGUID         m_GUID;
    BOOL                m_MMonWarn;

};  // class COMDecimationProperties
#endif

#endif // __OVMPROP__
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmprop\resource.h ===
// Copyright (c) 1999  Microsoft Corporation.  All Rights Reserved.
//{{NO_DEPENDENCIES}}
// Microsoft Developer Studio generated include file.
// Used by ovmprop.rc
//
#define IDD_Q1                          151
#define IDD_Q2                          152
#define IDD_Q4                          154
#define IDD_Q5                          155
#define IDD_Q6                          156
#define IDD_Q7                          157
#define FIRST_Q_BUTTON                  171
#define IDD_QDRAWN                      171
#define IDD_QDROPPED                    172
#define IDD_QAVGFRM                     174
#define IDD_QJITTER                     175
#define IDD_QSYNCAVG                    176
#define IDD_QSYNCDEV                    177
#define LAST_Q_BUTTON                   177
#define IDC_INPIN_RELPOS                1000
#define IDC_INPIN_DEST                  1001
#define IDC_INPIN_SRC                   1002
#define IDC_INPIN_SCALEDDEST            1003
#define IDC_BASIC_VID_DEST              1004
#define IDC_BASIC_VID_SRC               1005
#define IDC_BASIC_VID_SIZE              1006
#define IDC_VPINFO                      1080
#define IDC_VP_BANDWIDTH                1081
#define IDC_VP_CAPS                     1082
#define IDC_VP_FX                       1083
#define IDC_VP_INFO                     1084
#define IDC_VP_CONFIG                   1085
#define IDC_INPIN_RECTS                 1087
#define IDC_DECIMATION_OPTIONS          1088
#define IDC_DDRAW_DEVICE                1089
#define IDC_MAKE_DEFAULT                1090
#define IDC_DEFAULT_DECIMATION          1091
#define IDC_DECODER_CAPS                1092
#define IDC_MMWARNING                   1094
#define FIRST_PINCONFIG                 2004
#define IDC_POSITION_ZORDER             2004
#define IDC_BLENDING                    2005
#define IDC_TRANSPARENT                 2006
#define IDC_ASPECTRATIO_NONE            2007
#define IDC_ASPECTRATIO_ASPRIMARY       2008
#define IDC_ASPECTRATIO_LETTERBOX       2009
#define IDC_ASPECTRATIO_CROP            2010
#define IDD_DECIMATION_USAGE            2010
#define IDC_COLORKEY_R                  2011
#define IDC_COLORKEY_G                  2012
#define IDC_COLORKEY_B                  2013
#define IDC_COLORKEY                    2014
#define IDC_COLORKEY_NONE               2015
#define IDC_COLORKEY_INDEX              2016
#define IDC_COLORKEY_RGB                2017
#define IDC_COLORKEY_INDEXENTRY         2018
#define IDC_COLORKEY_TEXTR              2019
#define IDC_COLORKEY_TEXTG              2020
#define IDC_COLORKEY_TEXTB              2021
#define IDC_COLORKEY_TEXTINDEX          2022
#define LAST_PINCONFIG                  2022
#define IDC_PININFO                     2023
#define IDC_RESET                       2024
#define IDC_APPLY                       2025
#define IDD_IQUALITY                    3001
#define IDD_IMIXERPINCONFIG             3002
#define IDD_IOVMIXERPOS                 3003
#define IDD_IVPINFO                     3004
#define IDS_TITLE_MIXPOS                3005
#define IDS_TITLE_PINCFG                3006
#define IDS_TITLE_VPINFO                3007
#define IDS_TITLE_QUALITY               3008
#define IDS_DECIMATION_LEGACY           3009
#define IDS_DECIMATION_USE_DECODER_ONLY 3010
#define IDS_DECIMATION_USE_VIDEOPORT_ONLY 3011
#define IDS_DECIMATION_USE_OVERLAY_ONLY 3012
#define IDS_DEFAULT_DECIMATION          3013
#define IDS_TITLE_DECIMATION            3014
#define IDS_HW_LIMIT                    3015

// Next default values for new objects
//
#ifdef APSTUDIO_INVOKED
#ifndef APSTUDIO_READONLY_SYMBOLS
#define _APS_NEXT_RESOURCE_VALUE        2011
#define _APS_NEXT_COMMAND_VALUE         40001
#define _APS_NEXT_CONTROL_VALUE         1095
#define _APS_NEXT_SYMED_VALUE           101
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmprop\ovmprop2.cpp ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1999  Microsoft Corporation.  All Rights Reserved.
//

#include <streams.h>
#include <dvp.h>
#include <vptype.h>
#include <vpinfo.h>
#include <mpconfig3.h>
#include <ovmprop2.h>
#include <resource.h>
#include <atlbase.h>


extern void SetDlgItemRect(HWND hwnd, int id, const RECT& rect, BOOL valid);
extern HRESULT GetSrcRectFromMediaType(const CMediaType *pMediaType, RECT *pRect);
extern HRESULT GetDestRectFromMediaType(const CMediaType *pMediaType, RECT *pRect);

inline void SAFE_RELEASE(IUnknown **ppObj)
{
    if ( *ppObj != NULL )
    {
        ULONG cRef = (*ppObj)->Release();
        *ppObj = NULL;
    }
}


//
// CreateInstance
//
// Override CClassFactory method.
// Set lpUnk to point to an IUnknown interface on a new COMPinConfigProperties object
// Part of the COM object instantiation mechanism
//
CUnknown * WINAPI COMPinConfigProperties::CreateInstance(LPUNKNOWN lpunk, HRESULT *phr)
{

    CUnknown *punk = new COMPinConfigProperties(lpunk, phr);
    if (punk == NULL)
    {
        *phr = E_OUTOFMEMORY;
    }
    return punk;
} // CreateInstance


//
// COMPinConfigProperties::Constructor
//
// Constructs and initialises an COMPinConfigProperties object
//
COMPinConfigProperties::COMPinConfigProperties(LPUNKNOWN pUnk, HRESULT *phr)
: CBasePropertyPage(NAME("Overlay Mixer Property Page"),pUnk,
                    IDD_IMIXERPINCONFIG, IDS_TITLE_PINCFG)
                    , m_pIMixerPinConfig3(NULL)
                    , m_pIPin(NULL)
                    , m_amAspectRatioMode(AM_ARMODE_STRETCHED)
                    , m_dwBlending(DWORD(-1))
                    , m_dwZOrder(DWORD(-1))
                    , m_fTransparent(FALSE)
                    , m_dwKeyType(DWORD(-1))
                    , m_dwPaletteIndex(DWORD(-1))
                    , m_LowColor(COLORREF(-1))
                    , m_HighColor(COLORREF(-1))
                    , m_hDlg(HWND(NULL))

{
    ASSERT(phr);

} // (constructor) COMPinConfigProperties


HRESULT COMPinConfigProperties::OnActivate()
{
    Reset();
    return NOERROR;
}


// Override CBasePropertyPage's GetPageInfo
STDMETHODIMP COMPinConfigProperties::GetPageInfo(LPPROPPAGEINFO pPageInfo)
{
    HRESULT hr = CBasePropertyPage::GetPageInfo(pPageInfo);

    // Figure out which input pin it is, and concat the pin number to
    // property page's title
    if ( S_OK == hr && m_pIPin)
    {
        PIN_INFO PinInfo;
        PinInfo.pFilter = NULL;
        hr = m_pIPin->QueryPinInfo( &PinInfo );
        SAFE_RELEASE( (LPUNKNOWN *) &PinInfo.pFilter );

        // Get the default page title
        WCHAR wszTitle[STR_MAX_LENGTH];
        WideStringFromResource(wszTitle,m_TitleId);

        // Put the original title and pin name together
        wsprintfWInternal(wszTitle+lstrlenWInternal(wszTitle), L"%ls", PinInfo.achName);

        // Allocate dynamic memory for the new property page title
        int Length = (lstrlenWInternal(wszTitle) + 1) * sizeof(WCHAR);
        LPOLESTR pszTitle = (LPOLESTR) QzTaskMemAlloc(Length);
        if (pszTitle == NULL) {
            NOTE("No caption memory");
            return E_OUTOFMEMORY;
        }
        CopyMemory(pszTitle,wszTitle,Length);

        // Free the memory of the old title string
        if (pPageInfo->pszTitle)
            QzTaskMemFree(pPageInfo->pszTitle);
        pPageInfo->pszTitle = pszTitle;

    }

    return hr;
}


BOOL MyChooseColor(LPCHOOSECOLOR lpcc)
{
    typedef BOOL (APIENTRY *LPFNCHOOSECOLOR)(LPCHOOSECOLOR);
    static LPFNCHOOSECOLOR lpfnChooseColor;
    static const TCHAR szComDlg32[] = TEXT("ComDlg32.dll");
#ifdef UNICODE
    static const char szChooseColor[] = "ChooseColorW";
#else
    static const char szChooseColor[] = "ChooseColorA";
#endif

    if (!lpfnChooseColor) {
        HINSTANCE hInst = LoadLibrary(szComDlg32);
        if (hInst) {
            lpfnChooseColor =
                (LPFNCHOOSECOLOR)GetProcAddress(hInst, szChooseColor);
        }
    }

    if (!lpfnChooseColor) {
        return FALSE;
    }

    return (*lpfnChooseColor)(lpcc);
}



void COMPinConfigProperties::OnCommand(HWND hwnd, int id, HWND hwndCtl, UINT codeNotify)
{
    static COLORREF CustColors[16];

    switch(id) {
    case IDC_COLORKEY:

        CHOOSECOLOR ColorRec;
        ZeroMemory( &ColorRec, sizeof(CHOOSECOLOR) );

        ColorRec.lStructSize = sizeof(CHOOSECOLOR);
        ColorRec.hwndOwner = hwnd;
        ColorRec.hInstance = NULL;
        ColorRec.rgbResult = m_LowColor;
        ColorRec.lpCustColors = (LPDWORD) CustColors;
        ColorRec.Flags =  CC_RGBINIT | CC_FULLOPEN;
        ColorRec.lCustData = NULL;
        ColorRec.lpfnHook = NULL;
        ColorRec.lpTemplateName = NULL;
        if ( MyChooseColor( &ColorRec ) )
        {
            m_HighColor = m_LowColor = ColorRec.rgbResult;
            SetDlgItemInt( hwnd, IDC_COLORKEY_R, GetRValue(m_LowColor), FALSE );
            SetDlgItemInt( hwnd, IDC_COLORKEY_G, GetGValue(m_LowColor), FALSE );
            SetDlgItemInt( hwnd, IDC_COLORKEY_B, GetBValue(m_LowColor), FALSE );

            SetDirty();
        }

    case IDC_COLORKEY_R:
        //if ( HIWORD( wParam ) == EN_KILLFOCUS )
        UpdateColorKey(IDC_COLORKEY_R);
        break;

    case IDC_COLORKEY_G:
        //if ( HIWORD( wParam ) == EN_KILLFOCUS )
        UpdateColorKey(IDC_COLORKEY_G);
        break;

    case IDC_COLORKEY_B:
        //if ( HIWORD( wParam ) == EN_KILLFOCUS )
        UpdateColorKey(IDC_COLORKEY_B);
        break;


    case IDC_COLORKEY_NONE:
    case IDC_COLORKEY_INDEX:
    case IDC_COLORKEY_RGB:
        {
            DWORD keyType;
            CheckRadioButton( hwnd, IDC_COLORKEY_NONE, IDC_COLORKEY_RGB, id);
            switch (id) {
            case IDC_COLORKEY_NONE:
                keyType = CK_NOCOLORKEY;
                break;
            case IDC_COLORKEY_INDEX:
                keyType = CK_INDEX;
                break;
            case IDC_COLORKEY_RGB:
            default:
                keyType = CK_RGB;
                break;

            }

            if (m_dwKeyType != keyType)
                SetDirty();
            m_dwKeyType = keyType;
            ShowColorKey();
        }
        break;

    case IDC_COLORKEY_INDEXENTRY:
        //if ( HIWORD( wParam ) == EN_KILLFOCUS )
        {
            BOOL fTranslated;
            DWORD dwTmp = GetDlgItemInt( hwnd, IDC_COLORKEY_INDEXENTRY, &fTranslated, FALSE);
            if ( fTranslated )
            {
                if ( m_dwPaletteIndex != dwTmp )
                {
                    SetDirty();
                    m_dwPaletteIndex = dwTmp;

                    HDC hDC = GetDC( NULL );
                    BOOL bPalette = (RC_PALETTE == (RC_PALETTE & GetDeviceCaps( hDC, RASTERCAPS )));

                    if ( bPalette )
                    {
                        PALETTEENTRY PaletteEntry;
                        UINT nTmp = GetSystemPaletteEntries( hDC, m_dwPaletteIndex, 1, &PaletteEntry );
                        if ( nTmp == 1 )
                        {
                            m_HighColor = m_LowColor = RGB( PaletteEntry.peRed, PaletteEntry.peGreen, PaletteEntry.peBlue );
                            SetDlgItemInt( hwnd, IDC_COLORKEY_R, GetRValue(m_LowColor), FALSE );
                            SetDlgItemInt( hwnd, IDC_COLORKEY_G, GetGValue(m_LowColor), FALSE );
                            SetDlgItemInt( hwnd, IDC_COLORKEY_B, GetBValue(m_LowColor), FALSE );
                        }
                    }
                    ReleaseDC( NULL, hDC );
                }
            }
        }
        break;

    case IDC_ASPECTRATIO_NONE:
        if ( m_amAspectRatioMode != AM_ARMODE_STRETCHED )
            SetDirty();
        m_amAspectRatioMode = AM_ARMODE_STRETCHED;
        break;
    case IDC_ASPECTRATIO_ASPRIMARY:
        if ( m_amAspectRatioMode != AM_ARMODE_STRETCHED_AS_PRIMARY )
            SetDirty();
        m_amAspectRatioMode = AM_ARMODE_STRETCHED_AS_PRIMARY;
        break;

    case IDC_ASPECTRATIO_LETTERBOX:
        if ( m_amAspectRatioMode != AM_ARMODE_LETTER_BOX )
            SetDirty();
        m_amAspectRatioMode = AM_ARMODE_LETTER_BOX;
        break;

    case IDC_ASPECTRATIO_CROP:
        if ( m_amAspectRatioMode != AM_ARMODE_CROP )
            SetDirty();
        m_amAspectRatioMode = AM_ARMODE_CROP;
        break;

    case IDC_BLENDING:
        //if ( HIWORD( wParam ) == EN_KILLFOCUS )
        UpdateItemInt(IDC_BLENDING, &m_dwBlending);
        break;

    case IDC_POSITION_ZORDER:
        //if ( HIWORD( wParam ) == EN_KILLFOCUS )
        UpdateItemInt(IDC_POSITION_ZORDER, &m_dwZOrder);
        break;

    case IDC_TRANSPARENT:
        {
            BOOL fChecked = IsDlgButtonChecked( hwnd, IDC_TRANSPARENT );
            if ( fChecked != m_fTransparent ) SetDirty();
            m_fTransparent = fChecked;
            break;
        }

    case IDC_RESET:
        Reset();
    }

}


BOOL COMPinConfigProperties::OnInitDialog(HWND hwnd, HWND hwndFocus, LPARAM lParam)
{
    // init local variables
    m_dwBlending = -1;
    m_dwZOrder = -1;
    m_fTransparent = FALSE;

    m_dwKeyType = -1;
    m_dwPaletteIndex = -1;
    m_LowColor = -1;
    m_HighColor = -1;

    m_hDlg = hwnd;

    ShowColorKey();
    return TRUE;
}


//
// OnReceiveMessage
//
// Override CBasePropertyPage method.
// Handles the messages for our property window
//
INT_PTR COMPinConfigProperties::OnReceiveMessage(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam)
{
    switch (uMsg)
    {
        HANDLE_MSG(hwnd, WM_COMMAND,    OnCommand);
        HANDLE_MSG(hwnd, WM_INITDIALOG, OnInitDialog);
    } // switch

    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
} // OnReceiveMessage


//
// UpdateColorKey
//
// Compute Colorkey from the prop page entries,
// Update Colorkey and call SetDirty if changed
//
HRESULT COMPinConfigProperties::UpdateColorKey(int id)
{
    BOOL fTranslated;
    DWORD dwTmp;

    dwTmp = GetDlgItemInt( m_hDlg, id, &fTranslated, FALSE);
    if ( fTranslated )
    {
        switch (id) {
        case IDC_COLORKEY_R:
            m_LowColor = RGB( dwTmp, GetGValue(m_LowColor), GetBValue(m_LowColor) );
            break;
        case IDC_COLORKEY_G:
            m_LowColor = RGB( GetRValue(m_LowColor), dwTmp, GetBValue(m_LowColor) );
            break;
        case IDC_COLORKEY_B:
            m_LowColor = RGB( GetRValue(m_LowColor), GetGValue(m_LowColor), dwTmp );
            break;
        }
    }
    if ( m_LowColor != m_HighColor )
    {
        m_HighColor = m_LowColor;
        SetDirty();
    }
    return NOERROR;
}


//
// ShowColorKey
//
// Decide what dialog items to show depending on the colorkey type
//
HRESULT COMPinConfigProperties::ShowColorKey(void)
{
    BOOL bSet = (m_dwKeyType == CK_RGB? SW_SHOW : SW_HIDE);
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY ), bSet );
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY_R ), bSet );
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY_B ), bSet );
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY_G ), bSet );
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY_TEXTR ), bSet );
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY_TEXTB ), bSet );
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY_TEXTG ), bSet );
    bSet = (m_dwKeyType == CK_INDEX? SW_SHOW : SW_HIDE);
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY_INDEXENTRY ), bSet );
    ShowWindow( GetDlgItem( m_hDlg, IDC_COLORKEY_TEXTINDEX ), bSet );
    return NOERROR;
}


//
// UpdateItemInt
//
// Get int from a DlgItem, if different from saved
// Update saved and call SetDirty
//
HRESULT COMPinConfigProperties::UpdateItemInt(int id, DWORD* saved)
{
    BOOL fTranslated;
    DWORD dwTmp = GetDlgItemInt( m_hDlg, id, &fTranslated, FALSE);
    if ( fTranslated )
    {
        if ( *saved != dwTmp ) SetDirty();
        *saved = dwTmp;
    }
    return NOERROR;
}


//
// Reset
//
// Reset all dialog entries
//
void COMPinConfigProperties::Reset(void)
{
    ASSERT(m_pIMixerPinConfig3);
    ASSERT(m_pIPin);

    HRESULT hr = S_OK;

    IPin *iPin = NULL;
    hr = m_pIPin->ConnectedTo(&iPin);
    if (FAILED(hr) || !iPin) {
        SetDlgItemText( m_hDlg, IDC_PININFO, TEXT("Pin Not Connected"));
        for (int i=FIRST_PINCONFIG; i<=LAST_PINCONFIG; i++)
            EnableWindow( GetDlgItem( m_hDlg, i ), FALSE );
        return;
    }
    iPin->Release();

    TCHAR szError[255];
    lstrcpy( szError, TEXT("") );

    if ( S_OK == hr )
    {
        IPin *		pNextPin = NULL;
        IEnumPins *	pPinEnum = NULL;
        PIN_INFO	PinInfo;
        ULONG		ulFetched;

        PinInfo.pFilter = NULL;
        hr = m_pIPin->QueryPinInfo( &PinInfo );

        if ( S_OK == hr )
        {
            hr = PinInfo.pFilter->EnumPins( &pPinEnum );
            SAFE_RELEASE( (LPUNKNOWN *) &PinInfo.pFilter );
        }

        if ( S_OK == hr )
            hr = pPinEnum->Reset();

        while ( S_OK == hr )
        {
            hr = pPinEnum->Next( 1, &pNextPin, &ulFetched );

            if ( S_OK == hr )
            {
                hr = pNextPin->QueryPinInfo( &PinInfo );
                SAFE_RELEASE( (LPUNKNOWN *) &PinInfo.pFilter );
            }

            if ( S_OK == hr && PinInfo.dir == PINDIR_INPUT )
            {
                if ( m_pIPin == pNextPin ) {
                    lstrcpy( szError, TEXT("Primary Input Pin - ") );
                    ShowWindow( GetDlgItem( m_hDlg, IDC_ASPECTRATIO_ASPRIMARY ), FALSE );

                    // Get Render Tranport Mode
                    hr = m_pIMixerPinConfig3->GetRenderTransport( &m_amRenderTransport);
                    if ( S_OK == hr) {
                        switch (m_amRenderTransport) {
                        case AM_OVERLAY:
                            lstrcat( szError, TEXT("Overlay\n"));
                            break;
                        case AM_VIDEOPORT:
                            lstrcat( szError, TEXT("Videoport\n"));
                            break;
                        case AM_OFFSCREEN:
                            lstrcat( szError, TEXT("Offscreen\n"));
                            break;
                        case AM_VIDEOACCELERATOR:
                            lstrcat( szError, TEXT("Video Accelerator\n"));
                            break;
                        case AM_GDI:
                            lstrcat( szError, TEXT("GDI\n"));
                            break;
                        default:
                            lstrcat( szError, TEXT("Error\n"));
                        }
                    }
                }
                else {
                    lstrcpy( szError, TEXT("Secondary Input Pin\n") );
                    ShowWindow( GetDlgItem( m_hDlg, IDC_ASPECTRATIO_ASPRIMARY ), TRUE );
                }

                SAFE_RELEASE( (LPUNKNOWN *) &pNextPin );
                break;
            }
            SAFE_RELEASE( (LPUNKNOWN *) &pNextPin );
        }

        SAFE_RELEASE( (LPUNKNOWN *) &pPinEnum );
    }

    // Get inpin relative position
    RECT rect;
    if ( S_OK == hr )
        hr = m_pIMixerPinConfig3->GetRelativePosition
        ( (DWORD*)&(rect.left), (DWORD*)&(rect.top), (DWORD*)&(rect.right), (DWORD*)&(rect.bottom) );
    SetDlgItemRect(m_hDlg, IDC_INPIN_RELPOS, rect, SUCCEEDED(hr));

    // Get inpin src rect from media type
    AM_MEDIA_TYPE mt;
    hr = m_pIPin->ConnectionMediaType(&mt);
    if ( S_OK == hr )
        hr = GetSrcRectFromMediaType(&CMediaType(mt), &rect);
    SetDlgItemRect(m_hDlg, IDC_INPIN_SRC, rect, SUCCEEDED(hr));

    // Get inpin dest rect from media type
    if ( S_OK == hr )
        hr = GetDestRectFromMediaType(&CMediaType(mt), &rect );
    SetDlgItemRect(m_hDlg, IDC_INPIN_DEST, rect, SUCCEEDED(hr));


    hr = m_pIMixerPinConfig3->GetStreamTransparent( &m_fTransparent );
    CheckDlgButton( m_hDlg, IDC_TRANSPARENT, m_fTransparent ? BST_CHECKED : BST_UNCHECKED );
    if ( S_OK != hr )
    {
        lstrcat( szError, TEXT("Error Getting Transparency\n") );
    }

    hr = m_pIMixerPinConfig3->GetZOrder( &m_dwZOrder );
    if ( S_OK == hr )
    {
        SetDlgItemInt( m_hDlg, IDC_POSITION_ZORDER, m_dwZOrder, FALSE );
    }
    else
    {
        SetDlgItemText( m_hDlg, IDC_POSITION_ZORDER, TEXT("") );
        lstrcat( szError, TEXT("Error Getting ZOrder\n") );
    }

    hr = m_pIMixerPinConfig3->GetBlendingParameter( &m_dwBlending );
    if ( S_OK == hr )
    {
        SetDlgItemInt( m_hDlg, IDC_BLENDING, m_dwBlending, FALSE );
    }
    else
    {
        SetDlgItemText( m_hDlg, IDC_BLENDING, TEXT("") );
        lstrcat( szError, TEXT("Error Getting Blending\n") );
    }

    hr = m_pIMixerPinConfig3->GetAspectRatioMode( &m_amAspectRatioMode );
    switch ( m_amAspectRatioMode )
    {
        case AM_ARMODE_STRETCHED_AS_PRIMARY:
            CheckRadioButton( m_hDlg, IDC_ASPECTRATIO_NONE, IDC_ASPECTRATIO_CROP, IDC_ASPECTRATIO_ASPRIMARY );
            break;
        case AM_ARMODE_STRETCHED:
            CheckRadioButton( m_hDlg, IDC_ASPECTRATIO_NONE, IDC_ASPECTRATIO_CROP, IDC_ASPECTRATIO_NONE );
            break;
        case AM_ARMODE_LETTER_BOX:
            CheckRadioButton( m_hDlg, IDC_ASPECTRATIO_NONE, IDC_ASPECTRATIO_CROP, IDC_ASPECTRATIO_LETTERBOX );
            break;
        case AM_ARMODE_CROP:
            CheckRadioButton( m_hDlg, IDC_ASPECTRATIO_NONE, IDC_ASPECTRATIO_CROP, IDC_ASPECTRATIO_CROP );
            break;
    }

    if ( S_OK != hr )
    {
        lstrcat( szError, TEXT("Error Getting Aspect Ratio\n") );
    }

    COLORKEY	ColorKey;
    DWORD		dwColor;
    hr = m_pIMixerPinConfig3->GetColorKey( &ColorKey, &dwColor );
    if ( S_OK == hr )
    {
        m_dwKeyType = ColorKey.KeyType;
        m_dwPaletteIndex = ColorKey.PaletteIndex;
        m_LowColor = ColorKey.LowColorValue;
        m_HighColor = ColorKey.HighColorValue;

        HDC hDC = GetDC( NULL );
        BOOL bPalette;
        if ( hDC )
            bPalette = (RC_PALETTE == (RC_PALETTE & GetDeviceCaps( hDC, RASTERCAPS )));
        else
            bPalette = FALSE;

        if ( m_dwKeyType&CK_INDEX && bPalette) {
            CheckRadioButton( m_hDlg, IDC_COLORKEY_NONE, IDC_COLORKEY_RGB, IDC_COLORKEY_INDEX );

            PALETTEENTRY PaletteEntry;
            UINT nTmp = GetSystemPaletteEntries( hDC, m_dwPaletteIndex, 1, &PaletteEntry );
            if ( nTmp == 1 )
            {
                m_HighColor = m_LowColor = RGB( PaletteEntry.peRed, PaletteEntry.peGreen, PaletteEntry.peBlue );
            }
            m_dwKeyType = CK_INDEX;
            SendMessage( m_hDlg, WM_COMMAND, IDC_COLORKEY_INDEX, 0L );
            SetDlgItemInt( m_hDlg, IDC_COLORKEY_INDEXENTRY, m_dwPaletteIndex, FALSE );
        }
        else if ( m_dwKeyType&CK_RGB) {
            CheckRadioButton( m_hDlg, IDC_COLORKEY_NONE, IDC_COLORKEY_RGB, IDC_COLORKEY_RGB );
            m_dwKeyType = CK_RGB;
            SendMessage( m_hDlg, WM_COMMAND, IDC_COLORKEY_RGB, 0L );
            SetDlgItemInt( m_hDlg, IDC_COLORKEY_R, GetRValue(m_LowColor), FALSE );
            SetDlgItemInt( m_hDlg, IDC_COLORKEY_G, GetGValue(m_LowColor), FALSE );
            SetDlgItemInt( m_hDlg, IDC_COLORKEY_B, GetBValue(m_LowColor), FALSE );
        }

        else {
            CheckRadioButton( m_hDlg, IDC_COLORKEY_NONE, IDC_COLORKEY_INDEX, IDC_COLORKEY_NONE );
            SendMessage( m_hDlg, WM_COMMAND, IDC_COLORKEY_NONE, 0L );
        }
        if ( hDC )
            ReleaseDC( NULL, hDC );
    }

    else
    {
        SetDlgItemText( m_hDlg, IDC_COLORKEY_R, TEXT("") );
        SetDlgItemText( m_hDlg, IDC_COLORKEY_G, TEXT("") );
        SetDlgItemText( m_hDlg, IDC_COLORKEY_B, TEXT("") );
        SetDlgItemText( m_hDlg, IDC_COLORKEY_INDEXENTRY, TEXT("") );
        lstrcat( szError, TEXT("Error Getting ColorKey\n") );
    }

    if ( 0 != lstrlen( szError ) )
        SetDlgItemText( m_hDlg, IDC_PININFO, szError );
}


//
// OnApplyChanges
//
// Override CBasePropertyPage method.
// Process changes in IMixerPinConfig properties and reset m_bDirty bit
//
HRESULT COMPinConfigProperties::OnApplyChanges()
{
    HRESULT	hr = S_OK;
    TCHAR	szError[255];

    lstrcpy( szError, TEXT("") );

    COLORKEY ColorKey;
    if (m_dwKeyType == CK_NOCOLORKEY)
        ColorKey.KeyType = CK_NOCOLORKEY;
    else {
        ColorKey.KeyType = CK_RGB;
        if (m_dwKeyType == CK_INDEX)
            ColorKey.KeyType |= CK_INDEX;
    }

    ColorKey.PaletteIndex = m_dwPaletteIndex;
    ColorKey.LowColorValue = m_LowColor;
    ColorKey.HighColorValue = m_HighColor;
    hr = m_pIMixerPinConfig3->SetColorKey( &ColorKey );
    if ( S_OK != hr )
    {
        lstrcat( szError, TEXT("Error Setting ColorKey\n") );
    }

    hr = m_pIMixerPinConfig3->SetZOrder( m_dwZOrder );
    if ( S_OK != hr )
    {
        lstrcat( szError, TEXT("Error Setting ZOrder\n") );
    }

    hr = m_pIMixerPinConfig3->SetBlendingParameter( m_dwBlending );
    if ( S_OK != hr )
    {
        lstrcat( szError, TEXT("Error Setting Blending\n") );
    }

    hr = m_pIMixerPinConfig3->SetAspectRatioMode( m_amAspectRatioMode );
    if ( S_OK != hr )
    {
        lstrcat( szError, TEXT("Error Setting Aspect Ratio\n") );
    }

    hr = m_pIMixerPinConfig3->SetStreamTransparent( m_fTransparent );
    if ( S_OK != hr )
    {
        lstrcat( szError, TEXT("Error Setting Transparency\n") );
    }

    SetDlgItemText( m_hDlg, IDC_PININFO, szError );

    // Reset dirty bit
    if ( S_OK == IsPageDirty() ) {
        m_bDirty = FALSE;
        if (m_pPageSite)
            m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
    }

    return hr;
} // OnApplyChanges


//
// SetDirty
//
// Sets m_bDirty and notifies the property page site of the change
//
void COMPinConfigProperties::SetDirty()
{
    m_bDirty = TRUE;
    if (m_pPageSite)
        m_pPageSite->OnStatusChange(PROPPAGESTATUS_DIRTY);
} // SetDirty


//
// OnConnect
//
// Override CBasePropertyPage method.
// Notification of which object this property page should display.
// We query the object for the IID_IMixerPinConfig3 interface.
//
// If cObjects == 0 then we must release the interface.
// Initialize class variables
HRESULT COMPinConfigProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pIMixerPinConfig3 == NULL);
    ASSERT(m_pIPin == NULL);

    HRESULT hr = S_OK;

    // Query for IEnumPinConfig, if added for the filter
    CComPtr <IEnumPinConfig> pEnumPinConfig = NULL;

    hr = pUnknown->QueryInterface(IID_IEnumPinConfig, (void**) &pEnumPinConfig);
    if (SUCCEEDED(hr) && pEnumPinConfig) {
        hr = pEnumPinConfig->Next(&m_pIMixerPinConfig3);
        if (FAILED(hr))
            return hr;
        hr = m_pIMixerPinConfig3->QueryInterface(IID_IPin, (void**) &m_pIPin);
        if (FAILED(hr)) {
            m_pIMixerPinConfig3->Release();
            return hr;
        }
    }

    // Query for IPin directly, if added for the pin
    else  {
        hr = pUnknown->QueryInterface(IID_IPin, (void**) &m_pIPin);
        if (FAILED(hr))
            return hr;
        hr = m_pIPin->QueryInterface(IID_IMixerPinConfig3, (void **) &m_pIMixerPinConfig3);
        if (FAILED(hr)) {
            m_pIPin->Release();
            return hr;
        }
    }

    ASSERT(m_pIMixerPinConfig3);
    ASSERT(m_pIPin);

    return hr;

} // OnConnect


//
// OnDisconnect
//
// Override CBasePropertyPage method.
// Release the private interface.
//
HRESULT COMPinConfigProperties::OnDisconnect()
{
    // Release of Interface

    if (m_pIMixerPinConfig3) {
        m_pIMixerPinConfig3->Release();
        m_pIMixerPinConfig3 = NULL;
    }

    if (m_pIPin) {
        m_pIPin->Release();
        m_pIPin = NULL;
    }

    return NOERROR;

} // OnDisconnect


//
// CreateInstance
//
// Override CClassFactory method.
// Set lpUnk to point to an IUnknown interface on a new COMVPInfoProperties object
// Part of the COM object instantiation mechanism
//
CUnknown * WINAPI COMVPInfoProperties::CreateInstance(LPUNKNOWN lpunk, HRESULT *phr)
{

    CUnknown *punk = new COMVPInfoProperties(lpunk, phr);
    if (punk == NULL)
    {
        *phr = E_OUTOFMEMORY;
    }
    return punk;
} // CreateInstance


//
// COMVPInfoProperties::Constructor
//
// Constructs and initialises an COMVPInfoProperties object
//
COMVPInfoProperties::COMVPInfoProperties(LPUNKNOWN pUnk, HRESULT *phr)
: CBasePropertyPage(NAME("Overlay Mixer Property Page"),pUnk,
                    IDD_IVPINFO, IDS_TITLE_VPINFO)
                    , m_pIVPInfo(NULL)
                    , m_hDlg(HWND(NULL))

{
    ASSERT(phr);

} // (constructor) COMVPInfoProperties


BOOL COMVPInfoProperties::OnInitDialog(HWND hwnd, HWND hwndFocus, LPARAM lParam)
{
    m_hDlg = hwnd;
    // Set the font in the listbox to a fixed width font
    SetWindowFont(GetDlgItem (hwnd, IDC_VPINFO), GetStockObject(ANSI_FIXED_FONT), FALSE);
    return TRUE;
}


void COMVPInfoProperties::OnCommand(HWND hwnd, int id, HWND hwndCtl, UINT codeNotify)
{
    switch(id)
    {
    case IDC_RESET:
        Reset();
        break;
    case IDC_VP_CONFIG:
    case IDC_VP_BANDWIDTH:
    case IDC_VP_CAPS:
    case IDC_VP_FX:
    case IDC_VP_INFO:
        SetEditFieldData(id);
        break;
    }
}


// Handles the messages for our property window

INT_PTR COMVPInfoProperties::OnReceiveMessage(HWND hwnd,
                                           UINT uMsg,
                                           WPARAM wParam,
                                           LPARAM lParam)
{
    switch (uMsg) {
        HANDLE_MSG(hwnd, WM_COMMAND,    OnCommand);
        HANDLE_MSG(hwnd, WM_INITDIALOG, OnInitDialog);
    }

    return CBasePropertyPage::OnReceiveMessage(hwnd,uMsg,wParam,lParam);
}


void COMVPInfoProperties::Reset()
{
    ASSERT(m_pIVPInfo);

    m_pIVPInfo->GetPixelsPerSecond(&m_dwPixelsPerSecond);
    m_pIVPInfo->GetCropState(&m_CropState);
    m_pIVPInfo->GetVPDataInfo(&m_VPDataInfo);

    m_pIVPInfo->GetVPBandwidth(&m_sBandwidth);
    m_pIVPInfo->GetVPCaps(&m_VPCaps);
    m_pIVPInfo->GetVPInfo(&m_sVPInfo);

    CheckDlgButton(m_hDlg, IDC_VP_CONFIG, BST_CHECKED);
    SetEditFieldData(IDC_VP_CONFIG);
}


//
// OnConnect
//
// Override CBasePropertyPage method.
// Notification of which object this property page should display.
// We query the object for the ITestOMProp interface.
//
// If cObjects == 0 then we must release the interface.
HRESULT COMVPInfoProperties::OnConnect(IUnknown *pUnknown)
{
    ASSERT(m_pIVPInfo == NULL);

    HRESULT hr = pUnknown->QueryInterface(IID_IVPInfo,
        (void **) &m_pIVPInfo);

    if (FAILED(hr))
        return hr;

    ASSERT(m_pIVPInfo);

    return hr;

} // OnConnect


//
// OnDisconnect
//
// Override CBasePropertyPage method.
// Release the private interface.
//
HRESULT COMVPInfoProperties::OnDisconnect()
{
    // Release of Interface

    if (m_pIVPInfo) {
        m_pIVPInfo->Release();
        m_pIVPInfo = NULL;
    }

    return NOERROR;

} // OnDisconnect


// Create the window we will use to edit properties

HRESULT COMVPInfoProperties::OnActivate()
{
    Reset();
    return NOERROR;
}


// Initialise the property page fields

void COMVPInfoProperties::SetEditFieldData(int id)
{
    TCHAR buffer[2048];
    switch (id) {
    case IDC_VP_CONFIG:
        wsprintf(buffer,
            TEXT("[VPConfig]\r\n")
            TEXT("Max Pixel Rate                 %7d\r\n")
            TEXT("Crop State                     %7d\r\n")
            TEXT("Microseconds Per Field         %7d\r\n")
            TEXT("Field Width                    %7d\r\n")
            TEXT("Field Height                   %7d\r\n")
            TEXT("VBI Width                      %7d\r\n")
            TEXT("VBI Height                     %7d\r\n")
            TEXT("Valid Region         [%3d,%3d,%3d,%3d]\r\n")
            TEXT("Pict Aspect Ratio X            %7d\r\n")
            TEXT("Pict Aspect Ratio Y            %7d\r\n")
            TEXT("Enable Double Clock            %7d\r\n")
            TEXT("Enable VACT                    %7d\r\n")
            TEXT("Data Is Interlaced             %7d\r\n")
            TEXT("Half Lines Odd                 %7ld\r\n")
            TEXT("Half Lines Even                %7ld\r\n")
            TEXT("Field Polarity Inverted        %7d\r\n")
            TEXT("Num Lines In VREF              %7d\r\n"),
            m_dwPixelsPerSecond,
            m_CropState,
            m_VPDataInfo.dwMicrosecondsPerField,
            m_VPDataInfo.amvpDimInfo.dwFieldWidth,
            m_VPDataInfo.amvpDimInfo.dwFieldHeight,
            m_VPDataInfo.amvpDimInfo.dwVBIWidth,
            m_VPDataInfo.amvpDimInfo.dwVBIHeight,
            m_VPDataInfo.amvpDimInfo.rcValidRegion.left,
            m_VPDataInfo.amvpDimInfo.rcValidRegion.top,
            m_VPDataInfo.amvpDimInfo.rcValidRegion.right,
            m_VPDataInfo.amvpDimInfo.rcValidRegion.bottom,
            m_VPDataInfo.dwPictAspectRatioX,
            m_VPDataInfo.dwPictAspectRatioY,
            (m_VPDataInfo.bEnableDoubleClock)>0,
            (m_VPDataInfo.bEnableVACT)>0,
            (m_VPDataInfo.bDataIsInterlaced)>0,
            m_VPDataInfo.lHalfLinesOdd,
            m_VPDataInfo.lHalfLinesEven,
            (m_VPDataInfo.bFieldPolarityInverted)>0,
            m_VPDataInfo.dwNumLinesInVREF
            );
        break;
    case IDC_VP_BANDWIDTH:
        wsprintf(buffer,
            TEXT("[DDVIDEOPORTBANDWIDTH]\r\n")
            TEXT("DDVPBCAPS_DESTINATION          %7d\r\n")
            TEXT("DDVPBCAPS_SOURCE               %7d\r\n")
            TEXT("Overlay                        %7d\r\n")
            TEXT("Colorkey                       %7d\r\n")
            TEXT("Y Interpolate                  %7d\r\n")
            TEXT("Y Interp And Colorkey          %7d\r\n"),
            (m_sBandwidth.dwCaps&DDVPBCAPS_DESTINATION)>0,
            (m_sBandwidth.dwCaps&DDVPBCAPS_SOURCE)>0,
            m_sBandwidth.dwOverlay,
            m_sBandwidth.dwColorkey,
            m_sBandwidth.dwYInterpolate,
            m_sBandwidth.dwYInterpAndColorkey
            );
        break;


    case IDC_VP_CAPS:
        wsprintf(buffer,
            TEXT("[DDVIDEOPORTCAPS]\r\n")
            TEXT("Max Width                      %7d\r\n")
            TEXT("Max Height                     %7d\r\n")
            TEXT("Max VBI Width                  %7d\r\n")
            TEXT("Num Auto Flip Surfaces         %7d\r\n")
            TEXT("Align Video Port Boundary      %7d\r\n")
            TEXT("Align Video Port Prescale Wid  %7d\r\n")
            TEXT("Align Video Port Crop Boundary %7d\r\n")
            TEXT("Align Video Port Crop Width    %7d\r\n")
            TEXT("Preshrink X Step               %7d\r\n")
            TEXT("Preshrink Y Step               %7d\r\n")
            TEXT("Num VBI Auto Flip Surfaces     %7d\r\n")
            //"NumPreferredAutoflip          %d\r\n"
            //"NumFilterTapsX                %d\r\n"
            //"NumFilterTapsY                %d\r\n"
            TEXT("DDVPCAPS_AUTOFLIP              %7d\r\n")
            TEXT("DDVPCAPS_COLORCONTROL          %7d\r\n")
            TEXT("DDVPCAPS_INTERLACED            %7d\r\n")
            TEXT("DDVPCAPS_NONINTERLACED         %7d\r\n")
            TEXT("DDVPCAPS_OVERSAMPLEDVBI        %7d\r\n")
            TEXT("DDVPCAPS_READBACKFIELD         %7d\r\n")
            TEXT("DDVPCAPS_READBACKLINE          %7d\r\n")
            TEXT("DDVPCAPS_SHAREABLE             %7d\r\n")
            TEXT("DDVPCAPS_SKIPEVENFIELDS        %7d\r\n")
            TEXT("DDVPCAPS_SKIPODDFIELDS         %7d\r\n")
            TEXT("DDVPCAPS_SYNCMASTER            %7d\r\n")
            TEXT("DDVPCAPS_SYSTEMMEMORY          %7d\r\n")
            TEXT("DDVPCAPS_VBIANDVIDEOINDEPENDENT%7d\r\n")
            TEXT("DDVPCAPS_VBISURFACE            %7d\r\n"),
            m_VPCaps.dwMaxWidth,
            m_VPCaps.dwMaxHeight,
            m_VPCaps.dwMaxVBIWidth,
            m_VPCaps.dwNumAutoFlipSurfaces,
            m_VPCaps.dwAlignVideoPortBoundary,
            m_VPCaps.dwAlignVideoPortPrescaleWidth,
            m_VPCaps.dwAlignVideoPortCropBoundary,
            m_VPCaps.dwAlignVideoPortCropWidth,
            m_VPCaps.dwPreshrinkXStep,
            m_VPCaps.dwPreshrinkYStep,
            m_VPCaps.dwNumVBIAutoFlipSurfaces,
            //m_VPCaps.dwNumPreferredAutoflip,
            //m_VPCaps.wNumFilterTapsX,
            //m_VPCaps.wNumFilterTapsY,
            (m_VPCaps.dwCaps&DDVPCAPS_AUTOFLIP)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_COLORCONTROL)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_INTERLACED)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_NONINTERLACED)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_OVERSAMPLEDVBI)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_READBACKFIELD)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_READBACKLINE)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_SHAREABLE)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_SKIPEVENFIELDS)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_SKIPODDFIELDS)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_SYNCMASTER)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_SYSTEMMEMORY)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_VBIANDVIDEOINDEPENDENT)>0,
            (m_VPCaps.dwCaps&DDVPCAPS_VBISURFACE)>0
            );
        break;

    case IDC_VP_FX:
        wsprintf(buffer,
            TEXT("[DDVIDEOPORTCAPS::dwFX]\r\n")
            TEXT("DDVPFX_CROPTOPDATA             %7d\r\n")
            TEXT("DDVPFX_CROPX                   %7d\r\n")
            TEXT("DDVPFX_CROPY                   %7d\r\n")
            TEXT("DDVPFX_IGNOREVBIXCROP          %7d\r\n")
            TEXT("DDVPFX_INTERLEAVE              %7d\r\n")
            TEXT("DDVPFX_MIRRORLEFTRIGHT         %7d\r\n")
            TEXT("DDVPFX_MIRRORUPDOWN            %7d\r\n")
            TEXT("DDVPFX_PRESHRINKX              %7d\r\n")
            TEXT("DDVPFX_PRESHRINKY              %7d\r\n")
            TEXT("DDVPFX_PRESHRINKXB             %7d\r\n")
            TEXT("DDVPFX_PRESHRINKYB             %7d\r\n")
            TEXT("DDVPFX_PRESHRINKXS             %7d\r\n")
            TEXT("DDVPFX_PRESHRINKYS             %7d\r\n")
            TEXT("DDVPFX_PRESTRETCHX             %7d\r\n")
            TEXT("DDVPFX_PRESTRETCHY             %7d\r\n")
            TEXT("DDVPFX_PRESTRETCHXN            %7d\r\n")
            TEXT("DDVPFX_PRESTRETCHYN            %7d\r\n")
            TEXT("DDVPFX_VBICONVERT              %7d\r\n")
            //"DDVPFX_VBINOINTERLEAVE         %d\r\n"
            TEXT("DDVPFX_VBINOSCALE              %7d\r\n"),
            (m_VPCaps.dwFX&DDVPFX_CROPTOPDATA)>0,
            (m_VPCaps.dwFX&DDVPFX_CROPX)>0,
            (m_VPCaps.dwFX&DDVPFX_CROPY)>0,
            (m_VPCaps.dwFX&DDVPFX_IGNOREVBIXCROP)>0,
            (m_VPCaps.dwFX&DDVPFX_INTERLEAVE)>0,
            (m_VPCaps.dwFX&DDVPFX_MIRRORLEFTRIGHT)>0,
            (m_VPCaps.dwFX&DDVPFX_MIRRORUPDOWN)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESHRINKX)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESHRINKY)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESHRINKXB)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESHRINKYB)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESHRINKXS)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESHRINKYS)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESTRETCHX)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESTRETCHY)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESTRETCHXN)>0,
            (m_VPCaps.dwFX&DDVPFX_PRESTRETCHYN)>0,
            (m_VPCaps.dwFX&DDVPFX_VBICONVERT)>0,
            //m_VPCaps.dwFX&DDVPFX_VBINOINTERLEAVE,
            (m_VPCaps.dwFX&DDVPFX_VBINOSCALE)>0
            );
        break;
    case IDC_VP_INFO:
        {
            DWORD szFcc1 = 0;
            DWORD szFcc2 = 0;
            DWORD szFcc3 = 0;
            if (m_sVPInfo.lpddpfInputFormat)
                szFcc1 = m_sVPInfo.lpddpfInputFormat->dwFourCC;
            if (m_sVPInfo.lpddpfVBIInputFormat)
                szFcc2 = m_sVPInfo.lpddpfVBIInputFormat->dwFourCC;
            if (m_sVPInfo.lpddpfVBIOutputFormat)
                szFcc3 = m_sVPInfo.lpddpfVBIOutputFormat->dwFourCC;

            wsprintf(buffer,
                TEXT("[DDVIDEOPORTINFO]\r\n")
                TEXT("Origin X                       %7d\r\n")
                TEXT("Origin Y                       %7d\r\n")
                TEXT("Crop Rect            [%3d,%3d,%3d,%3d]\r\n")
                TEXT("Prescale Width                 %7d\r\n")
                TEXT("Prescale Height                %7d\r\n")
                TEXT("Input Format                   %7.4hs\r\n")
                TEXT("VBI Input Format               %7.4hs\r\n")
                TEXT("VBI Output Format              %7.4hs\r\n")
                TEXT("VBI Height                     %7d\r\n")
                TEXT("DDVP_AUTOFLIP                  %7d\r\n")
                TEXT("DDVP_CONVERT                   %7d\r\n")
                TEXT("DDVP_CROP                      %7d\r\n")
                TEXT("DDVP_IGNOREVBIXCROP            %7d\r\n")
                TEXT("DDVP_INTERLEAVE                %7d\r\n")
                TEXT("DDVP_MIRRORLEFTRIGHT           %7d\r\n")
                TEXT("DDVP_MIRRORUPDOWN              %7d\r\n")
                TEXT("DDVP_OVERRIDEBOBWEAVE          %7d\r\n")
                TEXT("DDVP_PRESCALE                  %7d\r\n")
                TEXT("DDVP_SKIPEVENFIELDS            %7d\r\n")
                TEXT("DDVP_SKIPODDFIELDS             %7d\r\n")
                TEXT("DDVP_SYNCMASTER                %7d\r\n")
                TEXT("DDVP_VBICONVERT                %7d\r\n")
                TEXT("DDVP_VBINOSCALE                %7d\r\n"),
                //"DDVP_VBINOINTERLEAVE         %d\r\n"
                m_sVPInfo.dwOriginX,
                m_sVPInfo.dwOriginY,
                m_sVPInfo.rCrop.left, m_sVPInfo.rCrop.top, m_sVPInfo.rCrop.right, m_sVPInfo.rCrop.bottom,
                m_sVPInfo.dwPrescaleWidth,
                m_sVPInfo.dwPrescaleHeight,
                &szFcc1,
                &szFcc2,
                &szFcc3,
                m_sVPInfo.dwVBIHeight,
                (m_sVPInfo.dwVPFlags&DDVP_AUTOFLIP)>0,
                (m_sVPInfo.dwVPFlags&DDVP_CONVERT)>0,
                (m_sVPInfo.dwVPFlags&DDVP_CROP)>0,
                (m_sVPInfo.dwVPFlags&DDVP_IGNOREVBIXCROP)>0,
                (m_sVPInfo.dwVPFlags&DDVP_INTERLEAVE)>0,
                (m_sVPInfo.dwVPFlags&DDVP_MIRRORLEFTRIGHT)>0,
                (m_sVPInfo.dwVPFlags&DDVP_MIRRORUPDOWN)>0,
                (m_sVPInfo.dwVPFlags&DDVP_OVERRIDEBOBWEAVE)>0,
                (m_sVPInfo.dwVPFlags&DDVP_PRESCALE)>0,
                (m_sVPInfo.dwVPFlags&DDVP_SKIPEVENFIELDS)>0,
                (m_sVPInfo.dwVPFlags&DDVP_SKIPODDFIELDS)>0,
                (m_sVPInfo.dwVPFlags&DDVP_SYNCMASTER)>0,
                (m_sVPInfo.dwVPFlags&DDVP_VBICONVERT)>0,
                (m_sVPInfo.dwVPFlags&DDVP_VBINOSCALE)>0
                //m_sVPInfo.dwVPFlags&DDVP_VBINOINTERLEAVE
                );
            break;
        }
    }
    SetDlgItemText( m_hDlg, IDC_VPINFO, buffer);
}

#pragma warning(disable: 4514) // "unreferenced inline function has been removed"
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\ovmprop\ovmprop2.h ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1992 - 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;
//----------------------------------------------------------------------------
// ovmconfigpp.h
//----------------------------------------------------------------------------

#ifndef __OVMPROP2__
#define __OVMPROP2__


// {A73BEEB2-B0B7-11d2-8853-0000F80883E3}
DEFINE_GUID(CLSID_COMPinConfigProperties, 
            0xa73beeb2, 0xb0b7, 0x11d2, 0x88, 0x53, 0x0, 0x0, 0xf8, 0x8, 0x83, 0xe3);


class COMPinConfigProperties : public CBasePropertyPage
{  
public:
    
    static CUnknown * WINAPI CreateInstance(LPUNKNOWN lpunk, HRESULT *phr);
    
private:
    
    COMPinConfigProperties(LPUNKNOWN lpunk, HRESULT *phr);
    STDMETHODIMP GetPageInfo(LPPROPPAGEINFO pPageInfo);
    
    void Reset();
    void OnCommand(HWND hwnd, int id, HWND hwndCtl, UINT codeNotify);
    BOOL OnInitDialog(HWND hwnd, HWND hwndFocus, LPARAM lParam);

    INT_PTR OnReceiveMessage(HWND hwnd,UINT uMsg,WPARAM wParam,LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();
    HRESULT OnApplyChanges();
    HRESULT UpdateColorKey(int id);
    HRESULT ShowColorKey();
    HRESULT UpdateItemInt(int id, DWORD* saved);
    void SetDirty();

    // IMixerPinConfig3 interface
    IMixerPinConfig3        *m_pIMixerPinConfig3;
    
    // IPin interface
    IPin                    *m_pIPin;
    
    // local data
    AM_ASPECT_RATIO_MODE    m_amAspectRatioMode;
    AM_RENDER_TRANSPORT     m_amRenderTransport;
    
    DWORD		    m_dwBlending;
    DWORD		    m_dwZOrder;
    BOOL		    m_fTransparent;
    
    DWORD		    m_dwKeyType;
    DWORD		    m_dwPaletteIndex;
    
    COLORREF	            m_LowColor;
    COLORREF	            m_HighColor;
    
    HWND		    m_hDlg;
    
};  // class COMPinConfigProperties


// {3FF23902-CD1F-11d2-8853-0000F80883E3}
DEFINE_GUID(CLSID_COMVPInfoProperties, 
            0x3ff23902, 0xcd1f, 0x11d2, 0x88, 0x53, 0x0, 0x0, 0xf8, 0x8, 0x83, 0xe3);

class COMVPInfoProperties : public CBasePropertyPage
{
public:
    
    static CUnknown *CreateInstance(LPUNKNOWN pUnk, HRESULT *phr);

private:

    COMVPInfoProperties(LPUNKNOWN lpUnk, HRESULT *phr);

    void SetEditFieldData(int id);
    void Reset();
    void OnCommand(HWND hwnd, int id, HWND hwndCtl, UINT codeNotify);
    BOOL OnInitDialog(HWND hwnd, HWND hwndFocus, LPARAM lParam);

    INT_PTR OnReceiveMessage(HWND hwnd, UINT uMsg, WPARAM wParam, LPARAM lParam);
    HRESULT OnConnect(IUnknown *pUnknown);
    HRESULT OnDisconnect();
    HRESULT OnActivate();

    // IVPInfo interface
    IVPInfo                 *m_pIVPInfo; 
    AMVP_MODE		    m_CurrentMode;
    AMVP_CROP_STATE	    m_CropState;
    DWORD		    m_dwPixelsPerSecond;
    AMVPDATAINFO	    m_VPDataInfo;
    
    // vp data structures
    DDVIDEOPORTINFO 	    m_sVPInfo;
    DDVIDEOPORTBANDWIDTH    m_sBandwidth;
    DDVIDEOPORTCAPS	    m_VPCaps;
    DDVIDEOPORTCONNECT	    m_ddConnectInfo;

    HWND                    m_hDlg;    
};  // class COMVPInfoProperties

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\testmc2\amva.h ===
/*==========================================================================;
 *
 *  Copyright (c) 1997 - 1999  Microsoft Corporation.  All Rights Reserved.
 *
 *  File:	amva.h
 *  Content:	DirectShowMotionComp include file
 *
 ***************************************************************************/


#ifndef __AMVA_INCLUDED__
#define __AMVA_INCLUDED__

#ifdef __cplusplus
extern "C" {
#endif


#define AMVA_TYPEINDEX_OUTPUTFRAME 0xFFFFFFFF

//  Flags for QueryRenderStatus
#define AMVA_QUERYRENDERSTATUSF_READ     0x00000001  // Query for read
                                                     // set this bit to 0
                                                     // if query for update

typedef struct _tag_AMVAUncompBufferInfo
{
 DWORD                   dwMinNumSurfaces;           // IN   min number of surfaces to be allocated
 DWORD                   dwMaxNumSurfaces;           // IN   max number of surfaces to be allocated
 DDPIXELFORMAT           ddUncompPixelFormat;        // IN   pixel format of surfaces to be allocated
} AMVAUncompBufferInfo, *LPAMVAUncompBufferInfo;

typedef struct _tag_AMVAUncompDataInfo
{
    DWORD                   dwUncompWidth;              // [in]     width of uncompressed data
    DWORD                   dwUncompHeight;             // [in]     height of uncompressed data
    DDPIXELFORMAT           ddUncompPixelFormat;        // [in]     pixel-format of uncompressed data
} AMVAUncompDataInfo, *LPAMVAUncompDataInfo;

typedef struct _tag_AMVAInternalMemInfo
{
    DWORD                   dwScratchMemAlloc;          // [out]    amount of scratch memory will the hal allocate for its private use
} AMVAInternalMemInfo, *LPAMVAInternalMemInfo;


typedef struct _tag_AMVACompBufferInfo
{
    DWORD                   dwNumCompBuffers;           // [out]    number of buffers reqd for compressed data
    DWORD                   dwWidthToCreate;            // [out]    Width of surface to create
    DWORD                   dwHeightToCreate;           // [out]    Height of surface to create
    DWORD                   dwBytesToAllocate;          // [out]    Total number of bytes used by each surface
    DDSCAPS2                ddCompCaps;                 // [out]    caps to create surfaces to store compressed data
    DDPIXELFORMAT           ddPixelFormat;              // [out]    fourcc to create surfaces to store compressed data
} AMVACompBufferInfo, *LPAMVACompBufferInfo;


// Note that you are NOT allowed to store any pointer in pMiscData
typedef struct _tag_AMVABeginFrameInfo
{
    DWORD                dwDestSurfaceIndex;         // IN  destination buffer in which to decoding this frame
    LPVOID               pInputData;                 // IN  pointer to misc data
    DWORD                dwSizeInputData;            // IN  size of other misc data to begin frame
    LPVOID               pOutputData;                // OUT pointer to data which the VGA is going to fill
    DWORD                dwSizeOutputData;           // IN  size of data which the VGA is going to fill
} AMVABeginFrameInfo, *LPAMVABeginFrameInfo;

// Note that you are NOT allowed to store any pointer in pMiscData
typedef struct _tag_AMVAEndFrameInfo
{
    DWORD                   dwSizeMiscData;             // [in]     size of other misc data to begin frame
    LPVOID                  pMiscData;                  // [in]     pointer to misc data
} AMVAEndFrameInfo, *LPAMVAEndFrameInfo;

typedef struct _tag_AMVABUFFERINFO
{
    DWORD                   dwTypeIndex;                // [in]    Type of buffer
    DWORD                   dwBufferIndex;              // [in]    Buffer index
    DWORD                   dwDataOffset;               // [in]    offset of relevant data from the beginning of buffer
    DWORD                   dwDataSize;                 // [in]    size of relevant data
} AMVABUFFERINFO, *LPAMVABUFFERINFO;

#ifdef __cplusplus
};
#endif

#endif // _AMVA_INCLUDED
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\testmc2\testva.cpp ===
//==========================================================================;
//
//  THIS CODE AND INFORMATION IS PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
//  KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
//  IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
//  PURPOSE.
//
//  Copyright (c) 1999  Microsoft Corporation.  All Rights Reserved.
//
//--------------------------------------------------------------------------;
#include <atlbase.h>
#include <streams.h>
#include <initguid.h>    // declares DEFINE_GUID to declare an EXTERN_C const.
#include "videoacc.h"
#include "videoacc_i.c"


// 1df2ecf0-75b8-11d2-abf0-00a0c905f375
DEFINE_GUID(CLSID_TESTVA, 0x1df2ecf0, 0x75b8, 0x11d2,
            0xab, 0xf0, 0x00, 0xa0, 0xc9, 0x05, 0xf3, 0x75);

DEFINE_GUID(CLSID_TESTMOCOMP1, 0x1df2ecf0, 0x75b8, 0x11d2,
            0xab, 0xf0, 0x00, 0xa0, 0xc9, 0x05, 0xf3, 0x76);

// 1df2ecf0-75b8-11d2-abf0-00a0c905f376
DEFINE_GUID(CLSID_TESTMOCOMP2, 0x1df2ecf0, 0x75b8, 0x11d2,
            0xab, 0xf0, 0x00, 0xa0, 0xc9, 0x05, 0xf3, 0x77);



const AMOVIESETUP_FILTER sudTestVA = {
    &CLSID_TESTVA,                  // clsID
    L"Test Video Acceleration",     // strName
    MERIT_DO_NOT_USE,               // dwMerit
    0,                              // nPins
    NULL                            // lpPin
};



#if !defined(AMTRACE)
#if defined(DEBUG)
class CAutoTrace
{
private:
    const TCHAR* _szBlkName;
    const int _level;
    static const TCHAR _szEntering[];
    static const TCHAR _szLeaving[];
public:
    CAutoTrace(const TCHAR* szBlkName, const int level = 2)
        : _szBlkName(szBlkName), _level(level)
    {DbgLog((LOG_TRACE, _level, _szEntering, _szBlkName));}

    ~CAutoTrace()
    {DbgLog((LOG_TRACE, _level, _szLeaving, _szBlkName));}
};

const TCHAR CAutoTrace::_szEntering[] = TEXT("Entering: %s");
const TCHAR CAutoTrace::_szLeaving[]  = TEXT("Leaving: %s");

#define AMTRACE(_x_) CAutoTrace __trace _x_
#else
#define AMTRACE(_x_)
#endif
#endif



// -------------------------------------------------------------------------
// CTestVAOutputPin
// -------------------------------------------------------------------------
//
class CTestVAOutputPin :
    public CTransformOutputPin,
    public IAMVideoAcceleratorNotify
{
public:
    CTestVAOutputPin(CTransformFilter *pTransformFilter, HRESULT * phr);
    DECLARE_IUNKNOWN

    // override to expose IAMVideoAcceleratorNotify
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void **ppv);

    // IAMVideoAcceleratorNotify methods

    // get information necessary to allocate uncompressed data buffers
    // which is not part of the mediatype format (like how many buffers to
    // allocate etc)
    STDMETHODIMP GetUncompSurfacesInfo(
        /*[in]*/ const GUID *pGuid,
        /*[in] [out]*/ LPAMVAUncompBufferInfo pUncompBufferInfo);

    // set information regarding allocated uncompressed data buffers
    STDMETHODIMP SetUncompSurfacesInfo(
        /*[in]*/ DWORD dwActualUncompSurfacesAllocated);

    // get information necessary to create video accelerator object.
    // It is the caller's responsibility to call CoTaskMemFree() on *ppMiscData
    STDMETHODIMP GetCreateVideoAcceleratorData(
        /*[in]*/ const GUID *pGuid,
        /*[out]*/ LPDWORD pdwSizeMiscData,
        /*[out]*/ LPVOID *ppMiscData);

private:
    //  Save format information ??
};


// -------------------------------------------------------------------------
// CTestVA
// -------------------------------------------------------------------------
//
class CTestVA :
    public CTransformFilter
{
private:
    int     m_iFrameNumber;

    static DWORD m_dwNumMCGuidsSupported;
    static LPCGUID m_pMCGuidsSupported[];

public:
    // Constructor
    CTestVA(TCHAR *tszName, LPUNKNOWN punk, HRESULT *phr);
    ~CTestVA();

    static CUnknown * WINAPI CreateInstance(LPUNKNOWN punk, HRESULT *phr);

    HRESULT Transform(IMediaSample *pIn, IMediaSample *pOut);
    HRESULT StartStreaming();
    HRESULT CheckInputType(const CMediaType *mtIn);
    HRESULT CheckTransform(const CMediaType *mtIn,const CMediaType *mtOut);
    HRESULT GetMediaType(int iPosition, CMediaType *pMediaType);
    HRESULT DecideBufferSize(IMemAllocator *pAlloc,
                             ALLOCATOR_PROPERTIES *pProperties);
    //
    // --- Override CTransform's GetPin to use our own pin classes
    //
    CBasePin *GetPin(int n);
};



// -------------------------------------------------------------------------
// Here is the list of MoComp GUID's that your filter supports.
//
// -------------------------------------------------------------------------
//
LPCGUID CTestVA::m_pMCGuidsSupported[] = {
    &CLSID_TESTMOCOMP1,
    &CLSID_TESTMOCOMP2
};
DWORD CTestVA::m_dwNumMCGuidsSupported = 2;


// -------------------------------------------------------------------------
// CTestVAOutputPin::CTestVAOutputPin
//
// Constructor
// -------------------------------------------------------------------------
//
CTestVAOutputPin::CTestVAOutputPin(
    CTransformFilter *pTransformFilter,
    HRESULT * phr
    ) :
    CTransformOutputPin(NAME("CTestVAOutputPin"), pTransformFilter,
                        phr, L"Test VA Output Pin")
{
    AMTRACE((TEXT("CTestVAOutputPin::CTestVAOutputPin")));
}


// -------------------------------------------------------------------------
// CTestVAOutputPin::NonDelegatingQueryInterface
//
// override to expose IAMVideoAcceleratorNotify
// -------------------------------------------------------------------------
//
STDMETHODIMP
CTestVAOutputPin::NonDelegatingQueryInterface(
    REFIID riid,
    void **ppv
    )
{
    AMTRACE((TEXT("CTestVAOutputPin::NonDelegatingQueryInterface")));

    if (riid == IID_IAMVideoAcceleratorNotify)
    {
        return GetInterface((IAMVideoAcceleratorNotify *)this, ppv);
    }
    else
    {
        return CTransformOutputPin::NonDelegatingQueryInterface(riid, ppv);
    }
}



// -------------------------------------------------------------------------
// CTestVAOutputPin::GetUncompSurfacesInfo
//
// get information necessary to allocate uncompressed data buffers
// which is not part of the mediatype format (like how many buffers
//  to allocate etc)
// -------------------------------------------------------------------------
//
STDMETHODIMP
CTestVAOutputPin::GetUncompSurfacesInfo(
    /*[in]*/ const GUID *pGuid,
    /*[in] [out]*/ LPAMVAUncompBufferInfo pUncompBufferInfo
    )
{
    AMTRACE((TEXT("CTestVAOutputPin::GetUncompSurfacesInfo")));

    /*  Ask the decoder for a suitable format */
    IAMVideoAccelerator *pAccel;
    HRESULT hr = VFW_E_NOT_CONNECTED;

    if (GetConnected())
    {
        AMTRACE((TEXT("GetUncompSurfacesInfo - Query IAMVideoAccelerator")));

        hr = GetConnected()->QueryInterface(IID_IAMVideoAccelerator,
                                            (void **)&pAccel);
        if (SUCCEEDED(hr))
        {
            DWORD dwFormats = 10;

            /*  Find out how many there are (test) */
            hr = pAccel->GetUncompFormatsSupported(pGuid, &dwFormats, NULL);

            /*  Just find the first uncomp buffer info we like */
            dwFormats = 1;
            pUncompBufferInfo->dwMinNumSurfaces = 4;
            pUncompBufferInfo->dwMaxNumSurfaces = 5;

            hr = pAccel->GetUncompFormatsSupported(pGuid, &dwFormats,
                    &pUncompBufferInfo->ddUncompPixelFormat);

            if (S_OK == hr)
            {
                if (dwFormats != 1)
                {
                    hr = E_INVALIDARG;
                }
            }
            pAccel->Release();
        }
    }

    return hr;
}

// -------------------------------------------------------------------------
// CTestVAOutputPin::SetUncompSurfacesInfo
//
// set information regarding allocated uncompressed data buffers
// -------------------------------------------------------------------------
//
STDMETHODIMP
CTestVAOutputPin::SetUncompSurfacesInfo(
    /*[in]*/ DWORD dwActualUncompSurfacesAllocated)
{
    return S_OK;
}


// -------------------------------------------------------------------------
// CTestVAOutputPin::GetCreateVideoAcceleratorData
//
// get information necessary to create video accelerator object.
// It is the caller's responsibility to call CoTaskMemFree() on *ppMiscData
// -------------------------------------------------------------------------
//
STDMETHODIMP
CTestVAOutputPin::GetCreateVideoAcceleratorData(
    /*[in]*/ const GUID *pGuid,
    /*[out]*/ LPDWORD pdwSizeMiscData,
    /*[out]*/ LPVOID *ppMiscData)
{
    *pdwSizeMiscData = 0;
    *ppMiscData = NULL;
    return S_OK;
}


// -------------------------------------------------------------------------
// CTestVA::CTestVA
//
// Constructor
// -------------------------------------------------------------------------
//
CTestVA::CTestVA(TCHAR *tszName, LPUNKNOWN punk, HRESULT *phr) :
    CTransformFilter(tszName, punk, CLSID_TESTVA)
{
}

// -------------------------------------------------------------------------
// CTestVA::~CTestVA
//
// Destructor
// -------------------------------------------------------------------------
//
CTestVA::~CTestVA()
{
}


// -------------------------------------------------------------------------
// CTestVA::CreateInstance
//
// Provide the way for COM to create a CTestVA object
// -------------------------------------------------------------------------
//
CUnknown* WINAPI
CTestVA::CreateInstance(
    LPUNKNOWN punk,
    HRESULT *phr
    )
{
    CTestVA *pNewObject = new CTestVA(NAME("CTestVA"), punk, phr);
    if (pNewObject == NULL)
    {
        *phr = E_OUTOFMEMORY;
    }
    return pNewObject;

}

//
// --- Override CTransform's GetPin to use our own pin classes
//

// -------------------------------------------------------------------------
// CTestVA::GetPin
//
// Override CTransformFilter's GetPin to create our own output pin
// -------------------------------------------------------------------------
//
CBasePin *
CTestVA::GetPin(
    int n
    )
{
    AMTRACE((TEXT("Entering CTestVA::GetPin")));

    /* Create the single input and output pins */

    if (m_pInput == NULL || m_pOutput == NULL)
    {

        HRESULT hr = S_OK;

        m_pInput = new CTransformInputPin(NAME("CTransformInputPin"),
                                          this, &hr, L"Input");

        // a failed return code should delete the object

        ASSERT(SUCCEEDED(hr));
        if (m_pInput == NULL)
        {
            return NULL;
        }

        m_pOutput = new CTestVAOutputPin(this,       // Owner filter
                                         &hr);       // Result code

        // failed return codes cause both objects to be deleted

        ASSERT(SUCCEEDED(hr));
        if (m_pOutput == NULL)
        {
            delete m_pInput;
            m_pInput = NULL;
            return NULL;
        }
    }

    /* Find which pin is required */

    switch (n)
    {
    case 0:
        return m_pInput;
    case 1:
        return m_pOutput;
    }

    return NULL;
}


// -------------------------------------------------------------------------
// CTestVA::StartStreaming
//
//
// -------------------------------------------------------------------------
//
HRESULT
CTestVA::StartStreaming()
{
    AMTRACE((TEXT("CTestVA::StartStreaming")));

    m_iFrameNumber = 0;
    return CTransformFilter::StartStreaming();
}

// -------------------------------------------------------------------------
// CTestVA::Transform
//
//
// -------------------------------------------------------------------------
//
HRESULT
CTestVA::Transform(
    IMediaSample *pIn,
    IMediaSample *pOut
    )
{

    AMTRACE((TEXT("CTestVA::Transform")));

    /*  Do a BeginFrame, EndFrame and DeliverFrame */
    IAMVideoAccelerator *pAccel;
    HRESULT hr = S_OK;
    hr = m_pOutput->GetConnected()->QueryInterface(IID_IAMVideoAccelerator,
                                                   (void **)&pAccel);

    if (SUCCEEDED(hr))
    {
        DWORD dwDestFrame, dwDisplayFrame;
        if (m_iFrameNumber % 3 == 0)
        {
            //  I or P
            dwDestFrame = (m_iFrameNumber / 3) & 1;
            dwDisplayFrame = 1 - dwDestFrame;
        }
        else
        {
            dwDestFrame = (m_iFrameNumber % 3) + 1;
            dwDisplayFrame = dwDestFrame;
        }

        DbgLog((LOG_TRACE, 5, TEXT("CTestVA::Transform - call BeginFrame")));
        AMVABeginFrameInfo BeginFrameInfo;

        ZeroMemory(&BeginFrameInfo, sizeof(BeginFrameInfo));
        BeginFrameInfo.dwDestSurfaceIndex = dwDestFrame;
        BeginFrameInfo.pInputData = NULL;
        BeginFrameInfo.dwSizeInputData = 0;

        //SURFMCS3 surfMCS3;
        //BeginFrameInfo.pOutputData = &surfMCS3;
        //BeginFrameInfo.dwSizeOutputData = sizeof(SURFMCS3);

        // call it with valid pOutputData
        hr = pAccel->BeginFrame(&BeginFrameInfo);

        //  For a reference frame just copy the next frame into a
        //  type 0 surface
        //  We need to know how many of these there are!
        if (SUCCEEDED(hr) && m_iFrameNumber % 3 == 0)
        {
            LONG lStride;
            PVOID pvBuffer;
            hr = pAccel->GetBuffer(0, (m_iFrameNumber / 3) & 1,
                                   FALSE,
                                   &pvBuffer,
                                   &lStride);
        }

        //  Send 1 buffer on execute
        if (SUCCEEDED(hr))
        {
            AMVABUFFERINFO Info;
            Info.dwTypeIndex = 0;
            Info.dwBufferIndex = dwDestFrame;
            Info.dwDataOffset = 0;
            Info.dwDataSize = 0;  //  Should get from the compbufferinfo
            DbgLog((LOG_TRACE, 5, TEXT("CTestVA::Transform - call Execute")));
            hr = pAccel->Execute(0, NULL, 0, NULL, 0, 1, &Info);
        }

        if (SUCCEEDED(hr))
        {
            AMVAEndFrameInfo EndFrameInfo;
            ZeroMemory(&EndFrameInfo, sizeof(&EndFrameInfo));
            DbgLog((LOG_TRACE, 5, TEXT("CTestVA::Transform - call EndFrame")));
            hr = pAccel->EndFrame(&EndFrameInfo);
        }

        if (SUCCEEDED(hr))
        {
            DbgLog((LOG_TRACE, 5, TEXT("CTestVA::Transform - call DisplayFrame")));
            hr = pAccel->DisplayFrame(dwDisplayFrame, pOut);
        }

        pAccel->Release();
    }

    //  Return S_FALSE to indicate the base classes should not call
    //  Receive() - this is a bit of a hack - probably best to override
    //  Receive() in CTransformFilter.
    if (S_OK == hr)
    {
        hr = S_FALSE;
    }
    return hr;
}

// -------------------------------------------------------------------------
// CTestVA::Transform
//
// Here we allow connection to a compressed MPEG1 video input stream, you
// will specify and validate all your input formats here.
//
// -------------------------------------------------------------------------
//
HRESULT
CTestVA::CheckInputType(
    const CMediaType *pmtIn
    )
{
    AMTRACE((TEXT("CTestVA::CheckInputType")));

    /*  Only support MPEG1 video */
    if (*pmtIn->Subtype() != MEDIASUBTYPE_MPEG1Packet &&
        *pmtIn->Subtype() != MEDIASUBTYPE_MPEG1Payload) {

        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    if (pmtIn->cbFormat < SIZE_VIDEOHEADER + sizeof(DWORD) ||
        pmtIn->cbFormat < SIZE_MPEG1VIDEOINFO((MPEG1VIDEOINFO *)pmtIn->pbFormat)) {

        return VFW_E_TYPE_NOT_ACCEPTED;
    }

    return S_OK;
}

// -------------------------------------------------------------------------
// CTestVA::CheckTransform
//
//
// -------------------------------------------------------------------------
//
HRESULT
CTestVA::CheckTransform(
    const CMediaType *mtIn,
    const CMediaType *mtOut
    )
{
    AMTRACE((TEXT("CTestVA::CheckTransform")));

    if ((mtOut->formattype == FORMAT_VideoInfo))
    {
        BOOL bFound = FALSE;
        for (int i=0; i < int(m_dwNumMCGuidsSupported); i++)
        {
            if (mtOut->subtype == *m_pMCGuidsSupported[i])
            {
                bFound = TRUE;
                break;
            }
        }
        return bFound? S_OK : VFW_E_TYPE_NOT_ACCEPTED;
    }

    return VFW_E_TYPE_NOT_ACCEPTED;
}


// -------------------------------------------------------------------------
// CTestVA::GetMediaType
//
//
// -------------------------------------------------------------------------
//
HRESULT
CTestVA::GetMediaType(
    int iPosition,
    CMediaType *pmt
    )
{
    AMTRACE((TEXT("CTestVA::GetMediaType")));

    BITMAPINFOHEADER *pbmiInput =
    HEADER((VIDEOINFO *)m_pInput->CurrentMediaType().pbFormat);

    if (iPosition >= int(m_dwNumMCGuidsSupported))
        return VFW_S_NO_MORE_ITEMS;


    pmt->majortype = MEDIATYPE_Video;
    pmt->SetSubtype(m_pMCGuidsSupported[iPosition]);
    pmt->formattype = FORMAT_VideoInfo;

    VIDEOINFOHEADER vi;
    ZeroMemory(&vi, sizeof(vi));
    vi.bmiHeader.biSize = sizeof(BITMAPINFOHEADER);
    vi.bmiHeader.biWidth = 720; //pbmiInput->biWidth;
    vi.bmiHeader.biHeight = 480; //pbmiInput->biHeight;

    if (!pmt->SetFormat((BYTE *)&vi, sizeof(vi)))
    {
        return E_OUTOFMEMORY;
    }
    return S_OK;
}


// -------------------------------------------------------------------------
// CTestVA::DecideBufferSize
//
//
// -------------------------------------------------------------------------
//
HRESULT
CTestVA::DecideBufferSize(
    IMemAllocator *pAlloc,
    ALLOCATOR_PROPERTIES *pProperties
    )
{
    AMTRACE((TEXT("CTestVA::DecideBufferSize")));

    ZeroMemory(pProperties, sizeof(*pProperties));
    pProperties->cbAlign = 1;
    pProperties->cBuffers = 1;
    pProperties->cbBuffer = 8;
    ALLOCATOR_PROPERTIES Props;
    return pAlloc->SetProperties(pProperties, &Props);
}


// -------------------------------------------------------------------------
// Needed for the CreateInstance mechanism
//
// -------------------------------------------------------------------------
//
CFactoryTemplate g_Templates[]=
{   { L"Test Motion Comp"
        , &CLSID_TESTVA
        , CTestVA::CreateInstance
        , NULL
        , &sudTestVA}
};
int g_cTemplates = sizeof(g_Templates)/sizeof(g_Templates[0]);


// -------------------------------------------------------------------------
// Needed for the CreateInstance mechanism
// exported entry points for registration and
// unregistration (in this case they only call
// through to default implmentations).
//
// -------------------------------------------------------------------------
//
STDAPI
DllRegisterServer()
{
    return AMovieDllRegisterServer2( TRUE );
}

STDAPI
DllUnregisterServer()
{
    return AMovieDllRegisterServer2( FALSE );
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\testmc2\videoacc_i.c ===
/* Copyright (c) 1999  Microsoft Corporation.  All Rights Reserved. */

#pragma warning( disable: 4049 )  /* more than 64k source lines */

/* this ALWAYS GENERATED file contains the IIDs and CLSIDs */

/* link this file in with the server and any clients */


 /* File created by MIDL compiler version 5.02.0235 */
/* at Tue Jun 29 18:46:22 1999
 */
/* Compiler settings for videoacc.idl:
    Oicf (OptLev=i2), W1, Zp8, env=Win32 (32b run), ms_ext, c_ext
    error checks: allocation ref bounds_check enum stub_data 
    VC __declspec() decoration level: 
         __declspec(uuid()), __declspec(selectany), __declspec(novtable)
         DECLSPEC_UUID(), MIDL_INTERFACE()
*/
//@@MIDL_FILE_HEADING(  )

#if !defined(_M_IA64) && !defined(_M_AXP64)

#ifdef __cplusplus
extern "C"{
#endif 


#include <rpc.h>
#include <rpcndr.h>

#ifdef _MIDL_USE_GUIDDEF_

#ifndef INITGUID
#define INITGUID
#include <guiddef.h>
#undef INITGUID
#else
#include <guiddef.h>
#endif

#define MIDL_DEFINE_GUID(type,name,l,w1,w2,b1,b2,b3,b4,b5,b6,b7,b8) \
        DEFINE_GUID(name,l,w1,w2,b1,b2,b3,b4,b5,b6,b7,b8)

#else // !_MIDL_USE_GUIDDEF_

#ifndef __IID_DEFINED__
#define __IID_DEFINED__

typedef struct _IID
{
    unsigned long x;
    unsigned short s1;
    unsigned short s2;
    unsigned char  c[8];
} IID;

#endif // __IID_DEFINED__

#ifndef CLSID_DEFINED
#define CLSID_DEFINED
typedef IID CLSID;
#endif // CLSID_DEFINED

#define MIDL_DEFINE_GUID(type,name,l,w1,w2,b1,b2,b3,b4,b5,b6,b7,b8) \
        const type name = {l,w1,w2,{b1,b2,b3,b4,b5,b6,b7,b8}}

#endif !_MIDL_USE_GUIDDEF_

MIDL_DEFINE_GUID(IID, IID_IAMVideoAcceleratorNotify,0x256A6A21,0xFBAD,0x11d1,0x82,0xBF,0x00,0xA0,0xC9,0x69,0x6C,0x8F);


MIDL_DEFINE_GUID(IID, IID_IAMVideoAccelerator,0x256A6A22,0xFBAD,0x11d1,0x82,0xBF,0x00,0xA0,0xC9,0x69,0x6C,0x8F);

#undef MIDL_DEFINE_GUID

#ifdef __cplusplus
}
#endif



#endif /* !defined(_M_IA64) && !defined(_M_AXP64)*/


#pragma warning( disable: 4049 )  /* more than 64k source lines */

/* this ALWAYS GENERATED file contains the IIDs and CLSIDs */

/* link this file in with the server and any clients */


 /* File created by MIDL compiler version 5.02.0235 */
/* at Tue Jun 29 18:46:22 1999
 */
/* Compiler settings for videoacc.idl:
    Oicf (OptLev=i2), W1, Zp8, env=Win64 (32b run,appending), ms_ext, c_ext
    error checks: allocation ref bounds_check enum stub_data 
    VC __declspec() decoration level: 
         __declspec(uuid()), __declspec(selectany), __declspec(novtable)
         DECLSPEC_UUID(), MIDL_INTERFACE()
*/
//@@MIDL_FILE_HEADING(  )

#if defined(_M_IA64) || defined(_M_AXP64)

#ifdef __cplusplus
extern "C"{
#endif 


#include <rpc.h>
#include <rpcndr.h>

#ifdef _MIDL_USE_GUIDDEF_

#ifndef INITGUID
#define INITGUID
#include <guiddef.h>
#undef INITGUID
#else
#include <guiddef.h>
#endif

#define MIDL_DEFINE_GUID(type,name,l,w1,w2,b1,b2,b3,b4,b5,b6,b7,b8) \
        DEFINE_GUID(name,l,w1,w2,b1,b2,b3,b4,b5,b6,b7,b8)

#else // !_MIDL_USE_GUIDDEF_

#ifndef __IID_DEFINED__
#define __IID_DEFINED__

typedef struct _IID
{
    unsigned long x;
    unsigned short s1;
    unsigned short s2;
    unsigned char  c[8];
} IID;

#endif // __IID_DEFINED__

#ifndef CLSID_DEFINED
#define CLSID_DEFINED
typedef IID CLSID;
#endif // CLSID_DEFINED

#define MIDL_DEFINE_GUID(type,name,l,w1,w2,b1,b2,b3,b4,b5,b6,b7,b8) \
        const type name = {l,w1,w2,{b1,b2,b3,b4,b5,b6,b7,b8}}

#endif !_MIDL_USE_GUIDDEF_

MIDL_DEFINE_GUID(IID, IID_IAMVideoAcceleratorNotify,0x256A6A21,0xFBAD,0x11d1,0x82,0xBF,0x00,0xA0,0xC9,0x69,0x6C,0x8F);


MIDL_DEFINE_GUID(IID, IID_IAMVideoAccelerator,0x256A6A22,0xFBAD,0x11d1,0x82,0xBF,0x00,0xA0,0xC9,0x69,0x6C,0x8F);

#undef MIDL_DEFINE_GUID

#ifdef __cplusplus
}
#endif



#endif /* defined(_M_IA64) || defined(_M_AXP64)*/
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mixer\testmc2\videoacc.h ===
// Copyright (c) 1999  Microsoft Corporation.  All Rights Reserved.

#pragma warning( disable: 4049 )  /* more than 64k source lines */

/* this ALWAYS GENERATED file contains the definitions for the interfaces */


 /* File created by MIDL compiler version 5.02.0235 */
/* at Tue Jun 29 18:46:22 1999
 */
/* Compiler settings for videoacc.idl:
    Oicf (OptLev=i2), W1, Zp8, env=Win32 (32b run), ms_ext, c_ext
    error checks: allocation ref bounds_check enum stub_data 
    VC __declspec() decoration level: 
         __declspec(uuid()), __declspec(selectany), __declspec(novtable)
         DECLSPEC_UUID(), MIDL_INTERFACE()
*/
//@@MIDL_FILE_HEADING(  )


/* verify that the <rpcndr.h> version is high enough to compile this file*/
#ifndef __REQUIRED_RPCNDR_H_VERSION__
#define __REQUIRED_RPCNDR_H_VERSION__ 440
#endif

#include "rpc.h"
#include "rpcndr.h"

#ifndef __RPCNDR_H_VERSION__
#error this stub requires an updated version of <rpcndr.h>
#endif // __RPCNDR_H_VERSION__

#ifndef COM_NO_WINDOWS_H
#include "windows.h"
#include "ole2.h"
#endif /*COM_NO_WINDOWS_H*/

#ifndef __videoacc_h__
#define __videoacc_h__

/* Forward Declarations */ 

#ifndef __IAMVideoAcceleratorNotify_FWD_DEFINED__
#define __IAMVideoAcceleratorNotify_FWD_DEFINED__
typedef interface IAMVideoAcceleratorNotify IAMVideoAcceleratorNotify;
#endif 	/* __IAMVideoAcceleratorNotify_FWD_DEFINED__ */


#ifndef __IAMVideoAccelerator_FWD_DEFINED__
#define __IAMVideoAccelerator_FWD_DEFINED__
typedef interface IAMVideoAccelerator IAMVideoAccelerator;
#endif 	/* __IAMVideoAccelerator_FWD_DEFINED__ */


/* header files for imported files */
#include "unknwn.h"

#ifdef __cplusplus
extern "C"{
#endif 

void __RPC_FAR * __RPC_USER MIDL_user_allocate(size_t);
void __RPC_USER MIDL_user_free( void __RPC_FAR * ); 

/* interface __MIDL_itf_videoacc_0000 */
/* [local] */ 

//
//   The following declarations within the 'if 0' block are dummy typedefs used to make
//   the motncomp.idl file build.  The actual definitions are contained in ddraw.h and amva.h
//
#if 0
typedef void __RPC_FAR *LPVOID;

typedef void __RPC_FAR *LPGUID;

typedef void __RPC_FAR *LPDIRECTDRAWSURFACE;

typedef void __RPC_FAR *LPDDPIXELFORMAT;

typedef void __RPC_FAR *LPAMVAInternalMemInfo;

typedef void AMVAUncompDataInfo;

typedef void __RPC_FAR *LPAMVACompBufferInfo;

typedef void AMVABUFFERINFO;

typedef void AMVAEndFrameInfo;

typedef void __RPC_FAR *LPAMVAUncompBufferInfo;

typedef void AMVABeginFrameInfo;

typedef IUnknown __RPC_FAR *IMediaSample;

#endif
#include <ddraw.h>
#include <amva.h>


extern RPC_IF_HANDLE __MIDL_itf_videoacc_0000_v0_0_c_ifspec;
extern RPC_IF_HANDLE __MIDL_itf_videoacc_0000_v0_0_s_ifspec;

#ifndef __IAMVideoAcceleratorNotify_INTERFACE_DEFINED__
#define __IAMVideoAcceleratorNotify_INTERFACE_DEFINED__

/* interface IAMVideoAcceleratorNotify */
/* [unique][helpstring][uuid][object][local] */ 


EXTERN_C const IID IID_IAMVideoAcceleratorNotify;

#if defined(__cplusplus) && !defined(CINTERFACE)
    
    MIDL_INTERFACE("256A6A21-FBAD-11d1-82BF-00A0C9696C8F")
    IAMVideoAcceleratorNotify : public IUnknown
    {
    public:
        virtual HRESULT STDMETHODCALLTYPE GetUncompSurfacesInfo( 
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [out][in] */ LPAMVAUncompBufferInfo pUncompBufferInfo) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE SetUncompSurfacesInfo( 
            /* [in] */ DWORD dwActualUncompSurfacesAllocated) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE GetCreateVideoAcceleratorData( 
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [out] */ LPDWORD pdwSizeMiscData,
            /* [out] */ LPVOID __RPC_FAR *ppMiscData) = 0;
        
    };
    
#else 	/* C style interface */

    typedef struct IAMVideoAcceleratorNotifyVtbl
    {
        BEGIN_INTERFACE
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *QueryInterface )( 
            IAMVideoAcceleratorNotify __RPC_FAR * This,
            /* [in] */ REFIID riid,
            /* [iid_is][out] */ void __RPC_FAR *__RPC_FAR *ppvObject);
        
        ULONG ( STDMETHODCALLTYPE __RPC_FAR *AddRef )( 
            IAMVideoAcceleratorNotify __RPC_FAR * This);
        
        ULONG ( STDMETHODCALLTYPE __RPC_FAR *Release )( 
            IAMVideoAcceleratorNotify __RPC_FAR * This);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *GetUncompSurfacesInfo )( 
            IAMVideoAcceleratorNotify __RPC_FAR * This,
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [out][in] */ LPAMVAUncompBufferInfo pUncompBufferInfo);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *SetUncompSurfacesInfo )( 
            IAMVideoAcceleratorNotify __RPC_FAR * This,
            /* [in] */ DWORD dwActualUncompSurfacesAllocated);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *GetCreateVideoAcceleratorData )( 
            IAMVideoAcceleratorNotify __RPC_FAR * This,
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [out] */ LPDWORD pdwSizeMiscData,
            /* [out] */ LPVOID __RPC_FAR *ppMiscData);
        
        END_INTERFACE
    } IAMVideoAcceleratorNotifyVtbl;

    interface IAMVideoAcceleratorNotify
    {
        CONST_VTBL struct IAMVideoAcceleratorNotifyVtbl __RPC_FAR *lpVtbl;
    };

    

#ifdef COBJMACROS


#define IAMVideoAcceleratorNotify_QueryInterface(This,riid,ppvObject)	\
    (This)->lpVtbl -> QueryInterface(This,riid,ppvObject)

#define IAMVideoAcceleratorNotify_AddRef(This)	\
    (This)->lpVtbl -> AddRef(This)

#define IAMVideoAcceleratorNotify_Release(This)	\
    (This)->lpVtbl -> Release(This)


#define IAMVideoAcceleratorNotify_GetUncompSurfacesInfo(This,pGuid,pUncompBufferInfo)	\
    (This)->lpVtbl -> GetUncompSurfacesInfo(This,pGuid,pUncompBufferInfo)

#define IAMVideoAcceleratorNotify_SetUncompSurfacesInfo(This,dwActualUncompSurfacesAllocated)	\
    (This)->lpVtbl -> SetUncompSurfacesInfo(This,dwActualUncompSurfacesAllocated)

#define IAMVideoAcceleratorNotify_GetCreateVideoAcceleratorData(This,pGuid,pdwSizeMiscData,ppMiscData)	\
    (This)->lpVtbl -> GetCreateVideoAcceleratorData(This,pGuid,pdwSizeMiscData,ppMiscData)

#endif /* COBJMACROS */


#endif 	/* C style interface */



HRESULT STDMETHODCALLTYPE IAMVideoAcceleratorNotify_GetUncompSurfacesInfo_Proxy( 
    IAMVideoAcceleratorNotify __RPC_FAR * This,
    /* [in] */ const GUID __RPC_FAR *pGuid,
    /* [out][in] */ LPAMVAUncompBufferInfo pUncompBufferInfo);


void __RPC_STUB IAMVideoAcceleratorNotify_GetUncompSurfacesInfo_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAcceleratorNotify_SetUncompSurfacesInfo_Proxy( 
    IAMVideoAcceleratorNotify __RPC_FAR * This,
    /* [in] */ DWORD dwActualUncompSurfacesAllocated);


void __RPC_STUB IAMVideoAcceleratorNotify_SetUncompSurfacesInfo_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAcceleratorNotify_GetCreateVideoAcceleratorData_Proxy( 
    IAMVideoAcceleratorNotify __RPC_FAR * This,
    /* [in] */ const GUID __RPC_FAR *pGuid,
    /* [out] */ LPDWORD pdwSizeMiscData,
    /* [out] */ LPVOID __RPC_FAR *ppMiscData);


void __RPC_STUB IAMVideoAcceleratorNotify_GetCreateVideoAcceleratorData_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);



#endif 	/* __IAMVideoAcceleratorNotify_INTERFACE_DEFINED__ */


#ifndef __IAMVideoAccelerator_INTERFACE_DEFINED__
#define __IAMVideoAccelerator_INTERFACE_DEFINED__

/* interface IAMVideoAccelerator */
/* [unique][helpstring][uuid][object][local] */ 


EXTERN_C const IID IID_IAMVideoAccelerator;

#if defined(__cplusplus) && !defined(CINTERFACE)
    
    MIDL_INTERFACE("256A6A22-FBAD-11d1-82BF-00A0C9696C8F")
    IAMVideoAccelerator : public IUnknown
    {
    public:
        virtual HRESULT STDMETHODCALLTYPE GetVideoAcceleratorGUIDs( 
            /* [out][in] */ LPDWORD pdwNumGuidsSupported,
            /* [out][in] */ LPGUID pGuidsSupported) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE GetUncompFormatsSupported( 
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [out][in] */ LPDWORD pdwNumFormatsSupported,
            /* [out][in] */ LPDDPIXELFORMAT pFormatsSupported) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE GetInternalMemInfo( 
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [in] */ const AMVAUncompDataInfo __RPC_FAR *pamvaUncompDataInfo,
            /* [out][in] */ LPAMVAInternalMemInfo pamvaInternalMemInfo) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE GetCompBufferInfo( 
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [in] */ const AMVAUncompDataInfo __RPC_FAR *pamvaUncompDataInfo,
            /* [out][in] */ LPDWORD pdwNumTypesCompBuffers,
            /* [out] */ LPAMVACompBufferInfo pamvaCompBufferInfo) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE GetInternalCompBufferInfo( 
            /* [out][in] */ LPDWORD pdwNumTypesCompBuffers,
            /* [out] */ LPAMVACompBufferInfo pamvaCompBufferInfo) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE BeginFrame( 
            /* [in] */ const AMVABeginFrameInfo __RPC_FAR *amvaBeginFrameInfo) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE EndFrame( 
            /* [in] */ const AMVAEndFrameInfo __RPC_FAR *pEndFrameInfo) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE GetBuffer( 
            /* [in] */ DWORD dwTypeIndex,
            /* [in] */ DWORD dwBufferIndex,
            /* [in] */ BOOL bReadOnly,
            /* [out] */ LPVOID __RPC_FAR *ppBuffer,
            /* [out] */ LONG __RPC_FAR *lpStride) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE ReleaseBuffer( 
            /* [in] */ DWORD dwTypeIndex,
            /* [in] */ DWORD dwBufferIndex) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE Execute( 
            /* [in] */ DWORD dwFunction,
            /* [in] */ LPVOID lpPrivateInputData,
            /* [in] */ DWORD cbPrivateInputData,
            /* [in] */ LPVOID lpPrivateOutputDat,
            /* [in] */ DWORD cbPrivateOutputData,
            /* [in] */ DWORD dwNumBuffers,
            /* [in] */ const AMVABUFFERINFO __RPC_FAR *pamvaBufferInfo) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE QueryRenderStatus( 
            /* [in] */ DWORD dwTypeIndex,
            /* [in] */ DWORD dwBufferIndex,
            /* [in] */ DWORD dwFlags) = 0;
        
        virtual HRESULT STDMETHODCALLTYPE DisplayFrame( 
            /* [in] */ DWORD dwFlipToIndex,
            /* [in] */ IMediaSample __RPC_FAR *pMediaSample) = 0;
        
    };
    
#else 	/* C style interface */

    typedef struct IAMVideoAcceleratorVtbl
    {
        BEGIN_INTERFACE
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *QueryInterface )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ REFIID riid,
            /* [iid_is][out] */ void __RPC_FAR *__RPC_FAR *ppvObject);
        
        ULONG ( STDMETHODCALLTYPE __RPC_FAR *AddRef )( 
            IAMVideoAccelerator __RPC_FAR * This);
        
        ULONG ( STDMETHODCALLTYPE __RPC_FAR *Release )( 
            IAMVideoAccelerator __RPC_FAR * This);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *GetVideoAcceleratorGUIDs )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [out][in] */ LPDWORD pdwNumGuidsSupported,
            /* [out][in] */ LPGUID pGuidsSupported);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *GetUncompFormatsSupported )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [out][in] */ LPDWORD pdwNumFormatsSupported,
            /* [out][in] */ LPDDPIXELFORMAT pFormatsSupported);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *GetInternalMemInfo )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [in] */ const AMVAUncompDataInfo __RPC_FAR *pamvaUncompDataInfo,
            /* [out][in] */ LPAMVAInternalMemInfo pamvaInternalMemInfo);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *GetCompBufferInfo )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ const GUID __RPC_FAR *pGuid,
            /* [in] */ const AMVAUncompDataInfo __RPC_FAR *pamvaUncompDataInfo,
            /* [out][in] */ LPDWORD pdwNumTypesCompBuffers,
            /* [out] */ LPAMVACompBufferInfo pamvaCompBufferInfo);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *GetInternalCompBufferInfo )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [out][in] */ LPDWORD pdwNumTypesCompBuffers,
            /* [out] */ LPAMVACompBufferInfo pamvaCompBufferInfo);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *BeginFrame )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ const AMVABeginFrameInfo __RPC_FAR *amvaBeginFrameInfo);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *EndFrame )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ const AMVAEndFrameInfo __RPC_FAR *pEndFrameInfo);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *GetBuffer )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ DWORD dwTypeIndex,
            /* [in] */ DWORD dwBufferIndex,
            /* [in] */ BOOL bReadOnly,
            /* [out] */ LPVOID __RPC_FAR *ppBuffer,
            /* [out] */ LONG __RPC_FAR *lpStride);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *ReleaseBuffer )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ DWORD dwTypeIndex,
            /* [in] */ DWORD dwBufferIndex);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *Execute )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ DWORD dwFunction,
            /* [in] */ LPVOID lpPrivateInputData,
            /* [in] */ DWORD cbPrivateInputData,
            /* [in] */ LPVOID lpPrivateOutputDat,
            /* [in] */ DWORD cbPrivateOutputData,
            /* [in] */ DWORD dwNumBuffers,
            /* [in] */ const AMVABUFFERINFO __RPC_FAR *pamvaBufferInfo);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *QueryRenderStatus )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ DWORD dwTypeIndex,
            /* [in] */ DWORD dwBufferIndex,
            /* [in] */ DWORD dwFlags);
        
        HRESULT ( STDMETHODCALLTYPE __RPC_FAR *DisplayFrame )( 
            IAMVideoAccelerator __RPC_FAR * This,
            /* [in] */ DWORD dwFlipToIndex,
            /* [in] */ IMediaSample __RPC_FAR *pMediaSample);
        
        END_INTERFACE
    } IAMVideoAcceleratorVtbl;

    interface IAMVideoAccelerator
    {
        CONST_VTBL struct IAMVideoAcceleratorVtbl __RPC_FAR *lpVtbl;
    };

    

#ifdef COBJMACROS


#define IAMVideoAccelerator_QueryInterface(This,riid,ppvObject)	\
    (This)->lpVtbl -> QueryInterface(This,riid,ppvObject)

#define IAMVideoAccelerator_AddRef(This)	\
    (This)->lpVtbl -> AddRef(This)

#define IAMVideoAccelerator_Release(This)	\
    (This)->lpVtbl -> Release(This)


#define IAMVideoAccelerator_GetVideoAcceleratorGUIDs(This,pdwNumGuidsSupported,pGuidsSupported)	\
    (This)->lpVtbl -> GetVideoAcceleratorGUIDs(This,pdwNumGuidsSupported,pGuidsSupported)

#define IAMVideoAccelerator_GetUncompFormatsSupported(This,pGuid,pdwNumFormatsSupported,pFormatsSupported)	\
    (This)->lpVtbl -> GetUncompFormatsSupported(This,pGuid,pdwNumFormatsSupported,pFormatsSupported)

#define IAMVideoAccelerator_GetInternalMemInfo(This,pGuid,pamvaUncompDataInfo,pamvaInternalMemInfo)	\
    (This)->lpVtbl -> GetInternalMemInfo(This,pGuid,pamvaUncompDataInfo,pamvaInternalMemInfo)

#define IAMVideoAccelerator_GetCompBufferInfo(This,pGuid,pamvaUncompDataInfo,pdwNumTypesCompBuffers,pamvaCompBufferInfo)	\
    (This)->lpVtbl -> GetCompBufferInfo(This,pGuid,pamvaUncompDataInfo,pdwNumTypesCompBuffers,pamvaCompBufferInfo)

#define IAMVideoAccelerator_GetInternalCompBufferInfo(This,pdwNumTypesCompBuffers,pamvaCompBufferInfo)	\
    (This)->lpVtbl -> GetInternalCompBufferInfo(This,pdwNumTypesCompBuffers,pamvaCompBufferInfo)

#define IAMVideoAccelerator_BeginFrame(This,amvaBeginFrameInfo)	\
    (This)->lpVtbl -> BeginFrame(This,amvaBeginFrameInfo)

#define IAMVideoAccelerator_EndFrame(This,pEndFrameInfo)	\
    (This)->lpVtbl -> EndFrame(This,pEndFrameInfo)

#define IAMVideoAccelerator_GetBuffer(This,dwTypeIndex,dwBufferIndex,bReadOnly,ppBuffer,lpStride)	\
    (This)->lpVtbl -> GetBuffer(This,dwTypeIndex,dwBufferIndex,bReadOnly,ppBuffer,lpStride)

#define IAMVideoAccelerator_ReleaseBuffer(This,dwTypeIndex,dwBufferIndex)	\
    (This)->lpVtbl -> ReleaseBuffer(This,dwTypeIndex,dwBufferIndex)

#define IAMVideoAccelerator_Execute(This,dwFunction,lpPrivateInputData,cbPrivateInputData,lpPrivateOutputDat,cbPrivateOutputData,dwNumBuffers,pamvaBufferInfo)	\
    (This)->lpVtbl -> Execute(This,dwFunction,lpPrivateInputData,cbPrivateInputData,lpPrivateOutputDat,cbPrivateOutputData,dwNumBuffers,pamvaBufferInfo)

#define IAMVideoAccelerator_QueryRenderStatus(This,dwTypeIndex,dwBufferIndex,dwFlags)	\
    (This)->lpVtbl -> QueryRenderStatus(This,dwTypeIndex,dwBufferIndex,dwFlags)

#define IAMVideoAccelerator_DisplayFrame(This,dwFlipToIndex,pMediaSample)	\
    (This)->lpVtbl -> DisplayFrame(This,dwFlipToIndex,pMediaSample)

#endif /* COBJMACROS */


#endif 	/* C style interface */



HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_GetVideoAcceleratorGUIDs_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [out][in] */ LPDWORD pdwNumGuidsSupported,
    /* [out][in] */ LPGUID pGuidsSupported);


void __RPC_STUB IAMVideoAccelerator_GetVideoAcceleratorGUIDs_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_GetUncompFormatsSupported_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ const GUID __RPC_FAR *pGuid,
    /* [out][in] */ LPDWORD pdwNumFormatsSupported,
    /* [out][in] */ LPDDPIXELFORMAT pFormatsSupported);


void __RPC_STUB IAMVideoAccelerator_GetUncompFormatsSupported_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_GetInternalMemInfo_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ const GUID __RPC_FAR *pGuid,
    /* [in] */ const AMVAUncompDataInfo __RPC_FAR *pamvaUncompDataInfo,
    /* [out][in] */ LPAMVAInternalMemInfo pamvaInternalMemInfo);


void __RPC_STUB IAMVideoAccelerator_GetInternalMemInfo_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_GetCompBufferInfo_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ const GUID __RPC_FAR *pGuid,
    /* [in] */ const AMVAUncompDataInfo __RPC_FAR *pamvaUncompDataInfo,
    /* [out][in] */ LPDWORD pdwNumTypesCompBuffers,
    /* [out] */ LPAMVACompBufferInfo pamvaCompBufferInfo);


void __RPC_STUB IAMVideoAccelerator_GetCompBufferInfo_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_GetInternalCompBufferInfo_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [out][in] */ LPDWORD pdwNumTypesCompBuffers,
    /* [out] */ LPAMVACompBufferInfo pamvaCompBufferInfo);


void __RPC_STUB IAMVideoAccelerator_GetInternalCompBufferInfo_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_BeginFrame_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ const AMVABeginFrameInfo __RPC_FAR *amvaBeginFrameInfo);


void __RPC_STUB IAMVideoAccelerator_BeginFrame_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_EndFrame_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ const AMVAEndFrameInfo __RPC_FAR *pEndFrameInfo);


void __RPC_STUB IAMVideoAccelerator_EndFrame_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_GetBuffer_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ DWORD dwTypeIndex,
    /* [in] */ DWORD dwBufferIndex,
    /* [in] */ BOOL bReadOnly,
    /* [out] */ LPVOID __RPC_FAR *ppBuffer,
    /* [out] */ LONG __RPC_FAR *lpStride);


void __RPC_STUB IAMVideoAccelerator_GetBuffer_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_ReleaseBuffer_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ DWORD dwTypeIndex,
    /* [in] */ DWORD dwBufferIndex);


void __RPC_STUB IAMVideoAccelerator_ReleaseBuffer_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_Execute_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ DWORD dwFunction,
    /* [in] */ LPVOID lpPrivateInputData,
    /* [in] */ DWORD cbPrivateInputData,
    /* [in] */ LPVOID lpPrivateOutputDat,
    /* [in] */ DWORD cbPrivateOutputData,
    /* [in] */ DWORD dwNumBuffers,
    /* [in] */ const AMVABUFFERINFO __RPC_FAR *pamvaBufferInfo);


void __RPC_STUB IAMVideoAccelerator_Execute_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_QueryRenderStatus_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ DWORD dwTypeIndex,
    /* [in] */ DWORD dwBufferIndex,
    /* [in] */ DWORD dwFlags);


void __RPC_STUB IAMVideoAccelerator_QueryRenderStatus_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);


HRESULT STDMETHODCALLTYPE IAMVideoAccelerator_DisplayFrame_Proxy( 
    IAMVideoAccelerator __RPC_FAR * This,
    /* [in] */ DWORD dwFlipToIndex,
    /* [in] */ IMediaSample __RPC_FAR *pMediaSample);


void __RPC_STUB IAMVideoAccelerator_DisplayFrame_Stub(
    IRpcStubBuffer *This,
    IRpcChannelBuffer *_pRpcChannelBuffer,
    PRPC_MESSAGE _pRpcMessage,
    DWORD *_pdwStubPhase);



#endif 	/* __IAMVideoAccelerator_INTERFACE_DEFINED__ */


/* Additional Prototypes for ALL interfaces */

/* end of Additional Prototypes */

#ifdef __cplusplus
}
#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\auddec.h ===
// Copyright (c) 1995 - 1998  Microsoft Corporation.  All Rights Reserved.
//++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
//	Mediamatics Audio Decoder Interface Specification
//+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#ifndef _MM_AUDIODEC_H_
#define _MM_AUDIODEC_H_

#ifdef __cplusplus
extern "C" {            /* Assume C declarations for C++ */
#endif	/* __cplusplus */

//	Control parameter values
#define DECODE_MONO         0x00000001L  // redundant, unused.
#define DECODE_STEREO       0x00000002L  // 1=allow stereo, 0=force mono.
#define DECODE_LEFT_ONLY    0x00000010L  // decode left  ch only, feed to both outputs
#define DECODE_RIGHT_ONLY   0x00000020L  // decode right ch only, feed to both outputs
#define DECODE_QUARTER      0x00000800L  // quarter bw:  8 sub-bands
#define DECODE_HALF         0x00001000L  // half    bw: 16 sub-bands
#define DECODE_FULL         0x00002000L  // full    bw: 32 sub-bands
#define DECODE_HALF_HIQ     0x00004000L  // half bw, hi quality
#define DECODE_HALF_FULLQ   0x00008000L  // half bw, full quality
#define DECODE_16BIT        0x00010000L  // 1=16bit output, 0=8-bit output.
#define DECODE_8BIT         0x00020000L  // redundant, unused.
#define DECODE_QSOUND       0x00040000L  // enable qsound (no longer used)
#define DECODE_INT          0x00080000L  // enable integer-only mode.
#define DECODE_MMX          0x00100000L  // enable mmx mode (has to in int mode as well).
#define DECODE_AC3          0x10000000L  // Open for AC-3 Decode.
#define DECODE_PRO_LOGIC	0x20000000L	 // Output in ProLogic for AC-3
#define DECODE_MIX_LFE		0x40000000L

#define DECODE_QUART_INT	DECODE_INT	// ## MSMM MERGE CHANGE ##

//  Function return values

#define DECODE_SUCCESS 		0x0000L
#define DECODE_ERR_MEMORY 	0x0001L
#define DECODE_ERR_DATA 	0x0002L
#define DECODE_ERR_PARM 	0x0003L
#define DECODE_ERR_VLDERROR	0x0004L
#define DECODE_ERR_SEVEREVLD	0x0005L
#define DECODE_ERR_MEMALLOC     DECODE_ERR_MEMORY
#define DECODE_ERR_TABLE        0x0081L
#define DECODE_ERR_PICKTABLE    0x0082L
#define DECODE_ERR_NOSYNC       0x0083L
#define DECODE_ERR_LAYER        0x0084L
#define DECODE_ERR_EMPH         0x0085L   // non-fatal error.
#define DECODE_ERR_CRC          0x0086L
#define DECODE_ERR_BADSTATE     0x0087L
#define DECODE_ERR_NBANDS       0x0088L
#define DECODE_ERR_BADHDR       0x0089L
#define DECODE_ERR_INBUFOV      0x008AL
#define DECODE_ERR_NOTENOUGHDATA 0x008BL
#define ERROR_BAD_DLL		0x1000L	    // A Dll had some problem loading/linking

typedef struct tagAudioDecStruct {
			DWORD	dwCtrl ;			// Control parameter
			DWORD	dwNumFrames ;		//	Number of Audio frames to decode
			DWORD	dwOutBuffSize ;	// Size of each buffer in bytes
			DWORD	dwOutBuffUsed ;	// Number of bytes used in each buffer
									// filled in by Decoder
			void *	pOutBuffer;		// Actual pointer to the buffer
			void *	pCmprHead ;			// Pointer to the Compressed Bit Buffer
										//		Head
			void *	pCmprRead ;			// Pointer to the Compressed Bit Read
										//		position
			void *	pCmprWrite ;		// Pointer to the Compressed Bit Write
										// 		position
			DWORD	dwMpegError ;
            DWORD   dwNumOutputChannels;	// input to decoder
			DWORD	dwFrameSize ; 		// output from decoder
			DWORD	dwBitRate ;			// output from decoder
			DWORD	dwSampleRate ;		// output from decoder
			DWORD	dwNumInputChannels ; // output from decoder
} stAudioDecode, * PAUDIODECODE, FAR * LPAUDIODECODE ;

typedef DWORD_PTR HADEC;

#ifdef STD_BACKAPI
#define BACKAPI APIENTRY
#else
#define BACKAPI
#endif

BOOL  BACKAPI CanDoAC3(void);
HADEC BACKAPI OpenAudio(DWORD ctrl);
DWORD BACKAPI CloseAudio(HADEC hDevice);
DWORD BACKAPI ResetAudio(HADEC hDevice, DWORD ctrl);
DWORD BACKAPI DecodeAudioFrame(HADEC hDevice, PAUDIODECODE lpAudioCtrlStruct);
#ifdef __cplusplus
}                       /* End of extern "C" { */
#endif	/* __cplusplus */

#endif  // _MM_AUDIODEC_H_
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\mpegapi.h ===
/*++
Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    mpegapi.h

Abstract:

    This module defines the MPEG driver API.

Author:

    Yi Sun (t-yisun) Aug-17-1994

Revision History:

    Robert Nelson (robertn) Oct-21-1994
        Updated to match first draft of actual spec.

--*/

#ifndef _MPEGAPI_H
#define _MPEGAPI_H

#ifdef  __cplusplus
extern "C" {
#endif

/***********************************************
     type and structure definitions
***********************************************/

typedef DWORDLONG         ULONGLONG; 
typedef HANDLE            HMPEG_DEVICE, *PHMPEG_DEVICE;

#include "mpegcmn.h"

typedef enum _MPEG_STATUS {
    MpegStatusSuccess = 0,
    MpegStatusPending,
    MpegStatusCancelled,
    MpegStatusNoMore,
    MpegStatusBusy,
    MpegStatusUnsupported,
    MpegStatusInvalidParameter,
    MpegStatusHardwareFailure
} MPEG_STATUS, *PMPEG_STATUS;

typedef struct _MPEG_ASYNC_CONTEXT {
    HANDLE      hEvent;
    ULONG       reserved[10];
} MPEG_ASYNC_CONTEXT, *PMPEG_ASYNC_CONTEXT;

// the caller of MpegEnumDevices must allocate
// at least MPEG_MAX_DEVICEID_SIZE bytes

#define MPEG_MAX_DEVICEID_SIZE 25

#ifdef IN_MPEGAPI_DLL
#define MPEGAPI __declspec(dllexport) __stdcall
#else
#define MPEGAPI __declspec(dllimport) __stdcall
#endif

// not part of API, but since the API doesn't support 
// window alignment, we need this for now
// also can be used for the testing purpose

HANDLE MPEGAPI
MpegHandle(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    );

/***********************************************
   functions prototypes
***********************************************/

MPEG_STATUS MPEGAPI 
MpegEnumDevices(
    IN int iAdapterIndex,
    OUT LPTSTR pstrDeviceDescription OPTIONAL,
    IN  UINT uiDescriptionSize,
    OUT LPDWORD pdwDeviceId OPTIONAL,
    OUT PHMPEG_DEVICE phDevice OPTIONAL
    );

MPEG_STATUS MPEGAPI 
MpegOpenDevice(
    IN DWORD dwDeviceId,
    OUT PHMPEG_DEVICE phDevice
    );

MPEG_STATUS MPEGAPI 
MpegCloseDevice(
    IN HMPEG_DEVICE hDevice
    );

MPEG_STATUS MPEGAPI 
MpegQueryDeviceCapabilities(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_CAPABILITY eCapability
    );

MPEG_STATUS MPEGAPI 
MpegWriteData(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_STREAM_TYPE eStreamType,
    IN PMPEG_PACKET_LIST pPacketList,
    IN UINT uiPacketCount,
    IN PMPEG_ASYNC_CONTEXT pAsyncContext OPTIONAL
    );

MPEG_STATUS MPEGAPI 
MpegQueryAsyncResult(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_STREAM_TYPE eStreamType,
    IN PMPEG_ASYNC_CONTEXT pAsyncContext,
    IN BOOL bWait
    );

MPEG_STATUS MPEGAPI 
MpegResetDevice(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    );

MPEG_STATUS MPEGAPI
MpegSetAutoSync(
    IN HMPEG_DEVICE hDevice,
    IN BOOL bEnable
    );

MPEG_STATUS MPEGAPI 
MpegSyncVideoToAudio(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_SYSTEM_TIME systemTimeDelta
    );

MPEG_STATUS MPEGAPI 
MpegQuerySTC(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    OUT PMPEG_SYSTEM_TIME pSystemTime
    );

MPEG_STATUS MPEGAPI 
MpegSetSTC(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN MPEG_SYSTEM_TIME systemTime
    );
    
MPEG_STATUS MPEGAPI 
MpegPlay(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    );

MPEG_STATUS MPEGAPI 
MpegPlayTo(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN MPEG_SYSTEM_TIME systemTime,
    IN PMPEG_ASYNC_CONTEXT pAsyncContext OPTIONAL
    );

MPEG_STATUS MPEGAPI 
MpegPause(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    );

MPEG_STATUS MPEGAPI 
MpegStop(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    );
    
MPEG_STATUS MPEGAPI 
MpegQueryDeviceState(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    OUT PMPEG_DEVICE_STATE pCurrentDeviceState
    );

MPEG_STATUS MPEGAPI 
MpegQueryInfo(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN MPEG_INFO_ITEM eInfoItem,
    OUT PULONG pulValue
    );


MPEG_STATUS MPEGAPI 
MpegClearVideoBuffer(
    IN HMPEG_DEVICE hDevice
    );

MPEG_STATUS MPEGAPI 
MpegSetOverlayMode(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_OVERLAY_MODE eNewMode
    );

MPEG_STATUS MPEGAPI 
MpegSetOverlayMask(
    IN HMPEG_DEVICE hDevice,
    IN ULONG ulHeight,
    IN ULONG ulWidth,
    IN ULONG ulOffset,
    IN ULONG ulLineLength,
    IN PUCHAR pMaskBits 
    );

MPEG_STATUS MPEGAPI 
MpegQueryOverlayKey(
    IN HMPEG_DEVICE hDevice,
    OUT COLORREF *prgbColor,
    OUT COLORREF *prgbMask
    );

MPEG_STATUS MPEGAPI 
MpegSetOverlayKey(
    IN HMPEG_DEVICE hDevice,
    IN COLORREF rgbColor,
    IN COLORREF rgbMask
    );

MPEG_STATUS MPEGAPI 
MpegSetOverlaySource(
    IN HMPEG_DEVICE hDevice,
    IN LONG lX,
    IN LONG lY,
    IN LONG lWidth,
    IN LONG lHeight
    );

MPEG_STATUS MPEGAPI 
MpegSetOverlayDestination(
    IN HMPEG_DEVICE hDevice,
    IN LONG lX,
    IN LONG lY,
    IN LONG lWidth,
    IN LONG lHeight
    );

MPEG_STATUS MPEGAPI 
MpegQueryAttributeRange(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_ATTRIBUTE eAttribute,
    OUT PLONG plMinimum,
    OUT PLONG plMaximum,
    OUT PLONG plStep
    );

MPEG_STATUS MPEGAPI 
MpegQueryAttribute(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_ATTRIBUTE eAttribute,
    OUT PLONG plValue
    );

MPEG_STATUS MPEGAPI 
MpegSetAttribute(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_ATTRIBUTE eAttribute,
    IN LONG lValue
    );

#ifdef  __cplusplus
}
#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\id3.h ===
// 


//   ID3 parsing stuff - see www.id3.org
//   

//  Make a class for name scoping
class CID3Parse {

public:
    /*  Only support versions 2 and 3 */
    BOOL static IsV2(const BYTE *pbData)
    {
        return (MAKEFOURCC(pbData[0], pbData[1], pbData[2], 0) == MAKEFOURCC('I', 'D', '3', 0) &&
            0 == (*(UNALIGNED DWORD *)(pbData + 6) & 0x80808080)) &&
            /*  Major versions 2 and 3 */
            (MajorVersion(pbData) == 2 || MajorVersion(pbData) == 3);
    }
    
    LONG static TotalLength(const BYTE *pbData)
    {
        return ((LONG)pbData[6] << 21) +
               ((LONG)pbData[7] << 14) +
               ((LONG)pbData[8] << 7)  +
                (LONG)pbData[9]
               + ID3_HEADER_LENGTH;
    }

    /*  de'unsynchronize and return the total length */
    LONG static DeUnSynchronize(const BYTE *pbIn, PBYTE pbOut)
    {
        LONG lID3 = TotalLength(pbIn);
    
        if (Flags(pbIn) & ID3_FLAGS_UNSYNCHRONIZED) {
            /*  Copy and perform de-'unsynchronization' 
                of the header
            */
            BYTE bLast = 0x00;
            PBYTE pbDest = pbOut;
            while (lID3--) {
                /*  ff 00 ==> ff */
                if (bLast == 0xFF && *pbIn == 0x00) {
                    bLast = *pbIn++;
                } else {
                    bLast = *pbIn++;
                    *pbDest++ = bLast;
                }
            }
            /*  Now fix up the length and clear the unsync flag */
            pbOut[5] &= ~ID3_FLAGS_UNSYNCHRONIZED;
            LONG lNew = (LONG)(pbDest - pbOut);
    
            /*  Bits 27-21 */
            pbOut[6] = (BYTE)(lNew >> 21);
            /*  Bits 20-14 */
            pbOut[7] = (BYTE)((lNew >> 14) & 0x7F);
            /*  Bits 13-7 */
            pbOut[8] = (BYTE)((lNew >> 7) & 0x7F);
            /*  Bits 6-0 */
            pbOut[9] = (BYTE)(lNew & 0x7F);
            return lNew;
        } else {
            CopyMemory(pbOut, pbIn, lID3);
            return lID3;
        }
    }

    static HRESULT GetField(const BYTE *pbID3, CBasicParse::Field field, BSTR *str)
    {
        /*  Do type 1 differently */
        if (pbID3[0] == 'T') {
            const BYTE *pbField;

            switch (field) {
            case CBasicParse::Author:
            case CBasicParse::Artist:
                pbField = &pbID3[33];
                break;

            case CBasicParse::Copyright:
                return E_NOTIMPL;

            case CBasicParse::Title:
            case CBasicParse::Description:
                pbField = &pbID3[3];
                break;
            }
            return GetAnsiString(pbField, 30, str);
        }

        /*  Other types */

        DWORD dwID;

        if (MajorVersion(pbID3) == 2) {
            switch (field) {
            case CBasicParse::Author:
                dwID = MAKEFOURCC('T', 'C', 'M', 0);
                break;

            case CBasicParse::Artist:
                dwID = MAKEFOURCC('T', 'P', '1', 0);
                break;

            case CBasicParse::Copyright:
                dwID = MAKEFOURCC('T', 'C', 'R', 0);
                break;

            case CBasicParse::Title:
            case CBasicParse::Description:
                dwID = MAKEFOURCC('T', 'T', '2', 0);
                break;
            }
        } else {
            switch (field) {
            case CBasicParse::Artist:
                dwID = MAKEFOURCC('T', 'P', 'E', '1');
                break;

            case CBasicParse::Author:
                dwID = MAKEFOURCC('T', 'C', 'O', 'M');
                break;

            case CBasicParse::Copyright:
                dwID = MAKEFOURCC('T', 'C', 'O', 'P');
                break;

            case CBasicParse::Title:
            case CBasicParse::Description:
                dwID = MAKEFOURCC('T', 'I', 'T', '2');
                break;
            }
        }

        /*  Now pull out the data */
        HRESULT hr = GetFrameString(pbID3, dwID, str);
        if (SUCCEEDED(hr) && field == CBasicParse::Copyright) {
            /*  Add Copyright (c) */
            WCHAR wszNew[1000];
#ifndef UNICODE
            CHAR szCopyright[100];
            int iStr = LoadString(g_hInst, IDS_COPYRIGHT, szCopyright, 100);
            if (0 != iStr) {
                iStr = MultiByteToWideChar(
                           CP_ACP, 
                           MB_PRECOMPOSED,
                           szCopyright,
                           -1,
                           wszNew,
                           100) - 1;
            }
#else
            int iStr = LoadString(g_hInst, IDS_COPYRIGHT, wszNew, 100);
#endif
            if (iStr != 0) {
                lstrcpyWInternal(wszNew + iStr, *str);
                hr = SysReAllocString(str, wszNew);
            }
        }
        return hr;
    }

private:

    enum {
        ID3_HEADER_LENGTH          = 10,
        ID3_EXTENDED_HEADER_LENGTH = 10,
    
    
        //  ID3 flags
        ID3_FLAGS_UNSYNCHRONIZED   = 0x80,
        ID3_FLAGS_EXTENDED_HEADER  = 0x40,

        // keep sizes down
        MAX_TEXT                   = 500
    };


    static BYTE MajorVersion(const BYTE *pbData)
    {
        return pbData[3];
    }
    
    static BYTE Flags(const BYTE *pbData)
    {
        return pbData[5];
    }
    
    static LONG ExtendedHeaderLength(const BYTE *pbData)
    {
        /*  Only if == version == 3 and bit set */
        if (MajorVersion(pbData) == 3 && 
            (Flags(pbData) & ID3_FLAGS_EXTENDED_HEADER)) {
            return 10 + GetLength(pbData + ID3_HEADER_LENGTH + 6);
        } else {
            return 0;
        }
    }
    
    DWORD static GetLength(const BYTE *pbData)
    {
        return (((DWORD)pbData[0] << 24) +
                ((DWORD)pbData[1] << 16) +
                ((DWORD)pbData[2] << 8 ) +
                 (DWORD)pbData[3]);
    }
    

    DWORD static GetLength3(const BYTE *pbData)
    {
        return (((DWORD)pbData[0] << 16) +
                ((DWORD)pbData[1] << 8 ) +
                 (DWORD)pbData[2]);
    }
    
    static LONG FrameLength(const BYTE *pbID3)
    {
        BYTE bVersion = MajorVersion(pbID3);
        ASSERT(bVersion == 2 || bVersion == 3);
        return bVersion == 2 ? 6 : 10;
    }
    
    /*  ID3 stuff - given a frame id returns
        pointer to the frame and length or NULL if frame id not found
    
        Assumes not unsynchronized
    */
    static const BYTE *GetFrame(
        const BYTE *pbID3,
        DWORD dwFrameId, 
        LONG *plLength
    )
    {
        /*  Scan the header for the frame data */
        if (pbID3) {
            ASSERT(0 == (Flags(pbID3) & ID3_FLAGS_UNSYNCHRONIZED));

            /*  Ignore compressed content */
            if (Flags(pbID3) & 0x40) {
                return NULL;
            }

            LONG lID3 = TotalLength(pbID3);
        
            /*  Different for V2 and V3 */
            LONG lPos = 10;
    
            if (MajorVersion(pbID3) == 2) {
                /*  Loop until the next header doesn't fit */
                while ( (lPos + 6) < lID3 ) {
                    /* Extract the frame length (including header) */
                    LONG lLength = 6 + GetLength3(pbID3 + lPos + 3);
                    DWORD dwID = pbID3[lPos] + 
                                 (pbID3[lPos + 1] << 8) +
                                 (pbID3[lPos + 2] << 16);
                    if (dwID == dwFrameId) {
                        if ( (lPos + lLength) <= lID3 ) {
                            *plLength = lLength - 6;
                            return pbID3 + lPos + 6;
                        }
                    }
                    lPos += lLength;
                }
            } else {
                ASSERT(MajorVersion(pbID3) == 3);
    
                /*  Skip any extended header */
                lPos += ExtendedHeaderLength(pbID3);
        
                /*  Loop until the next header doesn't fit */
                while ( (lPos + 10) < lID3 ) {
                    /* Extract the frame length (including header) */
                    LONG lLength = 10 + GetLength(pbID3 + lPos + 4);
                    if (*(UNALIGNED DWORD *)(pbID3 + lPos) == dwFrameId) {
                        if ( (lPos + lLength) <= lID3 ) {
                            /*  Ignore compressed or encrypted frames 
                                and reject 0 length or huge
                            */
                            if (pbID3[lPos + 9] & 0xC0) {
                                return NULL;
                            }
                            *plLength = lLength - 10;
                            return pbID3 + lPos + 10;
                        }
                    }
                    lPos += lLength;
                }
            }
        }
        return NULL;
    }
    
    /*  Extract a BSTR for a given tag type */
    
    /*  Grab the string from the ID3 frame and make a BSTR */
    static HRESULT GetFrameString(const BYTE *pbID3, DWORD dwId, BSTR *str)
    {
        LONG lFrame;
        const BYTE *pbFrame = GetFrame(pbID3, dwId, &lFrame);

        if (pbFrame && lFrame <= MAX_TEXT) {
            LPWSTR pwszCopy;

            /*  Handle UNICODE, non-UNICODE and byte order */
            if (pbFrame[0] == 0x01) {

                BOOL bSwap = TRUE;
                if (pbFrame[0] == 0xFF && pbFrame[1] == 0xFE) {
                    bSwap = FALSE;
                }

                /*  Make a copy for WORD alignment, swapping, and 
                    NULL termination

                    Same size -1 because 
                    -  Ignore UNICODE indicator
                    -  we'll ignore the Unicode BOM
                    -  but we may need to NULL terminate
                */
                PBYTE pbCopy = (PBYTE)_alloca(lFrame);

                /*  This is meant to be UNICODE - get length by
                    scanning for NULL
                */
                if (lFrame < 3) {
                    return E_NOTIMPL;
                }
                pbFrame += 3;
                lFrame -= 3;
                LONG lPos = 0; /*  Don't need the BOM or 1st char */
                while (lPos + 1 < lFrame) {
                    if (pbFrame[lPos] == 0 && pbFrame[lPos+1] == 0) {
                        break;
                    }
                    if (bSwap) {
                        pbCopy[lPos] = pbFrame[lPos + 1];
                        pbCopy[lPos + 1] = pbFrame[lPos];
                    } else {
                        pbCopy[lPos] = pbFrame[lPos];
                        pbCopy[lPos+1] = pbFrame[lPos+1];
                    }
                    lPos += 2;
                }
                pbCopy[lPos] = 0;
                pbCopy[lPos + 1] = 0;

                pwszCopy = (LPWSTR)pbCopy;

                *str = SysAllocString((const OLECHAR *)pwszCopy);
                if (*str == NULL) {
                    return E_OUTOFMEMORY;
                }
                return S_OK;
            } else {

                /*  Encoding type must be 0 or 1 */
                if (pbFrame[0] != 0) {
                    return E_NOTIMPL;
                }

                /*  Skip encoding type byte */
                pbFrame++;
                lFrame--;

                return GetAnsiString(pbFrame, lFrame, str);
            }
        }
        return E_NOTIMPL;
    } 

    static HRESULT GetAnsiString(const BYTE *pbData, LONG lLen, BSTR *str)
    {
        LPWSTR pwszCopy = (LPWSTR)_alloca((lLen + 1) * sizeof(WCHAR));
        int cch = MultiByteToWideChar(
                      CP_ACP,
                      MB_PRECOMPOSED, /* Is this right? */
                      (LPCSTR)pbData,
                      lLen,
                      pwszCopy,
                      lLen);

        /* make sure it's NULL terminated */
        pwszCopy[cch] = 0;

        /* Also remove trailing spaces */
        while (cch--) {
            if (pwszCopy[cch] == L' ') {
                pwszCopy[cch] = 0;
            } else {
                break;
            }
        }

        *str = SysAllocString((const OLECHAR *)pwszCopy);
        if (*str == NULL) {
            return E_OUTOFMEMORY;
        }
        return S_OK;
    }
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\mpegcmn.h ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    mpeg.h

Abstract:

    These are the definitions which are common to the MPEG API and
    Port/Miniport interfaces.

Author:

    Robert Nelson (robertn) 03-NOV-94

Revision History:

--*/
#ifndef _MPEGCMN_H
#define _MPEGCMN_H

typedef ULONGLONG         MPEG_SYSTEM_TIME, *PMPEG_SYSTEM_TIME;

//****************************************************************************
// Enumerated Constants
//****************************************************************************

typedef enum _MPEG_ATTRIBUTE {
    MpegAttrAudioBass =     0,
    MpegAttrAudioChannel,
    MpegAttrAudioMode,
    MpegAttrAudioTreble,
    MpegAttrAudioVolumeLeft,
    MpegAttrAudioVolumeRight,
    MpegAttrMaximumAudioAttribute,

    MpegAttrVideoBrightness  =400,
    MpegAttrVideoChannel,
    MpegAttrVideoContrast,
    MpegAttrVideoHue,
    MpegAttrVideoMode,
    MpegAttrVideoSaturation,
    MpegAttrVideoAGC,
    MpegAttrVideoClamp,
    MpegAttrVideoCoring,
    MpegAttrVideoGain,
    MpegAttrVideoGenLock,
    MpegAttrVideoSharpness,
    MpegAttrVideoSignalType,
    MpegAttrMaximumVideoAttribute,

    MpegAttrOverlayXOffset = 800,
    MpegAttrOverlayYOffset,
    MpegAttrMaximumOverlayAttribute,

} MPEG_ATTRIBUTE, *PMPEG_ATTRIBUTE;

#define MPEG_OEM_ATTRIBUTE(a) ((MPEG_ATTRIBUTE)(((unsigned)(a))+0x00008000))

    // MpegAttrVideoMode flags
#define MPEG_ATTRIBUTE_AUDIO_MONO           0
#define MPEG_ATTRIBUTE_AUDIO_STEREO         1
#define MPEG_ATTRIBUTE_AUDIO_SPATIAL_STEREO 2
#define MPEG_ATTRIBUTE_AUDIO_PSEUDO_STEREO  3

    // MpegAttrVideoMode flags
#define MPEG_ATTRIBUTE_VIDEO_NTSC       0
#define MPEG_ATTRIBUTE_VIDEO_PAL        1
#define MPEG_ATTRIBUTE_VIDEO_SECAM      2
#define MPEG_ATTRIBUTE_VIDEO_AUTO       3

    // MpegAttrVideoGenLock type
#define MPEG_ATTRIBUTE_VIDEO_GEN_LOCK_TV  0
#define MPEG_ATTRIBUTE_VIDEO_GEN_LOCK_VTR 1

    // MpegAttrVideoSignalType type
#define MPEG_ATTRIBUTE_VIDEO_SIGNAL_COMPOSITE  0
#define MPEG_ATTRIBUTE_VIDEO_SIGNAL_SVHS       1

    // MpegAttrAudioChannel Mpeg channel
    //  auxiliary channels are mini-port specific
#define MPEG_ATTRIBUTE_AUDIO_CHANNEL_MPEG  0

    // MpegAttrVideoChannel Mpeg channel
    //  auxiliary channels are mini-port specific
#define MPEG_ATTRIBUTE_VIDEO_CHANNEL_MPEG  0


typedef enum _MPEG_DEVICE_TYPE {
    MpegCombinedDevice = 1,
    MpegAudioDevice,
    MpegVideoDevice,
    MpegOverlayDevice
} MPEG_DEVICE_TYPE, *PMPEG_DEVICE_TYPE;

typedef enum _MPEG_STREAM_TYPE {
    MpegSystemStream = 1,
    MpegAudioStream,
    MpegVideoStream
} MPEG_STREAM_TYPE, *PMPEG_STREAM_TYPE;

typedef enum _MPEG_CAPABILITY {
    MpegCapAudioDevice = 0,
    MpegCapVideoDevice,
    MpegCapSeparateStreams,
    MpegCapCombinedStreams,
    MpegCapBitmaskOverlay,
    MpegCapChromaKeyOverlay,
    MpegCapAudioRenderToMemory,
    MpegCapVideoRenderToMemory,
	MpegCapMaximumCapability
} MPEG_CAPABILITY, *PMPEG_CAPABILITY;

#define MPEG_OEM_CAPABILITY(a)  ((MPEG_CAPABILITY)(((unsigned)a) + 0x00008000))

typedef enum _MPEG_INFO_ITEM {
    MpegInfoCurrentPendingRequest = 1,      // Video and Audio
    MpegInfoMaximumPendingRequests,         // Video and Audio
    MpegInfoDecoderBufferSize,              // Video and Audio
    MpegInfoDecoderBufferBytesInUse,        // Video and Audio
    MpegInfoCurrentPacketBytesOutstanding,  // Video and Audio
    MpegInfoCurrentFrameNumber,             // Video and Audio
    MpegInfoStarvationCounter,              // Video and Audio
    MpegInfoDecompressHeight,               // Video
    MpegInfoDecompressWidth,                // Video
    MpegInfoMinDestinationHeight,           // Overlay
    MpegInfoMaxDestinationHeight,           // Overlay
    MpegInfoMinDestinationWidth,            // Overlay
    MpegInfoMaxDestinationWidth             // Overlay
} MPEG_INFO_ITEM, *PMPEG_INFO_ITEM;

#define MPEG_OEM_INFO_ITEM(a)   ((MPEG_INFO_ITEM)(((unsigned)a) + 0x00008000))

typedef enum _MPEG_DEVICE_STATE {
    MpegStateStartup = 0,
    MpegStatePaused,
    MpegStatePlaying,
    MpegStateStarved,
    MpegStateFailed
} MPEG_DEVICE_STATE, *PMPEG_DEVICE_STATE;

typedef enum _MPEG_OVERLAY_MODE {
    MpegModeNone = 1,
    MpegModeRectangle,
    MpegModeOverlay
} MPEG_OVERLAY_MODE, *PMPEG_OVERLAY_MODE;

//****************************************************************************
// Data Structures
//****************************************************************************

typedef struct _MPEG_PACKET_LIST {
    PVOID       pPacketData;
    ULONG       ulPacketSize;
    MPEG_SYSTEM_TIME Scr;
} MPEG_PACKET_LIST, *PMPEG_PACKET_LIST;

typedef struct _MPEG_ATTRIBUTE_PARAMS {
    MPEG_ATTRIBUTE Attribute;          // attribute to Get or Set
    LONG   Value;                      // attribute dependent parameter 1
} MPEG_ATTRIBUTE_PARAMS, *PMPEG_ATTRIBUTE_PARAMS;

typedef struct _MPEG_OVERLAY_PLACEMENT {
    ULONG X;                         // window x position,width
    ULONG Y;                         // window y position,height
    ULONG cX;                        // window x position,width
    ULONG cY;                        // window y position,height
} MPEG_OVERLAY_PLACEMENT, *PMPEG_OVERLAY_PLACEMENT;

typedef struct _MPEG_OVERLAY_BIT_MASK {
    ULONG   PixelHeight;        // the height of the bit-mask buffer
    ULONG   PixelWidth;         // the wight of the bit-mask buffer
    ULONG   BufferPitch;        // the number of bytes-per-line
    ULONG   LeftEdgeBitOffset;  // the number of bits to skip on the left edge
    PCHAR   pBitMask;           // pointer to the data
} MPEG_OVERLAY_BIT_MASK, *PMPEG_OVERLAY_BIT_MASK;


#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\mpegprse.h ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*

     Stuff for parsing an MPEG-I system stream.

     Unfortunately we don't call to get the data - we get called.

     If we can't see the whole structure we're trying to look at
     we wait for more data.

     If the data we're trying to parse isn't contiguous and
     we want it to be we register an error (may have to revisit?).

     The two sources we know about at the moment:

         1.  Video CD
         2.  Raw file

     Will always give pass us contiguous MPEG-I stream constructs

     NOTE - the Video CD data is not subject to random seek parse
     errors because it is all segment aligned.
*/

typedef enum {
       State_Initializing = 0,
       State_Seeking,
       State_Run,
       State_FindEnd,
       State_Stopping
} Stream_State;



/*  Define a large value which doesn't wrap around if you add a bit */
#define VALUE_INFINITY ((LONGLONG)0x7F00000000000000)

/***************************************************************************\

              Basic stream parsing

\***************************************************************************/

class CParseNotify;  // Predeclare
class CBasicStream;
class CStream;
class CVideoParse;

class CBasicParse
{
public:

    /*  Constructor/destructor */
    CBasicParse() : m_pNotify(NULL),
                    m_bSeekable(FALSE)
    {};

    virtual ~CBasicParse() {};

    /*  State setting */
    void SetNotify(CParseNotify *pNotify)
    {
        m_pNotify = pNotify;
    };
    virtual BOOL IsSeekable()
    {
        return m_bSeekable;
    };
    LONGLONG Size()
    {
        return m_llTotalSize;
    };
    virtual HRESULT Init(LONGLONG llSize, BOOL bSeekable, CMediaType const *pmt)
    {
        ASSERT(bSeekable || llSize == 0);
        m_pTimeFormat        = &TIME_FORMAT_MEDIA_TIME;
        m_Rate               = 1.0;
        m_Start              = 0;
        m_Stop               = VALUE_INFINITY;

        m_llTotalSize        = llSize;
        m_bSeekable          = bSeekable;
        m_State              = State_Initializing;

        m_llSeek             = 0;

        m_pmt                = pmt;
        Discontinuity();
        return S_OK;
    };
                                                  // Set to initializing state
    virtual HRESULT FindEnd()                     // Set to 'find end' state
    {
        SetState(State_FindEnd);
        return S_OK;
    };
    virtual HRESULT Replay()                      // Be prepared to restart
    {
        Discontinuity();
        return S_OK;
    };
    virtual HRESULT Run()                         // Set to Run state
    {
        SetState(State_Run);
        return S_OK;
    };
    virtual HRESULT EOS()                         // End of segment - complete
    {                                             // your state transition or
        return S_OK;                              // die!
    };

    //  Start grovelling for start position
    virtual void SetSeekState() = 0;


    virtual HRESULT Seek(LONGLONG llSeek,
                         REFERENCE_TIME *prtStart,
                         const GUID *pTimeFormat) = 0;
                                                  // Set seek target
    virtual HRESULT SetStop(LONGLONG llStop)      // Set end
    {
        m_Stop = llStop;
        return S_OK;
    };

    //  Return start and stop in time units
    virtual REFERENCE_TIME GetStartTime()
    {
        return m_Start;
    };
    virtual REFERENCE_TIME GetStopTime();

    virtual void SetRate(double dRate)
    {
        m_Rate = dRate;
    };
    double GetRate()
    {
        return m_Rate;
    };

    //  Return start and stop in current time format units
    LONGLONG GetStart()
    {
        return m_llSeek;
    }
    LONGLONG GetStop()
    {
        return m_Stop;
    }

    /*  Flags for ParseBytes */
    enum { Flags_EOS   = 0x01,
           Flags_First = 0x02,
           Flags_SlowMedium = 0x04  // Set when file end not available
         };

    virtual LONG ParseBytes(LONGLONG llPos,
                            PBYTE    pData,
                            LONG     lLength,
                            DWORD    dwFlags) = 0;

    virtual HRESULT GetDuration(LONGLONG *pllDuration,
                                const GUID *pTimeFormat = &TIME_FORMAT_MEDIA_TIME) = 0;

    virtual LONG GetBufferSize() = 0;

    /*  Stream list manipulation to build up output pins */
    virtual CBasicStream *GetStream(int i) = 0;
    virtual int NumberOfStreams() = 0;

    /*  Time Format support - default to only time */
    virtual HRESULT IsFormatSupported(const GUID *pTimeFormat);

    /*  Set the time/position format */
    virtual HRESULT SetFormat(const GUID *pFormat);

    /*  Return the medium position */
    virtual BOOL GetMediumPosition(LONGLONG *pllPosition)
    {
        UNREFERENCED_PARAMETER(pllPosition);
        return FALSE;
    };

    virtual UCHAR GetStreamId(int iIndex)
    {
        return 0xFF;
    }

    /*  Get the time format */
    const GUID *TimeFormat()
    {
        return m_pTimeFormat;
    };

    // Converts a GUID pointer into a pointer to our local GUID
    // (NULL implies default which is the one returned by our TimeFormat() above.)
    const GUID * ConvertToLocalFormatPointer( const GUID * pFormat );

    HRESULT ConvertTimeFormat( LONGLONG * pTarget, const GUID * pTargetFormat
                            , LONGLONG    Source, const GUID * pSourceFormat );

    /*  Content stuff */
    typedef enum {
        Author      = 1,
        Copyright   = 2,
        Title       = 3,
        Description = 4,
        Artist      = 5
    } Field;

    virtual BOOL HasMediaContent() const { return FALSE; };
    virtual HRESULT GetContentField(Field dwFieldId, LPOLESTR *str)
    {
        return E_NOTIMPL;
    }


protected:

    /*  Shut off some warnings */
    CBasicParse(const CBasicParse& objectSrc);          // no implementation
    void operator=(const CBasicParse& objectSrc);       // no implementation

    /*  Utility function */
    virtual void Discontinuity() = 0;

    /*  Set the current stream processing state */
    virtual void SetState(Stream_State state)
    {
        m_State = state;
        Discontinuity();
    };

    // Convert times between formats
    virtual LONGLONG Convert(LONGLONG llOld,
                     const GUID *OldFormat,
                     const GUID *NewFormat)
    {
        // Caller must check that the formats are OK
        ASSERT( NewFormat == OldFormat );
        return llOld;
    }

    /*  Our state */

    CParseNotify * m_pNotify;

    /*  Position stuff */
    const GUID     *m_pTimeFormat;
    LONGLONG        m_Start;
    LONGLONG        m_Stop;
    double          m_Rate;

    /*  Inputs from Init */
    LONGLONG                 m_llTotalSize;    // Size in bytes
    BOOL                     m_bSeekable;        // If seekable

    /*  Parsing state */
    Stream_State m_State;

    /*  Input media type */
    CMediaType  const       *m_pmt;

    /*  Starting byte position */
    LONGLONG                 m_llStart;

    /*
    **  Seek information
    **  This information is saved when Seek is called
    **  and used when SetSeekState is called
    */

    /*  Next start position (format is m_pTimeFormat) */
    LONGLONG        m_llSeek;
};

class CParseNotify
{
public:
    virtual void ParseError(UCHAR       uStreamId,
                            LONGLONG    llPosition,
                            DWORD       Error) = 0;
    virtual void SeekTo(LONGLONG llPosition) = 0;
    virtual void Complete(BOOL          bSuccess,
                          LONGLONG      llPosFound,
                          REFERENCE_TIME tFound) = 0;
    virtual HRESULT QueuePacket(UCHAR uStreamId,
                                PBYTE pbData,
                                LONG lSize,
                                REFERENCE_TIME tStart,
                                BOOL bSync) = 0;


    /*  Read data - negative start means from end */
    virtual HRESULT Read(LONGLONG llStart, DWORD dwLen, BYTE *pbData) = 0;
};

/***************************************************************************\

              Multiple stream stuff for system streams

\***************************************************************************/

class CStreamList
{
public:
    CStreamList() : m_nValid(0),
                    m_lStreams(NAME("Stream List"))
    {
    };
    virtual ~CStreamList()
    {
    };

    virtual BOOL AddStream(CStream *) = 0;
    virtual BOOL RemoveStream(CStream *) = 0;

    /*  Find the start clock time in MPEG units for the system stream */
    virtual LONGLONG StartClock() = 0;


    /*  Callbacks to get the start and stop */
    virtual CSTC GetStart() = 0;
    virtual CSTC GetStop() = 0;

    /*  Are we playing x to x ? */
    virtual LONGLONG GetPlayLength() = 0;

    /*  Stream has finished state transition */
    virtual void Complete(UCHAR uStreamId,
                          BOOL bSuccess,
                          LONGLONG llPos,
                          CSTC stc) = 0;

    virtual void CheckStop() = 0;
    /*  Is the audio fixed rate ? */
    virtual BOOL AudioLock() = 0;

    /*  For debugging allow streams to get real clock */
    virtual REFERENCE_TIME CurrentTime(CSTC stc) = 0;
protected:
    /*  List of streams */
    CGenericList<CStream> m_lStreams;

    /*  Clock stuff */
    LONGLONG m_llLength;         // Total length (in time units)
    CSTC     m_stcStartPts;      // Starting 'time'
    CSTC     m_stcRealStartPts;  // Starting 'time' at start of file


    /*  Callback stuff */
    LONG     m_nValid;           // Number of valid streams so far
    BOOL     m_bCompletion;      // OK?
    LONG     m_nPacketsProcessed;// Count up how many we've done
};

class CMpeg1SystemParse : public CBasicParse,
                          public CMpegStreamTime,
                          public CStreamList
{
    typedef struct {
        DWORD dwStartCode;
        WORD  wLength;
        BYTE  RateBound[3];
        BYTE  AudioBoundAndFlags;
        BYTE  VideoBoundAndFlags;
        BYTE  bReserved;
        BYTE  StreamData[68 * 3];
    } SystemHeader;

public:
    CMpeg1SystemParse();
    ~CMpeg1SystemParse();

    /*  CBasicParse methods */

    virtual LONG ParseBytes(LONGLONG llPos,
                            PBYTE    pData,
                            LONG     lLength,
                            DWORD    dwFlags);

    void SearchForEnd() {
        ASSERT(Initialized());
        DbgLog((LOG_TRACE, 4, TEXT("Parse state <searching for end>")));
        m_State = State_FindEnd;
    };

    /*  2-stage initialization - says what type of data */
    HRESULT Init(LONGLONG llSize, BOOL bSeekable, CMediaType const *pmt);

    HRESULT FindEnd();                       // Set to 'find end' state
    void    SetSeekState();                  // Actually start seeking
    HRESULT Seek(LONGLONG llSeek,
                 REFERENCE_TIME *rtStart,
                 const GUID *pTimeFormat);   // Schedule seek
    HRESULT SetStop(LONGLONG llStop);        // Set end
    HRESULT Replay();                        // Be prepared to restart

    REFERENCE_TIME GetStartTime();

    /*  Set duration information when we've got the duration */
    void SetDurationInfo()
    {
        m_Stop = MpegToReferenceTime(m_llDuration);
        m_Stop = CRefTime(m_Stop) + (LONGLONG)1;
        m_rtDuration = Int64x32Div32(m_llDuration, 1000, 9, 500);

        /*  Absolute MPEG time to stop */
        m_llStopTime = m_llDuration + StartClock();
    };


    /*  Set the time/position format */
    HRESULT SetFormat(const GUID *pFormat);

    /*  CStreamList stuff - find the start and stop time */

    CSTC GetStart();
    CSTC GetStop();

    /*  How much are we being asked to play (in time format units)? */
    virtual LONGLONG GetPlayLength();

    /*  Stream has finished its work */
    void Complete(UCHAR uStreamId, BOOL bSuccess, LONGLONG llPos, CSTC stc);
    void SetState(Stream_State);

    /*  Stream list manipulation */
    CBasicStream *GetStream(int i);
    BOOL AddStream(CStream *);

    /*  Destructor of CStream calls this */
    BOOL RemoveStream(CStream *);

    /*  Set running state (ie begin preroll) */
    HRESULT Run();

    /*  Get total duration */
    HRESULT GetDuration(LONGLONG * pllDuration,
                        const GUID *pTimeFormat = &TIME_FORMAT_MEDIA_TIME);

    /*  Get the preferred allocator buffer size */
    LONG GetBufferSize();

    void Discontinuity();


    void Fail(HRESULT hr) {
        m_FailureCode = hr;
    };

    BOOL Failed()
    {
        return m_FailureCode != S_OK;
    };

    /*  Callbacks when something happens */
    virtual void ParseError(DWORD dwError);
    virtual HRESULT EOS();
    virtual void InitStreams();


    BOOL Initialized() {
        return TRUE;
    };

    LONGLONG Duration();

    //
    //  Find stuff from the system header
    //
    BOOL AudioLock()
    {
        ASSERT(m_lSystemHeaderSize != 0);
        return (m_SystemHeader.VideoBoundAndFlags & 0x80) != 0;
    };
    void CheckStop();


    virtual int NumberOfStreams()
    {
        return m_lStreams.GetCount();
    };

    REFERENCE_TIME CurrentTime(CSTC stc)
    {
        return MpegToReferenceTime(GetStreamTime(stc) - m_llStartTime);
    };

    /*  Say if we support a given format */
    HRESULT IsFormatSupported(const GUID *pTimeFormat);

    /*  Return the medium position */
    virtual BOOL GetMediumPosition(LONGLONG *pllPosition)
    {
        if (m_pTimeFormat == &TIME_FORMAT_MEDIA_TIME) {
            return FALSE;
        }
        if (m_pTimeFormat == &TIME_FORMAT_BYTE) {
            *pllPosition = m_llPos;
            return TRUE;
        }
        ASSERT(m_pTimeFormat == &TIME_FORMAT_FRAME);
        return FALSE;
    };

    UCHAR GetStreamId(int iIndex);

protected:

    /*  Parsing helper functions */
    LONG ParsePack(PBYTE pData, LONG lBytes);
    LONG ParseSystemHeader(PBYTE pData, LONG lBytes);
    LONG ParsePacket(DWORD dwStartCode, PBYTE pData, LONG lBytes);

    /*  Extract a clock from the MPEG data stream */
    BOOL GetClock(PBYTE pData, CSTC *Clock);
    LONGLONG StartClock();
    /*  Are we complete ? */
    BOOL IsComplete();

    /*  Return the reference time to be put in the sample
        This value is adjusted for rate
    */
    REFERENCE_TIME SampleTime(REFERENCE_TIME t)
    {
        if (m_Rate != 1.0) {
            return CRefTime((LONGLONG)((double)t / m_Rate));
        } else {
            return t;
        }
    };

    BOOL SendPacket(UCHAR    uStreamId,
                    PBYTE    pbPacket,
                    LONG     lPacketSize,
                    LONG     lHeaderSize,
                    BOOL     bHasPts,
                    CSTC     cstc);

    /*  Add a stream - returns NULL if stream not added */
    CStream * AddStream(UCHAR uStreamId);

protected:

    /*  Format conversion helper */
    LONGLONG Convert(LONGLONG llOld,
                     const GUID *OldFormat,
                     const GUID *NewFormat);

    /*  Keep track of current position */
    LONGLONG                 m_llPos;

    /*  Remember if we have a video stream */
    CVideoParse             *m_pVideoStream;

    /*  Bits to chop off for video in reference time units */ 
    LONGLONG                 m_rtVideoStartOffset;
    LONGLONG                 m_rtVideoEndOffset;
    DWORD                    m_dwFrameLength;

    /*  Handle discontinuities */
    BYTE                     m_bDiscontinuity;



    /*  The variables below are only valid if seeking is supported
        (m_bSeekable)
    */

    /*  Total length in time */
    BYTE                     m_bGotDuration;
    LONGLONG                 m_llDuration;   // In MPEG units
    REFERENCE_TIME           m_rtDuration;   // In REFERENCE_TIME units

    /*  Keep track of completions */
    CSTC                     m_stcComplete;
    LONGLONG                 m_llCompletePosition;


    /*  Start and stop time as absolute times (directly comparable to
        times in the movie
    */
    LONGLONG                 m_llStartTime;
    LONGLONG                 m_llStopTime;
    BYTE                     m_bGotStart;   // Start time valid?

    /*  Are we VideoCD? */
    BYTE                     m_bVideoCD;
    bool                     m_bItem;       // Has stills

    /********************************************************************
        Concatenated streams stuff (like Silent Steel)

        The 'design' is as follows:

        1.  Detect concatenated streams if the mux rate proportionately
            doesn't match the end time.

            In this case compute the duration based on the mux rate.

        2.  For a concatenated streams file while seeking of playing
            do nothing until we get a pack start code at which point we
            compute the timestamp offset based on the pack time stamp
            and the file position :

            m_stcTSOffset + Pack SCR == File time based on position using
                                        MUX rate

        3.  Every packet time stamp has m_stcTSOffset applied to it for
            a concatenated file.

        4.  When we detect a time discontinuity in a pack reset
            m_stcTSOffset again to the file position

        Variables:

        m_bConcatenatedStreams - set during initialization if we detect
                                 this situation

        m_stcTSOffset - Offset to add to all PTSs in this case
    */

    BYTE                     m_bConcatenatedStreams;
    CSTC                     m_stcTSOffset;

    /*  System header stuff - invalid if m_lSystemHeaderSize is 0
        also we don't remember this stuff for video cd
    */
    LONG                     m_lSystemHeaderSize;
    DWORD                    m_MuxRate;
    HRESULT                  m_FailureCode;
    SystemHeader             m_SystemHeader;
};

class CVideoCDParse : public CMpeg1SystemParse
{
public:
    CVideoCDParse()
    {
        m_bVideoCD = TRUE;
    };

    virtual LONG ParseBytes(LONGLONG llPos,
                            PBYTE    pData,
                            LONG     lLength,
                            DWORD    dwFlags);

    /*  Override byte positioning stuff to seek only the MPEG */

    /*  Get total duration */
    HRESULT GetDuration(LONGLONG * pllDuration,
                        const GUID *pTimeFormat = &TIME_FORMAT_MEDIA_TIME);

    /*  Seek to a given position */
    HRESULT Seek(LONGLONG llSeek,
                 REFERENCE_TIME *prtStart,
                 const GUID *pTimeFormat);
};

//  Basic stream class
class CBasicStream
{
public:
    CBasicStream() : m_bPayloadOnly(FALSE),
                     m_bDiscontinuity(TRUE),
                     m_uStreamId(0xFF),
                     m_uNextStreamId(0xFF),
                     m_uDefaultStreamId(0xFF)
    {};
    virtual ~CBasicStream() {};

    virtual HRESULT GetMediaType(CMediaType *cmt, int iPosition) = 0;
    virtual HRESULT SetMediaType(const CMediaType *cmt, BOOL bPayload);
    virtual HRESULT ProcessType(AM_MEDIA_TYPE const *pmt)
    {
        return E_NOTIMPL;
    };

    virtual BOOL GetDiscontinuity()
    {
        BOOL bResult = m_bDiscontinuity;
        m_bDiscontinuity = FALSE;
        return bResult;
    };

    /*  Override this if you want to hear more about discontinuities */
    virtual void Discontinuity()
    {
        m_bDiscontinuity = TRUE;
        return;
    };

    /*  Id */
    UCHAR                    m_uStreamId;
    UCHAR                    m_uNextStreamId;
    UCHAR                    m_uDefaultStreamId;
    bool                     m_bStreamChanged;

    /*  Handle predefined media types */

protected:
    /*  Shut off some warnings */
    CBasicStream(const CBasicStream& objectSrc);          // no implementation
    void operator=(const CBasicStream& objectSrc);       // no implementation

    /*  Save the type information here */
    BOOL                     m_bPayloadOnly;

    /*  Discontinuity flag */
    BOOL                     m_bDiscontinuity;


};

//  Muxed stream class
class CStream : public CBasicStream
{
public:

    CStream(CStreamList *pList, UCHAR uStreamId, bool bItem=false) :
        m_bValid(FALSE),
        m_bSeeking(TRUE),
        m_bGotFirstPts(FALSE),
        m_pStreamList(pList),
        m_bTypeSet(FALSE),
        m_llStartPosition(0),
        m_bReachedEnd(FALSE),
        m_stc(0),
        m_bComplete(FALSE),
        m_bStopping(FALSE),
        m_bItem(bItem)
    {
        m_uStreamId     = uStreamId;
        m_uNextStreamId = uStreamId;
        m_uDefaultStreamId = uStreamId;
    }

    /*  Remove ourselves from the list */
    ~CStream()
    {
        m_pStreamList->RemoveStream(this);
    };


    /*  Seek to - seek target got from stream list */
    virtual void SetState(Stream_State);

    virtual BOOL ParseBytes(PBYTE pData,
                            LONG lLen,
                            LONGLONG llPos,
                            BOOL bHasPts,
                            CSTC stc) = 0;
    virtual void EOS();
    virtual BOOL    IsPayloadOnly();
    virtual CSTC    CurrentSTC(BOOL bHasPts, CSTC stc)
    {
        if (bHasPts) {
            m_stc = stc;
        }
        return m_stc;
    }

    BOOL IsPlaying(LONGLONG llPos, LONG lLen);


    /*  Utility for state change completion */
    void                      Complete(BOOL bSuccess, LONGLONG llPos, CSTC stc);

protected:
    virtual  void             Init() = 0;
    /*  Check if transition is complete */
    virtual  void             CheckComplete(BOOL bForce) = 0;

public:
    /*  Don't parse because we're running */
    BOOL  m_bRunning;

protected:
    BOOL                      m_bValid;
    BOOL                      m_bTypeSet;
    BOOL                      m_bSeeking;
    BOOL                      m_bGotFirstPts;
    CSTC                      m_stcStart;

    /*  This count increments as the streams declare themselves valid
        during initialization
    */
    LONG                     m_nValid;


    /*  Our 'parent' */
    CStreamList * const      m_pStreamList;

    /*  'current time' */
    CSTC                     m_stc;

    /*  Where to start playing from and where to stop */
    LONGLONG                 m_llStartPosition;
    BOOL                     m_bReachedEnd;

    /*  Complete ? */
    BOOL  m_bComplete;


    /*  Internal stopping state */
    BOOL  m_bStopping;

    /*  Video CD */
    bool  m_bItem;

    /*  State */
    Stream_State m_State;

};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\mpegdef.h ===
// Copyright (c) 1994 - 1996  Microsoft Corporation.  All Rights Reserved.

/*
    mpegdef.h

    This file defines the externals for interfacing with MPEG
    components
*/

/*

    MPEG constants

*/

#define MPEG_TIME_DIVISOR (90000)
#define MPEG_MAX_TIME ((LONGLONG)0x200000000)

#define PICTURE_START_CODE       0x00000100
#define USER_DATA_START_CODE     0x000001B2
#define SEQUENCE_HEADER_CODE     0x000001B3
#define SEQUENCE_ERROR_CODE      0x000001B4
#define EXTENSION_START_CODE     0x000001B5
#define SEQUENCE_END_CODE        0x000001B7
#define GROUP_START_CODE         0x000001B8

#define ISO_11172_END_CODE       0x000001B9
#define PACK_START_CODE          0x000001BA
#define SYSTEM_HEADER_START_CODE 0x000001BB
#define PADDING_START_CODE       0x000001BE
#define PACKET_START_CODE_MIN    0x000001BC
#define PACKET_START_CODE_MAX    0x000001FF

#define AUDIO_GLOBAL             0xB8
#define VIDEO_GLOBAL             0xB9
#define RESERVED_STREAM          0xBC
#define PRIVATE_STREAM_1         0xBD
#define PADDING_STREAM           0xBE
#define PRIVATE_STREAM_2         0xBF
#define AUDIO_STREAM             0xC0
#define AUDIO_STREAM_MASK        0xE0
#define VIDEO_STREAM             0xE0
#define VIDEO_STREAM_MASK        0xF0
#define DATA_STREAM              0xF0
#define DATA_STREAM_MASK         0xF0

/*  MPEG-2 stuff */
#define PROGRAM_STREAM_DIRECTORY 0xFF
#define PROGRAM_STREAM_MAP       0xBC
#define ANCILLIARY_STREAM        0xF9
#define ECM_STREAM               0xF0
#define EMM_STREAM               0xF1

#define VALID_PACKET(data)      (((data) >= PACKET_START_CODE_MIN)  \
                              && ((data) <= PACKET_START_CODE_MAX))

#define VALID_SYSTEM_START_CODE(data)     \
       (VALID_PACKET(data)                \
    ||  (data) == SYSTEM_HEADER_START_CODE\
    ||  (data) == PACK_START_CODE         \
    ||  (data) == ISO_11172_END_CODE)


/*  Types of stream */
inline BOOL IsVideoStreamId(BYTE StreamId)
{
    return (StreamId & 0xF0) == 0xE0;
} ;
inline BOOL IsAudioStreamId(BYTE StreamId)
{
    return (StreamId & 0xE0) == 0xC0;
} ;

#define MAX_MPEG_PACKET_SIZE (65535+6)

/*  Lengths of the various structures */
#define PACK_HEADER_LENGTH 12
#define SYSTEM_HEADER_BASIC_LENGTH 12

#define DWORD_SWAP(x) \
     ((DWORD)( ((x) << 24) | ((x) >> 24) | \
               (((x) & 0xFF00) << 8) | (((x) & 0xFF0000) >> 8)))


/*  Video definitions */

/*  Frame types as defined in a picture header */
#define I_Frame 1
#define D_Frame 4
#define P_Frame 2
#define B_Frame 3
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\mpgtime.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
     mpgtime.h

        Timing stuff for MPEG :


        CSTC - model the 33 bit roll-around system time clock

        CMpegFileTime - try to track the clock around (several possible)
        roll-arounds

*/

REFERENCE_TIME inline MpegToReferenceTime(LONGLONG llTime)
{
    REFERENCE_TIME rt;
    rt = (llTime * 1000 + 500) / 9;
    return rt;
}

LONGLONG inline ReferenceTimeToMpeg(REFERENCE_TIME rt)
{
    return (rt * 9 + 4) / 1000;
}

class CSTC
{
public:
    inline CSTC()
    {
#ifdef DEBUG
        /*  Initialize to invalid */
        m_ll = 0x7F7F7F7F7F7F7F7F;
#endif
    };
    inline CSTC(LONGLONG ll)
    {
        LARGE_INTEGER li;
        li.QuadPart = ll;
        li.HighPart = -(li.HighPart & 1);
        m_ll = li.QuadPart;
    };
    inline CSTC operator-(CSTC cstc)
    {
        return CSTC(m_ll - (LONGLONG)cstc);
    };
    inline operator LONGLONG() const
    {
        ASSERT(m_ll + 0x100000000 < 0x200000000);
        return m_ll;
    };

    //  Copy constructor
    inline CSTC operator=(LONGLONG ll)
    {
        *this = CSTC(ll);
        return *this;
    }
    inline ~CSTC()
    {
    };
    inline BOOL operator<(CSTC cstc) const
    {
        LARGE_INTEGER li;
        li.QuadPart = m_ll - cstc.m_ll;
        return (li.HighPart & 1) != 0;
    };
    inline BOOL operator>(CSTC cstc) const
    {
        return cstc < *this;
    };

    inline BOOL operator>=(CSTC cstc) const
    {
        return !(*this < cstc);
    };
    inline BOOL operator<=(CSTC cstc) const
    {
        return !(*this > cstc);
    };

private:
    LONGLONG m_ll;
};

class CMpegStreamTime
{
public:
    CMpegStreamTime();
    ~CMpegStreamTime();
    void ResetToStart();
    void SeekTo(LONGLONG llGuess);
    void SetStreamTime(CSTC cstc, LONGLONG llPosition);
    LONGLONG GetStreamTime(CSTC cstc);
    BOOL StreamTimeInitialized();
    void StreamTimeDiscontinuity();
    virtual void StreamTimeError();

protected:
    LONGLONG                            m_llCurrentClock;
    BOOL                                m_bTimeDiscontinuity;

    BOOL                                m_bInitialized;
    BOOL                                m_bTimeContiguous;

    /*  m_llFirstClock is just something we remember to go back to */
    LONGLONG                            m_llFirstClock;
    LONGLONG                            m_llPositionForCurrentClock;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\resource.h ===
/******************************Module*Header*******************************\
* Module Name: Resource.h
*
*
*
*
* Copyright (c) 1999 Microsoft Corporation.  All Rights Reserved
\**************************************************************************/

#define MPEG_SPLITTER_BASE         5000

#define IDS_COPYRIGHT           MPEG_SPLITTER_BASE
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\parseerr.h ===
// Copyright (c) Microsoft Corporation 1995. All Rights Reserved

/*  MPEG parsing error codes */

enum {
    Error_InvalidPack                   = 0x10000,
    Error_Scanning                      = 0x20000,
    Error_InvalidSystemHeader           = 0x30000,
    Error_InvalidPacketHeader           = 0x40000,

    Error_InvalidSystemHeaderStream     = 0x01,
    Error_InvalidStreamId               = 0x02,
    Error_DuplicateStreamId             = 0x03,
    Error_InvalidLength                 = 0x04,
    Error_InvalidStartCode              = 0x05,
    Error_NoStartCode                   = 0x06,
    Error_InvalidMarkerBits             = 0x07,
    Error_InvalidStuffingByte           = 0x08,
    Error_InvalidHeaderSize             = 0x09,
    Error_InvalidType                   = 0x0A,
    Error_InvalidClock                  = 0x0B
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\seqhdr.h ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*  Define MPEG-I video sequence header format information
    and processing function
*/
#ifndef _INC_SEQHDR_H
#define _INC_SEQHDR_H
typedef struct {
    LONG           lWidth;             //  Native Width in pixels
    LONG           lHeight;            //  Native Height in pixels
    LONG           lvbv;               //  vbv
    REFERENCE_TIME  tPictureTime;      //  Time per picture in 100ns units
    float          fPictureRate;       //  In frames per second
    LONG           lTimePerFrame;      //  Time per picture in MPEG units
    LONG           dwBitRate;          //  Bits per second
    LONG           lXPelsPerMeter;     //  Pel aspect ratio
    LONG           lYPelsPerMeter;     //  Pel aspect ratio
    DWORD          dwStartTimeCode;    //  First GOP time code (or -1)
    LONG           lActualHeaderLen;   //  Length of valid bytes in raw seq hdr
    BYTE           RawHeader[140];     //  The real sequence header
} SEQHDR_INFO;

/*  Helper */
int inline SequenceHeaderSize(const BYTE *pb)
{
    /*  No quantization matrices ? */
    if ((pb[11] & 0x03) == 0x00) {
        return 12;
    }
    /*  Just non-intra quantization matrix ? */
    if ((pb[11] & 0x03) == 0x01) {
        return 12 + 64;
    }
    /*  Intra found - is there a non-intra ? */
    if (pb[11 + 64] & 0x01) {
        return 12 + 64 + 64;
    } else {
        return 12 + 64;
    }
}

/*  Extract info from video sequence header

    Returns FALSE if the sequence header is invalid
*/

BOOL ParseSequenceHeader(const BYTE *pbData, LONG lData, SEQHDR_INFO *hdrInfo);

/*  Audio stuff too */

BOOL ParseAudioHeader(PBYTE pbData, MPEG1WAVEFORMAT *pFormat, long *pLength = NULL);

/*  Get frame length in bytes based on the header */
DWORD MPEGAudioFrameLength(BYTE *pbData);

/*  Get the time 25-bit code from a group of pictures */
inline DWORD GroupTimeCode(PBYTE pbGOP)
{
    return  ((DWORD)pbGOP[4] << 17) +
            ((DWORD)pbGOP[5] << 9) +
            ((DWORD)pbGOP[6] << 1) +
            (pbGOP[7] >> 7);
}

/*  Is time code 0 ? */
inline BOOL TimeCodeZero(DWORD dwCode)
{
    return 0 == (dwCode & (0xFFEFFF));
}

/*  Seconds in a munched GOP Time Code */
inline DWORD TimeCodeSeconds(DWORD dwCode)
{
    return ((dwCode >> 19) & 0x1F) * 3600 +
           ((dwCode >> 13) & 0x3F) * 60 +
           ((dwCode >> 6) & 0x3F);
}

/*  Minutes in a munched GOP Time Code */
inline DWORD TimeCodeMinutes(DWORD dwCode)
{
    return ((dwCode >> 19) & 0x1F) * 60 +
           ((dwCode >> 13) & 0x3F);
}

/*  Drop frame? in a munched GOP time code */
inline BOOL TimeCodeDrop(DWORD dwCode)
{
    return 0 != (dwCode & (1 << 24));
}

/*  Residual frames in a time code */
inline DWORD TimeCodeFrames(DWORD dwCode)
{
    return dwCode & 0x3F;
}

/*  Compute number of frames between 2 time codes */
DWORD FrameOffset(DWORD dwGOPTimeCode, SEQHDR_INFO const *pInfo);

/*  Find packet data */
LPBYTE
SkipToPacketData(
    LPBYTE pSrc,
    long &LenLeftInPacket
);
/*  Find the first (potential) audio frame in a buffer */
DWORD MPEG1AudioFrameOffset(PBYTE pbData, DWORD dwLen);

//  Extra layer III format support
void ConvertLayer3Format(
    MPEG1WAVEFORMAT const *pFormat,
    MPEGLAYER3WAVEFORMAT *pFormat3
);

/*  Get video format stuff */
#ifdef __MTYPE__  // CMediaType
HRESULT GetVideoMediaType(CMediaType *cmt, BOOL bPayload, const SEQHDR_INFO *pInfo,
                          bool bItem = false);
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\native.h ===
// Copyright (c) 1996 - 1999  Microsoft Corporation.  All Rights Reserved.

/*
    Native.h

    Parsing classes for native streams

*/

/*  Since we're only one stream we can inherit directly from
    CBasicParse and CBasicStream
*/

class CNativeParse : public CBasicParse, public CBasicStream
{
public:
    /*  Constructor/destructor */
    CNativeParse() : m_dwFlags(0), m_Duration(0) {};
    virtual ~CNativeParse() {};

    /*  CBasicParse methods */


    /*  NOTE - we inherit :
           m_bDiscontinuity     from CBasicStream
           Discontinuity        from CBasicParse
           GetDiscontinuity     from CBasicStream
    */
    void Discontinuity() { m_bDiscontinuity = TRUE; };

    /*  CBasicStream methods */
    CBasicStream *GetStream(int i)
    {
        ASSERT(i == 0 && 0 != (m_dwFlags & FLAGS_VALID));
        return this;
    };

    //  Return 0 if no valid stream was found
    int NumberOfStreams()
    {
        return (m_dwFlags & FLAGS_VALID) ? 1 : 0;
    };

    HRESULT GetDuration(
        LONGLONG *pllDuration,
        const GUID *pTimeFormat
    );   // How long is the stream?

protected:
    REFERENCE_TIME   m_Duration; // Length in 100ns units
    DWORD            m_dwFrames; // Length in frames

    /*  Parse state flags */
    /*  Values for dwFlags */
    enum { FLAGS_VALID    = 0x01   // Stream is valid stream
         };

    DWORD            m_dwFlags;

};

class CNativeVideoParse : public CNativeParse
{
public:
    HRESULT Init(LONGLONG llSize, BOOL bSeekable, CMediaType const *pmt);

    /*  CBasicParse methods */

    // Seek
    HRESULT     Seek(LONGLONG llSeek,
                     REFERENCE_TIME *prtStart,
                     const GUID *pTimeFormat);
    LONG        ParseBytes(                     // Process data
                    LONGLONG llPos,
                    PBYTE    pData,
                    LONG     lLength,
                    DWORD    dwFlags);

    /*  No need to look for end of small files - we've already done it */
    HRESULT FindEnd()
    {
        CBasicParse::FindEnd();

        /*  Notify a seek */
        if (m_bSeekable) {
            LONGLONG llSeekTo;

            /*  Scan around 1.5 seconds at end */
            if (m_Info.dwBitRate == 0) {
                /*  GUESS something based on the movie size */
                LONG lSize = m_Info.lWidth * m_Info.lHeight;
                if (lSize > 352 * 240) {
                    llSeekTo = m_llTotalSize -
                               MulDiv(300000,
                                      lSize,
                                      352 * 240);
                } else {
                    llSeekTo = m_llTotalSize - 300000;
                }
            } else {
                llSeekTo = m_llTotalSize -
                    MulDiv(m_Info.dwBitRate, 3, 2 * 8);
            }
            m_pNotify->SeekTo(llSeekTo < 0 ? 0 : llSeekTo);
        }
        return S_OK;
    };

    REFERENCE_TIME GetStopTime();

    /*  Set seek position */
    void SetSeekState();

    LONG GetBufferSize();                       // What input buffer size?

    void Discontinuity()
    {
        m_bDiscontinuity    = TRUE;
        m_dwCurrentTimeCode = (DWORD)-1;
        m_rtCurrent         = (REFERENCE_TIME)-1;
        m_nFrames           = 0;
        m_nTotalFrames      = 0;
        m_bIFound           = FALSE;
    };

    /*  CBasicStream methods */
    HRESULT GetMediaType(CMediaType *cmt, int iPosition);

    /*  Format support */
    HRESULT IsFormatSupported(const GUID *pTimeFormat);


    // Convert times between formats
    LONGLONG Convert(LONGLONG llOld,
                     const GUID *OldFormat,
                     const GUID *NewFormat);


private:
    /*  Utility routine
        Compute the time up to the last picture start code
        decoded
    */
    REFERENCE_TIME CurrentTime(int iSequenceNumber)
    {
        ASSERT(m_dwCurrentTimeCode != (DWORD)-1);
        return ComputeTime(m_dwCurrentTimeCode) +
               Int32x32To64(iSequenceNumber, m_Info.tPictureTime);
    };

private:
    enum { FLAGS_GOTSEQHDR = 0x08 };

    /*  Convert a time code to a reference time */
    REFERENCE_TIME ConvertTimeCode(DWORD dwCode);
    /*  Compute times of GOPs */
    REFERENCE_TIME ComputeTime(DWORD dwTimeCode);

    /*  Send chunk downstream */
    BOOL SendData(PBYTE pbData, LONG lSize, LONGLONG llPos);

    /*  Compute file stats */
    void SetDurationAndBitRate(BOOL bAtEnd, LONGLONG llPos);

    /*  Compute where we're up to */
    void ComputeCurrent();
private:
    /*  Member variables */

    SEQHDR_INFO m_Info;
    LONG m_nFrames;        /*  For counting frames from start of GOP */
    LONG m_nTotalFrames;   /*  Counting frames for time estmination */
    LONG m_lFirstFrameOffset; /* Offset of first picture start code */
    DWORD m_dwCurrentTimeCode;

    /*  Time we're up to in terms of what can be decoded */
    REFERENCE_TIME m_rtCurrent;

    /*  Time of first picture in current buffer */
    REFERENCE_TIME m_rtBufferStart;

    BOOL m_bIFound;

    /*  Track bad GOPs */
    BOOL m_bBadGOP;      /* GOP values are bad */
    BOOL m_bOneGOP;      /* Only one GOP (!) */

    /*  More hackery - try remembering the max sequence number we found */
    int m_iMaxSequence;

};

class CNativeAudioParse : public CNativeParse
{
public:
    CNativeAudioParse()
    {
        m_pbID3 = NULL;
    }

    ~CNativeAudioParse()
    {
        delete [] m_pbID3;
    }

    HRESULT Init(LONGLONG llSize, BOOL bSeekable, CMediaType const *pmt);

    /*  CBasicParse methods */
    HRESULT     Seek(LONGLONG llSeek,
                     REFERENCE_TIME *prtStart,
                     const GUID *pTimeFormat);
    HRESULT     SetStop(LONGLONG tStop);
    LONG        ParseBytes(                     // Process data
                    LONGLONG llPos,
                    PBYTE    pData,
                    LONG     lLength,
                    DWORD    dwFlags);

    LONG GetBufferSize();                       // What input buffer size?

    /*  CBasicStream methods */
    HRESULT GetMediaType(CMediaType *cmt, BOOL bPayload);

    HRESULT FindEnd()
    {
        CBasicParse::FindEnd();
        m_pNotify->Complete(TRUE, 0, 0);
        return S_OK;
    };
    /*  Set seek position */
    void SetSeekState();

    /*  Format checking */
    LONG CheckMPEGAudio(PBYTE pbData, LONG lData);

    /*  Content stuff */
    BOOL HasMediaContent() const { return m_pbID3 != NULL; };
    HRESULT GetContentField(CBasicParse::Field dwFieldId, LPOLESTR *str);

private:
    /*  Helper - compute time from offset */
    REFERENCE_TIME ComputeTime(LONGLONG llOffset);

    DWORD static GetLength(const BYTE *pbData)
    {
        return (((DWORD)pbData[0] << 24) +
                ((DWORD)pbData[1] << 16) +
                ((DWORD)pbData[2] << 8 ) +
                 (DWORD)pbData[3]);
    }

private:
    /*  Member variables */
    MPEG1WAVEFORMAT m_Info;

    /*  Stop position */
    LONGLONG m_llStop;

    /*  ID3 information */
    PBYTE    m_pbID3;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\inc\videocd.h ===
// Copyright (c) 1994 - 1997  Microsoft Corporation.  All Rights Reserved.

/*
    videocd.h

    This file defines the externals for interfacing with video CDs
*/

#define VIDEOCD_HEADER_SIZE 0x2C
#define VIDEOCD_SECTOR_SIZE 2352
#define VIDEOCD_DATA_SIZE 2324
typedef struct {
    BYTE Sync[12];
    BYTE Header[4];
    BYTE SubHeader[8];
    BYTE UserData[VIDEOCD_DATA_SIZE];
    BYTE EDC[4];
} VIDEOCD_SECTOR;

//
// Channel numbers (SubHeader[1]):
//
// 01 - Motion pictures
// 02 - Normal resolution still
// 03 - High resolution still
// 00 - Padding
//

#define IS_MPEG_VIDEO_SECTOR(pSector)             \
    (((pSector)->SubHeader[1] >= 0x01 &&          \
      (pSector)->SubHeader[1] <= 0x03 ) &&        \
     ((pSector)->SubHeader[2] & 0x6E) == 0x62 &&  \
     ((pSector)->SubHeader[3] & 0x0F) == 0x0F)
#define IS_MPEG_AUDIO_SECTOR(pSector)             \
    ((pSector)->SubHeader[1] == 0x01 &&           \
     ((pSector)->SubHeader[2] & 0x6E) == 0x64 &&  \
     (pSector)->SubHeader[3] == 0x7F)
#define IS_MPEG_SECTOR(pSector)                   \
     (IS_MPEG_VIDEO_SECTOR(pSector) ||            \
      IS_MPEG_AUDIO_SECTOR(pSector))


#define IS_AUTOPAUSE(pSector)                     \
      (0 != ((pSector)->SubHeader[2] & 0x10))
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\dbgext.h ===
/*++

Copyright (c) 1995 Microsoft Corporation

Module Name:

   DbgExt.h

Abstract:
    Mpeg WinDbg debugger Extensions include

Author:

   Paul Lever (a-paull) 2-Feb-1995

Environment:

   Kernel mode only


Revision History:

--*/

#define TRACE_BUFFER_SIZE   255             // size of individual trace entry

typedef struct _TRACE_RECORD {
    ULONGLONG   now;                    // time stamp
    CHAR        desc[TRACE_BUFFER_SIZE]; // message
} TRACE_RECORD, *PTRACE_RECORD;

typedef struct _DEBUG_TRACE_INFO {
    LONG   TraceHead;                   // head of trace circular buffer
    LONG   Traced;                      // count of traced items
    PTRACE_RECORD   pTraceBuffer;       // ptr to trace buffer
} DEBUG_TRACE_INFO, *PDEBUG_TRACE_INFO;


typedef struct _MPEG_DEBUG_EXTENSION {
    PVOID   pDriverObject;              // pointer to this drivers Object
    DEBUG_TRACE_INFO TraceInfo;         // trace buffer structure        
} MPEG_DEBUG_EXTENSION, *PMPEG_DEBUG_EXTENSION;



#define SPRINT_TRACE_MASK	 0x3ff
#define SPRINT_MAX_ENTRIES	SPRINT_TRACE_MASK+1

void
CircularBufferTrace( char *format, ...);

#if DBG
extern MPEG_DEBUG_EXTENSION MpegDebugExtension;
#define TRACE(_d_)\
    CircularBufferTrace _d_
#else
#define TRACE(_d_)
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\init.c ===
/* Copyright (c) 1995  Microsoft Corporation.  All Rights Reserved. */
#include "windows.h"

/****************************************************************************
   FUNCTION: DllMain(HANDLE, DWORD, LPVOID)

   PURPOSE:  DllMain is called by Windows when
             the DLL is initialized, Thread Attached, and other times.
             Refer to SDK documentation, as to the different ways this
             may be called.

             The DllMain function should perform additional initialization
             tasks required by the DLL.  In this example, no initialization
             tasks are required.  DllMain should return a value of 1 if
             the initialization is successful.

*******************************************************************************/
BOOL APIENTRY DllMain(HANDLE hInst, DWORD ul_reason_being_called, LPVOID lpReserved)
{
    return 1;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\imp.h ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    imp.h

Abstract:

    This file defines all the implementation-dependent structures and
    declares internal functions for the MPEG API DLL.

Author:

    Yi SUN (t-yisun) 08-22-1994

Environment:

Revision History:

--*/

#ifndef _IMP_H
#define _IMP_H

/**************************************************************************
*                     types, vars and constants definition
**************************************************************************/

#define MAX_CHANNELS    8

extern  int     nMpegAdapters;

typedef enum _ATTRIBUTE_VALUE_STATUS
{
    AttrValueUnset,
    AttrValueUpdated,
    AttrValueUnwritten
} ATTRIBUTE_VALUE_STATUS, *PATTRIBUTE_VALUE_STATUS;

// MPEG attribute range struct
typedef struct _MPEG_ATTRIBUTE_INFO {
    MPEG_ATTRIBUTE          eAttribute;
    LONG                    lMinimum;
    LONG                    lMaximum;
    LONG                    lStep;                 // 0 indicates not supported
    LONG                    lCurrentValue[MAX_CHANNELS];
    ATTRIBUTE_VALUE_STATUS  eValueStatus[MAX_CHANNELS];
} MPEG_ATTRIBUTE_INFO, *PMPEG_ATTRIBUTE_INFO;

// abstract device control block contains info identifying each abstract
// device

typedef struct _ABSTRACT_DEVICE_CONTROL_BLOCK {
    BOOL bIsAvailable;     // indicate if the abstract device exists
    int nCurrentChannel;
    TCHAR szId[80];
    HMPEG_DEVICE hAD;      // handle to the abstract device; hidden from apps
} ABSTRACT_DEVICE_CONTROL_BLOCK, *PABSTRACT_DEVICE_CONTROL_BLOCK;


// NOTE: the following info should be obtained from the registry or by
//       querying the device.  For now, it's hard coded.

// define the max number of abstract devices for each physical MPEG device

#define MAX_ABSTRACT_DEVICES            4

// define the max number of attributes for each MPEG device

#define NUMBER_OF_ATTRIBUTES            32

// MPEG device control block

typedef struct _MPEG_DEVICE_CONTROL_BLOCK {
    int                             nDevice;
    TCHAR                           szDescription[256];
    ULONG                           ulCapabilities;
    USHORT                          usSequenceNumber;
    int                             nAttributes;
    BOOL                            bAttributesLocked;
    ABSTRACT_DEVICE_CONTROL_BLOCK   eAbstractDevices[MAX_ABSTRACT_DEVICES];
    MPEG_ATTRIBUTE_INFO             Attributes[NUMBER_OF_ATTRIBUTES];
} MPEG_DEVICE_CONTROL_BLOCK, *PMPEG_DEVICE_CONTROL_BLOCK;

// define the number of the MPEG devices in the system

typedef enum _MPEG_ABSTRACT_DEVICE_INDEX {
    MpegCombined,
    MpegAudio,
    MpegVideo,
    MpegOverlay
} MPEG_ABSTRACT_DEVICE_INDEX, *PMPEG_ABSTRACT_DEVICE_INDEX;

#define NONE -1

/**************************************************************************
*                  internal function prototypes
**************************************************************************/

int
ReadRegistry();

HMPEG_DEVICE
MpegADHandle(
    IN USHORT usIndex,
    IN MPEG_ABSTRACT_DEVICE_INDEX eIndex
    );

LPTSTR
MpegDeviceDescription(
    IN USHORT usIndex
    );

MPEG_STATUS
CreateMpegHandle(
    IN USHORT usIndex,
    OUT PHMPEG_DEVICE phDevice
    );

MPEG_STATUS
CreateMpegPseudoHandle(
    IN USHORT usIndex,
    OUT PHMPEG_DEVICE phDevice
    );

BOOL
HandleIsValid(
    IN HMPEG_DEVICE hDevice,
    OUT PUSHORT pusIndex
    );

BOOL
PseudoHandleIsValid(
    IN HMPEG_DEVICE hDevice,
    OUT PUSHORT pusIndex
    );

MPEG_STATUS
CloseMpegHandle(
    IN USHORT usIndex
    );

BOOL
DeviceSupportCap(
    IN USHORT usIndex,
    IN MPEG_CAPABILITY eCapability
    );

BOOL
DeviceSupportStream(
    IN USHORT usIndex,
    IN MPEG_STREAM_TYPE eStreamType
    );

BOOL
DeviceSupportDevice(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType
    );


MPEG_STATUS
GetAttributeRange(
    IN USHORT usIndex,
    IN MPEG_ATTRIBUTE eAttribute,
    OUT PLONG plMinimum,
    OUT PLONG plMaximum,
    OUT PLONG plStep
    );

BOOL
DeviceIoControlSync(
    HMPEG_DEVICE  hDevice,
    DWORD   dwIoControlCode,
    LPVOID  lpInBuffer,
    DWORD   nInBufferSize,
    LPVOID  lpOutBuffer,
    DWORD   nOutBufferSize,
    LPDWORD lpBytesReturned
    );

MPEG_STATUS
MpegTranslateWin32Error(
	DWORD dwWin32Error
	);

MPEG_STATUS
SetCurrentChannel(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN INT nChannel
    );

MPEG_STATUS
GetCurrentChannel(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType,
    OUT LPINT nChannel
    );

MPEG_STATUS
SetCurrentAttributeValue(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN MPEG_ATTRIBUTE eAttribute,
    IN LONG lValue
    );

MPEG_STATUS
UpdateAttributes(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType
    );
#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\ddmpeg.h ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    mpeg.h

Abstract:

    These are the structures and defines that are used in the
    MPEG port driver.

Author:

    Paul Shih (paulsh) 27-Mar-1994

Revision History:

--*/
#ifndef _DDMPEG_H
#define _DDMPEG_H

#include "mpegcmn.h"
//
// Define the various device type values.  Note that values used by Microsoft
// Corporation are in the range 0-32767, and 32768-65535 are reserved for use
// by customers.
//
#define FILE_DEVICE_MPEG_OVERLAY       0x00008200U
#define FILE_DEVICE_MPEG_VIDEO         0x00008300U
#define FILE_DEVICE_MPEG_AUDIO         0x00008600U

//
// Macro definition for defining IOCTL and FSCTL function control codes.  Note
// that function codes 0-2047 are reserved for Microsoft Corporation, and
// 2048-4095 are reserved for customers.
//
#define MPEG_OVERLAY_IOCTL_BASE        0x820U
#define MPEG_VIDEO_IOCTL_BASE          0x830U
#define MPEG_AUDIO_IOCTL_BASE          0x860U

//
// Defines used in simplifying actual declarations of device IOCTL values below
//
#define CTL_CODE_MPEG_AUDIO(offset)   CTL_CODE(FILE_DEVICE_MPEG_AUDIO,           \
                                               MPEG_AUDIO_IOCTL_BASE   + offset, \
                                               METHOD_BUFFERED,                  \
                                               FILE_ANY_ACCESS)

#define CTL_CODE_MPEG_VIDEO(offset)   CTL_CODE(FILE_DEVICE_MPEG_VIDEO,           \
                                               MPEG_VIDEO_IOCTL_BASE   + offset, \
                                               METHOD_BUFFERED,                  \
                                               FILE_ANY_ACCESS)

#define CTL_CODE_MPEG_OVERLAY(offset) CTL_CODE(FILE_DEVICE_MPEG_OVERLAY,         \
                                               MPEG_OVERLAY_IOCTL_BASE + offset, \
                                               METHOD_BUFFERED,                  \
                                               FILE_ANY_ACCESS)

//****************************************************************************
// MPEG_AUDIO device IOCTLs
//****************************************************************************

// Input:  None
// Output: None
#define IOCTL_MPEG_AUDIO_RESET               CTL_CODE_MPEG_AUDIO(0)

// Input:  None
// Output: MPEG_TIME_STAMP
#define IOCTL_MPEG_AUDIO_GET_STC             CTL_CODE_MPEG_AUDIO(1)

// Input:  MPEG_TIME_STAMP
// Output: None
#define IOCTL_MPEG_AUDIO_SET_STC             CTL_CODE_MPEG_AUDIO(2)

// Input:  None
// Output: None
#define IOCTL_MPEG_AUDIO_PLAY                CTL_CODE_MPEG_AUDIO(3)

// Input:  None
// Output: None
#define IOCTL_MPEG_AUDIO_PAUSE               CTL_CODE_MPEG_AUDIO(4)

// Input:  None
// Output: None
#define IOCTL_MPEG_AUDIO_STOP                CTL_CODE_MPEG_AUDIO(5)

// Input:  None
// Output: MPEG_AUDIO_DEVICE_INFO
#define IOCTL_MPEG_AUDIO_QUERY_DEVICE        CTL_CODE_MPEG_AUDIO(6)

// Input:  None
// Output: None
#define IOCTL_MPEG_AUDIO_END_OF_STREAM       CTL_CODE_MPEG_AUDIO(7)

// Input:  MPEG_ATTRIBUTE
// Output: none
#define IOCTL_MPEG_AUDIO_SET_ATTRIBUTE       CTL_CODE_MPEG_AUDIO(8)

// Input:  none
// Output: MPEG_ATTRIBUTE
#define IOCTL_MPEG_AUDIO_GET_ATTRIBUTE       CTL_CODE_MPEG_AUDIO(9)

// Input:  MPEG_PACKET_LIST[]
// Output: none
#define IOCTL_MPEG_AUDIO_WRITE_PACKETS       CTL_CODE_MPEG_AUDIO(10)

//****************************************************************************
// MPEG_VIDEO device IOCTLs
//****************************************************************************

// Input:  None
// Output: None
#define IOCTL_MPEG_VIDEO_RESET               CTL_CODE_MPEG_VIDEO(0)

// Input:  None
// Output: MPEG_TIME_STAMP
#define IOCTL_MPEG_VIDEO_GET_STC             CTL_CODE_MPEG_VIDEO(1)

// Input:  MPEG_TIME_STAMP
// Output: None
#define IOCTL_MPEG_VIDEO_SET_STC             CTL_CODE_MPEG_VIDEO(2)

// Input:  MPEG_TIME_STAMP (optional)
// Output: MPEG_TIME_STAMP (optional)
#define IOCTL_MPEG_VIDEO_SYNC                CTL_CODE_MPEG_VIDEO(3)

// Input:  None
// Output: None
#define IOCTL_MPEG_VIDEO_PLAY                CTL_CODE_MPEG_VIDEO(4)

// Input:  None
// Output: None
#define IOCTL_MPEG_VIDEO_PAUSE               CTL_CODE_MPEG_VIDEO(5)

// Input:  None
// Output: None
#define IOCTL_MPEG_VIDEO_STOP                CTL_CODE_MPEG_VIDEO(6)

// Input:  None
// Output: MPEG_VIDEO_DEVICE_INFO
#define IOCTL_MPEG_VIDEO_QUERY_DEVICE        CTL_CODE_MPEG_VIDEO(7)

// Input:  None
// Output: None
#define IOCTL_MPEG_VIDEO_END_OF_STREAM       CTL_CODE_MPEG_VIDEO(8)

// Input:  None
// Output: None
#define IOCTL_MPEG_VIDEO_CLEAR_BUFFER        CTL_CODE_MPEG_VIDEO(9)

// Input:  MPEG_ATTRIBUTE
// Output: none
#define IOCTL_MPEG_VIDEO_SET_ATTRIBUTE       CTL_CODE_MPEG_VIDEO(10)

// Input:  none
// Output: MPEG_ATTRIBUTE
#define IOCTL_MPEG_VIDEO_GET_ATTRIBUTE       CTL_CODE_MPEG_VIDEO(11)

// Input:  MPEG_PACKET_LIST[]
// Output: none
#define IOCTL_MPEG_VIDEO_WRITE_PACKETS       CTL_CODE_MPEG_VIDEO(12)

//****************************************************************************
// MPEG_OVERLAY device IOCTLs
//****************************************************************************

// Input:  MPEG_OVERLAY_MODE
// Output: None
#define IOCTL_MPEG_OVERLAY_MODE              CTL_CODE_MPEG_OVERLAY(0)

// Input:  MPEG_OVERLAY_PLACEMENT
// Output: None
#define IOCTL_MPEG_OVERLAY_SET_DESTINATION   CTL_CODE_MPEG_OVERLAY(1)

// Input:  MPEG_OVERLAY_PLACEMENT (optional)
// Output: MPEG_OVERLAY_PLACEMENT (optional)
//#define IOCTL_MPEG_OVERLAY_ALIGN_WINDOW      CTL_CODE_MPEG_OVERLAY(2)

// Input:  MPEG_OVERLAY_KEY
// Output: None
#define IOCTL_MPEG_OVERLAY_SET_VGAKEY        CTL_CODE_MPEG_OVERLAY(3)

// Input:  MPEG_ATTRIBUTE
// Output: none
#define IOCTL_MPEG_OVERLAY_SET_ATTRIBUTE     CTL_CODE_MPEG_OVERLAY(4)

// Input:  none
// Output: MPEG_ATTRIBUTE
#define IOCTL_MPEG_OVERLAY_GET_ATTRIBUTE     CTL_CODE_MPEG_OVERLAY(5)

// Input:  MPEG_OVERLAY_BIT_MASK
// Output: none
#define IOCTL_MPEG_OVERLAY_SET_BIT_MASK      CTL_CODE_MPEG_OVERLAY(6)

// Input:  None
// Output: MPEG_OVERLAY_DEVICE_INFO
#define IOCTL_MPEG_OVERLAY_QUERY_DEVICE      CTL_CODE_MPEG_OVERLAY(7)

//****************************************************************************
// Data Structures
//****************************************************************************

// Used with: IOCTL_MPEG_VIDEO_QUERY_DEVICE
typedef struct _MPEG_IOCTL_VIDEO_DEVICE_INFO {
    MPEG_DEVICE_STATE DeviceState;   // Current MPEG device decode state
    ULONG DecoderBufferSize;         // Size of the decoder buffer
    ULONG DecoderBufferFullness;     // Used bytes in docoder buffer
    ULONG DecompressHeight;          // Native MPEG decode height
    ULONG DecompressWidth;           // Native MPEG decode width



//!! below is bogus
    ULONG MaximumPendingRequest;     // max allowable packet entries in queue
    ULONG CurrentPendingRequest;     // number of requests not yet serviced

    ULONG StatusFlags;               // Flags on the current driver status

    ULONG BytesOutstanding;          // number of bytes outstand of current packet
// !! above is bogus

    ULONG StarvationCounter;         // The numer of times the device has
                                     //     entered the starvation state


} MPEG_IOCTL_VIDEO_DEVICE_INFO, *PMPEG_IOCTL_VIDEO_DEVICE_INFO;


typedef struct _MPEG_IOCTL_AUDIO_PACKET {
    PVOID Packet;                    // Pointer to start of ISO MPEG packet
    ULONG Length;                    // Total length of packet
} MPEG_IOCTL_AUDIO_PACKET, *PMPEG_IOCTL_AUDIO_PACKET;

// Used with: IOCTL_MPEG_AUDIO_QUERY_DEVICE
typedef struct _MPEG_IOCTL_AUDIO_DEVICE_INFO {
    MPEG_DEVICE_STATE DeviceState;   // Current MPEG device decode state
    ULONG DecoderBufferSize;         // Size of the decoder buffer
    ULONG DecoderBufferFullness;     // Used bytes in docoder buffer


//!! below is bogus
    ULONG MaximumPendingRequest;     // max allowable packet entries in queue
    ULONG CurrentPendingRequest;     // number of requests not yet serviced

    ULONG StatusFlags;               // Flags on the current driver status

    ULONG DecoderBufferBytesInUse;   // Number of bytes currently in buffer
    ULONG BytesOutstanding;          // number of bytes outstand of current packet

// !! above is bogus

    ULONG StarvationCounter;         // The numer of times the device has
                                     //     entered the starvation state

} MPEG_IOCTL_AUDIO_DEVICE_INFO, *PMPEG_IOCTL_AUDIO_DEVICE_INFO;


// Used with: IOCTL_MPEG_OVERLAY_QUERY_DEVICE
typedef struct _MPEG_IOCTL_OVERLAY_DEVICE_INFO {
    ULONG MinDestinationHeight;         // Minimum height of overlay
    ULONG MaxDestinationHeight;         // Maximum height of overlay
    ULONG MinDestinationWidth;          // Minimum width of overlay
    ULONG MaxDestinationWidth;          // Maximum width of overlay
} MPEG_IOCTL_OVERLAY_DEVICE_INFO, *PMPEG_IOCTL_OVERLAY_DEVICE_INFO;

// Used with: IOCTL_MPEG_OVERLAY_SET_VGAKEY
typedef struct _MPEG_IOCTL_OVERLAY_KEY {
    ULONG Color;                     // palette index or RGB color
    ULONG Mask;                      // significant bits in color
} MPEG_IOCTL_OVERLAY_KEY,*PMPEG_IOCTL_OVERLAY_KEY;



// Used with: IOCTL_MPEG_VIDEO_WRITE_PACKETS
//            IOCTL_MPEG_AUDIO_WRITE_PACKETS
//  This structure is passed as an array containing a list of packets.
//  The entry in the list can be a 0/NULL entry indicating End Of Stream

// Used with: IOCTL_MPEG_AUDIO_GET_ATTRIBUTE
//            IOCTL_MPEG_AUDIO_SET_ATTRIBUTE
//            IOCTL_MPEG_VIDEO_GET_ATTRIBUTE
//            IOCTL_MPEG_VIDEO_SET_ATTRIBUTE
//            IOCTL_MPEG_OVERLAY_GET_ATTRIBUTE
//            IOCTL_MPEG_OVERLAY_SET_ATTRIBUTE

#endif  // #if _MPEG_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\makefile.inc ===
# NOTE:
# this directory contains a makefile which contains a single line that
# includes the global build process makefile.def. If the
# NTTARGETFILE1 or NTTARGETFILE0 environment
# variable is set then makefile.def includes makefile.inc from the current
# directory. This makefile.inc creates an extra target for nmake to create
# when it is run. NTTARGETFILE0 is built before everything else, and
# NTTARGETFILE1 is built after everything else.

copyfiles:
  @if not exist $(QUARTZ)\bin\$(TARGET_DIRECTORY)      \
    md $(QUARTZ)\bin\$(TARGET_DIRECTORY)
  @if not exist $(QUARTZ)\lib\$(TARGET_DIRECTORY)      \
    md $(QUARTZ)\lib\$(TARGET_DIRECTORY)
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll     \
         $(QUARTZ)\bin\$(TARGET_DIRECTORY)\*.*
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).lib  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).lib     \
         $(QUARTZ)\lib\$(TARGET_DIRECTORY)\*.*

=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\imp.c ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    imp.c

Abstract:

    This file defines the internal functions for the MPEG API DLL.

Author:

    Yi SUN (t-yisun) 08-23-1994

Environment:

Revision History:

--*/

#include <windows.h>
#include <winioctl.h>
#include <stdio.h>
#include <stdlib.h>
#include "trace.h"

#define IN_MPEGAPI_DLL

#include "mpegapi.h"

#include "imp.h"
#include "ddmpeg.h"


#define NT_MPEG_KEY     TEXT("Software\\Microsoft\\Windows NT\\CurrentVersion\\Mpeg")
#define WIN95_MPEG_KEY  TEXT("Software\\Microsoft\\Windows\\CurrentVersion\\Mpeg")

//
//  NNNN\
//      Capabilities
//      Description
//      InstallDate
//      Manufacturer
//      ProductName
//      ServiceName
//      Title
//      Attributes\
//          Audio\
//              Bass\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Channel\
//                  Current=n
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//              Mode\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              VolumeLeft\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              VolumeRight\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//          Video\
//              Brightness\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Channel\
//                  Current=n
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//              Contrast\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Hue\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Mode\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Saturation\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Tint\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              AGC\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Clamp\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Coring\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Gain\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              GenLock\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              Sharpness\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n
//              SignalType\
//                  Minimum=n
//                  Maximum=n
//                  Step=n
//                  Channel0=n
//                  Channel1=n
//                  Channeln=n

typedef struct _MPEG_REGISTRY_LIST {
    MPEG_ATTRIBUTE  eAttribute;
    LPTSTR          pszKeyName;
} MPEG_REGISTRY_LIST, *PMPEG_REGISTRY_LIST;

MPEG_REGISTRY_LIST  AttributeList[] =
{
    { MpegAttrAudioBass,        TEXT("Attributes\\Audio\\Bass") },
    { MpegAttrAudioChannel,     TEXT("Attributes\\Audio\\Channel") },
    { MpegAttrAudioMode,        TEXT("Attributes\\Audio\\Mode") },
    { MpegAttrAudioTreble,      TEXT("Attributes\\Audio\\Treble") },
    { MpegAttrAudioVolumeLeft,  TEXT("Attributes\\Audio\\VolumeLeft") },
    { MpegAttrAudioVolumeRight, TEXT("Attributes\\Audio\\VolumeRight") },

    { MpegAttrVideoBrightness,  TEXT("Attributes\\Video\\Brightness") },
    { MpegAttrVideoChannel,     TEXT("Attributes\\Video\\Channel") },
    { MpegAttrVideoContrast,    TEXT("Attributes\\Video\\Contrast") },
    { MpegAttrVideoHue,         TEXT("Attributes\\Video\\Hue") },
    { MpegAttrVideoMode,        TEXT("Attributes\\Video\\Mode") },
    { MpegAttrVideoSaturation,  TEXT("Attributes\\Video\\Saturation") },
    { MpegAttrVideoAGC,         TEXT("Attributes\\Video\\AGC") },
    { MpegAttrVideoClamp,       TEXT("Attributes\\Video\\Clamp") },
    { MpegAttrVideoCoring,      TEXT("Attributes\\Video\\Coring") },
    { MpegAttrVideoGain,        TEXT("Attributes\\Video\\Gain") },
    { MpegAttrVideoGenLock,     TEXT("Attributes\\Video\\GenLock") },
    { MpegAttrVideoSharpness,   TEXT("Attributes\\Video\\Sharpness") },
    { MpegAttrVideoSignalType,  TEXT("Attributes\\Video\\SignalType") },

    { MpegAttrOverlayXOffset,   TEXT("Attributes\\Overlay\\DestinationXOffset") },
    { MpegAttrOverlayYOffset,   TEXT("Attributes\\Overlay\\DestinationYOffset") },
};

#define NUMBER_MPEG_ATTRIBUTES \
    (sizeof(AttributeList) / sizeof(AttributeList[0]))

// define an MPEG device control block for each MPEG device in the system

#define MAX_MPEG_DEVICES    4

int     nMpegAdapters = 0;

MPEG_DEVICE_CONTROL_BLOCK MpegDcbs[MAX_MPEG_DEVICES];

//  {
//      "ReelMagic",
//      "SIGMA DESIGNS ReelMagic",
//      NULL,           // pseudo handle
//      0x0017,         // capabilities to indicate it supports audio, video,
//                      // separate streams and video overlay, nothing else
//      0,              // sequence number
//      {   // abstract devices
//          { FALSE, NULL,                  "Combined", NULL },
//          { TRUE,  "\\\\.\\MPEGAudio0",   "Audio",    NULL },
//          { TRUE,  "\\\\.\\MPEGVideo0",   "Video",    NULL },
//          { TRUE,  "\\\\.\\VideoOverlay", "Overlay",  NULL }
//      },
//      {   // attribute ranges
//          { (ULONG)0, (ULONG)0,      (ULONG)0 },
//          { (ULONG)0, (ULONG)0,      (ULONG)0 },
//          { (ULONG)0, (ULONG)0xFFFF, (ULONG)1 },      // left volume
//          { (ULONG)0, (ULONG)0xFFFF, (ULONG)1 },      // right volume
//          { (ULONG)0, (ULONG)0xFFFF, (ULONG)1 },      // both volumes
//          { (ULONG)0, (ULONG)0,      (ULONG)0 },
//          { (ULONG)0, (ULONG)0,      (ULONG)0 },
//          { (ULONG)0, (ULONG)0,      (ULONG)0 }
//      }
//  };

// extern  int     __cdecl atoi(char *);


// Unicode support for converting strings to integers

#ifdef UNICODE
int
atoiW(LPCWSTR strW)
{
    CHAR strA[128];

    WideCharToMultiByte(CP_ACP, 0, strW, -1, strA,
                        sizeof strA, NULL, NULL);

    return atoi(strA);
}
#define ATOI(str)   atoiW(str)
#else
#define ATOI(str)   atoi(str)
#endif

int
ReadRegistry()
{
    OSVERSIONINFO   OsVersionInfo;
    LONG            lResult;
    HKEY            hMpegKey;
    HKEY            hDeviceKey;
    FILETIME        ftLastWrite;
    TCHAR           szSubKeyName[256];
    DWORD           dwSubKeySize;
    DWORD           dwType;
    HKEY            hAttributeKey;
    union
    {
        DWORD   dwBinary;
        TCHAR   szString[80];
    }               regValue;
    DWORD           dwValueSize;
    int             idxDevice;
    int             iDeviceNumber;
    int             nAttributes;
    PABSTRACT_DEVICE_CONTROL_BLOCK pADcb;
    int             i;
    int             j;

    OsVersionInfo.dwOSVersionInfoSize = sizeof(OsVersionInfo);

    GetVersionEx(&OsVersionInfo);

    lResult = RegOpenKeyEx(
        HKEY_LOCAL_MACHINE,
        OsVersionInfo.dwPlatformId == VER_PLATFORM_WIN32_NT ?
            NT_MPEG_KEY : WIN95_MPEG_KEY,
        0,
        KEY_ALL_ACCESS,
        &hMpegKey);

    if (lResult != ERROR_SUCCESS)
    {
        return 0;
    }

    for (idxDevice = 0; idxDevice < MAX_MPEG_DEVICES; idxDevice++)
    {
        dwSubKeySize = sizeof(szSubKeyName);

        lResult = RegEnumKeyEx(
            hMpegKey, idxDevice, &szSubKeyName[0], &dwSubKeySize,
            NULL, NULL, NULL, &ftLastWrite);

        if (lResult != ERROR_SUCCESS)
        {
            break;
        }

        iDeviceNumber = ATOI(szSubKeyName);

        lResult = RegOpenKeyEx(
            hMpegKey, szSubKeyName, 0, KEY_ALL_ACCESS, &hDeviceKey);

        if (lResult != ERROR_SUCCESS)
        {
            break;
        }

        MpegDcbs[idxDevice].nDevice = iDeviceNumber;

        dwValueSize = sizeof(regValue);

        lResult = RegQueryValueEx(
            hDeviceKey, TEXT("Capabilities"), 0,
            &dwType, (PUCHAR)&regValue, &dwValueSize);

        if (lResult == ERROR_SUCCESS && dwType == REG_DWORD)
        {
            MpegDcbs[idxDevice].ulCapabilities = regValue.dwBinary;
        }
        else
        {
            MpegDcbs[idxDevice].ulCapabilities = 0;
        }

        dwValueSize = sizeof(regValue);

        lResult = RegQueryValueEx(
            hDeviceKey, TEXT("Description"), 0,
            &dwType, (PUCHAR)&regValue, &dwValueSize);

        if (lResult == ERROR_SUCCESS && dwType == REG_SZ)
        {
            lstrcpy(MpegDcbs[idxDevice].szDescription, regValue.szString);
        }
        else
        {
            MpegDcbs[idxDevice].szDescription[0] = '\0';
        }

        dwValueSize = sizeof(regValue);

        lResult = RegQueryValueEx(
            hDeviceKey, TEXT("AttributesLocked"), 0,
            &dwType, (PUCHAR)&regValue, &dwValueSize);

        if (lResult == ERROR_SUCCESS && dwType == REG_DWORD)
        {
            MpegDcbs[idxDevice].bAttributesLocked = regValue.dwBinary;
        }
        else
        {
            MpegDcbs[idxDevice].bAttributesLocked = FALSE;
        }

        nAttributes = 0;

        for (i = 0; i < NUMBER_MPEG_ATTRIBUTES; i++)
        {
            lResult = RegOpenKeyEx(
                hDeviceKey,
                AttributeList[i].pszKeyName,
                0,
                KEY_ALL_ACCESS,
                &hAttributeKey);

            if (lResult != ERROR_SUCCESS)
            {
                continue;
            }

            MpegDcbs[idxDevice].Attributes[nAttributes].eAttribute =
                AttributeList[i].eAttribute;

            dwValueSize = sizeof(regValue);

            lResult = RegQueryValueEx(
                hAttributeKey, TEXT("Minimum"), 0,
                &dwType, (PUCHAR)&regValue, &dwValueSize);

            if (lResult == ERROR_SUCCESS)
            {
                switch (dwType)
                {
                case REG_DWORD:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lMinimum =
                        regValue.dwBinary;
                    break;

                case REG_SZ:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lMinimum =
                        ATOI(regValue.szString);
                    break;

                default:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lMinimum = 0;
                    break;
                }
            }
            else
            {
                MpegDcbs[idxDevice].Attributes[nAttributes].lMinimum = 0;
            }

            dwValueSize = sizeof(regValue);

            lResult = RegQueryValueEx(
                hAttributeKey, TEXT("Maximum"), 0,
                &dwType, (PUCHAR)&regValue, &dwValueSize);

            if (lResult == ERROR_SUCCESS)
            {
                switch (dwType)
                {
                case REG_DWORD:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lMaximum = regValue.dwBinary;
                    break;

                case REG_SZ:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lMaximum =
                         ATOI(regValue.szString);
                    break;

                default:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lMaximum =
                        MpegDcbs[idxDevice].Attributes[nAttributes].lMinimum;
                    break;
                }
            }
            else
            {
                MpegDcbs[idxDevice].Attributes[nAttributes].lMaximum =
                    MpegDcbs[idxDevice].Attributes[nAttributes].lMinimum;
            }

            dwValueSize = sizeof(regValue);

            lResult = RegQueryValueEx(
                hAttributeKey, TEXT("Step"), 0,
                &dwType, (PUCHAR)&regValue, &dwValueSize);

            if (lResult == ERROR_SUCCESS)
            {
                switch (dwType)
                {
                case REG_DWORD:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lStep =
                        regValue.dwBinary;
                    break;

                case REG_SZ:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lStep =
                        ATOI(regValue.szString);
                    break;

                default:
                    MpegDcbs[idxDevice].Attributes[nAttributes].lStep = 1;
                    break;
                }
            }
            else
            {
                MpegDcbs[idxDevice].Attributes[nAttributes].lStep = 1;
            }

            for (j = 0; j < MAX_CHANNELS; j++)
            {
                TCHAR    szValueName[40];

                wsprintf(szValueName, TEXT("CurrentValue%d"), j);

                dwValueSize = sizeof(regValue);

                lResult = RegQueryValueEx(
                    hAttributeKey, szValueName, 0,
                    &dwType, (PUCHAR)&regValue, &dwValueSize);

                if (lResult == ERROR_SUCCESS)
                {
                    MpegDcbs[idxDevice].Attributes[nAttributes].eValueStatus[j] =
                            AttrValueUpdated;

                    switch (dwType)
                    {
                    case REG_DWORD:
                        MpegDcbs[idxDevice].Attributes[nAttributes].lCurrentValue[j] =

                            regValue.dwBinary;
                        break;

                    case REG_SZ:
                        MpegDcbs[idxDevice].Attributes[nAttributes].lCurrentValue[j] =
                            ATOI(regValue.szString);
                        break;

                    default:
                        MpegDcbs[idxDevice].Attributes[nAttributes].eValueStatus[j] =
                            AttrValueUnset;
                        break;
                    }
                }
                else
                {
                    MpegDcbs[idxDevice].Attributes[nAttributes].eValueStatus[j] =
                        AttrValueUnset;
                }
            }

            RegCloseKey(hAttributeKey);

            nAttributes++;
        }

        MpegDcbs[idxDevice].nAttributes = nAttributes;

        RegCloseKey(hDeviceKey);

        //
        // Init abstract devices
        //

        // We don't support any combined devices yet
        MpegDcbs[idxDevice].eAbstractDevices[MpegCombined].bIsAvailable = FALSE;

        // Audio Device
        pADcb = &MpegDcbs[idxDevice].eAbstractDevices[MpegAudio];
        pADcb->bIsAvailable = TRUE;
        pADcb->nCurrentChannel = 0;
        wsprintf(pADcb->szId, TEXT("\\\\.\\MpegAudio%d"), iDeviceNumber);
        pADcb->hAD = NULL;

        // Video Device
        pADcb = &MpegDcbs[idxDevice].eAbstractDevices[MpegVideo];
        pADcb->bIsAvailable = TRUE;
        pADcb->nCurrentChannel = 0;
        wsprintf(pADcb->szId, TEXT("\\\\.\\MpegVideo%d"), iDeviceNumber);
        pADcb->hAD = NULL;

        // Overlay Device
        pADcb = &MpegDcbs[idxDevice].eAbstractDevices[MpegOverlay];
        pADcb->bIsAvailable = TRUE;
        wsprintf(pADcb->szId, TEXT("\\\\.\\MpegOverlay%d"), iDeviceNumber);
        pADcb->hAD = NULL;
    }

    RegCloseKey(hMpegKey);

    return idxDevice;
}

int
WriteRegistry(USHORT idxDevice)
{
    OSVERSIONINFO   OsVersionInfo;
    LONG            lResult;
    HKEY            hMpegKey;
    HKEY            hDeviceKey;
    TCHAR           szSubKeyName[256];
    HKEY            hAttributeKey;
    int             nAttribute;
    int             i;
    int             j;

    OsVersionInfo.dwOSVersionInfoSize = sizeof(OsVersionInfo);

    GetVersionEx(&OsVersionInfo);

    lResult = RegOpenKeyEx(
        HKEY_LOCAL_MACHINE,
        OsVersionInfo.dwPlatformId == VER_PLATFORM_WIN32_NT ?
            NT_MPEG_KEY : WIN95_MPEG_KEY,
        0,
        KEY_ALL_ACCESS,
        &hMpegKey);

    if (lResult != ERROR_SUCCESS)
    {
        return 0;
    }

    wsprintf(szSubKeyName, TEXT("%d"), MpegDcbs[idxDevice].nDevice);

    lResult = RegOpenKeyEx(
        hMpegKey, szSubKeyName, 0, KEY_ALL_ACCESS, &hDeviceKey);

    if (lResult != ERROR_SUCCESS)
    {
        return 0;
    }

    nAttribute = 0;

    for (i = 0; i < NUMBER_MPEG_ATTRIBUTES; i++)
    {
        PMPEG_ATTRIBUTE_INFO    pAttributeInfo;


        if (nAttribute >= MpegDcbs[idxDevice].nAttributes)
        {
            break;
        }

        pAttributeInfo = &MpegDcbs[idxDevice].Attributes[nAttribute];

        if (AttributeList[i].eAttribute != pAttributeInfo->eAttribute)
        {
            continue;
        }

        lResult = RegOpenKeyEx(
            hDeviceKey,
            AttributeList[i].pszKeyName,
            0,
            KEY_ALL_ACCESS,
            &hAttributeKey);

        if (lResult != ERROR_SUCCESS)
        {
            continue;
        }

        for (j = 0; j < MAX_CHANNELS; j++)
        {
            TCHAR    szValueName[40];

            if (pAttributeInfo->eValueStatus[j] == AttrValueUnwritten)
            {
                wsprintf(szValueName, TEXT("CurrentValue%d"), j);

                lResult = RegSetValueEx(
                    hAttributeKey, szValueName, 0, REG_DWORD,
                    (PUCHAR)&pAttributeInfo->lCurrentValue[j], sizeof(DWORD));

                if (lResult != ERROR_SUCCESS)
                {
                    // Should do something here
                }
            }
        }

        RegCloseKey(hAttributeKey);

        nAttribute++;
    }

    RegCloseKey(hDeviceKey);

    RegCloseKey(hMpegKey);

    return idxDevice;
}

HMPEG_DEVICE
MpegADHandle(
    IN USHORT usIndex,
    IN MPEG_ABSTRACT_DEVICE_INDEX eIndex
    )
/*++

Routine Description:

    returns the handle of the specified abstract device

Auguments:

    usIndex       --    the index of the MPEG device
    eIndex        --    the index of the abstract device

Return Value:

    the handle

--*/
{
    return MpegDcbs[usIndex].eAbstractDevices[eIndex].hAD;
}

LPTSTR
MpegDeviceDescription(
    IN USHORT usIndex
    )
/*++

Routine Description:

    returns the device ID of the Mpeg device

Auguments:

    usIndex       --    the index of the MPEG device

Return Value:

    the device description

--*/
{
    return (LPTSTR)MpegDcbs[usIndex].szDescription;
}

MPEG_STATUS
CreateMpegHandle(
    IN USHORT usIndex,
    OUT PHMPEG_DEVICE phDevice
    )
/*++

Routine Description:

    opens the MPEG device and generates a handle for it

Auguments:

    usIndex       --    the index of the MPEG device
    phDevice      --    pointer to an HMPEG_DEVICE to be set to the
                        generated handle

Return Value:

    MpegStatusSuccess          -- the call completed successfully
    MpegStatusBusy             -- the iAdapterIndex supplied doesn't
                                  correspond to a valid adapter
    MpegStatusHardwareFailure  -- the size of description buffer is too small

--*/
{
    MPEG_STATUS mpegStatus;
    USHORT i;
    ULONG sn;
    PABSTRACT_DEVICE_CONTROL_BLOCK pADcb;

// NOTE: for the time being, the flags are hard-coded
    DWORD flags[] = {0, FILE_ATTRIBUTE_NORMAL | FILE_FLAG_OVERLAPPED,
                     FILE_ATTRIBUTE_NORMAL | FILE_FLAG_OVERLAPPED,
                     FILE_ATTRIBUTE_NORMAL};

    // check to see if the MPEG device is already in use
    if (MpegDcbs[usIndex].usSequenceNumber & 1) {
        return MpegStatusBusy;
    }

//ISSUE:  open device with no abstract sub devices

    for (i = 0; i < MAX_ABSTRACT_DEVICES; i++) {
        pADcb = MpegDcbs[usIndex].eAbstractDevices + i;
        if (pADcb->bIsAvailable) {
            ULONG Cookie;

            TraceSynchronousIoctlStart (&Cookie, 0, IOCTL_MPEG_PSEUDO_CREATE_FILE, NULL, NULL);
            pADcb->hAD = CreateFile(pADcb->szId, GENERIC_READ | GENERIC_WRITE,
                                    0, NULL, OPEN_EXISTING, flags[i], NULL);
            if (pADcb->hAD == INVALID_HANDLE_VALUE) {
                TraceSynchronousIoctlEnd (Cookie, GetLastError ());
                return MpegStatusHardwareFailure;
            }
            TraceSynchronousIoctlEnd (Cookie, ERROR_SUCCESS);
        }
    }

    // increase the sequence no
    sn = ++MpegDcbs[usIndex].usSequenceNumber;

    // the higher 16 bits corresponds to the seq no; the lower does to the index
    *phDevice = (HMPEG_DEVICE)((sn << 16) | usIndex);

    MpegQueryAttribute(
        *phDevice, MpegAttrAudioChannel,
        &MpegDcbs[usIndex].eAbstractDevices[MpegAudio].nCurrentChannel);

    MpegQueryAttribute(
        *phDevice, MpegAttrVideoChannel,
        &MpegDcbs[usIndex].eAbstractDevices[MpegVideo].nCurrentChannel);

    if ((mpegStatus = UpdateAttributes(usIndex, MpegAudio)) != MpegStatusSuccess ||
        (mpegStatus = UpdateAttributes(usIndex, MpegVideo)) != MpegStatusSuccess ||
        (mpegStatus = UpdateAttributes(usIndex, MpegOverlay)) != MpegStatusSuccess)
    {
        return mpegStatus;
    }

    return MpegStatusSuccess;
}


MPEG_STATUS
CreateMpegPseudoHandle(
    IN USHORT usIndex,
    OUT PHMPEG_DEVICE phDevice
    )
/*++

Routine Description:

    retrieves the pseudo handle of the MPEG device

Auguments:

    usIndex          --    index to the MPEG device
    phDevice         --    pointer to an HMPEG_DEVICE

Return Value:

    MpegStatusSuccess          -- the call completed successfully

--*/
{
    *phDevice = (HMPEG_DEVICE) (0xFFFF0000 | usIndex);

    return MpegStatusSuccess;
}


BOOL
HandleIsValid(
    IN HMPEG_DEVICE hDevice,
    OUT PUSHORT pusIndex
    )
/*++

Routine Description:

    checks whether the handle is valid and returns the index in pusIndex

Auguments:

    hDevice           --    handle representing the MPEG device
    pusIndex          --    pointer to the index

Return Value:

    TRUE if valid; otherwise FALSE

--*/
{
    USHORT index;

    index = (USHORT) (((ULONG)hDevice) & 0x0000FFFF);

    if ((index < 0) || (index >= nMpegAdapters)) {
      return FALSE;
    }

    if (MpegDcbs[index].usSequenceNumber != (USHORT) (((ULONG)hDevice) >> 16)) {
        return FALSE;
    }

    *pusIndex = index;

    return TRUE;
}

BOOL
PseudoHandleIsValid(
    IN HMPEG_DEVICE hDevice,
    OUT PUSHORT pusIndex
    )
/*++

Routine Description:

    checks whether the pseudo handle is valid and returns the index in pusIndex

Auguments:

    hDevice           --    pseudo handle representing the MPEG device
    pusIndex          --    pointer to the index

Return Value:

    TRUE if valid; otherwise FALSE

--*/
{
    USHORT index;

    index = (USHORT) (((ULONG)hDevice) & 0x0000FFFFU);

    if ((index < 0) || (index >= nMpegAdapters)) {
      return FALSE;
    }

    if (((DWORD)hDevice & 0xFFFF0000U) != 0xFFFF0000U) {
        return FALSE;
    }

    *pusIndex = index;

    return TRUE;
}

MPEG_STATUS
CloseMpegHandle(
    USHORT usIndex
    )
/*++

Routine Description:

    close the handle

Auguments:

    usIndex           --    index of the MPEG device

Return Value:

    MpegStatusSuccess          -- the call completed successfully

--*/
{
    USHORT i;
    PABSTRACT_DEVICE_CONTROL_BLOCK pADcb;

    // close abstract devices
    for (i = 0; i < MAX_ABSTRACT_DEVICES; i++) {
        pADcb = MpegDcbs[usIndex].eAbstractDevices + i;
        if (pADcb->bIsAvailable) {
            ULONG Cookie;

            TraceSynchronousIoctlStart (&Cookie, 0, IOCTL_MPEG_PSEUDO_CLOSE_HANDLE, NULL, NULL);
            if (CloseHandle(pADcb->hAD)) {
                TraceSynchronousIoctlEnd (Cookie, ERROR_SUCCESS);
            } else {
                TraceSynchronousIoctlEnd (Cookie, GetLastError ());
            }
            pADcb->hAD = NULL;
        }
    }

    //
    // Write out updated attributes
    //

    if (!MpegDcbs[usIndex].bAttributesLocked)
    {
        WriteRegistry(usIndex);
    }

    // increase the sequence no
    ++MpegDcbs[usIndex].usSequenceNumber;

    return MpegStatusSuccess;
}


BOOL
DeviceSupportCap(
    IN USHORT usIndex,
    IN MPEG_CAPABILITY eCapability
    )
/*++

Routine Description:

    checks whether the MPEG device has the specified capability

Auguments:

    usIndex          --    index of the MPEG device
    eCapability      --    indicates the interested capability

Return Value:

    TRUE if it does; otherwise FALSE.

--*/
{
    if (eCapability >= MpegCapMaximumCapability) {
        return FALSE;
    }

    return (MpegDcbs[usIndex].ulCapabilities & (1 << eCapability));
}

BOOL
DeviceSupportStream(
    IN USHORT usIndex,
    IN MPEG_STREAM_TYPE eStreamType
    )
/*++

Routine Description:

    checks whether the MPEG device supports the specified stream type

Auguments:

    usIndex        --    index of the MPEG device
    eStreamType    --    indicates the interested stream type

Return Value:

    TRUE if it does; otherwise FALSE.

--*/
{
    if (eStreamType != MpegSystemStream &&
        !DeviceSupportCap(usIndex, MpegCapSeparateStreams))
    {
        return FALSE;
    }

    switch (eStreamType) {
        case MpegSystemStream:
            return DeviceSupportCap(usIndex, MpegCapCombinedStreams);
        case MpegAudioStream:
            return DeviceSupportCap(usIndex, MpegCapAudioDevice);
        case MpegVideoStream:
            return DeviceSupportCap(usIndex, MpegCapVideoDevice);
        default:
            return FALSE;
    }
}

BOOL
DeviceSupportDevice(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType
    )
/*++

Routine Description:

    checks whether the MPEG device supports the specified stream type;
    when eDeviceType is MpegCombinedDevice, checks whether the device
    supports both audio and video

Auguments:

    usIndex        --    index of the MPEG device
    eDeviceType    --    indicates the interested device type

Return Value:

    TRUE if it does; otherwise FALSE.

--*/
{
    switch (eDeviceType)
    {
    case MpegCombinedDevice:
        return (DeviceSupportCap(usIndex, MpegCapAudioDevice) &&
                DeviceSupportCap(usIndex, MpegCapVideoDevice));
    case MpegAudioDevice:
        return DeviceSupportCap(usIndex, MpegCapAudioDevice);
    case MpegVideoDevice:
        return DeviceSupportCap(usIndex, MpegCapVideoDevice);
    case MpegOverlayDevice:
        return (DeviceSupportCap(usIndex, MpegCapBitmaskOverlay) ||
                DeviceSupportCap(usIndex, MpegCapChromaKeyOverlay));
    default:
        return FALSE;
    }
}


MPEG_STATUS
GetAttributeRange(
    IN USHORT usIndex,
    IN MPEG_ATTRIBUTE eAttribute,
    OUT PLONG plMinimum,
    OUT PLONG plMaximum,
    OUT PLONG plStep
    )
/*++

Routine Description:

    retrieves the attribute range for the specified attr.

Auguments:

    usIndex         --    index of the MPEG device
    eAttribute      --    indicates the interested attribute
    plMinimum       --    pointer to a LONG to be set to the minimum
    plMaximum       --    pointer to a LONG to be set to the maximum
    plStep          --    pointer to a LONG to be set to the step

Return Value:

    MpegStatusSuccess          -- the call completed successfully
    MpegStatusInvalidParameter -- the size of description buffer is too small

--*/
{
    PMPEG_DEVICE_CONTROL_BLOCK  pDcb;
    int                         idxAttribute;

    pDcb = &MpegDcbs[usIndex];

    for (idxAttribute = 0; idxAttribute < pDcb->nAttributes; idxAttribute++)
    {
        if (pDcb->Attributes[idxAttribute].eAttribute == eAttribute)
        {
            *plMinimum = pDcb->Attributes[idxAttribute].lMinimum;
            *plMaximum = pDcb->Attributes[idxAttribute].lMaximum;
            *plStep = pDcb->Attributes[idxAttribute].lStep;
            return MpegStatusSuccess;
        }
    }

    return MpegStatusUnsupported;
}


BOOL
DeviceIoControlSync(
    HMPEG_DEVICE  hDevice,
    DWORD   dwIoControlCode,
    LPVOID  lpInBuffer,
    DWORD   nInBufferSize,
    LPVOID  lpOutBuffer,
    DWORD   nOutBufferSize,
    LPDWORD lpBytesReturned
    )
/*++

Routine Description:

    simulate a synchronous IOCTL command

Auguments:

    hDevice           --    handle representing the device
    dwIoControlCode   --    control code of operation to perform
    lpInBuffer        --    address of buffer for input data
    nInBufferSize     --    size of input buffer
    lpOutBuffer       --    address of buffer for output data
    nOutBufferSize    --    size of output buffer
    lpBytesReturned   --    address of actual bytes of output

Return Value:

    TRUE if the function succeeds; otherwise FALSE.

--*/

{
    OVERLAPPED  overlapped;
    BOOL        fResult;
    DWORD       dwSavedError;
    DWORD       dwBytesRet;

    //Create an overlapped structure needed to perform an asynchronous operation
    overlapped.hEvent = CreateEvent(NULL, FALSE, FALSE, NULL);

    // Send the IOCTL asynchronously to the device

    switch (dwIoControlCode) {
    case IOCTL_MPEG_AUDIO_END_OF_STREAM:
    case IOCTL_MPEG_AUDIO_WRITE_PACKETS:
    case IOCTL_MPEG_VIDEO_END_OF_STREAM:
    case IOCTL_MPEG_VIDEO_WRITE_PACKETS:
        TracePacketsStart ((DWORD)hDevice,
                           dwIoControlCode,
                           &overlapped,
                           lpInBuffer,
                           nInBufferSize / (sizeof (MPEG_PACKET_LIST)));
        break;
    default:
        TraceIoctlStart ((DWORD)hDevice, dwIoControlCode, &overlapped, lpInBuffer, lpOutBuffer);
        break;
    }
    fResult = DeviceIoControl(hDevice, dwIoControlCode, lpInBuffer,
                              nInBufferSize, lpOutBuffer, nOutBufferSize,
                              lpBytesReturned, (LPOVERLAPPED)&overlapped);

    // If the operation did not complete, then block until it has finished
    if (!fResult && GetLastError() == ERROR_IO_PENDING) {
        fResult = GetOverlappedResult(hDevice, (LPOVERLAPPED)&overlapped,
                                      &dwBytesRet, TRUE);

       // dwBytesRet is what DeviceIoControl() would have
       // returned in lpBytesReturned
       // if it had completed synchronously.

       if (lpBytesReturned)
          *lpBytesReturned = dwBytesRet;
    }

    dwSavedError = GetLastError();

    if (fResult) {
        TraceIoctlEnd (&overlapped, ERROR_SUCCESS);
    } else {
        TraceIoctlEnd (&overlapped, dwSavedError);
    }

    CloseHandle(overlapped.hEvent);

    SetLastError(dwSavedError);

    return fResult;
}

MPEG_STATUS
MpegTranslateWin32Error(
    DWORD dwWin32Error
    )
/*++

Routine Description:

    Translate a WIN32 error code into an equivalent MPEG status code.

Auguments:

    dwWin32Error -- WIN32 error code to be translated.

Return Value:

    MPEG status code.

--*/
{
    switch (dwWin32Error)
    {
    case NO_ERROR:
        return MpegStatusSuccess;

    case ERROR_INVALID_FUNCTION:    // STATUS_NOT_IMPLEMENTED
        return MpegStatusUnsupported;

    case ERROR_INVALID_PARAMETER:   // STATUS_INVALID_PARAMETER
        return MpegStatusInvalidParameter;

    case ERROR_OPERATION_ABORTED:
        return MpegStatusCancelled;

    case ERROR_REVISION_MISMATCH:   // STATUS_REVISION_MISMATCH
        return MpegStatusHardwareFailure;

    default:
        // Fall Thru for now

    case ERROR_IO_DEVICE:           // STATUS_IO_DEVICE_ERROR
    case ERROR_GEN_FAILURE:         // STATUS_UNSUCCESSFUL
        return MpegStatusHardwareFailure;
    }
}

MPEG_STATUS
SetCurrentChannel(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN INT nChannel
    )
/*++

Routine Description:

    Set the current channel for the given abstract device.

Auguments:

    usIndex     -- Index of miniport
    eDeviceType -- Index of abstract device
    nChannel    -- New channel

Return Value:

    MPEG status code.

--*/
{
    MpegDcbs[usIndex].eAbstractDevices[eDeviceType].nCurrentChannel = nChannel;

    return UpdateAttributes(usIndex, eDeviceType);
}

MPEG_STATUS
GetCurrentChannel(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType,
    OUT PINT pnChannel
    )
/*++

Routine Description:

    Get the current channel for the given abstract device.

Auguments:

    usIndex     -- Index of miniport
    eDeviceType -- Index of abstract device
    pnChannel   -- Address to place current channel

Return Value:

    MPEG status code.

--*/
{
    *pnChannel = MpegDcbs[usIndex].eAbstractDevices[eDeviceType].nCurrentChannel;
    return MpegStatusSuccess;
}

MPEG_STATUS
SetCurrentAttributeValue(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN MPEG_ATTRIBUTE eAttribute,
    IN LONG lValue
    )
/*++

Routine Description:

    Sets the current value for the given attribute based on the current
    channel for the given abstract device.

Auguments:

    usIndex     -- Index of miniport
    eDeviceType -- Index of abstract device
    eAttribute  -- Attribute to set
    lValue      -- New value for the attribute

Return Value:

    MPEG status code.

--*/
{
    PMPEG_DEVICE_CONTROL_BLOCK  pDcb;
    PMPEG_ATTRIBUTE_INFO        pAttributeInfo;
    int                         nCurrentChannel;

    pDcb = &MpegDcbs[usIndex];
    nCurrentChannel = pDcb->eAbstractDevices[ eDeviceType ].nCurrentChannel;

    for (pAttributeInfo = &pDcb->Attributes[0];
        pAttributeInfo < &pDcb->Attributes[ pDcb->nAttributes ];
        pAttributeInfo++)
    {
        if (pAttributeInfo->eAttribute == eAttribute)
        {
            pAttributeInfo->lCurrentValue[ nCurrentChannel ] = lValue;
            pAttributeInfo->eValueStatus[ nCurrentChannel ] = AttrValueUnwritten;
            return MpegStatusSuccess;
        }
    }

    return MpegStatusUnsupported;
}

MPEG_STATUS
UpdateAttributes(
    IN USHORT usIndex,
    IN MPEG_DEVICE_TYPE eDeviceType
    )
/*++

Routine Description:

    Update the attribute values for the given abstract device.

Auguments:

    usIndex     -- Index of miniport
    eDeviceType -- Index of abstract device

Return Value:

    MPEG status code.

--*/
{
    PMPEG_DEVICE_CONTROL_BLOCK  pDcb;
    PMPEG_ATTRIBUTE_INFO pAttributeInfo;
    HMPEG_DEVICE hAD;
    DWORD dwIoctlCode;
    DWORD cbReturn;
    MPEG_ATTRIBUTE_PARAMS attribute;
    int nCurrentChannel;

    if (eDeviceType == MpegAudio)
    {
        dwIoctlCode = IOCTL_MPEG_AUDIO_SET_ATTRIBUTE;
    }
    else if (eDeviceType == MpegVideo)
    {
        dwIoctlCode = IOCTL_MPEG_VIDEO_SET_ATTRIBUTE;
    }
    else if (eDeviceType == MpegOverlay)
    {
        dwIoctlCode = IOCTL_MPEG_OVERLAY_SET_ATTRIBUTE;
    }
    else
    {
        return MpegStatusUnsupported;
    }

    hAD = MpegADHandle(usIndex, eDeviceType);
    pDcb = &MpegDcbs[usIndex];
    nCurrentChannel = pDcb->eAbstractDevices[eDeviceType].nCurrentChannel;

    // Set each updated value

    for (pAttributeInfo = pDcb->Attributes;
        pAttributeInfo < &pDcb->Attributes[ pDcb->nAttributes ];
        pAttributeInfo++)
    {
        if (pAttributeInfo->eValueStatus[nCurrentChannel] != AttrValueUpdated)
        {
            continue;
        }

        if (pAttributeInfo->eAttribute < MpegAttrMaximumAudioAttribute)
        {
            if (eDeviceType != MpegAudio)
            {
                continue;
            }
        }
        else if (pAttributeInfo->eAttribute < MpegAttrMaximumVideoAttribute)
        {
            if (eDeviceType != MpegVideo)
            {
                continue;
            }
        }
        else
        {
            if (eDeviceType != MpegOverlay)
            {
                continue;
            }
        }

        attribute.Attribute = pAttributeInfo->eAttribute;
        attribute.Value = pAttributeInfo->lCurrentValue[nCurrentChannel];

        if (!DeviceIoControlSync(
            hAD, dwIoctlCode,
            &attribute, sizeof(attribute),
            NULL, 0, &cbReturn))
        {
            return MpegTranslateWin32Error(GetLastError());
        }

        pAttributeInfo->eValueStatus[nCurrentChannel] = AttrValueUnset;
    }

    return MpegStatusSuccess;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\mpegmini.h ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    MPEGMINI.H

Abstract:

    This file defines the interface between MPEG mini-port drivers and the
    MPEG port driver.

Author:

    Paul Shih (paulsh) 27-Mar-1994
    Paul Lever (a-paull)

Environment:

   Kernel mode only

Revision History:

--*/

#ifndef _MPEGMINI_H
#define _MPEGMINI_H

#include "mpegcmn.h"

#define MPEGAPI __stdcall

typedef enum {              // Use the given level to indicate:
    DebugLevelFatal = 0,   // * imminent nonrecoverable system failure
    DebugLevelError,       // * serious error, though recoverable
    DebugLevelWarning,     // * warnings of unusual occurances
    DebugLevelInfo,        // * status and other information - normal though
                            //   perhaps unusual events. System MUST remain
                            //   responsive.
    DebugLevelTrace,       // * trace information - normal events
                            //   system need not ramain responsive
    DebugLevelVerbose,     // * verbose trace information
                            //   system need not remain responsive
    DebugLevelMaximum
}   DEBUG_LEVEL;

#if DBG

#define DEBUG_PRINT(x) MpegDebugPrint x
#define DEBUG_BREAKPOINT MpegDebugBreakPoint

#define DEBUG_ASSERT(exp) \
            if ( !(exp) ) { \
                MpegDebugAssert( __FILE__, __LINE__, #exp, exp); \
            }

#else

#define DEBUG_PRINT(x)
#define DEBUG_BREAKPOINT
#define DEBUG_ASSERT(exp)

#endif

    // Uninitialized flag value.
#define MP_UNINITIALIZED_VALUE ((ULONG) ~0)


    // Devices supported on an HBA
typedef enum _CONTROL_DEVICE
{
    VideoDevice,
    AudioDevice,
    OverlayDevice,
    MaximumControlDevice
} CONTROL_DEVICE;


//
//  MRB code, and strctus
//

    // MRB command codes

typedef enum _MRB_COMMAND {                 // Parameter structure

    MrbCommandVideoReset = 0x100,       // no parameters
    MrbCommandVideoCancel,              // no parameters
    MrbCommandVideoPlay,                // no parameters
    MrbCommandVideoPause,               // no parameters
    MrbCommandVideoStop,                // no parameters
    MrbCommandVideoGetStc,              // MPEG_TIMESTAMP
    MrbCommandVideoSetStc,              // MPEG_TIMESTAMP
    MrbCommandVideoQueryInfo,           // VIDEO_DEVICE_INFO
    MrbCommandVideoEndOfStream,         // no parameters
    MrbCommandVideoPacket,              // MPEG_PACKET
    MrbCommandVideoClearBuffer,         // no parameters
    MrbCommandVideoGetAttribute,        // MPEG_ATTRIBUTE
    MrbCommandVideoSetAttribute,        // MPEG_ATTRIBUTE

    MrbCommandAudioReset = 0x200,       // no parameters
    MrbCommandAudioCancel,              // no parameters
    MrbCommandAudioPlay,                // no parameters
    MrbCommandAudioPause,               // no parameters
    MrbCommandAudioStop,                // no parameters
    MrbCommandAudioGetStc,              // MPEG_TIMESTAMP
    MrbCommandAudioSetStc,              // MPEG_TIMESTAMP
    MrbCommandAudioQueryInfo,           // AUDIO_DEVICE_INFO
    MrbCommandAudioEndOfStream,         // no parameters
    MrbCommandAudioPacket,              // MPEG_PACKET
    MrbCommandAudioGetAttribute,        // MPEG_ATTRIBUTE
    MrbCommandAudioSetAttribute,        // MPEG_ATTRIBUTE

    MrbCommandOverlayGetMode = 0x400,   // OVERLAY_MODE
    MrbCommandOverlaySetMode,           // OVERLAY_MODE
    MrbCommandOverlayGetVgaKey,         // OVERLAY_KEY
    MrbCommandOverlaySetVgaKey,         // OVERLAY_KEY
    MrbCommandOverlayGetDestination,    // OVERLAY_PLACEMENT
    MrbCommandOverlaySetDestination,    // OVERLAY_PLACEMENT
    MrbCommandOverlayEnable,            // OVERLAY_ENABLE
    MrbCommandOverlayDisable,           // no parameters
    MrbCommandOverlayUpdateClut,        // OVERLAY_CLUT
    MrbCommandOverlayGetAttribute,      // MPEG_ATTRIBUTE
    MrbCommandOverlaySetAttribute,      // MPEG_ATTRIBUTE
    MrbCommandOverlayQueryInfo,         // OVERLAY_DEVICE_INFO
    MrbCommandOverlaySetBitMask         // MPEG_OVERLAY_BIT_MASK

} MRB_COMMAND;

    // MRB status (command completion) codes

typedef enum _MRB_STATUS {

    MrbStatusSuccess = 0,
    MrbStatusCancelled,
    MrbStatusError,
    MrbStatusInvalidParameter,
    MrbStatusInvalidData,
    MrbStatusDeviceFailure,
    MrbStatusVersionMismatch,
    MrbStatusUnsupportedComand,
    MrbStatusDeviceBusy,

} MRB_STATUS;

#define MRB_INVALID_STATUS 0xffff

    // MPEG packet header information
typedef struct _MPEG_PACKET {
    ULONGLONG PtsValue;             // presentation time stamp
    ULONGLONG DtsValue;             // decode time stamp
    ULONG StreamNumber;             // packet stream id
    ULONG PacketTotalSize;          // total size of the packet including header
    ULONG PacketHeaderSize;         // size of compressed header (in bytes)
    ULONG PacketPayloadSize;        // size of the actuly data (full packet-header)
    PVOID PacketData;               // pointer to the MPEG packet
    ULONGLONG ScrValue;             // system SCR time for this packet
} MPEG_PACKET,*PMPEG_PACKET;

// Audio device information
typedef struct _AUDIO_DEVICEINFO {
    MPEG_DEVICE_STATE DeviceState;// MPEG device decode state
    ULONG DecoderBufferSize;      // Size of the decoder buffer
    ULONG DecoderBufferFullness;  // Byte count of data in decoder buffer
    ULONG StarvationCount;        // Number of times device was starved
} AUDIO_DEVICEINFO,*PAUDIO_DEVICEINFO;


// Video device information
typedef struct _VIDEO_DEVICEINFO {
    MPEG_DEVICE_STATE DeviceState;// MPEG device decode state
    ULONG DecoderBufferSize;      // Size of the decoder buffer
    ULONG DecoderBufferFullness;  // Byte count of data in decoder buffer
    ULONG DecompressHeight;       // Native MPEG decompress height
    ULONG DecompressWidth;        // Native MPEG decompress width
    ULONG StarvationCount;        // Number of times device was starved
} VIDEO_DEVICEINFO,*PVIDEO_DEVICEINFO;

// Overlay device information
typedef struct _OVERLAY_DEVICEINFO {
    ULONG MinDestinationHeight;         // Minimum height of overlay
    ULONG MaxDestinationHeight;         // Maximum height of overlay
    ULONG MinDestinationWidth;          // Minimum width of overlay
    ULONG MaxDestinationWidth;          // Maximum width of overlay
} OVERLAY_DEVICEINFO, *POVERLAY_DEVICEINFO;

    // Overlay VGA key
typedef struct _OVERLAY_KEY {
    ULONG   Key;                    // palette index or RGB color
    ULONG   Mask;                   // significant bits in color
} OVERLAY_KEY,*POVERLAY_KEY;


    // Overlay enable
typedef struct _OVERLAY_ENABLE {
    LONG    DisWMax;                // display width
    LONG    DisHMax;                // display height
    LONG    ScreenStride;           // Bytes per line
    LONG    DisXAdj;                // overlay X alignment adjustment
    LONG    DisYAdj;                // overlay Y alignment adjustment
    LONG    BitsPerPixel;           // bits used to represent a pixel
    LONG    NumberRedBits;          // in DAC on graphics card
    LONG    NumberGreenBits;
    LONG    NumberBlueBits;
    LONG    RedMask;                // Red color mask for device w/ direct color modes
    LONG    GreenMask;
    LONG    BlueMask;
    LONG    AttributeFlags;
} OVERLAY_ENABLE,*POVERLAY_ENABLE;

typedef struct _RGBX {
    UCHAR Red;       // red bits of the pixel
    UCHAR Green;     // green bits of the pixel
    UCHAR Blue;      // blue bits of the pixel
    UCHAR Unused;
} RGBX, *PRGBX;

typedef union {
    RGBX RgbColor;
    ULONG RgbLong;
} COLORLUT, *PCOLORLUT;

typedef struct  _COLORLUT_DATA {
    USHORT NumEntries;  // Number of entries in the CLUT RGBArray
    USHORT FirstEntry;  // Location in the device palette to which the
                        //      first entry in the CLUT is copied.  The other
                        //      entries in the CLUT are copied sequentially
                        //      into the device palette from the starting
                        //      point.
    PCOLORLUT RgbArray; // The CLUT to copy into the device color registers
                        //      (palette).
} COLORLUT_DATA, *PCOLORLUT_DATA;

    // Overlay CLUT
typedef struct _OVERLAY_CLUT {
    PCOLORLUT_DATA ClutData;            // pointer to CLUT data
} OVERLAY_CLUT,*POVERLAY_CLUT;

    // MPEG I/O Request Block
typedef struct _MPEG_REQUEST_BLOCK {
    ULONG Length;            // sizeof MPEG_REQUEST_BLOCK (version check)
    MRB_COMMAND Command;     // MRB command, see MRB_COMMAND_xxx
    MRB_STATUS Status;       // MRB completion status, see MRB_STATUS_xxx
    ULONG Reserved;          // reserved for use by the port driver
    union _commandData {
        MPEG_PACKET Packet;
        MPEG_SYSTEM_TIME Timestamp;
        AUDIO_DEVICEINFO AudioDeviceInfo;
        VIDEO_DEVICEINFO VideoDeviceInfo;
        MPEG_OVERLAY_MODE Mode;
        OVERLAY_KEY Key;
        MPEG_OVERLAY_PLACEMENT Placement;
        OVERLAY_ENABLE Enable;
        MPEG_OVERLAY_BIT_MASK OverlayBitMask;
        OVERLAY_CLUT Clut;
        OVERLAY_DEVICEINFO OverlayDeviceInfo;
        MPEG_ATTRIBUTE_PARAMS Attribute;
    } CommandData;
} MPEG_REQUEST_BLOCK, *PMPEG_REQUEST_BLOCK;

#define MPEG_REQUEST_BLOCK_SIZE sizeof(MPEG_REQUEST_BLOCK)


    // Interrupt Configuration Information
typedef struct _INTERRUPT_CONFIGURATION
{
    ULONG BusInterruptLevel;            // Interrupt request level for device
    ULONG BusInterruptVector;           // Bus interrupt vector used with hardware
                                        //   buses which use a vector as
                                        //   well as level, such as internal buses.
    KINTERRUPT_MODE InterruptMode;      // Interrupt mode (level-sensitive or
                                        //   edge-triggered)
} INTERRUPT_CONFIGURATION, *PINTERRUPT_CONFIGURATION;

    // DMA Channel Configuration Information
typedef struct _DMA_CONFIGURATION
{
    ULONG DmaChannel;                   // Specifies the DMA channel used by a
                                        //   slave HBA. By default, the value of
                                        //   this member is 0xFFFFFFFF. If the
                                        //   HBA uses a system DMA controller and
                                        //   the given AdapterInterfaceType is
                                        //   any value except MicroChannel, the
                                        //   miniport driver must reset this member.
    ULONG DmaPort;                      // Specifies the DMA port used by a slave
                                        //   HBA. By default, the value of this
                                        //   member is zero. If the HBA uses a
                                        //   system DMA controller and the given
                                        //   AdapterInterfaceType is MicroChannel,
                                        //   the miniport driver must reset this
                                        //   member.
    DMA_WIDTH DmaWidth;                 // Specifies the width of the DMA transfer:
                                        //   Width8Bits, Width16Bits or Width32Bits
    DMA_SPEED DmaSpeed;                 // Specifies the DMA transfer speed for EISA
                                        //   type HBAs. By default, the value specifies
                                        //   compatibility timing: Compatible,
                                        //   TypeA, TypeB or TypeC
    BOOLEAN Dma32BitAddresses;          // TRUE indicates that the HBA has 32 address
                                        //   lines and can access memory with physical
                                        //   addresses greater than 24 bits.
    BOOLEAN DemandMode;                 // TRUE indicates the system DMA controller
                                        //   should be programmed for demand-mode rather
                                        //   than single-cycle operations. If the HBA
                                        //   is not a slave device, this member should
                                        //   be FALSE. ?????
    BOOLEAN Master;                     // Indicates that the adapter is a bus master ????
    BOOLEAN MapBuffers;                 // Buffers must be mapped into system space
    ULONG   MaximumTransferLength;      // max number of bytes device can handle per
                                                                                //   DMA operation
 } DMA_CONFIGURATION, *PDMA_CONFIGURATION;

    // Special Initialization Data Configuration Information
    //  This data may be obtained by the Port driver from a Registry or Initialzation
    //  file or sequence.
typedef struct _SPECIAL_INIT_CONFIGURATION
{
    ULONG Length;                       // Specifies the length of the data buffer in bytes
    PVOID DataBuffer;                   // Pointer to data buffer
} SPECIAL_INIT_CONFIGURATION, *PSPECIAL_INIT_CONFIGURATION;

    // Video Mode information passed to the mini-port on start-up
typedef struct  _VIDEO_MODE_DATA {
    ULONG   ScreenWidth;        // Number of visible horizontal pixels on a scan line
    ULONG   ScreenHeight;       // Numbee, in pixels, of visible scan lines.
    ULONG   ScreenStride;       // Bytes per line
    ULONG   NumberOfPlanes;     // Number of separate planes combined by the video hardware
    ULONG   BitsPerPlane;       // Number of bits per pixel on a plane
    ULONG   Frequency;          // Frequency of the screen, in hertz.
    ULONG   NumberRedBits;      // Number of bits in the red DAC
    ULONG   NumberGreenBits;    // Number of bits in the Green DAC.
    ULONG   NumberBlueBits;     // Number of bits in the blue DAC.
    ULONG   RedMask;            // Red color mask.  Bits turned on indicated the color red
    ULONG   GreenMask;          // Green color mask.  Bits turned on indicated the color green
    ULONG   BlueMask;           // Blue color mask.  Bits turned on indicated the color blue
    ULONG   AttributeFlags;     // Flags indicating certain device behavior.
                                // It's an logical-OR summation of MODE_xxx flags.
}   VIDEO_MODE_DATA, *PVIDEO_MODE_DATA;
                                // AttributeFlags definitions
#define MODE_COLOR              0x01    // 0 = monochrome; 1 = color
#define MODE_GRAPHICS           0x02    // 0 = text mode; 1 = graphics mode
#define MODE_INTERLACED         0x04    // 0 = non-interlaced; 1 = interlaced
#define MODE_PALETTE_DRIVEN     0x08    // 0 = colors direct; 1 = colors indexed to a palette
#define MODE_VALID_DATA       0x8000    // 0 = VIDEO_MADE_DATA not valid; 1 = VIDEO_MODE_DATA valid
                                        //     if MODE_INVALID_DATA is 0, then none of the data
                                        //     within the VIDEO_MODE_DATA structure is valid




typedef PHYSICAL_ADDRESS MPEG_PHYSICAL_ADDRESS, *PMPEG_PHYSICAL_ADDRESS;
    // I/O and Memory address ranges
typedef struct _ACCESS_RANGE {
    MPEG_PHYSICAL_ADDRESS RangeStart;
    ULONG RangeLength;
    BOOLEAN RangeInMemory;
} ACCESS_RANGE, *PACCESS_RANGE;


    // Configuration information structure.  Contains the information necessary
    // to initialize the adapter.
typedef struct _PORT_CONFIGURATION_INFORMATION
{
    ULONG Length;                       // Size of this structure, used as version check

    ULONG SystemIoBusNumber;            // IO bus number (0 for machines that have
                                        //   only 1 IO bus)

    INTERFACE_TYPE  AdapterInterfaceType; // Adapter interface type supported by HBA:
                                        //          Internal
                                        //          Isa
                                        //          Eisa
                                        //          MicroChannel
                                        //          TurboChannel
                                        //          PCIBus
                                        //          VMEBus
                                        //          NuBus
                                        //          PCMCIABus
                                        //          CBus
                                        //          MPIBus
                                        //          MPSABus

                                        //  Interrupt descriptions
    INTERRUPT_CONFIGURATION Interrupts[MaximumControlDevice];

                                        // DMA CHannel descriptions
    DMA_CONFIGURATION DmaChannels[MaximumControlDevice];

    ULONG NumberOfAccessRanges;         // Number of access ranges allocated
                //  Specifies the number of AccessRanges elements in the array,
                //  described next. The OS-specific port driver always sets this
                //  member to the value passed in the HW_INITIALIZATION_DATA
                //  structure when the miniport driver called MpegPortInitialize.
    ACCESS_RANGE (*AccessRanges)[];    // Pointer to array of access range elements
                //  Points to an array of ACCESS_RANGE-type elements. The given
                //  NumberOfAccessRanges determines how many elements must be
                //  configured with bus-relative range values. The AccessRanges
                //  pointer must be NULL if NumberOfAccessRanges is zero.

                                        // Initialization special data,
                                        //   miniport dependent.
    SPECIAL_INIT_CONFIGURATION Special[MaximumControlDevice];

    ULONGLONG CounterFrequency;         // frequency of high resolution counter
                                        //  in Hertz (cycles per second)

    VIDEO_MODE_DATA VideoMode;          // Video mode information

} PORT_CONFIGURATION_INFORMATION, *PPORT_CONFIGURATION_INFORMATION;



    // MPEG Adapter Dependent Routines
typedef
BOOLEAN
(MPEGAPI *PHW_INITIALIZE) (
    IN PVOID DeviceExtension
    );

typedef
BOOLEAN
(MPEGAPI *PHW_UNINITIALIZE) (
    IN PVOID DeviceExtension
    );

typedef
BOOLEAN
(MPEGAPI *PHW_STARTIO) (
    IN PVOID DeviceExtension,
    IN PMPEG_REQUEST_BLOCK Mrb
    );

typedef
BOOLEAN
(MPEGAPI *PHW_INTERRUPT) (
    IN PVOID DeviceExtension
    );

typedef
VOID
(MPEGAPI *PHW_TIMER) (
    IN PVOID DeviceExtension
    );

typedef
VOID
(MPEGAPI *PHW_DEFFERED_CALLBACK) (
    IN PVOID DeviceExtension
    );

typedef
VOID
(MPEGAPI *PHW_ENABLE_BOARD_INTERRUPTS) (
    IN PVOID DeviceExtension
    );

typedef
VOID
(MPEGAPI *PHW_DMA_STARTED) (
    IN PVOID DeviceExtension
    );

typedef
ULONG
(MPEGAPI *PHW_FIND_ADAPTER) (
    IN PVOID DeviceExtension,
    IN PVOID HwContext,
    IN PVOID BusInformation,
    IN PCHAR ArgumentString,
    IN OUT PPORT_CONFIGURATION_INFORMATION ConfigInfo,
    OUT PBOOLEAN Again
    );



    // Structure passed between Miniport initialization
    // and MPEG port initialization
typedef struct _HW_INITIALIZATION_DATA {

    ULONG HwInitializationDataSize;     // Size of this structure, used as version check

    INTERFACE_TYPE  AdapterInterfaceType; // Adapter interface type supported by HBA:
                                        //          Internal
                                        //          Isa
                                        //          Eisa
                                        //          MicroChannel
                                        //          TurboChannel
                                        //          PCIBus
                                        //          VMEBus
                                        //          NuBus
                                        //          PCMCIABus
                                        //          CBus
                                        //          MPIBus
                                        //          MPSABus

                                        // Miniport driver routine pointers:
    PHW_INITIALIZE HwInitialize;        //   points to miniport's HwMpegInitialize routine
    PHW_UNINITIALIZE HwUnInitialize;    //   points to miniport's HwMpegUnInitialize routine
    PHW_STARTIO    HwStartIo;           //   points to miniport's HwMpegStartIo routine
    PHW_FIND_ADAPTER HwFindAdapter;     //   points to miniport's HwMpegFindAdapter routine
                                        //   points to miniport's HwMpegXXXInterrupt routines
    PHW_INTERRUPT  HwInterrupt[MaximumControlDevice];

                                        // Miniport driver resources
    ULONG DeviceExtensionSize;          //   size in bytes of the miniports per-HBA device
                                        //    extension data
    ULONG NumberOfAccessRanges;         //   number of access ranges required by miniport
                                        //    (memory or I/O addresses)

    ULONG NumberOfTimers;               // Number of timers required by Miniport

                                        // Vendor and Device identification
    USHORT VendorIdLength;              //   size in bytes of VendorId
    PVOID  VendorId;                    //   points to ASCII byte string identifying
                                        //    the manufacturer of the HBA. If
                                        //    AdapterInterfaceType is PCIBus, then the
                                        //    vendor ID is a USHORT represented as a
                                        //    string (ID 1001 is '1','0','0','1')
    USHORT DeviceIdLength;              //   size in bytes of DeviceId
    PVOID  DeviceId;                    //   points to ASCII byte string identifying
                                        //    the HBA model supported by the miniport.
                                        //    If AdapterInterfaceType is PCIBus, then
                                        //    the device ID is a USHORT represented as a
                                        //    string. If the miniport can support PCI
                                        //    devices with IDs 8040 and 8050,it might
                                        //    set the DeviceId with a pointer to the
                                        //    byte string  ('8','0')
    BOOLEAN NoDynamicRelocation;        // On dynamically configurable I/O busses, when set
                                        //    to TRUE, inhibits re-configuring. Currently this
                                        //    is limited to PCIbus. This flag can be set when a
                                        //    PCI Mpeg device is on the same adapter (and same
                                        //    function code) as the Video hardware and therefore
                                        //    can't be moved.
} HW_INITIALIZATION_DATA, *PHW_INITIALIZATION_DATA;



//
// MRB Functions
//


//
// MRB Status
//


//
// MRB Flag Bits
//
//
// Port driver error codes
//


//
// Return values for MPEG_HW_FIND_ADAPTER and HardwareInitialization
//

typedef enum _MP_RETURN_CODES{
     MP_RETURN_FOUND,               // adapter found OK
     MP_RETURN_NOT_FOUND,           // adapter not found
     MP_RETURN_ERROR,               // generic error
     MP_RETURN_BAD_CONFIG,          // configuration structure invalid
     MP_RETURN_REVISION_MISMATCH,   // configuration structure size mismatch
     MP_RETURN_INSUFFICIENT_RESOURCES, // Not enough access ranges
     MP_RETURN_INVALID_INTERRUPT,   // no interrupt specified, or unusable interrupt
     MP_RETURN_INVALID_DMA,         // No DMA channel specified or usuable channel
     MP_RETURN_NO_DMA_BUFFER,       // DMA buffer of sufficient size not available
     MP_RETURN_INVALID_MEMORY,      // no Memory I/O address specified or unusable address
     MP_RETURN_INVALID_PORT,        // no Port I/O address specified or unusable address
     MP_RETURN_HW_REVISION,         // revision of  H/W detected is not supported by driver
     MP_RETURN_BAD_VIDEO_MODE,      // Video data supplied is insufficient or unsupported
     MP_RETURN_VIDEO_INITIALIZATION_FAILED, // Video failed to initialize
     MP_RETURN_AUDIO_INITIALIZATION_FAILED, // Audio failed to initialize
     MP_RETURN_OVERLAY_INITIALIZATION_FAILED, // Overlay failed to initialize
     MP_RETURN_VIDEO_FAILED,        // Video failed
     MP_RETURN_AUDIO_FAILED,        // Audio failed 
     MP_RETURN_OVERLAY_FAILED,      // Overlay failed
} MP_RETURN_CODES, *PMP_RETURN_CODES;

//
// Port driver error codes
//

#define MP_INTERNAL_ADAPTER_ERROR   0x0006
#define MP_IRQ_NOT_RESPONDING       0x0008


//
// Notification Event Types
//

typedef enum _MPEG_NOTIFICATION_TYPE {
    RequestComplete,
    NextRequest,
    CallDisableInterrupts,
    CallEnableInterrupts,
    RequestTimerCall,
    StatusPending,
    DeviceFailure,
    LogError,
    NotificationMaximum
} MPEG_NOTIFICATION_TYPE, *PMPEG_NOTIFICATION_TYPE;





//
//  Port export routines
//


ULONG
MPEGAPI
MpegPortInitialize(
    IN PVOID Argument1,
    IN PVOID Argument2,
    IN PHW_INITIALIZATION_DATA HwInitializationData,
    IN PVOID HwContext OPTIONAL
    );

VOID
MPEGAPI
MpegPortRequestDma(
    IN CONTROL_DEVICE DeviceType,
    IN PVOID HwDeviceExtension,
    IN PHW_DMA_STARTED HwDmaStarted,
    IN PMPEG_REQUEST_BLOCK Mrb,
    IN PVOID LogicalAddress,
    IN ULONG Length
    );

VOID
MPEGAPI
MpegPortNotification(
    IN MPEG_NOTIFICATION_TYPE NotificationType,
    IN CONTROL_DEVICE DeviceType,
    IN PVOID HwDeviceExtension,
    ...
    );

VOID
MPEGAPI
MpegPortZeroMemory(
    IN PVOID WriteBuffer,
    IN ULONG Length
    );

VOID
MPEGAPI
MpegPortMoveMemory(
    IN PVOID WriteBuffer,
    IN PVOID ReadBuffer,
    IN ULONG Length
    );

MPEG_PHYSICAL_ADDRESS
MPEGAPI
MpegPortConvertUlongToPhysicalAddress(
    IN ULONG UlongAddress
    );

ULONG
MPEGAPI
MpegPortConvertPhysicalAddressToUlong(
    IN MPEG_PHYSICAL_ADDRESS Address
    );

#define MPEG_PORT_CONVERT_PHYSICAL_ADDRESS_TO_ULONG(Address) ((Address).LowPart)

VOID
MPEGAPI
MpegPortFlushDma(
    IN CONTROL_DEVICE DeviceType,
    IN PVOID HwDeviceExtension
    );

PVOID
MPEGAPI
MpegPortGetDeviceBase(
    IN PVOID HwDeviceExtension,
    IN INTERFACE_TYPE BusType,
    IN ULONG SystemIoBusNumber,
    IN MPEG_PHYSICAL_ADDRESS IoAddress,
    IN ULONG NumberOfBytes,
    IN BOOLEAN InIoSpace
    );

VOID
MPEGAPI
MpegPortFreeDeviceBase(
    IN PVOID HwDeviceExtension,
    IN PVOID MappedAddress
    );

PVOID
MPEGAPI
MpegPortGetDmaBuffer(
    IN PVOID HwDeviceExtension,
        IN CONTROL_DEVICE DeviceType,
    IN PPORT_CONFIGURATION_INFORMATION ConfigInfo,
    IN ULONG NumberOfBytes
    );

ULONG
MPEGAPI
MpegPortGetBusData(
    IN PVOID HwDeviceExtension,
    IN ULONG BusDataType,
    IN ULONG SystemIoBusNumber,
    IN ULONG SlotNumber,
    IN PVOID Buffer,
    IN ULONG Length
    );

MPEG_PHYSICAL_ADDRESS
MPEGAPI
MpegPortGetPhysicalAddress(
    IN PVOID HwDeviceExtension,
    IN PMPEG_REQUEST_BLOCK Mrb,
    IN PVOID VirtualAddress,
    OUT PULONG pLength
    );

PVOID
MPEGAPI
MpegPortGetVirtualAddress(
    IN PVOID HwDeviceExtension,
    IN MPEG_PHYSICAL_ADDRESS PhysicalAddress
    );

VOID
MPEGAPI
MpegPortStallExecution(
    IN ULONG Delay
    );

UCHAR
MPEGAPI
MpegPortReadPortUchar(
    IN PUCHAR Port
    );


USHORT
MPEGAPI
MpegPortReadPortUshort(
    IN PUSHORT Port
    );

ULONG
MPEGAPI
MpegPortReadPortUlong(
    IN PULONG Port
    );

UCHAR
MPEGAPI
MpegPortReadRegisterUchar(
    IN PUCHAR Register
    );

USHORT
MPEGAPI
MpegPortReadRegisterUshort(
    IN PUSHORT Register
    );

ULONG
MPEGAPI
MpegPortReadRegisterUlong(
    IN PULONG Register
    );

VOID
MPEGAPI
MpegPortReadPortBufferUchar(
    IN PUCHAR Port,
    IN PUCHAR Buffer,
    IN ULONG  Count
    );

VOID
MPEGAPI
MpegPortReadPortBufferUshort(
    IN PUSHORT Port,
    IN PUSHORT Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortReadPortBufferUlong(
    IN PULONG Port,
    IN PULONG Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortReadRegisterBufferUchar(
    IN PUCHAR Register,
    IN PUCHAR Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortReadRegisterBufferUshort(
    IN PUSHORT Register,
    IN PUSHORT Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortReadRegisterBufferUlong(
    IN PULONG Register,
    IN PULONG Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortWritePortUchar(
    IN PUCHAR Port,
    IN UCHAR  Value
    );

VOID
MPEGAPI
MpegPortWritePortUshort(
    IN PUSHORT Port,
    IN USHORT  Value
    );

VOID
MPEGAPI
MpegPortWritePortUlong(
    IN PULONG Port,
    IN ULONG  Value
    );

VOID
MPEGAPI
MpegPortWriteRegisterUchar(
    IN PUCHAR Register,
    IN UCHAR  Value
    );

VOID
MPEGAPI
MpegPortWriteRegisterUshort(
    IN PUSHORT Register,
    IN USHORT  Value
    );

VOID
MPEGAPI
MpegPortWriteRegisterUlong(
    IN PULONG Register,
    IN ULONG  Value
    );

VOID
MPEGAPI
MpegPortWritePortBufferUchar(
    IN PUCHAR Port,
    IN PUCHAR Buffer,
    IN ULONG  Count
    );

VOID
MPEGAPI
MpegPortWritePortBufferUshort(
    IN PUSHORT Port,
    IN PUSHORT Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortWritePortBufferUlong(
    IN PULONG Port,
    IN PULONG Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortWriteRegisterBufferUchar(
    IN PUCHAR Register,
    IN PUCHAR Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortWriteRegisterBufferUshort(
    IN PUSHORT Register,
    IN PUSHORT Buffer,
    IN ULONG Count
    );

VOID
MPEGAPI
MpegPortWriteRegisterBufferUlong(
    IN PULONG Register,
    IN PULONG Buffer,
    IN ULONG Count
    );

ULONGLONG
MPEGAPI
MpegPortQueryCounter(
    VOID
    );

VOID
MPEGAPI
MpegDebugPrint(
    IN DEBUG_LEVEL DebugPrintLevel,
    IN PCHAR DebugMessage,
    ...
    );

VOID
MPEGAPI
MpegDebugBreakPoint(
    VOID
    );

VOID
MPEGAPI
MpegDebugAssert(
    IN PCHAR File,
    IN ULONG Line,
    IN PCHAR AssertText,
    IN ULONG AssertValue
    );

#endif
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\mpegapi.c ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    mpegapi.c

Abstract:

    This module implements the MPEG driver API.

Author:

    Yi SUN (t-yisun) Aug-22-1994

Environment:

Revision History:

--*/

#include <windows.h>
#include <winioctl.h>
#include <malloc.h>
#define IN_MPEGAPI_DLL

#include "mpegapi.h"

#include "imp.h"
#include "ddmpeg.h"
#include "trace.h"


// not part of API
// just for testing purpose

HANDLE MPEGAPI
MpegHandle(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    )
{
    USHORT index;

    HandleIsValid(hDevice, &index);

    if (eDeviceType == MpegAudioDevice) {
      return (HANDLE)(MpegADHandle(index, MpegAudio));
    }

    if (eDeviceType == MpegVideoDevice) {
      return (HANDLE)(MpegADHandle(index, MpegVideo));
    }

    return (HANDLE)(MpegADHandle(index, MpegOverlay));
}

MPEG_STATUS MPEGAPI
MpegEnumDevices(
    IN int iAdapterIndex,
    OUT LPTSTR pstrDeviceDescription OPTIONAL,
    IN UINT uiDescriptionSize,
    OUT LPDWORD pdwDeviceId OPTIONAL,
    OUT PHMPEG_DEVICE phDevice OPTIONAL
    )
/*++

Routine Description:

    Enumerates the configured MPEG devices.

Auguments:

    iAdapterIndex          --    the index of the adapter to enumerate
    pstrDeviceDescription  --    buffer to contain a description of the device
    uiDescriptionSize      --    size of the description buffer in bytes
    pstrDeviceId           --    string which uniquely identifies an
                                 MPEG device
    phDevice               --    pseudo handle which can be used to
                                 call MpegQueryDeviceCapabilities
                                 NULL if not want the pseudo handle


Return Value:

    MpegStatusSuccess          -- the call completed successfully
    MpegStatusNoMore           -- the iAdapterIndex supplied doesn't
                                  correspond to a valid adapter
    MpegStatusInvalidParameter -- the size of description buffer is too small
                                  or the iAdapterIndex is less than 0

--*/
{
    if (iAdapterIndex < 0) {
        return MpegStatusInvalidParameter;
    }

    if (nMpegAdapters == 0)
    {
        nMpegAdapters = ReadRegistry();
    }

    if (nMpegAdapters <= 0 || iAdapterIndex  >= nMpegAdapters)
    {
        return MpegStatusNoMore;
    }

    if (pdwDeviceId != NULL) {
        *pdwDeviceId = iAdapterIndex;
    }

    if (pstrDeviceDescription != NULL) {
        lstrcpyn(
            pstrDeviceDescription, MpegDeviceDescription((USHORT)iAdapterIndex),
            uiDescriptionSize);
    }

    // create a pseudo handle only used to call MpegQueryDeviceCapabilities
    if (phDevice != NULL) {
        return CreateMpegPseudoHandle(((USHORT)iAdapterIndex), phDevice);
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegOpenDevice(
    IN DWORD dwDeviceId,
    OUT PHMPEG_DEVICE phDevice
    )
/*++

Routine Description:

    Opens an MPEG device.

Auguments:

    pstrDeviceId    --    Id identifying the device to be opened
    phDevice        --    set to a handle representing the MPEG device

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusBusy             --    the device is already in use
    MpegStatusInvalidParameter --    an invalid pstrDeviceId was specified
    MpegStatusHardwareFailure  --    the device couldn't be opened

--*/
{
    if (phDevice == NULL) {
        return MpegStatusInvalidParameter;
    }

    return CreateMpegHandle((USHORT)dwDeviceId, phDevice);
}


MPEG_STATUS MPEGAPI
MpegCloseDevice(
    IN HMPEG_DEVICE hDevice
    )
/*++

Routine Description:

    Closes the handle associated with an MPEG device.

Auguments:

    hDevice    --    handle representing the MPEG device

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the hDevice is invalid

--*/
{
    USHORT  index;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    //
    // Reset the device back to reasonable values
    //

    if (DeviceSupportCap(index, MpegCapBitmaskOverlay))
    {
        ULONG   ulWidth = 16;
        ULONG   ulHeight = 16;
        ULONG   ulLineLength;
        PUCHAR  pMaskBits;

        MpegQueryInfo(
            hDevice, MpegOverlayDevice, MpegInfoMinDestinationWidth, &ulWidth);

        MpegQueryInfo(
            hDevice, MpegOverlayDevice, MpegInfoMinDestinationHeight, &ulHeight);

        MpegSetOverlayDestination(hDevice, 0, -2, ulWidth, ulHeight);

        ulLineLength = (ulWidth + 7) / 8;
        if ((pMaskBits = malloc(ulLineLength * ulHeight)) != NULL)
        {
            memset(pMaskBits, 0xFF, ulLineLength * ulHeight);

            MpegSetOverlayMask(
                hDevice, ulHeight, ulWidth, 0, ulLineLength, pMaskBits);

            free(pMaskBits);
        }
    }

    MpegSetOverlayMode(hDevice, MpegModeNone);

    MpegSetAttribute(
        hDevice, MpegAttrAudioChannel, MPEG_ATTRIBUTE_AUDIO_CHANNEL_MPEG);

    MpegSetAttribute(
        hDevice, MpegAttrVideoChannel, MPEG_ATTRIBUTE_VIDEO_CHANNEL_MPEG);

    return CloseMpegHandle(index);
}

MPEG_STATUS MPEGAPI
MpegQueryDeviceCapabilities(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_CAPABILITY eCapability
    )
/*++

Routine Description:

    Queries the device to determine if it supports the specified capability.

Auguments:

    hDevice        --    handle representing the MPEG device
    eCapability    --    one of the system defined capabilities

Return Value:

    MpegStatusSuccess          --    the device supports the specified cap
    MpegStatusUnsupported      --    the capability is not supported
    MpegStatusInvalidParameter --    the hDevice is invalid

--*/
{
    USHORT index;

    if ((!HandleIsValid(hDevice, &index)) &&
        (!PseudoHandleIsValid(hDevice, &index))) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportCap(index, eCapability)) {
        return MpegStatusUnsupported;
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegWriteData(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_STREAM_TYPE eStreamType,
    IN PMPEG_PACKET_LIST pPacketList,
    IN UINT uiPacketCount,
    IN PMPEG_ASYNC_CONTEXT pAsyncContext OPTIONAL
    )
/*++

Routine Description:

    Writes an MPEG packet of the indicated stream type.

Auguments:

    hDevice        --    handle representing the MPEG device
    eStreamType    --    the type of steam contained in pStreamBuffer
    pStreamBuffer  --    pointer to buffer contained data
    cntStreamBuffer--    count of stream data bytes
    pAsyncContext  --    optional context structure which contains an event
                         handle and a reserved section.  The event handle is
                         signalled once the request has been processed

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusPending          --    the data is queued. only returned when
                                     pAsyncContext is not NULL
    MpegStatusCancelled        --    the request was cancelled
    MpegStatusInvalidParameter --    either hDevice or eStreamType is invalid
    MpegStatusHardwareFailure  --    the hardware has failed
--*/
{
    LPOVERLAPPED pOverlapped;
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;
    DWORD code;

//	ASSERT(sizeof(pAsyncContext->reserved) >= sizeof(OVERLAPPED));

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportStream(index, eStreamType)) {
        return MpegStatusInvalidParameter;
    }

    if (eStreamType == MpegSystemStream) {
         return MpegStatusUnsupported;
    }

    if (eStreamType == MpegAudioStream) {
        hAD = MpegADHandle(index, MpegAudio);
        if (pPacketList == NULL || uiPacketCount == 0) {
            code = (DWORD)IOCTL_MPEG_AUDIO_END_OF_STREAM;
        } else {
            code = (DWORD)IOCTL_MPEG_AUDIO_WRITE_PACKETS;
        }

    } else {  // Video
        hAD = MpegADHandle(index, MpegVideo);
        if (pPacketList == NULL || uiPacketCount == 0) {
            code = (DWORD)IOCTL_MPEG_VIDEO_END_OF_STREAM;
        } else {
            code = (DWORD)IOCTL_MPEG_VIDEO_WRITE_PACKETS;
        }
    }

    if (pAsyncContext == NULL) {

        // send synchronous ioctl call

        if (!DeviceIoControlSync(
                hAD, code, pPacketList,
                uiPacketCount * sizeof(*pPacketList), NULL, 0, &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        } else {
            return MpegStatusSuccess;
        }
    }

    // send data asynchronously
    pOverlapped = (LPOVERLAPPED)&pAsyncContext->reserved;

    // initialize the ovelapped structure
    pOverlapped->Internal = pOverlapped->InternalHigh = 0;
    pOverlapped->Offset = pOverlapped->OffsetHigh = 0;
    pOverlapped->hEvent = pAsyncContext->hEvent;

    // send asynchronous END_OF_STREAM ioctl call

    TracePacketsStart ((DWORD)hAD, code, pOverlapped, pPacketList, uiPacketCount);
    if (!DeviceIoControl(
            hAD, code, pPacketList, uiPacketCount * sizeof(*pPacketList),
            NULL, 0, &cbReturn, pOverlapped)) {
        if (GetLastError() == ERROR_IO_PENDING) {
            return MpegStatusPending;
        } else {
            TraceIoctlEnd (pOverlapped, GetLastError ());
        }
        return MpegTranslateWin32Error(GetLastError());
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegQueryAsyncResult(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_STREAM_TYPE eStreamType,
    IN PMPEG_ASYNC_CONTEXT pAsyncContext,
    IN BOOL bWait
    )
/*++

Routine Description:

   Retrieves the status of a completed asynchronous request

Auguments:

    hDevice        --    handle representing the MPEG device
    pAsyncContext  --    pointer to a context structure

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusCancelled        --    the request was cancelled
    MpegStatusInvalidParameter --    either hDevice or pAsyncContext
                                     is invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    LPOVERLAPPED pOverlapped;
    HANDLE hAD;
    DWORD cbReturn;
    DWORD dwError;
    USHORT index;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportStream(index, eStreamType)) {
        return MpegStatusInvalidParameter;
    }

    switch (eStreamType) {
    case MpegAudioStream:
        hAD = MpegADHandle(index, MpegAudio);
        break;

    case MpegVideoStream:
        hAD = MpegADHandle(index, MpegVideo);
        break;

    case MpegSystemStream:
    default:
        return MpegStatusUnsupported;

    }

    pOverlapped = (LPOVERLAPPED)&pAsyncContext->reserved;

    if (!GetOverlappedResult(hAD, pOverlapped, &cbReturn, bWait))
    {
        dwError = GetLastError();

        if (!bWait && dwError == ERROR_IO_INCOMPLETE)
        {
            return MpegStatusPending;
        }

        TraceIoctlEnd (pOverlapped, dwError);
        return MpegTranslateWin32Error(dwError);
    }

    TraceIoctlEnd (pOverlapped, ERROR_SUCCESS);
    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegResetDevice(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType       // not in the proposed API
    )
/*++

Routine Description:

    Resets the MPEG device.

Auguments:

    hDevice        --    handle representing the MPEG device

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the hDevice is invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;


    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

/*
    if (DeviceSupportCap(index, MpegCapAudioStream)) {
        hAD = MpegADHandle(index, MpegAudio);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_AUDIO_RESET,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegStatusHardwareFailure;
        }
    }

    if (DeviceSupportCap(index, MpegCapVideoStream)) {
        hAD = MpegADHandle(index, MpegVideo);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_VIDEO_RESET,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegStatusHardwareFailure;
        }
    }
*/
    if (!DeviceSupportDevice(index, eDeviceType)) {
        return MpegStatusInvalidParameter;
    }

    if (eDeviceType == MpegAudioDevice || eDeviceType == MpegCombinedDevice) {
        hAD = MpegADHandle(index, MpegAudio);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_AUDIO_RESET,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }
    }

    if (eDeviceType == MpegVideoDevice || eDeviceType == MpegCombinedDevice) {
        hAD = MpegADHandle(index, MpegVideo);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_VIDEO_RESET,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegSetAutoSync(
    IN HMPEG_DEVICE hDevice,
    IN BOOL bEnable
    )
/*++

Routine Description:

    Causes the driver to read out the audio STC, and set it as the video STC.

Auguments:

    hDevice        --    handle representing the MPEG device

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed
    MpegStatusUnsupported      --    either the audio or the video is
                                     not supported

--*/
{
    return MpegStatusUnsupported;
}

MPEG_STATUS MPEGAPI
MpegSyncVideoToAudio(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_SYSTEM_TIME systemTimeDelta
    )
/*++

Routine Description:

    Causes the driver to read out the audio STC, and set it as the video STC.

Auguments:

    hDevice        --    handle representing the MPEG device

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed
    MpegStatusUnsupported      --    either the audio or the video is
                                     not supported

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportCap(index, MpegCapVideoDevice)) {
        return MpegStatusUnsupported;
    }

    if (!DeviceSupportCap(index, MpegCapAudioDevice)) {
        return MpegStatusUnsupported;
    }

    hAD = MpegADHandle(index, MpegVideo);

    if (!DeviceIoControlSync(
            hAD, (DWORD)IOCTL_MPEG_VIDEO_SYNC,
            &systemTimeDelta, sizeof(systemTimeDelta), NULL, 0, &cbReturn))
    {
        return MpegTranslateWin32Error(GetLastError());
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegQuerySTC(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    OUT PMPEG_SYSTEM_TIME pSystemTime
    )
/*++

Routine Description:

    Retrieves the STC associated with the indicated MPEG stream type.

Auguments:

    hDevice        --    handle representing the MPEG device
    eStreamType    --    indicates which STC is to be retrieved
    pSystemTime    --    pointer to a PMPEG_SYSTEM_TIME to keep the
                         returned STC

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the hDevice is invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    MPEG_SYSTEM_TIME systemTime;
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;
    DWORD code;

    if (pSystemTime == NULL) {
        return MpegStatusInvalidParameter;
    }

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if ((eDeviceType==MpegCombinedDevice)||
        (!DeviceSupportDevice(index, eDeviceType))) {
        return MpegStatusInvalidParameter;
    }

    if (eDeviceType==MpegAudioDevice) {
        hAD = MpegADHandle(index, MpegAudio);
        code = (DWORD)IOCTL_MPEG_AUDIO_GET_STC;
    } else {            // Video
        hAD = MpegADHandle(index, MpegVideo);
        code = (DWORD)IOCTL_MPEG_VIDEO_GET_STC;
    }

    if (!DeviceIoControlSync(hAD, code, NULL, 0, &systemTime,
                             sizeof(systemTime),  &cbReturn)) {
        return MpegTranslateWin32Error(GetLastError());
    }

    *pSystemTime = systemTime;

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegSetSTC(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN MPEG_SYSTEM_TIME systemTime
    )
/*++

Routine Description:

    Sets the STC associated with the indicated MPEG stream type.

Auguments:

    hDevice        --    handle representing the MPEG device
    eDeviceType    --    indicates which STC is to be retrieved
    systemTime     --    a PMPEG_SYSTEM_TIME to set the STC

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;
    DWORD code;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if ((eDeviceType==MpegCombinedDevice)||
        (!DeviceSupportDevice(index, eDeviceType))) {
        return MpegStatusInvalidParameter;
    }

    if (eDeviceType==MpegAudioDevice) {
        hAD = MpegADHandle(index, MpegAudio);
        code = (DWORD)IOCTL_MPEG_AUDIO_SET_STC;
    } else {            // Video
        hAD = MpegADHandle(index, MpegVideo);
        code = (DWORD)IOCTL_MPEG_VIDEO_SET_STC;
    }

    if (!DeviceIoControlSync(hAD, code,  &systemTime, sizeof(systemTime),
                             NULL, 0, &cbReturn)) {
        return MpegTranslateWin32Error(GetLastError());
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegPlay(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    )
/*++

Routine Description:

    Starts playing on the stream(s) associated with the indicated type.

Auguments:

    hDevice        --    handle representing the MPEG device
    eDeviceType    --    indicates which stream(s) to set to play

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportDevice(index, eDeviceType)) {
        return MpegStatusInvalidParameter;
    }

    if ((eDeviceType==MpegAudioDevice) || (eDeviceType==MpegCombinedDevice)){
        hAD = MpegADHandle(index, MpegAudio);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_AUDIO_PLAY,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }
    }

    if ((eDeviceType==MpegVideoDevice) || (eDeviceType==MpegCombinedDevice)){
        hAD = MpegADHandle(index, MpegVideo);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_VIDEO_PLAY,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegPlayTo(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN MPEG_SYSTEM_TIME systemTime,
    IN PMPEG_ASYNC_CONTEXT pAsyncContext OPTIONAL
    )
/*++

Routine Description:

    Starts playing on the stream(s) associated with the indicated type.

Auguments:

    hDevice        --    handle representing the MPEG device
    eDeviceType    --    indicates which stream(s) to set to play

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    return MpegStatusUnsupported;
}

MPEG_STATUS MPEGAPI
MpegPause(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    )
/*++

Routine Description:

    Paused playing of data on the stream(s) assocated with the indicated type.

Auguments:

    hDevice        --    handle representing the MPEG device
    eDeviceType    --    indicates which stream(s) to set to the paused state

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportDevice(index, eDeviceType)) {
        return MpegStatusInvalidParameter;
    }

    if ((eDeviceType==MpegAudioDevice) || (eDeviceType==MpegCombinedDevice)){
        hAD = MpegADHandle(index, MpegAudio);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_AUDIO_PAUSE,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegStatusHardwareFailure;
        }
    }

    if ((eDeviceType==MpegVideoDevice) || (eDeviceType==MpegCombinedDevice)){
        hAD = MpegADHandle(index, MpegVideo);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_VIDEO_PAUSE,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegStop(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType
    )
/*++

Routine Description:

    Stops the playing of data on the stream(s) associated with indicated type.

Auguments:

    hDevice        --    handle representing the MPEG device
    eDeviceType    --    indicates which stream(s) to set to stop

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportDevice(index, eDeviceType)) {
        return MpegStatusInvalidParameter;
    }

    if ((eDeviceType==MpegAudioDevice) || (eDeviceType==MpegCombinedDevice)){
        hAD = MpegADHandle(index, MpegAudio);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_AUDIO_STOP,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }
    }

    if ((eDeviceType==MpegVideoDevice) || (eDeviceType==MpegCombinedDevice)){
        hAD = MpegADHandle(index, MpegVideo);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_VIDEO_STOP,
                                 NULL, 0, NULL, 0, &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegQueryDeviceState(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    OUT PMPEG_DEVICE_STATE pCurrentDeviceState
    )
/*++

Routine Description:

    Retrieves current state of the stream assocated with the specified type.

Auguments:

    hDevice        --    handle representing the MPEG device
    eDeviceType    --    indicates which stream's device state is to
                         be retrieved
    pCurrentDeviceState -- pointer to an MPEG_DEVICE_STATE which is set
                           to the current state of the device

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed
    MpegStatusUnsupported      --    the streamtype or the device state
                                     is not supported

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;
    MPEG_IOCTL_AUDIO_DEVICE_INFO ainfo;
    MPEG_IOCTL_VIDEO_DEVICE_INFO vinfo;

    if (pCurrentDeviceState == NULL) {
        return MpegStatusInvalidParameter;
    }

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportDevice(index, eDeviceType)) {
        return MpegStatusInvalidParameter;
    }

    if (eDeviceType == MpegAudioDevice) {
        hAD = MpegADHandle(index, MpegAudio);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_AUDIO_QUERY_DEVICE,
                                 NULL, 0, &ainfo,sizeof(MPEG_IOCTL_AUDIO_DEVICE_INFO),
                                 &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }

        *pCurrentDeviceState = ainfo.DeviceState;
    }

    if (eDeviceType == MpegVideoDevice) {
        hAD = MpegADHandle(index, MpegVideo);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_VIDEO_QUERY_DEVICE,
                                 NULL, 0, &vinfo,sizeof(MPEG_IOCTL_VIDEO_DEVICE_INFO),
                                 &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }

        *pCurrentDeviceState = vinfo.DeviceState;
    }

    if (eDeviceType == MpegCombinedDevice) {
        return MpegStatusUnsupported;
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegQueryInfo(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_DEVICE_TYPE eDeviceType,
    IN MPEG_INFO_ITEM eInfoItem,
    OUT PULONG pulValue
    )
/*++

Routine Description:

    Retrieves the current value of the specified counter.

Auguments:

    hDevice        --    handle representing the MPEG device
    eDeviceType    --    indicates which stream's counter is to be retrieved
    eInfoItem       --    indicates which counter to retrieve
    pulValue       --    points to a place to keep th retrieved value

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusUnsupported      --    the counter is not supported
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;

    if (!HandleIsValid(hDevice, &index) || pulValue == NULL) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportDevice(index, eDeviceType)) {
        return MpegStatusInvalidParameter;
    }

    if (eDeviceType == MpegAudioDevice)
    {
        MPEG_IOCTL_AUDIO_DEVICE_INFO ainfo;

        hAD = MpegADHandle(index, MpegAudio);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_AUDIO_QUERY_DEVICE,
                                 NULL, 0, &ainfo,sizeof(MPEG_IOCTL_AUDIO_DEVICE_INFO),
                                 &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }

        switch (eInfoItem) {
            case MpegInfoDecoderBufferSize:
                *pulValue = ainfo.DecoderBufferSize;
                break;
            case MpegInfoDecoderBufferBytesInUse:
                *pulValue = ainfo.DecoderBufferFullness;
                break;
            case MpegInfoStarvationCounter:
                *pulValue = ainfo.StarvationCounter;
                break;
#if 0       // currently not supported
            case MpegInfoCurrentPacketBytesOutstanding:
                *pulValue = ainfo.BytesOutstanding;
                break;
            case MpegInfoStarvationCounter:
                *pulValue = ainfo.StarvationCounter;
                break;
            case MpegInfoCurrentPendingRequest:
                *pulValue = ainfo.CurrentPendingRequest;
                break;
            case MpegInfoMaximumPendingRequests:
                *pulValue = ainfo.MaximumPendingRequest;
                break;
#endif
            default:
                return MpegStatusUnsupported;
        }
    }
    else if (eDeviceType == MpegVideoDevice)
    {
        MPEG_IOCTL_VIDEO_DEVICE_INFO vinfo;

        hAD = MpegADHandle(index, MpegVideo);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_VIDEO_QUERY_DEVICE,
                                 NULL, 0, &vinfo,sizeof(MPEG_IOCTL_VIDEO_DEVICE_INFO),
                                 &cbReturn)) {
            return MpegTranslateWin32Error(GetLastError());
        }

        switch(eInfoItem) {
            case MpegInfoDecoderBufferSize:
                *pulValue = vinfo.DecoderBufferSize;
                break;
            case MpegInfoDecoderBufferBytesInUse:
                *pulValue = vinfo.DecoderBufferFullness;
                break;
            case MpegInfoDecompressHeight:
                *pulValue = vinfo.DecompressHeight;
                break;
            case MpegInfoDecompressWidth:
                *pulValue = vinfo.DecompressWidth;
                break;
            case MpegInfoStarvationCounter:
                *pulValue = vinfo.StarvationCounter;
                break;
#if 0       // currently not supported
            case MpegInfoCurrentPacketBytesOutstanding:
                *pulValue = vinfo.BytesOutstanding;
                break;
            case MpegInfoCurrentPendingRequest:
                *pulValue = vinfo.CurrentPendingRequest;
                break;
            case MpegInfoMaximumPendingRequests:
                *pulValue = vinfo.MaximumPendingRequest;
                break;
#endif
            default:
                return MpegStatusUnsupported;
        }
    }
    else if (eDeviceType == MpegOverlayDevice)
    {
        MPEG_IOCTL_OVERLAY_DEVICE_INFO oinfo;

        hAD = MpegADHandle(index, MpegOverlay);

        if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_OVERLAY_QUERY_DEVICE,
                                 NULL, 0, &oinfo,sizeof(MPEG_IOCTL_OVERLAY_DEVICE_INFO),
                                 &cbReturn))
        {
            return MpegTranslateWin32Error(GetLastError());
        }

        switch (eInfoItem)
        {
            case MpegInfoMinDestinationHeight:
                *pulValue = oinfo.MinDestinationHeight;
                break;
            case MpegInfoMaxDestinationHeight:
                *pulValue = oinfo.MaxDestinationHeight;
                break;
            case MpegInfoMinDestinationWidth:
                *pulValue = oinfo.MinDestinationWidth;
                break;
            case MpegInfoMaxDestinationWidth:
                *pulValue = oinfo.MaxDestinationWidth;
                break;
            default:
                return MpegStatusUnsupported;
        }
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegClearVideoBuffer(
    IN HMPEG_DEVICE hDevice
    )
/*++

Routine Description:

    Clears the video decompression buffer to black.

Auguments:

    hDevice        --    handle representing the MPEG device

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusHardwareFailure  --    the hardware has failed
    MpegStatusUnsupported      --    the function is not supported

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportCap(index, MpegCapVideoDevice)) {
        return MpegStatusUnsupported;
    }

    hAD = MpegADHandle(index, MpegVideo);

    if (!DeviceIoControlSync(hAD, (DWORD)IOCTL_MPEG_VIDEO_CLEAR_BUFFER,
                                   NULL, 0, NULL, 0, &cbReturn)) {
        return MpegTranslateWin32Error(GetLastError());
    }

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegSetOverlayMode(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_OVERLAY_MODE eNewMode
    )
/*++

Routine Description:

    Sets the mode in which the MPEG device will overlay the graphics screen
    video.

Auguments:

    hDevice        --    handle representing the MPEG device
    eNewMode       --    determines which mode to set

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusUnsupported      --    the capability is not supported
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;
    DWORD Cookie;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportCap(index, MpegCapBitmaskOverlay) &&
        !DeviceSupportCap(index, MpegCapChromaKeyOverlay))
    {
        return MpegStatusUnsupported;
    }

    hAD = MpegADHandle(index, MpegOverlay);

    TraceSynchronousIoctlStart (&Cookie, (DWORD)hAD, IOCTL_MPEG_OVERLAY_MODE, &eNewMode, NULL);
    if (!DeviceIoControl(hAD, (DWORD)IOCTL_MPEG_OVERLAY_MODE,
                             &eNewMode, sizeof(MPEG_OVERLAY_MODE),
                             NULL, 0, &cbReturn, NULL)) {
        TraceSynchronousIoctlEnd (Cookie, GetLastError ());
        return MpegTranslateWin32Error(GetLastError());
    }

    TraceSynchronousIoctlEnd (Cookie, ERROR_SUCCESS);
    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegSetOverlayMask(
    IN HMPEG_DEVICE hDevice,
    IN ULONG ulHeight,
    IN ULONG ulWidth,
    IN ULONG ulOffset,
    IN ULONG ulLineLength,
    IN PUCHAR pMaskBits
    )
{
    MPEG_OVERLAY_BIT_MASK bitMask;
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;
    DWORD Cookie;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportCap(index, MpegCapBitmaskOverlay))
    {
        return MpegStatusUnsupported;
    }

    hAD = MpegADHandle(index, MpegOverlay);

    bitMask.PixelHeight = ulHeight;
    bitMask.PixelWidth = ulWidth;
    bitMask.BufferPitch = ulLineLength;
    bitMask.LeftEdgeBitOffset = ulOffset;
    bitMask.PixelHeight = ulHeight;
    bitMask.pBitMask = pMaskBits;

    TraceSynchronousIoctlStart (&Cookie, (DWORD)hAD, IOCTL_MPEG_OVERLAY_SET_BIT_MASK, &bitMask, NULL);
    if (!DeviceIoControl(
            hAD, (DWORD)IOCTL_MPEG_OVERLAY_SET_BIT_MASK,
            &bitMask, sizeof(bitMask), NULL, 0, &cbReturn, NULL))
    {
        TraceSynchronousIoctlEnd (Cookie, GetLastError ());
        return MpegTranslateWin32Error(GetLastError());
    }

    TraceSynchronousIoctlEnd (Cookie, ERROR_SUCCESS);
    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegQueryOverlayKey(
    IN HMPEG_DEVICE hDevice,
    OUT COLORREF *prgbColor,
    OUT COLORREF *prgbMask
    )
{
    return MpegStatusUnsupported;
}

MPEG_STATUS MPEGAPI
MpegSetOverlayKey(
    IN HMPEG_DEVICE hDevice,
    IN COLORREF rgbColor,
    IN COLORREF rgbMask
    )
/*++

Routine Description:

    Sets the color that will be used by the map the MPEG video onto.

Auguments:

    hDevice        --    handle representing the MPEG device
    rgbColor       --    the RGB value for the color desired
    rgbMask        --    determines which bits of the color will
                         be significant

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusUnsupported      --    the capability is not supported
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    MPEG_IOCTL_OVERLAY_KEY key;
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;
    DWORD Cookie;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportCap(index, MpegCapChromaKeyOverlay))
    {
        return MpegStatusUnsupported;
    }

    key.Color = (ULONG)rgbColor;
    key.Mask = (ULONG)rgbMask;
    hAD = MpegADHandle(index, MpegOverlay);

    TraceSynchronousIoctlStart (&Cookie, (DWORD)hAD, IOCTL_MPEG_OVERLAY_SET_VGAKEY, &key, NULL);
    if (!DeviceIoControl(hAD, (DWORD)IOCTL_MPEG_OVERLAY_SET_VGAKEY,
                             &key, sizeof(MPEG_IOCTL_OVERLAY_KEY),
                             NULL, 0, &cbReturn, NULL)) {
        TraceSynchronousIoctlEnd (Cookie, GetLastError ());
        return MpegTranslateWin32Error(GetLastError());
    }

    TraceSynchronousIoctlEnd (Cookie, ERROR_SUCCESS);
    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegSetOverlaySource(
    IN HMPEG_DEVICE hDevice,
    IN LONG lX,
    IN LONG lY,
    IN LONG lWidth,
    IN LONG lHeight
    )
/*++

Routine Description:

    Moves the overlay to a new position on the graphics screen
    without altering its size.

Auguments:

    hDevice        --    handle representing the MPEG device
    lX             --    desired X position of the video overlay
    lY             --    desired Y position of the video overlay

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusUnsupported      --    the capability is not supported
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    return MpegStatusUnsupported;
}

MPEG_STATUS MPEGAPI
MpegSetOverlayDestination(
    IN HMPEG_DEVICE hDevice,
    IN LONG lX,
    IN LONG lY,
    IN LONG lWidth,
    IN LONG lHeight
    )
/*++

Routine Description:

    Sets the size of the overlay window in the current graphics memory buffer.


Auguments:

    hDevice        --    handle representing the MPEG device
    lHeight        --    desired height of the video window
    lWidth         --    desired width of the video window

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusUnsupported      --    the capability is not supported
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    MPEG_OVERLAY_PLACEMENT placement;
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD cbReturn;
    DWORD Cookie;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportCap(index, MpegCapBitmaskOverlay) &&
		!DeviceSupportCap(index, MpegCapChromaKeyOverlay))
    {
        return MpegStatusUnsupported;
    }

    placement.X = (ULONG)lX;
    placement.Y = (ULONG)lY;
    placement.cX = (ULONG)lWidth;
    placement.cY = (ULONG)lHeight;
    hAD = MpegADHandle(index, MpegOverlay);

    TraceSynchronousIoctlStart (&Cookie, (DWORD)hAD, IOCTL_MPEG_OVERLAY_SET_DESTINATION, &placement, NULL);
    if (!DeviceIoControl(hAD, (DWORD)IOCTL_MPEG_OVERLAY_SET_DESTINATION,
                             &placement, sizeof(placement),
                             NULL, 0, &cbReturn, NULL)) {
        TraceSynchronousIoctlEnd (Cookie, GetLastError ());
        return MpegTranslateWin32Error(GetLastError());
    }

    TraceSynchronousIoctlEnd (Cookie, ERROR_SUCCESS);
    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegQueryAttributeRange(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_ATTRIBUTE eAttribute,
    OUT PLONG plMinimum,
    OUT PLONG plMaximum,
    OUT PLONG plStep
    )
/*++

Routine Description:

    Retrieves the supported values of the specified attribute.

Auguments:

    hDevice        --    handle representing the MPEG device
    eAttribute     --    attribute
    plMinimum     --    set to the minimum acceptable value
    plMaximum     --    set to the maximum acceptable value
    plStep        --    set to the size of each increment between
                         the min and max

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusUnsupported      --    the capability is not supported
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;

    if (plMinimum == NULL || plMaximum == NULL || plStep == NULL) {
        return MpegStatusInvalidParameter;
    }

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (!DeviceSupportCap(index, MpegCapAudioDevice)) {
        return MpegStatusUnsupported;
    }

    return GetAttributeRange(index, eAttribute, plMinimum, plMaximum, plStep);
}


MPEG_STATUS MPEGAPI
MpegQueryAttribute(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_ATTRIBUTE eAttribute,
    OUT PLONG plValue
    )
/*++

Routine Description:

    Retrieves the current value of the specified attribute.

Auguments:

    hDevice        --    handle representing the MPEG device
    eAttribute     --    attribute
    plValue       --    set to the current value of the attribute

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusUnsupported      --    the capability is not supported
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD dwIoctlCode;
    DWORD cbReturn;
    MPEG_ATTRIBUTE_PARAMS attribute;

    if (plValue == NULL || !HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (eAttribute < 0)
    {
        return MpegStatusUnsupported;
    }
    else if (eAttribute < MpegAttrMaximumAudioAttribute)
    {
        if (!DeviceSupportCap(index, MpegCapAudioDevice)) {
            return MpegStatusUnsupported;
        }

        hAD = MpegADHandle(index, MpegAudio);
        dwIoctlCode = IOCTL_MPEG_AUDIO_GET_ATTRIBUTE;
    }
    else if (eAttribute < MpegAttrMaximumVideoAttribute)
    {
        if (!DeviceSupportCap(index, MpegCapVideoDevice)) {
            return MpegStatusUnsupported;
        }

        hAD = MpegADHandle(index, MpegVideo);
        dwIoctlCode = IOCTL_MPEG_VIDEO_GET_ATTRIBUTE;
    }
    else if (eAttribute < MpegAttrMaximumOverlayAttribute)
    {
        if (!DeviceSupportCap(index, MpegCapBitmaskOverlay) &&
            !DeviceSupportCap(index, MpegCapChromaKeyOverlay))
        {
            return MpegStatusUnsupported;
        }

        hAD = MpegADHandle(index, MpegOverlay);
        dwIoctlCode = IOCTL_MPEG_OVERLAY_GET_ATTRIBUTE;
    }
    else
    {
        return MpegStatusUnsupported;
    }

    attribute.Attribute = eAttribute;

    if (!DeviceIoControlSync(hAD, dwIoctlCode,
                             &attribute, sizeof(attribute),
                             &attribute, sizeof(attribute),
                             &cbReturn)) {
        return MpegTranslateWin32Error(GetLastError());
    }

    *plValue = attribute.Value;

    return MpegStatusSuccess;
}

MPEG_STATUS MPEGAPI
MpegSetAttribute(
    IN HMPEG_DEVICE hDevice,
    IN MPEG_ATTRIBUTE eAttribute,
    IN LONG lValue
    )
/*++

Routine Description:

    Sets the value of the specified attribute.

Auguments:

    hDevice         --  handle representing the MPEG device
    eAttribute      --  attribute
    lValue          --  the specified attribute is set to this value

Return Value:

    MpegStatusSuccess          --    the call completed successfully
    MpegStatusInvalidParameter --    the parameter(s) is(are) invalid
    MpegStatusUnsupported      --    the capability is not supported
    MpegStatusHardwareFailure  --    the hardware has failed

--*/
{
    USHORT index;
    HMPEG_DEVICE hAD;
    DWORD dwIoctlCode;
    DWORD cbReturn;
    MPEG_ATTRIBUTE_PARAMS attribute;
    MPEG_DEVICE_TYPE eDeviceType;
	INT currentChannel;

    if (!HandleIsValid(hDevice, &index)) {
        return MpegStatusInvalidParameter;
    }

    if (eAttribute < 0)
    {
        return MpegStatusUnsupported;
    }
    else if (eAttribute < MpegAttrMaximumAudioAttribute)
    {
        if (!DeviceSupportCap(index, MpegCapAudioDevice))
        {
            return MpegStatusUnsupported;
        }

        eDeviceType = MpegAudio;
        dwIoctlCode = IOCTL_MPEG_AUDIO_SET_ATTRIBUTE;
    }
    else if (eAttribute < MpegAttrMaximumVideoAttribute)
    {
        if (!DeviceSupportCap(index, MpegCapVideoDevice))
        {
            return MpegStatusUnsupported;
        }

        eDeviceType = MpegVideo;
        dwIoctlCode = IOCTL_MPEG_VIDEO_SET_ATTRIBUTE;
    }
    else if (eAttribute < MpegAttrMaximumOverlayAttribute)
    {
        if (!DeviceSupportCap(index, MpegCapBitmaskOverlay) &&
            !DeviceSupportCap(index, MpegCapChromaKeyOverlay))
        {
            return MpegStatusUnsupported;
        }

        eDeviceType = MpegOverlay;
        dwIoctlCode = IOCTL_MPEG_OVERLAY_SET_ATTRIBUTE;
    }
    else
    {
        return MpegStatusUnsupported;
    }

    hAD = MpegADHandle(index, eDeviceType);
    attribute.Attribute = eAttribute;
    attribute.Value = lValue;

    if (eAttribute == MpegAttrAudioChannel ||
        eAttribute == MpegAttrVideoChannel)
    {
        if( (cbReturn = GetCurrentChannel(index, eDeviceType, &currentChannel) ) != MpegStatusSuccess )
			return cbReturn;
		if( currentChannel == lValue )	// We are already set to the correct channel
			return MpegStatusSuccess;
    }

    if (!DeviceIoControlSync(hAD, dwIoctlCode,
                             &attribute, sizeof(attribute),
                             NULL, 0, &cbReturn)) {
        return MpegTranslateWin32Error(GetLastError());
    }

    if (eAttribute == MpegAttrAudioChannel ||
        eAttribute == MpegAttrVideoChannel)
    {
        SetCurrentChannel(index, eDeviceType, lValue);
    }
    else
    {
        SetCurrentAttributeValue(index, eDeviceType, eAttribute, lValue);
    }

    return MpegStatusSuccess;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\trace.c ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    trace.c

Abstract:

    This module implements a trace facility for WIN32 I/O
    calls made by the Mpeg API.

Author:

    Jeff East [jeffe] 6-Dec-1994

Environment:

Revision History:

--*/

#include <windows.h>
#include <winioctl.h>
#include <stdarg.h>
#include <stdio.h>
#include <string.h>
#include <errno.h>

#define IN_MPEGAPI_DLL
#define ENABLE_IO_TRACE

#include "mpegapi.h"
#include "ddmpeg.h"
#include "trace.h"

//
//      MODULE WIDE DATA DEFINITIONS
//


//
//      Control flags
//

BOOLEAN TracePrint = FALSE;             // Print trace events to stdout


//
//      Trace Entry
//
//      Each event is represented by an entry with the following structure.
//

#define MAX_IOCTL_NAME_LENGTH 43

typedef enum _TRACE_TYPE {
    TRACE_NONE = 0,
    TRACE_SYNC_IOCTL,
    TRACE_IOCTL,
    TRACE_PACKETS,
    TRACE_SYNC_PACKETS
} TRACE_TYPE, * PTRACE_TYPE;

typedef struct _TRACE_ENTRY {
    DWORD TimeStarted;
    DWORD TimeEnded;
    DWORD Id;
    TRACE_TYPE IoType;
    DWORD IoControlCode;
    BOOLEAN InProgress;
    DWORD Result;
    union {
        LPOVERLAPPED pOverlapped;
        DWORD Cookie;
    };
    ULONGLONG FirstTimeStamp;
    ULONGLONG LastTimeStamp;
    PVOID pOutBuffer;
    PMPEG_PACKET_LIST pPacketList;
    UINT PacketCount;
} TRACE_ENTRY, * PTRACE_ENTRY;



//
//      Trace Ring
//
//      We track the I/Os with the following ring
//

#define RING_ENTRIES 1000

TRACE_ENTRY TraceEntries[RING_ENTRIES];
LONG NextEntry = 0;
CRITICAL_SECTION CriticalSection;
BOOLEAN Initialized = FALSE;


//
//      Output file handle (defaults to stdout)
//

FILE * pOutputFile;


//
//      Cookies used to track synchronous operations
//              

ULONG NextCookie = 0x80000001;


//
//      Base tick count when we first started
//

DWORD BaseTime = 0;


//
//      Forward Routine Definitions
//

VOID
Initialize (
    );

PUCHAR
IoctlToText (
    IN DWORD IoControlCode
    );

VOID
PrintEntry (
    IN PTRACE_ENTRY pEntry
    );


VOID
MPEGAPI
TraceDump (
    VOID
    )

/*++

RoutineDescription:

    This routine dumps the contents of the trace ring to stdout in
    FIFO order.

Arguments:

    None.

Return Value:

    None.

--*/

{

    LONG i;


    //  Just scan the ring, displaying all the entries that have valid data
    //  data in them.

    EnterCriticalSection (&CriticalSection);
    i = NextEntry;
    do {
        PTRACE_ENTRY pEntry = &TraceEntries[i];

        if (pEntry->IoType != TRACE_NONE) {
            PrintEntry (pEntry);
        }
        i++;
        if (i == RING_ENTRIES) {
            i = 0;
        }
    } while (i != NextEntry);
    LeaveCriticalSection (&CriticalSection);

}


VOID
MPEGAPI
TraceDumpFile (
    IN PUCHAR pFileName
    )

/*++

RoutineDescription:

    This routine dumps the contents of the trace ring to the named file in
    FIFO order.

Arguments:

    pFileName - provides the null-terminated ASCII name of the output file.

Return Value:

    None.

--*/

{

    //  Open the output file

    pOutputFile = fopen (pFileName, "wt");
    if (pOutputFile == NULL) {

        fprintf (stderr, "Unable to create file '%s', errno = %d\n", pFileName, errno);

    } else {

        //  Perform the dump
        
        TraceDump ();
        
        
        //  And close the output file

        fclose (pOutputFile);
    }


    //  Restore the default output device to be stdout

    pOutputFile = stdout;

}


VOID
TraceIoctlEnd (
    IN LPOVERLAPPED pOverlapped,
    IN DWORD Result
    )

/*++

Routine Description:

    This routine is used to record the termination of an asynchronous
    call to DeviceIoControl.

Arguments:

    pOverlapped - provides the address of the  OVERLAPPED structure being
        used to synchronize with the I/O

    Result - provides the final execution status of the operation

Return Value:

    None.

--*/

{
    PTRACE_ENTRY pEntry;
    LONG i;


    //  Find the associated trace entry

    EnterCriticalSection (&CriticalSection);
    i = NextEntry - 1;
    do {
        if (i < 0) {
            i = RING_ENTRIES - 1;
        }
        pEntry = &TraceEntries[i];
        if (pEntry->pOverlapped == pOverlapped && pEntry->InProgress) {

            //  Mark the entry as "done" and display it, if requested

            pEntry->TimeEnded = GetTickCount ();
            pEntry->Result = Result;
            pEntry->InProgress = FALSE;


            //  If this is a GET_STC, save the value

            switch (pEntry->IoControlCode) {
            case IOCTL_MPEG_AUDIO_GET_STC:
            case IOCTL_MPEG_VIDEO_GET_STC:
                if (pEntry->pOutBuffer) {
                    pEntry->FirstTimeStamp = *(PMPEG_SYSTEM_TIME)(pEntry->pOutBuffer);
                }
                break;
            }

            if (TracePrint) {
                PrintEntry (pEntry);
            }
            LeaveCriticalSection (&CriticalSection);
            return;
        }
        i--;
    } while (i != NextEntry - 1);


    //  We couldn't find it!

    LeaveCriticalSection (&CriticalSection);
    printf ("??? TRACE UNABLE TO FIND MATCHING TRACE ENTRY, pOverlapped = %x\n",
            pOverlapped);

}



VOID
TraceIoctlStart (
    IN DWORD Id,
    IN DWORD Operation,
    IN LPOVERLAPPED pOverlapped,
    IN LPVOID pInBuffer,
    IN LPVOID pOutBuffer
    )

/*++

Routine Description:

    This routine is called right before calling DeviceIoControl
    asynchronously. It records the IoControl that's about to be
    performed, and returns.

Arguments:

    Id - provides an indication of the channel being used

    Operation - provides a the IoControl operation being
        performed.

    pOverlapped - provides the address of the  OVERLAPPED structure being
        used to synchronize with the I/O

    pInBuffer - provides the address of the buffer being passed to DeviceIoControl

    pOutBuffer - provides the address of the output buffer passed to DeviceIoControl

Return Value:

    None.

--*/

{
    PTRACE_ENTRY pEntry;

    if (!Initialized) {
        Initialize ();
    }



    //  Allocate a ring entry for this I/O. 

    EnterCriticalSection (&CriticalSection);    
    pEntry = &TraceEntries[NextEntry];
    if (pEntry->InProgress) {
        printf ("??? TRACE RING OVERFLOW\n");
        LeaveCriticalSection (&CriticalSection);
        return;
    }
    pEntry->InProgress = TRUE;
    if (++NextEntry >= RING_ENTRIES) {
        NextEntry = 0;
    }
    LeaveCriticalSection (&CriticalSection);

    
    //  Initialize the trace entry

    pEntry->TimeStarted = GetTickCount ();
    pEntry->TimeEnded = 0;
    pEntry->Id = Id;
    pEntry->IoType = TRACE_IOCTL;
    pEntry->IoControlCode = Operation;
    pEntry->Result = ERROR_IO_PENDING;
    pEntry->pOverlapped = pOverlapped;
    pEntry->pOutBuffer = pOutBuffer;
    pEntry->pPacketList = NULL;
    pEntry->PacketCount = 0;


    //  Save command-specific info

    pEntry->LastTimeStamp = 0;
    switch (Operation) {
    case IOCTL_MPEG_AUDIO_SET_STC:
    case IOCTL_MPEG_VIDEO_SET_STC:
        if (pInBuffer) {
            pEntry->FirstTimeStamp = *(PMPEG_SYSTEM_TIME)pInBuffer;
        } else {
            pEntry->FirstTimeStamp = 0;
        }
        break;
    default:
        pEntry->FirstTimeStamp = 0;
    }


    //  If we're printing in real time, dump the entry

    if (TracePrint) {
        PrintEntry (pEntry);
    }
}



VOID
TracePacketsStart (
    IN DWORD Id,
    IN DWORD Operation,
    IN LPOVERLAPPED pOverlapped,
    IN PMPEG_PACKET_LIST pPacketList,
    IN UINT PacketCount
    )

/*++

Routine Description:

    This routine is called right before calling DeviceIoControl
    asynchronously to write a packet list. It records the IoControl 
    that's about to be performed, and returns.

Arguments:

    Id - provides an indication of the channel being used

    Operation - provides the I/O control code of the operation being
        performed.

    pOverlapped - provides the address of the  OVERLAPPED structure being
        used to synchronize with the I/O

    pPacketList - provides the address of the packet list

    PacketCount - provides the count of the number of packets being sent

Return Value:

    None.

--*/

{
    PTRACE_ENTRY pEntry;

    if (!Initialized) {
        Initialize ();
    }



    //  Allocate a ring entry for this I/O. 

    EnterCriticalSection (&CriticalSection);    
    pEntry = &TraceEntries[NextEntry];
    if (pEntry->InProgress) {
        printf ("??? TRACE RING OVERFLOW\n");
        LeaveCriticalSection (&CriticalSection);
        return;
    }
    pEntry->InProgress = TRUE;
    if (++NextEntry >= RING_ENTRIES) {
        NextEntry = 0;
    }
    LeaveCriticalSection (&CriticalSection);

    
    //  Initialize the trace entry

    pEntry->TimeStarted = GetTickCount ();
    pEntry->TimeEnded = 0;
    pEntry->Id = Id;
    pEntry->IoType = TRACE_PACKETS;
    pEntry->IoControlCode = Operation;
    pEntry->Result = ERROR_IO_PENDING;
    pEntry->pOverlapped = pOverlapped;
    pEntry->pOutBuffer = NULL;
    pEntry->pPacketList = pPacketList;
    pEntry->PacketCount = PacketCount;


    //  Save command-specific info

    switch (Operation) {
    case IOCTL_MPEG_AUDIO_WRITE_PACKETS:
    case IOCTL_MPEG_VIDEO_WRITE_PACKETS:
        pEntry->FirstTimeStamp = pPacketList[0].Scr;
        pEntry->LastTimeStamp = pPacketList[PacketCount-1].Scr;
        break;
    default:
        pEntry->FirstTimeStamp = 0;
        pEntry->LastTimeStamp = 0;
    }


    //  If we're printing in real time, dump the entry

    if (TracePrint) {
        PrintEntry (pEntry);
    }
}



VOID
TraceSynchronousIoctlEnd (
    IN DWORD Cookie,
    IN DWORD Result
    )

/*++

Routine Description:

    This routine is used to record the termination of a synchronous
    call to DeviceIoControl.

Arguments:

    Cookie - provides the token used to associate this trace with
        the original start operation

    Result - provides the final execution status of the operation

Return Value:

    None.

--*/

{
    PTRACE_ENTRY pEntry;
    LONG i;


    //  Find the associated trace entry

    EnterCriticalSection (&CriticalSection);
    i = NextEntry - 1;
    do {
        if (i < 0) {
            i = RING_ENTRIES - 1;
        }
        pEntry = &TraceEntries[i];
        if (pEntry->Cookie == Cookie && pEntry->InProgress) {

            //  Mark the entry as "done" and display it, if requested

            pEntry->TimeEnded = GetTickCount ();
            pEntry->Result = Result;
            pEntry->InProgress = FALSE;

            
            //  If this is a GET_STC, save the value
            
            switch (pEntry->IoControlCode) {
            case IOCTL_MPEG_AUDIO_GET_STC:
            case IOCTL_MPEG_VIDEO_GET_STC:
                if (pEntry->pOutBuffer) {
                    pEntry->FirstTimeStamp = *(PMPEG_SYSTEM_TIME)(pEntry->pOutBuffer);
                }
                break;
            }
            
            if (TracePrint) {
                PrintEntry (pEntry);
            }
            LeaveCriticalSection (&CriticalSection);
            return;
        }
        i--;
    } while (i != NextEntry - 1);


    //  We couldn't find it!

    LeaveCriticalSection (&CriticalSection);
    printf ("??? TRACE UNABLE TO FIND MATCHING TRACE ENTRY, Cookie = %x\n",
            Cookie);

}



VOID
TraceSynchronousIoctlStart (
    OUT DWORD * pCookie,
    IN DWORD Id,
    IN DWORD Operation,
    IN LPVOID pInBuffer,
    IN LPVOID pOutBuffer
    )

/*++

Routine Description:

    This routine is called right before calling DeviceIoControl
    synchronously. It records the IoControl that's about to be
    performed, and returns.

Arguments:

    pCookie - receives a token that can be used to associated the
        ending trace of this DeviceIoControl with this trace.

    Id - provides an indication of the channel being used

    Operation - provides the I/O control code of the operation being
        performed.

    pInBuffer - provides the address of the input buffer being passed
        to DeviceIoControl

    pOutBuffer - provides the address of the output buffer passed to
        DeviceIoControl

Return Value:

    None.

--*/

{
    PTRACE_ENTRY pEntry;

    if (!Initialized) {
        Initialize ();
    }



    //  Allocate a ring entry for this I/O. 

    EnterCriticalSection (&CriticalSection);    
    pEntry = &TraceEntries[NextEntry];
    if (pEntry->InProgress) {
        printf ("??? TRACE RING OVERFLOW\n");
        LeaveCriticalSection (&CriticalSection);
        return;
    }
    pEntry->InProgress = TRUE;
    if (++NextEntry >= RING_ENTRIES) {
        NextEntry = 0;
    }
    LeaveCriticalSection (&CriticalSection);

    
    //  Initialize the trace entry

    pEntry->TimeStarted = GetTickCount ();
    pEntry->TimeEnded = 0;
    pEntry->Id = Id;
    pEntry->IoType = TRACE_SYNC_IOCTL;
    pEntry->IoControlCode = Operation;
    pEntry->Result = ERROR_IO_PENDING;
    *pCookie = pEntry->Cookie = NextCookie++;
    pEntry->pOutBuffer = pOutBuffer;
    pEntry->pPacketList = NULL;
    pEntry->PacketCount = 0;


    //  Save command-specific info

    pEntry->LastTimeStamp = 0;
    switch (Operation) {
    case IOCTL_MPEG_AUDIO_SET_STC:
    case IOCTL_MPEG_VIDEO_SET_STC:
        if (pInBuffer) {
            pEntry->FirstTimeStamp = *(PMPEG_SYSTEM_TIME)pInBuffer;
        } else {
            pEntry->FirstTimeStamp = 0;
        }
        break;
    default:
        pEntry->FirstTimeStamp = 0;
    }


    //  If we're printing in real time, dump the entry

    if (TracePrint) {
        PrintEntry (pEntry);
    }
}



VOID
TraceSynchronousPacketsStart (
    OUT DWORD *pCookie,
    IN DWORD Id,
    IN DWORD Operation,
    IN PMPEG_PACKET_LIST pPacketList,
    IN UINT PacketCount
    )

/*++

Routine Description:

    This routine is called right before calling DeviceIoControl
    synchronously to write a set of packets. It records the IoControl 
    that's about to be performed, and returns.

Arguments:

    pCookie - receives a token that can be used to associated the
        ending trace of this DeviceIoControl with this trace.

    Id - provides an indication of the channel being used

    Operation - provides the I/O control code of the operation being
        performed.

    pPacketList - provides the address of the packet list

    PacketCount - provides the count of the number of packets being sent


Return Value:

    None.

--*/

{
    PTRACE_ENTRY pEntry;

    if (!Initialized) {
        Initialize ();
    }



    //  Allocate a ring entry for this I/O. 

    EnterCriticalSection (&CriticalSection);    
    pEntry = &TraceEntries[NextEntry];
    if (pEntry->InProgress) {
        printf ("??? TRACE RING OVERFLOW\n");
        LeaveCriticalSection (&CriticalSection);
        return;
    }
    pEntry->InProgress = TRUE;
    if (++NextEntry >= RING_ENTRIES) {
        NextEntry = 0;
    }
    LeaveCriticalSection (&CriticalSection);

    
    //  Initialize the trace entry

    pEntry->TimeStarted = GetTickCount ();
    pEntry->TimeEnded = 0;
    pEntry->Id = Id;
    pEntry->IoType = TRACE_SYNC_PACKETS;
    pEntry->IoControlCode = Operation;
    pEntry->Result = ERROR_IO_PENDING;
    *pCookie = pEntry->Cookie = NextCookie++;
    pEntry->pOutBuffer = NULL;
    pEntry->pPacketList = pPacketList;
    pEntry->PacketCount = PacketCount;


    //  Save command-specific info

    switch (Operation) {
    case IOCTL_MPEG_AUDIO_WRITE_PACKETS:
    case IOCTL_MPEG_VIDEO_WRITE_PACKETS:
        pEntry->FirstTimeStamp = pPacketList[0].Scr;
        pEntry->FirstTimeStamp = pPacketList[PacketCount-1].Scr;
        break;
    default:
        pEntry->FirstTimeStamp = 0;
        pEntry->LastTimeStamp = 0;
    }


    //  If we're printing in real time, dump the entry

    if (TracePrint) {
        PrintEntry (pEntry);
    }
}




VOID
Initialize (
    )

/*++

Routine Description:

    This routine initializes the mode-wide data structures.
    It only needs to be called once.

Arguments:

    None.

Return Value:

    Initialized is set to TRUE.

--*/

{

    if (!Initialized) {

        InitializeCriticalSection (&CriticalSection);
        BaseTime = GetTickCount ();
        pOutputFile = stdout;
        Initialized = TRUE;

    }

}


PUCHAR
IoctlToText (
    IN DWORD IoControlCode
    )

/*++
 
Routine Description:

    This routine translates an Mpeg IOCTL code to its text name.

Arguments:

    IoControlCode - provides the IOCTL I/O code to be translated.

Return Value:

    Returns the address of a null-terminated ASCII string, with the
    IOCTL name.

--*/

{

    switch (IoControlCode) {
    case IOCTL_MPEG_AUDIO_END_OF_STREAM: 
        return "IOCTL_MPEG_AUDIO_END_OF_STREAM";
    case IOCTL_MPEG_AUDIO_WRITE_PACKETS: 
        return "IOCTL_MPEG_AUDIO_WRITE_PACKETS";
    case IOCTL_MPEG_VIDEO_END_OF_STREAM: 
        return "IOCTL_MPEG_VIDEO_END_OF_STREAM";
    case IOCTL_MPEG_VIDEO_WRITE_PACKETS: 
        return "IOCTL_MPEG_VIDEO_WRITE_PACKETS";
    case IOCTL_MPEG_AUDIO_RESET: 
        return "IOCTL_MPEG_AUDIO_RESET";
    case IOCTL_MPEG_VIDEO_RESET: 
        return "IOCTL_MPEG_VIDEO_RESET";
    case IOCTL_MPEG_VIDEO_SYNC: 
        return "IOCTL_MPEG_VIDEO_SYNC";
    case IOCTL_MPEG_AUDIO_GET_STC: 
        return "IOCTL_MPEG_AUDIO_GET_STC";
    case IOCTL_MPEG_VIDEO_GET_STC: 
        return "IOCTL_MPEG_VIDEO_GET_STC";
    case IOCTL_MPEG_AUDIO_SET_STC: 
        return "IOCTL_MPEG_AUDIO_SET_STC";
    case IOCTL_MPEG_VIDEO_SET_STC: 
        return "IOCTL_MPEG_VIDEO_SET_STC";
    case IOCTL_MPEG_AUDIO_PLAY: 
        return "IOCTL_MPEG_AUDIO_PLAY";
    case IOCTL_MPEG_VIDEO_PLAY: 
        return "IOCTL_MPEG_VIDEO_PLAY";
    case IOCTL_MPEG_AUDIO_PAUSE: 
        return "IOCTL_MPEG_AUDIO_PAUSE";
    case IOCTL_MPEG_VIDEO_PAUSE: 
        return "IOCTL_MPEG_VIDEO_PAUSE";
    case IOCTL_MPEG_AUDIO_STOP: 
        return "IOCTL_MPEG_AUDIO_STOP";
    case IOCTL_MPEG_VIDEO_STOP: 
        return "IOCTL_MPEG_VIDEO_STOP";
    case IOCTL_MPEG_AUDIO_QUERY_DEVICE: 
        return "IOCTL_MPEG_AUDIO_QUERY_DEVICE";
    case IOCTL_MPEG_VIDEO_QUERY_DEVICE: 
        return "IOCTL_MPEG_VIDEO_QUERY_DEVICE";
    case IOCTL_MPEG_VIDEO_CLEAR_BUFFER: 
        return "IOCTL_MPEG_VIDEO_CLEAR_BUFFER";
    case IOCTL_MPEG_OVERLAY_MODE: 
        return "IOCTL_MPEG_OVERLAY_MODE";
    case IOCTL_MPEG_OVERLAY_SET_BIT_MASK: 
        return "IOCTL_MPEG_OVERLAY_SET_BIT_MASK";
    case IOCTL_MPEG_OVERLAY_SET_VGAKEY: 
        return "IOCTL_MPEG_OVERLAY_SET_VGAKEY";
    case IOCTL_MPEG_OVERLAY_SET_DESTINATION: 
        return "IOCTL_MPEG_OVERLAY_SET_DESTINATION";
    case IOCTL_MPEG_AUDIO_GET_ATTRIBUTE: 
        return "IOCTL_MPEG_AUDIO_GET_ATTRIBUTE";
    case IOCTL_MPEG_VIDEO_GET_ATTRIBUTE: 
        return "IOCTL_MPEG_VIDEO_GET_ATTRIBUTE";
    case IOCTL_MPEG_AUDIO_SET_ATTRIBUTE: 
        return "IOCTL_MPEG_AUDIO_SET_ATTRIBUTE";
    case IOCTL_MPEG_VIDEO_SET_ATTRIBUTE: 
        return "IOCTL_MPEG_VIDEO_SET_ATTRIBUTE";
    case IOCTL_MPEG_PSEUDO_CREATE_FILE: 
        return "CreateFile";
    case IOCTL_MPEG_PSEUDO_CLOSE_HANDLE: 
        return "CloseHandle";
    default:
        {
            //      We don't recognize this IOCTL code. This is a memory
            //      leak, but we don't expect this happen. Allocate a buffer 
            //      to hold the message and return the buffer to the caller.
            
            PUCHAR pBuffer = (PUCHAR)GlobalAlloc (32, GMEM_FIXED);
            
            if (pBuffer) {
                sprintf (pBuffer, "Unrecognized code: 0x%x", IoControlCode);
                return pBuffer;
            } else {
                return "<Not recognized>";
            }
        }
    }

}



VOID
PrintEntry (
    IN PTRACE_ENTRY pEntry
    )

/*++

Routine Description:

    This routine displays a trace entry on stdout.    

Arguments:

    pEntry - provides the address of the entry to be displayed

Return Value:

    None.

--*/

{
    PUCHAR IoTypes[] = {
        "NONE",
        "SYNC_IOCTL",
        "IOCTL",
        "PACKETS",
        "SYNC_PACKETS"
        };

    fprintf (pOutputFile,
             "IoType: %s Op: %s, Id: %x, Result: %x\n\tInPrg: %x, Start/End: %d/%d, F/L: 0x%01x%08x/%01x%08x\n",
            IoTypes[pEntry->IoType],
            IoctlToText (pEntry->IoControlCode),
            pEntry->Id,
            pEntry->Result,
            pEntry->InProgress,
            pEntry->TimeStarted - BaseTime,
            pEntry->TimeEnded - BaseTime,
            (ULONG)(pEntry->FirstTimeStamp >> 32),
            (ULONG)pEntry->FirstTimeStamp,
            (ULONG)(pEntry->LastTimeStamp >> 32),
            (ULONG)pEntry->LastTimeStamp);
    fprintf (pOutputFile,
             "\tDuration: %d, pOverlapped = %x, pPktList = %x, PktCnt = %d\n",
            (pEntry->TimeEnded ? pEntry->TimeEnded : GetTickCount ()) - pEntry->TimeStarted,
            pEntry->pOverlapped,
            pEntry->pPacketList,
            pEntry->PacketCount);

            
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\makefile.inc ===
# NOTE:
# this directory contains a makefile which contains a single line that
# includes the global build process makefile.def. If the
# NTTARGETFILE1 or NTTARGETFILE0 environment
# variable is set then makefile.def includes makefile.inc from the current
# directory. This makefile.inc creates an extra target for nmake to create
# when it is run. NTTARGETFILE0 is built before everything else, and
# NTTARGETFILE1 is built after everything else.

copyfiles:
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll     \
         $(SDK_ROOT)\bin\*.*
  @if not exist $(QUARTZ)\lib\$(TARGET_DIRECTORY) \
    md $(QUARTZ)\lib\$(TARGET_DIRECTORY)
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).lib  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).lib     \
         $(QUARTZ)\lib\$(TARGET_DIRECTORY)\*.*


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\alloc.cpp ===
// Copyright (c) 1995 - 1996  Microsoft Corporation.  All Rights Reserved.

/*  alloc.cpp - allocator for output pins */

#include <streams.h>
#include "driver.h"

CMpeg1Splitter::COutputAllocator::COutputAllocator(CStreamAllocator * pAllocator,
                                                   HRESULT          * phr) :
    CSubAllocator(NAME("CMpeg1Splitter::COutputAllocator"),
                  NULL,
                  pAllocator,
                  phr)
{
}

CMpeg1Splitter::COutputAllocator::~COutputAllocator()
{
}

long CMpeg1Splitter::COutputAllocator::GetCount()
{
    return m_lCount;
}
#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\driver.h ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

#include <mmreg.h>             // For MPEG1WAVEFORMAT
#include <mpegdef.h>           // General MPEG definitions
#include <buffers.h>           // Buffer class definition
#include <stmalloc.h>          // Allocator classes
#include <mpgtime.h>           // MPEG time base
#include <mpegprse.h>          // Parsing
#include "pullpin.h"	       // pulling from IAsyncReader
#include <rdr.h>	       // simple reader for GetStreamsAndDuration
#include <qnetwork.h>          // IAMMediaContent
#include "mpgsplit.h"          // Filter
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\vpfilter.h ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    vpfilter.h

Abstract:

    This is the include file for kernel mode drivers intend to link to
    the video filter driver.

Author:

    Paul Shih (paulsh) 01-Apr-1994

Revision History:

--*/
#ifndef _VPFILTER_H
#define _VPFILTER_H

typedef struct  _MODE_DATA {
    ULONG   ScreenWidth;        // Number of visible horizontal pixels on a scan line
    ULONG   ScreenHeight;       // Number, in pixels, of visible scan lines.
    ULONG   ScreenStride;       // Bytes per line
    ULONG   NumberOfPlanes;     // Number of separate planes combined by the video hardware
    ULONG   BitsPerPlane;       // Number of bits per pixel on a plane
    ULONG   Frequency;          // Frequency of the screen, in hertz.
    ULONG   NumberRedBits;      // Number of bits in the red DAC
    ULONG   NumberGreenBits;    // Number of bits in the Green DAC.
    ULONG   NumberBlueBits;     // Number of bits in the blue DAC.
    ULONG   RedMask;            // Red color mask.  Bits turned on indicated the color red
    ULONG   GreenMask;          // Green color mask.  Bits turned on indicated the color green
    ULONG   BlueMask;           // Blue color mask.  Bits turned on indicated the color blue
    ULONG   AttributeFlags;     // Flags indicating certain device behavior.
                                // It's an logical-OR summation of MODE_xxx flags.
}   MODE_DATA, *PMODE_DATA;

#define MODE_COLOR              0x01    // 0 = monochrome; 1 = color
#define MODE_GRAPHICS           0x02    // 0 = text mode; 1 = graphics mode
#define MODE_INTERLACED         0x04    // 0 = non-interlaced; 1 = interlaced
#define MODE_PALETTE_DRIVEN     0x08    // 0 = colors direct; 1 = colors indexed to a palette

typedef	struct _RGBCOLOR {
    UCHAR   Red;            // Bits to be put in the red portion of the clor register
    UCHAR   Green;          // Bits to be put in the green portion of the color register
    UCHAR   Blue;           // Bits to be put in the blue portion of the color register
    UCHAR   Unused;
}   RGBCOLOR, *PRGBCOLOR;

typedef	union {
    RGBCOLOR    RgbColor;
    ULONG       RgbLong;
}   CLUT, *PCLUT;

typedef struct  _CLUT_DATA {
    USHORT      NumEntries; // Number of entries in the CLUT pointed by RGBArray
    USHORT      FirstEntry; // Location in the device palette to which the
                            //  first entry in the CLUT is copied.  The other
                            //  entries in the CLUT are copied sequentially
                            //  into the device palette from the starting
                            //  point.
    PCLUT       RgbArray;   // The CLUT to copy into the device color registers
                            //  (palette).
}	CLUT_DATA, *PCLUT_DATA;

typedef	struct	_PALETTE_DATA {
    USHORT  NumEntries; // Number of entries in the CLUT pointed by Colors.
    USHORT  FirstEntry; // Location in the device palette to which the
                        //  first entry in the CLUT is copied.  The other
                        //  entries in the CLUT are copied sequentially
                        //  into the device palette from the starting
                        //  point.
    PUSHORT Colors;     //  points to the CLUT to copy into the color palette.
}   PALETTE_DATA, *PPALETTE_DATA;

typedef enum {
    VideoReset = 0,
    VideoModeChange,
    VideoClutChange,
    VideoPaletteChange
}   NOTIFICATION_CODE;

typedef VOID    (*PVPFILTER_CALLBACK)(
                IN NOTIFICATION_CODE    NotificationCode,
                IN PVOID                UserContext,
                IN PVOID                NotificationContext
                );

NTSTATUS    HookVideoFilter(
                IN PVPFILTER_CALLBACK VPFilterCallBack,
                IN PVOID              Context
            );

NTSTATUS    UnhookVideoFilter(
            IN PVPFILTER_CALLBACK VPFilterCallBack
            );

#endif  // #ifndef _VPFILTER_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\filter.cpp ===
// Copyright (c) 1995 - 1997  Microsoft Corporation.  All Rights Reserved.

/*

    File:  filter.cpp

    Description:

        Code for MPEG-I system stream splitter filter CFilter

*/

#include <streams.h>
#include "driver.h"

//  Setup data

const AMOVIESETUP_MEDIATYPE
sudMpgInputType[4] =
{
    { &MEDIATYPE_Stream, &MEDIASUBTYPE_MPEG1System },
    { &MEDIATYPE_Stream, &MEDIASUBTYPE_MPEG1VideoCD },
    { &MEDIATYPE_Stream, &MEDIASUBTYPE_MPEG1Video },
    { &MEDIATYPE_Stream, &MEDIASUBTYPE_MPEG1Audio }
};

const AMOVIESETUP_MEDIATYPE
sudMpgAudioOutputType[2] =
{
    { &MEDIATYPE_Audio, &MEDIASUBTYPE_MPEG1Packet },
    { &MEDIATYPE_Audio, &MEDIASUBTYPE_MPEG1AudioPayload }
};

const AMOVIESETUP_MEDIATYPE
sudMpgVideoOutputType[2] =
{
    { &MEDIATYPE_Video, &MEDIASUBTYPE_MPEG1Packet },
    { &MEDIATYPE_Video, &MEDIASUBTYPE_MPEG1Payload }
};

const AMOVIESETUP_PIN
sudMpgPins[3] =
{
    { L"Input",
      FALSE,                               // bRendered
      FALSE,                               // bOutput
      FALSE,                               // bZero
      FALSE,                               // bMany
      &CLSID_NULL,                         // clsConnectsToFilter
      NULL,                                // ConnectsToPin
      NUMELMS(sudMpgInputType),            // Number of media types
      sudMpgInputType
    },
    { L"Audio Output",
      FALSE,                               // bRendered
      TRUE,                                // bOutput
      TRUE,                                // bZero
      FALSE,                               // bMany
      &CLSID_NULL,                         // clsConnectsToFilter
      NULL,                                // ConnectsToPin
      NUMELMS(sudMpgAudioOutputType),      // Number of media types
      sudMpgAudioOutputType
    },
    { L"Video Output",
      FALSE,                               // bRendered
      TRUE,                                // bOutput
      TRUE,                                // bZero
      FALSE,                               // bMany
      &CLSID_NULL,                         // clsConnectsToFilter
      NULL,                                // ConnectsToPin
      NUMELMS(sudMpgVideoOutputType),      // Number of media types
      sudMpgVideoOutputType
    }
};

const AMOVIESETUP_FILTER
sudMpgsplit =
{
    &CLSID_MPEG1Splitter,
    L"MPEG-I Stream Splitter",
    MERIT_NORMAL,
    NUMELMS(sudMpgPins),                   // 3 pins
    sudMpgPins
};

CMpeg1Splitter::CFilter::CFilter(
     CMpeg1Splitter *pSplitter,
     HRESULT *phr                // OLE failure return code
) :
     CBaseFilter(NAME("CMpeg1Splitter::CFilter"), // Object name
                      pSplitter->GetOwner(),           // Owner
                      &pSplitter->m_csFilter,          // Lock
                      CLSID_MPEG1Splitter),            // clsid
     m_pSplitter(pSplitter)
{
}


CMpeg1Splitter::CFilter::~CFilter()
{
}

int CMpeg1Splitter::CFilter::GetPinCount()
{
    CAutoLock lck(m_pLock);
    return 1 + m_pSplitter->m_OutputPins.GetCount();
}


CBasePin * CMpeg1Splitter::CFilter::GetPin(int n)
{
    CAutoLock lck(m_pLock);
    if (n == 0) {
        return &m_pSplitter->m_InputPin;
    }
    POSITION pos = m_pSplitter->m_OutputPins.GetHeadPosition();
    while (pos) {
        CBasePin *pPin = m_pSplitter->m_OutputPins.GetNext(pos);
        if (--n == 0) {
            return pPin;
        }
    }
    return NULL;
}


//
//  Override Pause() so we can prevent the input pin from starting
//  the puller before we're ready (ie have exited stopped state)
//
//  Starting the puller in Active() caused a hole where the first
//  samples could be rejected becase we seemed to be in 'stopped'
//  state
//
STDMETHODIMP
CMpeg1Splitter::CFilter::Pause()
{
    CAutoLock lockfilter(&m_pSplitter->m_csFilter);
    HRESULT hr = S_OK;
    if (m_State == State_Stopped) {
        // and do the normal inactive processing
        POSITION pos = m_pSplitter->m_OutputPins.GetHeadPosition();
        while (pos) {
            COutputPin *pPin = m_pSplitter->m_OutputPins.GetNext(pos);
            if (pPin->IsConnected()) {
                hr = pPin->COutputPin::Active();
                if (FAILED(hr)) {
                    break;
                }
            }
        }

        if (SUCCEEDED(hr)) {
            CAutoLock lockreceive(&m_pSplitter->m_csReceive);

            m_pSplitter->m_bAtEnd = FALSE;

            //  Activate our input pin only if we're connected
            if (m_pSplitter->m_InputPin.IsConnected()) {
                hr = m_pSplitter->m_InputPin.CInputPin::Active();
            }
            m_State = State_Paused;
        }
        //  Make Stop do something
        m_State = State_Paused;
        if (FAILED(hr)) {
            CFilter::Stop();
        }
    } else {
        m_State = State_Paused;
    }
    return hr;
}

// Return our current state and a return code to say if it's stable
// If we're splitting multiple streams see if one is potentially stuck
// and return VFW_S_CANT_CUE
STDMETHODIMP
CMpeg1Splitter::CFilter::GetState(DWORD dwMSecs, FILTER_STATE *pfs)
{
    CheckPointer( pfs, E_POINTER );
    CAutoLock lck(m_pLock);
    *pfs = m_State;
    if (m_State == State_Paused) {
        return m_pSplitter->CheckState();
    } else {
        return S_OK;
    }
}

// there is a Receive critsec that we need to hold to sync with the input pin,
// but we need to make it inactive before we hold it or we could deadlock.
STDMETHODIMP
CMpeg1Splitter::CFilter::Stop()
{
    // must get this one first.
    CAutoLock lockfilter(&m_pSplitter->m_csFilter);
    if (m_State == State_Stopped) {
        return NOERROR;
    }

    if (m_pSplitter->m_InputPin.IsConnected()) {
        // decommit the input pin or we can deadlock
        m_pSplitter->m_InputPin.CInputPin::Inactive();

        // now hold the Receive critsec to prevent further Receive and EOS calls,
        CAutoLock lockReceive(&m_pSplitter->m_csReceive);

        //  When we go active again the file reader is just going to
        //  send us the same old junk again so flush our allocator
        //
        //  Do this once we know the receive thread has been stopped (or
        //  all receives will be rejected before getting to the allocator)
        m_pSplitter->m_InputPin.Allocator()->ResetPosition();


        // and do the normal inactive processing
        POSITION pos = m_pSplitter->m_OutputPins.GetHeadPosition();
        while (pos) {
            COutputPin *pPin = m_pSplitter->m_OutputPins.GetNext(pos);
            if (pPin->IsConnected()) {
                pPin->COutputPin::Inactive();
            }
        }
    }
    m_State = State_Stopped;
    return S_OK;

}

#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpegapi\trace.h ===
/*++

Copyright (c) 1994 - 1995  Microsoft Corporation.  All Rights Reserved.

Module Name:

    trace.h

Abstract:

    This module defines the interface to the Mpeg API
    I/O trace facility.

Author:

    Jeff East [jeffe] 6-Dec-1994

Environment:

Revision History:

--*/

#ifndef TRACE_H
#define TRACE_H

#include <windows.h>
#include "mpegapi.h"


//
//      Determine if tracing is wanted in this compilation.
//
//      The rule is simple: if explicitly enabled, supply it.
//      Otherwise, provide it in checked builds, but not in free
//      builds.
//

#ifdef ENABLE_IO_TRACE
#define TRACE 1
#else
#define TRACE DBG
#endif


//
//      The trace entry points expect an IoControl operation code. But some
//      operations are performed using operations other than IoControl. These
//      are traced using the following "pseudo-op-codes".
//

#define MPEG_PSEUDO_IOCTL_BASE          0x890U
#define FILE_DEVICE_MPEG_PSEUDO         0x00008900U

#define CTL_CODE_MPEG_PSEUDO(offset)   CTL_CODE(FILE_DEVICE_MPEG_PSEUDO,           \
                                               MPEG_PSEUDO_IOCTL_BASE   + offset, \
                                               METHOD_BUFFERED,                  \
                                               FILE_ANY_ACCESS)

#define IOCTL_MPEG_PSEUDO_CREATE_FILE  (CTL_CODE_MPEG_PSEUDO (0))
#define IOCTL_MPEG_PSEUDO_CLOSE_HANDLE (CTL_CODE_MPEG_PSEUDO (1))


//
//      The trace entry points
//

#if TRACE

#ifdef  __cplusplus
extern "C" {
#endif

VOID
TraceSynchronousIoctlStart (
    OUT DWORD *pCookie,
    IN DWORD Id,
    IN DWORD Operation,
    IN LPVOID pInBuffer,
    IN LPVOID pOutBuffer
    );

VOID
TraceSynchronousIoctlEnd (
    IN DWORD Cookie,
    IN DWORD Result
    );

VOID
TraceIoctlStart (
    IN DWORD Id,
    IN DWORD Operation,
    IN LPOVERLAPPED pOverlapped,
    IN LPVOID pInBuffer,
    IN LPVOID pOutBuffer
    );

VOID
TraceIoctlEnd (
    IN LPOVERLAPPED pOverlapped,
    IN DWORD Result
    );

VOID
TracePacketsStart  (
    IN DWORD Id,
    IN DWORD Operation,
    IN LPOVERLAPPED pOverlapped,
    IN PMPEG_PACKET_LIST pPacketList,
    IN UINT PacketCount
    );

VOID
TraceSynchronousPacketsStart  (
    OUT DWORD *pCookie,
    IN DWORD Id,
    IN DWORD Operation,
    IN PMPEG_PACKET_LIST pPacketList,
    IN UINT PacketCount
    );

VOID
MPEGAPI
TraceDump (
    VOID
    );

VOID
MPEGAPI
TraceDumpFile (
    IN PUCHAR pFileName
    );

#ifdef  __cplusplus
}
#endif

#else

//
//      Tracing isn't enabled, so just define the the trace entrypoints
//      into oblivion.
//


#define TraceSynchronousIoctlStart(Cookie, eStreamType, Operation, pInBuffer, pOutBuffer)

#define TraceSynchronousIoctlEnd(Cookie, Result)

#define TraceIoctlStart(eStreamType, Operation,pOverlapped, pInBuffer, pOutBuffer)

#define TraceIoctlEnd(pOverlapped, Result)

#define TracePacketStart(eStreamType, Operation, pOverlapped, pBuffer, BufferSize)

#define TracePacketsStart(eStreamType, Operation, pOverlapped, pPacketList, PacketCount)

#define TraceSynchronousPacketsStart(pCookie, Id, Operation, pPacketList, PacketCount)

#define TraceDump()

#endif

#endif // TRACE_H
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\inputpin.cpp ===
// Copyright (c) 1995 - 1998  Microsoft Corporation.  All Rights Reserved.

/*

    File:  inputpin.cpp

    Description:

        Definitions for CMpeg1Splitter::CInputPin

    This class defines the input pin for the MPEG-I stream splitter.

    It handles

        Connection of the input pin including allocator negotiation

        Receive() of data from its connected pin which is sends
        to the parser
*/

#include <streams.h>
#include "driver.h"
#include <seqhdr.h>
#include <native.h>

#pragma warning(disable:4355)

/*  Constructor and Destructor */
CMpeg1Splitter::CInputPin::CInputPin(CMpeg1Splitter *pSplitter,
                                     HRESULT *phr) :
    CBaseInputPin(NAME("CMpeg1Splitter::CInputPin"),
                  &pSplitter->m_Filter,
                  &pSplitter->m_csFilter,
                  phr,
                  L"Input"),
    m_pSplitter(pSplitter),
    m_pPosition(NULL),
    m_llSeekPosition(0),
    m_bPulling(FALSE),
    m_puller(this)
{
}

CMpeg1Splitter::CInputPin::~CInputPin()
{
    ASSERT(m_pPosition == NULL);
}

/*  Helper to pass stuff to the parser

    If in the process of handling the data we do a seek within the
    allocator we repeat sending the data to the parser.  If we didn't
    do this we wouldn't work properly because if the output pin we're
    connected to is at end of stream in this situation we won't get
    called again
*/
inline HRESULT CMpeg1Splitter::CInputPin::SendDataToParser(
    BOOL bEOS
)
{
    CStreamAllocator *pAllocator = (CStreamAllocator *)m_pAllocator;

    for (;;) {

        /*  We validate any newly valid data, call the parser and
            advance the pointer by as much as the parser ate
        */
        LONG lLengthToProcess = pAllocator->LengthValid();

        LONG lProcessed = m_pSplitter->m_pParse->ParseBytes(
                               pAllocator->GetCurrentOffset(),
                               pAllocator->GetPosition(),
                               lLengthToProcess,
                               bEOS ? CBasicParse::Flags_EOS : 0);

        DbgLog((LOG_TRACE, 3, TEXT("Processed %d bytes out of %d"),
                lProcessed, pAllocator->LengthValid()));

        pAllocator->Advance(lProcessed);

        if (m_State == State_Seeking) {
            /*  Force completion of seek */
            if (bEOS) {
                m_pSplitter->m_pParse->EOS();
            }

            /*  Check if a seek was requested */
            if (m_bSeekRequested) {
                //  This fires for some reason after time format
                //  changes due to the implicit seek
                //  generated by the format change
                //  ASSERT(m_bComplete);
                ASSERT(m_bPulling || (m_pPosition != NULL));

                /*  Note that we ate a seek but didn't request the
                    reader to seek
                */
                m_bSeekRequested = FALSE;

                CStreamAllocator *pAllocator = (CStreamAllocator *)m_pAllocator;

                /*  Check to see if the allocator can do it */
                pAllocator->Seek(m_llSeekPosition);
            }

            if (m_bComplete) {
                /*  If we've completed a seek then Run() */
                SetState(State_Run);
                m_pSplitter->m_pParse->Run();

                /*  Send any data already in the allocator

                    If we don't do this here then the next call we
                    get might be EndOfStream and we wouldn't use
                    the data we already have
                */
            } else {
                return S_OK;
            }
        } else {  // State_Running
            /*  Flush out the rest */
            m_pSplitter->SendOutput();

            /*  We don't want any more data if we've completed the play */
            if (m_bComplete || bEOS) {
                /*  We must have finished a play */
                EndOfStreamInternal();

                /*  Return S_FALSE if there was no seek - in this case
                **  WE generate the EndOfStream() call (what if none of
                **  our output pins are connected)?
                */
                return S_FALSE;
            } else {
                return S_OK;
            }

            /*  Parsing errors are reported to the filter graph - but then
                we may be completely stuck if we get one?
            */
        }
    }
}


/* IMemInputPin virtual methods */

/*  Gets called by the output pin when another sample is ready */
STDMETHODIMP CMpeg1Splitter::CInputPin::Receive(IMediaSample *pSample)
{
    // m_csReceive is held for the receive-thread operations such as Receive
    // You must hold m_csFilter already if you want both.
    CAutoLock lck(&m_pSplitter->m_csReceive);

    // This function does not check for media type changes because
    // it is extremely unlikely that the upstream filter will try to change
    // the media type by attaching a media type to a media sample.  If
    // the upstream filter tries to change the media type, the parser code
    // will reject the samples with the new media type.
    HRESULT hr = CheckStreaming();
    if (S_OK != hr) {
        return hr;
    }

    BOOL bDiscontinuity = pSample->IsDiscontinuity() == S_OK;

    /*  Find out the position this sample corresponds to */
    CStreamAllocator *pAllocator = (CStreamAllocator *)m_pAllocator;

    if (bDiscontinuity) {
        // Make sure the parser knows
        m_pSplitter->m_pParse->Replay();

        // we can seek if we have either IAsyncReader or IMediaPosition
        if (m_bPulling || (m_pPosition != NULL)) {

            // if we are receiving data from a new segment, then
            // IPin::NewSegment will have told us the start time
            // (handled in CBasePin).
            //
            // if we are pulling data, then we maintain m_tStart and m_tStop
            // ourselves to be the selection we are fetching.

            // We must have the rounded start time from the puller
            // so do it anyway
            pAllocator->SetStart((LONGLONG)m_tStart / UNITS);


            //  Don't overlap with next seek request

            {
                CAutoLock lck(&m_pSplitter->m_csPosition);

                //  Always go to seeking state for a time-based seek
                SetState(State_Seeking);
                m_pSplitter->m_pParse->SetSeekState();

                //  May not require seek phase
                if (m_bComplete) {
                    SetState(State_Run);
                }
            }


        } else {
            /*  If the source is not seekable then the start position
                is meaningless but the allocator wants to be told something
            */
            pAllocator->SetStart(0);
        }
    }

    /*  First give the sample back to the allocator - this
        will AddRef the sample and update the length valid
    */
    PBYTE pbData;
    EXECUTE_ASSERT(SUCCEEDED(pSample->GetPointer(&pbData)));
    LONG lData = pSample->GetActualDataLength();

    /*  Avoid bugs in allocator */
    if (lData == 0) {
        DbgLog((LOG_TRACE, 0, TEXT("Unexpected End Of File")));
        EndOfStream();
        return S_FALSE;
    }

    /*  AddRef() it so we hold on to it (Advance() in the allocator balances
        this)
    */
    pSample->AddRef();

    hr = pAllocator->Receive(pbData, lData);
    if (FAILED(hr)) {

        pSample->Release();
        NotifyError(hr);

        /*  The whole allocator is now 'bad' */
        return hr;
    }

    /*  Process the new data */
    return SendDataToParser(FALSE);
}

/*  Where we're told which allocator we are using */
STDMETHODIMP CMpeg1Splitter::CInputPin::NotifyAllocator(IMemAllocator *pAllocator)
{
    // The MPEG1 Splitter's input pin is designed to only work with its' own allocator.
    if (pAllocator != m_pAllocator) {
        return E_FAIL;
    }
    return S_OK;
}

/*  Use our own allocator if possible */
STDMETHODIMP CMpeg1Splitter::CInputPin::GetAllocator(IMemAllocator **ppAllocator)
{
    CAutoLock lck(m_pLock);

    HRESULT hr = S_OK;

    /*  Create our own allocator if it isn't already created */
    if (m_pAllocator == NULL) {
        m_pAllocator =
            new CStreamAllocator(NAME("CMpeg1Splitter::CInputPin::m_pAllocator"),
                                 NULL,     // No owner
                                 &hr,
                                 MAX_MPEG_PACKET_SIZE + 4);
        if (m_pAllocator == NULL) {
            hr = E_OUTOFMEMORY;
        } else {
            if (FAILED(hr)) {
                delete static_cast<CStreamAllocator *>(m_pAllocator);
                m_pAllocator = NULL;
            } else {
                m_pAllocator->AddRef();
            }
        }
    }

    *ppAllocator = m_pAllocator;

    /*  We return a reference counted pointer */
    if (m_pAllocator != NULL) {
        m_pAllocator->AddRef();
    }
    return hr;
}

/*  Start Flushing samples
*/
STDMETHODIMP CMpeg1Splitter::CInputPin::BeginFlush()
{
    CAutoLock lck(m_pLock);

    if (m_pSplitter->m_Filter.m_State == State_Stopped) {
        return S_OK;
    }
    CBaseInputPin::BeginFlush();

    // can't flush the allocator here - need to sync with receive
    // thread, so do it in EndFlush

    /*  call the downstream pins  */
    return m_pSplitter->BeginFlush();
}

/*  End flushing samples - after this we won't send any more
*/
STDMETHODIMP CMpeg1Splitter::CInputPin::EndFlush()
{
    CAutoLock lck(m_pLock);
    if (!IsFlushing()) {
        return S_OK;
    }

    //  Flush the allocator - need to do this after the receive
    // thread has been deactivated.
    CStreamAllocator *pAlloc = (CStreamAllocator *)m_pAllocator;
    pAlloc->ResetPosition();

    if (m_pSplitter->m_Filter.m_State != State_Stopped) {
        m_pSplitter->EndFlush();
    }
    return CBaseInputPin::EndFlush();
}

#if 0
HRESULT CMpeg1Splitter::CInputPin::SetStop(REFTIME llTime)
{
    ASSERT(m_bPulling || (m_pPosition != NULL));

    /*  We have to make the reader flush so reset its start! */
    // m_tStart is not our last SetStart value, but the last
    // NewSegment call. Thus if the app does put_Current, put_Stop
    // the put_Stop may reset the start position on the reader to
    // the start position before the put_Current.
    //
    // Safest fix according to Robin is just to not do this. The cost
    // is that if someone does (just) a put_Stop when the reader had
    // already reached the old stop position, the reader will not continue
    // to play beyond that old stop position

    // we know the start time from the last NewSegment call
    DbgLog((LOG_TRACE, 2, TEXT("CInputPin::SetStop - put_CurrentPosition(%s)"),
               (LPCTSTR)CDisp(m_tStart)));

    HRESULT hr = m_pPosition->put_CurrentPosition(m_tStart);

    return S_OK;
}
#endif


/*  Say if Receive can block
    It can't for us so we return S_FALSE
*/
STDMETHODIMP CMpeg1Splitter::CInputPin::ReceiveCanBlock()
{
    return S_FALSE;
}

void CMpeg1Splitter::CInputPin::EndOfStreamInternal()
{
    DbgLog((LOG_TRACE, 2, TEXT("CMpeg1Splitter::CInputPin::EndOfStreamInternal()")));
    CStreamAllocator *pAllocator = (CStreamAllocator *)m_pAllocator;
    pAllocator->Advance(pAllocator->TotalLengthValid());
    m_pSplitter->EndOfStream();
}

/*  End of data - either called by our input pin or by us if we
    detect it ourselves
*/
STDMETHODIMP CMpeg1Splitter::CInputPin::EndOfStream()
{
    // hold m_csReceive on receive-thread operations to sync with Stop

    CAutoLock lck(&m_pSplitter->m_csReceive);
    HRESULT hr = CheckStreaming();
    if (S_OK != hr) {
        return hr;
    }
    /*  Send any dregs to the parser
        SendDataToParser will call EndOfStreamInternal
    */
    SendDataToParser(TRUE);

    return S_OK;
}


/* CBasePin methods */

HRESULT CMpeg1Splitter::CInputPin::GetMediaType(int iPosition,CMediaType *pMediaType)
{
    pMediaType->majortype            = MEDIATYPE_Stream;
    ASSERT(pMediaType->bFixedSizeSamples);
    pMediaType->bTemporalCompression = TRUE;
    ASSERT(pMediaType->lSampleSize == 1);

    switch (iPosition) {
    case 0:
        pMediaType->subtype = MEDIASUBTYPE_MPEG1System;
        break;

    case 1:
        pMediaType->subtype = MEDIASUBTYPE_MPEG1VideoCD;
        break;

    case 2:
        pMediaType->subtype = MEDIASUBTYPE_MPEG1Video;
        break;

    case 3:
        pMediaType->subtype = MEDIASUBTYPE_MPEG1Audio;
        break;

    default:
        return VFW_S_NO_MORE_ITEMS;
    }
    return S_OK;
}


/*  Connection establishment */
HRESULT CMpeg1Splitter::CInputPin::CheckMediaType(const CMediaType *pmt)
{
    for (int i = 0; ; i++) {
        CMediaType mt;
        HRESULT hr = GetMediaType(i, &mt);
        if (hr == VFW_S_NO_MORE_ITEMS) {
            break;
        }
        if (*pmt->Type() == *mt.Type() &&
            *pmt->Subtype() == *mt.Subtype()) {
            if (*pmt->FormatType() == GUID_NULL) {
                return S_OK;
            }
            if ((pmt->subtype == MEDIASUBTYPE_MPEG1System ||
                 pmt->subtype == MEDIASUBTYPE_MPEG1VideoCD) &&
                pmt->formattype == FORMAT_MPEGStreams ||
                pmt->subtype == MEDIASUBTYPE_MPEG1Audio &&
                pmt->formattype == FORMAT_WaveFormatEx ||
                pmt->subtype == MEDIASUBTYPE_MPEG1Video &&
                pmt->formattype == FORMAT_VideoInfo) {
                return S_OK;
            }
        }
    }
    return S_FALSE;
}

/*  Called when connect is broken or we fail to connect */
HRESULT CMpeg1Splitter::CInputPin::BreakConnect()
{
    DbgLog((LOG_TRACE, 2, TEXT("CInputPin::BreakConnect()")));

    if (m_bPulling) {
        m_puller.Disconnect();
        m_bPulling = FALSE;
    }

    /*  Disconnect and remove all the output pins */
    m_pSplitter->RemoveOutputPins();
    if (m_pPosition != NULL) {
        m_pPosition->Release();
        m_pPosition = NULL;
    }

    /*  Free the parser */
    if (m_pSplitter->m_pParse != NULL) {
        delete m_pSplitter->m_pParse;
        m_pSplitter->m_pParse = NULL;
    }
    return CBaseInputPin::BreakConnect();
}

/*  Override active to tell parser we're going to get new data */
HRESULT CMpeg1Splitter::CInputPin::Active()
{
    DbgLog((LOG_TRACE, 2, TEXT("CMpeg1Splitter::CInputPin::Active()")));
    HRESULT hr = m_pSplitter->m_pParse->Replay();
    if (FAILED(hr)) {
        return hr;
    }

    if (m_bPulling) {

        // since we control exactly when and where we get data from,
        // we should always explicitly set the start and stop position
        // ourselves here
        m_puller.Seek(m_tStart, m_tStop);

        // if we are pulling data from IAsyncReader, start our thread working
        hr = m_puller.Active();
        if (FAILED(hr)) {
            return hr;
        }
    }

    return CBaseInputPin::Active();
}

/*  Override Inactive to synchronize with Receive() */
HRESULT CMpeg1Splitter::CInputPin::Inactive()
{
    if (!IsConnected()) {
        return S_OK;
    }

    DbgLog((LOG_TRACE, 2, TEXT("CMpeg1Splitter::CInputPin::Inactive()")));

    // if we are pulling data from IAsyncReader, stop our thread
    if (m_bPulling) {
        HRESULT hr = m_puller.Inactive();
        if (FAILED(hr)) {
            return hr;
        }
    }

    /*  Call the base class - future Receives will now fail */
    return CBaseInputPin::Inactive();
}

/*  Override CompleteConnect so we can check out the real file data
    before accepting the connection
*/
HRESULT CMpeg1Splitter::CInputPin::CompleteConnect(IPin *pPin)
{
    DbgLog((LOG_TRACE, 3, TEXT("CMpeg1Splitter::CInputPin::CompleteConnect")));

#define READ_SIZE 32768
#define BUFFER_SIZE \
        (((MAX_MPEG_PACKET_SIZE + READ_SIZE - 1) / READ_SIZE) * READ_SIZE)

    int ReadSize = READ_SIZE;
    int BufferSize = BUFFER_SIZE;

    /*  Set up the parser */
    if (m_mt.subtype == MEDIASUBTYPE_MPEG1System) {
        m_pSplitter->m_pParse = new CMpeg1SystemParse;
        if (m_pSplitter->m_pParse == NULL) {
            return E_OUTOFMEMORY;
        }
    } else {
        if (m_mt.subtype == MEDIASUBTYPE_MPEG1VideoCD) {
            m_pSplitter->m_pParse = new CVideoCDParse;
            if (m_pSplitter->m_pParse == NULL) {
                return E_OUTOFMEMORY;
            }
        } else {
            if (m_mt.subtype == MEDIASUBTYPE_MPEG1Video) {
                m_pSplitter->m_pParse = new CNativeVideoParse;
            } else {
                if (m_mt.subtype == MEDIASUBTYPE_MPEG1Audio) {
                    m_pSplitter->m_pParse = new CNativeAudioParse;

                    //  Allow for large (64K) ID3 headers when scanning
                    ReadSize = 16 * 1024;
                    BufferSize = 128 * 1024;
                } else {
                    return E_FAIL;
                }
            }
        }
    }


    // simple file reader class for use by GetStreamsAndDuration.
    // we can build one of these on IStream or IAsyncReader
    CReader* pReader = NULL;

    //
    // look for IAsyncReader on the output pin and if found set up for
    // pulling data instead of using IMemInputPin.
    //
    // make an allocator first
    IMemAllocator* pAlloc;
    HRESULT hr = GetAllocator(&pAlloc);
    if (FAILED(hr)) {
        return hr;
    }
    pAlloc->Release();  // Our pin still has a ref count

    // Pull synchrously to avoid reading too much beyond the stop time
    // or seek position
    hr = m_puller.Connect(pPin, pAlloc, TRUE);
    if (S_OK == hr) {
        m_bPulling = TRUE;

        CReaderFromAsync* pR = new CReaderFromAsync;
        if (NULL == pR) {
            m_puller.Disconnect();
            return E_OUTOFMEMORY;
        }
        IAsyncReader* pSource = m_puller.GetReader();

        //  HACKHACK - do a huge read to download the whole of an FTP
        //  file
        ASSERT(pSource != NULL);
        BYTE bData[1];
        LONGLONG llTotal, llAvailable;
        HRESULT hr = pSource->Length(&llTotal, &llAvailable);
        if (FAILED(hr)) {
            pSource->Release();
            return hr;
        }
        if (llTotal == 0) {
            HRESULT hrRead = pSource->SyncRead(0x7FFFFFFFFFF, 1, bData);
            ASSERT(S_OK != hrRead);

            //  Reconnect to set up correct duration
            pSource->Release();
            m_puller.Disconnect();
            hr = m_puller.Connect(pPin, pAlloc, TRUE);
            if (FAILED(hr)) {
                return hr;
            }
            pSource = m_puller.GetReader();
            pSource->Length(&llTotal, &llAvailable);
            if (llTotal == 0) {
                pSource->Release();
                return FAILED(hrRead) ? hrRead : VFW_E_TYPE_NOT_ACCEPTED;
            }
            ASSERT(llTotal >= llAvailable);
        }

        hr = pR->Init(
                pSource,
                BufferSize,
                ReadSize,
                TRUE);
        if (FAILED(hr)) {
            delete pR;
            return hr;
        }
        // if it succeeded, it addrefed the interface

        pReader = pR;
   } else {


        /*  See if output pin supports IStream */
        IStream *pStream;
        hr = pPin->QueryInterface(IID_IStream, (void **)&pStream);

        if (FAILED(hr)) {
            DbgLog((LOG_ERROR, 2, TEXT("Outpin pin doesn't support IStream")));
        } else {

            /*  See if the output pin supports IMediaPosition */
            pPin->QueryInterface(IID_IMediaPosition, (void **)&m_pPosition);

            /*  Read the stream to get the stream data */
            CReaderFromStream* pR = new CReaderFromStream;
            if (pR) {
                hr = pR->Init(
                        pStream,
                        BufferSize,
                        ReadSize,
                        m_pPosition != NULL);
            } else {
                hr = E_OUTOFMEMORY;
            }

            if (FAILED(hr)) {
                pStream->Release();
                delete pR;
                return hr;
            }
            // if it succeeded it addrefed the stream.
            pReader = pR;
        }
    }

    hr = GetStreamsAndDuration(pReader);

    // releases any addrefed interfaces
    delete pReader;

    return hr;
}

/*
     Do all the basic work to create information from the MPEG data:

     1.  Read the start of the data (or from the current data if
         the stream is not seekable) and pass the data to the parser
         for it to extract format data and a start time for each
         stream

     2.  If the stream is seekable find the end (time)

     3.  For each stream found an output pins


*/
HRESULT CMpeg1Splitter::CInputPin::GetStreamsAndDuration(CReader *pReader)
{
    /*  Basically just process the file until we've got the
        data we need we use a circular buffer object for this (do
        we really need this or can we work to a fixed size?)
    */

    /*  No pins yet */
    ASSERT(m_pSplitter->m_OutputPins.GetCount() == 0);

    /*  Initialize */
    m_bSeekRequested = FALSE;

    /*  Initialize the parser */
    CBasicParse *pParse = m_pSplitter->m_pParse;
    pParse->SetNotify(this);

    LONGLONG llSize, llAvail;
    if (pReader != NULL) {
        llSize = pReader->GetSize(&llAvail);
    }
    pParse->Init(pReader == NULL ? 0 : llSize,
                 pReader == NULL ? FALSE : pReader->IsSeekable(),
                 &m_mt);

    if (pReader != NULL) {
        /*  m_bComplete is set by the completion callback from the parser
        */
        SetState(State_Initializing);
        LONGLONG llPos = 0;

        /*  Find the streams by searching from the start */
        HRESULT hr;
        while (!m_bComplete) {

            hr = pReader->ReadMore();
            if (FAILED(hr)) {
                return hr;
            }

            PBYTE    pbData;
            LONG     lLength;
            pbData = pReader->GetCurrent(lLength, llPos);

            DWORD dwFlags = llSize == llAvail ? 0 : CBasicParse::Flags_SlowMedium;
            if (S_FALSE == hr) {
                dwFlags |= CBasicParse::Flags_EOS;
            }

            LONG lProcessed = pParse->ParseBytes(llPos,
                                                  pbData,
                                                  lLength,
                                                  dwFlags);
            ASSERT(lProcessed <= lLength);
            if (hr == S_FALSE) {
                pParse->EOS();
                break;
            }
            pReader->Advance(lProcessed);
        }

        /*  If we got no streams fail */
        if (pParse->NumberOfStreams() == 0) {
            /*  Not an MPEG file */
            return E_INVALIDARG;
        }


        /*  See if we should find the length */
        if (pParse->IsSeekable() && llSize == llAvail) {

            /*  Set our own state */
            SetState(State_FindEnd);
            pParse->FindEnd();
            if (m_bSeekRequested) {
                m_bSeekRequested = FALSE;
                hr = pReader->Seek(m_llSeekPosition);
                if (FAILED(hr)) {
                    return hr;
                }
            }

            /*  Some parsing doesn't require this extra pass
                (Audio and short video files) in which case it
                will have called complete() inside FindEnd().
            */
            if (!m_bComplete) {

                for (;;) {
                    hr = pReader->ReadMore();
                    if (FAILED(hr)) {
                        return hr;
                    }

                    PBYTE    pbData;
                    LONGLONG llPos;
                    LONG     lLength;
                    pbData = pReader->GetCurrent(lLength, llPos);

                    LONG lProcessed = pParse->ParseBytes(llPos,
                                                         pbData,
                                                         lLength,
                                                         S_FALSE == hr ? CBasicParse::Flags_EOS : 0);
                    ASSERT(lProcessed <= lLength);
                    if (hr == S_FALSE) {
                        pParse->EOS();
                        break;
                    }
                    pReader->Advance(lProcessed);
                }
            }
            REFERENCE_TIME tDuration;
            HRESULT hr = pParse->GetDuration(&tDuration);
            if (FAILED(hr)) {
                return hr;
            }

            DbgLog((LOG_TRACE, 2, TEXT("Duration is %s"),
                   (LPCTSTR)CDisp(tDuration)));
        }
    } else {
        /*  If we got no streams in the media type fail */
        if (pParse->NumberOfStreams() == 0) {
            /*  Not an MPEG file */
            return E_INVALIDARG;
        }
    }

    /*  Now make a pin for each stream
    */

    for (int i = 0; i < pParse->NumberOfStreams(); i++) {

        CBasicStream *pStream;
        pStream = pParse->GetStream(i);

        HRESULT hr = S_OK;
        /*  Create an output pin for this stream */
        COutputPin *pPin = new COutputPin(m_pSplitter,
                                          pStream->m_uStreamId,
                                          pStream,
                                          &hr);
        if (pPin == NULL) {
            return E_OUTOFMEMORY;
        }
        if (FAILED(hr)) {
            delete pPin;
            return hr;
        }

        /* Release() is called when the pin is removed from the list */
        pPin->AddRef();
        POSITION pos = m_pSplitter->m_OutputPins.AddTail(pPin);
        if (pos == NULL) {
            delete pPin;
            return E_OUTOFMEMORY;
        }
    }

    /*  Fix up the allocator for this file */
    ALLOCATOR_PROPERTIES propRequest, propActual;

    /* Make sure we've got an allocator then set our preferred size */
    IMemAllocator *pAlloc;
    EXECUTE_ASSERT(SUCCEEDED(GetAllocator(&pAlloc)));
    pAlloc->Release();
    LONG lBufferSize = m_pSplitter->m_pParse->GetBufferSize();

    propRequest.cbPrefix = 0;
    propRequest.cbAlign = 1;
    propRequest.cBuffers = 4;
    propRequest.cbBuffer = lBufferSize/4;
    EXECUTE_ASSERT(SUCCEEDED(
        m_pAllocator->SetProperties(
            &propRequest,
            &propActual)));

    /*  Put ourselves into 'running' state */
    SetState(State_Run);
    pParse->Run();
    return S_OK;
}

/*  Get available and total byte counts from upstream */
HRESULT CMpeg1Splitter::CInputPin::GetAvailable(
    LONGLONG * pllTotal,
    LONGLONG * pllAvailable )
{
    if (!m_bPulling) {
        return E_FAIL;
    } else {
        IAsyncReader *pReader = m_puller.GetReader();
        HRESULT hr = pReader->Length(pllTotal, pllAvailable);
        pReader->Release();
        return hr;
    }

}

/*  Set up for seeking */
HRESULT CMpeg1Splitter::CInputPin::SetSeek(
             LONGLONG llStart,
             REFERENCE_TIME *prtStart,
             const GUID *pTimeFormat)
{
    BOOL bDoSeek = FALSE;
    REFERENCE_TIME tSeekPosition;
    {
        CAutoLock lck2(&m_pSplitter->m_csPosition);

        /*  Latch the seek time

            This will be used next time we get a discontinuity in the
            input data
        */

        /*  Ask the parser where to seek to */
        m_pSplitter->m_pParse->Seek(llStart, prtStart, pTimeFormat);

        /*  Check if this generated a seek request */
        if (m_bSeekRequested) {
            ASSERT(m_bPulling || (m_pPosition != NULL));
            m_bSeekRequested = FALSE;

            /*  Position is in seconds */
            tSeekPosition = COARefTime((REFTIME)m_llSeekPosition);
            DbgLog((LOG_TRACE, 3, TEXT("Requesting reader to seek to %s"),
                   (LPCTSTR)CDisp(tSeekPosition)));

            bDoSeek = TRUE;
        }
    }
    if (bDoSeek) {
        return DoSeek(COARefTime(tSeekPosition));
    } else {
        return S_OK;
    }
}
/*  Seek the upstream pin */
HRESULT CMpeg1Splitter::CInputPin::DoSeek(REFERENCE_TIME tSeekPosition)
{
    HRESULT hr = S_OK;
    if (m_bPulling) {
        // tell our worker thread the new segment.
        ALLOCATOR_PROPERTIES Actual;
        hr = m_pAllocator->GetProperties(&Actual);
        m_tStart = m_puller.AlignDown(tSeekPosition / UNITS, Actual.cbAlign) * UNITS;
        hr = m_puller.Seek(m_tStart, m_tStop);
    } else {
        // m_tStart will be set by the NewSegment call from the
        // upstream filter when it starts pushing this data
        hr = m_pPosition->put_CurrentPosition(COARefTime(tSeekPosition));
    }

    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 1, TEXT("Seek failed code 0x%8.8X"), hr));
    }
    return hr;
}

#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\mpgsplit.h ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*

    File:  mpgsplit.h

    Description:

        Definitions for MPEG-I system stream splitter filter

*/

extern const AMOVIESETUP_FILTER sudMpgsplit;

class CMpeg1Splitter : public CUnknown,     // We're an object
                       public IAMStreamSelect,
                       public IAMMediaContent //  For ID3
{

public:
    DECLARE_IUNKNOWN

public:
    // global critical section
    CCritSec    m_csFilter;

    // sync stop with receive thread activities eg Receive, EndOfStream...
    // get m_csFilter before this if you need both
    CCritSec    m_csReceive;

    // Lock on setting and getting position values
    //
    CCritSec    m_csPosition;  // Integrity of values set

    /*  Internal classes */

    class CInputPin;
    class COutputPin;

    /*  Filter */

    class CFilter : public CBaseFilter
    {
    private:
         /*  Our owner */
         CMpeg1Splitter * const m_pSplitter;
         friend class CInputPin;

    public:
         /*  Constructor and destructor */
         CFilter(CMpeg1Splitter *pSplitter,
                 HRESULT        *phr);
         ~CFilter();

         /* CBaseFilter */
         int GetPinCount();
         CBasePin *GetPin(int n);

         /* IBaseFilter */

         // override Stop to sync with inputpin correctly
         STDMETHODIMP Stop();

         // override Pause to stop ourselves starting too soon
         STDMETHODIMP Pause();

         // Override GetState to signal Pause failures
         STDMETHODIMP GetState(DWORD dwMSecs, FILTER_STATE *State);

         // Helper
         BOOL IsStopped()
         {
             return m_State == State_Stopped;
         };
    };

    //  Implementation if IMediaSeeking
    class CImplSeeking : public CUnknown, public IMediaSeeking
    {
    private:
        CMpeg1Splitter * const m_pSplitter;
        COutputPin     * const m_pPin;

    public:
        CImplSeeking(CMpeg1Splitter *, COutputPin *, LPUNKNOWN, HRESULT *);
        DECLARE_IUNKNOWN

        //  IMediaSeeking methods
        STDMETHODIMP NonDelegatingQueryInterface(REFIID riid,void **ppv);

        // returns S_OK if mode is supported, S_FALSE otherwise
        STDMETHODIMP IsFormatSupported(const GUID * pFormat);
        STDMETHODIMP QueryPreferredFormat(GUID *pFormat);

        // can only change the mode when stopped
        // (returns VFE_E_WRONG_STATE otherwise)
        STDMETHODIMP SetTimeFormat(const GUID * pFormat);
        STDMETHODIMP IsUsingTimeFormat(const GUID * pFormat);
        STDMETHODIMP GetTimeFormat(GUID *pFormat);

        // return current properties
        STDMETHODIMP GetDuration(LONGLONG *pDuration);
        STDMETHODIMP GetStopPosition(LONGLONG *pStop);
        STDMETHODIMP GetCurrentPosition(LONGLONG *pCurrent);

        STDMETHODIMP GetCapabilities( DWORD * pCapabilities );
        STDMETHODIMP CheckCapabilities( DWORD * pCapabilities );
        STDMETHODIMP ConvertTimeFormat(LONGLONG * pTarget, const GUID * pTargetFormat,
                                       LONGLONG    Source, const GUID * pSourceFormat );
        STDMETHODIMP SetPositions( LONGLONG * pCurrent, DWORD CurrentFlags
                                 , LONGLONG * pStop, DWORD StopFlags );
        STDMETHODIMP GetPositions( LONGLONG * pCurrent, LONGLONG * pStop );
        STDMETHODIMP SetRate(double dRate);
        STDMETHODIMP GetRate(double * pdRate);
        STDMETHODIMP GetAvailable( LONGLONG * pEarliest, LONGLONG * pLatest );
        STDMETHODIMP GetPreroll(LONGLONG *pPreroll) { return E_NOTIMPL; }

    };

    /*  Input pin */
    class CInputPin : public CBaseInputPin,
                      public CParseNotify  // Parse notifications
    {
    private:
        /*  Our owner */
        CMpeg1Splitter * const m_pSplitter;

        /*  IMediaPosition of output pin connected to us */
        IMediaPosition *       m_pPosition;

        /*  Notification stuff */
        Stream_State           m_State;

        /*  Notification data  */
        BOOL                   m_bComplete;  /*  State change complete */
        BOOL                   m_bSuccess;   /*  Succeded or not       */
        BOOL                   m_bSeekRequested;
        LONGLONG               m_llSeekPosition;

    public:
        /*  Constructor and Destructor */
        CInputPin(CMpeg1Splitter *pSplitter,
                  HRESULT *hr);
        ~CInputPin();

        /*  -- IPin - override CBaseInputPin -- */

        HRESULT CompleteConnect(IPin *pPin);

        /*  Start Flushing samples
        */
        STDMETHODIMP BeginFlush();

        /*  End flushing samples - after this we won't send any more
        */
        STDMETHODIMP EndFlush();

        /*  CBasePin */
        HRESULT BreakConnect();
        HRESULT Active();
        HRESULT Inactive();

        /* -- IMemInputPin virtual methods -- */

        /*  Gets called by the output pin when another sample is ready */
        STDMETHODIMP Receive(IMediaSample *pSample);

        /*  End of data */
        STDMETHODIMP EndOfStream();

        /*  Where we're told which allocator we are using */
        STDMETHODIMP NotifyAllocator(IMemAllocator *pAllocator);

        /*  Use our own allocator if possible */
        STDMETHODIMP GetAllocator(IMemAllocator **ppAllocator);

        /*  Say if we're blocking */
        STDMETHODIMP ReceiveCanBlock();

        /* CBasePin methods */

        /* returns the preferred formats for a pin */
        virtual HRESULT GetMediaType(int iPosition,CMediaType *pMediaType);

        /*  Connection establishment */
        HRESULT CheckMediaType(const CMediaType *pmt);

        /*  EndOfStream helper */
        void EndOfStreamInternal();


        /*  Seek from output pin's position stuff */
        HRESULT SetSeek(LONGLONG llStart,
                        REFERENCE_TIME *prtStart,
                        const GUID *pTimeFormat);
        /*  Get the available data from upstream */
        HRESULT GetAvailable( LONGLONG * pEarliest, LONGLONG * pLatest );

        /*  CParseNotify Methods */

        void ParseError(UCHAR       uStreamId,
                        LONGLONG    llPosition,
                        DWORD       Error);
        void SeekTo(LONGLONG llPosition);
        void Complete(BOOL          bSuccess,
                      LONGLONG      llPosFound,
                      REFERENCE_TIME tFound);
        HRESULT QueuePacket(UCHAR uStreamId,
                            PBYTE pbData,
                            LONG lSize,
                            REFERENCE_TIME tStart,
                            BOOL bSync);

        HRESULT Read(LONGLONG llStart, DWORD dwLen, BYTE *pbData);

        /*  Set notify state */
        void SetState(Stream_State);

        /*  Check if a seek has been requested and issue it to the
            connected output pin if it has been

            We also need to know if the allocator was used or not
            because if it wasn't we want to turn off the data coming
            from the reader
        */
        HRESULT CheckSeek();

        /*  Seek the output pin we're connected to */
        HRESULT DoSeek(REFERENCE_TIME tSeekPosition);

        /*  Return our allocator */
        CStreamAllocator *Allocator() const
        {
            return (CStreamAllocator *)m_pAllocator;
        }

        /*  Report filter from reader */
        void NotifyError(HRESULT hr)
        {
            m_pFilter->NotifyEvent(EC_ERRORABORT, hr, 0);
            EndOfStream();
        };

    private:

        // class to pull data from IAsyncReader if we detect that interface
        // on the output pin
        class CImplPullPin : public CPullPin
        {
            // forward everything to containing pin
            CInputPin* m_pPin;

        public:
            CImplPullPin(CInputPin* pPin)
              : m_pPin(pPin)
            {
            };

            // Override allocator selection to make sure we get our own
            HRESULT DecideAllocator(
        		IMemAllocator* pAlloc,
        		ALLOCATOR_PROPERTIES * pProps)
            {
                HRESULT hr = CPullPin::DecideAllocator(pAlloc, pProps);
                if (SUCCEEDED(hr) && m_pAlloc != pAlloc) {
                    return VFW_E_NO_ALLOCATOR;
                }
                return hr;
            }

	    // forward this to the pin's IMemInputPin::Receive
	    HRESULT Receive(IMediaSample* pSample) {
		return m_pPin->Receive(pSample);
	    };
	
	    // override this to handle end-of-stream
	    HRESULT EndOfStream(void) {
		return m_pPin->EndOfStream();
	    };

            // these errors have already been reported to the filtergraph
            // by the upstream filter so ignore them
            void OnError(HRESULT hr) {
                // ignore VFW_E_WRONG_STATE since this happens normally
                // during stopping and seeking
                if (hr != VFW_E_WRONG_STATE) {
                    m_pPin->NotifyError(hr);
                }
            };

            // flush the pin and all downstream
            HRESULT BeginFlush() {
                return m_pPin->BeginFlush();
            };
            HRESULT EndFlush() {
                return m_pPin->EndFlush();
            };

	};
	CImplPullPin m_puller;

        // true if we are using m_puller to get data rather than
        // IMemInputPin
        BOOL m_bPulling;


        HRESULT GetStreamsAndDuration(CReader* pReader);
        inline HRESULT SendDataToParser(BOOL bEOS);
    };

    //
    //  COutputPin defines the output pins
    //  This contain a list of samples generated by the parser to be
    //  sent to this pin and a thread handle for the sending thread
    //
    class COutputPin : public CBaseOutputPin, public CCritSec
    {
    public:
        // Constructor and Destructor

        COutputPin(
            CMpeg1Splitter * pSplitter,
            UCHAR            StreamId,
            CBasicStream   * pStream,
            HRESULT        * phr);

        ~COutputPin();

        // CUnknown methods

        // override this to say what interfaces we support where
        STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** ppv);
        STDMETHODIMP_(ULONG) NonDelegatingRelease();
        STDMETHODIMP_(ULONG) NonDelegatingAddRef();


        // CBasePin methods

        // returns the preferred formats for a pin
        virtual HRESULT GetMediaType(int iPosition,CMediaType *pMediaType);

        // check if the pin can support this specific proposed type and format
        virtual HRESULT CheckMediaType(const CMediaType *);

        // set the connection to use this format (previously agreed)
        virtual HRESULT SetMediaType(const CMediaType *);

        // override to call Commit and Decommit
        HRESULT Active();
        HRESULT Inactive();
        HRESULT BreakConnect();

        // CBaseOutputPin methods

        // override this to set the buffer size and count. Return an error
        // if the size/count is not to your liking
        HRESULT DecideBufferSize(
                            IMemAllocator * pAlloc,
                            ALLOCATOR_PROPERTIES * pProp);

        // negotiate the allocator and its buffer size/count
        // calls DecideBufferSize to call SetCountAndSize
        HRESULT DecideAllocator(IMemInputPin * pPin, IMemAllocator ** pAlloc);

        // override this to control the connection
        HRESULT InitAllocator(IMemAllocator **ppAlloc);

        // Queue a sample to the outside world
        HRESULT QueuePacket(PBYTE         pPacket,
                            LONG          lPacket,
                            REFERENCE_TIME tTimeStamp,
                            BOOL          bTimeValid);

        // Override to handle quality messages
        STDMETHODIMP Notify(IBaseFilter * pSender, Quality q)
        {    return E_NOTIMPL;   // We do NOT handle this
        }


        // Short cut to output queue
        void SendAnyway()
        {
            CAutoLock lck(this);
            if (m_pOutputQueue != NULL) {
                m_pOutputQueue->SendAnyway();
            }
        };

        // override DeliverNewSegment to queue with output q
        HRESULT DeliverNewSegment(
                    REFERENCE_TIME tStart,
                    REFERENCE_TIME tStop,
                    double dRate) {
                m_pOutputQueue->NewSegment(tStart, tStop, dRate);
                return S_OK;
        };

        // Are we the pin being used for seeking
        BOOL IsSeekingPin();

        // Pass out a pointer to our media type
        const AM_MEDIA_TYPE *MediaType() const {
            return &m_mt;
        }
    public:
        UCHAR                  m_uStreamId;    // Stream Id
        BOOL                   m_bPayloadOnly; // Packet or payload type?

    private:
        friend class CMpeg1Splitter;
        CMpeg1Splitter * const m_pSplitter;
        CBasicStream   *       m_Stream;
        COutputQueue   *       m_pOutputQueue;

        /*  Position stuff */
        CImplSeeking           m_Seeking;
    };

    /*  Override CSubAllocator to find out what the size and count
        are.  We use the count to give us a hint about batch sizes.
    */

    class COutputAllocator : public CSubAllocator
    {
    public:
        COutputAllocator(CStreamAllocator * pAllocator,
                         HRESULT          * phr);
        ~COutputAllocator();

        long GetCount();
    };

public:
    /* Constructor and Destructor */

    CMpeg1Splitter(
        TCHAR    * pName,
        LPUNKNOWN  pUnk,
        HRESULT  * phr);

    ~CMpeg1Splitter();

    /* This goes in the factory template table to create new instances */
    static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);

    /* Overriden to say what interfaces we support and where */
    STDMETHODIMP NonDelegatingQueryInterface(REFIID, void **);

    /* IAMStreamSelect */

    //  Returns total count of streams
    STDMETHODIMP Count(
        /*[out]*/ DWORD *pcStreams);      // Count of logical streams

    //  Return info for a given stream - S_FALSE if iIndex out of range
    //  The first steam in each group is the default
    STDMETHODIMP Info(
        /*[in]*/ long iIndex,              // 0-based index
        /*[out]*/ AM_MEDIA_TYPE **ppmt,   // Media type - optional
                                          // Use DeleteMediaType to free
        /*[out]*/ DWORD *pdwFlags,        // flags - optional
        /*[out]*/ LCID *plcid,            // Language id - optional
        /*[out]*/ DWORD *pdwGroup,        // Logical group - 0-based index - optional
        /*[out]*/ WCHAR **ppszName,       // Name - optional - free with CoTaskMemFree
                                          // Can return NULL
        /*[out]*/ IUnknown **ppPin,       // Associated pin - returns NULL - optional
                                          // if no associated pin
        /*[out]*/ IUnknown **ppUnk);      // Stream specific interface

    //  Enable or disable a given stream
    STDMETHODIMP Enable(
        /*[in]*/  long iIndex,
        /*[in]*/  DWORD dwFlags);

    /*  Remove our output pins */
    void RemoveOutputPins();



    /***  IAMMediaContent - cheapo implementation - no IDispatch ***/


    /* IDispatch methods */
    STDMETHODIMP GetTypeInfoCount(UINT * pctinfo) {return E_NOTIMPL;}

    STDMETHODIMP GetTypeInfo(
      UINT itinfo,
      LCID lcid,
      ITypeInfo ** pptinfo) { return E_NOTIMPL; }

    STDMETHODIMP GetIDsOfNames(
      REFIID riid,
      OLECHAR  ** rgszNames,
      UINT cNames,
      LCID lcid,
      DISPID * rgdispid) { return E_NOTIMPL; }


    STDMETHODIMP Invoke(
                DISPID dispIdMember,
                REFIID riid,
                LCID lcid,
                WORD wFlags,
                DISPPARAMS * pDispParams,
                VARIANT * pVarResult,
                EXCEPINFO * pExcepInfo,
                UINT * puArgErr
            ) { return E_NOTIMPL; }
    

    /*  IAMMediaContent */
    STDMETHODIMP get_AuthorName(BSTR FAR* strAuthorName);
    STDMETHODIMP get_Title(BSTR FAR* strTitle);
    STDMETHODIMP get_Copyright(BSTR FAR* strCopyright);
    STDMETHODIMP get_Description(BSTR FAR* strDescription);

    STDMETHODIMP get_Rating(BSTR FAR* strRating){ return E_NOTIMPL;}
    STDMETHODIMP get_BaseURL(BSTR FAR* strBaseURL){ return E_NOTIMPL;}
    STDMETHODIMP get_LogoURL(BSTR FAR* pbstrLogoURL){ return E_NOTIMPL;}
    STDMETHODIMP get_LogoIconURL(BSTR FAR* pbstrLogoIconURL){ return E_NOTIMPL;}
    STDMETHODIMP get_WatermarkURL(BSTR FAR* pbstrWatermarkURL){ return E_NOTIMPL;}
    STDMETHODIMP get_MoreInfoURL(BSTR FAR* pbstrMoreInfoURL){ return E_NOTIMPL;}
    STDMETHODIMP get_MoreInfoBannerURL(BSTR FAR* pbstrMoreInfoBannerURL) { return E_NOTIMPL;}
    STDMETHODIMP get_MoreInfoBannerImage(BSTR FAR* pbstrMoreInfoBannerImage) { return E_NOTIMPL;}
    STDMETHODIMP get_MoreInfoText(BSTR FAR* pbstrMoreInfoText) { return E_NOTIMPL;}

    /*  Helper for ID3 */
    HRESULT GetContentString(CBasicParse::Field dwId, BSTR *str);

private:
    /* Internal stream info stuff */
    BOOL    GotStreams();
    HRESULT SetDuration();
    BOOL    SendInit(UCHAR    uStreamId,
                     PBYTE    pbPacket,
                     LONG     lPacketSize,
                     LONG     lHeaderSize,
                     BOOL     bHasPts,
                     LONGLONG llPts);
    /*  Flush after receive completes */
    void    SendOutput();

    /*  Send EndOfStream downstream */
    void    EndOfStream();

    /*  Send BeginFlush() downstream */
    HRESULT BeginFlush();

    /*  Send EndFlush() downstream */
    HRESULT EndFlush();

    /*  Check state against streams and fail if one looks stuck
        Returns S_OK           if not stuck
                VFW_S_CANT_CUE if any stream is stuck
    */
    HRESULT CheckState();

private:
    /*  Allow our internal classes to see our private data */
    friend class CFilter;
    friend class COutputPin;
    friend class CInputPin;
    friend class CImplSeeking;

    /*  Members - simple really -
            filter
            input pin,
            output pin list
            parser
    */
    CFilter                  m_Filter;
    CInputPin                m_InputPin;
    CGenericList<COutputPin> m_OutputPins;

    /*  Parser */
    CBasicParse            * m_pParse;

    /*  At end of data so EndOfStream sent for all pins */
    BOOL                     m_bAtEnd;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\parse.cpp ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*

    File:  parse.cpp

    Description:

        Implement the CParseNotify class for the MPEG splitter

*/

#include <streams.h>
#include "driver.h"

void CMpeg1Splitter::CInputPin::ParseError(UCHAR       uStreamId,
                                           LONGLONG    llPosition,
                                           DWORD       Error)
{
    if (m_State != State_Initializing &&
        m_State != State_FindEnd) {
        m_pSplitter->m_Filter.NotifyEvent(EC_STREAM_ERROR_STILLPLAYING,
                                          0,
                                          (LONG)Error);
    }
}

void CMpeg1Splitter::CInputPin::SeekTo(LONGLONG llPosition)
{
    /*  Seek our input pin */

    REFERENCE_TIME tStart;
    tStart = llPosition;
    m_bSeekRequested = TRUE;
    m_llSeekPosition = llPosition;
}

void CMpeg1Splitter::CInputPin::Complete(BOOL          bSuccess,
                                         LONGLONG      llPosFound,
                                         REFERENCE_TIME tFound)
{
    UNREFERENCED_PARAMETER(tFound);
    m_bComplete       = TRUE;
    m_bSuccess        = bSuccess;
    if (m_State == State_Seeking) {
        m_llSeekPosition = llPosFound;
        m_bSeekRequested = TRUE;
    }
}

HRESULT CMpeg1Splitter::CInputPin::QueuePacket(UCHAR uStreamId,
                                               PBYTE pbData,
                                               LONG lSize,
                                               REFERENCE_TIME tStart,
                                               BOOL bSync)
{
    /*  Find the correct output pin and send the packet */
    POSITION pos = m_pSplitter->m_OutputPins.GetHeadPosition();
    while (pos) {
        COutputPin *pPin = m_pSplitter->m_OutputPins.GetNext(pos);
        ASSERT(pPin != NULL);
        if (pPin->m_uStreamId == uStreamId) {
            return pPin->QueuePacket(pbData,
                                     lSize,
                                     tStart,
                                     bSync);
        }
    }
    return S_FALSE;
}

/*  Allow the parser to read some stuff */

HRESULT CMpeg1Splitter::CInputPin::Read(LONGLONG llStart, DWORD dwLen, BYTE *pbData)
{
    if (!m_bPulling) {
        return E_NOTIMPL;
    }
    IAsyncReader* pSource = m_puller.GetReader();

    LONGLONG llTotal, llAvailable;
    HRESULT hr = pSource->Length(&llTotal, &llAvailable);
    if (S_OK == hr) {
        if (llStart < 0) {
            llStart = llTotal + llStart;
        }
        if (llStart >= 0 && llStart + dwLen <= llAvailable) {
            hr = pSource->SyncRead(llStart, dwLen, pbData);
        } else {
            hr = E_FAIL;
        }
    }
    pSource->Release();
    return hr;
}

#ifdef DEBUG
/*  State names */
LPCTSTR StateNames[] = { TEXT("Initializing"),
                         TEXT("Seeking"),
                         TEXT("Run"),
                         TEXT("Finding End"),
                         TEXT("Stopping")
                       };
#endif

/*  Set a new state for notifications */
void CMpeg1Splitter::CInputPin::SetState(Stream_State s)
{
    DbgLog((LOG_TRACE, 2, TEXT("Setting state %s"),
            StateNames[(int)s]));
    m_State = s;
    m_bComplete = FALSE;
};


#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\position.cpp ===
// Copyright (c) 1995 - 1997  Microsoft Corporation.  All Rights Reserved.

/*

    position.cpp

    Implementation of IMediaSeeking for the file reader source filter

*/

#include <streams.h>
#include "driver.h"

//
//  IMediaSeeking stuff
//
/*  Constructor and Destructor */
CMpeg1Splitter::CImplSeeking::CImplSeeking(CMpeg1Splitter *pSplitter,
                                               COutputPin *pPin,
                                               LPUNKNOWN pUnk,
                                               HRESULT *phr) :
    CUnknown(NAME("CMpeg1Splitter::CImplSeeking"),pUnk),
    m_pSplitter(pSplitter),
    m_pPin(pPin)
{
}

STDMETHODIMP
CMpeg1Splitter::CImplSeeking::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv)
{
    if (riid == IID_IMediaSeeking && m_pSplitter->m_pParse->IsSeekable()) {
	return GetInterface(static_cast<IMediaSeeking *>(this), ppv);
    } else {
	return CUnknown::NonDelegatingQueryInterface(riid, ppv);
    }
}
// returns S_OK if mode is supported, S_FALSE otherwise
STDMETHODIMP CMpeg1Splitter::CImplSeeking::IsFormatSupported(const GUID * pFormat)
{
    //  Don't support frame seeking except on the video pin - otherwise
    //  the frame seek info won't get passed through the video decoder
    //  filter by the filter graph

    //
    //  Actually now don't support ANY stuff on anything except video
    //  This works better because video is the larger component of the stream
    //  anyway
    //  However, we need to support TIME_FORMAT_MEDIA_TIME or the graph
    //  code gets confused and starts using IMediaPosition
    if (!m_pPin->IsSeekingPin()) {
        return pFormat == NULL || *pFormat == TIME_FORMAT_MEDIA_TIME ?
            S_OK : S_FALSE;
    }
    //  The parser knows if this time format is supported for this type
    return m_pSplitter->m_pParse->IsFormatSupported(pFormat);
}
STDMETHODIMP CMpeg1Splitter::CImplSeeking::QueryPreferredFormat(GUID *pFormat)
{
    /*  Don't care - they're all just as bad as one another */
    *pFormat = m_pPin->IsSeekingPin()
               ? TIME_FORMAT_MEDIA_TIME
               : TIME_FORMAT_NONE;
    return S_OK;
}

// can only change the mode when stopped
// (returns VFE_E_WRONG_STATE otherwise)
STDMETHODIMP CMpeg1Splitter::CImplSeeking::SetTimeFormat(const GUID * pFormat)
{
    CAutoLock lck(&m_pSplitter->m_csFilter);
    if (!m_pSplitter->m_Filter.IsStopped()) {
        return VFW_E_WRONG_STATE;
    }
    if (S_OK != IsFormatSupported(pFormat)) {
        return E_INVALIDARG;
    }


    /*  Translate the format (later we compare pointers, not what they point at!) */
    if (*pFormat == TIME_FORMAT_MEDIA_TIME) {
        pFormat = &TIME_FORMAT_MEDIA_TIME;
    } else
    if (*pFormat == TIME_FORMAT_BYTE) {
        pFormat = &TIME_FORMAT_BYTE;
    } else
    if (*pFormat == TIME_FORMAT_FRAME) {
        pFormat = &TIME_FORMAT_FRAME;
    }

    HRESULT hr = m_pSplitter->m_pParse->SetFormat(pFormat);
    return hr;
}

//
//  Returns the current time format
//
STDMETHODIMP CMpeg1Splitter::CImplSeeking::GetTimeFormat(GUID *pFormat)
{
    CAutoLock lck(&m_pSplitter->m_csPosition);
    if (m_pPin->IsSeekingPin()) {
        *pFormat = *m_pSplitter->m_pParse->TimeFormat();
    } else {
        *pFormat = TIME_FORMAT_NONE;
    }
    return S_OK;
}

//
//  Returns the current time format
//
STDMETHODIMP CMpeg1Splitter::CImplSeeking::IsUsingTimeFormat(const GUID * pFormat)
{
    CAutoLock lck(&m_pSplitter->m_csPosition);
    return ( m_pPin->IsSeekingPin() ? *pFormat == *m_pSplitter->m_pParse->TimeFormat() : *pFormat == TIME_FORMAT_NONE )
           ? S_OK
           : S_FALSE;
}

// return current properties
STDMETHODIMP CMpeg1Splitter::CImplSeeking::GetDuration(LONGLONG *pDuration)
{
    CAutoLock lck(&m_pSplitter->m_csPosition);
    return m_pSplitter->m_pParse->GetDuration(pDuration, m_pSplitter->m_pParse->TimeFormat());
}
STDMETHODIMP CMpeg1Splitter::CImplSeeking::GetStopPosition(LONGLONG *pStop)
{
    CAutoLock lck(&m_pSplitter->m_csPosition);
    *pStop = m_pSplitter->m_pParse->GetStop();
    return S_OK;
}
//  Return the start position if we get asked for the current position on
//  the basis that we'll only be asked if we haven't sent any position data
//  yet in any samples
STDMETHODIMP CMpeg1Splitter::CImplSeeking::GetCurrentPosition(LONGLONG *pCurrent)
{
    CAutoLock lck(&m_pSplitter->m_csPosition);
    *pCurrent = m_pSplitter->m_pParse->GetStart();
    return S_OK;
}

STDMETHODIMP CMpeg1Splitter::CImplSeeking::GetCapabilities( DWORD * pCapabilities )
{
    *pCapabilities = AM_SEEKING_CanSeekForwards
      | AM_SEEKING_CanSeekBackwards
      | AM_SEEKING_CanSeekAbsolute
      | AM_SEEKING_CanGetStopPos
      | AM_SEEKING_CanGetDuration;
    return NOERROR;
}

STDMETHODIMP CMpeg1Splitter::CImplSeeking::CheckCapabilities( DWORD * pCapabilities )
{
    DWORD dwCaps;
    HRESULT hr = GetCapabilities( &dwCaps );
    if (SUCCEEDED(hr))
    {
        dwCaps &= *pCapabilities;
        hr =  dwCaps ? ( dwCaps == *pCapabilities ? S_OK : S_FALSE ) : E_FAIL;
        *pCapabilities = dwCaps;
    }
    else *pCapabilities = 0;

    return hr;
}

STDMETHODIMP CMpeg1Splitter::CImplSeeking::ConvertTimeFormat(LONGLONG * pTarget, const GUID * pTargetFormat,
                                                             LONGLONG    Source, const GUID * pSourceFormat )
{
    return m_pSplitter->m_pParse->ConvertTimeFormat( pTarget, pTargetFormat, Source, pSourceFormat );
}

STDMETHODIMP CMpeg1Splitter::CImplSeeking::SetPositions
( LONGLONG * pCurrent, DWORD CurrentFlags
, LONGLONG * pStop, DWORD StopFlags )
{
    LONGLONG Current, Stop ;

    HRESULT hr = S_OK;

    const DWORD PosCurrentBits = CurrentFlags & AM_SEEKING_PositioningBitsMask;
    const DWORD PosStopBits    = StopFlags & AM_SEEKING_PositioningBitsMask;

    if (PosCurrentBits == AM_SEEKING_AbsolutePositioning) {
        Current = *pCurrent;
    } else {
        hr = GetCurrentPosition( &Current );
        if (FAILED(hr)) {
            return hr;
        }
        if (PosCurrentBits == AM_SEEKING_RelativePositioning) Current += *pCurrent;
    }

    if (PosStopBits == AM_SEEKING_AbsolutePositioning) {
        Stop = *pStop;
    } else if (PosStopBits == AM_SEEKING_IncrementalPositioning) {
        Stop = Current + *pStop;
    } else {
        hr = GetStopPosition( &Stop );
        if (FAILED(hr)) {
            return hr;
        }
        if (PosStopBits == AM_SEEKING_RelativePositioning) Stop += *pStop;
    }

    //  Call the input pin to call the parser and do the seek
    {
        CAutoLock lck(&m_pSplitter->m_csPosition);
        if (!m_pPin->IsSeekingPin()) {
            //  We only agreed to format setting on our seeking pin
            return E_UNEXPECTED;
        }
        LONGLONG llDuration;

        //  Check limits
        EXECUTE_ASSERT(SUCCEEDED(m_pSplitter->m_pParse->GetDuration(
            &llDuration, m_pSplitter->m_pParse->TimeFormat())));
        if (PosCurrentBits &&
            (Current < 0 || PosStopBits && Current > Stop)
           ) {
            return E_INVALIDARG;
        }


        if (PosStopBits)
        {
            if (Stop > llDuration) {
                Stop = llDuration;
            }
            m_pSplitter->m_pParse->SetStop(Stop);
        }
    }

    REFERENCE_TIME rt;

    if (PosCurrentBits)
    {
        hr = m_pSplitter->m_InputPin.SetSeek(
                          *pCurrent,
                          &rt,
                          m_pSplitter->m_pParse->TimeFormat());
        if (FAILED(hr)) {
            return hr;
        }
        if (CurrentFlags & AM_SEEKING_ReturnTime)
        {
            *pCurrent = rt;
        }
        if (StopFlags & AM_SEEKING_ReturnTime)
        {
            *pStop = llMulDiv( Stop, rt, Current, 0 );
        }
    }
    return hr;
}

STDMETHODIMP CMpeg1Splitter::CImplSeeking::GetPositions( LONGLONG * pCurrent, LONGLONG * pStop )
{
    HRESULT hrResult = S_OK;

    if (pCurrent)
    {
        hrResult = GetCurrentPosition( pCurrent );
        if (FAILED(hrResult)) {
            return hrResult;
        }
    }

    if (pStop)
    {
        hrResult = GetStopPosition( pStop );
    }

    return hrResult;
}

STDMETHODIMP CMpeg1Splitter::CImplSeeking::SetRate(double dRate)
{
    CAutoLock lck2(&m_pSplitter->m_csPosition);
    if (dRate < 0) {
        return E_INVALIDARG;
    }
    m_pSplitter->m_pParse->SetRate(dRate);
    return S_OK;
}

STDMETHODIMP CMpeg1Splitter::CImplSeeking::GetRate(double * pdRate)
{
    CAutoLock lck(&m_pSplitter->m_csPosition);
    *pdRate = m_pSplitter->m_pParse->GetRate();
    return S_OK;
}

STDMETHODIMP CMpeg1Splitter::CImplSeeking::GetAvailable( LONGLONG * pEarliest, LONGLONG * pLatest )
{
    HRESULT hr = S_OK;
    if (pEarliest != NULL) {
        *pEarliest = 0;
    }

    if (pLatest != NULL) {
        hr = GetDuration(pLatest);

        /*  If we're being driven with IAsyncReader just get the available byte
            count and extrapolate a guess from that
        */
        if (SUCCEEDED(hr)) {
            LONGLONG llTotal;
            LONGLONG llAvailable;
            HRESULT hr1 = m_pSplitter->m_InputPin.GetAvailable(&llTotal, &llAvailable);
            if (SUCCEEDED(hr1) && llTotal != llAvailable) {
                *pLatest = llMulDiv(llAvailable, *pLatest, llTotal, llTotal / 2);
                hr = VFW_S_ESTIMATED;
            }
        }
    }
    return hr;
}



#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\mpgsplit.cpp ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*

    File:  mpgsplit.cpp

    Description:

        Code for MPEG-I system stream splitter filter object CMpeg1Splitter

*/

#include <streams.h>
#include "driver.h"


#ifdef FILTER_DLL
/* List of class IDs and creator functions for the class factory. This
   provides the link between the OLE entry point in the DLL and an object
   being created. The class factory will call the static CreateInstance
   function when it is asked to create a CLSID_MPEG1Splitter object */

extern const AMOVIESETUP_FILTER sudMpgsplit;

CFactoryTemplate g_Templates[1] = {
    { L""
    , &CLSID_MPEG1Splitter
    , CMpeg1Splitter::CreateInstance
    , NULL
    , &sudMpgsplit }
};

int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);

STDAPI DllRegisterServer()
{
  return AMovieDllRegisterServer2( TRUE );
}

STDAPI DllUnregisterServer()
{
  return AMovieDllRegisterServer2( FALSE );
}
#endif


/* This goes in the factory template table to create new instances */

CUnknown *CMpeg1Splitter::CreateInstance(LPUNKNOWN pUnk, HRESULT *phr)
{
    CUnknown *pUnkRet = new CMpeg1Splitter(NAME("Mpeg-I stream splitter"), pUnk, phr);
    return pUnkRet;
}

#pragma warning(disable:4355)

/*  Constructor */

CMpeg1Splitter::CMpeg1Splitter(
    TCHAR    * pName,
    LPUNKNOWN  pUnk,
    HRESULT  * phr) :
    CUnknown(NAME("CMpeg1Splitter object"), pUnk, phr),
    m_Filter(this, phr),
    m_InputPin(this, phr),
    m_OutputPins(NAME("CMpeg1Splitter output pin list")),
    m_pParse(NULL),
    m_bAtEnd(FALSE)
{
}

/*  Destructor */

CMpeg1Splitter::~CMpeg1Splitter()
{
}

/* Override this to say what interfaces we support and where */

STDMETHODIMP
CMpeg1Splitter::NonDelegatingQueryInterface(REFIID riid,void ** ppv)
{

    if (riid == IID_IBaseFilter  ||
        riid == IID_IMediaFilter ||
        riid == IID_IPersist         ) {
        return m_Filter.NonDelegatingQueryInterface(riid,ppv);
    } else {
        /* Do we have this interface? */
        if (riid == IID_IAMStreamSelect) {
            return GetInterface((IAMStreamSelect *)this, ppv);
        } else if (riid == IID_IAMMediaContent) {
            return GetInterface((IAMMediaContent *)this, ppv);
        }
        return CUnknown::NonDelegatingQueryInterface(riid,ppv);
    }
}

/*  Tell the output pins there's more data */
void CMpeg1Splitter::SendOutput()
{
    POSITION pos = m_OutputPins.GetHeadPosition();
    while (pos) {
        COutputPin *pPin = m_OutputPins.GetNext(pos);
        if (pPin->IsConnected()) {
            pPin->SendAnyway();
        }
    }
}

/*  Remove our output pins when our input pin becomes disconnected */
void CMpeg1Splitter::RemoveOutputPins()
{
    for (;;) {
        COutputPin *pPin = m_OutputPins.RemoveHead();
        if (pPin == NULL) {
            return;
        }
        IPin *pPeer = pPin->GetConnected();
        if (pPeer != NULL) {
            pPeer->Disconnect();
            pPin->Disconnect();
        }
        pPin->Release();
    }
    m_Filter.IncrementPinVersion();
}

/*  Send EndOfStream */
void CMpeg1Splitter::EndOfStream()
{
    CAutoLock lck(&m_csReceive);
    ASSERT(m_pParse != NULL);
    m_pParse->EOS();
    POSITION pos = m_OutputPins.GetHeadPosition();
    while (pos) {
        COutputPin *pPin = m_OutputPins.GetNext(pos);
        if (pPin->IsConnected()) {
            DbgLog((LOG_TRACE, 3, TEXT("Calling EOS() for stream 0x%2.2X"),
                    pPin->m_uStreamId));
            pPin->m_pOutputQueue->EOS();
        }
    }
    m_bAtEnd = TRUE;
}

/*  Send BeginFlush() */
HRESULT CMpeg1Splitter::BeginFlush()
{
    CAutoLock lck(&m_csFilter);
    POSITION pos = m_OutputPins.GetHeadPosition();
    while (pos) {
        COutputPin *pPin = m_OutputPins.GetNext(pos);
        if (pPin->IsConnected()) {
            DbgLog((LOG_TRACE, 3, TEXT("Calling BeginFlush() for stream 0x%2.2X"),
                    pPin->m_uStreamId));
            pPin->m_pOutputQueue->BeginFlush();
        }
    }
    return S_OK;
}

/*  Send EndFlush() */
HRESULT CMpeg1Splitter::EndFlush()
{
    CAutoLock lck(&m_csFilter);
    POSITION pos = m_OutputPins.GetHeadPosition();
    while (pos) {
        COutputPin *pPin = m_OutputPins.GetNext(pos);
        if (pPin->IsConnected()) {
            DbgLog((LOG_TRACE, 3, TEXT("Calling EndFlush() for stream 0x%2.2X"),
                    pPin->m_uStreamId));
            pPin->m_pOutputQueue->EndFlush();
        }
    }
    m_bAtEnd = FALSE;
    return S_OK;
}

/* Check if a stream is stuck - filter locked on entry

   Returns S_OK           if no stream is stuck
           VFW_S_CANT_CUE if a stream is stuck

   A stream is stuck if:

         We haven't sent EndOfStream for it (!m_bAtEnd)
     AND We have exhausted our own allocator (IsBlocked())
     AND The output queue has pass all its data downstream and is not
         blocked waiting for the data to be processed (IsIdle())

   A single stream can't get stuck because if all its data has been
   processed the allocator will have free buffers
*/
HRESULT CMpeg1Splitter::CheckState()
{
    if (m_OutputPins.GetCount() <= 1) {
        /*  Can't stick on one pin */
        return S_OK;
    }

    /*  See if a pin is stuck and we've got lots of data outstanding */
    if (!m_bAtEnd && m_InputPin.Allocator()->IsBlocked()) {

        /*  Check to see if any of the streams have completed their
            data
        */
        POSITION pos = m_OutputPins.GetHeadPosition();
        while (pos) {
            COutputQueue *pQueue = m_OutputPins.GetNext(pos)->m_pOutputQueue;
            if (pQueue != NULL && pQueue->IsIdle()) {
                DbgLog((LOG_TRACE, 1, TEXT("Failed Pause!")));
                return VFW_S_CANT_CUE;
            }
        }
    }
    return S_OK;
}

/*  Implement IAMStreamSelect */

//  Returns total count of streams
STDMETHODIMP CMpeg1Splitter::Count(
    /*[out]*/ DWORD *pcStreams)       // Count of logical streams
{
    CAutoLock lck(&m_csFilter);
    *pcStreams = 0;
    if (m_pParse != NULL) {
        for (int i = 0; m_pParse->GetStreamId(i) != 0xFF; i++) {
        }
        *pcStreams = i;
    }
    return S_OK;
}

//  Return info for a given stream - S_FALSE if iIndex out of range
//  The first steam in each group is the default
STDMETHODIMP CMpeg1Splitter::Info(
    /*[in]*/ long iIndex,              // 0-based index
    /*[out]*/ AM_MEDIA_TYPE **ppmt,   // Media type - optional
                                      // Use DeleteMediaType to free
    /*[out]*/ DWORD *pdwFlags,        // flags - optional
    /*[out]*/ LCID *plcid,            // Language id
    /*[out]*/ DWORD *pdwGroup,        // Logical group - 0-based index - optional
    /*[out]*/ WCHAR **ppszName,       // Name - optional - free with CoTaskMemFree
                                      // Can return NULL
    /*[out]*/ IUnknown **ppPin,       // Pin if any
    /*[out]*/ IUnknown **ppUnk)       // Stream specific interface
{
    CAutoLock lck(&m_csFilter);
    UCHAR uId = m_pParse->GetStreamId(iIndex);
    if (uId == 0xFF) {
        return S_FALSE;
    }
    /*  Find the stream corresponding to this one that has a pin */
    COutputPin *pPin = NULL;
    POSITION pos = m_OutputPins.GetHeadPosition();
    while (pos) {
        pPin = m_OutputPins.GetNext(pos);
        if (IsVideoStreamId(pPin->m_uStreamId) == IsVideoStreamId(uId)) {
            break;
        }
    }
    if (ppszName) {
        WCHAR wszStreamName[20];
        wsprintfW(wszStreamName, L"Stream(%2.2X)", uId);
        if (S_OK != AMGetWideString(wszStreamName, ppszName)) {
            return E_OUTOFMEMORY;
        }
    }
    /* pPin cannot be NULL because each output pin corresponds to a MPEG stream. */
    ASSERT(pPin != NULL);
    if (pdwFlags) {
        *pdwFlags = uId == pPin->m_Stream->m_uNextStreamId ? AMSTREAMSELECTINFO_ENABLED : 0;
    }
    if (ppUnk) {
        *ppUnk = NULL;
    }
    if (pdwGroup) {
        *pdwGroup = IsVideoStreamId(pPin->m_uStreamId) ? 0 : 1;
    }
    if (ppmt) {
        *ppmt = CreateMediaType(pPin->MediaType());
        if (*ppmt == NULL) {
            if (ppszName) {
                CoTaskMemFree((LPVOID)*ppszName);
            }
            return E_OUTOFMEMORY;
        }
    }
    if (plcid) {
        *plcid = 0;
    }
    if (ppPin) {
        pPin->QueryInterface(IID_IUnknown, (void**)ppPin);
    }
    return S_OK;
}

//  Enable or disable a given stream
STDMETHODIMP CMpeg1Splitter::Enable(
    /*[in]*/  long iIndex,
    /*[in]*/  DWORD dwFlags)
{
    if (!(dwFlags & AMSTREAMSELECTENABLE_ENABLE)) {
        return E_NOTIMPL;
    }

    CAutoLock lck(&m_csFilter);
    /*  Find the pin from the index */
    /*  Find the stream corresponding to this one that has a pin */
    UCHAR uId = m_pParse->GetStreamId(iIndex);
    if (uId == 0xFF) {
        return E_INVALIDARG;
    }
    COutputPin *pPin = NULL;
    POSITION pos = m_OutputPins.GetHeadPosition();
    while (pos) {
        pPin = m_OutputPins.GetNext(pos);
        if (IsVideoStreamId(pPin->m_uStreamId) == IsVideoStreamId(uId)) {
            break;
        }
    }
    /* pPin cannot be NULL because each output pin corresponds to a MPEG stream. */
    ASSERT(pPin != NULL);
    pPin->m_Stream->m_uNextStreamId = uId;
    return S_OK;
}

/*  IAMMediaContent */
STDMETHODIMP CMpeg1Splitter::get_AuthorName(BSTR FAR* strAuthorName)
{
    HRESULT hr = GetContentString(CBasicParse::Author, strAuthorName);
    if (FAILED(hr)) {
        hr = GetContentString(CBasicParse::Artist, strAuthorName);
    }
    return hr;
}
STDMETHODIMP CMpeg1Splitter::get_Title(BSTR FAR* strTitle)
{
    return GetContentString(CBasicParse::Title, strTitle);
}
STDMETHODIMP CMpeg1Splitter::get_Copyright(BSTR FAR* strCopyright)
{
    return GetContentString(CBasicParse::Copyright, strCopyright);
}
STDMETHODIMP CMpeg1Splitter::get_Description(BSTR FAR* strDescription)
{
    return GetContentString(CBasicParse::Description, strDescription);
}

/*  Grab the string from the ID3 frame and make a BSTR */
HRESULT CMpeg1Splitter::GetContentString(CBasicParse::Field dwId, BSTR *str)
{
    if (m_pParse->HasMediaContent()) {
        return m_pParse->GetContentField(dwId, str);
    }  else {
        return E_NOTIMPL;
    }
}

#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\mpgsplit\outpin.cpp ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*

     Output pin members for CMpeg1Splitter::COutputPin

     The pin is created with the (fixed) media type
*/

#include <streams.h>
#include <stdio.h>            // For swprintf
#include "driver.h"

#pragma warning(disable:4355)

/*  Constructor - we know the media type when we create the pin */

CMpeg1Splitter::COutputPin::COutputPin(
            CMpeg1Splitter * pSplitter,
            UCHAR            StreamId,
            CBasicStream   * pStream,
            HRESULT        * phr) :
    CBaseOutputPin(NAME("CMpeg1Splitter::COutputPin"),   // Object name
                   &pSplitter->m_Filter,                 // Filter
                   &pSplitter->m_csFilter,               // CCritsec *
                   phr,
                   IsAudioStreamId(StreamId) ? L"Audio" : L"Video"),
    m_Seeking(pSplitter, this, GetOwner(), phr),
    m_pOutputQueue(NULL),
    m_pSplitter(pSplitter),
    m_uStreamId(StreamId),
    m_Stream(pStream),
    m_bPayloadOnly(FALSE)
{
    DbgLog((LOG_TRACE, 2, TEXT("CMpeg1Splitter::COutputPin::COutputPin - stream id 0x%2.2X"),
           StreamId));
}

/*  Destructor */

CMpeg1Splitter::COutputPin::~COutputPin()
{
    DbgLog((LOG_TRACE, 2, TEXT("CMpeg1Splitter::COutputPin::~COutputPin - stream id 0x%2.2X"),
           m_uStreamId));

    /*  We only get deleted when we're disconnected so
        we should be inactive with no thread etc etc
    */
    ASSERT(m_pOutputQueue == NULL);
}

// override say what interfaces we support where
STDMETHODIMP CMpeg1Splitter::COutputPin::NonDelegatingQueryInterface(
    REFIID riid,
    void ** ppv)
{
    /* See if we have the interface */

    if (riid == IID_IStream) {
        return GetInterface((IStream *)this, ppv);
    } else if (riid == IID_IMediaSeeking) {
        if (m_pSplitter->m_pParse->IsSeekable()) {
            return GetInterface ((IMediaSeeking *)&m_Seeking, ppv);
        }
    }
    return CBaseOutputPin::NonDelegatingQueryInterface(riid, ppv);
}

/* Override revert to normal ref counting
   These pins cannot be finally Release()'d while the input pin is
   connected */

STDMETHODIMP_(ULONG)
CMpeg1Splitter::COutputPin::NonDelegatingAddRef()
{
    return CUnknown::NonDelegatingAddRef();
}


/* Override to decrement the owning filter's reference count */

STDMETHODIMP_(ULONG)
CMpeg1Splitter::COutputPin::NonDelegatingRelease()
{
    return CUnknown::NonDelegatingRelease();
}




HRESULT CMpeg1Splitter::COutputPin::GetMediaType(int iPosition, CMediaType *pMediaType)
{
    CAutoLock lck(m_pLock);
    if (iPosition < 0)  {
        return E_INVALIDARG;
    }
    return m_Stream->GetMediaType(pMediaType, iPosition);
}

HRESULT CMpeg1Splitter::COutputPin::CheckMediaType(const CMediaType *pmt)
{
    CAutoLock lck(m_pLock);
    for (int i = 0;; i++) {
        CMediaType mt;
        HRESULT hr = GetMediaType(i, &mt);
        if (FAILED(hr)) {
            return hr;
        }
        if (hr==VFW_S_NO_MORE_ITEMS) {
            break;
        }
        if (*pmt == mt) {
            return S_OK;
        }
    }
    return S_FALSE;
}

HRESULT CMpeg1Splitter::COutputPin::SetMediaType(const CMediaType *mt)
{
    HRESULT hr = CBaseOutputPin::SetMediaType(mt);
    if (S_OK != hr) {
        return hr;
    }

    if (mt->subtype != MEDIASUBTYPE_MPEG1Packet) {
        m_bPayloadOnly = TRUE;
    } else {
        m_bPayloadOnly = FALSE;
    }
    m_Stream->SetMediaType(mt, m_bPayloadOnly);


    return S_OK;
}

HRESULT CMpeg1Splitter::COutputPin::BreakConnect()
{
    CBaseOutputPin::BreakConnect();
    return S_OK;
}

// override this to set the buffer size and count. Return an error
// if the size/count is not to your liking.
HRESULT CMpeg1Splitter::COutputPin::DecideBufferSize(
    IMemAllocator * pAlloc,
    ALLOCATOR_PROPERTIES * pProp
    )
{
    pProp->cBuffers = 100;
    pProp->cbBuffer = MAX_MPEG_PACKET_SIZE;            /* Don't care about size */
    pProp->cbAlign = 1;
    pProp->cbPrefix = 0;
    ALLOCATOR_PROPERTIES propActual;
    return pAlloc->SetProperties(pProp, &propActual);
}

//
//  Override DecideAllocator because we insist on our own allocator since
//  it's 0 cost in terms of bytes
//
HRESULT CMpeg1Splitter::COutputPin::DecideAllocator(IMemInputPin *pPin,
                                                    IMemAllocator **ppAlloc)
{
    HRESULT hr = InitAllocator(ppAlloc);
    if (SUCCEEDED(hr)) {
        ALLOCATOR_PROPERTIES propRequest;
        ZeroMemory(&propRequest, sizeof(propRequest));
        hr = DecideBufferSize(*ppAlloc, &propRequest);
        if (SUCCEEDED(hr)) {
            // tell downstream pins that modification
            // in-place is not permitted
            hr = pPin->NotifyAllocator(*ppAlloc, TRUE);
            if (SUCCEEDED(hr)) {
                return NOERROR;
            }
        }
    }

    /* Likewise we may not have an interface to release */

    if (*ppAlloc) {
        (*ppAlloc)->Release();
        *ppAlloc = NULL;
    }
    return hr;
}

// override this to control the connection
// We use the subsample allocator derived from the input pin's allocator
HRESULT CMpeg1Splitter::COutputPin::InitAllocator(IMemAllocator **ppAlloc)
{
    ASSERT(m_pAllocator == NULL);
    HRESULT hr = NOERROR;
    *ppAlloc = NULL;
    COutputAllocator *pMemObject = NULL;
    IMemAllocator *pInputAllocator;
    hr = m_pSplitter->m_InputPin.GetAllocator(&pInputAllocator);
    if (FAILED(hr)) {
        return hr;
    }

    pMemObject = new COutputAllocator((CStreamAllocator *)pInputAllocator, &hr);
    pInputAllocator->Release();
    if (pMemObject == NULL) {
        return E_OUTOFMEMORY;
    }

    if (FAILED(hr)) {
        delete pMemObject;
        return hr;
    }
    /* Get a reference counted IID_IMemAllocator interface */

    hr = pMemObject->QueryInterface(IID_IMemAllocator,(void **)ppAlloc);
    if (FAILED(hr)) {
        delete pMemObject;
        return hr;
    }
    ASSERT(*ppAlloc != NULL);
    return NOERROR;
}


// Queue a sample to the outside world
//
// This involves allocating the sample from the pin's allocator
// (NOTE - this will ONLY involve queuing on the output pin if
// we're stretching file window too much).
//
HRESULT CMpeg1Splitter::COutputPin::QueuePacket(PBYTE         pPacket,
                                                LONG          lPacket,
                                                REFERENCE_TIME tSample,
                                                BOOL          bTimeValid)
{
    CAutoLock lck(this);
    if (!IsConnected()) {
        return S_OK;
    }
    COutputAllocator *pAllocator = (COutputAllocator *)m_pAllocator;
    IMediaSample *pSample;
    if (m_pOutputQueue == NULL) {
        return E_UNEXPECTED;
    }

    HRESULT hr = pAllocator->GetSample(pPacket, lPacket, &pSample);
    if (FAILED(hr)) {
        DbgLog((LOG_ERROR, 2, TEXT("Could not get sample - code 0x%8.8X"),
                hr));
        return hr;
    }

    if (bTimeValid) {
        REFERENCE_TIME tStop = tSample + 1;
        EXECUTE_ASSERT(SUCCEEDED(pSample->SetSyncPoint(bTimeValid)));
        EXECUTE_ASSERT(SUCCEEDED(pSample->SetTime(
                (REFERENCE_TIME*)&tSample,
                (REFERENCE_TIME*)&tStop)));
        DbgLog((LOG_TRACE, 4, TEXT("Sending sample for stream %2.2X time %s"),
                m_uStreamId,
                (LPCTSTR)CDisp(CRefTime(tSample))));
    } else {
        DbgLog((LOG_TRACE, 4,
                TEXT("Sending sample for stream %2.2X - no time"),
                m_uStreamId));
    }
    if (m_Stream->GetDiscontinuity()) {
        EXECUTE_ASSERT(SUCCEEDED(pSample->SetDiscontinuity(TRUE)));
        DbgLog((LOG_TRACE, 2, TEXT("NewSegment(%s, %s, %s)"),
                (LPCTSTR)CDisp(CRefTime(m_pSplitter->m_pParse->GetStartTime())),
                (LPCTSTR)CDisp(CRefTime(m_pSplitter->m_pParse->GetStopTime())),
                (LPCTSTR)CDisp(m_pSplitter->m_pParse->GetRate())
                ));
        m_pOutputQueue->NewSegment(m_pSplitter->m_pParse->GetStartTime(),
                                   m_pSplitter->m_pParse->GetStopTime(),
                                   m_pSplitter->m_pParse->GetRate());
    }
    LONGLONG llPosition;
    if (m_pSplitter->m_pParse->GetMediumPosition(&llPosition)) {
        LONGLONG llStop = llPosition + lPacket;
        pSample->SetMediaTime(&llPosition, &llStop);
    }
    return m_pOutputQueue->Receive(pSample);
}


/*  Active and inactive methods */

/*  Active

    Create the worker thread
*/
HRESULT CMpeg1Splitter::COutputPin::Active()
{
    DbgLog((LOG_TRACE, 2, TEXT("COutputPin::Active()")));
    CAutoLock lck(m_pLock);
    CAutoLock lck1(this);

    /*  If we're not connected we don't participate so it's OK */
    if (!IsConnected()) {
        return S_OK;
    }

    HRESULT hr = CBaseOutputPin::Active();
    if (FAILED(hr)) {
        return hr;
    }

    /*  Create our batch list */
    ASSERT(m_pOutputQueue == NULL);

    hr = S_OK;
    m_pOutputQueue = new COutputQueue(GetConnected(), // input pin
                                      &hr,            // return code
                                      TRUE,           // Auto detect
                                      TRUE,           // ignored
                                      50,             // batch size
                                      TRUE,           // exact batch
                                      50);            // queue size
    if (m_pOutputQueue == NULL) {
        return E_OUTOFMEMORY;
    }
    if (FAILED(hr)) {
        delete m_pOutputQueue;
        m_pOutputQueue = NULL;
    }
    return hr;
}

HRESULT CMpeg1Splitter::COutputPin::Inactive()
{
    DbgLog((LOG_TRACE, 2, TEXT("COutputPin::Inactive()")));
    CAutoLock lck(m_pLock);

    /*  If we're not involved just return */
    if (!IsConnected()) {
        return S_OK;
    }

    CAutoLock lck1(this);
    HRESULT hr = CBaseOutputPin::Inactive(); /* Calls Decommit - why? */
    if (FAILED(hr)) {
        /*  Incorrect state transition */
        return hr;
    }

    delete m_pOutputQueue;
    m_pOutputQueue = NULL;
    return S_OK;
}

//  Return TRUE if we're the pin being used for seeking
//  If there's a connected video pin we use that - otherwise we
//  just choose the first in the list
BOOL CMpeg1Splitter::COutputPin::IsSeekingPin()
{
    if (IsVideoStreamId(m_uStreamId)) {
        // We're connected or we wouldn't be here(!)
        ASSERT(IsConnected());
        return TRUE;
    }
    //  See if we're the first pin and there's no
    //  video stream
    POSITION pos = m_pSplitter->m_OutputPins.GetHeadPosition();
    BOOL bGotFirst = FALSE;
    for (;;) {
        COutputPin *pPin;
        pPin = m_pSplitter->m_OutputPins.GetNext(pos);
        if (pPin == NULL) {
            break;
        }

        if (pPin->IsConnected()) {
            if (!bGotFirst) {
                if (this != pPin) {
                    return FALSE;
                }
                bGotFirst = TRUE;
            }

            //  We're not the seeking pin if there's a connected
            //  video pin
            if (IsVideoStreamId(pPin->m_uStreamId)) {
                return FALSE;
            }
        }
    }
    ASSERT(bGotFirst);
    return TRUE;
}
#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\coverlay.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*

    Methods for COverlayOutputPin

    We need to verify the existence of IOverlay on the pin
    we're connecting to.

    When we're connected we need to register calls for callbacks
    from COverlayOutputPin - so don't we need to be called for
    'connected' too?

*/

#include <streams.h>
#include "driver.h"

/*
    COverlayOutputPin constructor
*/
COverlayOutputPin::COverlayOutputPin(
    TCHAR              * pObjectName,
    CMpeg1PacketFilter * pFilter,
    CCritSec           * pLock,
    LPUNKNOWN            pUnk,
    HRESULT            * phr,
    LPCWSTR              pPinName) :

    CBaseOutputPin(pObjectName, pFilter, pLock, phr, pPinName),
    m_OverlayNotify(NAME("Overlay notification interface"), pFilter, pUnk, phr),
    m_pPosition(NULL),
    m_bAdvise(FALSE),
    m_pOverlay(NULL),
    m_pFilter(pFilter)
{
}

COverlayOutputPin::~COverlayOutputPin()
{
    delete m_pPosition;
};


// overriden to expose IMediaPosition and IMediaSeeking control interfaces

STDMETHODIMP
COverlayOutputPin::NonDelegatingQueryInterface(REFIID riid,
                                               void **ppv)
{
    *ppv = NULL;

    if (riid == IID_IMediaPosition || riid == IID_IMediaSeeking) {
        if (m_pPosition == NULL) {

            HRESULT hr = S_OK;
            m_pPosition = new CPosPassThru(NAME("Mpeg Overlay CPosPassThru"),
                                           GetOwner(),
                                           &hr,
                                           m_pFilter->m_VideoInputPin);
            if (m_pPosition == NULL) {
                return E_OUTOFMEMORY;
            }

            if (FAILED(hr)) {
                delete m_pPosition;
                m_pPosition = NULL;
                return hr;
            }
        }
        return m_pPosition->NonDelegatingQueryInterface(riid, ppv);
    } else {
        return CBaseOutputPin::NonDelegatingQueryInterface(riid, ppv);
    }
}


/*
    Say if we're prepared to connect to a given input pin from
    this output pin
*/
STDMETHODIMP COverlayOutputPin::Connect(
        IPin *pReceivePin,
        const AM_MEDIA_TYPE* pmt
        )
{
    /*  Call the base class to make sure the directions match! */
    HRESULT hr = CBaseOutputPin::Connect(pReceivePin, pmt);
    if (FAILED(hr)) {
        return hr;
    }
    /*  We're happy if we can get an IOverlay interface */

    hr = pReceivePin->QueryInterface(IID_IOverlay,
                                     (void **)&m_pOverlay);

    if (FAILED(hr)) {
        Disconnect();
        return hr;
    }

    /*  If we're a chromakey overlay set the key now
    */
    COLORREF rgbColor;
    COLORREF rgbMask;

    if (S_OK == m_pFilter->GetDevice()->GetChromaKey(&rgbColor, &rgbMask)) {
        COLORKEY ColorKey;
        ColorKey.LowColorValue = rgbColor & rgbMask;
        ColorKey.HighColorValue = rgbColor | ~rgbMask;
        ColorKey.KeyType = CK_RGB;
        m_pOverlay->SetColorKey(&ColorKey);
    }

    /*  Because we're not going to get called again - except to
        propose a media type - we set up a callback here.

        There's only one output pin so we don't need any context.
    */

    hr = m_pOverlay->Advise(&m_OverlayNotify,ADVISE_CLIPPING);

    /*
        We don't need to hold on to the IOverlay pointer
        because BreakConnect will be called before the receiving
        pin goes away.
    */


    if (FAILED(hr)) {
        /*  Don't need to free anything because the base class is going
            to call BreakConnect() next if we fail
        */
        Disconnect();
        return hr;
    } else {
        m_bAdvise = TRUE;
    }

    /*  Holding the MPEG device open will be synchronous with being
        connected to the renderer
    */
    hr = m_pFilter->GetDevice()->Open();

    if (FAILED(hr)) {
        Disconnect();
    }
    return hr;
}
// Activation - not allowed if no output device
HRESULT COverlayOutputPin::Active()
{
    if (m_pFilter->GetDevice()->IsOpen()) {
        return S_OK;
    } else {
        return E_FAIL;
    }
}

HRESULT COverlayOutputPin::Inactive()
{
    return S_OK;
}


/*  We override this so we can do nothing because we don't use an
    allocator since we have no data as an overlay device
*/
HRESULT COverlayOutputPin::DecideBufferSize(
    IMemAllocator * pAlloc,
    ALLOCATOR_PROPERTIES * pProp)
{
    return S_OK;
}

HRESULT COverlayOutputPin::BreakConnect()
{
    if (m_pPosition != NULL) {
        m_pPosition->ForceRefresh();
    }
    /*  This is when we close our device */
    m_pFilter->GetDevice()->Close();

    if (m_pOverlay != NULL) {
        if (m_bAdvise) {
            m_pOverlay->Unadvise();
            m_bAdvise = FALSE;
        }
        m_pOverlay->Release();
        m_pOverlay = NULL;
    }

    return CBaseOutputPin::BreakConnect();
}


/*
    ProposeMediaType - we really don't want to propose anything -
    we only care if the receive pin supports IOverlay
*/


HRESULT COverlayOutputPin::GetMediaType(int iPosition, CMediaType *pmt)
{
    if (iPosition <0) {
        return E_INVALIDARG;
    }
    if (iPosition >0) {
        return VFW_S_NO_MORE_ITEMS;
    }

    //  Can't do this if our input pin isn't connected
    RECT rcSrc;
    HRESULT hr;
    hr = m_pFilter->GetDevice()->GetSourceRectangle(&rcSrc);
    if (FAILED(hr)) {
        return hr;
    }

    // We set the BITMAPINFOHEADER to be a really basic eight bit palettised
    // format so that the video renderer will always accept it. We have to
    // provide a valid media type as source filters can swap between the
    // IMemInputPin and IOverlay transports as and when they feel like it

    VIDEOINFO Format;
    ZeroMemory(&Format, sizeof(Format));
    Format.bmiHeader.biWidth  = rcSrc.right - rcSrc.left;
    Format.bmiHeader.biHeight = rcSrc.bottom - rcSrc.top;
    Format.bmiHeader.biSize   = sizeof(BITMAPINFOHEADER);
    Format.bmiHeader.biPlanes = 1;
    Format.bmiHeader.biBitCount = 8;
    Format.bmiHeader.biSize = sizeof(BITMAPINFOHEADER);

    // Hack - use bitmapinfoheader for now!
    pmt->SetFormat((PBYTE)&Format, sizeof(Format));
    pmt->SetFormatType(&FORMAT_VideoInfo);

    if (pmt->pbFormat == NULL) {
        return E_OUTOFMEMORY;
    }

    pmt->majortype = MEDIATYPE_Video;
    pmt->subtype   = MEDIASUBTYPE_Overlay;
    pmt->bFixedSizeSamples    = FALSE;
    pmt->bTemporalCompression = FALSE;
    pmt->lSampleSize          = 0;
    return S_OK;
}

/*
    CheckMediaType - what media types are acceptable?

    We don't care - we just rely on the existence of the IOverlay
    interface on the input pin
*/

HRESULT COverlayOutputPin::CheckMediaType(const CMediaType *pmt)
{
    return S_OK;
}

HRESULT COverlayOutputPin::SetMediaType(const CMediaType *pmt)
{
    return S_OK;
}

/*
    Deliver a sample

    We don't ever expect to be called to do this.
*/
HRESULT COverlayOutputPin::Deliver(IMediaSample *)
{
    return E_UNEXPECTED;
}

// Override this because we don't want any allocator!
HRESULT COverlayOutputPin::DecideAllocator(IMemInputPin * pPin,
                        IMemAllocator ** pAlloc) {
    /*  We just don't want one so everything's OK as it is */
    return S_OK;
}

/*
        IOverlayNotify
*/

COverlayNotify::COverlayNotify(TCHAR              * pName,
                               CMpeg1PacketFilter * pFilter,
                               LPUNKNOWN            pUnk,
                               HRESULT            * phr) :
    CUnknown(pName, pUnk)
{
   m_pFilter = pFilter;
}

COverlayNotify::~COverlayNotify() {};

STDMETHODIMP COverlayNotify::NonDelegatingQueryInterface(REFIID riid,
                                                         void ** ppv)
{
    /* Do we have this interface */

    if (riid == IID_IOverlayNotify) {
        return GetInterface((LPUNKNOWN) (IOverlayNotify *) this, ppv);
    } else {
        return CUnknown::NonDelegatingQueryInterface(riid, ppv);
    }
}
STDMETHODIMP_(ULONG) COverlayNotify::NonDelegatingRelease()
{
    return m_pFilter->Release();
}
STDMETHODIMP_(ULONG) COverlayNotify::NonDelegatingAddRef()
{
    return m_pFilter->AddRef();
}

STDMETHODIMP COverlayNotify::OnColorKeyChange(
    const COLORKEY *pColorKey)          // Defines new colour key
{
    // If we're a chromakey device the renderer should take care
    // of this for drawing - we just set up the device

    return m_pFilter->GetDevice()->SetChromaKey(
        (COLORREF)(pColorKey->LowColorValue & 0xFFFFFF),
        0xFFFFFFFF);
}

STDMETHODIMP COverlayNotify::OnClipChange(
    const RECT    * pSourceRect,         // Area of source video to use
    const RECT    * pDestinationRect,    // Area of source video to use
    const RGNDATA * pRegionData)         // Header describing clipping
{
    return m_pFilter->GetDevice()->SetOverlay(pSourceRect,
                                              pDestinationRect,
                                              pRegionData);
}

STDMETHODIMP COverlayNotify::OnPaletteChange(
    DWORD dwColors,                     // Number of colours present
    const PALETTEENTRY *pPalette)       // Array of palette colours
{
    return S_OK;
}


/* The calls to OnClipChange happen in sync with the window. So it's called
   with an empty clip list before the window moves to freeze the video, and
   then when the window has stabilised it is called again with the new clip
   list. The OnPositionChange callback is for overlay cards that don't want
   the expense of synchronous clipping updates and just want to know when
   the source or destination video positions change. They will NOT be called
   in sync with the window but at some point after the window has changed
   (basicly in time with WM_SIZE etc messages received). This is therefore
   suitable for overlay cards that don't inlay to the display frame buffer */

STDMETHODIMP COverlayNotify::OnPositionChange(
    const RECT *pSourceRect,            // Area of video to play with
    const RECT *pDestinationRect)       // Area video goes
{
    DbgLog((LOG_TRACE,1,TEXT("COverlayNotify::OnPositionChange")));
    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\coverlay.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

class COverlayNotify : public CUnknown, public IOverlayNotify
{
    public:
        /* Constructor and destructor */
        COverlayNotify(TCHAR              *pName,
                       CMpeg1PacketFilter *pFilter,
                       LPUNKNOWN           pUnk,
                       HRESULT            *phr);
        ~COverlayNotify();

        /* Unknown methods */

        DECLARE_IUNKNOWN

        STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** ppv);
        STDMETHODIMP_(ULONG) NonDelegatingRelease();
        STDMETHODIMP_(ULONG) NonDelegatingAddRef();

        /* IOverlayNotify methods */

        STDMETHODIMP OnColorKeyChange(const COLORKEY *pColorKey);

        STDMETHODIMP OnClipChange(
            const RECT *pSourceRect,            // Area of video to play
            const RECT *pDestinationRect,       // Area of video to play
            const RGNDATA *pRegionData);        // Header describing clipping

        STDMETHODIMP OnPaletteChange(
            DWORD dwColors,                     // Number of colours present
            const PALETTEENTRY *pPalette);      // Array of palette colours

        STDMETHODIMP OnPositionChange(
            const RECT *pSourceRect,            // Area of video to play with
            const RECT *pDestinationRect);      // Area video goes

    private:
        CMpeg1PacketFilter *m_pFilter;
} ;

class COverlayOutputPin : public CBaseOutputPin
{
    public:
        // override to expose IMediaPosition
        STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void **ppv);

        /*  Pin methods
        */

        //  Override connect so we can do more work if it works
        STDMETHODIMP Connect(IPin * pReceivePin, const AM_MEDIA_TYPE*pmt);

        // Activation - not allowed if no output device
        HRESULT Active();
        HRESULT Inactive();

        // return default media type & format
        HRESULT GetMediaType(int iPosition, CMediaType *);

        // check if the pin can support this specific proposed type&format
        HRESULT CheckMediaType(const CMediaType *);

        // Set this specific proposed type&format
        HRESULT SetMediaType(const CMediaType *);

        // undo any work done in CheckConnect.
        HRESULT BreakConnect();

        // Override this because we don't want any allocator!
        HRESULT DecideAllocator(IMemInputPin * pPin,
                                IMemAllocator ** pAlloc);


        // override this to set the buffer size and count. Return an error
        // if the size/count is not to your liking
        // Why do we have to implement this?

        HRESULT DecideBufferSize(IMemAllocator * pAlloc,
                                 ALLOCATOR_PROPERTIES * pProp);

        HRESULT COverlayOutputPin::Deliver(IMediaSample *);

        // Override to handle quality messages
        STDMETHODIMP Notify(IBaseFilter * pSender, Quality q)
        {    return E_NOTIMPL;             // We do NOT handle this
        }


        /*  Constructor and Destructor
        */
        COverlayOutputPin(
            TCHAR              * pObjectName,
            CMpeg1PacketFilter * pFilter,
            CCritSec           * pLock,
            LPUNKNOWN            pUnk,
            HRESULT            * phr,
            LPCWSTR              pPinName);

        ~COverlayOutputPin();

    /*  Private members */

    private:

        /*  Position control */
        CPosPassThru * m_pPosition;

        /*  Controlling filter */
        CMpeg1PacketFilter *m_pFilter;

        /*  Overlay window on output pin */
        IOverlay     * m_pOverlay;

        /*  Notify object */
        COverlayNotify m_OverlayNotify;

        /*  Do we have an active advise link */
        BOOL           m_bAdvise;
} ;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\device.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

#include <streams.h>
#include "driver.h"
#include "fill.h"

/*
    Translate a return code from the MPEG API into an HRESULT
*/

HRESULT CMpegDevice::MpegStatusToHResult( MPEG_STATUS Status )
{
    switch (Status) {
        case MpegStatusSuccess:
            return S_OK;

        case MpegStatusPending:
            return MAKE_HRESULT(SEVERITY_SUCCESS,
                                FACILITY_NULL,
                                ERROR_IO_PENDING);

        case MpegStatusCancelled:
            return E_FAIL;

        case MpegStatusNoMore:

            /* This is returned by the API when device enumeration
               has got to the end of the list

               We therefore don't expect to get it.
            */

            ASSERT(FALSE);
            return E_UNEXPECTED;


        case MpegStatusBusy:
            return MAKE_HRESULT(SEVERITY_ERROR,
                                FACILITY_NULL,
                                ERROR_BUSY);

        case MpegStatusUnsupported:
            return E_NOTIMPL;

        case MpegStatusInvalidParameter:
            return E_INVALIDARG;

        case MpegStatusHardwareFailure:
            return E_FAIL;

        default:
            ASSERT(FALSE);
            return E_UNEXPECTED;
    }
}

/*  Constructor */
CMpegDevice::CMpegDevice() : m_Handle(NULL),// use default constructor for
                                            // packet list
                             m_PseudoHandle(NULL)
{
    /*  Find our device - we need this for querying attributes etc
        and this will anyway tell us if there's likely to be
        a device
    */

    /* get description of driver */

    m_szDriverPresent[0] = '\0';
    MPEG_STATUS Status =
        MpegEnumDevices(0,
                        m_szDriverPresent,
                        sizeof(m_szDriverPresent),
                        &m_dwID,
                        &m_PseudoHandle);
    if (Status != MpegStatusSuccess) {
       DbgLog((LOG_ERROR,1,TEXT("Failed to find device - status 0x%8.8X"), Status));
    }

    DbgLog((LOG_TRACE,1,TEXT("Found device %hs, id 0x%8X"), m_szDriverPresent, m_dwID));

    /*  Pull out the caps */

    for (int eCapability = MpegCapAudioDevice;
             eCapability < MpegCapMaximumCapability;
             eCapability++) {
        m_Capability[eCapability] = (MpegStatusSuccess ==
                                     MpegQueryDeviceCapabilities(
                                         m_PseudoHandle,
                                         (MPEG_CAPABILITY)eCapability));

        LPCTSTR str = m_Capability[eCapability] ? TEXT("Supports ") :
                                                  TEXT("Does not support ");
        switch (eCapability) {
            case MpegCapAudioDevice:
                DbgLog((LOG_TRACE,2,TEXT("%s Audio"), str));
                break;
            case MpegCapVideoDevice:
                DbgLog((LOG_TRACE,2,TEXT("%s Video"), str));
                break;
            case MpegCapSeparateStreams:
                DbgLog((LOG_TRACE,2,TEXT("%s Separate streams"), str));
                break;
            case MpegCapCombinedStreams:
                DbgLog((LOG_TRACE,2,TEXT("%s Combined streams"), str));
                break;
            case MpegCapBitmaskOverlay:
                DbgLog((LOG_TRACE,2,TEXT("%s Bitmask overlay"), str));
                break;
            case MpegCapChromaKeyOverlay:
                DbgLog((LOG_TRACE,2,TEXT("%s Chromakey overlay"), str));
                break;
            case MpegCapAudioRenderToMemory:
                DbgLog((LOG_TRACE,2,TEXT("%s Audio render to memory"), str));
                break;
            case MpegCapVideoRenderToMemory:
                DbgLog((LOG_TRACE,2,TEXT("%s Video render to memory"), str));
                break;
        }
    }
    SetRectEmpty(&m_rcSrc);
    ResetTimers();
}

CMpegDevice::~CMpegDevice() {}

HRESULT CMpegDevice::Close()
{
    CAutoLock lck(&m_CritSec);
    if (m_Handle == NULL) {
        return S_OK;
    }

    /*  There's not much we can do if this fails! */

    MPEG_STATUS Status = MpegCloseDevice(m_Handle);

    if (Status != MpegStatusSuccess) {
        DbgLog((LOG_ERROR,1,TEXT("Failed to close device - Handle = %8X, Mpeg Status = %d"),
            m_Handle,
            Status));
    } else {

        DbgLog((LOG_TRACE, 3, TEXT("Device Closed")));
    }

    m_Handle = NULL;

    return MpegStatusToHResult(Status);
}

BOOL CMpegDevice::IsOpen()
{
    return m_Handle != NULL;
}

HRESULT CMpegDevice::Open()
{
    CAutoLock lck(&m_CritSec);
    ASSERT(m_Handle == NULL);
    m_bRunning = FALSE;

    HRESULT hr = MpegStatusToHResult(MpegOpenDevice(m_dwID, &m_Handle));
    if (FAILED(hr)) {
       DbgLog((LOG_ERROR,1,TEXT("Failed to open device - status 0x%8.8X"), hr));
       m_Handle = NULL;
       return hr;
    } else {
       /*  Set up the source rectangle */
       SetSourceRectangle(&m_rcSrc);
    }

    DbgLog((LOG_TRACE,2,TEXT("Device Successfully opened")));

    return TRUE;
}

HRESULT CMpegDevice::Pause()
{
    CAutoLock lck(&m_CritSec);

    ASSERT(m_Handle != NULL);

    m_bRunning = FALSE;

    DbgLog((LOG_TRACE, 3, TEXT("Device Pause")));

    MPEG_STATUS Status = MpegPause(m_Handle, MpegAudioDevice);
    if (Status != MpegStatusSuccess) {
        DbgLog((LOG_ERROR,1,TEXT("Failed to pause audio - Handle = %8X, Mpeg Status = %d"),
            m_Handle,
            Status));
        return MpegStatusToHResult(Status);
    }

    Status = MpegPause(m_Handle, MpegVideoDevice);

    if (Status != MpegStatusSuccess) {
        DbgLog((LOG_ERROR,1,TEXT("Failed to pause video - Handle = %8X, Mpeg Status = %d"),
            m_Handle,
            Status));
    }

#ifdef DEBUG
    if (ThreadExists()) {
        SetEvent(GetRequestHandle());
        CAMThread::Close();
    }
#endif

    return MpegStatusToHResult(Status);
}

HRESULT CMpegDevice::Reset(MPEG_STREAM_TYPE StreamType)
{
    CAutoLock lck(&m_CritSec);

    DbgLog((LOG_TRACE, 3, TEXT("Device Reset")));

    ASSERT(m_Handle != NULL);

    MPEG_STATUS Status = MpegResetDevice(m_Handle, StreamType == MpegAudioStream ?
                                                MpegAudioDevice :
                                                MpegVideoDevice);
    if (StreamType == MpegAudioStream) {
        m_bAudioStartingSCRSet = FALSE;
    } else {
        m_bVideoStartingSCRSet = FALSE;
    }

    if (m_bRunning) {
        MpegPlay(m_Handle, StreamType == MpegAudioStream ? MpegAudioDevice :
                                                           MpegVideoDevice);
    }
    /*  If we were running set it back to running state */
    return Status == MpegStatusSuccess ? S_OK :
                                         MpegStatusToHResult(Status);
}

HRESULT CMpegDevice::Pause(MPEG_STREAM_TYPE StreamType)
{
    CAutoLock lck(&m_CritSec);

    ASSERT(m_Handle != NULL);

    MPEG_STATUS Status = MpegPause(m_Handle, StreamType == MpegAudioStream ?
                                                 MpegAudioDevice :
                                                 MpegVideoDevice);
    return Status == MpegStatusSuccess ? S_OK :
                                         MpegStatusToHResult(Status);
}

HRESULT CMpegDevice::Stop(MPEG_STREAM_TYPE StreamType)
{
    CAutoLock lck(&m_CritSec);

    ASSERT(m_Handle != NULL);

    MPEG_STATUS Status = MpegStop(m_Handle, StreamType == MpegAudioStream ?
                                                 MpegAudioDevice :
                                                 MpegVideoDevice);
    if (Status == MpegStatusHardwareFailure) {
        DbgLog((LOG_ERROR,1,TEXT("Failed to stop %s - Handle = %8X, Mpeg Status = %d"),
            StreamType == MpegAudioStream ? TEXT("Audio") : TEXT("Video"),
            m_Handle,
            Status));
        Reset(StreamType);
    }
    if (Status != MpegStatusSuccess) {
        DbgLog((LOG_ERROR,1,TEXT("Failed to stop %s - Handle = %8X, Mpeg Status = %d"),
            StreamType == MpegAudioStream ? TEXT("Audio") : TEXT("Video"),
            m_Handle,
            Status));
    }
    return Status == MpegStatusSuccess ? S_OK :
                                         MpegStatusToHResult(Status);
}

HRESULT CMpegDevice::Stop()
{
    CAutoLock lck(&m_CritSec);

    DbgLog((LOG_TRACE, 3, TEXT("Device Stop")));

    ASSERT(m_Handle != NULL);

    HRESULT hr1, hr2;

    m_bRunning = FALSE;

    hr1 = Stop(MpegAudioStream);

    hr2 = Stop(MpegVideoStream);

    if (FAILED(hr1)) {
        return hr1;
    } else {
        return hr2;
    }
}

#ifdef DEBUG
/*  Info wrapper */
DWORD CMpegDevice::QueryInfo(MPEG_DEVICE_TYPE Type, MPEG_INFO_ITEM Item)
{
    DWORD dwResult;
    return MpegQueryInfo(m_Handle, Type, Item, &dwResult) ==
           MpegStatusSuccess ? dwResult : 0;
}

/*  Device monitor thread */
DWORD CMpegDevice::ThreadProc()
{
    /*  Dump out the buffer sizes */
    DWORD dwAudioBufferSize;
    DWORD dwVideoBufferSize;
    for (;;) {
        DWORD dwRet = WaitForSingleObject(GetRequestHandle(), 1000);
        if (dwRet == WAIT_OBJECT_0) {
            return 0;
        }
        /*  Dump out MPEG info */
        DWORD dwBytesInUse;
        DWORD dwPacketBytesOutstanding;
        DWORD dwStarvationCount;

        DbgLog((LOG_TIMING, 2,
                TEXT("Audio %d bytes in use, %d outstanding, starvation count %d"),
                QueryInfo(MpegAudioDevice, MpegInfoDecoderBufferBytesInUse),
                QueryInfo(MpegAudioDevice, MpegInfoCurrentPacketBytesOutstanding),
                QueryInfo(MpegAudioDevice, MpegInfoStarvationCounter)));
        DbgLog((LOG_TIMING, 2,
                TEXT("Video %d bytes in use, %d outstanding, starvation count %d"),
                QueryInfo(MpegVideoDevice, MpegInfoDecoderBufferBytesInUse),
                QueryInfo(MpegVideoDevice, MpegInfoCurrentPacketBytesOutstanding),
                QueryInfo(MpegVideoDevice, MpegInfoStarvationCounter)));
    }
}
#endif
HRESULT CMpegDevice::Run(REFERENCE_TIME StreamTime)
{
    CAutoLock lck(&m_CritSec);
    ASSERT(m_Handle != NULL);

    /*  Set the STC! */
    /*  For now we'll just assume the stream time is a moderate number of
        years
    */

    /*  Try to set the STC */

    SetSTC(MpegAudioStream, (MPEG_SYSTEM_TIME)((StreamTime * 9) / 1000));
    SetSTC(MpegVideoStream, (MPEG_SYSTEM_TIME)((StreamTime * 9) / 1000));


    MPEG_STATUS Status = MpegPlay(m_Handle, MpegAudioDevice);
    if (Status != MpegStatusSuccess) {
        DbgLog((LOG_ERROR,1,TEXT("Failed to play audio device - Handle = %8X, Mpeg Status = %d"),
            m_Handle,
            Status));
        return MpegStatusToHResult(Status);
    }

    Status = MpegPlay(m_Handle, MpegVideoDevice);

    if (Status != MpegStatusSuccess) {
        DbgLog((LOG_ERROR,2,TEXT("Failed to play video - Handle = %8X, Mpeg Status = %d"),
            m_Handle,
            Status));
        MpegPause(m_Handle, MpegAudioDevice);
    }

#ifdef DEBUG
    else {
        if (DbgCheckModuleLevel(LOG_TIMING, 2)) {
            Create();
        }
    }
#endif

    if (Status == MpegStatusSuccess) {
        m_bRunning = TRUE;
    }

    return MpegStatusToHResult(Status);
}

/*
**  Class      CMpeg1Device
**
**  Method     Write
**
*/

HRESULT CMpegDevice::Write(MPEG_STREAM_TYPE    StreamType,
                           UINT                nPackets,
                           PMPEG_PACKET_LIST   pList,
                           PMPEG_ASYNC_CONTEXT pAsyncContext)
{
    CAutoLock lck(&m_CritSec);

    DbgLog((LOG_TRACE, 2, TEXT("CMpegDevice::Write Type %s, %d packets"),
           StreamType == MpegAudioStream ? TEXT("Audio") : TEXT("Video"),
           nPackets));

    /* Check the event is properly reset */

    ASSERT(WaitForSingleObject(pAsyncContext->hEvent, 0) == WAIT_TIMEOUT);

    /*  Write the packet */

    MPEG_STATUS Status = MpegWriteData(m_Handle,
                                       StreamType,
                                       pList,
                                       nPackets,
                                       pAsyncContext);

    if (Status != MpegStatusSuccess &&
        Status != MpegStatusPending) {
        DbgLog((LOG_ERROR,1,TEXT("Failed to write to device - Handle = %8X, Mpeg Status = %d"),
            m_Handle,
            Status));
    }

    return MpegStatusToHResult(Status);
}

/*  Initial clock settings
*/
BOOL CMpegDevice::SetStartingSCR(MPEG_STREAM_TYPE StreamType, LONGLONG Scr)
{
    DbgLog((LOG_TRACE, 3, TEXT("Setting starting SCR to %d"), (LONG)Scr));
    if (StreamType == MpegAudioStream) {
        DbgLog((LOG_TRACE, 4, TEXT("Setting starting Audio SCR to %d"), (LONG)Scr));
        m_StartingAudioSCR = Scr;
        if (!m_bAudioStartingSCRSet) {
            m_bAudioStartingSCRSet = TRUE;
            //SetSTC(StreamType, Scr);
            return TRUE;
        }
        return FALSE;
    } else {
        ASSERT(StreamType == MpegVideoStream);
        DbgLog((LOG_TRACE, 4, TEXT("Setting starting Video SCR to %d"), (LONG)Scr));
        m_StartingVideoSCR = Scr;
        if (!m_bVideoStartingSCRSet) {
            m_bVideoStartingSCRSet = TRUE;
            //SetSTC(StreamType, Scr);
            return TRUE;
        }
        return FALSE;
    }
}

/*
    Set the device clock
*/
HRESULT CMpegDevice::SetSTC(MPEG_STREAM_TYPE StreamType,
                            LONGLONG         Scr)
{
#ifdef DEBUG
#pragma message (REMIND("Fix bad clock setting by resetting clocks (?)"))
#endif
    CAutoLock lck(&m_CritSec);
    /*  We can have different (!) clocks for video and audio? */

    MPEG_STATUS Status;

    if (StreamType == MpegAudioStream) {
        if (!m_bAudioStartingSCRSet) {
            DbgLog((LOG_ERROR, 3, TEXT("CMpegDevice::SetSTC() - Audio SCR not set yet")));
            return S_OK;
        }
        MPEG_SYSTEM_TIME RealScr =
             0x1FFFFFFFF & (MPEG_SYSTEM_TIME)(m_StartingAudioSCR + Scr);
        Status = MpegSetSTC(m_Handle,
                            MpegAudioDevice,
                            RealScr);
        DbgLog((LOG_TRACE, 2, TEXT("Setting Audio stream time to %d"),
                (LONG)RealScr));
        if (Status != MpegStatusSuccess) {
            DbgLog((LOG_ERROR,1,TEXT("Failed to set audio STC to %s - Handle = %8X, Mpeg Status = %d"),
                (LPCTSTR)CDisp((LONGLONG)Scr),
                m_Handle,
                Status));
        }
    } else {
        /*  Sync to audio if present */
        if (!m_bVideoStartingSCRSet) {
            DbgLog((LOG_ERROR, 3, TEXT("CMpegDevice::SetSTC() - Video SCR not set yet")));
            return S_OK;
        }
        if (m_bAudioStartingSCRSet) {
            MPEG_SYSTEM_TIME SystemDelta =
#if 0
                0x1FFFFFFFF & (MPEG_SYSTEM_TIME)(m_StartingVideoSCR -
                                                 m_StartingAudioSCR);
#else
                              (MPEG_SYSTEM_TIME)(m_StartingVideoSCR -
                                                 m_StartingAudioSCR);
#endif
            Status = MpegSyncVideoToAudio(m_Handle,  SystemDelta);
            DbgLog((LOG_TRACE, 2, TEXT("Synching video to Audio - delta %d"),
                   (LONG)SystemDelta));
            if (Status != MpegStatusSuccess) {
                DbgLog((LOG_ERROR,1,TEXT("Failed to sync video to audio STC to %s - Handle = %8X, Mpeg Status = %d"),
                    (LPCTSTR)CDisp((LONGLONG)SystemDelta),
                    m_Handle,
                    Status));
            }
        } else
        {
            MPEG_SYSTEM_TIME RealScr =
                 0x1FFFFFFFF & (MPEG_SYSTEM_TIME)(m_StartingVideoSCR + Scr);
            Status = MpegSetSTC(m_Handle,
                                MpegAudioDevice,
                                RealScr);

            DbgLog((LOG_TRACE, 2, TEXT("Setting Video stream time to %d"),
                    (LONG)RealScr));
            if (Status != MpegStatusSuccess) {
                DbgLog((LOG_ERROR,1,TEXT("Failed to set video STC to %s - Handle = %8X, Mpeg Status = %d"),
                    (LPCTSTR)CDisp((LONGLONG)Scr),
                    m_Handle,
                    Status));
            }
        }
        if (Status == MpegStatusHardwareFailure) {
#if 0
            Reset(StreamType);
#else
#if 0
        if (StreamType == MpegAudioStream) {
            m_bAudioStartingSCRSet = FALSE;
        } else {
            m_bVideoStartingSCRSet = FALSE;
        }
#endif
#endif
        }
    }

    return MpegStatusToHResult(Status);
}

HRESULT CMpegDevice::QuerySTC(MPEG_STREAM_TYPE StreamType,
                              MPEG_SYSTEM_TIME& Scr)
{
    CAutoLock lck(&m_CritSec);
    /*  We can have different (!) clocks for video and audio? */

    MPEG_STATUS Status = MpegQuerySTC(m_Handle,
                                      StreamType == MpegAudioStream ?
                                          MpegAudioDevice :
                                          MpegVideoDevice,
                                      &Scr);

    if (Status != MpegStatusSuccess) {
        DbgLog((LOG_ERROR,1,TEXT("Failed to query %s STC - Handle = %8X, Mpeg Status = %d"),
            StreamType == MpegAudioDevice ? TEXT("Audio") : TEXT("Video"),
            m_Handle,
            Status));
    }

    return MpegStatusToHResult(Status);
}

#ifdef DEBUG
#define OVERLAY_LOG_LEVEL 1
#endif

/*
    For the overlay stuff we will open the device if it's not open.

    How do we pass ownership of the device around? - we don't we only
    allow 1 open at a time by keeping the device open all the time for
    now until we think of a different solution.


    Basically the device is open whenever the output pin is connected.
    There is an assumption that when we are not inactive the output
    pin will be connected.
*/

/*
    Set a region for the overlay

    This is quite complicated.  If we're setting a null region prior
    to a move or size we want to disable the overlay and set a null
    rectange.  If we're setting a new rectangle we want to set
    everything up before reenabling the new overlay.
*/

HRESULT CMpegDevice::SetOverlay(const RECT    * pSourceRect,
                                const RECT    * pDestinationRect,
                                const RGNDATA * pRegionData)
{

#ifdef DEBUG
#pragma message (REMIND("Remember to do something with the source rectangle!"))
#endif

    const RECT *pRectArray = (RECT *) pRegionData->Buffer;

#ifdef DEBUG
    DbgLog((LOG_TRACE, OVERLAY_LOG_LEVEL, TEXT("SetOverlay source = %d %d %d %d"),
            pSourceRect->left,
            pSourceRect->top,
            pSourceRect->right,
            pSourceRect->bottom));
    DbgLog((LOG_TRACE, OVERLAY_LOG_LEVEL, TEXT("SetOverlay dest = %d %d %d %d"),
            pDestinationRect->left,
            pDestinationRect->top,
            pDestinationRect->right,
            pDestinationRect->bottom));
    for (unsigned int j = 0; j < pRegionData->rdh.nCount; j++) {
        DbgLog((LOG_TRACE, OVERLAY_LOG_LEVEL, TEXT("SetOverlay rect = %d %d %d %d"),
                pRectArray[j].left,
                pRectArray[j].top,
                pRectArray[j].right,
                pRectArray[j].bottom));
    }
#endif

    CAutoLock lck(&m_CritSec);
    if (!m_Capability[MpegCapBitmaskOverlay] &&
        !m_Capability[MpegCapChromaKeyOverlay]) {
        return E_FAIL;
    }


    /*  If we're changing then disable! - should really compare
        with last rectangle to see what it was then
    */
    HRESULT hr = MpegStatusToHResult(MpegSetOverlayMode(m_Handle,
                                                        MpegModeNone));
    if (FAILED(hr)) {
        return hr;
    }


    /*  Choose overlay mode - if we're completely visible use
        rectangle, if we're invisible use none, otherwise use
        overlay */

//#define HACK
#ifdef HACK
    if (IsRectEmpty(pDestinationRect)
#else
    if (pRegionData->rdh.nCount == 0 ||
        IsRectEmpty(&pRegionData->rdh.rcBound)
#endif // HACK
        ) {
        DbgLog((LOG_TRACE, OVERLAY_LOG_LEVEL, TEXT("Setting overlay off")));
        return S_OK;
    } else {
        /*  Assume stretch for now */
        DbgLog((LOG_TRACE, OVERLAY_LOG_LEVEL, TEXT("Setting overlay destination to (%d, %d), (%d, %d)"),
                pDestinationRect->left,
                pDestinationRect->top,
                pDestinationRect->right,
                pDestinationRect->bottom));
        MpegSetOverlayDestination(m_Handle,
                                  pDestinationRect->left,
                                  pDestinationRect->top,
                                  pDestinationRect->right - pDestinationRect->left,
                                  pDestinationRect->bottom - pDestinationRect->top);


#ifdef HACK
        if (TRUE)
#else
#if 0
        if (EqualRect(&pRectArray[0], pDestinationRect))
#else
        if (FALSE)
#endif
#endif
        {
            /*  Set the overlay key */
            if (m_Capability[MpegCapChromaKeyOverlay]) {
                MpegSetOverlayKey(m_Handle,
                                  m_rgbChromaKeyColor,
                                  m_rgbChromaKeyMask);
            }
            DbgLog((LOG_TRACE, OVERLAY_LOG_LEVEL, TEXT("Setting overlay mode to rectangle")));
            return MpegStatusToHResult(MpegSetOverlayMode(m_Handle,
                                                          MpegModeRectangle));
        } else {
            ASSERT(!m_Capability[MpegCapChromaKeyOverlay]);


            /*  Create a bitmask of size rcBound and pass it to the device */

            LONG Width  = pDestinationRect->right -
                          pDestinationRect->left;

            /*  Our mask is DWORD aligned */
            LONG WidthInBytes = (((pDestinationRect->right + 31) >> 3) & ~3) -
                                (( pDestinationRect->left        >> 3) & ~3);

            /*  Must be the height of the whole window */
            LONG Height = pDestinationRect->bottom -
                          pDestinationRect->top;
            BYTE *Mask = (BYTE *)LocalAlloc(LPTR, WidthInBytes * Height);

            if (Mask == NULL) {
                return E_OUTOFMEMORY;
            }

            for (unsigned int i = 0; i < pRegionData->rdh.nCount; i++) {
                FillOurRect(Mask,
                            WidthInBytes,
                            pDestinationRect->left,
                            pDestinationRect->bottom,
                            &pRectArray[i]);
            }


            MPEG_STATUS Status =
                MpegSetOverlayMask(m_Handle,
                                   (ULONG)Height,
                                   Width,
                                   0,
                                   WidthInBytes,
                                   Mask);
            if (Status != MpegStatusSuccess) {
                DbgLog((LOG_ERROR, 1, TEXT("MpegSetOverlayMask failed code %d"),
                        Status));
            }

            LocalFree((HLOCAL)Mask);

            DbgLog((LOG_TRACE, OVERLAY_LOG_LEVEL, TEXT("Setting overlay mode to Overlay")));
            Status =
                MpegSetOverlayMode(m_Handle,
                                   MpegModeOverlay);
            if (Status != MpegStatusSuccess) {
                DbgLog((LOG_ERROR, 1, TEXT("MpegSetOverlayMode(MpegModeOverlay) failed code %d"),
                        Status));
            }
            return Status;
        }
    }
}

HRESULT CMpegDevice::GetChromaKey(COLORREF * prgbColor,
                                  COLORREF * prgbMask)
{
    CAutoLock lck(&m_CritSec);
    if (!m_Capability[MpegCapChromaKeyOverlay]) {
        return S_FALSE;
    }

    /*  MpegQueryOverlayKey not supported currently */

    *prgbColor = m_rgbChromaKeyColor;
    *prgbMask  = m_rgbChromaKeyMask;

    return S_OK;
}

/*  Set the rectangle we're going to play from */

HRESULT CMpegDevice::SetSourceRectangle(const RECT * Rect)
{
    CAutoLock lck(&m_CritSec);

    m_rcSrc = *Rect;
    if (m_Handle != NULL) {
        MpegSetOverlaySource(m_Handle,
                             m_rcSrc.left,
                             m_rcSrc.top,
                             m_rcSrc.right - m_rcSrc.left,
                             m_rcSrc.bottom - m_rcSrc.top);

    }
    return S_OK;
}

/*  Get the source rectangle */

HRESULT CMpegDevice::GetSourceRectangle(RECT * Rect)
{
    CAutoLock lck(&m_CritSec);

    *Rect = m_rcSrc;

    return S_OK;
}

HRESULT CMpegDevice::SetChromaKey(COLORREF rgbColor, COLORREF rgbMask)
{
    CAutoLock lck(&m_CritSec);
    m_rgbChromaKeyColor = rgbColor;
    m_rgbChromaKeyMask  = rgbMask;

    if (m_Handle != NULL) {
        MpegSetOverlayKey(m_Handle,
                          m_rgbChromaKeyColor,
                          m_rgbChromaKeyMask);
    }

    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\devq.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

#include <streams.h>
#include "driver.h"

/*

    devq.cpp

    CMpeq1DeviceQueue functions

*/

/*  Constructor */

CMpeg1DeviceQueue::CMpeg1DeviceQueue(CMpegDevice        * Device,
                                     MPEG_STREAM_TYPE     StreamType,
                                     CMpeg1PacketFilter * pFilter,
                                     HRESULT            * phr) :
        m_Device(Device),
        m_StreamType(StreamType),
        m_Head(NULL),
        m_pFilter(pFilter),
        m_SampleQueue(NULL),
        m_nOutstanding(0),
        m_Parse(StreamType,
                StreamType == MpegVideoStream ? pFilter->GetSequenceHeader() :
                                                NULL)
{
    *phr = S_OK;

    /* Use manual reset events so it's more predictable what happens
       when WaitForMultipleObjects is called
    */

    for (int i = 0; i < MAX_QUEUE_ELEMENTS; i++) {
        m_Elements[i].m_AsyncContext.hEvent =
            CreateEvent(NULL, TRUE, FALSE, NULL);

        if (m_Elements[i].m_AsyncContext.hEvent == NULL) {
            /*  Failed - free the events we've allocated and exit
            */
            for (; i ; i--) {
                BOOL rc = CloseHandle(m_Elements[i - 1].m_AsyncContext.hEvent);
                ASSERT(rc);
            }
            *phr = E_OUTOFMEMORY;
            return;
        }
    }
}

/* Destructor */

CMpeg1DeviceQueue::~CMpeg1DeviceQueue()
{
    for (int i = 0; i < MAX_QUEUE_ELEMENTS; i++) {
        ASSERT(!m_Elements[i].m_InUse ||
               WAIT_OBJECT_0 == WaitForSingleObject(m_Elements[i].m_AsyncContext.hEvent, 0));
        BOOL bClosed = CloseHandle(m_Elements[i].m_AsyncContext.hEvent);
        ASSERT(bClosed);
    }
}

/*  Extra bit of construction - because we point to our sample queue
    and vice versa!
*/
void CMpeg1DeviceQueue::SetSampleQueue(CSampleQueue *SampleQueue)
{
    m_SampleQueue = SampleQueue;
}

/*  Set the System time clock in the hardware from the packet
    at the head of the queue (ie the next one that will complete)
*/
HRESULT CMpeg1DeviceQueue::SetSTC()
{
    CAutoLock lck(&m_Lock);

    return SetSTCFromStreamTime();
}

/*  Call back here to complete a sample
*/
void CMpeg1DeviceQueue::Complete()
{
    CAutoLock lck(&m_Lock);

    ASSERT(m_Head != NULL);
    CQueueElement *Element = m_Head;

    /*  See if we should set the STC for the next sample */
    if (m_Head->m_Next != NULL &&
        m_Head->m_pSample != m_Head->m_Next->m_pSample) {
#ifdef DEBUG
#pragma message (REMIND("Remove hack for audio master and do it properly!"))
#endif
        if (m_StreamType != MpegAudioStream) {
            SetSTCFromStreamTime();
        }
    }

    m_Head = m_Head->m_Next;

    m_nOutstanding--;
    if (m_Head == NULL) {
        DbgLog((LOG_TRACE, 2, TEXT("0 buffers oustanding for %s stream"),
                m_StreamType == MpegAudioStream ? TEXT("Audio") :
                                                  TEXT("Video")));
        ASSERT(m_nOutstanding == 0);
    }

    Element->m_Next = NULL;

    ASSERT(m_SampleQueue != NULL);

    /*  The sample at the head of the list is complete */

    ASSERT(Element->m_InUse);
    if (Element->m_nPackets != 0) {
        if (Element->m_nPackets != Element->m_nSamples) {
            for (int i = 0; i < Element->m_nPackets; i++) {
                if (Element->m_pSample[i] == NULL) {
                    DbgLog((LOG_TRACE, 4, TEXT("Deleting copied packet")));
                    delete [] (PBYTE)Element->m_PacketList[i].pPacketData;
                }
            }
        }
        m_SampleQueue->NotifySamples(Element->m_nSamples);
    } else {
        m_pFilter->EndOfStream(m_StreamType);
    }

    ResetEvent(Element->m_AsyncContext.hEvent);
    Element->m_InUse = FALSE;
    Element->m_nSamples = 0;
    Element->m_nPackets = 0;

    if (m_Head == NULL) {
        /*  Tell the parser it's OK to send stuff on now */
        m_Parse.Empty();
        /*  Stop the device to reset its state */
        //m_Device->Stop(m_StreamType);
        SetSTC();
    }

    /*  Try to queue some more */

    m_SampleQueue->SendSamplesToDevice();
}

/*
    QueueSample
       Add a new sample to our list and send it to the device
           (each only if there's room)

       This must be called repeatedly until *nBytes is 0 or the sample
       data is exhausted

    Parameters:

       pQueue - sample queue

    Returns:
        TRUE  if the sample data was OK

        FALSE if there was a parsing problem in the sample data

              The caller should then effectively truncate the sample data
              at end of the last good packet which can be determined by
              looking *nBytes from the start of the buffer

*/
BOOL CMpeg1DeviceQueue::QueueSamples()
{
    CAutoLock lck(&m_Lock);

    /* If there's no free slot give up */
    CQueueElement* Element = NULL;

    BOOL bOK = TRUE;
    BOOL bDoEOS = FALSE;

    for (int i = 0; i < MAX_QUEUE_ELEMENTS; i++) {

        if (!m_Elements[i].m_InUse) {

            Element          = &m_Elements[i];
            Element->m_InUse = TRUE;
            ASSERT(Element->m_nSamples == 0);
            ASSERT(WaitForSingleObject(Element->m_AsyncContext.hEvent, 0) ==
                   WAIT_TIMEOUT);

            break;
        } else {
            ASSERT(m_Elements[i].m_nSamples != 0);
        }
    }

    if (Element == NULL) {

        /*  Nothing wrong with the packets, just no free slots */
        DbgLog((LOG_TRACE, 2, TEXT("CMpeg1DeviceQueue::QueueSample - queue full")));
        return FALSE;
    }



    /* First pull out some packets

       We pull out and wrap a maximum of MAX_PACKETS_PER_ELEMENT packets
    */


    for (Element->m_nSamples = 0, Element->m_nPackets = 0;
         Element->m_nPackets < MAX_PACKETS_PER_ELEMENT;
        )
    {
        PBYTE pPacket;
        IMediaSample *pSample = m_SampleQueue->Next();
        if (pSample == NULL) {
            break;
        }
        if (pSample == EOS_SAMPLE) {
            break;
        }

        /*  Check sequence info */
        DWORD dwProcessFlags;
        long lPacketSize;
        ASSERT(dwProcessFlags != (DWORD)-1);
        HRESULT hr = m_Parse.ParseSample(pSample, pPacket, lPacketSize, dwProcessFlags);

        if (S_OK != hr) {
            if (FAILED(hr)) {
                 m_SampleQueue->Discard();
            }
            bOK = FALSE;
            break;
        }

        if (dwProcessFlags & CStreamParse::ProcessSend) {

            if (pPacket != NULL) {
                ASSERT(pSample != NULL);
                /*  Pull out the length of the  packet */

                long     RealLength;
                BOOL     bHasPts;
                LONGLONG llPts;
                ParsePacket((PBYTE)pPacket,
                            lPacketSize,
                            &RealLength,
                            &llPts,
                            &bHasPts);

                if (lPacketSize == 0) {
                    DbgLog((LOG_ERROR, 1, TEXT("0 sized samples")));
                    bOK = FALSE;
                    continue;
                }

#ifdef DEBUG
#pragma message (REMIND("Fix start time!"))
#endif

                if (bHasPts) {
                    /*  Set the start clock */
                    REFERENCE_TIME tStart, tStop;
                    pSample->GetTime(&tStart, &tStop);
                    LONGLONG llStartScr = llPts -
                                          (tStart * 9) / 1000;
                    if (m_Device->SetStartingSCR(m_StreamType,
                                                 llStartScr)) {
                        SetSTC();
                    }
                }
            }

            Element->m_PacketList[Element->m_nPackets].ulPacketSize = (ULONG)lPacketSize;
            Element->m_PacketList[Element->m_nPackets].pPacketData  = (PVOID)pPacket;
            Element->m_PacketList[Element->m_nPackets].Scr          = 0;
            Element->m_pSample[Element->m_nPackets] =
                (dwProcessFlags & CStreamParse::ProcessCopied) ? NULL : pSample;

            Element->m_nPackets++;
        }

        if (dwProcessFlags & CStreamParse::ProcessComplete) {
            if (dwProcessFlags ==
                   (CStreamParse::ProcessComplete | CStreamParse::ProcessSend)) {
                Element->m_nSamples++;
                m_SampleQueue->Advance();
            } else {
                /*  It's a copy or we're discarding */
                DbgLog((LOG_TRACE, 3, TEXT("Discarding a packet")));
                m_SampleQueue->Discard();
                pSample = NULL;
            }
        }
    }

    /*  See if we're going to send anything */
    if (Element->m_nPackets == 0) {
        /*  Do EOS here */
        if (m_SampleQueue->Next() == EOS_SAMPLE) {
            m_SampleQueue->Discard();
        } else {
            Element->m_InUse = FALSE;
            return FALSE;
        }
    } else {
        /* Set the STC if this is the first one we've seen for
           a while
        */
        if (m_Head == NULL) {
            SetSTCFromStreamTime();
        }
    }

    /* Now pass it to the device.  If this fails we'd
       better amend the length of this sample (!) */

    DbgLog((LOG_TRACE, 3, TEXT("Writing %d packets to device"),
            Element->m_nPackets));
    HRESULT hr = m_Device->Write(m_StreamType,
                                 Element->m_nPackets,
                                 Element->m_PacketList,
                                 &Element->m_AsyncContext);

    /*  Note we can get back ERROR_BUSY */
    if (FAILED(hr)) {
        if (HRESULT_CODE(hr) == ERROR_BUSY) {
            DbgLog((LOG_TRACE,1,TEXT("Device busy when trying to queue packet")));
        }
    } else {
        /*  Put this packet at the tail */

        ASSERT(Element->m_Next == NULL);
        CQueueElement **pSearch;
        for (pSearch = &m_Head;
             *pSearch != NULL;
             pSearch = &(*pSearch)->m_Next) {
        };

        *pSearch = Element;
        m_nOutstanding++;
    }

    return bOK;

}

/*  Flush the device */
HRESULT CMpeg1DeviceQueue::Flush()
{
    DbgLog((LOG_TRACE, 3, TEXT("CMpeg1DeviceQueue::Flush() %s"),
            m_StreamType == MpegAudioStream ? TEXT("Audio") : TEXT("Video")));
    /*  Stop the device first */
    HRESULT hr = m_Device->Reset(m_StreamType);
    if (SUCCEEDED(hr)) {
        /*  Now complete all the samples synchronously - the stop
            should have caused the driver to complete all the IO
        */
        while (m_Head != NULL) {
            EXECUTE_ASSERT(WAIT_OBJECT_0 ==
                           WaitForSingleObject(m_Head->m_AsyncContext.hEvent, 0));
            Complete();
        }
        hr = m_Device->Pause(m_StreamType);
    }
    m_Parse.Reset();
    return hr;
}

/*  Extract the handle that will say we're complete
*/
HANDLE CMpeg1DeviceQueue::NotifyHandle() const
{
    /*  No need to lock this one because it doesn't change the
        queue and it's only called on the worker thread
    */
    HANDLE hEvent;

    /*  Return the event for the first buffer which will complete
        on this stream.  If there is none then just return
        a random event (which should of course be reset).
    */

    if (m_Head != NULL) {
        hEvent = m_Head->m_AsyncContext.hEvent;
        /*  Note that this event may already be set */
    } else {
        hEvent = m_Elements[0].m_AsyncContext.hEvent;
        DbgLog((LOG_TRACE, 4, TEXT("No data for this stream, using event 0")));
        /*  This tests if it's a valid hevent and checks that it's
            reset
        */
        ASSERT(WaitForSingleObject(hEvent, 0) == WAIT_TIMEOUT);
    }

    return hEvent;
}
/*
    Packet helper functions
*/

/*  Look into the packet to find out how long it is and parse the PTS
    We also eat through any garbage after the packet */

long ParsePacket(PBYTE pPacket,
                 long lSize,
                 long *RealSize,
                 LONGLONG *pPts,
                 PBOOL HasPts)
{
    *HasPts = FALSE;

    /* Make sure the buffer is big enough to read anything */
    if (lSize < 6) {
        DbgLog((LOG_ERROR,1,TEXT("Bad packet size %d"), lSize));
        return 0; // WRONG
    }

    /* Check the header */

    /* Check packet start prefix */
    if ((*(UNALIGNED ULONG *)pPacket & 0xFFFFFF)!= 0x010000) {
        DbgLog((LOG_ERROR,1,
               TEXT("Invalid start code - 0x%2.2X%2.2X%2.2X%2.2X"),
               pPacket[0], pPacket[1], pPacket[2], pPacket[3]));
        return 0;
    }

    long Length =  ((long)pPacket[4] << 8) + (long)pPacket[5] + 6;
    if (Length > lSize) {
        DbgLog((LOG_ERROR,1,TEXT("Bad packet size %d - expected at most %d"), Length, lSize));
        return 0; // WRONG
    }

    /* Pull out the pts if there is one and we want it */

    if (pPts != NULL)
    {
        PBYTE pData = &pPacket[6];

        /* First skip over stuffing bytes */
        while (lSize > 0 && (*pData & 0x80)) {
            pData++;
            lSize--;
        }

        if (lSize > 1) {
            if (*pData & 0x40) { /* skip over STD_buffer stuff */
                pData += 2;
                lSize -= 2;
            }
        }

        /*  Pts is '0010', Pts + Dts is '0011' */
        if (lSize >= 5 && (*pData & 0xE0) == 0x20 ) {
            LARGE_INTEGER Pts;
            Pts.HighPart = (pData[0] & 8) != 0;
            Pts.LowPart  = ((pData[0] & 0x06) << 29) +
                           ((pData[1]       ) << 22) +
                           ((pData[2] & 0xFE) << 14) +
                           ((pData[3]       ) << 7 ) +
                           ((pData[4]       ) >> 1 );

            *pPts = Pts.QuadPart;
            *HasPts = TRUE;

            DbgLog((LOG_TRACE, 3, TEXT("Detected PTS - %d"), Pts.LowPart));
        }
    }

    if (!*HasPts) {
        DbgLog((LOG_TRACE, 3, TEXT("Packet with no PTS")));
    }

    /*  Skip over any garbage at the end of the packet */
    pPacket += Length;
    lSize -= Length + 4;
    LONG RealLength = Length;

    if (RealSize != NULL) {
        *RealSize = RealLength;
    }

    return Length;
}

long CMpeg1DeviceQueue::PacketLength(PBYTE pPacketData, long lSize, long *RealSize)
{
    BOOL     HasPts;

    return ParsePacket(pPacketData, lSize, RealSize, NULL, &HasPts);
}

#if 0
BOOL CMpeg1DeviceQueue::GetPtsFromSample(IMediaSample *pSample, LONGLONG *pPts)
{
    BOOL     HasPts = FALSE;
    PBYTE    pData;
    if (FAILED(pSample->GetPointer(&pData))) {
        return FALSE;
    }
    ParsePacket(pData,
                pSample->GetActualDataLength(),
                pPts,
                &HasPts);

    return HasPts;
}
#endif


/*
    Given a sample use it to compute a corrected STC and set it.
*/

HRESULT CMpeg1DeviceQueue::SetSTCFromStreamTime()
{

    /*
        We want to set the STC to be:

        StreamTime + StartingSCR

        Where:

            StreamTime  = time since stream 'started'

            StartingSCR = Start of MPEG stream
     */

#ifdef DEBUG
#pragma message (REMIND("Fix stream time when not running after seek!"))
#endif
     if (!m_pFilter->IsRunning()) {
         return S_FALSE;
     }

     CRefTime StreamTime;
     HRESULT hr = m_pFilter->StreamTime(StreamTime);
     if (FAILED(hr)) {
         return hr;
     }

     /*  For now we'll just assume the stream time is a moderate number of
         years
     */

     /*  Try to set the STC */

     return m_Device->SetSTC(m_StreamType, (MPEG_SYSTEM_TIME)((StreamTime * 9) / 1000));
}


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\driver.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

#include <mmreg.h>
#include <wxdebug.h>
#include <mpegapi.h>
#include <mpegdef.h>
#include <seqhdr.h>

#include "device.h"
#include "sample.h"
#include "parse.h"
#include "devq.h"
#include "stream.h"
#include "worker.h"
#include "mpegfilt.h"
#include "inputpin.h"
#include "coverlay.h"
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\device.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

class CMpegDevice
#ifdef DEBUG
      : public CAMThread
#endif
{
    public:
        CMpegDevice();
        ~CMpegDevice();

        // Call after construction to check if it's worth going on
        BOOL    DeviceExists() const {
            return m_PseudoHandle != NULL;
        } ;

        /*  Device / handle management */

        HRESULT Open();       // Opens the real driver
        BOOL    IsOpen();
        HRESULT Close();
        HRESULT Pause();
        HRESULT Pause(MPEG_STREAM_TYPE);
        HRESULT Stop();
        HRESULT Stop(MPEG_STREAM_TYPE);
        HRESULT Reset(MPEG_STREAM_TYPE);
        HRESULT Run(REFERENCE_TIME StreamTime);
        HRESULT Write(MPEG_STREAM_TYPE    StreamType,
                      UINT                nPackets,
                      PMPEG_PACKET_LIST   pList,
                      PMPEG_ASYNC_CONTEXT pAsyncContext);

        /*  Timing */

        HRESULT SetSTC(MPEG_STREAM_TYPE StreamType,
                       LONGLONG         Scr);

        HRESULT QuerySTC(MPEG_STREAM_TYPE StreamType,
                         MPEG_SYSTEM_TIME& Scr);

        void ResetTimers()
        {
            m_bVideoStartingSCRSet = FALSE;
            m_bAudioStartingSCRSet = FALSE;
        };

        /*  Overlay management */

        HRESULT GetChromaKey(COLORREF * prgbColor,
                             COLORREF * prgbMask);

        HRESULT SetChromaKey(COLORREF rgbColor,
                             COLORREF rgbMask);

        HRESULT SetOverlay(const RECT    * pSourceRect,
                           const RECT    * pDestinationRect,
                           const RGNDATA * pRegionData);

        HRESULT SetSourceRectangle(const RECT * rcSrc);
        HRESULT GetSourceRectangle(RECT * rcSrc);

        BOOL SetStartingSCR(MPEG_STREAM_TYPE StreamType, LONGLONG Scr);

    private:
        /*  Starting time for streams */
        BOOL      m_bAudioStartingSCRSet;
        BOOL      m_bVideoStartingSCRSet;
        LONGLONG  m_StartingAudioSCR;
        LONGLONG  m_StartingVideoSCR;

        /*  State to restore after Reset() */
        BOOL      m_bRunning;
        BOOL      m_bSynced;

        HMPEG_DEVICE m_Handle;       // When open
        CCritSec     m_CritSec;      // Synchronize all calls


        TCHAR       m_szDriverPresent[256];
        DWORD       m_dwID;          // Device id - saved in
                                     // constructor
        HMPEG_DEVICE m_PseudoHandle; // Pseudo handle - saved in
                                     // in constructor

        /*  Caps - cached when we are created */

        BOOL        m_Capability[    // Save all caps values
                       MpegCapMaximumCapability];


        /*  Stuff for Overlay */

        /*  Source */
        RECT        m_rcSrc;

        /*  Chroma key stuff it it's supported */
        COLORREF    m_rgbChromaKeyColor;
        COLORREF    m_rgbChromaKeyMask;

        /*  Return code translation */

static HRESULT     MpegStatusToHResult(MPEG_STATUS);

#ifdef DEBUG
        /*  Performance monitoring thread */
        DWORD      QueryInfo(MPEG_DEVICE_TYPE Type, MPEG_INFO_ITEM Item);
        DWORD      ThreadProc();
#endif
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\devq.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    devq.h

    CMpeg1DeviceQueue definitions

    Lists of packets are queued up on the real device.  This object
    is notified when an event is set notifying that the next IO
    request has completed.

*/

class CMpeg1PacketFilter;

/*  Global function */
long ParsePacket(PBYTE pPacket,
                 long lSize,
                 long *RealSize,
                 LONGLONG *pPts,
                 PBOOL HasPts);

class CMpeg1DeviceQueue
{
    #define MAX_PACKETS_PER_ELEMENT 8
    #define MAX_QUEUE_ELEMENTS      8

    private:

        /*  We'll serialize methods that change things for now.
            This is because we want to set the STC instantaneously
            without jumping to the worker thread when Run is issued
            so we need to be synchonized with this object.
        */

        CCritSec m_Lock;

        /*  Pointer to the hardware device wrapper
        */
        CMpegDevice     *m_Device;

        /*  Stream type this queue supports (should really be stream id)
        */
        MPEG_STREAM_TYPE m_StreamType;

        /*  Private queue elements - members are public to this class */

        /*  Predeclare class */
        class CQueueElement;

        class CQueueElement {
            public:
                CQueueElement    * m_Next;
                long               m_nSamples;
                long               m_nPackets;
                BOOL               m_InUse;

                /* Remember which sample this came from for debugging */

                IMediaSample * m_pSample[MAX_PACKETS_PER_ELEMENT];

                MPEG_PACKET_LIST   m_PacketList[MAX_PACKETS_PER_ELEMENT];
                MPEG_ASYNC_CONTEXT m_AsyncContext;

                CQueueElement() : m_Next(NULL),
                                  m_InUse(FALSE),
                                  m_nSamples(0),
                                  m_nPackets(0)
                {
                };
                ~CQueueElement()
                {
                };
        } ;

        /*  Our list of queue elements (each element is a set of packets)
            This is a stactically allocated list for now
        */
        CQueueElement               * m_Head;
        CQueueElement                 m_Elements[MAX_QUEUE_ELEMENTS];
        int                           m_nOutstanding;

        /*  Our buddy queue of samples */
        CSampleQueue                * m_SampleQueue;

        /*  Our time source */
        CMpeg1PacketFilter          * m_pFilter;

        /*  Stream state */
        CStreamParse                  m_Parse;

    public:

        /*  Constructor */

        CMpeg1DeviceQueue(CMpegDevice        * Device,
                          MPEG_STREAM_TYPE     StreamType,
                          CMpeg1PacketFilter * pFilter,
                          HRESULT            * phr);

        /* Destructor */

        ~CMpeg1DeviceQueue();

        /*  Extra bit of construction - because we point to our sample queue
            and vice versa!
        */
        void SetSampleQueue(CSampleQueue *SampleQueue);

        /*  Set the System time clock in the hardware from the packet
            at the head of the queue (ie the next one that will complete
            next
        */
        HRESULT SetSTC();

        /*  Call back here to complete a sample
        */
        void Complete();

        /*  Add a new sample to our list and send it to the device
            (each only if there's room)
        */
        BOOL QueueSamples();

        /*  Flush */
        HRESULT Flush();

        /*  Extract the handle that will say we're complete
        */
        HANDLE NotifyHandle() const;

    private:
        HRESULT SetSTCFromStreamTime();
        long PacketLength(PBYTE pPacketData,
                          long lSize,
                          long *lRealSize);
} ;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\fill.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    Fill a rectangle in a bit array.  The bit array is assumed to
    be a multiple of 32 bits wide and we always try to write
    ULONGs.
*/

#include <streams.h>
#include <driver.h>
#include "fill.h"

void FillOurRect(PBYTE Bits,              // Array to fill
                 LONG  WidthInBytes,      // Number to add to get to next row
                 LONG  leftbit,           // Left bit position of bit array
                 LONG  bottombit,         // top bit position of bit array
                 const RECT *pRect)       // rectangle to fill
{
    ASSERT(bottombit >= pRect->bottom &&
           leftbit <= pRect->left);

    /*  Make sure the rect is not empty */
    ASSERT(!IsRectEmpty(pRect));

    LONG Left = pRect->left - leftbit;
    LONG Bottom  = bottombit - pRect->bottom;
    LONG Right = pRect->right - leftbit;

    PBYTE BottomRow = Bits +
                      WidthInBytes * Bottom;

    PBYTE BottomLeft = BottomRow + ((Left >> 3) & ~3);

    /*  Right is exclusive - ie it's the first DWORD that contains
        bits NOT in the rectangle
    */
    PBYTE BottomRight = BottomRow + ((Right >> 3) & ~3);

    /*  Do left and right masks */
    DWORD LeftMask = 0xFFFFFFFF >> (Left & 31);
    DWORD RightMask = ~(0xFFFFFFFF >> (Right & 31));

    if (BottomLeft == BottomRight) {
        LeftMask &= RightMask;
        RightMask = 0;
    }

    /*  Fill in left and right */
    LPDWORD pdw;
    int Height = pRect->bottom - pRect->top;

    /*  Byte swap the mask */
    LeftMask = (LeftMask >> 24) |
               (LeftMask << 24) |
               ((LeftMask & 0xFF00) << 8) |
               ((LeftMask & 0xFF0000) >> 8);
    int i;
    for (pdw = (LPDWORD)BottomLeft, i = 0;
         i < Height;     // Bottom is exclusive
         i++, pdw = (LPDWORD)((PBYTE)pdw + WidthInBytes)) {
        *pdw = LeftMask;
    }
    if (RightMask != 0) {
        /*  Byte swap the mask */
        RightMask = (RightMask >> 24) |
                    (RightMask << 24) |
                    ((RightMask & 0xFF00) << 8) |
                    ((RightMask & 0xFF0000) >> 8);
        for (pdw = (LPDWORD)BottomRight, i = 0;
             i < Height;
             i++, pdw = (LPDWORD)((PBYTE)pdw + WidthInBytes)) {
            *pdw = RightMask;
        }
    }

    if (BottomRight - BottomLeft > sizeof(ULONG)) {
        /*  Fill in the middle bits */
        PBYTE pRow;
        LONG  Length = BottomRight - BottomLeft - sizeof(ULONG);
        for (pRow = BottomLeft + sizeof(ULONG), i = 0;
             i < Height;
             i++, pRow += WidthInBytes)
        {
            FillMemory((PVOID)pRow, Length, 0xFF);
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\fill.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

void FillOurRect(PBYTE Bits,              // Array to fill
                 LONG  WidthInBytes,      // Number to add to get to next row
                 LONG  leftbit,           // Left bit position of bit array
                 LONG  topbit,            // top bit position of bit array
                 const RECT *pRect);      // rectangle to fill
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\inputpin.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

class CMpeg1PacketInputPin : public CBaseInputPin
{
    public:

        CMpeg1PacketInputPin(
            TCHAR              * pObjectName,
            CMpeg1PacketFilter * pFilter,
            MPEG_STREAM_TYPE     StreamType,
            HRESULT            * phr,
            LPCWSTR              pPinName
        );

        ~CMpeg1PacketInputPin();

        /* IPin methods */
        STDMETHODIMP BeginFlush();
        STDMETHODIMP EndFlush();
        STDMETHODIMP EndOfStream();

        /* CBasePin overrides */

        HRESULT GetMediaType(int iPosition, CMediaType *pmt);
        HRESULT CheckMediaType(const CMediaType *pmt);
        HRESULT SetMediaType(const CMediaType *pmt);

        /* IMemInputPin methods */

        STDMETHODIMP Receive(IMediaSample *pSample);
        STDMETHODIMP ReceiveMultiple (
            IMediaSample **pSamples,
            long nSamples,
            long *nSamplesProcessed);

        STDMETHODIMP ReceiveCanBlock();

        /*  Get the sequence header */
        const BYTE *GetSequenceHeader();

        /*  Say what's connected to what or FilGraph is confused
            by us having an input pin that doesn't stream to the output pin
        */
        STDMETHODIMP  QueryInternalConnections(IPin **apPin, ULONG *nPin);

    private:
        CMpeg1PacketFilter * const m_pFilter;
        const MPEG_STREAM_TYPE     m_StreamType;
        const int                  m_iStream;
        DWORD                      m_MPEGStreamId; // Real Mpeg stream id
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\inputpin.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

#include <streams.h>
#include "driver.h"

/*
    Support for the input pins
*/

/*  Constructor */

CMpeg1PacketInputPin::CMpeg1PacketInputPin(
                                       TCHAR              * pObjectName,
                                       CMpeg1PacketFilter * pFilter,
                                       MPEG_STREAM_TYPE     StreamType,
                                       HRESULT            * phr,
                                       LPCWSTR              pPinName) :
    CBaseInputPin(pObjectName, pFilter, pFilter->GetLock(), phr, pPinName),
    m_StreamType(StreamType),
    m_iStream(pFilter->AddStream(StreamType)),
    m_pFilter(pFilter),
    m_MPEGStreamId(0)
{
};

CMpeg1PacketInputPin::~CMpeg1PacketInputPin() {};

HRESULT CMpeg1PacketInputPin::GetMediaType(int iPosition, CMediaType *pmt)
{
    if (iPosition < 0) {
        return E_INVALIDARG;
    }
    if (iPosition > 0) {
        return VFW_S_NO_MORE_ITEMS;
    }
    if (m_StreamType == MpegAudioStream) {
        pmt->majortype            = MEDIATYPE_Audio;
        pmt->subtype              = MEDIASUBTYPE_MPEG1Packet;
        pmt->bFixedSizeSamples    = FALSE;
        pmt->bTemporalCompression = TRUE;
        pmt->lSampleSize          = 0;
    } else {
        ASSERT(m_StreamType == MpegVideoStream);
        pmt->majortype            = MEDIATYPE_Video;
        pmt->subtype              = MEDIASUBTYPE_MPEG1Packet;
        pmt->bFixedSizeSamples    = FALSE;
        pmt->bTemporalCompression = TRUE;
        pmt->lSampleSize          = 0;
    }
    return S_OK;
}

/* Return S_OK if we support the requested media type */

HRESULT CMpeg1PacketInputPin::CheckMediaType(const CMediaType *pmt)
{
    /*  No need to lock as the base class is calling us back here */

    if (m_StreamType == MpegAudioStream) {
        if (pmt->majortype == MEDIATYPE_Audio &&
            pmt->subtype   == MEDIASUBTYPE_MPEG1Packet &&
            *pmt->FormatType() == FORMAT_WaveFormatEx) {
           return S_OK;
        } else {
           return E_FAIL;
        }
    }

    ASSERT(m_StreamType == MpegVideoStream);

    if (pmt->majortype == MEDIATYPE_Video &&
        pmt->subtype   == MEDIASUBTYPE_MPEG1Packet &&
        *pmt->FormatType() == FORMAT_MPEGVideo &&
        pmt->cbFormat == SIZE_MPEG1VIDEOINFO((MPEG1VIDEOINFO *)pmt->pbFormat)) {
        return S_OK;
    } else {
        return E_FAIL;
    }
}

HRESULT CMpeg1PacketInputPin::SetMediaType(const CMediaType *pmt)
{

    /*  No need to lock as the base class is calling us back here */
    ASSERT(SUCCEEDED(CheckMediaType(pmt)));

    HRESULT hr = CBasePin::SetMediaType(pmt);
    if (FAILED(hr)) {
        return hr;
    }

    if (m_StreamType == MpegAudioStream) {
       return S_OK;
    }

    ASSERT(m_StreamType == MpegVideoStream);

    /*  We save the video format stuff to pass on to the
        output pin

        If the output pin is already connected we should
        attempt to change it (??? for the next sample ???).
    */

    /*
        Hack for now - just set the whole rectangle
    */
    RECT rcSrc;
    SetRect(&rcSrc,
            0,
            0,
            ((VIDEOINFO *)pmt->pbFormat)->bmiHeader.biWidth,
            ((VIDEOINFO *)pmt->pbFormat)->bmiHeader.biHeight);

    return m_pFilter->GetDevice()->SetSourceRectangle(&rcSrc);
}

/*  Queue up these samples */
STDMETHODIMP CMpeg1PacketInputPin::ReceiveMultiple (
    IMediaSample **ppSamples,
    long nSamples,
    long *nSamplesProcessed)
{
    CAutoLock lck(m_pLock);
    HRESULT hr;

    if (m_bFlushing) {
        return S_FALSE;
    }

    FILTER_STATE State;
    m_pFilter->GetState(INFINITE, &State);

    if (State != State_Stopped) {

        // Send the request to the worker

        DbgLog((LOG_TRACE, 4, TEXT("CMpeg1PacketInputPin::ReceiveMultiple - %d samples"),
                nSamples));
        hr = m_pFilter->QueueSamples(m_iStream, ppSamples, nSamples, nSamplesProcessed);
    } else {
        DbgLog((LOG_ERROR, 2, TEXT("Rejecting packet in stopped state")));
        hr = E_INVALIDARG;
    }

    return hr;
}

/*  Queue up this sample

    if we want to keep the sample we must AddRef() it
    (COM ref counting rules for 'in' parameters).  This is done
    in the constructor for CSampleElement.
*/
HRESULT CMpeg1PacketInputPin::Receive(IMediaSample *pSample)
{
    long nSamplesProcessed;
    return ReceiveMultiple(&pSample, 1, &nSamplesProcessed);
}

/*  CMpeg1PacketInputPin::BeginFlush()

    Release()'s all samples queued up so that upstream pins are
    no longer waiting for us
*/
STDMETHODIMP CMpeg1PacketInputPin::BeginFlush()
{
    CAutoLock lck(m_pLock);
    CBaseInputPin::BeginFlush();

    /*  This call to BeginFlush clears everything out */
    return m_pFilter->BeginFlush(m_iStream);
}
STDMETHODIMP CMpeg1PacketInputPin::EndFlush()
{
    CAutoLock lck(m_pLock);
    HRESULT hr = CBaseInputPin::EndFlush();
    if (SUCCEEDED(hr) && m_StreamType == MpegVideoStream) {
        return m_pFilter->m_OverlayPin->EndFlush();
    } else {
        return hr;
    }
}

/*  EndOfStream - pass on downstream for video */
STDMETHODIMP CMpeg1PacketInputPin::EndOfStream()
{
    CAutoLock lck(m_pLock);
    IMediaSample *pSample = EOS_SAMPLE;
    long nSamplesProcessed;

    FILTER_STATE State;
    m_pFilter->GetState(INFINITE, &State);

    if (State != State_Stopped) {
        /*  Private agreement that NULL sample is EOS */
        return m_pFilter->QueueSamples(m_iStream,
                                       &pSample,
                                       1,
                                       &nSamplesProcessed);
    } else {
        return VFW_E_WRONG_STATE;
    }
}

/*  CMpeg1PacketInputPin::ReceiveCanBlock()

    Can we block Receive? - no so return S_FALSE
*/
STDMETHODIMP CMpeg1PacketInputPin::ReceiveCanBlock()
{
    return S_FALSE;
}

/*  Get the sequence header for video */
const BYTE *CMpeg1PacketInputPin::GetSequenceHeader()
{
    ASSERT(m_mt.pbFormat != NULL);
    return MPEG1_SEQUENCE_INFO((MPEG1VIDEOINFO *)m_mt.pbFormat);
}

/*  Say what's connected to what */
STDMETHODIMP CMpeg1PacketInputPin::QueryInternalConnections(
    IPin **apPin,
    ULONG *nPin
)
{
    if (m_StreamType == MpegVideoStream) {
        if (m_pFilter->m_VideoInputPin->IsConnected()) {
            if (*nPin < 1) {
                *nPin = 1;
                return S_FALSE;
            } else {
                *nPin = 1;
                m_pFilter->m_OverlayPin->AddRef();
                apPin[0] = (IPin *)m_pFilter->m_OverlayPin;
                return S_OK;
            }
        } else {
            *nPin = 0;
            return S_OK;
        }
    } else {
        *nPin = 0;
        return S_OK;
    }
}

=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\inputput.cpp ===
// Copyright (c) 1995  Microsoft Corporation.  All Rights Reserved.
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\makefile.inc ===
# NOTE:
# this directory contains a makefile which contains a single line that
# includes the global build process makefile.def. If the
# NTTARGETFILE1 or NTTARGETFILE0 environment
# variable is set then makefile.def includes makefile.inc from the current
# directory. This makefile.inc creates an extra target for nmake to create
# when it is run. NTTARGETFILE0 is built before everything else, and
# NTTARGETFILE1 is built after everything else.

copyfiles:
  @if not exist $(QUARTZ)\bin\$(TARGET_DIRECTORY)      \
    md $(QUARTZ)\bin\$(TARGET_DIRECTORY)
  @if exist obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll  \
    copy obj\$(TARGET_DIRECTORY)\$(TARGETNAME).dll     \
         $(QUARTZ)\bin\$(TARGET_DIRECTORY)\*.*


=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\parse.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    parse.cpp


    Parsing for hardware MPEG-I drivers
*/

#include <streams.h>
#include "driver.h"

CStreamParse::CStreamParse(MPEG_STREAM_TYPE StreamType,
                           const BYTE *pSeqHdr) :
    m_StreamType(StreamType),
    m_pSeqHdr(pSeqHdr)
{
    ASSERT((StreamType == MpegVideoStream) == (pSeqHdr != NULL));
    Reset();
}

void CStreamParse::Reset()
{
    m_bDiscontinuity           = FALSE;
    m_bDiscontinuityInProgress = FALSE;
    m_bEndOfStream             = FALSE;
    m_bSampleProcessed         = FALSE;
    m_iBytes                   = 0;
}

/*  Everything has gone down the pipe so we can accept data again */
void CStreamParse::Empty()
{
    m_bDiscontinuityInProgress = FALSE;
}

/*  Parse sample data

*/

HRESULT CStreamParse::ParseSample(IMediaSample *&pSample,
                                  PBYTE&        pbPacket,
                                  LONG&         lPacketSize,
                                  DWORD&        dwProcessFlags)
{
    pbPacket = NULL;
#ifdef DEBUG
    dwProcessFlags = (DWORD)-1;
#endif
    if (m_bEndOfStream) {
        dwProcessFlags = ProcessComplete;
        return VFW_E_SAMPLE_REJECTED_EOS;
    }

    /*  Are we wanting for a discontiuity to finish? */
    if (m_bDiscontinuityInProgress) {
        dwProcessFlags = 0;
        return S_FALSE;             // Try again later
    }

    /*  See if it's really an EOS */
    if (pSample == EOS_SAMPLE) {
        m_bEndOfStream = TRUE;
        lPacketSize = 0;
        dwProcessFlags = ProcessComplete | ProcessSend;
        return S_OK;
    }

    /*  Is this a discontinuity requiring clearing out of the stream? */
    if (m_bSampleProcessed &&
        !m_bDiscontinuity &&
        S_OK == pSample->IsDiscontinuity()) {
        dwProcessFlags = ProcessSend;
        m_bDiscontinuity = TRUE;
        m_bDiscontinuityInProgress = TRUE;
        dwProcessFlags = ProcessSend;
        return S_OK;
    } else {
        m_bDiscontinuity = FALSE;
    }

    /*  Extract the sample info */
    pSample->GetPointer(&pbPacket);
    lPacketSize = pSample->GetActualDataLength();

    /* Are we up and running yet ? */
    if (m_StreamType == MpegVideoStream && m_iBytes != 4) {
        /*  No - look at the data and see where we've got to */
        long lData;
        PBYTE pbPacketData = SkipToPacketData(pbPacket, lData);
        if (pbPacketData == NULL) {
            dwProcessFlags = ProcessComplete;
            return S_OK;
        }
        PBYTE pbData = pbPacketData;
        while (lData) {
            switch (m_iBytes) {
            case 0:
                if (pbData[0] == 0) {
                    m_iBytes = 1;
                }
                break;
            case 1:
                if (pbData[0] == 0) {
                    m_iBytes = 2;
                } else {
                    m_iBytes = 0;
                }
                break;
            case 2:
                if (pbData[0] == 1) {
                    m_iBytes = 3;
                } else {
                    if (pbData[0] != 0) {
                        m_iBytes = 0;
                    }
                }
                break;
            case 3:
                /*  OK if it's a GOP or a sequence header */
                if (pbData[0] == 0xB8 || pbData[0] == 0xB3) {
                    m_iBytes = 4;
                }
                break;
            }
            lData--;
            pbData++;
            if (m_iBytes == 4) {
                break;
            }
        }

        if (m_iBytes == 4) {
            /*  OK - now we can synthesize the right data :

                ----------------------
                | Packet header      |
                ----------------------
                | Sequence Header    |
                ----------------------
                | GOP start code     |
                ----------------------
                | rest of this packet|
                ----------------------
            */
            int hdrSize = SequenceHeaderSize(m_pSeqHdr);
            if (pbData[-1] == 0xB8) {
                lPacketSize =  pbPacketData - pbPacket +  // Header
                               hdrSize,                   // seq hdr
                               4 +                        // GOP start
                               lData;                     // rest of this packet
            } else {
                lPacketSize =  pbPacketData - pbPacket +  // Header
                               4 +                        // seqhdr start code
                               lData;                     // rest of this packet
            }
            PBYTE pbNewData = new BYTE[lPacketSize];
            if (pbNewData == NULL) {
                dwProcessFlags = ProcessComplete;
                return S_OK;
            }
            /*  Copy the header */
            PBYTE pbDest = pbNewData;
            long l = pbPacketData - pbPacket;
            CopyMemory((PVOID)pbDest, (PVOID)pbPacket, l);

            /*  Set the length in the packet header */
            WORD wLen = (WORD)(lPacketSize - 6);
            *(WORD *)(pbNewData + 4) = (wLen << 8) | (wLen >> 8);
            pbDest += l;
            if (pbData[-1] == 0xB8) {
                /*  Precede Group of pictures with sequence header */
                l = hdrSize;
                CopyMemory((PVOID)pbDest, (PVOID)m_pSeqHdr, l);
                pbDest += l;
                *(UNALIGNED DWORD *)pbDest = DWORD_SWAP(GROUP_START_CODE);
            } else {
                *(UNALIGNED DWORD *)pbDest = DWORD_SWAP(SEQUENCE_HEADER_CODE);
            }
            pbDest += 4;
            l = lData;
            CopyMemory((PVOID)pbDest, (PVOID)pbData, l);
            pbPacket = pbNewData;
            dwProcessFlags = ProcessComplete | ProcessCopied | ProcessSend;
            DbgLog((LOG_TRACE, 3, TEXT("Turned an packet of size %d into 1 of size %d"),
                    pSample->GetActualDataLength(), lPacketSize));
            return S_OK;
        } else {
            /*  Still not there yet */
            dwProcessFlags = ProcessComplete;
            return S_OK;
        }
    } else {
        /*  Just a plain boring old send */
        dwProcessFlags = ProcessComplete | ProcessSend;
        return S_OK;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\parse.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    parse.h

    Parsing for hardware MPEG-I drivers

    From the point of view of this component each for each segment we play
    we start in the 'Reset' state.  When we have found a Group of Pictures
    (GOP) we send that preceded by a sequence header and succeed the
    data in the packet immediately following the GOP.

    Logically (and in reality) a GOP start code can span packets.

*/

class CStreamParse
{
public:
    CStreamParse(MPEG_STREAM_TYPE StreamType, const BYTE *pbSeqHdr);

    //  Return flags from ParseSample
    enum { ProcessCopied   = 0x01,
           ProcessComplete = 0x02,
           ProcessSend     = 0x04
         };
    HRESULT ParseSample(IMediaSample *&pSample,  // in / out the sample
                        PBYTE& pbPacket,         // out - this is the data
                        LONG& lPacketSize,       // size of output to send
                        DWORD& dwProcessFlags    // out - what to do
                      );

    void Reset();
    void Empty();       //  All samples now processed (how do we know?)

private:
    /*  Type */
    MPEG_STREAM_TYPE const m_StreamType;

    /*  Internal state */
    BOOL   m_bSampleProcessed;     // Have any samples been processed
                                   // Since the last reset?
    BOOL   m_bDiscontinuity;       // Are we processing a discontinuity?
    BOOL   m_bDiscontinuityInProgress; // Are we waiting to flush for one?
    BOOL   m_bEndOfStream;         // Are we at end of stream?

    /*  Stuff for getting GOP start code */
    int    m_iBytes;
    const BYTE * const m_pSeqHdr;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\mpegfilt.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

#define INIT_OUR_GUIDS
#include <streams.h>
#include "driver.h"

/*
   mpegfilt.cpp

   This file implements the filter object for rendering MPEG1 packets
*/

/* List of class ids and creator functions for class factory */

CFactoryTemplate g_Templates[1] = {
    {
      L"",
      &CLSID_MPEG1PacketPlayer,
      CMpeg1PacketFilter::CreateInstance
    }
};

int g_cTemplates = sizeof(g_Templates) / sizeof(g_Templates[0]);

/*  This is where new filters get created */

CUnknown * CMpeg1PacketFilter::CreateInstance(
    LPUNKNOWN pUnk,
    HRESULT  *phr)
{
    *phr = S_OK;
    DbgLog((LOG_TRACE, 2, TEXT("Creating new filter instance")));
    CMpeg1PacketFilter *pCFilter = new CMpeg1PacketFilter(
                                            TEXT("MPEG1 core packet filter"),
                                            pUnk,
                                            phr);
    if (pCFilter == NULL) {
        *phr = E_OUTOFMEMORY;
    }

    if (FAILED(*phr)) {
        delete pCFilter;
        return NULL;
    }

    return pCFilter;
}

/*  Return our device */
CMpegDevice* CMpeg1PacketFilter::GetDevice()
{
    return &m_Device;
}

/* Override this to say what interfaces we support and where  - does
   the new base class do this now?
*/


CMpeg1PacketFilter::CMpeg1PacketFilter(TCHAR *pName,
                                       LPUNKNOWN pUnk,
                                       HRESULT * phr) :
    CBaseFilter(pName, pUnk, &m_Lock, CLSID_MPEG1PacketPlayer),
    m_Worker(NULL),
    m_AudioInputPin(NULL),
    m_VideoInputPin(NULL),
    m_OverlayPin(NULL),
    m_pImplPosition(NULL)
{
#ifdef DEBUG
    m_cRef = 0;
#endif

    if (FAILED(*phr)) {
        return;
    }

    if (!m_Device.DeviceExists()) {
        *phr = E_FAIL;
        return;
    }

    m_AudioInputPin = new CMpeg1PacketInputPin(NAME("MPEG1 packet audio input pin"),
                                               this,
                                               MpegAudioStream,
                                               phr,
                                               L"Audio Input");
    if (m_AudioInputPin == NULL) {
        *phr = E_OUTOFMEMORY;
        return;
    }

    if (FAILED(*phr)) {
        return;
    }

    m_VideoInputPin = new CMpeg1PacketInputPin(NAME("MPEG1 packet video input pin"),
                                               this,
                                               MpegVideoStream,
                                               phr,
                                               L"Video Input");
    if (m_VideoInputPin == NULL) {
        *phr = E_OUTOFMEMORY;
        return;
    }
    if (FAILED(*phr)) {
        return;
    }

    m_OverlayPin       = new COverlayOutputPin(NAME("MPEG1 overlay output pin"),
                                               this,
                                               &m_Lock,
                                               pUnk,
                                               phr,
                                               L"Overlay");
    if (m_OverlayPin == NULL) {
        *phr = E_OUTOFMEMORY;
        return;
    }

    if (FAILED(*phr)) {
        return;
    }
}

CMpeg1PacketFilter::~CMpeg1PacketFilter()
{
    DbgLog((LOG_TRACE, 2, TEXT("CMpeg1PacketFilter destructor")));
    delete m_AudioInputPin;
    delete m_VideoInputPin;
    delete m_OverlayPin;
    delete m_pImplPosition;
}

/* This returns the IMediaPosition and IMediaSelection interfaces */

HRESULT CMpeg1PacketFilter::GetMediaPositionInterface(REFIID riid,void **ppv)
{
    if (m_pImplPosition) {
        return m_pImplPosition->NonDelegatingQueryInterface(riid,ppv);
    }

    HRESULT hr = NOERROR;

    /* Create implementation of this dynamically */

    m_pImplPosition = new CPosPassThru(NAME("Mpeg1 packet CPosPassThru"),
                                       GetOwner(),&hr,(IPin *) m_AudioInputPin);
    if (m_pImplPosition == NULL) {
        return E_OUTOFMEMORY;
    }

    if (FAILED(hr)) {
        delete m_pImplPosition;
        m_pImplPosition = NULL;
        return hr;
    }
    return GetMediaPositionInterface(riid,ppv);
}

// override this to say what interfaces we support and where

STDMETHODIMP
CMpeg1PacketFilter::NonDelegatingQueryInterface(REFIID riid, void ** ppv)
{

    /* Is it an interface we know */
    if (riid == IID_IBaseFilter) {
        return GetInterface((LPUNKNOWN) (IBaseFilter *) this, ppv);
    } else if (riid == IID_IMediaFilter) {
        return GetInterface((LPUNKNOWN) (IMediaFilter *) this, ppv);
#if 0
    } else if (riid == IID_IReferenceClock) {
        return GetInterface((LPUNKNOWN) (IReferenceClock *) (CSystemClock *) this, ppv);
#endif
    } else if (riid == IID_IPersist) {
        return GetInterface((LPUNKNOWN) (IPersist *) this, ppv);
    } else if (riid == IID_IMediaPosition || riid == IID_IMediaSeeking) {
        return GetMediaPositionInterface(riid, ppv);
    } else {
        return CUnknown::NonDelegatingQueryInterface(riid, ppv);
    }
}

#if 0
STDMETHODIMP CMpeg1PacketFilter NotifyAllocator(IMemAllocator * pAllocator);
{
    /*  Just try and assert what we'd like */
    long countRequest = MAX_PACKETS;
    long sizeRequest  = MAX_SIZE;

    pAllocator->SetProperties(countRequest,
                                sizeRequest,
                                &countRequest,
                                &sizeRequest);
}
#endif


// map getpin/getpincount for base enum of pins to owner

int CMpeg1PacketFilter::GetPinCount()
{
    return m_VideoInputPin->IsConnected() ? 3 : 2;
}

CBasePin *CMpeg1PacketFilter::GetPin(int n)
{
    switch (n)
    {
        case 0:
            return (CBasePin *)m_AudioInputPin;

        case 1:
            return (CBasePin *)m_VideoInputPin;

        case 2:
            return (CBasePin *)m_OverlayPin;

        default:
            return NULL;
    }
}



STDMETHODIMP CMpeg1PacketFilter::Stop()
{
    CAutoLock lck(&m_Lock);

    FILTER_STATE OldState = m_State;

    HRESULT hr = CBaseFilter::Stop();

    if (FAILED(hr)) {
        return hr;
    }

    if (OldState == State_Stopped) {
        DbgLog((LOG_ERROR,2,TEXT("Stopping while already stopped")));
        return S_OK;
    }

    ASSERT(m_Worker != NULL);

    //  Kill everything to do with playing
    delete m_Worker;
    m_Worker = NULL;

    DbgLog((LOG_TRACE,2,TEXT("Stopped...")));

    //  Base class should have set us to inactive
    ASSERT(m_State == State_Stopped);

    return S_OK;
}

STDMETHODIMP CMpeg1PacketFilter::Pause()
{
    CAutoLock lck(&m_Lock);

    FILTER_STATE OldState = m_State;


    HRESULT hr = CBaseFilter::Pause();

    if (FAILED(hr)) {
        return hr;
    }

    if (OldState == State_Paused) {
        return S_OK;
    }

    DbgLog((LOG_TRACE, 3, TEXT("Pause")));


    if (OldState == State_Stopped)
    {
        HRESULT hr = E_OUTOFMEMORY;
        m_Worker = new CDeviceWorker(this, &hr);
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR,2,TEXT("Failed to go from stopped to paused - hr = %8X"),hr));
            delete m_Worker;
            m_Worker = NULL;
            CBaseFilter::Stop();
            return hr;
        }
    } else {
        ASSERT(OldState == State_Running);
        HRESULT hr = m_Device.Pause();
        return hr;
    }

    /*  I assume we can now start getting media samples from our
        pins!
    */

    return S_OK;
}

STDMETHODIMP CMpeg1PacketFilter::Run(REFERENCE_TIME tStart)
{
    CAutoLock lck(&m_Lock);

    FILTER_STATE OldState = m_State;

    /*  Get the base class to save away the start time */
    HRESULT hr = CBaseFilter::Run(tStart);
    if (FAILED(hr)) {
        return hr;
    }

    if (OldState != State_Running) {
        /*  Set the STC! */
        HRESULT hr = SetSTC();
        if (FAILED(hr)) {
            DbgLog((LOG_ERROR,2,TEXT("Run failed to set the STC!")));
        } else {
            CRefTime tStart;
            HRESULT hr = StreamTime(tStart);
            if (FAILED(hr)) {
                return hr;
            }
            hr = m_Device.Run(tStart);
        }
        if (SUCCEEDED(hr)) {
            m_State = State_Running;
            DbgLog((LOG_TRACE,2,TEXT("Running...")));
        } else {
            DbgLog((LOG_ERROR,2,TEXT("Run request failed")));
            if (OldState == State_Stopped) {
                Stop();
            }
        }
        return hr;
    } else {
        ASSERT(OldState == State_Running);
        DbgLog((LOG_TRACE, 2, TEXT("Receive run while running")));
        return S_OK;
    }
}

void CMpeg1PacketFilter::EndOfStream(MPEG_STREAM_TYPE StreamType)
{
    if (StreamType == MpegVideoStream) {
        m_OverlayPin->GetConnected()->EndOfStream();
    } else {
        /*  Tell the filter graph */
        NotifyEvent(EC_COMPLETE, S_OK, 0);
    }
}

HRESULT CMpeg1PacketFilter::BeginFlush(int iStream)
{
    return m_Worker->BeginFlush(iStream);
}

const BYTE *CMpeg1PacketFilter::GetSequenceHeader()
{
    return m_VideoInputPin->GetSequenceHeader();
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\mpegfilt.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved


class COverlayOutputPin;

class CMpeg1PacketInputPin;

/*
    CMpeg1PacketFilter

    This inherits from CStreamList to make the methods of
    CStreamList directly visible rather than having to expose
    a member of the filter

*/

class CDeviceWorker;  // Forward declare

class CMpeg1PacketFilter;

class CMpeg1PacketFilter : public CBaseFilter, public CStreamList
{

    public:

        CMpeg1PacketFilter(TCHAR *pName, LPUNKNOWN pUnk, HRESULT *phr);
        ~CMpeg1PacketFilter();

        /* Map getpin/getpincount for base enum of pins to owner */

        int GetPinCount();
        CBasePin * GetPin(int n);

        // override state changes to allow derived transform filter
        // to control streaming start/stop
        STDMETHODIMP Stop();
        STDMETHODIMP Pause();
        STDMETHODIMP Run(REFERENCE_TIME tStart);
#ifdef DEBUG
        //  Check ref counting
        STDMETHODIMP_(ULONG) AddRef()
        {
            ASSERT(InterlockedIncrement(&m_cRef) > 0);
            return CBaseFilter::AddRef();
        };
        STDMETHODIMP_(ULONG) Release()
        {
            ASSERT(InterlockedDecrement(&m_cRef) >= 0);
            return CBaseFilter::Release();
        };
#endif
#if 0
        // tell the input pin which allocator the output pin is actually
        // going to use.
        STDMETHODIMP NotifyAllocator(IMemAllocator * pAllocator);
#endif
        /* Override this to say what interfaces we support */

        STDMETHODIMP NonDelegatingQueryInterface(REFIID, void **);

        /* This goes in the factory template table to create new
           instances */

        static CUnknown *CreateInstance(LPUNKNOWN, HRESULT *);

        /*
            Return our device
        */
        CMpegDevice* GetDevice();

        /*  Return our lock */
        CCritSec *GetLock()
        {
            return &m_Lock;
        };

        /*  Flow control functions */

        /*  Send a sample to the filter */
        HRESULT QueueSamples(int iStream, IMediaSample **ppSamples,
                             long nSamples, long *nSamplesProcessed)
        {
            ASSERT(m_Worker != NULL);
            return m_Worker->QueueSamples(iStream,
                                          ppSamples,
                                          nSamples,
                                          nSamplesProcessed);
        };

        HRESULT BeginFlush(int iStream);

        /*  Fast way to find out if we're running */
        BOOL IsRunning()
        {
            return m_State == State_Running;
        };

        /*  Called when an end of stream has really been processed */
        void EndOfStream(MPEG_STREAM_TYPE StreamType);

        /*  Get a pointer to the sequence header */
        const BYTE *GetSequenceHeader();

    private:

        HRESULT GetMediaPositionInterface(REFIID riid,void **ppv);

#ifdef DEBUG
        /*  Trace references */
        LONG m_cRef;
#endif

        /*  Locking */
        CCritSec m_Lock;

        /* Machinery to play the device */

        /* The device worker is only instaniated when we're active */
        CDeviceWorker *          m_Worker;

        /*  Position control */
        CPosPassThru           * m_pImplPosition;
        /*  Pins */

        CMpeg1PacketInputPin   * m_VideoInputPin;
        CMpeg1PacketInputPin   * m_AudioInputPin;
        COverlayOutputPin      * m_OverlayPin;

        /*  Media types for video in and out */
        SIZE                     sizeInput;
        RECT                     rectInput;
        SIZE                     sizeOutput;
        RECT                     rectOutput;

    friend class CMpeg1PacketInputPin;
    friend class COverlayOutputPin;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\sample.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    sample.cpp

    CSampleElement and CSampleQueue classes

*/

#include <streams.h>
#include "driver.h"

/*  CSampleElement  */

/*  Constructor

    The sample if AddRef'd and the size cached

    Note that the size may decrease if we find invalid packets in the
    sample
*/

CSampleElement::CSampleElement(IMediaSample *pSample) :
    m_pSample(pSample),
    m_Next(NULL)
{
    if (m_pSample != EOS_SAMPLE) {
        m_pSample->AddRef();
    }
}

/* Destructor

   The sample is Release'd
*/

CSampleElement::~CSampleElement()
{
    if (m_pSample != EOS_SAMPLE) {
        m_pSample->Release();
    }
}


/* CSampleQueue - queue of CSampleElement */

/*  Constructor of queue - initially empty
*/
CSampleQueue::CSampleQueue(MPEG_STREAM_TYPE StreamType,
                           CMpeg1PacketFilter *pFilter,
                           CMpeg1DeviceQueue *DeviceQueue,
                           int iStream) :
                 m_DeviceQueue(DeviceQueue),
                 m_pFilter(pFilter),
                 m_StreamType(StreamType),
                 m_Head(NULL),
                 m_Position(0),
                 m_Current(NULL),
                 m_iStream(iStream)
{
}

/* Destructor - empty the queue */

CSampleQueue::~CSampleQueue()
{
    /* This is the tough one! - we can only hope everything
       has been shut down in advance!
    */
    for ( CSampleElement *pElement = m_Head;
          pElement != NULL;
        ) {
        CSampleElement *pCurrent = pElement;
        pElement = pElement->m_Next;

        /*  This is where the upstream filter gets back its samples when
            we stop
        */

        delete pCurrent;
    }
}

/*  Queue a sample on the real device if possible, in any case add
    it to our own list
*/

HRESULT CSampleQueue::QueueSamples(IMediaSample **ppSample,
                                   long nSamples,
                                   long *nSamplesProcessed)
{
    for (*nSamplesProcessed = 0;
         *nSamplesProcessed < nSamples;
         (*nSamplesProcessed)++) {
        CSampleElement *pElement = new CSampleElement(ppSample[*nSamplesProcessed]);
        if (pElement == NULL) {
            return E_OUTOFMEMORY;
        }

        /* Add it to the tail */
        for (CSampleElement **pSearch = &m_Head;
             ;
             pSearch = &(*pSearch)->m_Next) {
            if (*pSearch == NULL) {
                *pSearch = pElement;
                break;
            }
        }

        /*  Now try to queue it to the real device */
        if (m_Current == NULL) {
            m_Current = pElement;
        }
    }
    SendSamplesToDevice();
    return S_OK;
}

/*  Try to send some more stuff to the device.
    This can be called by the thread pump or QueueSample.
*/

void CSampleQueue::SendSamplesToDevice()
{
    /*  Send as much data to the device as we can.

        We're not going to bother to batch it here because
        in the normal case there won't be much which is queued
        but not queued on the device so we'd normally only queue
        data from one sample here.
    */

    while (m_Current != NULL) {
        if (!m_DeviceQueue->QueueSamples()) {
            return;
        }
    }
}

/*  The device has completed nSamples samples */

void CSampleQueue::NotifySamples(long nSamples)
{
    ASSERT(m_Head != NULL);

    /* A single notify might complete multiple buffers */

    while (nSamples--) {
        ASSERT(m_Head != m_Current);
        CSampleElement *pElement = m_Head;
        m_Head = m_Head->m_Next;
        delete pElement;
    }
}

/*  Discard the current queue element without processing it */
void CSampleQueue::Discard()
{
    ASSERT(m_Current != NULL);
    CSampleElement **ppElement = &m_Head;
    while ((*ppElement) != m_Current) { ppElement = &(*ppElement)->m_Next; };
    *ppElement = m_Current->m_Next;
    delete m_Current;
    m_Current = *ppElement;
}

/*  Go on to the next */
void CSampleQueue::Advance()
{
    ASSERT(m_Current != NULL);
    m_Current = m_Current->m_Next;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\sample.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    Definition of CSampleQueue and CSampleElement

    This class wraps IMediaSamples (passed to the input pins) so
    they can be processed internally.

*/

//  Special sample denotes EOS
#define EOS_SAMPLE ((IMediaSample *)-1L)


class CMpeg1DeviceQueue;

class CMpeg1PacketFilter;

class CSampleElement;

class CSampleQueue;

class CSampleElement
{
    public:
        CSampleElement(IMediaSample *pSample);
        ~CSampleElement();
        friend CSampleQueue;
        friend CMpeg1DeviceQueue;
        BOOL IsEOS() { return m_pSample == EOS_SAMPLE; };

    private:

        IMediaSample         * m_pSample;
        CSampleElement       * m_Next;
} ;

class CSampleQueue
{
    private:
        CSampleElement          * m_Head;       // Head of the list
        CSampleElement          * m_Current;    // One we're currently sending
        long                      m_Position;   // How much of the first sample has been
                                               // processed.
        CMpeg1DeviceQueue * const m_DeviceQueue;// Associated device queue
        long                      m_Queued;     // How many bytes are queued?
        MPEG_STREAM_TYPE    const m_StreamType;
        CMpeg1PacketFilter *const m_pFilter;
        const int                 m_iStream;    // Which stream we are

    public:
        CSampleQueue(MPEG_STREAM_TYPE StreamType,
                     CMpeg1PacketFilter *pFilter,
                     CMpeg1DeviceQueue *DeviceQueue,
                     int iStream);
        ~CSampleQueue();

        /*  New sample received */

        HRESULT QueueSamples(IMediaSample **ppSamples,
                             long nSamples,
                             long *nSamplesProcessed);

        /*  Try to send some more stuff to the device.
            This can be called by the thread pump or QueueSample.
        */

        void SendSamplesToDevice();

        /*  Called when nBytes have been completed by the device
        */

        void NotifySamples(long nSamples);

        /*  Queue manipulation */
        IMediaSample *Next() {
            return m_Current == NULL ? NULL : m_Current->m_pSample;
        };
        void Discard();
        void Advance();
} ;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\stream.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    stream.cpp

    CMpeg1Stream and CStreamList definitions

    CMpeg1Stream :

        Data is written into the stream by the input pin (QueueSample) and
        pulled off to be written to the device by the worker thread.

        When the filter moves from stopped to paused Allocate() is
        called

        When the filter moves to stopped Free() is called

    CStreamList :
        Just a list of CMpeg1Stream objects
*/

#include <streams.h>
#include "driver.h"

/*  CMpeg1Stream */

CMpeg1Stream::CMpeg1Stream() :
     m_SampleQueue(NULL),
     m_DeviceQueue(NULL),
     m_Allocated(FALSE)
{
}

CMpeg1Stream::~CMpeg1Stream()
{
    ASSERT(m_SampleQueue == NULL && m_DeviceQueue == NULL);
}

//  Input pin calls this for when it receives a new sample

HRESULT CMpeg1Stream::QueueSamples(IMediaSample **ppSample,
                                   long nSamples,
                                   long *nSamplesProcessed)
{
    ASSERT(m_Allocated);
    return m_SampleQueue->QueueSamples(ppSample, nSamples, nSamplesProcessed);
} ;


//  Worker thread calls this when something completes (ie
//  when the stream event becomes signalled

void CMpeg1Stream::NotifyCompletion()
{
    ASSERT(m_Allocated);
    DbgLog((LOG_TRACE, 4, TEXT("CMpeg1Stream::NotifyCompletion - type %s"),
           m_StreamType == MpegAudioStream ? TEXT("Audio") : TEXT("Video")));
    m_DeviceQueue->Complete();
}

//  Flush a stream

HRESULT CMpeg1Stream::Flush()
{
    return m_DeviceQueue->Flush();
}

//  Get the event for the worker thread to wait on

HANDLE CMpeg1Stream::NotifyHandle() const
{
    ASSERT(m_Allocated);
    HANDLE hEvent;
    hEvent = m_DeviceQueue->NotifyHandle();
    ASSERT(hEvent != NULL);
    return hEvent;
}

HRESULT CMpeg1Stream::Allocate(CMpegDevice *Device, CMpeg1PacketFilter *pFilter, int iStream)
{
    ASSERT(!m_Allocated);
    HRESULT hr = E_OUTOFMEMORY;
    m_iStream = iStream;
    m_DeviceQueue = new CMpeg1DeviceQueue(Device,
                                          m_StreamType,
                                          pFilter,
                                          &hr);
    if (FAILED(hr)) {
        return hr;
    }

    m_SampleQueue = new CSampleQueue(m_StreamType, pFilter, m_DeviceQueue, m_iStream);

    if (m_SampleQueue == NULL) {
        hr = E_OUTOFMEMORY;
        delete m_DeviceQueue;
    } else {
        m_DeviceQueue->SetSampleQueue(m_SampleQueue);
        m_Allocated = TRUE;
    }


    return hr;
}

void CMpeg1Stream::Free()
{
    //  This can be called if we're not allocated (specifically
    //  when we're freeing - but note that delete is well defined
    //  for NULL)

    delete m_SampleQueue;
    m_SampleQueue = NULL;
    delete m_DeviceQueue;
    m_DeviceQueue = NULL;
    m_Allocated = FALSE;
}

HRESULT CMpeg1Stream::SetSTC()
{

#if 0
    if (!m_IsMasterReferenceClock)  {

#endif
        return m_DeviceQueue->SetSTC();

#if 0
    } else {
        return S_OK;
    }
#endif
}

/* CStreamList */


/*  Constructor and Destructor */
CStreamList::CStreamList() : m_nStreams(0) {};
CStreamList::~CStreamList()
{
    /*  Clean up the streams */
    Free();
};

/*  Operator overload */
CMpeg1Stream& CStreamList::operator[] (int i)
{
    return m_Streams[i];
}

/*  More comprehensible function to access stream i */
CMpeg1Stream& CStreamList::GetStream(int i)
{
    return m_Streams[i];
}

int CStreamList::NumberOfStreams()
{
    return m_nStreams;
}

/* Add a new stream - returns new stream id */
int CStreamList::AddStream(MPEG_STREAM_TYPE StreamType)
{
    ASSERT(m_nStreams < MAX_WORKER_STREAMS);
    m_Streams[m_nStreams].m_StreamType = StreamType;
    return m_nStreams++;
} ;

/* Set the STC for all streams which have samples queued up */
HRESULT CStreamList::SetSTC()
{
    for (int i=0; i < m_nStreams; i++) {
        HRESULT hr = m_Streams[i].SetSTC();

        /*  Note that SetSTC can return S_FALSE - this is OK */

        if (FAILED(hr)) {
            return hr;
        }
    }
    return S_OK;
} ;

HRESULT CStreamList::StreamQueueSamples(int iStream,
                                        IMediaSample **ppSample,
                                        long nSamples,
                                        long *nSamplesProcessed)
{
    return m_Streams[iStream].QueueSamples(ppSample, nSamples, nSamplesProcessed);
}

/*  Stop and pause the device.

    This must be done from the device worker thread.

    The samples get completed a bit later when we service the completions
    a bit later so this call can't be used to synchronize with them but
    for Flush we only care that we cancelled them all
*/

HRESULT CStreamList::Flush(int iStream)
{
    return m_Streams[iStream].Flush();
}

/* Set up all the streams for transfer (happens on Pause()) */
HRESULT CStreamList::Allocate(CMpeg1PacketFilter *pFilter)
{
    for (int i = 0; i < m_nStreams; i++) {
        HRESULT hr = m_Streams[i].Allocate(&m_Device, pFilter, i);
        if (FAILED(hr)) {
            Free();
            return hr;
        }
    }
    return S_OK;
} ;

void CStreamList::Free()
{
    for (int i = 0; i < m_nStreams; i++) {
        m_Streams[i].Free();
    }
} ;

=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\stream.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    stream.h

    CMpeg1Stream and CStreamList definitions

    CMpeg1Stream :

        Data is written into the stream by the input pin (QueueSample) and
        pulled off to be written to the device by the worker thread.

        When the filter moves from stopped to paused Allocate() is
        called

        When the filter moves to stopped Free() is called

    CStreamList :
        Just a list of CMpeg1Stream objects
*/

/*  Current design can only cope with a limited number of streams
    (NOTE however that this limit is 63!)
*/
#define MAX_INPUT_PINS 2

#define MAX_WORKER_STREAMS \
(MAX_INPUT_PINS<MAXIMUM_WAIT_OBJECTS-1?MAX_INPUT_PINS:MAXIMUM_WAIT_OBJECTS-1)

class CStreamList;

class CMpeg1PacketFilter;

/* CMpeg1Stream */

class CMpeg1Stream
{
    private:
        MPEG_STREAM_TYPE    m_StreamType;
        CSampleQueue      * m_SampleQueue;
        CMpeg1DeviceQueue * m_DeviceQueue;
        BOOL                m_Allocated;
        int                 m_iStream;

    public:

        CMpeg1Stream();

        ~CMpeg1Stream();

        /*  Access to Stream members */
        friend CStreamList;


        //  Input pin calls this for when it receives a new sample

        HRESULT QueueSamples(IMediaSample **ppSample,
                             long nSamples,
                             long *nSamplesProcessed);

        //  Worker thread calls this when something completes (ie
        //  when the stream event becomes signalled

        void NotifyCompletion();

        //  Flush a stream

        HRESULT Flush();

        //  Get the event for the worker thread to wait on

        HANDLE NotifyHandle() const;

        HRESULT Allocate(CMpegDevice *Device, CMpeg1PacketFilter *pFilter, int iStream);

        void Free();

        HRESULT SetSTC();
} ;

/*  CStreamList  */

class CStreamList
{
    private:
        CMpeg1Stream m_Streams[MAX_WORKER_STREAMS];
        int m_nStreams;

    protected:
        CMpegDevice         m_Device;

    public:
        /*  Constructor and Destructor */
        CStreamList();
        ~CStreamList();

        /*  Access to Stream members */
        friend CMpeg1Stream;

        /*  Operator overload */
        CMpeg1Stream& operator[] (int i);

        /*  More comprehensible function to access stream i */
        CMpeg1Stream& GetStream(int i);

        int NumberOfStreams();

        /* Add a new stream - returns new stream id */
        int AddStream(MPEG_STREAM_TYPE StreamType);

        /* Set the STC for all streams which have samples queued up */
        HRESULT SetSTC();

        HRESULT StreamQueueSamples(int iStream, IMediaSample **ppSample,
                                   long nSamples, long *nSamplesProcessed);

        /*  Flush the device */
        HRESULT Flush(int iStream);

        /* Set up all the streams for transfer (happens on Pause()) */
        HRESULT Allocate(CMpeg1PacketFilter *pFilter);

        void Free();
} ;

=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\statepse\audio.h ===
// Copyright (c) 1995 - 1998  Microsoft Corporation.  All Rights Reserved.


/*  Audio stream parsing */
class CAudioParse : public CStream
{
public:
    CAudioParse(CStreamList *pList, UCHAR uStreamId) :
        CStream(pList, uStreamId),
        m_nBytes(0)
    {
    };
    HRESULT GetMediaType(CMediaType *cmt, BOOL bPayload);
    HRESULT ProcessType(AM_MEDIA_TYPE const *pmt);

    BOOL ParseBytes(PBYTE pData,
                            LONG lLen,
                            LONGLONG llPos,
                            BOOL bHasPts,
                            CSTC stc);

    /*  Find out the 'current' time */
    CSTC GetStreamTime(BOOL bHasPts, CSTC stc);

    /*  Override SetState */
    void SetState(Stream_State);

private:
    /*  Check if transition is complete */
    void CheckComplete(BOOL bForce);

    /*  Check an audio header */
    BOOL ParseHeader();

    void Discontinuity()
    {
        m_nBytes = 0;
        m_bDiscontinuity = TRUE;
    };

    void Init();
    BOOL CurrentTime(CSTC& stc);


private:
    int   m_nBytes;

    BYTE  m_bData[4];
    BYTE  m_bHeader[4];

    /*  Timing stuff */
    BOOL  m_bFrameHasPTS;
    BOOL  m_bGotTime;
    CSTC  m_stcFrame;
    CSTC  m_stcAudio;
    CSTC  m_stcFirst;
    LONG  m_lTimePerFrame;

    /*  current position */
    LONGLONG m_llPos;
};

/*  Do basic checks on a audio header - note this doesn't check the
    sync word
*/

BOOL CheckAudioHeader(PBYTE pbData);

/*  Compute the sample rate for audio */
LONG SampleRate(PBYTE pbData);
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\worker.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    worker.h

    CDeviceWorker definitions

    Define the thread and control for the 'playing' environment

    Samples are passed by the input pin to be 'played' by the worker
    thread.
*/

class CMpeg1PacketFilter;

class CDeviceWorker : public CAMThread
{
    /*  CAMThread methods */

    DWORD ThreadProc();

    /*  New methods and definitions    */

    private:

        CMpeg1PacketFilter * const m_pFilter;

        /* Parameters to thread */
        enum { RequestInvalid = 0,
               RequestInitialize,
               RequestTerminate,
               RequestQueueSample,
               RequestFlush,
               RequestSetSTC } ;

        CCritSec             m_Lock;     // Protect these variables
        int                  m_iStream;  // set for QueueSample request
        IMediaSample      ** m_ppSample; // set for QueueSample request
        long                 m_nSamples;
        long               * m_nSamplesProcessed;

        /*  Our objects */

    private:
        /*  Worker thread functions */
        HRESULT ThreadInitialize();
        HRESULT ThreadTerminate();
        HRESULT ThreadQueueSample();
        HRESULT ThreadFlush();

    public:

        CDeviceWorker(CMpeg1PacketFilter * pFilter, HRESULT *phr) :
            CAMThread(),
            m_pFilter(pFilter)
        {
            if (!Create()) {
                *phr = E_OUTOFMEMORY;
            }

            *phr = CallWorker(RequestInitialize);
            if (FAILED(*phr)) {
                Close();
            }
        } ;

        ~CDeviceWorker()
        {
            if (ThreadExists()) {
                HRESULT rc = CallWorker(RequestTerminate);
                ASSERT(rc == S_OK);
            }
        } ;

        /*  Override CallWorker to return an HRESULT */

        HRESULT CallWorker(DWORD dwParam)
        {
            return (HRESULT)CAMThread::CallWorker(dwParam);
        } ;


        /*  Pass a media sample to the worker thread to queue up
            on the real device
        */

        HRESULT QueueSamples(int iStream, IMediaSample **ppSample,
                             long nSamples, long *nSamplesProcessed);

        HRESULT BeginFlush(int iStream);
        HRESULT SetSTC()
        {
            return CallWorker(RequestSetSTC);
        } ;
} ;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\statepse\mpegprse.cpp ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*
    Parse the MPEG-I stream and send out samples as we go

    This parser is a bit weird because it is called rather than calls.
    The result is that we have to be very careful about what we do
    when we get to the 'end'- ie we haven't got enough bytes to make sense
    of the structure we're trying to parse (eg we can't see a whole system
    header or packet).

    Basically there are 2 cases:

    1.  End of data, not EOS - OK - try again later
    2.  End of data, EOS     - Error, invalid data

    The basic call is to ParseBytes which returns the number of bytes
    processed.

    When ParseBytes thinks it hasn't got enough bytes to complete
    the current structure it returns the number of bytes it has
    successfully parsed - a number less than the number of bytes
    it was passed.  This does not mean there is an error unless
    ParseBytes was called with the last bytes of a stream when it is up to
    the caller of ParseBytes to detect this.
*/

#include <streams.h>
#include <mmreg.h>
#include <mpegtype.h>          // Packed type format

#include <mpegdef.h>           // General MPEG definitions
#include <parseerr.h>          // Error codes

#include <mpgtime.h>
#include <mpegprse.h>          // Parsing
#include <videocd.h>           // Video CD special parsing
#include <seqhdr.h>
#include "video.h"
#include "audio.h"

const GUID * CBasicParse::ConvertToLocalFormatPointer( const GUID * pFormat )
{
    ASSERT(this);
    /*  Translate the format (later we compare pointers, not what they point at!) */
    if (pFormat == 0) {
        pFormat = TimeFormat();
    } else
    if (*pFormat == TIME_FORMAT_BYTE) {
        pFormat = &TIME_FORMAT_BYTE;
    } else
    if (*pFormat == TIME_FORMAT_FRAME) {
        pFormat = &TIME_FORMAT_FRAME;
    } else
    if (*pFormat == TIME_FORMAT_MEDIA_TIME) {
        pFormat = &TIME_FORMAT_MEDIA_TIME;  // For now
    }

    return pFormat;
}


/*  CBasicParse methods */
/*  Time Format support - default to only time */
HRESULT CBasicParse::IsFormatSupported(const GUID *pTimeFormat)
{
    if (*pTimeFormat == TIME_FORMAT_MEDIA_TIME) {
        return S_OK;
    } else {
        return S_FALSE;
    }
};

/*  Default setting the time format */
HRESULT CBasicParse::SetFormat(const GUID *pFormat)
{
    //  Caller should have checked
    ASSERT(S_OK == IsFormatSupported(pFormat));
    m_Stop = Convert(m_Stop, m_pTimeFormat, pFormat);
    m_pTimeFormat = ConvertToLocalFormatPointer(pFormat);
    return S_OK;
};

HRESULT CBasicParse::ConvertTimeFormat
( LONGLONG * pTarget, const GUID * pTargetFormat
, LONGLONG    Source, const GUID * pSourceFormat
)
{
    pTargetFormat = ConvertToLocalFormatPointer(pTargetFormat);
    pSourceFormat = ConvertToLocalFormatPointer(pSourceFormat);

    // Assume the worst...
    HRESULT hr = E_INVALIDARG;

    if ( IsFormatSupported(pTargetFormat) == S_OK
         && IsFormatSupported(pSourceFormat) == S_OK )
    {
        *pTarget = Convert( Source, pSourceFormat, pTargetFormat );
        hr = NOERROR;
    }

    return hr;
}


/*  Time format conversions
    Returns llOld converted from OldFormat to NewFormat
*/
LONGLONG CMpeg1SystemParse::Convert(LONGLONG llOld,
                                    const GUID *OldFormat,
                                    const GUID *NewFormat)
{
    if (OldFormat == NewFormat) {
        return llOld;
    }
    LONGLONG llTime;
    if (OldFormat == &TIME_FORMAT_MEDIA_TIME) {
        llTime = llOld;
    } else if (OldFormat == &TIME_FORMAT_FRAME) {
        ASSERT(m_pVideoStream != NULL);

        /*  m_pVideoStream->m_iFirstSequence is the first frame counted
            in the movie time-based duration

            So, time for 1 frame is
                (duration in time) / (number of frames counted in duration)

            Round UP when going to time

            To avoid rounding errors convert up 1ms unless it's the first frame
        */
        const int iOffset = m_pVideoStream->m_iFirstSequence;
        if (llOld >= m_dwFrameLength) {
            llTime = m_rtDuration;
        } else
        if (llOld <= 0) {
            llTime = 0;
        } else {
            llTime = m_rtVideoStartOffset +

                     //  Our adjusted duration doesn't include the
                     //  time of the last frame so scale using 1
                     //  frame less than the frame length
                     llMulDiv(llOld - iOffset,
                              m_rtDuration - m_rtVideoStartOffset - m_rtVideoEndOffset,
                              m_dwFrameLength - iOffset - 1,
                              m_dwFrameLength - iOffset - 2);
            if (llOld != 0) {
                llTime += UNITS / MILLISECONDS;

            }
        }
    } else {
        ASSERT(OldFormat == &TIME_FORMAT_BYTE);
        llTime = llMulDiv(llOld,
                          m_rtDuration,
                          m_llTotalSize,
                          m_llTotalSize/2);
    }

    /*  Now convert the other way */
    if (NewFormat == &TIME_FORMAT_FRAME) {
        ASSERT(m_pVideoStream != NULL);

        /*  Round DOWN when going to frames */
        const int iOffset = m_pVideoStream->m_iFirstSequence;

        //  Our adjusted duration of the video doesn't include the
        //  time of the last frame so scale using 1
        //  frame less than the frame length
        llTime = llMulDiv(llTime - m_rtVideoStartOffset,
                          m_dwFrameLength - iOffset - 1,
                          m_rtDuration - m_rtVideoStartOffset - m_rtVideoEndOffset,
                          0) + iOffset;
        if (llTime < 0) {
            llTime = 0;
        }
        if (llTime > m_dwFrameLength) {
            llTime = m_dwFrameLength;
        }
    } else if (NewFormat == &TIME_FORMAT_BYTE) {
        llTime = llMulDiv(llTime,
                          m_llTotalSize,
                          m_rtDuration,
                          m_rtDuration/2);
    }
    if (llTime < 0) {
        llTime = 0;
    }
    return llTime;
}

/*  Set the time format for MPEG 1 system stream */
HRESULT CMpeg1SystemParse::SetFormat(const GUID *pFormat)
{
    //  Caller should have checked
    ASSERT(S_OK == IsFormatSupported(pFormat));

    /*  Set start and stop times based on the old values */
    m_Stop = Convert(m_Stop, m_pTimeFormat, pFormat);
    REFERENCE_TIME rtStart;
    const GUID *pOldFormat = m_pTimeFormat;
    m_pTimeFormat = pFormat;
    Seek(m_llSeek, &rtStart, pOldFormat);
    return S_OK;
};

#ifdef DEBUG
    #define CONTROL_LEVEL 2
#endif

/*  Constructor and destructor */
CMpeg1SystemParse::CMpeg1SystemParse() : m_bVideoCD(FALSE)
{
}

CMpeg1SystemParse::~CMpeg1SystemParse()
{
    /*  Free the streams */
    while (m_lStreams.GetCount() != 0) {
        delete m_lStreams.RemoveHead();
    }
}

/*
    Init

    Initialize the parser:

        (re) initializes the parser.  Deletes all streams previously present.

    Parameters:

        llSize - total size of file (if Seekable, otherwise 0)

        bVideoCD - if the file is in VideoCD format

        bSeekable - if the file is seekable

    Returns

        S_OK
*/

HRESULT CMpeg1SystemParse::Init(LONGLONG llSize, BOOL bSeekable, CMediaType const *pmt)
{
    CBasicParse::Init(llSize, bSeekable, pmt);

    m_FailureCode          = S_OK;
    m_llPos                = 0;
    DbgLog((LOG_TRACE, 4, TEXT("Parse state <initializing>")));
    m_lSystemHeaderSize    = 0;
    m_MuxRate              = 0;
    m_bGotStart            = FALSE;
    m_llStartTime          = 0;
    m_llStopTime           = 0x7FFFFFFFFFFFFFFF;  // Init to never stop
    m_stcStartPts          = 0;
    m_bGotDuration         = FALSE;
    m_bConcatenatedStreams = FALSE;
    m_stcTSOffset          = (LONGLONG)0;
    m_pVideoStream         = NULL;
    m_dwFrameLength        = (DWORD)-1;
    m_bItem                = false;
    m_rtVideoStartOffset   = 0;
    m_rtVideoEndOffset     = 0;
    InitStreams();

    /*  Process input media type */
    if (pmt != NULL &&
        pmt->formattype == FORMAT_MPEGStreams &&
        pmt->cbFormat >= sizeof(AM_MPEGSYSTEMTYPE)) {
        AM_MPEGSYSTEMTYPE *pSystem = (AM_MPEGSYSTEMTYPE *)pmt->Format();
        AM_MPEGSTREAMTYPE *pMpegStream = pSystem->Streams;
        for (DWORD i = 0; i < pSystem->cStreams; i++) {
            /*  Add the stream to our list */
            DWORD dwStreamId = pMpegStream->dwStreamId;
            CStream *pStream = AddStream((UCHAR)dwStreamId);
            if (pStream == NULL) {
                return E_OUTOFMEMORY;
            }

            /*  Let the stream try to initialize itself using the type */
            AM_MEDIA_TYPE mt = pMpegStream->mt;
            mt.pbFormat = pMpegStream->bFormat;
            HRESULT hr = pStream->ProcessType(&mt);
            if (FAILED(hr)) {
                return hr;
            }
            pMpegStream = AM_MPEGSTREAMTYPE_NEXT(pMpegStream);
        }
        m_MuxRate = pSystem->dwBitRate / (50 * 8);
    }

    return S_OK;
}

/*
    FindEnd

        Sets the state to searching for the end.  Only valid when
        the data is seekable.

        Generates a call back to seek the source to 1 second before
        the end.
*/

HRESULT CMpeg1SystemParse::FindEnd()
{
    DbgLog((LOG_TRACE, CONTROL_LEVEL, TEXT("CMpeg1SystemParse::FindEnd()")));
    ASSERT(m_bSeekable);

    m_State = State_FindEnd;

    /*  Get all the streams ready */
    SetState(State_FindEnd);

    /*  Go to near the end (end - 1.5 seconds to) */
    LONGLONG llPos = m_llTotalSize - m_MuxRate * 75;
    if (llPos < 0) {
        llPos = 0;
    }

    /*  Seek the reader  - what if this fails? */
    m_pNotify->SeekTo(llPos);

    Discontinuity();

    return S_OK;
}

/*  Return the file duration time in MPEG units
*/
LONGLONG CMpeg1SystemParse::Duration()
{
    ASSERT(m_State != State_Initializing &&
           (m_State != State_FindEnd || IsComplete()));
    ASSERT(m_bSeekable);
    return m_llDuration;
}

/*
    SetStop

        Set the stop time to tTime.
*/
HRESULT CMpeg1SystemParse::SetStop(LONGLONG llStop)
{
    if (m_pTimeFormat == &TIME_FORMAT_MEDIA_TIME) {
        REFERENCE_TIME tTime = llStop;

        DbgLog((LOG_TRACE, CONTROL_LEVEL, TEXT("CMpeg1SystemParse::SetStop(%s)"),
                (LPCTSTR)CDisp(llStop)));
        if (CRefTime(tTime) == CRefTime(m_Stop)) {
            return S_OK;
        }
        m_Stop = tTime;

        m_llStopTime = ReferenceTimeToMpeg(tTime);
        if (m_llStopTime > Duration()) {
            DbgLog((LOG_ERROR, 2, TEXT("Stop time beyond end!")));
            m_llStopTime = Duration();
            CheckStop();
            return S_OK;
        }
        m_llStopTime += StartClock();
        DbgLog((LOG_TRACE, 3, TEXT("Stop time in MPEG units is %s"),
                (LPCTSTR)CDisp(m_llStopTime)));

        if (m_State == State_Run || m_State == State_Stopping) {
            CheckStop();
        }
    } else {
        /*  The stop time for these formats will immediately be
            followed by a set start time because IMediaSelection
            can't set the stop time independently so we just cache the
            value here
        */
        ASSERT(m_pTimeFormat == &TIME_FORMAT_BYTE ||
               m_pTimeFormat == &TIME_FORMAT_FRAME);
        m_Stop = llStop;
    }
    return S_OK;
}

/*
     Replay the same data.  We have to ASSUME that our
     data supplier knows where to restart sending data from because
     we already told them (and anyway they may not be seekable)
*/
HRESULT CMpeg1SystemParse::Replay()
{
    /*  Find out what we were doing and do it again (!) */
    DbgLog((LOG_TRACE, 3, TEXT("CMpeg1SystemParse::Replay")));
    SetState(m_State == State_Stopping ? State_Run : m_State);

    /*  Data not expected to tally with old */
    Discontinuity();
    return S_OK;
}

/*  Return the start time in reference time units or our best guess */
REFERENCE_TIME CMpeg1SystemParse::GetStartTime()
{
    if (m_pTimeFormat == &TIME_FORMAT_MEDIA_TIME) {
        return m_Start;
    }
    if (m_pTimeFormat == &TIME_FORMAT_FRAME) {
        return MpegToReferenceTime(m_llStartTime - StartClock());
    }

    /*  For other time formats we don't know the start time position to
        offset samples from until we see the first PTS
    */
    ASSERT(m_pTimeFormat == &TIME_FORMAT_BYTE);
    if (!m_bGotStart) {
        /*  Guess */
        return llMulDiv(m_Start,
                        m_rtDuration,
                        m_llTotalSize,
                        0);
    } else {

        /*  Return value of start time vs real start time */
        return MpegToReferenceTime(
                   m_llStartTime - (LONGLONG)m_stcRealStartPts
               );
    }
};

/*  Return the stop time in reference time units or our best guess */
REFERENCE_TIME CBasicParse::GetStopTime()
{
    return Convert(m_Stop, m_pTimeFormat, &TIME_FORMAT_MEDIA_TIME);
};

/*  Get the total file duration for Video CD */
HRESULT CVideoCDParse::GetDuration(
    LONGLONG *llDuration,
    const GUID *pTimeFormat
)
{
    if (m_pTimeFormat == &TIME_FORMAT_BYTE) {
        *llDuration =
            llMulDiv(m_llTotalSize - VIDEOCD_HEADER_SIZE,
                     VIDEOCD_DATA_SIZE,
                     VIDEOCD_SECTOR_SIZE,
                     0);
        return S_OK;
    } else {
        return CMpeg1SystemParse::GetDuration(llDuration, pTimeFormat);
    }
}

/*  Get the total file duration */
HRESULT CMpeg1SystemParse::GetDuration(
    LONGLONG *llDuration,
    const GUID *pTimeFormat
)
{
    if (!m_bGotDuration) {
        return E_FAIL;
    }
    if (pTimeFormat == &TIME_FORMAT_MEDIA_TIME) {
        *llDuration = m_rtDuration;
        return S_OK;
    } else {
        if (pTimeFormat == &TIME_FORMAT_FRAME) {
            if (m_dwFrameLength == (DWORD)-1) {
                return VFW_E_NO_TIME_FORMAT_SET;
            }
            *llDuration = m_dwFrameLength;
            return S_OK;
        }
    }
    ASSERT(pTimeFormat == &TIME_FORMAT_BYTE);
    *llDuration = m_llTotalSize;
    return S_OK;
};

/*  Seek VideoCD */
HRESULT CVideoCDParse::Seek(LONGLONG llSeek,
                            REFERENCE_TIME *prtStart,
                            const GUID *pTimeFormat)
{
    if (pTimeFormat == &TIME_FORMAT_BYTE) {
        /*  Recompute the seek based on sectors etc */
        llSeek = (llSeek / VIDEOCD_DATA_SIZE) * VIDEOCD_SECTOR_SIZE +
                 llSeek % VIDEOCD_DATA_SIZE +
                 VIDEOCD_HEADER_SIZE;
    }
    return CMpeg1SystemParse::Seek(llSeek, prtStart, pTimeFormat);
}

/*
     Seek to a new position

     This effectively generates the seek to the notify object and
     saves the seek information in

         m_llSeek     - seek position
         m_pTimeFormat - time format used for seek
*/
HRESULT CMpeg1SystemParse::Seek(LONGLONG llSeek,
                                REFERENCE_TIME *prtStart,
                                const GUID *pTimeFormat)
{
    if (pTimeFormat != m_pTimeFormat) {
        llSeek = Convert(llSeek, pTimeFormat, m_pTimeFormat);
    }
    m_llSeek = llSeek;
    LONGLONG llSeekPosition;
    if (m_pTimeFormat == &TIME_FORMAT_BYTE) {
        llSeekPosition = llSeek;
        *prtStart = llMulDiv(llSeek,
                             m_rtDuration,
                             m_llTotalSize,
                             m_llTotalSize/2);
    } else {
        DbgLog((LOG_TRACE, CONTROL_LEVEL, TEXT("CMpeg1SystemParse::Seek(%s)"),
                (LPCTSTR)CDisp(CRefTime(llSeek))));
        if (llSeek < 0) {
            return E_UNEXPECTED;
        }

        LONGLONG llDuration = Duration();
        LONGLONG llStreamTime;

        if (m_pTimeFormat == &TIME_FORMAT_FRAME) {

            /*  Also return the 'where are we now' information */
            *prtStart = Convert(llSeek,
                                &TIME_FORMAT_FRAME,
                                &TIME_FORMAT_MEDIA_TIME);

        } else {
            ASSERT(m_pTimeFormat == &TIME_FORMAT_MEDIA_TIME);
            /*  Get the time in MPEG time units */
            *prtStart = llSeek;
        }
        llStreamTime = ReferenceTimeToMpeg(*prtStart);

        ASSERT(llDuration != 0);

        if (llStreamTime > llDuration) {
            llStreamTime = llDuration;
        }
        /*  Is is somewhere we could seek to ?
            (NOTE - allow some leeway at the end or we may only find audio)
        */
        if (llStreamTime > llDuration - (MPEG_TIME_DIVISOR / 2)) {
           DbgLog((LOG_ERROR, 2, TEXT("Trying to seek past end???")));
           llStreamTime = llDuration - (MPEG_TIME_DIVISOR / 2);
        }

        ASSERT(Initialized());

        /*  Cheap'n nasty seek */
        llSeekPosition = llMulDiv(llStreamTime - MPEG_TIME_DIVISOR,
                                  m_llTotalSize,
                                  llDuration,
                                  0);

        if (llSeekPosition < 0) {
            llSeekPosition = 0;
        }
    }

    /*  Seek the reader  - what if this fails? */
    m_pNotify->SeekTo(llSeekPosition);

    return S_OK;
}

/*  Set seeking state

    Here we pick up the information dumped by Seek() :

        m_llSeek            -  Where to seek to
        m_pTimeFormat        -  What time format to use

    For BYTE based seeking we don't do any prescan etc

    For Frame based seeking we don't actually generate any frame number
    in the samples - we just arrange to try to send the right data so
    that the downstream filter can pick out the frames it needs.
*/
void CMpeg1SystemParse::SetSeekState()
{
    /*  Cache new information */
    m_Start      = m_llSeek;

    /*  What we do depends on what time format we're using */
    if (m_pTimeFormat == &TIME_FORMAT_BYTE) {
        m_bGotStart = FALSE;
        SetState(State_Seeking);
        SetState(State_Run);
        m_pNotify->Complete(TRUE, 0, 0);
        return;
    } else {
        /*  Fix up any byte seeking hackery */
        m_bGotStart = TRUE;
        m_stcStartPts = m_stcRealStartPts;

        REFERENCE_TIME rtStart;
        if (m_pTimeFormat == &TIME_FORMAT_MEDIA_TIME) {
            rtStart = m_Start;
            if (rtStart < 0) {
                rtStart = 0;
            }
            m_llStopTime = ReferenceTimeToMpeg(m_Stop);
        } else {
            ASSERT(m_pTimeFormat == &TIME_FORMAT_FRAME);

            /*  Subtract half a frame in case we miss one !
                Also allow for the fact that some frames are before
                time 0 (!)
            */
            rtStart = Convert(m_Start,
                              &TIME_FORMAT_FRAME,
                              &TIME_FORMAT_MEDIA_TIME);

            /*  Add on an extra half frame just to make sure we don't miss one! */
            m_llStopTime = ReferenceTimeToMpeg(
                               Convert(m_Stop,
                                       &TIME_FORMAT_FRAME,
                                       &TIME_FORMAT_MEDIA_TIME) +
                               m_pVideoStream->m_seqInfo.tPictureTime / 2);
            if (m_llStopTime > m_llDuration) {
                m_llStopTime = m_llDuration;
            }
        }

        DbgLog((LOG_TRACE, CONTROL_LEVEL, TEXT("CMpeg1SystemParse::SetSeekState(%s)"),
                (LPCTSTR)CDisp(CRefTime(rtStart))));

        /*  Get the time in MPEG time units */
        LONGLONG llStreamTime = ReferenceTimeToMpeg(rtStart);

        LONGLONG llDuration = Duration();
        ASSERT(llDuration != 0);

        if (llStreamTime > llDuration) {
            llStreamTime = llDuration;
        }
        /*  We're going to roughly the right place (I hope!) */
        m_llStartTime = llStreamTime + StartClock();
        SeekTo(m_llStartTime - MPEG_TIME_DIVISOR);

        if (m_llStopTime > Duration()) {
            DbgLog((LOG_ERROR, 2, TEXT("Stop time beyond end!")));
            m_llStopTime = Duration();
        }
        m_llStopTime += StartClock();
        DbgLog((LOG_TRACE, 3, TEXT("Stop time in MPEG units is %s"),
                (LPCTSTR)CDisp(m_llStopTime)));
    }
    /*  Seek all the streams */
    Discontinuity();
    m_State = State_Seeking;
    SetState(State_Seeking);
    DbgLog((LOG_TRACE, 4, TEXT("Parse state <seeking>")));
}

HRESULT CMpeg1SystemParse::Run()
{
    DbgLog((LOG_TRACE, CONTROL_LEVEL, TEXT("CMpeg1SystemParse::Run()")));
    /*  Set all the embedded streams to run */
    if (m_State != State_Run) {
        m_State = State_Run;
        SetState(State_Run);
    }
    Discontinuity();
    return S_OK;
}

HRESULT CMpeg1SystemParse::EOS()
{
    DbgLog((LOG_TRACE, CONTROL_LEVEL, TEXT("CMpeg1SystemParse::EOS()")));
    /*  Just call EOS in all the streams in turn */
    POSITION pos = m_lStreams.GetHeadPosition();
    while (pos) {
        m_lStreams.GetNext(pos)->EOS();
    }
    return m_bCompletion ? S_OK : S_FALSE;
}

/*  Check to see if the current time is near the stop time
*/
void CMpeg1SystemParse::CheckStop()
{
    if (m_State == State_Run) {

        /*  Stream time must be offset if we're in concatenated stream mode */
        if ((m_bConcatenatedStreams &&
             m_llStopTime - m_llCurrentClock - (LONGLONG)m_stcTSOffset <=
                 MPEG_TIME_DIVISOR
            ) ||
            (!m_bConcatenatedStreams &&
             m_llStopTime - m_llCurrentClock <= MPEG_TIME_DIVISOR)
           ) {
            DbgLog((LOG_TRACE, 3, TEXT("Setting stopping state near end of play")));
            m_State = State_Stopping;
            SetState(State_Stopping);
        }
    }
}

/*
      IsComplete

          Are we complete ?  (ie have we completed the last state transition?)
*/
BOOL CMpeg1SystemParse::IsComplete()
{
    if (m_State == State_Initializing && m_nValid == 2 ||
        m_State != State_Initializing && m_nValid == m_lStreams.GetCount()) {
        return TRUE;
    } else {
        return FALSE;
    }
}

/*
    return the 'i'th stream
*/
CBasicStream * CMpeg1SystemParse::GetStream(int i)
{
    POSITION pos = m_lStreams.GetHeadPosition();
    while (pos) {
        CStream *pStream = m_lStreams.GetNext(pos);
        if (i-- == 0) {
            return pStream;
        }
    }
    return NULL;
}

/*  Add a stream to our list of streams */
BOOL CMpeg1SystemParse::AddStream(CStream *pStream)
{
    return m_lStreams.AddTail(pStream) != NULL;
}

/*  Remove a stream from our list of streams */
BOOL CMpeg1SystemParse::RemoveStream(CStream *pStream)
{
    if (pStream == m_pVideoStream) {
        m_pVideoStream = NULL;
    }
    return m_lStreams.Remove(m_lStreams.Find((CStream *)pStream)) != NULL;
}

/*  Return start time in non-wrapped MPEG units */
CSTC CMpeg1SystemParse::GetStart()
{
    return m_llStartTime;
}

/*  Return stop time in non-wrapped MPEG units */
CSTC CMpeg1SystemParse::GetStop()
{
    return m_llStopTime;
}

LONGLONG CMpeg1SystemParse::GetPlayLength()
{
    return m_Stop - m_Start;
}



/*  Get the buffer size for the reader - 2 seconds */
LONG CMpeg1SystemParse::GetBufferSize()
{
    ASSERT(m_MuxRate != 0);
    LONG lBufferSize = m_MuxRate * (50 * 2);
    if (lBufferSize < (MAX_MPEG_PACKET_SIZE * 2)) {
        lBufferSize = MAX_MPEG_PACKET_SIZE * 2;
    }
    return lBufferSize;
}

/*  Short cut to stream list parse error routine */
void CMpeg1SystemParse::ParseError(DWORD dwError)
{
    /*  Start all over again */
    switch (m_State) {
    case State_Initializing:
        InitStreams();
        break;
    default:
        break;
    }
    if (!m_bDiscontinuity) {
        /*  Note a possible discontinuity */
        Discontinuity();

        /*  Call back for notification */
        ASSERT(m_pNotify != NULL);
        m_pNotify->ParseError(0xFF, m_llPos, dwError);
    }
}

/*  Return format support for system stream and video CD */
HRESULT CMpeg1SystemParse::IsFormatSupported(const GUID *pTimeFormat)
{
    if (*pTimeFormat == TIME_FORMAT_BYTE ||
        *pTimeFormat == TIME_FORMAT_FRAME && m_dwFrameLength != (DWORD)-1 ||
        *pTimeFormat == TIME_FORMAT_MEDIA_TIME) {
        return S_OK;
    } else {
        return S_FALSE;
    }
};

/*
    Parse the data in an MPEG system stream pack header
*/

LONG CMpeg1SystemParse::ParsePack(PBYTE pData, LONG lBytes)
{
    DbgLog((LOG_TRACE, 4, TEXT("Parse pack %d bytes"), lBytes));
    /*  Note that we can validly return if there are less than
        a pack header + a start code because the stream must end
        with a start code (the end code) if it is to be valid
    */
    if (lBytes < PACK_HEADER_LENGTH + 4) {
        return 0;
    }

    /*  Additional length of system header (or 0) */
    LONG lParse;
    DWORD dwNextCode = *(UNALIGNED DWORD *)&pData[PACK_HEADER_LENGTH];

    DbgLog((LOG_TRACE, 4, TEXT("Next start code after pack is 0x%8.8X"),
           DWORD_SWAP(dwNextCode)));

    /*  Check if this is going to be followed by a system header */
    if (dwNextCode == DWORD_SWAP(SYSTEM_HEADER_START_CODE)) {
        lParse = ParseSystemHeader(pData + PACK_HEADER_LENGTH,
                                   lBytes - PACK_HEADER_LENGTH);
        if (lParse == 4) {
            /*  Don't even bother - it's an error */
            return 4;
        } else {
            if (lParse == 0) {
                /*  Try again when we've got more data */
                return 0;
            }
        }
    } else {
        if ((dwNextCode & 0xFFFFFF) != 0x010000) {
            /*  Stop now - it's an error */
            DbgLog((LOG_TRACE, 4, TEXT("Parse pack invalid next start code 0x%8.8X"),
                   DWORD_SWAP(dwNextCode)));
            return 4;
        }
        lParse = 0;
    }

    /*  Check pack */


    if ((pData[4] & 0xF1) != 0x21 ||
        (pData[6] & 0x01) != 0x01 ||
        (pData[8] & 0x01) != 0x01 ||
        (pData[9] & 0x80) != 0x80 ||
        (pData[11] & 0x01) != 0x01) {
        DbgLog((LOG_TRACE, 4, TEXT("Parse pack invalid marker bits")));
        ParseError(Error_InvalidPack | Error_InvalidMarkerBits);
        return 4;    // Try again!
    }

    CSTC Clock;
    if (!GetClock(pData + 4, &Clock)) {
        return 4;
    }

    /*  Note - for VideoCD the mux rate is the rate for the whole file,
        including the sector header junk etc so we don't need to
        munge it when using it in our position calculations
    */
    m_MuxRate     = ((LONG)(pData[9] & 0x7F) << 15) +
                    ((LONG)pData[10] << 7) +
                    ((LONG)pData[11] >> 1);
    LARGE_INTEGER liClock;
    liClock.QuadPart = Clock;
    DbgLog((LOG_TRACE, 4, TEXT("Parse pack clock 0x%1.1X%8.8X mux rate %d bytes per second"),
           liClock.HighPart & 1, liClock.LowPart, m_MuxRate * 50));

    /*  Update our internal clock - this will wrap correctly provided the
        current clock is correct
    */
    SetStreamTime(Clock, m_llPos + 8);

    if (m_bConcatenatedStreams) {
        if (!m_bTimeContiguous) {
            m_stcTSOffset =  llMulDiv(m_llPos,
                                      m_llDuration,
                                      m_llTotalSize,
                                      0) -
                             (m_llCurrentClock - m_llFirstClock);
            DbgLog((LOG_TRACE, 1,
                   TEXT("Time was discontiguous - setting offset to %s"),
                   (LPCTSTR)CDisp((double)(LONGLONG)m_stcTSOffset / 90000)));
            m_bTimeContiguous = TRUE;
        }
    }

    /*  If we're near the stop time it's time to kick the parsers back in
    */
    CheckStop();

    return PACK_HEADER_LENGTH + lParse;
}

LONG CMpeg1SystemParse::ParseSystemHeader(PBYTE pData, LONG lBytes)
{
    DbgLog((LOG_TRACE, 4, TEXT("ParseSystemHeader %d bytes"), lBytes));

    /*  Check if we already know the system header for this stream.
        VideoCD can contain different system headers for the different
        streams however

        Since other files seem to allow for this too there's nothing
        to do but allow for multiple different system headers!
    */
#if 0
    if (m_lSystemHeaderSize != 0) {

        /*  They must ALL be identical - see 2.4.5.6 or ISO-1-11172
            UNFORTUNATELY Video-CD just pretends it is two streams
            so there are at least 2 versions of the system header (!)
        */

        if (lBytes < m_lSystemHeaderSize) {
            return 0;
        } else {
            if (memcmp(pData, &m_SystemHeader, m_lSystemHeaderSize) == 0) {
                return m_lSystemHeaderSize;
            } else {
                /*  Well, of course they're not all the same (!) */
                DbgLog((LOG_ERROR, 3,
                        TEXT("System header different - size %d, new 0x%8.8X, old 0x%8.8X!"),
                             m_lSystemHeaderSize, (DWORD)pData, &m_SystemHeader));
                ParseError(Error_DifferentSystemHeader);
                return 4;
            }
        }
    }
#endif
    if (lBytes < SYSTEM_HEADER_BASIC_LENGTH) {
        return 0;
    }

    LONG lHdr = ((LONG)pData[4] << 8) + (LONG)pData[5] + 6;

    /*  Check system header */
    if (lHdr < 12 ||
        (pData[6] & 0x80) != 0x80 ||
        // (pData[8] & 0x01) != 0x01 ||  Robocop1(1) fails this test
        (pData[10] & 0x20) != 0x20 ||
         pData[11] != 0xFF) {
        DbgLog((LOG_ERROR, 3, TEXT("System header invalid marker bits")));
        ParseError(Error_InvalidSystemHeader | Error_InvalidMarkerBits);
        return 4;
    }

    if (lBytes < lHdr) {
        return 0;
    }

    /*  Pull out the streams and check the header length */
    LONG lPosition = 12;
    BYTE bStreams[0x100 - 0xB8];
    ZeroMemory((PVOID)bStreams, sizeof(bStreams));
    while (lPosition < lBytes - 2) {
        if (pData[lPosition] & 0x80) {
            if (lPosition <= sizeof(m_SystemHeader) - 3) { /* There IS a limit of 68 streams */
                /*  Check marker bits */
                if ((pData[lPosition + 1] & 0xC0) != 0xC0) {
                    DbgLog((LOG_ERROR, 3, TEXT("System header bad marker bits!")));
                    ParseError(Error_InvalidSystemHeaderStream |
                               Error_InvalidMarkerBits);
                    return 4;
                }

                /*  Check the stream id is valid - check for repeats? */
                if (pData[lPosition] != AUDIO_GLOBAL &&
                    pData[lPosition] != VIDEO_GLOBAL &&
                    pData[lPosition] < 0xBC) {
                    DbgLog((LOG_ERROR, 3, TEXT("System header bad stream id!")));
                    ParseError(Error_InvalidSystemHeaderStream |
                               Error_InvalidStreamId);
                    return 4;
                }
                if (m_State == State_Initializing) {
                    if (pData[lPosition] >= AUDIO_STREAM) {
                        AddStream(pData[lPosition]);
                    }
                }

                /*  Don't allow repeats in the list */
                if (bStreams[pData[lPosition] - 0xB8]++) {
                    // Repeat
                    DbgLog((LOG_ERROR, 3, TEXT("System header stream repeat!")));
                    ParseError(Error_InvalidSystemHeaderStream |
                               Error_DuplicateStreamId);
                    return 4;
                }
            }
            lPosition += 3;
        } else {
            break;
        }
    }
    if (lHdr != lPosition) {
        DbgLog((LOG_ERROR, 3, TEXT("System header bad size!")));
        ParseError(Error_InvalidSystemHeader |
                   Error_InvalidLength);
        return 4;
    }
    /*  VideoCD can have multiple different system headers but we'll
        ignore this for now (!)
    */
    CopyMemory((PVOID)&m_SystemHeader, (PVOID)pData, lHdr);
    m_lSystemHeaderSize = lHdr;

    DbgLog((LOG_TRACE, 4, TEXT("System header length %d"), lHdr));

    return lHdr;
}

/*  Parse a packet */
LONG CMpeg1SystemParse::ParsePacket(DWORD dwStartCode,
                                    PBYTE pData,
                                    LONG lBytes)
{
    // The minimum packet header size is 6 bytes.  3 bytes for
    // the start code, 1 byte for the stream ID and 2 byte for
    // the packet length.
    const LONG MIN_PACKET_HEADER_SIZE = 6;

#ifdef DEBUG
    if (m_bVideoCD) {
        if (!IsAudioStreamId((BYTE)dwStartCode) &&
            !IsVideoStreamId((BYTE)dwStartCode)) {
            DbgLog((LOG_ERROR, 2, TEXT("VideoCD contained packet from stream 0x%2.2X"),
                    (BYTE)dwStartCode));
        }
    }
#endif
    DbgLog((LOG_TRACE, 4, TEXT("Parse packet %d bytes"), lBytes));
    /*  Send it to the right stream */
    if (lBytes < MIN_PACKET_HEADER_SIZE) {
        return 0;
    }

    /*  Find the length */
    LONG lLen = ((LONG)pData[4] << 8) + (LONG)pData[5] + MIN_PACKET_HEADER_SIZE;
    DbgLog((LOG_TRACE, 4, TEXT("Packet length %d bytes"), lLen));
    if (lLen > lBytes) {
        return 0;
    }

    /*  Pull out PTS if any */
    BOOL bHasPts = FALSE;
    LONG lHeaderSize = MIN_PACKET_HEADER_SIZE;
    CSTC stc = 0;

    if (dwStartCode != PRIVATE_STREAM_2) {
        int lPts = 6;
        for (;;) {
            if (lPts >= lLen) {
                ParseError(Error_InvalidPacketHeader |
                           Error_InvalidLength);
                return 4;
            }

            if (pData[lPts] & 0x80) {
                /*  Stuffing byte */
                if (pData[lPts] != 0xFF) {
                    ParseError(Error_InvalidPacketHeader |
                               Error_InvalidStuffingByte);
                    return 4;
                }
                lPts++;
                continue;
            }

            /*  Check for STD (nextbits == '01') -
                we know the next bit is 0 so check the next one after that
            */
            if (pData[lPts] & 0x40) { // STD stuff
                lPts += 2;
                continue;
            }

            /*  No PTS - normal case */
            if (pData[lPts] == 0x0F) {
                lHeaderSize = lPts + 1;
                break;
            }

            if ((pData[lPts] & 0xF0) == 0x20 ||
                (pData[lPts] & 0xF0) == 0x30) {


                /*  PTS or PTS and DTS */
                lHeaderSize = (pData[lPts] & 0xF0) == 0x20 ? lPts + 5 :
                                                             lPts + 10;
                if (lHeaderSize > lLen) {
                    ParseError(Error_InvalidPacketHeader |
                               Error_InvalidHeaderSize);
                    return 4;
                }
                if (!GetClock(pData + lPts, &stc)) {
                    return 4;
                }
                bHasPts = TRUE;
                if (!m_bGotStart) {
                    if (m_bConcatenatedStreams) {
                        if (m_bTimeContiguous) {
                            m_stcStartPts = stc + m_stcTSOffset;
                            m_llStartTime = StartClock();
                            m_bGotStart = TRUE;
                        }
                    } else {
                        m_stcStartPts = stc;
                        /*  Make sure we have a valid position to play from */
                        m_llStartTime = StartClock();
                        DbgLog((LOG_TRACE, 2, TEXT("Start PTS = %s"), (LPCTSTR)CDisp(m_stcStartPts)));
                        m_bGotStart = TRUE;
                    }
                }
                break;
            } else {
                ParseError(Error_InvalidPacketHeader | Error_InvalidType);
                return 4;
                break;
            }
        }
    }


    /*  If we're not parsing video CD then there should be a valid
        start code after this packet.

        If this is a video CD we're not prone to seek errors anyway
        unless the medium is faulty.
    */
    if (!m_bVideoCD) {
        if (lLen + 3 > lBytes) {
            return 0;
        }
        /*  Check (sort of) for valid start code
            The next start code might not be straight away so we may
            only see 0s
        */
        if ((pData[lLen] | pData[lLen + 1] | (pData[lLen + 2] & 0xFE)) != 0) {
            DbgLog((LOG_ERROR, 2, TEXT("Invalid code 0x%2.2X%2.2X%2.2X after packet"),
                   pData[lLen], pData[lLen + 1], pData[lLen + 2]));
            ParseError(Error_InvalidPacketHeader | Error_InvalidStartCode);
            return 4;
        }
    }

    /*  Handle concatenated streams :

        1.  Don't do anything until we've got a pack time to sync to
        2.  Offset all times to the timestamp offset
    */

    if (m_bConcatenatedStreams) {
        if (!m_bTimeContiguous) {
            return lLen;
        }
        if (bHasPts) {
            stc = stc + m_stcTSOffset;
        }
    }

    if (lLen > lHeaderSize) {
        /*  Pass the packet on to the stream handler */
        SendPacket((BYTE)dwStartCode,
                   pData,
                   lLen,
                   lHeaderSize,
                   bHasPts,
                   stc);
    }

    /*  Ate the packet */

    /*  Clear the discontinuity flag - this means if we find another
        error we'll call the filter graph again
    */
    m_bDiscontinuity = FALSE;
    return lLen;
}

BOOL CMpeg1SystemParse::GetClock(PBYTE pData, CSTC *Clock)
{
    BYTE  Byte1 = pData[0];
    DWORD Word2 = ((DWORD)pData[1] << 8) + (DWORD)pData[2];
    DWORD Word3 = ((DWORD)pData[3] << 8) + (DWORD)pData[4];

    /*  Do checks */
    if ((Byte1 & 0xE0) != 0x20 ||
        (Word2 & 1) != 1 ||
        (Word3 & 1) != 1) {
        DbgLog((LOG_TRACE, 2, TEXT("Invalid clock field - 0x%2.2X 0x%4.4X 0x%4.4X"),
            Byte1, Word2, Word3));
        ParseError(Error_InvalidClock | Error_InvalidMarkerBits);
        return FALSE;
    }

    LARGE_INTEGER liClock;
    liClock.HighPart = (Byte1 & 8) != 0;
    liClock.LowPart  = (DWORD)((((DWORD)Byte1 & 0x6) << 29) +
                       (((DWORD)Word2 & 0xFFFE) << 14) +
                       ((DWORD)Word3 >> 1));

    *Clock = liClock.QuadPart;

    return TRUE;
}

void CMpeg1SystemParse::Discontinuity()
{
    DbgLog((LOG_TRACE, 1, TEXT("CMpeg1SystemParse::Discontinuity")));

    POSITION pos = m_lStreams.GetHeadPosition();
    m_bDiscontinuity = TRUE;
    m_bTimeContiguous = FALSE;
    while (pos) {
        m_lStreams.GetNext(pos)->Discontinuity();
    }
}

/*  CVideoCDParse::ParseBytes

    This is a cheap wrapping for parsing a buffer full of VideoCD
    sectors
*/
LONG CVideoCDParse::ParseBytes(LONGLONG llPos,
                               PBYTE pData,
                               LONG lBytes,
                               DWORD dwFlags)
{
    LONG lOrigBytes = lBytes;

    /*  Make sure we're starting past the header */
    if (llPos < VIDEOCD_HEADER_SIZE) {
        LONG lDiff = VIDEOCD_HEADER_SIZE - (LONG)llPos;
        llPos += lDiff;
        pData += lDiff;
        lBytes -= lDiff;
    }
    LONG lRem = (LONG)((llPos - VIDEOCD_HEADER_SIZE) % VIDEOCD_SECTOR_SIZE);
    if (lRem != 0) {
        llPos += VIDEOCD_SECTOR_SIZE - lRem;
        lBytes -= VIDEOCD_SECTOR_SIZE - lRem;
        pData += VIDEOCD_SECTOR_SIZE - lRem;
    }
    /*  Should now be pointing at valid data (!) */
    while (lBytes >= VIDEOCD_SECTOR_SIZE && !IsComplete()) {
        VIDEOCD_SECTOR *pSector = (VIDEOCD_SECTOR *)pData;

        /*  Check for autopause */
        if (IS_AUTOPAUSE(pSector) && !m_bDiscontinuity) {
            /*  Set our current position correctly and send
                EndOfStream
            */
        }
        if (IS_MPEG_SECTOR(pSector)) {
            if (m_State == State_Initializing) {
                if (pSector->SubHeader[1] != 1) {
                    if (pSector->SubHeader[1] == 2 ||
                        pSector->SubHeader[1] == 3) {
                        m_bItem = true;
                    }
                }
            }
            LONG lRc = CMpeg1SystemParse::ParseBytes(
                            llPos + FIELD_OFFSET(VIDEOCD_SECTOR, UserData[0]),
                            pSector->UserData,
                            sizeof(pSector->UserData),
                            0);
            DbgLog((LOG_TRACE, 4, TEXT("Processed %d bytes in video CD sector"),
                    lRc));
        } else {
            if (m_State == State_Initializing) {
                /*  Check if this is a sector at all */
                if (*(UNALIGNED DWORD *)&pSector->Sync[0] != 0xFFFFFF00 ||
                    *(UNALIGNED DWORD *)&pSector->Sync[4] != 0xFFFFFFFF ||
                    *(UNALIGNED DWORD *)&pSector->Sync[8] != 0x00FFFFFF)
                {
                    m_pNotify->Complete(FALSE, 0, 0);
                    return 0;
                }
            }
        }
        pData += VIDEOCD_SECTOR_SIZE;
        lBytes -= VIDEOCD_SECTOR_SIZE;
        llPos += VIDEOCD_SECTOR_SIZE;
    }

    if (lBytes < 0) {
        return lOrigBytes;
    } else {
        return lOrigBytes - lBytes;
    }
}

/*  CMpeg1SystemParse::ParseBytes

    This is the basic parsing routine

    It is a loop which extracts a start code (possibly seeking) and
    then parses the data after the start code until we run out of
    bytes
*/
LONG CMpeg1SystemParse::ParseBytes(LONGLONG llPos,
                                   PBYTE pData,
                                   LONG lBytes,
                                   DWORD dwFlags)
{
    if (llPos != m_llPos) {
        if (!m_bDiscontinuity && !m_bVideoCD) {
            DbgLog((LOG_ERROR, 1, TEXT("Unexpected discontinuity!!!")));

            /*  We don't really know where we are       */
            m_bDiscontinuity = TRUE;

            /*  Tell the streams about the discontinuity */
            Discontinuity();
        }
        m_llPos = llPos;
    }

    /*  Discard rounding due to byte seeking and stop at the end */
    LONG lBytesLeft = lBytes;
    if (m_pTimeFormat == &TIME_FORMAT_BYTE) {
        if (!m_bGotStart && llPos < m_Start) {
            LONG lOffset = (LONG)(m_Start - llPos);
            if (lOffset > lBytes) {
                DbgLog((LOG_ERROR, 1, TEXT("Way off at start !")));
            }
            llPos = m_Start;
            lBytesLeft -= lOffset;
            pData += lOffset;
        }
        if (llPos + lBytesLeft >= m_Stop) {
            if (llPos >= m_Stop) {
                m_pNotify->Complete(TRUE, 0, 0);
                return 0;
            }
            lBytesLeft = (LONG)(m_Stop - llPos);
        }
    }

    DbgLog((LOG_TRACE, 4, TEXT("ParseBytes %d bytes"), lBytes));
    for (; lBytesLeft >= 4; ) {
        /*  First task is to find a start code.
            If we're not seeking and we're not at one it's an error
        */
        DWORD dwStart = *(UNALIGNED DWORD *)pData;
        DbgLog((LOG_TRACE, 4, TEXT("Start code 0x%8.8X"), DWORD_SWAP(dwStart)));
        if ((dwStart & 0x00FFFFFF) == 0x00010000) {
            dwStart = DWORD_SWAP(dwStart);
            if (VALID_SYSTEM_START_CODE(dwStart)) {
                /*  Got a start code for the system stream */
            } else {
                if (m_bVideoCD) {
                    break;
                }

                /*  4th byte might be 0 so just ignore 3 bytes */
                ParseError(Error_Scanning | Error_InvalidStartCode);
                pData += 3;
                m_llPos += 3;
                lBytesLeft -= 3;
                continue;
            }
        } else {
            if (m_bVideoCD) {
                break;
            }
            if ((dwStart & 0x00FFFFFF) != 0) {
                ParseError(Error_Scanning | Error_NoStartCode);
            }

            /*  Find a new 0 */
            PBYTE pDataNew;
            pDataNew = (PBYTE)memchrInternal((PVOID)(pData + 1), 0, lBytesLeft - 1);
            if (pDataNew == NULL) {
                m_llPos += lBytes - lBytesLeft;
                lBytesLeft = 0;
                break;
            }
            lBytesLeft -= (LONG)(pDataNew - pData);
            m_llPos += pDataNew - pData;
            pData = pDataNew;
            continue;
        }


        LONG lParsed;

        /*  Got a start code - is it a packet start code? */
        if (VALID_PACKET(dwStart)) {
            lParsed = ParsePacket(dwStart,
                                  pData,
                                  lBytesLeft);
        } else {
            /*  See if we recognize the start code */
            switch (dwStart)
            {
                case ISO_11172_END_CODE:
                    DbgLog((LOG_TRACE, 4, TEXT("ISO 11172 END CODE")));
                    /*  What if we find a bogus one while seeking? */
                    if (!((dwFlags & Flags_EOS) && lBytesLeft == 4)) {
                        DbgLog((LOG_ERROR, 1, TEXT("ISO 11172 END CODE in middle of stream")));
                    }
                    lParsed = 4;
                    break;

                case PACK_START_CODE:
                    lParsed = ParsePack(pData, lBytesLeft);
                    break;

                /*  Don't parse random system headers unless they're
                    immediately preceded by pack headers
                */
                case SYSTEM_HEADER_START_CODE:
                    /*  Just skip it */
                    if (lBytesLeft < 6 ||
                        lBytesLeft < 6 + pData[5] + 256 * pData[4]) {
                        lParsed = 0;
                    } else {
                        lParsed = 6 + pData[5] + 256 * pData[4];
                    }
                    break;

                default:
                    ParseError(Error_Scanning | Error_InvalidStartCode);
                    /*  Last byte might be 0 so only go on 3 */
                    lParsed = 3;
            }
        }
        /*  If we're stuck and need some more data get out */
        if (lParsed == 0) {
            break;
        }
        m_llPos += lParsed;
        lBytesLeft -= lParsed;
        pData     += lParsed;

        /*  Once the current action is complete just stop */
        if (VALID_PACKET(dwStart) && IsComplete()) {
            break;
        }
    }

    /*  Don't waste too much time searching for stuff during initialization */
    if (m_State == State_Initializing) {
        if (IsComplete()) {
            m_pNotify->Complete(TRUE, 0, 0);
        } else {

            /*  Hack for infogrames whose audio starts 8 seconds (!)
                into their file
            */
            if (llPos > 200000 && m_lStreams.GetCount() == m_nValid) {
                m_pNotify->Complete(FALSE, 0, 0);
            }
        }
    }

    /*  There are less than 4 bytes left or we're stuck - go and wait for some
        more!

        Note that if there isn't any more the caller will detect both
        End of Stream and the fact that we haven't eaten the data which
        is enough to conclude the data was bad
    */
    return lBytes - lBytesLeft;
}

/*  Initialize stream variables, freeing any currently existing pins
*/
void CMpeg1SystemParse::InitStreams()
{
    m_nValid = 0;
    m_nPacketsProcessed = 0;
    m_lSystemHeaderSize = 0;

    /*  Free all the pins */
    while (m_lStreams.GetCount() != 0) {
        /*  I hope the ref counts are 0 !*/
        CStream *pStream = m_lStreams.RemoveHead();
        delete pStream;
    }
}

/*  Process a packet

    Returns FALSE if no need to process rest of buffer
*/
BOOL CMpeg1SystemParse::SendPacket(UCHAR    uStreamId,
                                   PBYTE    pbPacket,
                                   LONG     lPacketSize,
                                   LONG     lHeaderSize,
                                   BOOL     bHasPts,
                                   CSTC     stc)
{
    m_nPacketsProcessed++;

    POSITION pos = m_lStreams.GetHeadPosition();
    CStream *pStream = NULL;

    /*  Look for our stream */
    while (pos) {
        pStream = m_lStreams.GetNext(pos);
        if (pStream->m_uNextStreamId == uStreamId) {
            if (pStream->m_uNextStreamId != pStream->m_uStreamId) {
                pStream->Discontinuity();
                pStream->m_uStreamId = pStream->m_uNextStreamId;
            }
            break;
        } else {
            pStream = NULL;
        }
    }

    /*  If we're initializing, we haven't seen a packet for this stream
        before and we've had a valid system header then add the
        stream
    */
    if (pStream == NULL &&
        m_State == State_Initializing &&
        m_lSystemHeaderSize != 0) {
        pStream = AddStream(uStreamId);
    }
    if (pStream == NULL) {
        DbgLog((LOG_TRACE, 2, TEXT("Packet for stream 0x%2.2X not processed"),
               uStreamId));
        return TRUE;
    } else {
        DbgLog((LOG_TRACE, 4, TEXT("Packet for stream 0x%2.2X at offset %s"),
                uStreamId, (LPCTSTR)CDisp(m_llPos)));
    }

    BOOL bPlaying = pStream->IsPlaying(m_llPos, lPacketSize);

    /*  We only parse at the start and the end.
        After we have parsed the start correctly the stream calls
        complete() so eventually we stop stream parsing
    */
    if (!IsComplete() && !pStream->m_bRunning &&
        (bPlaying || m_State != State_Run && m_State != State_Stopping)) {

         /*  This generates notifications of interesting
             events (like Seeking failed or succeeded!)

             For concatenated streams we do the hack of prentending
             the position is the last pack position so that the
             stream completes on a pack start when seeking
         */
         pStream->ParseBytes(pbPacket + lHeaderSize,
                             lPacketSize - lHeaderSize,
                             m_bConcatenatedStreams && m_State == State_Seeking ?
                                 m_llPositionForCurrentClock - 8:
                                 m_llPos,
                             bHasPts,
                             stc);
    } else {
        DbgLog((LOG_TRACE, 4, TEXT("Not processing packet for stream %2.2X"),
                uStreamId));
    }

    if ((m_State == State_Run || m_State == State_Stopping) && bPlaying) {
        HRESULT hr;
        if (pStream->IsPayloadOnly()) {
            hr = m_pNotify->QueuePacket(pStream->m_uDefaultStreamId,
                                        pbPacket + lHeaderSize,
                                        lPacketSize - lHeaderSize,
                                        SampleTime(CurrentTime(pStream->CurrentSTC(bHasPts, stc))),
                                        bHasPts);
        } else {
            hr = m_pNotify->QueuePacket(pStream->m_uDefaultStreamId,
                                        pbPacket,
                                        lPacketSize,
                                        SampleTime(CurrentTime(pStream->CurrentSTC(bHasPts, stc))),
                                        bHasPts);
        }
        if (FAILED(hr)) {
            DbgLog((LOG_TRACE, 2,
                   TEXT("Failed to queue packet to output pin - stream 0x%2.2X, code 0x%8.8X"),
                   uStreamId, hr));
            /*  Don't try sending any more */
            pStream->Complete(FALSE, m_llPos, stc);
            return FALSE;
        } else {
            return TRUE;
        }
    }
    return TRUE;
}

/*  Get the id of the nth stream */
UCHAR CMpeg1SystemParse::GetStreamId(int iIndex)
{
    long lOffset = 0;
    while (lOffset + FIELD_OFFSET(SystemHeader, StreamData[0]) <
                m_lSystemHeaderSize) {
        UCHAR uId = m_SystemHeader.StreamData[lOffset];
        if (IsVideoStreamId(uId) || IsAudioStreamId(uId)) {
            if (iIndex == 0) {
                return uId;
            }
            iIndex--;
        }
        lOffset += 3;
    }
    return 0xFF;
}

CStream * CMpeg1SystemParse::AddStream(UCHAR uStreamId)
{
    /*  Only interested in audio and video */
    if (!IsVideoStreamId(uStreamId) &&
        !IsAudioStreamId(uStreamId)) {
        return NULL;
    }

    /*  See if we've got this stream type yet */

    CStream *pStreamFound = NULL;

    POSITION pos = m_lStreams.GetHeadPosition();
    while (pos) {
        CStream *pStream = m_lStreams.GetNext(pos);

        /*  If we already have a stream of the same type then just return */
        if (IsVideoStreamId(uStreamId) && IsVideoStreamId(pStream->m_uStreamId) ||
            IsAudioStreamId(uStreamId) && IsAudioStreamId(pStream->m_uStreamId)) {
            return NULL;
        }
    }

    //  Force low-res stream for VideoCD.
    if (m_bVideoCD && IsVideoStreamId(uStreamId) && uStreamId == 0xE2) {
        return NULL;
    }

    CStream *pStream;
    if (IsVideoStreamId(uStreamId)) {
        ASSERT(m_pVideoStream == NULL);
        pStream = m_pVideoStream = new CVideoParse(this, uStreamId, m_bItem);
    } else {
        pStream = new CAudioParse(this, uStreamId);
    }

    if (pStream == NULL) {
        Fail(E_OUTOFMEMORY);
        return NULL;
    }

    /*  Set the stream state */
    pStream->SetState(State_Initializing);

    /*  Add this pin to our list */
    if (m_lStreams.AddTail(pStream) == NULL) {
        delete pStream;
        Fail(E_OUTOFMEMORY);
        return NULL;
    }

    return pStream;
}

/*  Set a new substream state */
void CMpeg1SystemParse::SetState(Stream_State s)
{
    /*  State_Stopping is not a real state change */
    if (s != State_Stopping) {
        /*  If there are 0 streams let the caller know */
        if (m_lStreams.GetCount() == 0) {
            m_pNotify->Complete(FALSE, 0, MpegToReferenceTime(StartClock()));
            return;
        }
        m_nValid = 0;
        m_bCompletion = TRUE;
    }
    POSITION pos = m_lStreams.GetHeadPosition();
    while (pos) {
        m_lStreams.GetNext(pos)->SetState(s);
    }
}

/*  Callback from stream handler to say a stream has completed the
    current state transition
*/
void CMpeg1SystemParse::Complete(UCHAR uStreamId, BOOL bSuccess, LONGLONG llPos, CSTC stc)
{
    m_nValid++;
    m_bCompletion = m_bCompletion && bSuccess;

    if (m_nValid == 1) {
        m_stcComplete        = stc;
        m_llCompletePosition = llPos;
        if (m_State == State_Initializing) {
            m_stcStartPts = m_stcComplete;
            m_stcRealStartPts = m_stcStartPts;
        }
    } else {
        switch (m_State) {
        case State_Seeking:
        case State_Initializing:
            if (bSuccess) {
                if (stc < m_stcComplete) {
                    m_stcComplete = stc;
#if 1 // We just use the first PTS we find now - easier to define
                    if (m_State == State_Initializing) {
                        m_stcStartPts = m_stcComplete;
                        m_stcRealStartPts = m_stcStartPts;
                    }
#endif
                }
                if (llPos < m_llCompletePosition) {
                    m_llCompletePosition = llPos;
                }
            }
            break;

        case State_Run:
        case State_Stopping:
        case State_FindEnd:
            if (bSuccess) {
                if (stc > m_stcComplete) {
                    m_stcComplete = stc;
                }
                if (llPos > m_llCompletePosition) {
                    m_llCompletePosition = llPos;
                }
            }
            break;
        }
    }
    if (m_State == State_Initializing) {
        /*  Guess some length stuff in case we don't get a second chance */
        m_bGotDuration = TRUE;
        m_llDuration =
            llMulDiv(m_llTotalSize, MPEG_TIME_DIVISOR, m_MuxRate * 50, 0);
        if (m_pVideoStream != NULL) {
            m_dwFrameLength = (DWORD)(((double)(m_rtDuration / 10000) *
                               m_pVideoStream->m_seqInfo.fPictureRate) /
                              1000);
        }
        /*  Initialize stop time and reference time length */
        SetDurationInfo();
    } else
    if (IsComplete()) {
        REFERENCE_TIME tComplete;
        if (m_bCompletion) {
            tComplete = MpegToReferenceTime(GetStreamTime(m_stcComplete));
        } else {
            tComplete = CRefTime(0L);
        }
        if (m_State == State_Seeking) {
            if (m_bVideoCD) {
                /*  Adjust the start time to include the sector header etc */
                if (m_llCompletePosition > VIDEOCD_HEADER_SIZE) {
                    m_llCompletePosition -=
                        (LONGLONG)(
                        (LONG)(m_llCompletePosition - VIDEOCD_HEADER_SIZE) %
                            VIDEOCD_SECTOR_SIZE);

                }
            }
        } else

        if (m_State == State_FindEnd) {

            /*  Do frame length estimation if there is a video stream
                If we didn't find a GOP while seeking for the end
                we won't allow frame seeking - which is probably OK as
                there aren't enough GOPs to do it anyway
            */
            if (m_pVideoStream != NULL &&
                m_pVideoStream->m_dwFramePosition != (DWORD)-1) {
                m_dwFrameLength = m_pVideoStream->m_dwFramePosition;

                /*  Compute video offsets */
                m_rtVideoStartOffset = MpegToReferenceTime((LONGLONG)(m_pVideoStream->m_stcRealStart - m_stcStartPts));
                if (m_pVideoStream->m_bGotEnd) {
                    m_rtVideoEndOffset = MpegToReferenceTime((LONGLONG)(m_stcComplete - m_pVideoStream->m_stcEnd));
                }
            }

            /*  Estimate the duration from the mux rate =
                length / mux_rate
            */
            LONGLONG llMuxDuration = m_llDuration;

            /*  If we found valid data at the end then use it to compute
                the length
            */
            if (m_bCompletion) {
                /*  Initial stop is end of file */
                m_llDuration = GetStreamTime(m_stcComplete) - StartClock();

                /*  Check for large files */
                if (llMuxDuration > MPEG_MAX_TIME / 2) {
                    while (m_llDuration < llMuxDuration - MPEG_MAX_TIME / 2) {
                        m_llDuration += MPEG_MAX_TIME;
                    }
                } else {
                    /*  Check for concatenated files */
                    if (llMuxDuration >= (m_llDuration << 1) - MPEG_TIME_DIVISOR) {
                        DbgLog((
                            LOG_TRACE, 1,
                            TEXT("MUX size (%s) >= Computed (%s) * 2 - assuming concatenated"),
                            (LPCTSTR)CDisp(llMuxDuration, CDISP_DEC),
                            (LPCTSTR)CDisp(m_llDuration, CDISP_DEC)));

                        m_bConcatenatedStreams = TRUE;

                        /*  Don't allow frame seeking of concatenated files */
                        m_dwFrameLength = (DWORD)-1;
                        m_llDuration = llMuxDuration;
                    }
                }

            } else {
                m_llDuration = llMuxDuration;
            }
            SetDurationInfo();
        }
        m_pNotify->Complete(m_bCompletion,
                            m_llCompletePosition,
                            tComplete);
    }
}

/*  Return the starting clock of the combined stream in MPEG units
*/
LONGLONG CMpeg1SystemParse::StartClock()
{
    /*  The CSTC class correctly sign extends the clock for us */
    ASSERT(Initialized());
    return (LONGLONG)m_stcStartPts;
}



HRESULT CBasicStream::SetMediaType(const CMediaType *cmt, BOOL bPayload)
{
    m_bPayloadOnly = bPayload;
    return S_OK;
}

BOOL CStream::IsPlaying(LONGLONG llPos, LONG lLen)
{
    return (m_llStartPosition < llPos + lLen) && !m_bReachedEnd;
};


BOOL    CStream::IsPayloadOnly()
{
    return m_bPayloadOnly;
}

/*
    Set a new state
*/
void CStream::SetState(Stream_State state)
{
    /*  State_Stopping is not really a state change */
    if (state == State_Stopping) {
        if (m_bComplete) {
            return;
        }
        m_bStopping = TRUE;
        if (!m_bRunning) {
            return;
        }
        m_bRunning = FALSE;
    } else {
        m_stc = m_pStreamList->StartClock();
    }

    /*  Reinitialize 'complete' state */
    m_bComplete = FALSE;

    /*  Reinitialize the parse state */
    Init();


    if (state == State_Run) {
        m_bReachedEnd = FALSE;
    }

    if (state == State_Seeking) {
        m_llStartPosition = 0;
    }

    /*  Set new state */
    if (state == State_Stopping) {
        ASSERT(m_State == State_Run);
    } else {
        m_bStopping = FALSE;
        m_State = state;
    }
}

/*  Internal routine calls back to the stream list */
void CStream::Complete(BOOL bSuccess, LONGLONG llPos, CSTC stc)
{
    /*  Don't complete twice */
    if (m_bComplete) {
        return;
    }
    m_bRunning = FALSE;
    m_bComplete = TRUE;
    if (m_State == State_Initializing) {
        m_stcStart = stc;
    }
    if (m_State == State_Seeking) {
        if (bSuccess) {
            m_llStartPosition = llPos;
        }
    }
    if (bSuccess) {
        DbgLog((LOG_TRACE, 3, TEXT("Stream %2.2X complete OK - STC %s"),
               m_uStreamId, (LPCTSTR)CDisp(stc)));
    } else {
        DbgLog((LOG_ERROR, 2, TEXT("Complete failed for stream 0x%2.2X"),
                m_uStreamId));
    }
    m_pStreamList->Complete(m_uStreamId, bSuccess, llPos, stc);
}


/*  End of stream */
void CStream::EOS()
{
    if (!m_bComplete) {
        if (m_State == State_Run && !m_bStopping) {
            SetState(State_Stopping);
        }
        CheckComplete(TRUE);
    }
}
#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\packet\worker.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

#include <streams.h>
#include "driver.h"

/*
    Worker thread functions
*/


HRESULT CDeviceWorker::ThreadInitialize()
{

    IEnumPins *pEnum;
    IPin      *pPin;

    /*  First open our device - actually it should already be open! */

    ASSERT(m_pFilter->GetDevice()->IsOpen());

    m_pFilter->GetDevice()->ResetTimers();

    HRESULT hr = m_pFilter->GetDevice()->Pause();

    if (FAILED(hr)) {
        m_pFilter->GetDevice()->Stop();
        return hr;
    }

    /*  Allocate stream (playing) resources */

    hr = m_pFilter->Allocate(m_pFilter);

    if (FAILED(hr)) {
        m_pFilter->GetDevice()->Stop();
    }

    /*  Set our priority! */
    SetThreadPriority(GetCurrentThread(), THREAD_PRIORITY_HIGHEST);
    return hr;
}

HRESULT CDeviceWorker::ThreadTerminate()
{
    /*  Close the device (!)      */
    m_pFilter->GetDevice()->Stop();

    /*  Free the stream resources */
    m_pFilter->Free();

    return S_OK;
}

HRESULT CDeviceWorker::ThreadQueueSample()
{
    /*  Find which stream to route it to */
    return m_pFilter->StreamQueueSamples(m_iStream,
                                         m_ppSample,
                                         m_nSamples,
                                         m_nSamplesProcessed);
}

HRESULT CDeviceWorker::ThreadFlush()
{
    /*  We can flush our device by Stopping it then pausing it */
    return m_pFilter->Flush(m_iStream);
}

DWORD CDeviceWorker::ThreadProc()
{
    HRESULT hr;

    {
        DWORD dwRequest = GetRequest();

        ASSERT(dwRequest == RequestInitialize);

        hr = ThreadInitialize();

        Reply(hr);

        if (FAILED(hr)) {
            ThreadTerminate();
            return 0;
        }
    } ;

    while (TRUE) {

        /*  Create a list of events :

            entry 0    :  The event that says there's something to do

            entry 1 + s:  The next event we expect to be signalled on stream s

        */

        HANDLE hEvent[MAXIMUM_WAIT_OBJECTS];

        hEvent[0] = GetRequestHandle();
        for (int i = 0; i < m_pFilter->NumberOfStreams(); i++)
        {
            // For now if we're not waiting for anything on stream i
            // NotifyHandle will just return a random (reset) event

            hEvent[i + 1] = m_pFilter->GetStream(i).NotifyHandle();
        }

        DWORD WaitResult = WaitForMultipleObjects(
                               1 + m_pFilter->NumberOfStreams(),
                               hEvent,
                               FALSE,
                               INFINITE);

        if (WaitResult == WAIT_OBJECT_0)
        {

            /*  We're being told to do something */

            switch (GetRequestParam())
            {
                case RequestQueueSample:
                    DbgLog((LOG_TRACE, 4, TEXT("CDeviceWorker got sample")));
                    Reply(ThreadQueueSample());
                    break;

                case RequestFlush:
                    DbgLog((LOG_TRACE, 4, TEXT("CDeviceWorker flush requested")));
                    Reply(ThreadFlush());
                    break;

                case RequestTerminate:
                    DbgLog((LOG_TRACE, 4, TEXT("CDeviceWorker got terminate request")));
                    ThreadTerminate();
                    Reply(S_OK);
                    return 0;

                case RequestSetSTC:
                {
                    HRESULT hr;
                    DbgLog((LOG_TRACE, 4, TEXT("CDeviceWorker set STC")));
                    hr = m_pFilter->SetSTC();
                    Reply(hr);
                }
                break;

                default:
                    ASSERT(FALSE);
                    break;
            }
        } else {
            WaitResult -= WAIT_OBJECT_0 + 1;
            ASSERT(WaitResult < (DWORD)m_pFilter->NumberOfStreams());

            /* Something has completed on one of the streams

               Calling Complete() will notify completed bytes
               and submit waiting sample data
            */

            m_pFilter->GetStream(WaitResult).NotifyCompletion();
        }
    }
}

HRESULT CDeviceWorker::QueueSamples(int iStream, IMediaSample **ppSample,
                                    long nSamples, long *nSamplesProcessed)
{
    //  Serialize calls to protect variables passed
    //  NB - probably better just to have the request parameter be
    //  A pointer to a structure!
    CAutoLock lck(&m_Lock);
    ASSERT(iStream < m_pFilter->NumberOfStreams());
    m_ppSample = ppSample;
    m_iStream = iStream;
    m_nSamples = nSamples;
    m_nSamplesProcessed = nSamplesProcessed;
    return CallWorker(RequestQueueSample);
} ;

HRESULT CDeviceWorker::BeginFlush(int iStream)
{
    ASSERT(iStream < m_pFilter->NumberOfStreams());
    m_iStream = iStream;
    return CallWorker(RequestFlush);
} ;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\statepse\audio.cpp ===
// Copyright (c) 1994 - 1999  Microsoft Corporation.  All Rights Reserved.

/*

     audio.cpp

     Audio stream parsing code for the MPEG-I system stream splitter
*/
#include <streams.h>
#include <mmreg.h>

#include <mpegdef.h>           // General MPEG definitions
#include <mpgtime.h>
#include <mpegprse.h>          // Parsing
#include <seqhdr.h>
#include "audio.h"

/*  Bit rate tables */
const WORD BitRates[3][16] =
{{  0, 32,  64,  96,  128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 0 },
 {  0, 32,  48,  56,   64,  80,  96, 112, 128, 160, 192, 224, 256, 320, 384, 0 },
 {  0, 32,  40,  48,   56,  64,  80,  96, 112, 128, 160, 192, 224, 256, 320, 0 }
};
const WORD LowBitRates[3][16] =
{{  0, 32,  48,  56,   64,  80,  96, 112, 128, 144, 160, 176, 192, 224, 256, 0 },
 {  0,  8,  16,  24,   32,  40,  48,  56,  64,  80,  96, 112, 128, 144, 160, 0 },
 {  0,  8,  16,  24,   32,  40,  48,  56,  64,  80,  96, 112, 128, 144, 160, 0 }
};

void CAudioParse::Init()
{
    m_nBytes       = 0;
    m_bGotTime     = FALSE;
    m_llPos        = 0;
    m_bFrameHasPTS = FALSE;
    m_bRunning     = FALSE;
}

/*  Where are we up to? */
BOOL CAudioParse::CurrentTime(CSTC& stc)
{
    if (!m_bGotTime) {
        return FALSE;
    }
    stc = m_stcAudio;
    return TRUE;
}

/*  Get length of a frame (on frame by frame basis) - returns 0 for variable */
DWORD MPEGAudioFrameLength(BYTE *pbData)
{
    if (!CheckAudioHeader(pbData)) {
        return 0;
    }
    DWORD dwHeadBitrate;
    int Layer = 2;

    /*  Get the layer so we can work out the bit rate */
    switch ((pbData[1] >> 1) & 3) {
        case 3:
            Layer = 1;
            break;
        case 2:
            Layer = 2;
            break;
        case 1:
            Layer = 3;
            break;
        case 0:
            DbgBreak("Invalid layer");
    }

    /*  Low bitrates if id bit is not set */
    if (pbData[1] & 8) {
        dwHeadBitrate =
            (DWORD)BitRates[Layer - 1][pbData[2] >> 4] * 1000;
    } else {
        dwHeadBitrate =
            (DWORD)LowBitRates[Layer - 1][pbData[2] >> 4] * 1000;

        /*  Bitrate is really half for FHG stuff */
        //if (0 == (pbData[1] & 0x10)) {
        //    dwHeadBitrate /= 2;
        //}
    }

    /*  free form bitrate not supported */
    if (dwHeadBitrate == 0) {
        return 0;
    }

    DWORD nSamplesPerSec = SampleRate(pbData);

    DWORD dwFrameLength;

    if (1 == Layer) {
        /*  Layer 1 */
        dwFrameLength = (4 * ((dwHeadBitrate * 12) / nSamplesPerSec));
        /*  Do padding */
        if (pbData[2] & 0x02) {
            dwFrameLength += 4;
        }
    } else {
        /*  For MPEG-2 layer 3 only 576 samples per frame
            according to Martin Seiler - can't find it in the spec */
        DWORD dwMultiplier = (Layer == 3 && 0 == (pbData[1] & 0x08) ? 72 : 144);
        dwFrameLength = ((dwMultiplier * dwHeadBitrate) / nSamplesPerSec);
        /*  Do padding */
        if (pbData[2] & 0x02) {
            dwFrameLength += 1;
        }
    }

    return dwFrameLength;
}

BOOL CheckAudioHeader(PBYTE pbData)
{
    if (pbData[0] != 0xFF ||
        ((pbData[1] & 0xE0) != 0xE0) ||

        //  Check for MPEG2.5 and Id bit or not layer 3
        (0 == (pbData[1] & 0x10) && (0 != ((pbData[1] & 0x08)) ||
                                     (pbData[1] >> 1) & 3) != 0x01)) {
        return FALSE;
    }

    /*  Just check it's valid */
    if ((pbData[2] & 0x0C) == 0x0C) {
        DbgLog((LOG_ERROR, 2, TEXT("Invalid audio sampling frequency")));
        return FALSE;
    }
    if ((pbData[1] & 0x08) != 0x08) {
        DbgLog((LOG_TRACE, 3, TEXT("ID bit = 0")));
    }
    if (((pbData[1] >> 1) & 3) == 0x00) {
        DbgLog((LOG_ERROR, 2, TEXT("Invalid audio Layer")));
        return FALSE;
    }

    if (((pbData[2] >> 2) & 3) == 3) {
        DbgLog((LOG_ERROR, 2, TEXT("Invalid sample rate")));
        return FALSE;
    }
    if ((pbData[2] >> 4) == 0x0F) {
        DbgLog((LOG_ERROR, 2, TEXT("Invalid bit rate")));
        return FALSE;
    }

    return TRUE;
}

LONG SampleRate(PBYTE pbData)
{
    LONG lRate;
    switch ((pbData[2] >> 2) & 3) {
        case 0:
            lRate = 44100;
            break;

        case 1:
            lRate = 48000;
            break;

        case 2:
            lRate = 32000;
            break;

        default:
            DbgBreak("Unexpected Sample Rate");
            lRate = 44100;
            break;
    }

    //  Support low bit rates for MPEG-2 and FHG extension (they call
    //  it MPEG2.5).
    if (0 == (pbData[1] & 0x08)) {
        lRate /= 2;
        if (0 == (pbData[1] & 0x10)) {
            lRate /= 2;
        }
    }
    return lRate;
}

DWORD AudioFrameSize(int Layer, DWORD dwHeadBitrate, DWORD nSamplesPerSec,
                     BOOL bMPEG1)
{
    DWORD dwFrameSize;
    if (Layer == 1) {
        dwFrameSize = (4 * (dwHeadBitrate * 12) / nSamplesPerSec);
    } else {
        DWORD dwMultiplier = (Layer == 3 && !bMPEG1 ? 72 : 144);
        dwFrameSize = ((dwMultiplier * dwHeadBitrate) / nSamplesPerSec);
    }
    return dwFrameSize;
}

BOOL ParseAudioHeader(PBYTE pbData, MPEG1WAVEFORMAT *pFormat, long *pLength)
{
    if (!CheckAudioHeader(pbData)) {
        return FALSE;
    }
    pFormat->wfx.wFormatTag = WAVE_FORMAT_MPEG;

    /*  Get number of channels from Mode */
    switch (pbData[3] >> 6) {
    case 0x00:
        pFormat->fwHeadMode = ACM_MPEG_STEREO;
        break;
    case 0x01:
        pFormat->fwHeadMode = ACM_MPEG_JOINTSTEREO;
        break;
    case 0x02:
        pFormat->fwHeadMode = ACM_MPEG_DUALCHANNEL;
        break;
    case 0x03:
        pFormat->fwHeadMode = ACM_MPEG_SINGLECHANNEL;
        break;
    }
    pFormat->wfx.nChannels =
        (WORD)(pFormat->fwHeadMode == ACM_MPEG_SINGLECHANNEL ? 1 : 2);
    pFormat->fwHeadModeExt = (WORD)(1 << (pbData[3] >> 4));
    pFormat->wHeadEmphasis = (WORD)((pbData[3] & 0x03) + 1);
    pFormat->fwHeadFlags   = (WORD)(((pbData[2] & 1) ? ACM_MPEG_PRIVATEBIT : 0) +
                           ((pbData[3] & 8) ? ACM_MPEG_COPYRIGHT : 0) +
                           ((pbData[3] & 4) ? ACM_MPEG_ORIGINALHOME : 0) +
                           ((pbData[1] & 1) ? ACM_MPEG_PROTECTIONBIT : 0) +
                           ((pbData[1] & 0x08) ? ACM_MPEG_ID_MPEG1 : 0));

    int Layer;

    /*  Get the layer so we can work out the bit rate */
    switch ((pbData[1] >> 1) & 3) {
        case 3:
            pFormat->fwHeadLayer = ACM_MPEG_LAYER1;
            Layer = 1;
            break;
        case 2:
            pFormat->fwHeadLayer = ACM_MPEG_LAYER2;
            Layer = 2;
            break;
        case 1:
            pFormat->fwHeadLayer = ACM_MPEG_LAYER3;
            Layer = 3;
            break;
        case 0:
            return (FALSE);
    }

    /*  Get samples per second from sampling frequency */
    pFormat->wfx.nSamplesPerSec = SampleRate(pbData);

    /*  Low bitrates if id bit is not set */
    if (pbData[1] & 8) {
        pFormat->dwHeadBitrate =
            (DWORD)BitRates[Layer - 1][pbData[2] >> 4] * 1000;
    } else {
        pFormat->dwHeadBitrate =
            (DWORD)LowBitRates[Layer - 1][pbData[2] >> 4] * 1000;

        /*  Bitrate is really half for FHG stuff */
        //if (0 == (pbData[1] & 0x10)) {
        //    pFormat->dwHeadBitrate /= 2;
        //}
    }
    pFormat->wfx.nAvgBytesPerSec = pFormat->dwHeadBitrate / 8;

    //  We don't handle variable bit rate (index 0)

    DWORD dwFrameSize = AudioFrameSize(Layer,
                                       pFormat->dwHeadBitrate,
                                       pFormat->wfx.nSamplesPerSec,
                                       0 != (pbData[1] & 0x08));

    if (pFormat->wfx.nSamplesPerSec != 44100 &&
        /*  Layer 3 can sometimes switch bitrates */
        !(Layer == 3 && /* !m_pStreamList->AudioLock() && */
            (pbData[2] >> 4) == 0)) {
        pFormat->wfx.nBlockAlign = (WORD)dwFrameSize;
    } else {
        pFormat->wfx.nBlockAlign = 1;
    }

    if (pLength) {
        *pLength = (long)dwFrameSize;
    }

    pFormat->wfx.wBitsPerSample = 0;
    pFormat->wfx.cbSize = sizeof(MPEG1WAVEFORMAT) - sizeof(WAVEFORMATEX);

    pFormat->dwPTSLow  = 0;
    pFormat->dwPTSHigh = 0;

    return TRUE;
}

BOOL CAudioParse::ParseHeader()
{

    if (!CheckAudioHeader(m_bData)) {
        return FALSE;
    }

    if (m_bFrameHasPTS) {
        DbgLog((LOG_TRACE, 3, TEXT("Audio frame at PTS %s"), (LPCTSTR)CDisp(m_stcFrame)));
        /*  See what this does for our state */
        if (!m_bGotTime) {
            if ((m_bData[1] >> 1) & 3) {
                /*  Not layer 1 */
                m_lTimePerFrame = 1152 * MPEG_TIME_DIVISOR / SampleRate(m_bData);
            } else {
                m_lTimePerFrame = 384 * MPEG_TIME_DIVISOR / SampleRate(m_bData);
            }
            m_bGotTime  = TRUE;
            m_stcFirst = m_stcFrame;
        }
        m_stcAudio = m_stcFrame;

        m_bFrameHasPTS = FALSE;
    } else {
        if (m_bGotTime) {
            m_stcAudio = m_stcAudio + m_lTimePerFrame;
        }
    }

    if (!m_bValid) {
        m_bValid = TRUE;
        CopyMemory((PVOID)m_bHeader, (PVOID)m_bData, sizeof(m_bData));
    }

    /*  See what our state transition should/might be */
    CheckComplete(FALSE);

    return m_bComplete;
}

/*  Override SetState so we can play nothing after seeks */
void CAudioParse::SetState(Stream_State state)
{
    CStream::SetState(state);
    if (state == State_Run && m_pStreamList->GetPlayLength() == 0) {
        m_bReachedEnd = TRUE;
        Complete(TRUE, 0, m_pStreamList->GetStart());
    }
}

/*  Get the media type from the audio stream - this will be a
    MPEG1WAVEFORMAT structure

    See MSDN for a description of MPEG1WAVEFORMAT
*/
HRESULT CAudioParse::GetMediaType(CMediaType *cmt, int iPosition)
{
    /*  NOTE - this stuff is only really valid if the system_audio_lock
        flag is set
    */

    if (iPosition > 5) {
        return VFW_S_NO_MORE_ITEMS;
    }

    if (!m_bValid) {
        DbgLog((LOG_ERROR, 1, TEXT("Asking for format on invalid stream")));
        return E_UNEXPECTED;
    }
    MPEG1WAVEFORMAT Format;
    if (!ParseAudioHeader(m_bHeader, &Format)) {
        return E_INVALIDARG;
    }

    //LARGE_INTEGER Pts;

    /*  Audio PTS is starting PTS of this audio stream */
    //Pts.QuadPart     = m_stcStart;
    //Format.dwPTSLow  = Pts.LowPart;
    //Format.dwPTSHigh = (DWORD)Pts.HighPart;
    Format.dwPTSLow = 0;
    Format.dwPTSHigh = 0;

    WAVEFORMATEX *pFormat;
    MPEGLAYER3WAVEFORMAT wfx;
    if (iPosition / 3) {
        if (Format.fwHeadLayer != ACM_MPEG_LAYER3) {
            return VFW_S_NO_MORE_ITEMS;
        }
        ConvertLayer3Format(&Format, &wfx);
        pFormat = &wfx.wfx;
    } else {
        pFormat = &Format.wfx;
    }
    if (S_OK != CreateAudioMediaType(pFormat, cmt, TRUE)) {
        return E_OUTOFMEMORY;
    }
    iPosition = iPosition % 3;
    if (iPosition == 1) {
        cmt->subtype = MEDIASUBTYPE_MPEG1Payload;
    } else if (iPosition == 2) {
        cmt->subtype = MEDIASUBTYPE_MPEG1Packet;
    }

    return S_OK;
}

/*  Turn a media type back into our own data (!) */
HRESULT CAudioParse::ProcessType(AM_MEDIA_TYPE const *pmt)
{
    if (pmt->formattype != FORMAT_WaveFormatEx ||
        pmt->cbFormat != sizeof(MPEG1WAVEFORMAT)) {
        return E_INVALIDARG;
    }
    MPEG1WAVEFORMAT const *pwfx = (MPEG1WAVEFORMAT *)pmt->pbFormat;
    if (pwfx->wfx.wFormatTag != WAVE_FORMAT_MPEG ||
        0 == (ACM_MPEG_ID_MPEG1 & pwfx->fwHeadFlags)) {
    }

    m_bData[0] = (BYTE)0xFF;
    m_bData[1] = (BYTE)0xF8;
    int iLayer;
    switch (pwfx->fwHeadLayer) {
    case ACM_MPEG_LAYER1:
        m_bData[1] |= (BYTE)0x06;
        iLayer = 1;
        break;
    case ACM_MPEG_LAYER2:
        m_bData[1] |= (BYTE)0x04;
        iLayer = 2;
        break;
    case ACM_MPEG_LAYER3:
        m_bData[1] |= (BYTE)0x02;
        iLayer = 3;
        break;
    default:
        return E_INVALIDARG;
    }

    if (pwfx->fwHeadFlags & ACM_MPEG_PROTECTIONBIT) {
        m_bData[1] |= (BYTE)1;
    }

    if (pwfx->fwHeadFlags & ACM_MPEG_PRIVATEBIT) {
        m_bData[2] = (BYTE)0x01;
    } else {
        m_bData[2] = (BYTE)0x00;
    }
    switch (pwfx->wfx.nSamplesPerSec) {
    case 44100:
        break;
    case 48000:
        m_bData[2] |= (BYTE)0x04;  // 1 << 2
        break;
    case 32000:
        m_bData[2] |= (BYTE)0x08;  // 2 << 2
        break;
    default:
        return E_INVALIDARG;
    }

    switch (pwfx->fwHeadMode) {
    case ACM_MPEG_STEREO:
        m_bData[3] = (BYTE)0x00;
        break;
    case ACM_MPEG_JOINTSTEREO:
        m_bData[3] = (BYTE)0x40;
        break;
    case ACM_MPEG_DUALCHANNEL:
        m_bData[3] = (BYTE)0x80;
        break;
    case ACM_MPEG_SINGLECHANNEL:
        m_bData[3] = (BYTE)0xC0;
        break;
    default:
        return E_INVALIDARG;
    }

    switch (pwfx->fwHeadModeExt) {
    case 1:
        //m_bData[3] |= (BYTE)0;
        break;
    case 2:
        m_bData[3] |= (0x01 << 4);
        break;
    case 4:
        m_bData[3] |= (0x02 << 4);
        break;
    case 8:
        m_bData[3] |= (0x03 << 4);
        break;
    default:
        return E_INVALIDARG;
    }

    if (pwfx->fwHeadFlags & ACM_MPEG_COPYRIGHT) {
        m_bData[3] |= (BYTE)0x08;
    }
    if (pwfx->fwHeadFlags & ACM_MPEG_ORIGINALHOME) {
        m_bData[3] |= (BYTE)0x04;
    }
    if (pwfx->wHeadEmphasis > 4 || pwfx->wHeadEmphasis == 0) {
        return E_INVALIDARG;
    }
    m_bData[3] |= (BYTE)(pwfx->wHeadEmphasis - 1);

    //
    //  Set up the start time
    //
    LARGE_INTEGER liPTS;
    liPTS.LowPart = pwfx->dwPTSLow;
    liPTS.HighPart = (LONG)pwfx->dwPTSHigh;
    m_stcStart = liPTS.QuadPart;

    //  Finally try and find the bit rate
    DWORD dwBitRate = pwfx->dwHeadBitrate / 1000;
    for (int i = 0; i < 16; i++) {
        if (BitRates[iLayer - 1][i] == dwBitRate) {
            m_bData[2] |= (BYTE)(i << 4);
            ParseHeader();
            ASSERT(m_bValid);
            return S_OK;
        }
    }
    return E_INVALIDARG;
}

/*
    Check if we've completed a state change

    bForce is set at end of stream
*/
void CAudioParse::CheckComplete(BOOL bForce)
{
    ASSERT(!m_bComplete);

    /*  Have we completed a state change ? */
    CSTC stcCurrent;
    BOOL bGotTime = CurrentTime(stcCurrent);
    CSTC stcStart;

    if (bGotTime || bForce) {
        switch (m_State) {
        case State_Run:
        {
            BOOL bCompleted = FALSE;
            if (bGotTime && (stcCurrent > m_pStreamList->GetStart())) {
                // Position should really be the end of packet in this case
                if (!m_bStopping) {
                    m_bRunning = TRUE;
                    m_pStreamList->CheckStop();
                }
                if (m_bStopping) {
                    if (stcCurrent >= m_pStreamList->GetStop()) {
                        m_bReachedEnd = TRUE;
                        Complete(TRUE, m_llPos, m_pStreamList->GetStop());
                        bCompleted = TRUE;
                    }
                }
            }
            if (bForce && !bCompleted) {
                Complete(FALSE, m_llPos, 0);
            }
            break;

        }
        case State_Initializing:
            if (m_bValid && m_bGotTime) {
                /*
                    The start file position is ASSUMED to be 0 (!)
                */
                Complete(TRUE, 0, m_stcFirst);
            } else {
                if (bForce) {
                    Complete(FALSE, 0, stcCurrent);
                }
            }
            break;

        case State_Seeking:

            stcStart = m_pStreamList->GetStart();
            if (bGotTime && (stcCurrent > stcStart)) {
                /*  If we've got a clock ref by now then
                    we're all set - choose the max start position to
                    get both to start playing from
                    Otherwise we've messed up!
                */
                DbgLog((LOG_TRACE, 2, TEXT("Audio Seek complete position %s - target was %s, first PTS was %s, current is %s"),
                       (LPCTSTR)CDisp(m_llPos),
                       (LPCTSTR)CDisp(m_pStreamList->GetStart()),
                       (LPCTSTR)CDisp(m_stcFirst),
                       (LPCTSTR)CDisp(stcCurrent)));

                /*  OK provided we can play a frame close to the
                    start time
                */
                Complete((LONGLONG)(stcCurrent - stcStart) <= (LONGLONG)m_lTimePerFrame,
                         m_llPos,
                         stcCurrent);
            } else {
                /*  Don't care if we got nothing (not like video) */
                if (bForce) {
                    Complete(TRUE, m_llPos, m_pStreamList->GetStop());
                }
            }
            break;

        case State_FindEnd:
            /*  Only finish when we're forced ! */
            if (bForce) {
                // NOTE: Position is not a useful value here
                /*  We have to ASSUME the last frame was complete */
                Complete(bGotTime,
                         m_llPos,
                         bGotTime ? stcCurrent + m_lTimePerFrame :
                                    CSTC(0));
            }
            break;

        default:
            DbgBreak("Unexpected State");
            break;
        }
    }
    /*  bForce ==> complete */
    ASSERT(m_bComplete || !bForce);
}


/*  New set of bytes passed to the audio stream
*/
BOOL CAudioParse::ParseBytes(PBYTE pData,
                             LONG lData,
                             LONGLONG llPos,
                             BOOL bHasPts,
                             CSTC stc)
{
    /*  If we're not valid find some valid data first -
        in either case we need a start code
    */
    if (m_bComplete || m_bRunning) {
        return FALSE;
    }

    while (lData > 0) {
        PBYTE pDataNew;

        switch (m_nBytes) {
        case 0:
            /*  Look for a sync code */
            pDataNew = (PBYTE)memchrInternal((PVOID)pData, 0xFF, lData);
            if (pDataNew == NULL) {
                return FALSE;
            }
            lData -= (LONG)(pDataNew - pData) + 1;
            pData = pDataNew + 1;
            m_nBytes = 1;
            m_bData[0] = 0xFF;
            m_bFrameHasPTS = bHasPts;
            m_stcFrame  = stc;
            m_llPos = llPos;
            break;

        case 1:
            if ((pData[0] & 0xF0) == 0xF0) {
                m_nBytes = 2;
                m_bData[1] = pData[0];
            } else {
                m_nBytes = 0;
            }
            pData++;
            lData--;
            break;

        case 2:
            m_bData[2] = pData[0];
            pData++;
            lData--;
            m_nBytes = 3;
            break;

        case 3:
            m_bData[3] = pData[0];
            pData++;
            lData--;
            m_nBytes = 0;
            bHasPts = FALSE;
            if (ParseHeader()) {
                return TRUE;
            }
            break;

        default:
            DbgBreak("Unexpected byte count");
            break;
        }
    }
    return FALSE;
}
//  Bogus extra layer III format support
void ConvertLayer3Format(
    MPEG1WAVEFORMAT const *pFormat,
    MPEGLAYER3WAVEFORMAT *pFormat3
)
{
    pFormat3->wfx.wFormatTag        = WAVE_FORMAT_MPEGLAYER3;
    pFormat3->wfx.nChannels         = pFormat->wfx.nChannels;
    pFormat3->wfx.nSamplesPerSec    = pFormat->wfx.nSamplesPerSec;
    pFormat3->wfx.nAvgBytesPerSec   = pFormat->wfx.nAvgBytesPerSec;
    pFormat3->wfx.nBlockAlign       = 1;
    pFormat3->wfx.wBitsPerSample    = 0;
    pFormat3->wfx.cbSize            = MPEGLAYER3_WFX_EXTRA_BYTES;
    pFormat3->wID                   = MPEGLAYER3_ID_MPEG;
    pFormat3->fdwFlags              = MPEGLAYER3_FLAG_PADDING_ISO;
    pFormat3->nBlockSize            = pFormat->wfx.nBlockAlign;
    pFormat3->nFramesPerBlock       = 1;
    pFormat3->nCodecDelay           = 0;
}

#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\statepse\native.cpp ===
/******************************Module*Header*******************************\
* Module Name: Native.cpp
*
* Mpeg codec native streams definitions
*
* Copyright (c) 1996 - 1999  Microsoft Corporation.  All Rights Reserved.
*
* Notes:
*
*   If a video file is < 2 megabytes in length the we deduce its length by
*   counting the picture start codes.  This bypasses the problem that
*   some video files have a variable bitrate because the only tests we have
*   like this are < 2 megabytes long.
*
*   Seeking is particularly crude for video and basically fails if there
*   aren't enough Groups of Pictures on the file.
*
\**************************************************************************/

#include <streams.h>
#include <limits.h>
#include <mimeole.h> /* for CP_USASCII */
#include <malloc.h>  /* _alloca */
#include <mmreg.h>
#include <mpgtime.h>
#include <mpegprse.h>          // Parsing
#include <videocd.h>           // Video CD special parsing
#include <seqhdr.h>
#include "resource.h"          // IDS_COPYRIGHT
#include <id3.h>
#include <native.h>
#include <mpegdef.h>
#include "audio.h"

/*************************************************************************\

    CNativeVideoParse

\*************************************************************************/

HRESULT CNativeVideoParse::GetMediaType(CMediaType *cmt, int iPosition)
{
    ASSERT(m_dwFlags & FLAGS_VALID);
    if (iPosition != 0) {
        return VFW_S_NO_MORE_ITEMS;
    }
    return GetVideoMediaType(cmt, TRUE, &m_Info);
}


/*  Format support */
HRESULT CNativeVideoParse::IsFormatSupported(const GUID *pTimeFormat)
{
    if (*pTimeFormat == TIME_FORMAT_FRAME) {
        return S_OK;
    } else {
        return CBasicParse::IsFormatSupported(pTimeFormat);
    }
}

//  Return the duration in the current time format
HRESULT CNativeParse::GetDuration(
    LONGLONG *pllDuration,
    const GUID *pTimeFormat
)    // How long is the stream?
{
    if (pTimeFormat == &TIME_FORMAT_MEDIA_TIME) {
        *pllDuration = m_Duration;
    } else {
        ASSERT(pTimeFormat == &TIME_FORMAT_FRAME);
        *pllDuration = m_dwFrames;
    }
    return S_OK;
};


// Convert times between formats
LONGLONG CNativeVideoParse::Convert(LONGLONG llOld,
                 const GUID *OldFormat,
                 const GUID *NewFormat)
{
    if (OldFormat == NewFormat) {
        return llOld;
    }

    //  Round up to time and down to frames
    if (NewFormat == &TIME_FORMAT_MEDIA_TIME) {
        ASSERT(OldFormat == &TIME_FORMAT_FRAME);
        return llMulDiv(llOld, m_Duration, m_dwFrames, m_dwFrames - 1);
    } else {
        ASSERT(NewFormat == &TIME_FORMAT_FRAME &&
               OldFormat == &TIME_FORMAT_MEDIA_TIME);
        return llMulDiv(llOld, m_dwFrames, m_Duration, 0);
    }
}

HRESULT CNativeVideoParse::Seek(LONGLONG llSeekTo,
                                REFERENCE_TIME *prtStart,
                                const GUID *pTimeFormat)
{
    DbgLog((LOG_TRACE, 2, TEXT("CNativeVideoParse::Seek(%s)"),
            (LPCTSTR)CDisp(CRefTime(llSeekTo))));

    llSeekTo = Convert(llSeekTo,
                       TimeFormat(),
                       &TIME_FORMAT_MEDIA_TIME);

    /*  Set the seek time position */
    *prtStart = llSeekTo;

    /*  Compute current */
    LONGLONG llSeek;
    if (m_bOneGOP) {

        /*  If there's only one GOP in the file we have no choice but
            to start from the beginning!
        */
        DbgLog((LOG_ERROR, 2,
                TEXT("MPEG Native stream - only 1 GOP - seeking to start!")));
        llSeek = 0;
    } else {

        /*  Seek to 1 and 1/3 seconds early and hope we get a GOP in time! */
        llSeek = llMulDiv(m_llTotalSize,
                          llSeekTo,
                          m_Duration,
                          0) -
                 (LONGLONG)(m_Info.dwBitRate / 6);
        if (llSeek < 0) {
            llSeek = 0;
        }
    }

    DbgLog((LOG_TRACE, 2, TEXT("CNativeVideoParse::Seek - seeking to byte position %s"),
            (LPCTSTR)CDisp(llSeek, CDISP_DEC)));

    /*  Do the seek immediately */
    m_llSeek = llSeekTo;
    m_pNotify->SeekTo(llSeek);

    return S_OK;
}

//  Hack because of so much badly authored content.  If the stop
//  time is at the end make it infinite.
//  This value is only used in NewSegment and in this file to
//  determine if we're at the end yet
REFERENCE_TIME CNativeVideoParse::GetStopTime()
{
    REFERENCE_TIME rtStop = CBasicParse::GetStopTime();
    if (rtStop >= m_Duration) {
        rtStop = _I64_MAX / 2;
    }
    return rtStop;
}

void CNativeVideoParse::SetSeekState()
{
    /*  This is a discontinuity */
    Discontinuity();

    DbgLog((LOG_TRACE, 2, TEXT("CNativeVideoParse::SetSeekState(%s)"),
            (LPCTSTR)CDisp(CRefTime(m_llSeek))));

    /*  Save start position and set state*/
    m_Start = m_llSeek;

    /*  Don't do any special processing for Seek
    */
    m_pNotify->Complete(TRUE, 0, 0);

}

/*  Initialization */
HRESULT CNativeVideoParse::Init(LONGLONG llSize, BOOL bSeekable, CMediaType const *pmt)
{
    /*  Initialize base class */
    CBasicParse::Init(llSize, bSeekable, pmt);

    /*  Initialize GOP time code */
    m_Info.dwStartTimeCode = (DWORD)-1;
    m_dwFlags = 0;
    m_nFrames = 0;
    m_nTotalFrames = 0;
    m_bBadGOP = FALSE;
    m_bOneGOP = TRUE;
    m_iMaxSequence = 0;
    m_uStreamId = (BYTE)VIDEO_STREAM;
    return S_OK;
}

/*  Check the stream for being a valid stream and determine:

    The media type by decoding a video sequence header

    If seeking is supported :
    1.  Length in bytes
    2.  Length
*/

LONG CNativeVideoParse::ParseBytes(LONGLONG llPos,
                                   PBYTE pbDataStart,
                                   LONG  lData,
                                   DWORD dwBufferFlags)
{
    /*  Note that we haven't had a picture start code yet in this buffer */
    m_rtBufferStart = (REFERENCE_TIME)-1;

    /*  To determine the media type and validate the file type we
        need to find a valid sequence header.

        Abscence of one does not prove the stream is invalid but we can't
        do anything useful unless we find one
    */
    PBYTE pbData = pbDataStart;
    LONG lDataToSend = lData;

#define SEQUENCE_HEADER_SIZE MAX_SIZE_MPEG1_SEQUENCE_INFO
    LONG lLeft = lData;
    while (lLeft >= SEQUENCE_HEADER_SIZE) {
        PBYTE pbFound = (PBYTE)memchrInternal((PVOID)pbData, 0,
                                      lLeft - (SEQUENCE_HEADER_SIZE - 1));
        if (pbFound == NULL) {

            lLeft = SEQUENCE_HEADER_SIZE - 1;
            break;
        }
        lLeft -= (LONG)(pbFound - pbData);
        pbData = pbFound;

        ASSERT(lLeft >= SEQUENCE_HEADER_SIZE);

        /*  Check if it's a valid start code */
        if ((*(UNALIGNED DWORD *)pbData & 0xFFFFFF) != 0x010000) {
            pbData++;
            lLeft--;
            continue;
        }
        DWORD dwCode = *(UNALIGNED DWORD *)pbData;
        dwCode = DWORD_SWAP(dwCode);
        if (VALID_SYSTEM_START_CODE(dwCode) && m_State == State_Initializing) {

            /*  Video should NOT contain any valid system stream start code */
            DbgLog((LOG_ERROR, 2, TEXT("Invalid system start code in video stream!")));
            m_pNotify->Complete(FALSE, 0, 0);
            return 0;
        }

        /*  Sequence header extension means MPEG-2 - this is only made
            clear in the MPEG-2 spec and is left ambiguous in the
            MPEG-1 spec
        */
        if (dwCode == EXTENSION_START_CODE) {
            DbgLog((LOG_TRACE, 2, TEXT("Sequence Header Extension ==> MPEG2")));
            m_pNotify->Complete(FALSE, 0, 0);
            return 0;
        }

        /*  If it's a sequence header code then this is it! */
        if (dwCode ==  SEQUENCE_HEADER_CODE) {
            if (!(m_dwFlags & FLAGS_GOTSEQHDR)) {
                int size = SequenceHeaderSize(pbData);

                /*  Check the sequence header and allow for quantization matrices */
                if (ParseSequenceHeader(pbData, size, &m_Info)) {

                    m_dwFlags |= FLAGS_GOTSEQHDR;

                    /*  Hack the rate for bad content (eg RedsNightMare.mpg) */
                    if (m_Info.dwBitRate == 0x3FFF * 400) {
                        if (m_Info.lWidth <= 352 && m_Info.lHeight <= 288) {
                            m_Info.dwBitRate = 0;
                        }
                    }

                    /*  just carry on so we scan at least one buffer - that
                        way we may find stray system stream codes or
                        something
                    */
                    lLeft -= size;
                    pbData += size;
                    continue;

                } else {
                    /*  Not valid */
                    m_pNotify->Complete(FALSE, 0, 0);
                    return 0;
                }
            }
        } else if (dwCode == GROUP_START_CODE) {
            if (m_dwFlags & FLAGS_GOTSEQHDR) {

                DWORD dwTimeCode = GroupTimeCode(pbData);

                DbgLog((LOG_TRACE, 3, TEXT("CNativeVideoParse - found GOP(%d:%d:%d:%d hmsf)"),
                        (dwTimeCode >> 19) & 0x1F,
                        (dwTimeCode >> 13) & 0x3F,
                        (dwTimeCode >> 6) & 0x3F,
                        dwTimeCode & 0x3F));


                /*  First time we got a GOP in this scan ? */
                if (m_dwCurrentTimeCode == (DWORD)-1) {

                    /*  Make sure we get a decent buffer for the first one */
                    if (lLeft < 2000 &&
                        pbData != pbDataStart &&
                        !(dwBufferFlags & Flags_EOS))
                    {
                        return (LONG)(pbData - pbDataStart);
                    } else {
                        lDataToSend -= (LONG)(pbData - pbDataStart);
                        pbDataStart = pbData;
                    }

                    m_dwCurrentTimeCode = dwTimeCode;

                } else {

                    /*  OK - so there's > 1 GOP */
                    m_bOneGOP = FALSE;

                    /*  Allow for bad files with all GOPs 0 or ones
                        that don't match the frame position
                    */
                    REFERENCE_TIME rtDiff =
                        ConvertTimeCode(dwTimeCode) -
                        ConvertTimeCode(m_dwCurrentTimeCode);
                    LONG rtPictures = (LONG)m_Info.tPictureTime * m_nFrames;

                    if (!m_bBadGOP &&
                        dwTimeCode != 0 &&
                        (LONG)rtDiff > rtPictures - (LONG)m_Info.tPictureTime &&
                        (LONG)rtDiff < rtPictures + (LONG)m_Info.tPictureTime
                        ) {
                        /*  If we had a previous group going we can now
                            decode its last frame
                        */
                        ComputeCurrent();

                        /*  Save latest time code */
                        m_dwCurrentTimeCode = dwTimeCode;
                    } else {
                        DbgLog((LOG_ERROR, 1, TEXT("Native MPEG video GOPs bad")));
                        m_bBadGOP = TRUE;
                    }
                }


                /*  Track stuff during initialization */
                if (m_State == State_Initializing) {
                    m_dwFlags |= FLAGS_VALID;

                    /*  We scan the whole length of 'small' files
                        counting pictures because they're full of bugs

                        However, we can't do this if we're coming off
                        the internet

                        Otherwise we just scan the end of the file hoping
                        for a Group Of Pictures to tell us where we are.
                    */
                    if (m_Info.dwStartTimeCode == (DWORD)-1) {
                        m_Info.dwStartTimeCode = m_dwCurrentTimeCode;
                        if (m_Info.dwBitRate != 0 || m_nFrames != 0) {
                            SetDurationAndBitRate(FALSE, llPos + lData - lLeft);
                            m_pNotify->Complete(TRUE, 0, 0);
                            return lData - lLeft;
                        }
                    }
                }
#if 0 // Unfortunately lots of native streams have bad time codes
                /*  Check marker bits */
                if (!(m_Info.dwCurrentTimeCode & 0x1000)) {
                    m_pNotify->Complete(FALSE, 0, 0);
                    return 0;
                }
#endif
                /*  Reset frame count */
                if (!m_bBadGOP) {
                    m_nFrames = 0;
                }

                /*  Is this GOP different from the first one we found? */
                if (m_Info.dwStartTimeCode != m_dwCurrentTimeCode) {
                    /*  OK - so there's > 1 GOP */
                    m_bOneGOP = FALSE;
                }
                lLeft -= 8;
                pbData += 8;
                continue;
            }

        /*  Only look at picture start codes if we've processed a GOP in this
            sequence
        */
        } else if (dwCode == PICTURE_START_CODE) {

            /*  Remember max sequence number for length guess algorithm
                number 3!
            */
            int iSeqNo = ((int)pbData[4] << 2) + (int)(pbData[5] >> 6);
            m_iMaxSequence = max(iSeqNo, m_iMaxSequence);

            if (m_dwCurrentTimeCode != (DWORD)-1) {
                /*  Are we scanning at the start */
                if (m_State == State_Initializing) {
                    ASSERT(m_Info.dwBitRate == 0);
                    if (m_nTotalFrames >= m_Info.fPictureRate) {
                        SetDurationAndBitRate(FALSE, llPos + lData - lLeft);
                        m_pNotify->Complete(TRUE, 0, 0);
                        return lData - lLeft;
                    }
                }
                /*  Do some computations on where we are up to
                    based on the fact that we have at least enough to
                    decode the previous picture
                */
                if (m_State == State_Run) {
                    REFERENCE_TIME tStop = GetStopTime();
                    if (m_rtCurrent > tStop) {
                        if (m_rtCurrent > tStop + m_Info.tPictureTime / 2 &&
                            m_bIFound) {
                            m_pNotify->Complete(TRUE, 0, 0);
                        }
                    }
                }

                /*  Update stats for this next picture */
                if (!m_bIFound) {
                    int iType = (pbData[5] >> 3) & 7;
                    if (iType == I_Frame || iType == D_Frame) {
                        m_bIFound = TRUE;
                    }
                }

                /*  The timestamp we want to use is the time stamp for
                    the first picture whose start code commences in this
                    buffer.

                    That time stamp is computed from the group of pictures
                    time stamp plus the sequence number of the picture
                    multiplied by the inter-frame time

                    Some files are incorrectly authored as I-Frame only
                    with the first frame having a sequence number of 1
                */
                if (m_rtBufferStart == (REFERENCE_TIME)-1) {
                    m_rtBufferStart = CurrentTime(iSeqNo);
                }

                /*  We can now decode the last frame so update our
                    count
                */
                ComputeCurrent();
                m_nFrames++;
                if (m_nTotalFrames == 0) {
                    m_lFirstFrameOffset = (LONG)llPos + lData - lLeft;
                }
                m_nTotalFrames++;
            }
        }
        lLeft  -= 3;
        pbData += 3;
    }

    /*  Completed scan of data */

    /*  If we're at the end of data process it all anyway */
    LONG lProcessed = (dwBufferFlags & Flags_EOS) ?
                          lData :
                          lData - lLeft;

    /*  Pass on data in running state */
    if (m_State == State_Run) {
        /*  Send the data on */
        if (!(dwBufferFlags & Flags_EOS)) {
            lDataToSend -= lLeft;
        }
        if (!SendData(pbDataStart, lDataToSend, llPos)) {
            return 0;
        }
    } else
    if (m_State == State_Initializing ||
        m_State == State_FindEnd) {
            if (m_State == State_Initializing) {
            /*  See if we've failed to find anything useful in our initial scan */
            if (llPos + lData > 150000 &&
                !(m_dwFlags & FLAGS_VALID)) {

                m_pNotify->Complete(FALSE, 0, 0);
                return 0;
            }
        }
        /*  If we reached the end of the file cache our results */
        if (dwBufferFlags & Flags_EOS) {
            if (m_dwFlags & FLAGS_VALID) {
                /*  Set the length etc */
                SetDurationAndBitRate(TRUE, llPos + lData - lLeft);

                /*  Do the last frame */
                if (m_dwCurrentTimeCode != (DWORD)-1) {
                    ComputeCurrent();
                }
            }
        }
    }
    return lProcessed;
}

/*  Return the preferred buffer size - 1 second */
LONG CNativeVideoParse::GetBufferSize()
{
    LONG lSize = m_Info.dwBitRate / 8;
    if (lSize < 128 * 1024) {
        lSize = 128 * 1024;
    }
    return lSize;
}

/*  Compute the size and bit rate based on the position reached */
void CNativeVideoParse::SetDurationAndBitRate(BOOL bAtEnd, LONGLONG llPos)
{
    REFERENCE_TIME rtBitRateDuration;
    if (m_Info.dwBitRate != 0) {
        rtBitRateDuration  = (REFERENCE_TIME)llMulDiv(m_llTotalSize,
                                                      (LONG)UNITS * 8,
                                                      m_Info.dwBitRate,
                                                      0);
    }
    if (m_dwCurrentTimeCode != (DWORD)-1 && bAtEnd && !m_bBadGOP && !m_bOneGOP) {
        m_Duration = m_rtCurrent;
        /*  Also set a pseudo bit-rate */
        if (m_Info.dwBitRate == 0) {
            m_Info.dwBitRate = (DWORD)llMulDiv(m_llTotalSize,
                                               UNITS * 8,
                                               m_Duration,
                                               0);
        } else {
            /*  Believe the bit rate - pick up GOPs */
            if (m_Duration < rtBitRateDuration / 2 ||
                m_Duration > rtBitRateDuration * 2) {
                m_Duration = rtBitRateDuration;
                m_bBadGOP = TRUE;
            }
        }
    } else {
        /*  HOPE (!) that we found a reasonable bit rate */
        if (m_Info.dwBitRate == 0) {
            /*  Maybe we can guess by the biggest sequence number
                we got (!)
            */
            if (bAtEnd && m_bOneGOP) {
                m_Duration = m_Info.tPictureTime * m_iMaxSequence;
            } else {
                /*  Guess the bitrate based on the bit rate near the start */
                m_Duration = llMulDiv(m_llTotalSize,
                                      m_nTotalFrames * (LONG)m_Info.tPictureTime,
                                      (LONG)llPos - m_lFirstFrameOffset,
                                      0);
            }
        } else {
            m_Duration = rtBitRateDuration;
        }
    }

    /*  Initialize stop time */
    m_Stop = m_Duration;

    /*  Set the frame size */
    m_dwFrames = (DWORD)((m_Duration + ((LONG)m_Info.tPictureTime - 1)) /
                         (LONG)m_Info.tPictureTime);
}

/*  Convert a time code to a reference time */
REFERENCE_TIME CNativeVideoParse::ConvertTimeCode(DWORD dwCode)
{
    REFERENCE_TIME t;
    DWORD dwSecs = TimeCodeSeconds(dwCode);

    t = UInt32x32To64(dwSecs, UNITS) +
        UInt32x32To64((DWORD)m_Info.tPictureTime, TimeCodeFrames(dwCode));
    return t;
}

/*  Compute the stream time for a group of pictures time code */
REFERENCE_TIME CNativeVideoParse::ComputeTime(DWORD dwTimeCode)
{
    return ConvertTimeCode(dwTimeCode) - ConvertTimeCode(m_Info.dwStartTimeCode);
}

/*  Send a video chunk to our output */
BOOL CNativeVideoParse::SendData(PBYTE pbData, LONG lSize, LONGLONG llPos)
{
    /*  Don't send anything before the first GOP */
    if (m_dwCurrentTimeCode == (DWORD)-1) {
        /*  Not reached a GOP yet - don't pass anything on */
        ASSERT(m_rtBufferStart == (REFERENCE_TIME)-1);
        return TRUE;
    }

    REFERENCE_TIME rtBuffer = m_rtBufferStart;

    /*  If there are bad GOPs only put a timestamp at the start */
    if (m_bBadGOP || m_bOneGOP) {
        if (m_bDiscontinuity) {
            //  Make a guess about where we are since we can't rely
            //  on the GOPs
            rtBuffer = m_bOneGOP ?
                           -m_Start :
                           (REFERENCE_TIME)llMulDiv(llPos,
                                                    m_Duration,
                                                    m_llTotalSize,
                                                    0) -
                           m_Start;
        } else {
            rtBuffer = (REFERENCE_TIME)-1;
        }
    } else {
        if (rtBuffer != (REFERENCE_TIME)-1) {
            rtBuffer -= m_Start;
        }
    }
    if (m_Rate != 1.0 && rtBuffer != (REFERENCE_TIME)-1) {
        if (m_Rate == 0.0) {
            //  Never play anything
            rtBuffer = (REFERENCE_TIME)-1;
        } else {
            rtBuffer = (REFERENCE_TIME)(rtBuffer / m_Rate);
        }
    }

    /*  Send packets on */

    while (lSize > 0) {
#define MAX_VIDEO_SIZE 50000
        LONG lData = lSize;
        if (lData > MAX_VIDEO_SIZE) {
            lData = (MAX_VIDEO_SIZE * 4) / 5;
        }

        /*  Calling this will clear m_bDiscontinuity */
        ASSERT(!m_bDiscontinuity || rtBuffer != (REFERENCE_TIME)-1 ||
               m_Rate == 0.0);
        HRESULT hr =
            m_pNotify->QueuePacket(m_uStreamId,
                                   pbData,
                                   lData,
                                   rtBuffer,
                                   m_bDiscontinuity);
        if (S_OK != hr) {
            m_pNotify->Complete(TRUE, 0, 0);
            return FALSE;
        }
        rtBuffer = (REFERENCE_TIME)-1;
        lSize -= lData;
        pbData += lData;
    }

    m_rtBufferStart = (REFERENCE_TIME)-1;
    return TRUE;
}

/*  Compute where we're up to.

    This is called each time we decode a frame or a group of
    pictures or end of sequence.

    The first frame of each group of pictures (m_nFrames == 0) is
    ignored and counted in at the end of the group.

    If m_nFrames is 1 we're effectively up to the first frame
    in this group so we re-origin to the current group.
*/
void CNativeVideoParse::ComputeCurrent()
{
    ASSERT(m_dwCurrentTimeCode != (DWORD)-1);
    if (m_nFrames != 0) {
        if (m_nFrames == 1) {
            /*  Group start time not yet included */
            m_rtCurrent = ComputeTime(m_dwCurrentTimeCode);
        } else {

            /*  We can compute one more frame */
            m_rtCurrent += m_Info.tPictureTime;
        }
    }
}

/*************************************************************************\

    CNativeAudioParse

\*************************************************************************/

HRESULT CNativeAudioParse::Init(LONGLONG llSize, BOOL bSeekable, CMediaType const *pmt)
{
    /*  Initialize base class */
    CBasicParse::Init(llSize, bSeekable, pmt);

    ASSERT(m_pbID3 == NULL);

    m_uStreamId = (BYTE)AUDIO_STREAM;
    return S_OK;
}

/*  Get audio type */
HRESULT CNativeAudioParse::GetMediaType(CMediaType *cmt, int iPosition)
{
    ASSERT(m_dwFlags & FLAGS_VALID);
    if (iPosition == 0 || iPosition == 1) {
        cmt->SetFormat((PBYTE)&m_Info, sizeof(m_Info));
        cmt->subtype = iPosition == 1 ?
            MEDIASUBTYPE_MPEG1Payload :
            MEDIASUBTYPE_MPEG1AudioPayload;
    } else if (iPosition == 2) {
        if (m_Info.fwHeadLayer != ACM_MPEG_LAYER3) {
            return VFW_S_NO_MORE_ITEMS;
        }
        MPEGLAYER3WAVEFORMAT wfx;
        ConvertLayer3Format(&m_Info, &wfx);
        cmt->SetFormat((PBYTE)&wfx, sizeof(wfx));
        cmt->subtype = FOURCCMap(wfx.wfx.wFormatTag);

    } else {
        return VFW_S_NO_MORE_ITEMS;
    }
    cmt->majortype = MEDIATYPE_Audio;
    cmt->SetFormatType(&FORMAT_WaveFormatEx);
    return S_OK;
}

/*  Seek Audio to given position */
HRESULT CNativeAudioParse::Seek(LONGLONG llSeek,
                                REFERENCE_TIME *prtStart,
                                const GUID *pTimeFormat)
{
    /*  Set the seek time position */
    *prtStart = llSeek;

    ASSERT(pTimeFormat == &TIME_FORMAT_MEDIA_TIME);
    /*  Seek to 1/30 second early */
    REFERENCE_TIME rtSeek = llMulDiv(m_llTotalSize,
                                     llSeek,
                                     m_Duration,
                                     0) -
                            (REFERENCE_TIME)(m_Info.dwHeadBitrate / (30 * 8));
    if (rtSeek < 0) {
        rtSeek = 0;
    }
    m_llSeek = llSeek;

    m_pNotify->SeekTo(rtSeek);

    return S_OK;
}

/*  Set seeking state */
void CNativeAudioParse::SetSeekState()
{
    m_Start = m_llSeek;
    Discontinuity();

    m_pNotify->Complete(TRUE, 0, 0);
}

HRESULT CNativeAudioParse::SetStop(LONGLONG tStop)
{
    /*  Set to 1/80s late */
    LONGLONG llSeek = llMulDiv(m_llTotalSize,
                               tStop,
                               m_Duration,
                               0) +
                      (LONGLONG)(m_Info.dwHeadBitrate / (80 * 8));
    if (llSeek > m_llTotalSize) {
        llSeek = m_llTotalSize;
    }
    m_llStop = llSeek;
    return CBasicParse::SetStop(tStop);
}

/*  Check up to 2000 bytes for a valid start code with 3
    consecutive following frames

    Also skip any ID3v2 tag at the start

    Returns >0 - position of first valid frame
            -1 for 'not enough bytes to tell'
            -2 for 'no valid frame sequence found in first 2000 bytes'

*/
LONG CNativeAudioParse::CheckMPEGAudio(PBYTE pbData, LONG lData)
{
    const nFramesToFind = 5;

    for (int bID3 = 1; bID3 >= 0; bID3--) {
        LONG lPos = 0;
        LONG lID3;
        if (bID3) {
            /*  Skip ID3 */
            if (lData < 10) {
                return -1;
            }
            if (CID3Parse::IsV2(pbData)) {
                lPos = lID3 = CID3Parse::TotalLength(pbData);
            } else {
                //  Not ID3
                continue;
            }
        }

        LONG lFrameSearch = 2000 + lPos;

        /*  Search the first 2000 bytes for a sequence of 5 frame starts */
        for ( ; lPos < lFrameSearch; lPos++) {
            LONG lFramePosition = lPos;

            /*  Look for 5 frames in a row */
            for (int i = 0; i < nFramesToFind; i++) {

                /*  Wait for more data if we can't see the whole header */
                if (lFramePosition + 4 > lData) {
                    return -1;
                }

                /*  Get the header length - 0 means invalid header */
                DWORD dwLength = MPEGAudioFrameLength(pbData + lFramePosition);

                /*  Not a valid frame - move on to the next byte */
                if (dwLength == 0) {
                    break;
                }
                if (i == nFramesToFind - 1) {

                    /*  Save ID3 header for ID3V2.3.0 and above */
                    if (bID3) {
                        /*  Save the ID3 header */
                        m_pbID3 = new BYTE [lID3];
                        CID3Parse::DeUnSynchronize(pbData, m_pbID3);
                    } else {
                        BOOL bID3V1 = FALSE;
                        /*  see if it's ID3V1 */
                        m_pbID3 = new BYTE[128];
                        if (NULL != m_pbID3) {
                            if (S_OK == m_pNotify->Read(-128, 128, m_pbID3)) {
                                if (m_pbID3[0] == 'T' &&
                                    m_pbID3[1] == 'A' &&
                                    m_pbID3[2] == 'G') {
                                    bID3V1 = TRUE;
                                }
                            }
                            if (!bID3V1) {
                                delete [] m_pbID3;
                                m_pbID3 = NULL;
                            }
                        }
                    }
                    return lPos;
                }
                lFramePosition += dwLength;
            }
        }
    }

    /*  Failed */
    return -2;
}

/*  Parse MPEG bytes */
LONG CNativeAudioParse::ParseBytes(LONGLONG llPosition,
                                   PBYTE pbData,
                                   LONG  lData,
                                   DWORD dwBufferFlags)
{
    if (m_State == State_Initializing) {
        /*  Scan for sync word but avoid system bit streams (!!) */
        LONG lLeft = lData;
        if (lLeft >= 4) {
            PBYTE pbFound = pbData;

            /*  If we find 3 compatible frame starts in a row it's a 'go'
                in which case we start at the offset of the first
                frame in.

                We allow a random number of bytes (500) before
                giving up
            */
            LONG lPosition = CheckMPEGAudio(pbData, lData);

            if (lPosition >= 0) {
                /*  Check if this is a valid audio header.  Unfortunately
                    it doesn't have to be!
                */
                if (ParseAudioHeader(pbData + lPosition, &m_Info)) {
                    /*  Compute the duration */
                    m_Duration = ComputeTime(m_llTotalSize);
                    m_Stop = m_Duration;
                    m_llStop = m_llTotalSize;
                    m_dwFlags = FLAGS_VALID;
                    m_pNotify->Complete(TRUE, 0, 0);
                    return 0;
                }
            } else {
                if (lPosition < -1) {
                    m_pNotify->Complete(FALSE, 0, 0);
                }
                return 0;
            }
        }
        return lData - lLeft;
    } else {
        ASSERT(m_State == State_Run);
        /*  Send it on - setting a timestamp on the first packet */
        REFERENCE_TIME rtBufferStart;
        if (m_bDiscontinuity) {
            /*  Look for a frame start code and discard this section */
            LONG lPos = 0;
            for (;;) {
                if (lPos + 4 >= lData) {
                    break;
                }
                if (CheckAudioHeader(pbData + lPos)) {
                    break;
                }
                lPos++;
            }
            if (lPos != 0) {
                return lPos;
            }
            rtBufferStart = ComputeTime(llPosition) - m_Start;
        } else {
            rtBufferStart = 0;
        }

        /*  Truncate to stop position */
        if (llPosition + lData > m_llStop) {
            if (llPosition < m_llStop) {
                lData = (LONG)(m_llStop - llPosition);
            } else {
                lData = 0;
            }

            /*  Tell caller this is the last one */
            m_pNotify->Complete(TRUE, 0, 0);
        }
        LONG lSize = lData;
        while (lSize > 0) {
#define MAX_AUDIO_SIZE 10000
            LONG lToSend = lSize;
            if (lToSend > MAX_AUDIO_SIZE) {
                lToSend = (MAX_AUDIO_SIZE * 4) / 5;
            }
            HRESULT hr =
                m_pNotify->QueuePacket(m_uStreamId,
                                       pbData,
                                       lToSend,
                                       rtBufferStart,
                                       m_bDiscontinuity); // On TS on first

            if (S_OK != hr) {
                m_pNotify->Complete(TRUE, 0, 0);
                return 0;
            }
            lSize -= lToSend;
            pbData += lToSend;
        }
        return lData;
    }
}

/*  Compute time given file offset */
REFERENCE_TIME CNativeAudioParse::ComputeTime(LONGLONG llPosition)
{
    REFERENCE_TIME t;
    t = llMulDiv(llPosition,
                 8 * UNITS,
                 (LONGLONG)m_Info.dwHeadBitrate,
                 0);
    return t;
}

/*  Return the preferred buffer size - 1 second */
LONG CNativeAudioParse::GetBufferSize()
{
    return m_Info.dwHeadBitrate / 8;
}

/*  Get a media content field */
HRESULT CNativeAudioParse::GetContentField(CBasicParse::Field dwFieldId, LPOLESTR *str)
{
    if (m_pbID3 == NULL) {
        return E_NOTIMPL;
    }
    return CID3Parse::GetField(m_pbID3, dwFieldId, str);
}

/*  Content stuff */

#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\statepse\time.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
        Timing stuff for MPEG

        This should really all be inline but the compiler seems to miss
        out half the code if we do that!

*/

#include <streams.h>
#include <mpgtime.h>

#if 0 //  Inline now
CSTC::CSTC(LONGLONG ll)
{
    LARGE_INTEGER li;
    li.QuadPart = ll;
    li.HighPart = -(li.HighPart & 1);
    m_ll = li.QuadPart;
};

CSTC CSTC::operator-(CSTC cstc)
{
    return CSTC(m_ll - (LONGLONG)cstc);
};

CSTC::operator LONGLONG() const
{
    ASSERT(m_ll + 0x100000000 < 0x200000000);
    return m_ll;
};

CSTC CSTC::operator=(LONGLONG ll)
{
    *this = CSTC(ll);
    return *this;
}

BOOL CSTC::operator<(CSTC cstc) const
{
    LARGE_INTEGER li;
    li.QuadPart = m_ll - cstc.m_ll;
    return (li.HighPart & 1) != 0;
};
BOOL CSTC::operator>(CSTC cstc) const
{
    return cstc < *this;
};
BOOL CSTC::operator>=(CSTC cstc) const
{
    return !(*this < cstc);
};
BOOL CSTC::operator<=(CSTC cstc) const
{
    return !(*this > cstc);
};
#endif

/*  Stream time stuff */

CMpegStreamTime::CMpegStreamTime() : m_bInitialized(FALSE)
{
};
CMpegStreamTime::~CMpegStreamTime()
{
};

void CMpegStreamTime::ResetToStart()
{
    ASSERT(m_bInitialized);
    m_llCurrentClock = m_llFirstClock;
    m_bInitialized   = TRUE;
};
void CMpegStreamTime::SeekTo(LONGLONG llGuess) {
    if (m_bInitialized) {
        m_llCurrentClock = llGuess;
    }
    StreamTimeDiscontinuity();
};
void CMpegStreamTime::SetStreamTime(CSTC cstc, LONGLONG llPosition)
{
    if (!m_bInitialized) {
        m_llCurrentClock = m_llFirstClock = (LONGLONG)cstc;
        m_bInitialized = TRUE;
    } else {
        if (!m_bTimeDiscontinuity) {
            LONGLONG llNextClock = GetStreamTime(cstc);
            if (llNextClock < m_llCurrentClock ||
                llNextClock > m_llCurrentClock + 90000) {
                DbgLog((LOG_ERROR, 1, TEXT("Invalid clock! - Previous %s, Current %s"),
                       (LPCTSTR)CDisp(m_llCurrentClock),
                       (LPCTSTR)CDisp(llNextClock)));
                StreamTimeError();

                /*  Not time is not contiguous for concatenated streams
                    mode
                */
                m_bTimeContiguous = FALSE;
            } else {
                /*  m_bTimeContiguous is set to TRUE in ParsePack for
                    concatenated streams mode
                */
            }
        } else {
            m_bTimeDiscontinuity = FALSE;
        }
        m_llCurrentClock = GetStreamTime(cstc);
    }
    m_llPositionForCurrentClock = llPosition;
};

/*  Return stream time offset in MPEG units */
LONGLONG CMpegStreamTime::GetStreamTime(CSTC cstc)
{
    ASSERT(m_bInitialized);

    /*  We should be close so apply the correction */
    return m_llCurrentClock +
           (LONGLONG)(CSTC((LONGLONG)cstc - m_llCurrentClock));
};

BOOL CMpegStreamTime::StreamTimeInitialized()
{
    return m_bInitialized;
};
void CMpegStreamTime::StreamTimeDiscontinuity()
{
    m_bTimeDiscontinuity = TRUE;
    m_bTimeContiguous = FALSE;
};

void CMpegStreamTime::StreamTimeError()
{
    return;
};

#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\statepse\video.h ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*  Frame state machine */
class CVideoState
{
public:

    CVideoState();
    ~CVideoState();

protected:
    int SeqDiff(int a, int b) {
        return (((a - b) & 0x3FF) ^ 0xFFFFFE00) + 0x200;
    };

    void Init();
    virtual void NewFrame(int fType, int iSequence, BOOL bSTC, CSTC stc) = 0;

    /*  When we get a group of pictures the numbering scheme is reset */
    void ResetSequence();

    /*  Have we had ANY frames yet? */
    BOOL Initialized();


protected:
    /*  Timing stuff */
    CSTC      m_stcFirst;          // The first time we found

    CSTC      m_stcVideo;
    int       m_Type;              // Type of m_iAhead frame
    LONGLONG  m_llTimePos;
    bool      m_bGotTime;

public:
    bool      m_bGotEnd;           // true if and only if m_stcEnd is valid

protected:
    /*  Sequence handling stuff */
    bool      m_bGotIFrame;
    bool      m_bGotGOP;
    int       m_iCurrent;
    int       m_iAhead;
    int       m_iSequenceNumberOfFirstIFrame;
    LONGLONG  m_llStartPos;
    LONGLONG  m_llNextIFramePos;
    LONGLONG  m_llGOPPos;

public:
    CSTC      m_stcRealStart;      // Start
    CSTC      m_stcEnd;            // End
};

/*  Video stream parsing */
class CVideoParse : public CStream, public CVideoState
{
public:
    CVideoParse(CStreamList *pList, UCHAR uStreamId, bool bVideoCD) :
        CStream(pList, uStreamId, bVideoCD),
        m_nBytes(0),
        m_bGotSequenceHeader(FALSE)
    {
        m_bData[0] = 0;
        m_bData[1] = 0;
        m_bData[2] = 1;
        m_seqInfo.dwStartTimeCode = (DWORD)-1;
        m_seqInfo.fPictureRate  = 1.0;
    };
    BOOL CurrentTime(CSTC& stc);
    virtual HRESULT GetMediaType(CMediaType *cmt, BOOL bPayload);
    HRESULT ProcessType(AM_MEDIA_TYPE const *pmt);
    virtual BOOL ParseBytes(PBYTE pData,
                            LONG lLen,
                            LONGLONG llPos,
                            BOOL bHasPts,
                            CSTC stc);
    void Discontinuity()
    {
        m_nBytes = 0;
        m_bDiscontinuity = TRUE;
    };

protected:
    void Init();

private:
    /*  Check if transition is complete */
    void CheckComplete(BOOL bForce);

    /*  Complete wrapper */
    void Complete(BOOL bSuccess, LONGLONG llPos, CSTC stc);

    /*  Examine a sequence header */
    BOOL ParseSequenceHeader();
    BOOL ParseGroup();
    BOOL ParsePicture();

    /*  Frame sequence handling */
    virtual void NewFrame(int fType, int iSequence, BOOL bSTC, CSTC stc);

public:
    /*  Current frame position */
    DWORD    m_dwFramePosition;

    /*  Format info */
    SEQHDR_INFO m_seqInfo;

    /*  First frame may not be start */
    int         m_iFirstSequence;

private:
    /*  Parsing stuff */
    int  m_nBytes;
    int  m_nLengthRequired;
    BYTE m_bData[MAX_SIZE_MPEG1_SEQUENCE_INFO];

    /*  Persistent state */
    BOOL m_bGotSequenceHeader;


    /*  Timing stuff */
    BOOL  m_bFrameHasPTS;
    CSTC  m_stcFrame;

    /*  Set when we're just marking time until we've got a whole picture */
    BOOL  m_bWaitingForPictureEnd;

    /*  Position */
    LONGLONG m_llPos;

};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\statepse\video.cpp ===
// Copyright (c) 1995 - 1999  Microsoft Corporation.  All Rights Reserved.

/*
     video.cpp

     Video parsing stuff for the MPEG-I splitter

     class CVideoParse

*/
#include <streams.h>
#include <mmreg.h>

#include <mpegdef.h>           // General MPEG definitions
#include <mpgtime.h>
#include <mpegprse.h>          // Parsing
#include <seqhdr.h>            // ParseSequenceHeader
#include "video.h"

#ifdef DEBUG
LPCTSTR PictureTypes[8]   = { TEXT("forbidden frame type"),
                              TEXT("I-Frame"),
                              TEXT("P-Frame"),
                              TEXT("B-Frame"),
                              TEXT("D-Frame"),
                              TEXT("Reserved frame type"),
                              TEXT("Reserved frame type"),
                              TEXT("Reserved frame type")
                            };
LPCTSTR PelAspectRatios[16] = { TEXT("Forbidden"),
                                TEXT("1.0000 - VGA etc"),
                                TEXT("0.6735"),
                                TEXT("0.7031 - 16:9, 625 line"),
                                TEXT("0.7615"),
                                TEXT("0.8055"),
                                TEXT("0.8437 - 16:9, 525 line"),
                                TEXT("0.8935"),
                                TEXT("0.9375 - CCIR601, 625 line"),
                                TEXT("0.9815"),
                                TEXT("1.0255"),
                                TEXT("1.0695"),
                                TEXT("1.1250 - CCIR601, 525 line"),
                                TEXT("1.1575"),
                                TEXT("1.2015"),
                                TEXT("Reserved") };
LPCTSTR PictureRates[16] = { TEXT("Forbidden"),
                             TEXT("23.976"),
                             TEXT("24"),
                             TEXT("25"),
                             TEXT("29.97"),
                             TEXT("30"),
                             TEXT("50"),
                             TEXT("59.94"),
                             TEXT("60"),
                             TEXT("Reserved"),
                             TEXT("Reserved"),
                             TEXT("Reserved"),
                             TEXT("Reserved"),
                             TEXT("Reserved"),
                             TEXT("Reserved"),
                             TEXT("Reserved") };
#endif // DBG

const LONG PictureTimes[16] = { 0,
                                (LONG)((double)10000000 / 23.976),
                                (LONG)((double)10000000 / 24),
                                (LONG)((double)10000000 / 25),
                                (LONG)((double)10000000 / 29.97),
                                (LONG)((double)10000000 / 30),
                                (LONG)((double)10000000 / 50),
                                (LONG)((double)10000000 / 59.94),
                                (LONG)((double)10000000 / 60)
                              };

const float fPictureRates[] = { 0, (float)23.976, 24, 25, (float)29.97, 30, 50, (float)59.94, 60 };

const LONG AspectRatios[16] = { 2000,
                                2000,
                                (LONG)(2000.0 * 0.6735),
                                (LONG)(2000.0 * 0.7031),
                                (LONG)(2000.0 * 0.7615),
                                (LONG)(2000.0 * 0.8055),
                                (LONG)(2000.0 * 0.8437),
                                (LONG)(2000.0 * 0.8935),
                                (LONG)(2000.0 * 0.9375),
                                (LONG)(2000.0 * 0.9815),
                                (LONG)(2000.0 * 1.0255),
                                (LONG)(2000.0 * 1.0695),
                                (LONG)(2000.0 * 1.1250),
                                (LONG)(2000.0 * 1.1575),
                                (LONG)(2000.0 * 1.2015),
                                2000
                              };

HRESULT GetVideoMediaType(CMediaType *cmt, BOOL bPayload, const SEQHDR_INFO *pInfo, bool bItem)
{
    cmt->majortype = MEDIATYPE_Video;
    cmt->subtype = bPayload ? MEDIASUBTYPE_MPEG1Payload :
                              MEDIASUBTYPE_MPEG1Packet;
    VIDEOINFO *videoInfo =
        (VIDEOINFO *)cmt->AllocFormatBuffer(FIELD_OFFSET(MPEG1VIDEOINFO, bSequenceHeader[pInfo->lActualHeaderLen]));
    if (videoInfo == NULL) {
        return E_OUTOFMEMORY;
    }
    RESET_HEADER(videoInfo);

    videoInfo->dwBitRate          = pInfo->dwBitRate;
    videoInfo->rcSource.right     = pInfo->lWidth;
    videoInfo->bmiHeader.biWidth  = pInfo->lWidth;
    videoInfo->rcSource.bottom    = pInfo->lHeight;
    videoInfo->bmiHeader.biHeight = pInfo->lHeight;
    videoInfo->bmiHeader.biXPelsPerMeter = pInfo->lXPelsPerMeter;
    videoInfo->bmiHeader.biYPelsPerMeter = pInfo->lYPelsPerMeter;
    videoInfo->bmiHeader.biSize   = sizeof(BITMAPINFOHEADER);

    videoInfo->AvgTimePerFrame = bItem ? UNITS : pInfo->tPictureTime;
    MPEG1VIDEOINFO *mpgvideoInfo = (MPEG1VIDEOINFO *)videoInfo;
    mpgvideoInfo->cbSequenceHeader = pInfo->lActualHeaderLen;
    CopyMemory((PVOID)mpgvideoInfo->bSequenceHeader,
               (PVOID)pInfo->RawHeader,
               pInfo->lActualHeaderLen);
    mpgvideoInfo->dwStartTimeCode = pInfo->dwStartTimeCode;


    cmt->SetFormatType(&FORMAT_MPEGVideo);
    return S_OK;
}

HRESULT CVideoParse::GetMediaType(CMediaType *cmt, int iPosition)
{
    if (iPosition > 1) {
        return VFW_S_NO_MORE_ITEMS;
    }
    if (!m_bValid) {
        DbgLog((LOG_ERROR, 1, TEXT("Asking for format on invalid stream")));
        return E_UNEXPECTED;
    }
    return GetVideoMediaType(cmt, iPosition == 0, &m_seqInfo, m_bItem);
}

//  Process a media type given to us
HRESULT CVideoParse::ProcessType(AM_MEDIA_TYPE const *pmt)
{
    //  Just process the sequence header
    if (pmt->formattype != FORMAT_VideoInfo ||
        pmt->cbFormat < sizeof(MPEG1VIDEOINFO)) {
        return E_INVALIDARG;
    }
    MPEG1VIDEOINFO *pInfo = (MPEG1VIDEOINFO *)pmt->pbFormat;
    if (pInfo->cbSequenceHeader > 140) {
        return E_INVALIDARG;
    }
    CopyMemory((PVOID)m_bData, (PVOID)pInfo->bSequenceHeader,
               pInfo->cbSequenceHeader);
    m_nLengthRequired = pInfo->cbSequenceHeader;
    ParseSequenceHeader();
    if (m_bValid) {
        return S_OK;
    } else {
        return E_INVALIDARG;
    }
}
BOOL CVideoParse::ParseSequenceHeader()
{
    if (!m_bValid) {
        if (::ParseSequenceHeader(m_bData, m_nLengthRequired, &m_seqInfo)) {
            /*  Check for quantization matrix change */
            if (m_bData[11] & 3) {
                DbgLog((LOG_TRACE, 1, TEXT("Quantization matrix change!!")));
            }
            m_bValid = TRUE;
        }
        return FALSE;
    } else {
        /*  Check for quantization matrix change */
        if (m_bData[11] & 3) {
            DbgLog((LOG_TRACE, 1, TEXT("Quantization matrix change!!")));
        }
        return FALSE;
    }
}

BOOL ParseSequenceHeader(const BYTE *pbData, LONG lData, SEQHDR_INFO *pInfo)
{
    ASSERT(*(UNALIGNED DWORD *)pbData == DWORD_SWAP(SEQUENCE_HEADER_CODE));

    /*  Check random marker bit */
    if (!(pbData[10] & 0x20)) {
        DbgLog((LOG_ERROR, 2, TEXT("Sequence header invalid marker bit")));
        return FALSE;
    }

    DWORD dwWidthAndHeight = ((DWORD)pbData[4] << 16) +
                             ((DWORD)pbData[5] << 8) +
                             ((DWORD)pbData[6]);

    pInfo->lWidth = dwWidthAndHeight >> 12;
    pInfo->lHeight = dwWidthAndHeight & 0xFFF;
    DbgLog((LOG_TRACE, 2, TEXT("Width = %d, Height = %d"),
        pInfo->lWidth,
        pInfo->lHeight));

    /* the '8' bit is the scramble flag used by sigma designs - ignore */
    BYTE PelAspectRatioAndPictureRate = pbData[7];
    if ((PelAspectRatioAndPictureRate & 0x0F) > 8) {
        PelAspectRatioAndPictureRate &= 0xF7;
    }
    DbgLog((LOG_TRACE, 2, TEXT("Pel Aspect Ratio = %s"),
        PelAspectRatios[PelAspectRatioAndPictureRate >> 4]));
    DbgLog((LOG_TRACE, 2, TEXT("Picture Rate = %s"),
        PictureRates[PelAspectRatioAndPictureRate & 0x0F]));

    if ((PelAspectRatioAndPictureRate & 0xF0) == 0 ||
        (PelAspectRatioAndPictureRate & 0x0F) == 0) {
        DbgLog((LOG_ERROR, 2, TEXT("Sequence header invalid ratio/rate")));
        return FALSE;
    }

    pInfo->tPictureTime = (LONGLONG)PictureTimes[PelAspectRatioAndPictureRate & 0x0F];
    pInfo->fPictureRate = fPictureRates[PelAspectRatioAndPictureRate & 0x0F];
    pInfo->lTimePerFrame = MulDiv((LONG)pInfo->tPictureTime, 9, 1000);

    /*  Pull out the bit rate and aspect ratio for the type */
    pInfo->dwBitRate = ((((DWORD)pbData[8] << 16) +
                   ((DWORD)pbData[9] << 8) +
                   (DWORD)pbData[10]) >> 6);
    if (pInfo->dwBitRate == 0x3FFFF) {
        DbgLog((LOG_TRACE, 2, TEXT("Variable video bit rate")));
        pInfo->dwBitRate = 0;
    } else {
        pInfo->dwBitRate *= 400;
        DbgLog((LOG_TRACE, 2, TEXT("Video bit rate is %d bits per second"),
               pInfo->dwBitRate));
    }

#if 0
#pragma message (REMIND("Get pel aspect ratio right don't call GDI - it will create a thread!"))
    /*  Get a DC */
    HDC hdc = GetDC(GetDesktopWindow());

    ASSERT(hdc != NULL);
    /*  Guess (randomly) 39.37 inches per meter */
    LONG lNotionalPelsPerMeter = MulDiv((LONG)GetDeviceCaps(hdc, LOGICALPELSX),
                                        3937, 100);
#else
    LONG lNotionalPelsPerMeter = 2000;
#endif

    pInfo->lYPelsPerMeter = lNotionalPelsPerMeter;

    pInfo->lXPelsPerMeter = AspectRatios[PelAspectRatioAndPictureRate >> 4];

    /*  Pull out the vbv */
    pInfo->lvbv = ((((LONG)pbData[10] & 0x1F) << 5) |
             ((LONG)pbData[11] >> 3)) * 2048;

    DbgLog((LOG_TRACE, 2, TEXT("vbv size is %d bytes"), pInfo->lvbv));

    /*  Check constrained parameter stuff */
    if (pbData[11] & 0x04) {
        DbgLog((LOG_TRACE, 2, TEXT("Constrained parameter video stream")));

        if (pInfo->lvbv > 40960) {
            DbgLog((LOG_ERROR, 1, TEXT("Invalid vbv (%d) for Constrained stream"),
                    pInfo->lvbv));

            /*  Have to let this through too!  bisp.mpg has this */
            /*  But constrain it since it might be random        */
            pInfo->lvbv = 40960;
        }
    } else {
        DbgLog((LOG_TRACE, 2, TEXT("Non-Constrained parameter video stream")));
    }

#if 0  // Allow low bitrate stuff to get started
    /*  tp_orig has a vbv of 2048 (!) */
    if (pInfo->lvbv < 20000) {
        DbgLog((LOG_TRACE, 2, TEXT("Small vbv (%d) - setting to 40960"),
               pInfo->lvbv));
        pInfo->lvbv = 40960;
    }
#endif

    pInfo->lActualHeaderLen = lData;
    CopyMemory((PVOID)pInfo->RawHeader, (PVOID)pbData, pInfo->lActualHeaderLen);
    return TRUE;
}

void CVideoParse::Complete(BOOL bSuccess, LONGLONG llPos, CSTC stc)
{
    if (m_State == State_Initializing) {
        m_stcRealStart = stc;
    } else {
        if (m_State == State_FindEnd && bSuccess) {
            m_bGotEnd = true;
            m_stcEnd = stc;
        }
    }
    CStream::Complete(bSuccess, llPos, stc);
}

/*
    Check if we've completed a state change

    bForce is set at end of stream
*/
void CVideoParse::CheckComplete(BOOL bForce)
{
    ASSERT(!m_bComplete);

    /*  Have we completed a state change ? */
    CSTC stcCurrent;
    BOOL bGotTime = CurrentTime(stcCurrent);
    CSTC stcStart;

    if (bGotTime || bForce) {
        switch (m_State) {
        case State_Run:
        {
            BOOL bCompleted = FALSE;
            if (bGotTime && (stcCurrent >= m_pStreamList->GetStart())) {
                // Position should really be the end of packet in this case
                if (!m_bStopping) {
                    m_bRunning = TRUE;
                    m_pStreamList->CheckStop();
                }
                if (m_bStopping) {
                    if (stcCurrent >= m_pStreamList->GetStop()) {
                        /*  Send at least ONE frame */
                        if (!m_bWaitingForPictureEnd) {
                            m_bWaitingForPictureEnd = TRUE;
                        } else {
                            m_bReachedEnd = TRUE;
                            Complete(TRUE, m_llPos, stcCurrent);
                            bCompleted = TRUE;
                        }
                    }
                }
            }
            if (bForce && !bCompleted) {
                Complete(FALSE, m_llPos, stcCurrent);
            }
            break;
        }
        case State_Initializing:
            if (m_bValid && m_bGotTime && m_bGotIFrame) {
                /*
                    The start file position is ASSUMED to be 0 (!)
                    We assume the first b-frames can be decoded for
                    our frame count calculations
                */
                CSTC stcStart = m_stcFirst +
                    (-m_iSequenceNumberOfFirstIFrame * m_seqInfo.lTimePerFrame);
                Complete(TRUE, 0, stcStart);
            } else {
                if (bForce) {
                    Complete(FALSE, 0, stcCurrent);
                }
            }
            break;

        case State_Seeking:

            stcStart = m_pStreamList->GetStart();
            if (bGotTime && ((stcCurrent + m_seqInfo.lTimePerFrame > stcStart) || bForce)) {
                /*  If we've got an I-Frame and a clock ref by now then
                    we're all set - choose the max start position to
                    get both to start playing from
                    Otherwise we've messed up!
                */
                LONGLONG llPos;
                llPos = m_llTimePos;
                if (m_bGotIFrame && llPos > m_llStartPos) {
                    llPos = m_llStartPos;
                }
                DbgLog((LOG_TRACE, 2, TEXT("Video Seek complete Position %s - target was %s, first PTS was %s, current is %s"),
                       (LPCTSTR)CDisp(llPos),
                       (LPCTSTR)CDisp(m_pStreamList->GetStart()),
                       (LPCTSTR)CDisp(m_stcFirst),
                       (LPCTSTR)CDisp(stcCurrent)));

                /*  OK provided we can display a picture close to the
                    start time
                */
                Complete((LONGLONG)(m_stcFirst - stcStart) <= (LONGLONG)m_seqInfo.lTimePerFrame,
                         llPos,
                         stcCurrent);
            } else {
                if (bForce) {
                    DbgLog((LOG_TRACE, 1, TEXT("Seek failed for video - pos (%s)"),
                            (LPCTSTR)CDisp(bGotTime ? stcCurrent : CSTC(0))));
                    Complete(FALSE, 0, stcCurrent);
                }
            }
            break;

        case State_FindEnd:
            /*  Only finish when we're forced ! */
            if (bForce) {
                // NOTE: Position is note a useful value here
                Complete(bGotTime, m_llPos, bGotTime ? stcCurrent : CSTC(0));
            }
            break;

        default:
            DbgBreak("Setting Invalid State");
            break;
        }
    }
    /*  bForce ==> complete */
    ASSERT(m_bComplete || !bForce);
}

/*  Handle a picture group */
BOOL CVideoParse::ParseGroup()
{
    m_bGotGOP  = true;
    m_llGOPPos = m_llPos;
    DbgLog((LOG_TRACE, 3,
           TEXT("Group of pictures - time code : %s, %d hrs %d mins %d secs %d frames"),
           m_bData[4] & 0x80 ? TEXT("drop frame") : TEXT("no drop frame"),
           (m_bData[4] >> 2) & 0x1F,
           ((m_bData[4] & 0x03) << 4) + (m_bData[5] >> 4),
           ((m_bData[5] & 0x07) << 3) + (m_bData[6] >> 5),
           ((m_bData[6] & 0x1F) << 1) + (m_bData[7] >> 7)));

    if (m_dwFramePosition == (DWORD)-1) {
        if (m_seqInfo.dwStartTimeCode == (DWORD)-1) {
            m_seqInfo.dwStartTimeCode = GroupTimeCode(m_bData);
            m_dwFramePosition = 0;
        } else {
            m_dwFramePosition = FrameOffset(GroupTimeCode(m_bData), &m_seqInfo);
        }
    } else {
#ifdef DEBUG
        DWORD dwOffset = FrameOffset(GroupTimeCode(m_bData), &m_seqInfo);
        if (m_dwFramePosition != dwOffset) {
            DbgLog((LOG_ERROR, 2,
                    TEXT("Bad GOP - predicted Frame was %d, actual is %d"),
                    dwOffset, m_dwFramePosition));
        }
#endif // DEBUG
    }

    /*  Reset the video sequence */
    ResetSequence();
    return FALSE;
}

/*  Parse the header data for a PICTURE_START_CODE */
BOOL CVideoParse::ParsePicture()
{
    /*  Pull out the sequence number so we can relate any preceding I-Frame */
    int iSeqNo = ((int)m_bData[4] << 2) + (int)(m_bData[5] >> 6);

    /*  We only care if it's an I-Frame */
    DbgLog((LOG_TIMING, 3, m_bFrameHasPTS ? TEXT("%s seq no %d PTS = %s, Time = %s") : TEXT("%s seq no %d "),
           PictureTypes[(m_bData[5] >> 3) & 0x07],
           iSeqNo,
           (LPCTSTR)CDisp((LONGLONG)m_stcFrame),
           (LPCTSTR)CDisp(m_pStreamList->CurrentTime(m_stcFrame))));

    /*  Update the video state */
    NewFrame((m_bData[5] >> 3) & 0x07, iSeqNo, m_bFrameHasPTS, m_stcFrame);

    CheckComplete(FALSE);

    /*  Advanced another frame */
    if (m_dwFramePosition != (DWORD)-1) {
        m_dwFramePosition++;
    }
    m_bFrameHasPTS = FALSE;
    return m_bComplete;
}

/*
     Maintain the video parsing state machine looking for
     start codes

     When we have parsed either :

         A sequence header
         A group of pictures header
         A picture header

     call the appropriate handler
*/
BOOL CVideoParse::ParseBytes(PBYTE pData,
                             LONG lLength,
                             LONGLONG llPos,
                             BOOL bHasPts,
                             CSTC stc)
{
    if (m_bComplete || m_bRunning) {
        return FALSE;
    }

    LONG lData = lLength;

    /*  Parse all the data we've been given
    */
    PBYTE pDataNew;
    BYTE bData;

    while (lData > 0) {
        switch (m_nBytes) {
        case 0:
            /*  Look for a start code */
            pDataNew = (PBYTE)memchrInternal((PVOID)pData, 0, lData);
            if (pDataNew == NULL) {
                return FALSE;
            }
            lData -= (LONG)(pDataNew - pData) + 1;
            pData = pDataNew + 1;
            m_nBytes = 1;

            /*  CAREFUL! - the PTS that goes with a picture is the PTS
                of the packet where the first byte of the start code
                was found
            */
            m_bFrameHasPTS = bHasPts;
            m_stcFrame  = stc;
            m_llPos = llPos;
            break;

        case 1:
            bData = *pData;
            lData--;
            pData++;
            if (bData == 0) {
                m_nBytes = 2;
            } else {
                m_nBytes = 0;
            }
            break;

        case 2:
            bData = *pData;
            lData--;
            pData++;
            if (bData == 1) {
                m_nBytes = 3;
            } else {
                if (bData != 0) {
                    m_nBytes = 0;
                } else {
                    /*  So did the start code start in this buffer ? */
                    if (lLength - lData >= 2) {
                        m_bFrameHasPTS = bHasPts;
                        m_stcFrame  = stc;
                        m_llPos = llPos;
                    }
                }
            }
            break;

        case 3:
            bData = *pData;
            lData--;
            pData++;
            switch (bData) {

            case (BYTE)SEQUENCE_HEADER_CODE:
            case (BYTE)PICTURE_START_CODE:
                m_nLengthRequired = 12;
                m_bData[3] = bData;
                m_nBytes = 4;
                break;

            case (BYTE)GROUP_START_CODE:
                m_nLengthRequired = 8;
                m_bData[3] = bData;
                m_nBytes = 4;
                break;

            default:
                m_nBytes = 0;
                break;
            }
            break;

        default:
            ASSERT(m_nBytes <= m_nLengthRequired);
            if (m_nBytes < m_nLengthRequired) {
                LONG lCopy = min(lData, m_nLengthRequired - m_nBytes);
                CopyMemory((PVOID)(m_bData + m_nBytes), pData, lCopy);
                m_nBytes += lCopy;
                lData    -= lCopy;
                pData    += lCopy;
            }
            if (m_nBytes == m_nLengthRequired) {
                m_nBytes = 0;
                switch (*(DWORD *)m_bData) {
                case DWORD_SWAP(SEQUENCE_HEADER_CODE):
                    /*  Get any quantization matrices */
                    if (m_nLengthRequired == 12 &&
                        (m_bData[11] & 0x03) ||
                        m_nLengthRequired == (12 + 64) &&
                        (m_bData[11] & 0x02) &&
                        (m_bData[11 + 64] & 0x01)) {
                        m_nBytes = m_nLengthRequired;
                        m_nLengthRequired += 64;
                        break;
                    }
                    if (ParseSequenceHeader()) {
                        return TRUE;
                    }
                    break;

                case DWORD_SWAP(GROUP_START_CODE):
                    if (ParseGroup()) {
                        return TRUE;
                    }
                    break;

                case DWORD_SWAP(PICTURE_START_CODE):
                    /*  PTS applies to FIRST picture in packet */
                    if (m_bFrameHasPTS) {
                        /*  Check whether the start code start in THIS
                            buffer (in which case we eat the PTS or in
                            the last in which case the PTS in this buffer
                            refers to the NEXT picture start code (in this
                            buffer) - clear?

                            Anyway, the spec is that the PTS refers to the
                            picture whose start code STARTs in this buffer.
                        */
                        if (lLength - lData >= 4) {
                           bHasPts = FALSE;
                        }
                    }
                    if (ParsePicture()) {
                        return TRUE;
                    }
                    break;

                default:
                    DbgBreak("Unexpected start code!");
                    return FALSE;
                }
            }
        }
    }
    return FALSE;
}


/*----------------------------------------------------------------------
 *
 *   Video frame state stuff
 *
 *   This is to track the sequence numbers in the frames to work
 *   out which is the latest frame that could be rendered given the
 *   current data and what time that frame would be rendered
 *
 *----------------------------------------------------------------------*/



CVideoState::CVideoState() : m_iCurrent(-1), m_bGotEnd(false)
{
}

CVideoState::~CVideoState()
{
}

/*  Have we had any frames yet ? */
BOOL CVideoState::Initialized()
{
    return m_iCurrent >= 0;
}

void CVideoState::Init()
{
    m_bGotTime              = false;
    m_bGotIFrame            = false;
    m_bGotGOP               = false;
    m_iCurrent              = -1;
}

void CVideoParse::Init()
{
    m_nBytes                = 0;
    m_llPos                 = 0;
    m_bWaitingForPictureEnd = FALSE;
    m_dwFramePosition       = (DWORD)-1;
    m_bRunning              = FALSE;
    CVideoState::Init();
}

/*
    Return the 'current time' of the video stream

    Returns FALSE if current time is not valid
*/
BOOL CVideoParse::CurrentTime(CSTC& stc)
{
    if (!m_bGotTime || !m_bGotIFrame) {
        if (!(m_State == State_FindEnd && m_bGotTime)) {
            return FALSE;
        } else {
            /*  We don't need an iframe to calculate the extent */
            stc = m_stcVideo;
            return TRUE;
        }
    } else {
        DbgLog((LOG_TRACE, 3, TEXT("Current video time %s"),
                (LPCTSTR)CDisp(m_stcVideo)));
        stc = m_stcVideo;
        return TRUE;
    }
}

/*  New frame received */
void CVideoParse::NewFrame(int fType, int iSequence, BOOL bSTC, CSTC stc)
{
    BOOL bGotBoth = m_bGotIFrame && m_bGotTime;
    BOOL bNextI = FALSE;

    if (fType == I_Frame || fType == D_Frame) {
        /*  Help out the hardware by starting at a GOP */
        if (m_bGotGOP) {
            m_llNextIFramePos = m_llGOPPos;
        } else {
            m_llNextIFramePos = m_llPos;
        }
        if (!m_bGotIFrame) {
            m_llStartPos = m_llNextIFramePos;
            m_bGotIFrame  = TRUE;
            m_iSequenceNumberOfFirstIFrame = iSequence;
        }
    }

    int iOldCurrent = m_iCurrent;

    if (!Initialized()) {
        m_iCurrent = iSequence;
        if (m_State == State_Initializing) {
            m_iFirstSequence = 0;
        }
        m_iAhead = iSequence;
        m_Type     = fType;
    } else {
        if (fType == B_Frame) {
            if (SeqDiff(iSequence, m_iCurrent) > 0) {
                if (m_iCurrent == m_iAhead) {
                    if (m_Type != B_Frame) {
                        DbgLog((LOG_ERROR, 1, TEXT("Out of sequence B-frame")));
                    }
                    m_iAhead = iSequence;
                }
                m_iCurrent = iSequence;
            } else {
                DbgLog((LOG_TRACE, 3, TEXT("Skipping old B-Frame")));
            }
        } else {
            /*  If we're getting another I or P then we should have caught
                up with the previous one
            */
            if (m_iCurrent != m_iAhead) {
                DbgLog((LOG_ERROR, 1, TEXT("Invalid sequence number")));
                m_iCurrent = m_iAhead;
            }
            m_Type     = fType;
            m_iAhead = iSequence;
        }
        /*  See if we've caught up */
        if (SeqDiff(m_iAhead, m_iCurrent) == 1) {
            m_iCurrent = m_iAhead;
            if (m_Type == I_Frame || m_Type == D_Frame) {
                bNextI = TRUE;
            }
        }
    }

    if (bSTC) {
        m_llTimePos = m_llPos;
        if (!m_bGotTime) {
            m_bGotTime  = TRUE;
        }
        if (m_iCurrent != iSequence) {
            m_stcVideo  = stc + SeqDiff(m_iCurrent, iSequence) * m_seqInfo.lTimePerFrame;
        } else {
            m_stcVideo  = stc;
        }
    } else {
        /*  Can only go through here if we had a previous frame so
            iOldCurrent is valid
        */
        if (m_bGotTime && m_iCurrent != iOldCurrent) {
            m_stcVideo = m_stcVideo + SeqDiff(m_iCurrent, iOldCurrent) * m_seqInfo.lTimePerFrame;
        }
    }
    if (!bGotBoth) {
        CurrentTime(m_stcFirst);
    }
    if (bNextI) {
        if (!m_bGotTime || m_stcVideo < m_pStreamList->GetStart()) {
            m_llStartPos = m_llNextIFramePos;
        }
    }
    DbgLog((LOG_TRACE, 3, TEXT("Current = %d, Ahead = %d, Time = %s"),
           m_iCurrent, m_iAhead, m_bGotTime ? (LPCTSTR)CDisp(m_stcVideo) : TEXT("No PTS yet")));
}

/*  When we get a group of pictures the numbering scheme is reset */
void CVideoState::ResetSequence() {

    /*  Maintain the difference between iCurrent and iAhead -
        iAhead is always the last frame processed
    */

    /*  The spec says (2.4.1 of the video section)
        "The last coded picture, in display order, of a group of
         pictures is either an I-Picture or a P-Picture"
        So if the last one we know about is a B-picture there must
        have been another one we didn't see
    */
    if (Initialized()) {
        if (m_Type == B_Frame) {
            m_iCurrent = 0x3FF & (m_iCurrent - m_iAhead - 2);
            m_iAhead = 0x3FF & -2;
        } else {
            m_iCurrent = 0x3FF & (m_iCurrent - m_iAhead - 1);
            m_iAhead = 0x3FF & -1;
        }
    }
}
#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\inc\src.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved


/*
     Generic source filter class

     This filter class
     --  Supports IMediaFilter
     --  has 1 single (output) pin
         --  accepts any media type
         --  supports IPin
         --  'Plays' samples by waiting until their render time then
             discarding them (but returning S_OK)
     --  Optionally supports IMediaPosition on its pin
*/

class CSourceFilter : public CBaseFilter
{
public:
    CSourceFilter(LPUNKNOWN, HRESULT *);
    ~CSourceFilter();

    virtual int GetPinCount()
    {
        return m_pOutputPin != NULL;
    };
    virtual CBasePin * GetPin(int n)
    {
        if (n == 0) {
            return m_pOutputPin;
        } else {
            return NULL;
        }
    };


protected:
    CBaseOutputPin  *m_pOutputPin;
    CCritSec         m_CritSec;
};

class CSourcePin : public CBaseOutputPin,
                   public CSourcePosition,
                   public CAMThread
{
public:
    CSourcePin(IStream     *pStream,
               BOOL         bSupportSeek,
               LONG         lSize,
               LONG         lCount,
               CBaseFilter *pFilter,
               CCritSec    *pLock,
               HRESULT     *phr);
    ~CSourcePin();

    // check that we can support this output type
    HRESULT CheckMediaType(const CMediaType* mtIn)
    {
        // We'll take anything!
        return S_OK;
    };

    // Return the position interface if it was requested
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** pv)
    {
        if (m_bSupportPosition && riid == IID_IMediaPosition) {
            return CSourcePosition::NonDelegatingQueryInterface(riid, pv);
        } else {
            return CBaseOutputPin::NonDelegatingQueryInterface(riid, pv);
        }
    };

    // Override the position change stuff
    HRESULT ChangeStart();
    HRESULT ChangeStop();
    HRESULT ChangeRate();

    // CSourcePosition stuff
    double Rate() {
        return m_Rate;
    };
    CRefTime Start() {
        return (LONGLONG)(REFTIME)m_Start;
    };
    CRefTime Stop() {
        return (LONGLONG)(REFTIME)m_Stop;
    };

    // We support just a null media type
    virtual HRESULT GetMediaType(int iPosition,CMediaType *pMediaType)
    {
        if (iPosition != 0) { return S_FALSE; };
        *pMediaType = CMediaType();
        return S_OK;
    };

    /*  CBaseOutputPin stuff */

    // override this to set the buffer size and count. Return an error
    // if the size/count is not to your liking
    HRESULT DecideBufferSize(IMemAllocator * pAlloc, ALLOCATOR_PROPERTIES *pProp);

    // Start and stop
    //
    HRESULT Active();
    HRESULT Inactive();


    // Override to handle quality messages
    STDMETHODIMP Notify(IBaseFilter * pSender, Quality q)
    {    return E_NOTIMPL;             // We do NOT handle this
    }

    // Thread stuff
    virtual DWORD ThreadProc(void);  		// the thread function

    // BeginFlush downstream
    virtual void DoBeginFlush();

    // BeginFlush downstream
    virtual void DoEndFlush();



    // End of stream
    virtual void DoEndOfStream()
    {
        CAutoLock lck(&m_PlayCritSec);
        DeliverEndOfStream();
    };

private:
    HRESULT Play();

private:
    // Thread commands
    enum { Thread_Terminate, Thread_Stop, Thread_SetStart, Thread_SetStop };
    CCritSec         m_PlayCritSec;
    BOOL             m_bSupportPosition;
    IStream        * m_pStream;
    LONG const       m_lSize;
    LONG const       m_lCount;

    /*  Position stuff */
    LARGE_INTEGER    m_liCurrent;
    LARGE_INTEGER    m_liStop;
    BOOL             m_bDiscontinuity;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\statepse\util.cpp ===
// Copyright (c) 1995 - 1998  Microsoft Corporation.  All Rights Reserved.

/*  MPEG utility functions */
#include <objbase.h>
#include <streams.h>
#include <wxdebug.h>
#include <mmreg.h>
#include <seqhdr.h>

/******************************Public*Routine******************************\
* SkipToPacketData
*
*
*
* History:
* dd-mm-94 - StephenE - Created
*
\**************************************************************************/
LPBYTE
SkipToPacketData(
    LPBYTE pSrc,
    long &LenLeftInPacket
    )
{
    LPBYTE  lpPacketStart;
    DWORD   bData;
    long    Length;


    //
    // Skip the stream ID and extract the packet length
    //
    pSrc += 4;
    bData = *pSrc++;
    Length = (long)((bData << 8) + *pSrc++);
    DbgLog((LOG_TRACE, 3, TEXT("Packet length %ld"), Length ));


    //
    // Record position of first byte after packet length
    //
    lpPacketStart = pSrc;


    //
    // Remove stuffing bytes
    //
    for (; ; ) {
        bData = *pSrc++;
        if (!(bData & 0x80)) {
            break;
        }
    }

    if ((bData & 0xC0) == 0x40) {
        pSrc++;
        bData = *pSrc++;
    }

    switch (bData & 0xF1) {

    case 0x21:
        pSrc += 4;
        break;

    case 0x31:
        pSrc += 9;
        break;

    default:
        if (bData != 0x0F) {
            DbgLog((LOG_TRACE, 2, TEXT("Invalid packet - 0x%2.2X\n"), bData));
            return NULL;
        }
    }

    //
    // The length left in the packet is the original length of the packet
    // less those bytes that we have just skipped over.
    //
    LenLeftInPacket = Length - (LONG)(pSrc - lpPacketStart);
    return pSrc;
}

//
//  Find the first (potential) audio frame in a buffer
//
DWORD MPEG1AudioFrameOffset(PBYTE pbData, DWORD dwLen)
{
    DWORD dwOffset = 0;
    if (dwLen == 0) {
        return (DWORD)-1;
    }
    for (;;) {
        ASSERT(dwOffset < dwLen);
        PBYTE pbFound = (PBYTE)memchrInternal((PVOID)(pbData + dwOffset), 0xFF, dwLen);
        if (pbFound == NULL) {
            return (DWORD)-1;
        }
        dwOffset = (DWORD)(pbFound - pbData);

        //  Check sync bits, id bit and layer if we can see the second byte
        if (dwOffset < (dwLen - 1) &&
            ((pbFound[1] & 0xF8) != 0xF8 ||
             (pbFound[1] & 0x06) == 0)) {

            //  Keep going
            dwOffset++;
        } else {
            return dwOffset;
        }
    }
}

//  Adjust for drop frame
DWORD FrameDropAdjust(DWORD dwGOPTimeCode)
{
    /*  Do drop frames - 2 for every minute not divisible by 10
        Note that (dwMinutes + 9) / 10 increments every time
        dwMinutes % 10 == 1 - ie we don't subtract frames for
        the first minute of each 10
    */
    DWORD dwMinutes = TimeCodeMinutes(dwGOPTimeCode);
    DWORD dwAdjust = (dwMinutes - (dwMinutes + 10 - 1) / 10) * 2;

    /*  Adjust this minute */
    if (dwMinutes % 10 != 0) {

        /*  Just ASSUME that we drop the first frame the count straight
            away and the last one at the end of the minute since this
            would keep the most faithful adherence to the frame rate
        */
        if (TimeCodeSeconds(dwGOPTimeCode) != 0) {
            dwAdjust += 2;
        }
        /*  Don't adjust the frame count - if there are frames the're
            really there !
        */
    }
    return dwAdjust;
}

//
//  Compute frame numbers
//
DWORD FrameOffset(DWORD dwGOPTimeCode, SEQHDR_INFO const *pInfo)
{
    DWORD dwRateType = pInfo->RawHeader[7] & 0x0F;

    /*  Remove the Sigma hackery */
    if (dwRateType > 8) {
        dwRateType &= 0x07;
    }

    /*  Computation depends on frame type */

    /*  For exact frames per second just compute the seconds and
        add on the frames */

#if 0
    /*  What are we supposed to do with these ? */
    if (dwRateType == 1) {
    } else
    if (dwRateType == 7) {
    } else
#endif
    {
        /*  Exact rate per second */
        static const double FramesPerSecond[] =
        { 0, 24, 24, 25, 30, 30, 50, 59.94, 60 };
        double dFramesPerSecond = FramesPerSecond[dwRateType];
        ASSERT(dFramesPerSecond != 0);
        DWORD dwFramesGOP = (DWORD)(TimeCodeSeconds(dwGOPTimeCode) *
                                    dFramesPerSecond) +
                            TimeCodeFrames(dwGOPTimeCode);
        DWORD dwFramesStart = (DWORD)(TimeCodeSeconds(pInfo->dwStartTimeCode) *
                                                      dFramesPerSecond) +
                              TimeCodeFrames(pInfo->dwStartTimeCode);
        DWORD dwFrames = dwFramesGOP - dwFramesStart;

        /*  23.976 rate drops 1 frame in 1000 */
        if (dwRateType == 1) {
            dwFrames -= (dwFramesGOP / 1000) - (dwFramesStart / 1000);
        }
        if (TimeCodeDrop(dwGOPTimeCode)) {
            dwFrames = dwFrames +
                       FrameDropAdjust(pInfo->dwStartTimeCode) -
                       FrameDropAdjust(dwGOPTimeCode);
        }
        return dwFrames;
    }

}
#pragma warning(disable:4514)
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\inc\sink.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved


/*
     Generic sink filter class

     This filter class
     --  Supports IMediaFilter
     --  has 1 single (input) pin
         --  accepts any media type
         --  supports IPin
         --  'Plays' samples by waiting until their render time then
             discarding them (but returning S_OK)
     --  Supports IMediaPosition if the pin it's connect to does
*/

class CStateInputPin : public CBaseInputPin
{
public:

    CStateInputPin(
        TCHAR            *pObjectName,
        CBaseFilter      *pFilter,
        CCritSec         *pLock,
        HRESULT          *phr,
        LPCWSTR           pName);

    // Synchronize our state setting
    virtual HRESULT SetState(FILTER_STATE) = 0;
};

class CSinkFilter : public CBaseFilter
{
public:
    CSinkFilter(LPUNKNOWN, HRESULT *);
    ~CSinkFilter();
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void **ppv);

    virtual int GetPinCount();
    virtual CBasePin * GetPin(int n);
    STDMETHODIMP Run(REFERENCE_TIME tStart)
    {
        CAutoLock lck(m_pLock);
        m_tStart = tStart;
        if (m_State != State_Running) {
            m_State = State_Running;
            m_pInputPin->SetState(State_Running);
        }
        return S_OK;
    };
    STDMETHODIMP Pause()
    {
        CAutoLock lck(m_pLock);
        if (m_State != State_Paused) {
            m_State = State_Paused;
            m_pInputPin->SetState(State_Paused);
        }
        return S_OK;
    };
    STDMETHODIMP Stop()
    {
        CAutoLock lck(m_pLock);
        if (m_State != State_Stopped) {
            m_State = State_Stopped;
            m_pInputPin->SetState(State_Stopped);
        }
        return S_OK;
    };
    // Special method to set the media type we support
    void SetMediaType(const AM_MEDIA_TYPE *pmt) { m_mtype = *pmt; };

    // Get the type for the pin
    CMediaType        GetMediaType() { return CMediaType(m_mtype); };

protected:
    CCritSec          m_CritSec;
    CStateInputPin   *m_pInputPin;
    CPosPassThru     *m_pPosition;
    CMediaType        m_mtype;
};


class CSinkPin : public CStateInputPin
{
public:
    CSinkPin(CSinkFilter *, CCritSec *, HRESULT *);
    ~CSinkPin();

    // check that we can support this output type
    HRESULT CheckMediaType(const CMediaType* mtIn)
    {
        CMediaType mt = m_pMediaFilter->GetMediaType();
        // Check against our type
        if (*mt.Type() == GUID_NULL) {
            return S_OK;
        }
        if (*mtIn->Type() == *mt.Type()) {
            if (*mt.Subtype() == *mtIn->Subtype() ||
                *mt.Subtype() == GUID_NULL) {
                return S_OK;
            } else {
                return E_FAIL;
            }
        } else {
            return E_FAIL;
        }
    };

    // --- IPin --- */
    // override to pass downstream
    STDMETHODIMP BeginFlush();
    STDMETHODIMP EndFlush();
    STDMETHODIMP EndOfStream();

    // --- IMemInputPin -----

    // here's the next block of data from the stream.
    // AddRef it yourself if you need to hold it beyond the end
    // of this call.
    STDMETHODIMP Receive(IMediaSample * pSample);


    // We support just 1 media type
    virtual HRESULT GetMediaType(int iPosition,CMediaType *pMediaType)
    {
        if (iPosition != 0) { return S_FALSE; };
        *pMediaType = CMediaType();
        return S_OK;
    };

    // Special method to synchronize state changes
    HRESULT SetState(FILTER_STATE);


private:
    CSinkFilter         *m_pMediaFilter;
    CCritSec             m_PlayCritSec;
    BOOL                 m_bHoldingOnToBuffer;
    BOOL                 m_bFlushing;
    FILTER_STATE          m_State;
    CAMEvent               m_StateChange;
    CAMEvent               m_StateChanged;
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\inc\tstream.h ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

/*
    tStream.h

    Some classes for test IStreams

    NOTE - stmonfil.h must be included before including this file

*/

/*  Our IStream - override ByteAt to change the function */
class CIStreamOnFunction : public CSimpleStream
{
public:
    /*  Constructor */
    CIStreamOnFunction(LPUNKNOWN pUnk,
                       LONGLONG llLength,
                       BOOL bSeekable,
                       HRESULT *phr);

    /*  Override this for more interesting streams */
    virtual ByteAt(LONGLONG llPos);

    /*  IStream overrides */
    STDMETHODIMP Read(void * pv, ULONG cb, PULONG pcbRead);
    STDMETHODIMP Seek(LARGE_INTEGER dlibMove, DWORD dwOrigin,
                      ULARGE_INTEGER *plibNewPosition);
    STDMETHODIMP Stat(STATSTG *pstatstg, DWORD grfStatFlag);

private:
    LONGLONG  m_llPosition;
    BOOL      m_bSeekable;
    LONGLONG  m_llLength;
};

/*
   This class exposes an IStream.  The IStream can be used multiple
   times because we share it via the critical section passed to the
   constructor.
*/

class CIStreamOnIStream : public CSimpleStream
{
public:
    CIStreamOnIStream(LPUNKNOWN pUnk,
                      IStream  *pStream,
                      BOOL      bSeekable,
                      CCritSec *pLock,
                      HRESULT  *phr);
    ~CIStreamOnIStream();

    STDMETHODIMP Read(void * pv, ULONG cb, PULONG pcbRead);
    STDMETHODIMP Seek(LARGE_INTEGER dlibMove, DWORD dwOrigin,
                      ULARGE_INTEGER *plibNewPosition);
    STDMETHODIMP Stat(STATSTG *pstatstg, DWORD grfStatFlag);

private:
    LONGLONG  m_llLength;
    IStream  *m_pStream;       // The stream we're based on
    LONGLONG  m_llPosition;    // Maintain current position
    BOOL      m_bSeekable;     // Whether we can seek
    CCritSec *m_pLock;         // Sharing m_pStream
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testsplt\dialogs.h ===
#define ID_TIME                     101
#define DLG_FRAMETIME               100
BOOL CALLBACK FrameTimeDlg(HWND hwnd, UINT uiMsg, WPARAM wParam, LPARAM lParam);
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testlib\sink.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

#include <streams.h>
#include "sink.h"

/*

    Implement a sink filter and its associated pin

    CSinkFilter - the filter
    CSinkPin    - the pin

*/

/*  State input pin implementation */
CStateInputPin::CStateInputPin(
    TCHAR *pObjectName,
    CBaseFilter *pFilter,
    CCritSec *pLock,
    HRESULT *phr,
    LPCWSTR pName) :
    CBaseInputPin(pObjectName, pFilter, pLock, phr, pName)
{
}

/*  Implement methods for sink filter class */

CSinkFilter::CSinkFilter(LPUNKNOWN lpUnk, HRESULT *phr)  :
    CBaseFilter(NAME("Sink Filter"), lpUnk, &m_CritSec, CLSID_NULL),
    m_pInputPin(NULL),
    m_pPosition(NULL)
{
}

CSinkFilter::~CSinkFilter()
{
    delete m_pPosition;
    delete m_pInputPin;
}

int CSinkFilter::GetPinCount()
{
    return 1;
}

CBasePin *CSinkFilter::GetPin(int n)
{
    if (n == 0) {
        return m_pInputPin;
    } else {
        return NULL;
    }
}

// overriden to expose IMediaPosition and IMediaSelection control interfaces

STDMETHODIMP CSinkFilter::NonDelegatingQueryInterface(REFIID riid, void **ppv)
{
    *ppv = NULL;

    if (riid == IID_IMediaPosition || riid == IID_IMediaSeeking) {
        if (m_pPosition == NULL) {

            HRESULT hr = S_OK;
            m_pPosition = new CPosPassThru(NAME("sink CPosPassThru"),
                                           GetOwner(),
                                           &hr,
                                           m_pInputPin);
            if (m_pPosition == NULL) {
                return E_OUTOFMEMORY;
            }

            if (FAILED(hr)) {
                delete m_pPosition;
                m_pPosition = NULL;
                return hr;
            }
        }
        return m_pPosition->NonDelegatingQueryInterface(riid, ppv);
    } else {
        return CBaseFilter::NonDelegatingQueryInterface(riid, ppv);
    }
}


CSinkPin::CSinkPin(CSinkFilter * pFilter, CCritSec *pLock, HRESULT * phr) :
    CStateInputPin(NAME("CSinkPin Pin"), pFilter, pLock, phr, L"Sink"),
    m_bHoldingOnToBuffer(FALSE),
    m_bFlushing(FALSE),
    m_pMediaFilter(pFilter)
{
}
CSinkPin::~CSinkPin()
{
};

// --- IMemInputPin -----

// here's the next block of data from the stream.
// AddRef it yourself if you need to hold it beyond the end
// of this call.
STDMETHODIMP CSinkPin::Receive(IMediaSample * pSample)
{
    HRESULT hr;

    /*  If we're paused just hold on to it - that means looping
        If we're not paused then wait until it's time to play

        Also wait for Inactive() or Flush()
    */
    while (TRUE) {
        {
            CAutoLock lck(&m_PlayCritSec);
            m_bHoldingOnToBuffer = TRUE;
            if (m_State == State_Stopped) {
                hr = E_INVALIDARG;
                break;
            }
            if (m_bFlushing) {
                hr = S_FALSE;
                break;
            }
            m_bHoldingOnToBuffer = TRUE;
        }
        /*  Not stopped so carry on */
        REFERENCE_TIME tStart, tStop;
        hr = pSample->GetTime(&tStart, &tStop);
        DWORD dwTimeout;

        if (m_State == State_Paused) {
            dwTimeout = INFINITE;
        } else {
            CRefTime tStream;
            hr = m_pMediaFilter->StreamTime(tStream);
            if (FAILED(hr)) {
                break;
            }
            if (tStream >= CRefTime(tStop)) {
                hr = S_OK;
                break;
            } else {
                CRefTime t(tStop);
                t -= tStream;
                dwTimeout = t.Millisecs();
            }
        }
        DWORD dwResult = WaitForSingleObject(m_StateChange, dwTimeout);

        /*  Did we 'complete' the buffer or did we just get told
            to flush (or did nothing actually happen?)
        */
        if (dwResult == WAIT_TIMEOUT) {
            /*  We 'played' the sample */
            hr = S_OK;
            break;
        } else {
            /*  We may have been told to - go back to the start and find out
            */
        }
    }

    /*  Synchronize on exit */
    CAutoLock lck(&m_PlayCritSec);

    /*  Make sure we tidy up in the general case */
    if (m_bFlushing) {
        m_bFlushing = FALSE;
        m_StateChanged.Set();
    }
    m_bHoldingOnToBuffer = FALSE;
    m_bFlushing          = FALSE;
    return hr;
}

// override to pass downstream
STDMETHODIMP CSinkPin::BeginFlush()
{
    CAutoLock lck(m_pLock);
    if (IsStopped()) {
        return E_FAIL;
    }
    while (TRUE) {
        {
            CAutoLock lck1(&m_PlayCritSec);
            if (!m_bHoldingOnToBuffer) {
                m_bFlushing = FALSE;
                return S_OK;
            }
            m_bFlushing = TRUE;
        }
        m_StateChange.Set();
        WaitForSingleObject(m_StateChanged, INFINITE);
    }
}

// EndFlush says start accepting data again
STDMETHODIMP CSinkPin::EndFlush()
{
    CAutoLock lck(&m_PlayCritSec);
    m_bFlushing = FALSE;
    return S_OK;
}

// End Of Stream
STDMETHODIMP CSinkPin::EndOfStream()
{
    m_pFilter->NotifyEvent(EC_COMPLETE, S_OK, 0);
    return S_OK;
}

// Set the new state - synchronzied with our critical section
// NOTE - we MUST be also synchronized with the filter state
HRESULT CSinkPin::SetState(FILTER_STATE State)
{
    if (State != m_State) {
        {
            CAutoLock lck(&m_PlayCritSec);
            m_State = State;
        }
        if (State == State_Stopped) {
            BeginFlush();
        } else {
            m_StateChange.Set();
        }
    }
    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testsplt\objects.h ===
// Copyright (c) Microsoft Corporation 1996. All Rights Reserved


class CTestError
{
public:
    CTestError(int iTestError)
    {
        m_iError = iTestError;
    };
    int ErrorCode() { return m_iError; };

private:
    int   m_iError;
};

/*
    Test pins, filters etc

*/

class CTestSplt;

class CTestSourcePin : public CSourcePin
{
public:
    CTestSourcePin(CTestSplt   *pTest,
                   IStream     *pStream,
                   BOOL         bSupportSeek,
                   LONG         lSize,
                   LONG         lCount,
                   CBaseFilter *pFilter,
                   CCritSec    *pLock,
                   HRESULT     *phr) :
         CSourcePin(new CIStreamOnIStream(NULL,
                                          pStream,
                                          bSupportSeek,
                                          &m_CritStream,
                                          phr),
                    bSupportSeek,
                    lSize,
                    lCount,
                    pFilter,
                    pLock,
                    phr),
         m_pStream(NULL),
         m_pTest(pTest)
    {
         m_pStream = new CIStreamOnIStream(CBaseOutputPin::GetOwner(),
                                           pStream,
                                           bSupportSeek,
                                           &m_CritStream,
                                           phr);
    };

    ~CTestSourcePin()
    {
    };

    // Return the IStream interface if it was requested
    STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void ** pv)
    {
        if (riid == IID_IStream) {
            return m_pStream->NonDelegatingQueryInterface(riid, pv);
        } else {
            return CSourcePin::NonDelegatingQueryInterface(riid, pv);
        }
    };

private:
    CIStreamOnIStream *m_pStream;
    CCritSec           m_CritStream;  // Share stream across multiple streams
    CTestSplt  * const m_pTest;
};

/*  Source pin implementation */
class CTestSource : public CSourceFilter
{
public:
    CTestSource(CTestSplt *pTest,
                IStream   *pStream,
                BOOL       bSupportSeek,
                LONG       lSize,
                LONG       lCount,
                HRESULT   *phr) :
        CSourceFilter(NULL, phr)
    {
        m_pOutputPin = new CTestSourcePin(pTest,
                                          pStream,
                                          bSupportSeek,
                                          lSize,
                                          lCount,
                                          this,
                                          &m_CritSec,
                                          phr);
        if (m_pOutputPin == NULL) {
            *phr = E_OUTOFMEMORY;
            return;
        }
    };
    ~CTestSource()
    {
    };
};

class CTestSink : public CSinkFilter
{
public:
    CTestSink(CTestSplt *pTest, HRESULT *phr);
    ~CTestSink() {};
    STDMETHODIMP Run(REFERENCE_TIME t) {
        m_dwSamples = 0;
        return CSinkFilter::Run(t);
    };
    void Wait() { TestWaitForSingleObject(m_Event); };
    void Set() { m_Event.Set(); };
    /* Number of samples processed */
    DWORD GetSamples() { return m_dwSamples; };
    /* Display times? */
    void SetDisplay(BOOL bDisplay) { m_bDisplay = bDisplay; };
    BOOL    m_bDisplay;
    DWORD   m_dwSamples;
private:
    CAMEvent  m_Event;
};


class CTestInputPin : public CSinkPin
{
public:
    CTestInputPin(CTestSplt *pTest, CSinkFilter *pFilter, CCritSec *pLock,
                  HRESULT *phr) :
        CSinkPin(pFilter, pLock, phr),
        m_pSinkFilter(pFilter),
        m_pTest(pTest),
        m_tStartPrev(-1000000L),
        m_bGotStart(FALSE)
    {
    };

    ~CTestInputPin()
    {
    };

    /*  Track time stamps */
    STDMETHODIMP Receive(IMediaSample *pSample);
    /* Trap EndOfStream */
    STDMETHODIMP EndOfStream();

private:
    CSinkFilter  *m_pSinkFilter;
    CTestSplt    *m_pTest;
    CRefTime      m_tStartPrev;
    BOOL          m_bGotStart;
};


class CTestSplt
{
public:
    CTestSplt(IStream *pStream, BOOL bSeekable, LONG lSize, LONG lCount);
    ~CTestSplt();
    void TestConnectInput();
    void TestConnectOutput();
    void TestDisconnect();
    void SetState(FILTER_STATE s)
    {
        switch (s) {
        case State_Stopped:
            m_pMF->Stop();
            m_pSource->Stop();
            break;

        case State_Paused:
            m_pMF->Pause();
            m_pSource->Pause();
            break;

        case State_Running:
            m_pMF->Run(GetStart());
            m_pSource->Run(GetStart());
            break;
        }
    };
    void TestPause();
    void TestRun();
    void TestStop();
    void TestSend();

    void Fail() { m_iResult = TST_FAIL; };

    IBaseFilter      *GetSplitter() { return m_pF; };
    REFERENCE_TIME GetStart() { return m_tStart; };

    virtual void CheckStart(CRefTime& tStart) {};
    virtual BOOL IsMedium() { return FALSE; };
    virtual void CheckPosition(LONGLONG llStart, LONGLONG llStop) {};


protected:

    CTestSource     *m_pSource;      // Our source filter
    IReferenceClock *m_pClock;       // Global clock
    IBaseFilter     *m_pF;           // Splitter's IBaseFilter
    IMediaFilter    *m_pMF;          // Splitter's IMediaFilter
    IPin            *m_pInput;       // Splitter's input pin
    BOOL             m_bInputConnected; // Have we connected the input?
    REFERENCE_TIME    m_tStart;

    /*  Play from to stuff */
    REFERENCE_TIME    m_tPlayStart;
    REFERENCE_TIME    m_tPlayStop;
    LONGLONG          m_llPlayStart;
    LONGLONG          m_llPlayStop;

    /*  'return code' */
    int              m_iResult;
};

class CTestOutputConnection
{
public:
    CTestOutputConnection(CTestSplt *pTest,
                          REFCLSID clsidCodec,
                          IReferenceClock *pClock,
                          const AM_MEDIA_TYPE *pmt = NULL);
    ~CTestOutputConnection();

    IMediaSeeking *GetSinkSeeking() { return m_pSeeking; };
    CTestSink *GetSink() { return m_pSink; };

    HRESULT SetState(FILTER_STATE s)
    {
        IMediaFilter *pMF;
        EXECUTE_ASSERT(SUCCEEDED(m_pFilter->QueryInterface(IID_IMediaFilter,
                                                           (void **)&pMF)));
        HRESULT hr = E_FAIL;
        switch (s) {
        case State_Stopped:
            m_pSink->Stop();
            hr = pMF->Stop();
            break;

        case State_Paused:
            m_pSink->Pause();
            hr = pMF->Pause();
            break;

        case State_Running:
            m_pSink->Run(m_pTest->GetStart());
            hr = pMF->Run(m_pTest->GetStart());
            break;
        }
        pMF->Release();
        return hr;
    };

    void Wait() { m_pSink->Wait(); };

private:
    IBaseFilter    *m_pFilter;
    IMediaSeeking  *m_pSeeking;
    CTestSink        *m_pSink;
    CTestSplt * const m_pTest;
};

class CTestPosition : public CTestSplt
{
public:
    CTestPosition(IStream *pStream, LONG lSize, LONG lCount);
    ~CTestPosition();
    void SetConnections(BOOL bAudio, BOOL bVideo, const AM_MEDIA_TYPE *pmt = NULL);
    int TestPlay(REFERENCE_TIME tStart, REFERENCE_TIME tStop);
    int TestMediumPlay(LONGLONG tStart, LONGLONG tStop, const GUID *TimeFormat,
                       IMediaSeeking *pSeeking);
    int TestSeek(BOOL bAudio, BOOL bVideo);
    int TestMediumSeek(BOOL bAudio, BOOL bVideo, const GUID *TimeFormat);
    int PerfPlay(BOOL bAudio, BOOL bVideo, const GUID *VideoType);
    int TestFrame(CRefTime tFrame);
    int TestVideoFrames();
    int TestVideoFrame(REFTIME d);
    void SetState(FILTER_STATE s)
    {
        if (s == State_Running) {
            m_pClock->GetTime(&m_tStart);
            m_tStart = CRefTime(m_tStart) + CRefTime(100L);
        }
        if (m_pAudio) {
            m_pAudio->SetState(s);
        }
        if (m_pVideo) {
            m_pVideo->SetState(s);
        }
        CTestSplt::SetState(s);
    };

    void CheckStart(CRefTime& tStart)
    {
        if (tStart + CRefTime(m_tPlayStart) > CRefTime(m_tDuration)) {
            tstLog(TERSE,
                   "Sample start time too late - offset %s",
                   (LPCTSTR)CDisp(tStart + CRefTime(m_tPlayStart)));
            Fail();
        }
    };
    void CheckPosition(LONGLONG llStart, LONGLONG llStop)
    {
        if (llStart < m_llPlayStart) {
            tstLog(TERSE, "Sample medium time before start!");
#if 0
            Fail();
#endif
        }
        if (llStop > m_llPlayStop) {
            tstLog(TERSE, "Sample medium time after stop!");
            Fail();
        }
    };
    BOOL IsMedium() {
        return m_bMedium;
    };

private:
    REFERENCE_TIME          m_tDuration;
    LONGLONG                m_llDuration;
    CTestOutputConnection * m_pAudio;
    CTestOutputConnection * m_pVideo;
    BOOL                    m_bMedium;    // Is this a Medium seek?
};
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testlib\stream.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved


#include <streams.h>
#include <stmonfil.h>
#include <tstream.h>

/*

     Implement a couple of IStream classes for testing

*/


/*  Constructor */
CIStreamOnFunction::CIStreamOnFunction(LPUNKNOWN pUnk,
                                       LONGLONG llLength,
                                       BOOL bSeekable,
                                       HRESULT *phr) :
    CSimpleStream(NAME("CIStreamOnFunction"), pUnk, phr),
    m_llPosition(0), m_llLength(llLength),
    m_bSeekable(bSeekable)
{
}

/*  Override this for more interesting streams */
CIStreamOnFunction::ByteAt(LONGLONG llPos) { return (BYTE)llPos; }

STDMETHODIMP CIStreamOnFunction::Read(void * pv, ULONG cb, PULONG pcbRead)
{
    PBYTE pb = (PBYTE)pv;
    *pcbRead = 0;
    while (*pcbRead < cb &&
           (!m_bSeekable || m_llPosition < m_llLength)) {
        *pb = ByteAt(m_llPosition);
        *pcbRead = *pcbRead + 1;
        pb++;
        m_llPosition++;
    }
    return S_OK;
}

STDMETHODIMP CIStreamOnFunction::Seek(LARGE_INTEGER dlibMove, DWORD dwOrigin,
                  ULARGE_INTEGER *plibNewPosition)
{
    if (!m_bSeekable) {
        return E_NOTIMPL;
    }
    LONGLONG llNewPosition;
    switch (dwOrigin) {
    case STREAM_SEEK_SET:
        llNewPosition = dlibMove.QuadPart;
        break;
    case STREAM_SEEK_CUR:
        llNewPosition = m_llPosition + dlibMove.QuadPart;
        break;
    case STREAM_SEEK_END:
        llNewPosition = m_llLength + dlibMove.QuadPart;
        break;
    }
    if (llNewPosition < 0) {
        llNewPosition = 0;
    } else {
        if (llNewPosition > m_llLength) {
            llNewPosition = m_llLength;
        }
    }
    plibNewPosition->QuadPart = (DWORDLONG)llNewPosition;
    m_llPosition              = llNewPosition;
    return S_OK;
}
STDMETHODIMP CIStreamOnFunction::Stat(STATSTG *pstatstg,
                  DWORD grfStatFlag)
{
    ZeroMemory((PVOID)pstatstg, sizeof(*pstatstg));
    pstatstg->type              = STGTY_STREAM;
    pstatstg->cbSize.QuadPart   = (DWORDLONG)m_llLength;
    pstatstg->clsid             = CLSID_NULL;

    return S_OK;
}

/* -- CIStreamOnIStream implementation -- */

CIStreamOnIStream::CIStreamOnIStream(LPUNKNOWN pUnk,
                  IStream  *pStream,
                  BOOL      bSeekable,
                  CCritSec *pLock,
                  HRESULT  *phr) :
    CSimpleStream(NAME("CIStreamOnIStream"), pUnk, phr),
    m_pStream(pStream),
    m_bSeekable(bSeekable),
    m_llPosition(0),
    m_pLock(pLock)
{
    if (pStream == NULL) {
        *phr = E_OUTOFMEMORY;
        return;
    }
    pStream->AddRef();
    if (bSeekable) {
        STATSTG statstg;
        HRESULT hr = pStream->Stat(&statstg, STATFLAG_NONAME);
        if (FAILED(hr)) {
            *phr = hr;
            return;
        }
        m_llLength = (LONGLONG)statstg.cbSize.QuadPart;
    }
}
CIStreamOnIStream::~CIStreamOnIStream()
{
    m_pStream->Release();
}

STDMETHODIMP CIStreamOnIStream::Read(void * pv, ULONG cb, PULONG pcbRead)
{
    LARGE_INTEGER  liSeekTarget;
    ULARGE_INTEGER liSeekResult;

    CAutoLock lck(m_pLock);

    liSeekTarget.QuadPart = m_llPosition;
    if (m_bSeekable) {
        HRESULT hr = m_pStream->Seek(liSeekTarget,
                                     STREAM_SEEK_SET,
                                     &liSeekResult);
        if (FAILED(hr)) {
            return hr;
        }
        if ((LONGLONG)liSeekResult.QuadPart != liSeekTarget.QuadPart) {
            return E_FAIL;
        }
    }
    HRESULT hr = m_pStream->Read(pv, cb, pcbRead);
    if (SUCCEEDED(hr)) {
        m_llPosition += *pcbRead;
    }
    return hr;
}

STDMETHODIMP CIStreamOnIStream::Seek(LARGE_INTEGER dlibMove, DWORD dwOrigin,
                  ULARGE_INTEGER *plibNewPosition)
{
    if (!m_bSeekable) {
        return E_NOTIMPL;
    }
    CAutoLock lck(m_pLock);
    LONGLONG llNewPosition;
    switch (dwOrigin) {
    case STREAM_SEEK_SET:
        llNewPosition = dlibMove.QuadPart;
        break;
    case STREAM_SEEK_CUR:
        llNewPosition = m_llPosition + dlibMove.QuadPart;
        break;
    case STREAM_SEEK_END:
        llNewPosition = m_llLength + dlibMove.QuadPart;
        break;
    }
    if (llNewPosition < 0) {
        llNewPosition = 0;
    } else {
        if (llNewPosition > m_llLength) {
            llNewPosition = m_llLength;
        }
    }
    plibNewPosition->QuadPart = (DWORDLONG)llNewPosition;
    m_llPosition              = llNewPosition;
    return S_OK;
}
STDMETHODIMP CIStreamOnIStream::Stat(STATSTG *pstatstg,
                  DWORD grfStatFlag)
{
    return m_pStream->Stat(pstatstg, grfStatFlag);
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testlib\src.cpp ===
// Copyright (c) Microsoft Corporation 1994-1996. All Rights Reserved

#include <streams.h>
#include "src.h"

/*  Implement methods for Source filter class */

CSourceFilter::CSourceFilter(LPUNKNOWN lpUnk, HRESULT *phr)  :
    CBaseFilter(NAME("Source Filter"), lpUnk, &m_CritSec, CLSID_NULL),
    m_pOutputPin(NULL)
{
}

CSourceFilter::~CSourceFilter()
{
    delete m_pOutputPin;
}


/*  Source pin stuff */

CSourcePin::CSourcePin(IStream *pStream,
                       BOOL bSupportSeek,
                       LONG lSize,
                       LONG lCount,
                       CBaseFilter *pFilter,
                       CCritSec *pLock,
                       HRESULT *phr) :
    CBaseOutputPin(NAME("CSourcePin"), pFilter, pLock, phr, L"Source"),
    CSourcePosition(NAME("CSourcePin:CSourcePosition"),
                    CBaseOutputPin::GetOwner(),
                    phr,
                    pLock),
    m_pStream(pStream),
    m_lSize(lSize),
    m_lCount(lCount),
    m_bSupportPosition(bSupportSeek),
    m_bDiscontinuity(FALSE)
{
    pStream->AddRef();
    /*  Set the default stop position */
    STATSTG statstg;
    pStream->Stat(&statstg, STATFLAG_NONAME);
    m_Stop = COARefTime((double)(LONGLONG)statstg.cbSize.QuadPart);
    m_Start = COARefTime(); // Set to 0
}

CSourcePin::~CSourcePin()
{
    m_pStream->Release();
}

HRESULT CSourcePin::DecideBufferSize(
    IMemAllocator *pAllocator,
    ALLOCATOR_PROPERTIES * pProp)
{
    ALLOCATOR_PROPERTIES propActual;
    pProp->cBuffers = m_lCount;
    pProp->cbBuffer = m_lSize;
    // happy to leave alignment and prefix in the hands of the
    // sink
    return pAllocator->SetProperties(pProp, &propActual);
}

// BeginFlush downstream
void CSourcePin::DoBeginFlush()
{
    CAutoLock lck(&m_PlayCritSec);
    DeliverBeginFlush();
}

// BeginFlush downstream
void CSourcePin::DoEndFlush()
{
    CAutoLock lck(&m_PlayCritSec);
    DeliverEndFlush();
}

HRESULT CSourcePin::ChangeStart()
{
    /*  Flush */
    DoBeginFlush();
    CallWorker(Thread_Stop);
    DoEndFlush();
    m_bDiscontinuity = TRUE;
    CallWorker(Thread_SetStart);
    return S_OK;
}
HRESULT CSourcePin::ChangeStop()
{
    CallWorker(Thread_SetStop);
    return S_OK;
}
HRESULT CSourcePin::ChangeRate()
{
    return E_NOTIMPL;
}

HRESULT CSourcePin::Active()
{
    DbgLog((LOG_TRACE, 2, TEXT("CSourcePin::Active()")));
    HRESULT hr = CBaseOutputPin::Active();
    if (FAILED(hr)) {
        return hr;
    }
    // Create the thread
    ASSERT(!ThreadExists());
    if (!Create()) {
        return E_OUTOFMEMORY;
    }
    m_bDiscontinuity = TRUE;
    CallWorker(Thread_SetStart);
    return S_OK;
}

HRESULT CSourcePin::Inactive()
{
    DbgLog((LOG_TRACE, 2, TEXT("CSourcePin::Inactive()")));
    CallWorker(Thread_Terminate);
    Close();
    return CBaseOutputPin::Inactive();
}

DWORD CSourcePin::ThreadProc()
{
    DbgLog((LOG_TRACE, 2, TEXT("CSourcePin::ThreadProc")));
    while (TRUE) {
        HRESULT hr;
        DWORD dwRequest = GetRequest();
        switch (dwRequest) {
        case Thread_Terminate:
            Reply(0);
            DbgLog((LOG_TRACE, 2, TEXT("CSourcePin::ThreadProc exiting")));
            return 0;

        case Thread_SetStart:
            DbgLog((LOG_TRACE, 2, TEXT("CSourcePin::ThreadProc SetStart")));
            // Start from start (again?) if we can
            m_liCurrent.QuadPart = Start();
            m_liStop.QuadPart    = Stop();
            Reply(0);
            hr = Play();
            if (FAILED(hr)) {
                DbgLog((LOG_ERROR, 2, TEXT("Play() failed code 0x%8.8X")));
            }
            break;

        case Thread_SetStop:
            DbgLog((LOG_TRACE, 2, TEXT("CSourcePin::ThreadProc SetStop")));
            // Start from current
            m_liStop.QuadPart    = Stop();
            Reply(0);
            hr = Play();
            break;

        case Thread_Stop:
            Reply(0);
            break;
        }
        if (FAILED(hr)) {
            m_pFilter->NotifyEvent(EC_ERRORABORT, hr, 0);
        }
    }
}

/*  Play from m_liCurrent to m_liStop */
HRESULT CSourcePin::Play()
{
    /* Seek to the start (if possible!) */
    if (m_bSupportPosition) {
        ULARGE_INTEGER liSeekResult;
        m_pStream->Seek(m_liCurrent,
                        STREAM_SEEK_SET,
                        &liSeekResult);
    }
    DbgLog((LOG_TRACE, 2, TEXT("CSourcePin playing from %s to %s"),
            (LPCTSTR)CDisp(m_liCurrent.QuadPart),
            (LPCTSTR)CDisp(m_liStop.QuadPart)));

    /*  Now just loop sending data to the output pin */
    DWORD dwRequest;
    while (!CheckRequest(&dwRequest)) {
        IMediaSample *pSample;
        HRESULT hr = GetDeliveryBuffer(&pSample,NULL,NULL,0);
        if (FAILED(hr)) {
            return hr;
        }
        PBYTE pbData;
        LONG  lData = pSample->GetSize();
        EXECUTE_ASSERT(SUCCEEDED(pSample->GetPointer(&pbData)));

        /*  Adjust for stop time */
        if (m_bSupportPosition != 0) {
            if (m_liCurrent.QuadPart + lData > m_liStop.QuadPart) {
                if (m_liCurrent.QuadPart >= m_liStop.QuadPart) {
                    /* 'end of stream' */
                    pSample->Release();
                    DoEndOfStream();
                    return 0;
                } else {
                    lData = (LONG)(m_liStop.QuadPart - m_liCurrent.QuadPart);
                }
            }
        }

        /*  Read the data */
        ULONG cbRead;
        hr = m_pStream->Read((PVOID)pbData,
                             (ULONG)lData,
                             &cbRead);
        if (FAILED(hr)) {
            pSample->Release();
            DoEndOfStream();
            return hr;
        }

        /*  Put the data in the sample */
        if (cbRead != 0) {
            pSample->SetActualDataLength((LONG)cbRead);
            REFERENCE_TIME tStart, tStop;

            tStart = m_liCurrent.QuadPart -
                                      Start();
            m_liCurrent.QuadPart += cbRead;
            tStop = m_liCurrent.QuadPart -
                                     Start();
            pSample->SetTime(&tStart, &tStop);

            DbgLog((LOG_TRACE, 4, TEXT("CSourcePin : Sending sample size %d"),
                    cbRead));

            if (m_bDiscontinuity) {
                m_bDiscontinuity = FALSE;
                /*  Send NewSegment */
                DeliverNewSegment(m_Start, m_Stop, 1.0);
                pSample->SetDiscontinuity(TRUE);
            }

            hr = Deliver(pSample);
            pSample->Release();

            /*  S_FALSE means stop sending */
            if (S_OK != hr) {
                return hr;
            }
        }
        if (cbRead != (DWORD)lData) {
            DoEndOfStream();
            return S_OK;
        }
    }
    return S_OK;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testsplt\testfg.cpp ===
// Copyright (c) Microsoft Corporation 1996. All Rights Reserved


#include <stdio.h>
#include <streams.h>
#include <src.h>
#include <sink.h>
#include <tstshell.h>
#include <testfuns.h>
#include <stmonfil.h>
#include <tstream.h>
#include "tstwrap.h"

//--------------------------------------------------------------------------;
//
//  int expect
//
//  Description:
//      Compares the expected result to the actual result.  Note that this
//      function is not at all necessary; rather, it is a convenient
//      method of saving typing time and standardizing output.  As an input,
//      you give it an expected value and an actual value, which are
//      unsigned integers in our example.  It compares them and returns
//      TST_PASS indicating that the test was passed if they are equal, and
//      TST_FAIL indicating that the test was failed if they are not equal.
//      Note that the two inputs need not be integers.  In fact, if you get
//      strings back, you can modify the function to use lstrcmp to compare
//      them, for example.  This function is NOT to be copied to a test
//      application.  Rather, it should serve as a model of construction to
//      similar functions better suited for the specific application in hand
//
//  Arguments:
//      UINT uExpected: The expected value
//
//      UINT uActual: The actual value
//
//      LPSTR CaseDesc: A description of the test case
//
//  Return (int): TST_PASS if the expected value is the same as the actual
//      value and TST_FAIL otherwise
//
//   History:
//      06/08/93    T-OriG (based on code by Fwong)
//
//--------------------------------------------------------------------------;

int expect
(
    UINT    uExpected,
    UINT    uActual,
    LPSTR   CaseDesc
)
{
    if(uExpected == uActual)
    {
        tstLog(TERSE, "PASS : %s",CaseDesc);
        return(TST_PASS);
    }
    else
    {
        tstLog(TERSE,"FAIL : %s",CaseDesc);
        return(TST_FAIL);
    }
} // Expect()

/***************************************************************************\
*                                                                           *
*   BOOL CheckResult                                                        *
*                                                                           *
*   Description:                                                            *
*       Check an HRESULT, and notify if failed                              *
*                                                                           *
*   Arguments:                                                              *
*       HRESULT hr:         The value to check                              *
*       LPTSTR szAction:    String to notify on failure                     *
*                                                                           *
*   Return (void):                                                          *
*       True if HRESULT is a success code, FALSE if a failure code          *
*                                                                           *
\***************************************************************************/

BOOL
CheckResult(HRESULT hr, LPTSTR szAction)
{
    if (FAILED(hr)) {
        tstLog(TERSE, "%s failed: 0x%x", szAction, hr);
        return FALSE;
    }
    return TRUE;
}



/*  Tests using the filter graph (actually nothing to do with MPEG */

/***************************************************************************\
*                                                                           *
*   IMediaControl* OpenGraph                                                 *
*                                                                           *
*   Description:                                                            *
*       Instantiate the filtergraph and open a file                         *
*                                                                           *
*   Arguments:                                                              *
*                                                                           *
*   Return (void):                                                          *
*       Pointer to the IMediaControl interface of the filter graph, or NULL *
*       on failure                                                          *
*                                                                           *
\***************************************************************************/

IMediaControl*
OpenGraph(void)
{
    WCHAR wszFile[100];

    if (lstrlen(szSourceFile) == 0) {
        SelectFile();
    }
#ifdef UNICODE
    lstrcpy(wszFile, szSourceFile);
#else
    MultiByteToWideChar(GetACP(), 0, szSourceFile, lstrlen(szSourceFile) + 1,
                        wszFile, 100);
#endif
    tstLog(TERSE, TEXT("Opening %s"), szSourceFile);

    // instantiate the filtergraph
    IGraphBuilder* pFG;
    HRESULT hr = CoCreateInstance(
                            CLSID_FilterGraph,
                            NULL,
                            CLSCTX_INPROC,
                            IID_IGraphBuilder,
                            (void**) &pFG);
    if (!CheckResult(hr, "Open")) {
        return NULL;
    }

    // tell it to build the graph for this file
    hr = pFG->RenderFile(wszFile, NULL);

    if (!CheckResult(hr, "RenderFile") ) {
        pFG->Release();
        return NULL;
    }

    // get and IBasicVideo interface
    IVideoWindow *pVideo;
    hr = pFG->QueryInterface(IID_IVideoWindow, (void **)&pVideo);
    if (SUCCEEDED(hr)) {
        pVideo->put_Left(500);
        pVideo->put_Top(400);
        pVideo->Release();
    }

    // get an IMediaControl interface
    IMediaControl* pMF;
    hr = pFG->QueryInterface(IID_IMediaControl, (void**) &pMF);
    if (!CheckResult(hr, "QI for IMediaControl")) {
        pFG->Release();
        return NULL;
    }

    // dont need this. We keep the IMediaControl around and
    // release that to get rid of the filter graph
    pFG->Release();

    tstLog(VERBOSE, "Open Completed");
    return pMF;
}


//
//  Wait for a play to complete
//
int WaitForPlayComplete(IMediaControl *pMC, IMediaPosition *pMP, LONG& lCode, LONG& lP1, LONG& lP2, BOOL bDbgOut)
{
    BOOL bFailed = FALSE;
    // wait for completion
    REFTIME tCurr;

    IMediaEvent * pME;
    HRESULT hr = pMC->QueryInterface(IID_IMediaEvent, (void**)&pME);
    if (FAILED(hr)) {
        tstLog(TERSE, "Failed to get IMediaEvent");
        return TST_FAIL;
    }


    do {
        while (TRUE) {
            HRESULT hr = pME->GetEvent(&lCode, &lP1, &lP2, 500);
            if (SUCCEEDED(hr)) {
                /*  Find out where we are */
                pMP->get_CurrentPosition(&tCurr);
                break;
            }
            /*  Find out where we are */
            pMP->get_CurrentPosition(&tCurr);
            if (bDbgOut) {
                tstLog(TERSE, "Position %s seconds", (LPCTSTR)CDisp(tCurr));
            }
        }
        if (lCode != EC_COMPLETE) {
            tstLog(VERBOSE, "Got event code 0x%8.8X", lCode);
        }
    } while (lCode != EC_COMPLETE && lCode != EC_USERABORT && lCode != EC_ERRORABORT);

    if (bDbgOut) {
        tstLog(TERSE, "Position at end of stream %s seconds", (LPCTSTR)CDisp(tCurr));
    }

    pME->Release();

    return bFailed ? TST_FAIL : TST_PASS;
}

int TestPlay(IMediaControl *pMC, IMediaPosition *pMP, REFTIME dStart, REFTIME dStop, BOOL bDbgOut)
{
    if (bDbgOut) {
         tstLog(TERSE, "Playing from %s to %s",
                (LPCTSTR)CDisp(dStart),
                (LPCTSTR)CDisp(dStop));
    }

    /*  Set the sink now because the put_Start can actually cause
        EndOfStream - ven when paused!

        !!!actually this shouldn't be true and must be a bug in the renderer
        that we should fix!!!
    */

    HRESULT hr = pMP->put_CurrentPosition(dStart);
    if (!CheckResult(hr, "put_CurrentPosition")) {
        return TST_FAIL;
    }
    hr = pMP->put_StopTime(dStop);
    if (!CheckResult(hr, "put_StopTime")) {
        return TST_FAIL;
    }
    double dStopNew;
    hr = pMP->get_StopTime(&dStopNew);
    if (dStopNew - 0.00001 > dStop ||
        dStopNew + 0.00001 < dStop) {
        tstLog(TERSE, "Stop time set wrong - set %s, got back %s!",
               (LPCTSTR)CDisp(dStop), (LPCTSTR)CDisp(dStopNew));
    }

    hr = pMC->Run();
    if (!CheckResult(hr, "Run")) {
        return TST_FAIL;
    }

    LONG lCode, P1, P2;
    int result = WaitForPlayComplete(pMC, pMP, lCode, P1, P2, bDbgOut);
    if (lCode == EC_ERRORABORT || result != TST_PASS) {
        if (lCode == EC_ERRORABORT) {
            tstLog(TERSE, "Completion code was EC_ERRORABORT");
        }
        return TST_FAIL;
    }

    pMC->Pause();
    return result;
}

int WaitForSeekingComplete(IMediaControl *pMC, IMediaSeeking *pMS, LONG& lCode, LONG& lP1, LONG& lP2, BOOL bDbgOut)
{
    BOOL bFailed = FALSE;
    // wait for completion
    LONGLONG llCurr;
    pMS->GetCurrentPosition(&llCurr);

    IMediaEvent * pME;
    HRESULT hr = pMC->QueryInterface(IID_IMediaEvent, (void**)&pME);
    if (FAILED(hr)) {
        tstLog(TERSE, "Failed to get IMediaEvent");
        return TST_FAIL;
    }


    do {
        while (TRUE) {
            HRESULT hr = pME->GetEvent(&lCode, &lP1, &lP2, 500);
            if (SUCCEEDED(hr)) {
                break;
            }
            /*  Find out where we are */
            if (bDbgOut) {
                pMS->GetCurrentPosition(&llCurr);
                tstLog(TERSE, "Position %s units", (LPCTSTR)CDisp(llCurr, CDISP_DEC));
            }
        }
        if (lCode != EC_COMPLETE) {
            tstLog(VERBOSE, "Got event code 0x%8.8X", lCode);
        }
    } while (lCode != EC_COMPLETE && lCode != EC_USERABORT && lCode != EC_ERRORABORT);

    if (bDbgOut) {
        tstLog(TERSE, "Position at end of stream %s seconds", (LPCTSTR)CDisp(llCurr));
    }

    pME->Release();

    return bFailed ? TST_FAIL : TST_PASS;
}
int TestSeeking(IMediaControl *pMC,
                  IMediaSeeking *pMS,
                  double dStart,
                  double dStop,
                  const GUID *pFormat,
                  BOOL bDbgOut)
{
    /*  Set the sink now because the put_Start can actually cause
        EndOfStream - ven when paused!

        !!!actually this shouldn't be true and must be a bug in the renderer
        that we should fix!!!
    */

    HRESULT hr = pMS->SetTimeFormat(pFormat);
    if (S_OK != hr) {
        tstLog(TERSE, "Format %s not supported", GuidNames[*pFormat]);
        return TST_FAIL;
    }

    LONGLONG llDuration;
    hr = pMS->GetDuration(&llDuration);
    if (S_OK != hr) {
        tstLog(TERSE, "Duration not available");
        return TST_FAIL;
    }

    LONGLONG llStart = llDuration * dStart;
    LONGLONG llStop = llDuration * dStop;

    if (bDbgOut) {
         tstLog(TERSE, "Playing from %s to %s using format %s",
                (LPCTSTR)CDisp(llStart, CDISP_DEC),
                (LPCTSTR)CDisp(llStop, CDISP_DEC),
                GuidNames[*pFormat]);
    }

    hr = pMS->SetPositions(
        &llStart, AM_SEEKING_AbsolutePositioning,
        &llStop, AM_SEEKING_AbsolutePositioning);
    if (!CheckResult(hr, "SetSeeking")) {
        return TST_FAIL;
    }
    LONGLONG llCurr;
    pMS->GetCurrentPosition(&llCurr);
    if (llStart != llCurr) {
        tstLog(TERSE, "Current position(%d) at start != start(%d)!",
               (LONG)llCurr, (LONG)llStart);
    }

    hr = pMC->Run();
    if (!CheckResult(hr, "Run")) {
        return TST_FAIL;
    }

    LONG lCode, P1, P2;
    int result = WaitForSeekingComplete(pMC, pMS, lCode, P1, P2, bDbgOut);
    if (lCode == EC_ERRORABORT || result != TST_PASS) {
        if (lCode == EC_ERRORABORT) {
            tstLog(TERSE, "Completion code was EC_ERRORABORT");
        }
        return TST_FAIL;
    }

    pMC->Stop();
    return result;
}


// simple seek test to play all the movie

STDAPI_(int) execTest3(void)
{
    IMediaControl * pMC = OpenGraph();
    if (pMC == NULL) {
        return TST_FAIL;
    }

    int result = TestInterface("Filter Graph", pMC);
    if (result != TST_PASS) {
        return result;
    }

    IMediaPosition * pMP;
    HRESULT hr = pMC->QueryInterface(IID_IMediaPosition, (void**)&pMP);
    if (!CheckResult(hr, "QI for IMediaPosition")) {
        return TST_FAIL;
    }

    BOOL bFailed = FALSE;

    hr = pMC->Stop();
    if (!CheckResult(hr, "Stop")) {
        bFailed = TRUE;
    }

    double d;
    hr = pMP->get_Duration(&d);

    if (CheckResult(hr, "get_Duration")) {
        tstLog(TERSE,
            "Duration is %s seconds",
            (LPCTSTR)CDisp(d)
        );
    } else {
        bFailed = TRUE;
    }

    if (!bFailed) {
        bFailed = TestPlay(pMC, pMP, 0, 0, TRUE) != TST_PASS;
    }
    if (!bFailed) {
        bFailed = TestPlay(pMC, pMP, 0, 0.033, TRUE) != TST_PASS;
    }
    if (!bFailed) {
        bFailed = TestPlay(pMC, pMP, 0, 0.066, TRUE) != TST_PASS;
    }
    if (!bFailed) {
        bFailed = TestPlay(pMC, pMP, 2.2, 5.1, TRUE) != TST_PASS;
    }
    if (!bFailed) {
        bFailed = TestPlay(pMC, pMP, 0, d, TRUE) != TST_PASS;
    }

    if (!bFailed) {
        tstLog(TERSE, "Displaying frames at 33ms intervals");

        /*  assume 33ms per frame and display 'all' the frames */
        for (REFTIME dStart = 0.0; !bFailed && dStart <= d; dStart += 0.033) {
            tstLog(TERSE | FLUSH, "    %s", (LPCTSTR)CDisp(dStart));
            bFailed = TestPlay(pMC, pMP, dStart, dStart, FALSE) != TST_PASS;
        }
    }

    if (!bFailed) {
        tstLog(TERSE, "Displaying frames backwards at 33ms intervals");

        /*  assume 33ms per frame and display 'all' the frames */
        for (REFTIME dStart = d; !bFailed && dStart >= 0; dStart -= 0.033) {
            tstLog(TERSE | FLUSH, "    %s", (LPCTSTR)CDisp(dStart));
            bFailed = TestPlay(pMC, pMP, dStart, dStart, FALSE) != TST_PASS;
        }
    }

    hr = pMC->Stop();
    if (!CheckResult(hr, "Stop")) {
	bFailed = TRUE;
    }


    pMP->Release();
    ULONG ulRelease = pMC->Release();
    if (0 != ulRelease) {
       tstLog(TERSE | FLUSH, "Final Release of filter graph returned %d!",
              ulRelease);
       bFailed = TRUE;
    }

    if (bFailed) {
        return TST_FAIL;
    } else {
        return TST_PASS;
    }
}

// simple seek test

STDAPI_(int) execTest6(void)
{
    IMediaControl * pMC = OpenGraph();
    if (pMC == NULL) {
        return TST_FAIL;
    }

    int result = TestInterface("Filter Graph", pMC);
    if (result != TST_PASS) {
        return result;
    }

    IMediaSeeking * pMS;
    HRESULT hr = pMC->QueryInterface(IID_IMediaSeeking, (void**)&pMS);
    if (!CheckResult(hr, "QI for IMediaSeeking")) {
        return TST_FAIL;
    }

    BOOL bFailed = FALSE;

    hr = pMC->Stop();
    if (!CheckResult(hr, "Stop")) {
        bFailed = TRUE;
    }

    if (!bFailed) {
        bFailed = TestSeeking(pMC, pMS, 0, 0, &TIME_FORMAT_BYTE, TRUE) != TST_PASS;
    }
    if (!bFailed) {
        bFailed = TestSeeking(pMC, pMS, 0.5, 1.0, &TIME_FORMAT_BYTE, TRUE) != TST_PASS;
    }
    if (!bFailed) {
        bFailed = TestSeeking(pMC, pMS, 0.25, 0.75, &TIME_FORMAT_BYTE, TRUE) != TST_PASS;
    }
    if (!bFailed) {
        bFailed = TestSeeking(pMC, pMS, 0, 1.0, &TIME_FORMAT_BYTE, TRUE) != TST_PASS;
    }

    hr = pMC->Stop();
    if (!CheckResult(hr, "Stop")) {
	bFailed = TRUE;
    }

    pMS->Release();
    ULONG ulRelease = pMC->Release();
    if (0 != ulRelease) {
       tstLog(TERSE | FLUSH, "Final Release of filter graph returned %d!",
              ulRelease);
       bFailed = TRUE;
    }

    if (bFailed) {
        return TST_FAIL;
    } else {
        return TST_PASS;
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testsplt\testsplt.cpp ===
// Copyright (c) Microsoft Corporation 1996. All Rights Reserved


#include <streams.h>
#include <windowsx.h>
#include <mmsystem.h>
#include <src.h>
#include <sink.h>
#include <tstshell.h>
#include <testfuns.h>
#include <stmonfil.h>
#include <tstream.h>
#include "tstwrap.h"
#include "objects.h"
#include "dialogs.h"
/*
    Tests for the MPEG stream splitter
*/


/* -- CTestInputPin  methods -- */
STDMETHODIMP CTestInputPin::EndOfStream()
{
    HRESULT hr = CSinkPin::EndOfStream();
    CTestSink *pSink = (CTestSink *)m_pFilter;
    tstLog(VERBOSE, "End Of Stream");
    pSink->Set();
    m_bGotStart = FALSE;
    m_tStartPrev = -1000000; // something big and negative
    return hr;
}

STDMETHODIMP CTestInputPin::Receive(IMediaSample *pSample)
{
    CRefTime tStart, tStop;
    CTestSink *pSink = (CTestSink *)m_pFilter;
    if (pSink->m_bDisplay) {
        pSample->GetTime((REFERENCE_TIME*)&tStart, (REFERENCE_TIME*)&tStop);
        tstLog(VERBOSE, "%s : Start : %s  Stop : %s   %s %s %s",
               (LPCTSTR)CDisp(m_Connected),
               (LPCTSTR)CDisp(tStart),
               (LPCTSTR)CDisp(tStop),
               S_OK == pSample->IsSyncPoint() ? "Sync" : "",
               S_OK == pSample->IsDiscontinuity() ? "Discontinuity" : "",
               S_OK == pSample->IsPreroll() ? "Preroll" : "");
        /*  Check the sample times increase */
        if (m_bGotStart) {
            if (tStart < m_tStartPrev) {
                tstLog(TERSE, "Sample time decrease! - last %s, this %s",
                       (LPCTSTR)CDisp(m_tStartPrev),
                       (LPCTSTR)CDisp(tStart));
                m_pTest->Fail();
            }
        } else {
            m_bGotStart = TRUE;
        }
        m_tStartPrev = tStart;
        /*  Check the sample times are in range */
        if (!m_pTest->IsMedium()) {
            m_pTest->CheckStart(tStart);
        }

        /*  See if there's a media time associated */
        LONGLONG llStart, llStop;
        if (S_OK == pSample->GetMediaTime(&llStart, &llStop)) {
            tstLog(VERBOSE, "Media Time Start: %s, Stop: %s",
                   (LPCTSTR)CDisp(llStart, CDISP_DEC),
                   (LPCTSTR)CDisp(llStop, CDISP_DEC));
            if (llStart > llStop) {
                tstLog(TERSE, "Sample medium times going backwards!");
                m_pTest->Fail();
            }
            m_pTest->CheckPosition(llStart, llStop);
        }
    }
    pSink->m_dwSamples++;
    //return CSinkPin::Receive(pSample);
    return S_OK;
};


/* -- CTestSink methods -- */
CTestSink::CTestSink(CTestSplt *pTest, HRESULT   *phr) :
   CSinkFilter(NULL, phr),
   m_bDisplay(TRUE),
   m_dwSamples(0)
{
    m_pInputPin = new CTestInputPin(pTest,
                                    this,
                                    &m_CritSec,
                                    phr);
    if (m_pInputPin == NULL) {
        *phr = E_OUTOFMEMORY;
        return;
    }
}

/*  Utility to make a filter */

TCHAR szSourceFile[MAX_PATH];

/* --  CTestSplt implemenation -- */
CTestSplt::CTestSplt(IStream *pStream, BOOL bSeekable, LONG lSize, LONG lCount) :
    m_pSource(NULL),
    m_pClock(NULL),
    m_pF(NULL),
    m_pMF(NULL),
    m_pInput(NULL),
    m_bInputConnected(NULL)
{
    /*  Make our objects */
    tstLog(TERSE, "Testing splitter %s, Requested Sample size is %d, Requested Sample Count is %d",
           bSeekable ? "Seekable source" : "Not seekable source",
           lSize, lCount);

    HRESULT hr = S_OK;

    /*  Construct our components */

    m_pSource = new CTestSource(this, pStream, bSeekable, lSize, lCount, &hr);
    ASSERT(SUCCEEDED(hr));
    m_pSource->AddRef();

    /*  Just for fun test our pin! */
    EXECUTE_ASSERT(TestPin( "Our source pin"
                          , (IUnknown *)(IPin *)(m_pSource->GetPin(0))
                          , FALSE
                          )
                   == TST_PASS);

    // make a reference clock
    hr = CoCreateInstance(CLSID_SystemClock,
                          NULL,
                          CLSCTX_INPROC,
                          IID_IReferenceClock,
                          (void**) &m_pClock);
    ASSERT(SUCCEEDED(hr));

    //  Create the splitter (so we can test it !)
    hr = CoCreateInstance(CLSID_MPEG1Splitter,
                          NULL,
                          CLSCTX_INPROC,
                          IID_IBaseFilter,
                          (void **) &m_pF);

    if (FAILED(hr)) {
        tstLog(TERSE, "Failed to instantiate MPEG splitter code 0x%8.8X", hr);
        DbgLog((LOG_ERROR, 2, TEXT("Failed to instantiate MPEG splitter code 0x%8.8X"), hr));
        throw CTestError(TST_FAIL);
    }

    /*  Get the media filter interface */
    hr = m_pF->QueryInterface(IID_IMediaFilter, (void **)&m_pMF);
    if (FAILED(hr)) {
        tstLog(TERSE, "Failed to get MPEG splitter IMediaFilter interface - code 0x%8.8X", hr);
        DbgLog((LOG_ERROR, 2, TEXT("Failed to get MPEG splitter IMediaFilter interface - code 0x%8.8X"), hr));
        throw CTestError(TST_FAIL);
    }

    /*  Find the splitter's input pin and check there's only 1 pin */
    IEnumPins *pEnum;
    IPin      *paPins[2];
    ULONG      nPins;
    hr = m_pF->EnumPins(&pEnum);
    if (FAILED(hr)) {
        tstLog(TERSE, "Splitter EnumPins call failed code 0x%8.8X", hr);
        DbgLog((LOG_ERROR, 2, TEXT("Splitter EnumPins call failed code 0x%8.8X"), hr));
        throw CTestError(TST_FAIL);
    }
    hr = pEnum->Next(2, paPins, &nPins);
    pEnum->Release();
    if (FAILED(hr)) {
        tstLog(TERSE, "Splitter EnumPins->Next() call failed code 0x%8.8X", hr);
        DbgLog((LOG_ERROR, 1, TEXT("Splitter EnumPins->Next() call failed code 0x%8.8X"), hr));
        throw CTestError(TST_FAIL);
    }
    if (nPins != 1) {
        tstLog(TERSE, "Splitter EnumPins->Next() call failed code 0x%8.8X", hr);
        DbgLog((LOG_ERROR, 1, TEXT("Splitter EnumPins->Next() call failed code 0x%8.8X"), hr));
        throw CTestError(TST_FAIL);
    }

    /*  Check the pin */
    m_pInput = paPins[0];

    int iResult = TestPin("Splitter input pin", (IUnknown *)m_pInput, FALSE);

    if (iResult != TST_PASS) {
        DbgLog((LOG_ERROR, 1, TEXT("Test of splitter input pin failed")));
        throw CTestError(TST_FAIL);
    }

    m_pSource->SetSyncSource(m_pClock);
    m_pMF->SetSyncSource(m_pClock);
}

CTestSplt::~CTestSplt()
{
    TestDisconnect();
    if (m_pInput != NULL) {
        m_pInput->Release();
    }
    if (m_pSource != NULL) {
        if (0 != m_pSource->Release()) {
            tstLog(TERSE, "Source Filter ref count was non-zero on final Release()");
            DbgLog((LOG_ERROR, 1, TEXT("Source Filter ref count was non-zero on final Release()")));
            throw CTestError(TST_FAIL);
        }
    }
    if (m_pMF != NULL) {
        m_pMF->Release();
    }
    if (m_pF != NULL) {
        if (0 != m_pF->Release()) {
            tstLog(TERSE, "Splitter Filter ref count was non-zero on final Release()");
            DbgLog((LOG_ERROR, 1, TEXT("Splitter Filter ref count was non-zero on final Release()")));
            throw CTestError(TST_FAIL);
        }
    }
    if (m_pClock != NULL) {
        m_pClock->Release();
    }
}

void CTestSplt::TestConnectInput()
{
    /*  Connect the splitter's input pin to our test output pin
        Try a few combinations then leave it connected if possible
    */
    if (m_bInputConnected) {
        return;
    }

    /*  Connect the output pin - it doesn't work very well the other
        way round!
    */
    HRESULT hr = m_pSource->GetPin(0)->Connect(m_pInput, NULL);
    if (FAILED(hr)) {
        tstLog(TERSE, "Failed to connect source to splitter input - code 0x%8.8X", hr);
        DbgLog((LOG_ERROR, 1, TEXT("Failed to connect source to splitter input - code 0x%8.8X"), hr));
        throw CTestError(TST_FAIL);
    }
    int result = TestPin("Splitter input pin", m_pInput, TRUE);
    if (result != TST_PASS) {
        throw CTestError(TST_FAIL);
    }
    result = TestPin("Source pin", (IUnknown *)(IPin *)(m_pSource->GetPin(0)), TRUE);
    if (result != TST_PASS) {
        throw CTestError(TST_FAIL);
    }
    m_bInputConnected = TRUE;
    TestDisconnect();

    hr = m_pSource->GetPin(0)->Connect(m_pInput, NULL);
    if (FAILED(hr)) {
        tstLog(TERSE, "Failed to connect splitter input to source - code 0x%8.8X", hr);
        DbgLog((LOG_ERROR, 1, TEXT("Failed to connect splitter input to source - code 0x%8.8X"), hr));
        throw CTestError(TST_FAIL);
    }
    result = TestPin("Splitter input pin", m_pInput, TRUE);
    if (result != TST_PASS) {
        throw CTestError(TST_FAIL);
    }
    m_bInputConnected = TRUE;
}

void CTestSplt::TestDisconnect()
{
    if (!m_bInputConnected) {
        return;
    }

    //  Get a pointer to the allocator
    IMemInputPin *pMemInput;
    EXECUTE_ASSERT(SUCCEEDED(
        m_pInput->QueryInterface(IID_IMemInputPin, (void **)&pMemInput)));
    IMemAllocator *pAllocator;
    EXECUTE_ASSERT(SUCCEEDED(pMemInput->GetAllocator(&pAllocator)));
    pMemInput->Release();
    EXECUTE_ASSERT(SUCCEEDED(m_pSource->GetPin(0)->Disconnect()));
    HRESULT hr = m_pInput->Disconnect();
    if (FAILED(hr)) {
        tstLog(TERSE, "Failed to disconnect splitter input from source - code 0x%8.8X", hr);
        DbgLog((LOG_ERROR, 1, TEXT("Failed to disconnect splitter input from source - code 0x%8.8X"), hr));
        throw CTestError(TST_FAIL);
    }
    ULONG ulRef = pAllocator->Release();
    if (ulRef != 0) {
        tstLog(TERSE, "Allocator not freed! Ref count was %d", ulRef);
        throw CTestError(TST_FAIL);
    }

    int result = TestPin("Splitter input pin", m_pInput, FALSE);
    if (result != TST_PASS) {
        throw CTestError(TST_FAIL);
    }
    m_bInputConnected = FALSE;
}

void BasicTest(BOOL bSeekable, LONG lSize, LONG lCount)
{
    HRESULT hr = S_OK;
    CStreamOnFile *pStream = new CStreamOnFile(NAME("Stream"), NULL, &hr);
    ASSERT(pStream != NULL && hr == S_OK);

    if (lstrlen(szSourceFile) == 0) {
        SelectFile();
    }
    if (FAILED(pStream->Open(szSourceFile))) {
#ifdef UNICODE
        tstLog(TERSE, "Failed to open file %s code 0x%8.8X", szSourceFile, hr);
#else
        tstLog(TERSE, "Failed to open file %ls code 0x%8.8X", szSourceFile, hr);
#endif
        DbgLog((LOG_ERROR, 1, TEXT("Failed to open file %s code 0x%8.8X"), szSourceFile, hr));
        throw CTestError(TST_FAIL);
    }
    CTestSplt TestObj(pStream, bSeekable, lSize, lCount);
    TestObj.TestConnectInput();
}

CTestOutputConnection::CTestOutputConnection(CTestSplt *pTest,
                                             REFCLSID clsidCodec,
                                             IReferenceClock *pClock,
                                             const AM_MEDIA_TYPE *pmt) :
    m_pSink(NULL),
    m_pFilter(NULL),
    m_pTest(pTest)
{
    /*  Instantiate the CODEC and connect it */
    HRESULT hr = CoCreateInstance(clsidCodec,
                                  NULL,
                                  CLSCTX_INPROC,
                                  IID_IBaseFilter,
                                  (void **) &m_pFilter);

    if (FAILED(hr)) {
        tstLog(TERSE, "Failed to instantiate CODEC code 0x8.8X", hr);
        throw  CTestError(TST_FAIL);
    }
    IMediaFilter *pMF;
    m_pFilter->QueryInterface(IID_IMediaFilter, (void **)&pMF);
    pMF->SetSyncSource(pClock);
    pMF->Release();

    int result = TestInterface("Codec", m_pFilter);
    if (result != TST_PASS) {
        throw  CTestError(TST_FAIL);
    }

    /*  Connect this to the input filter */
    result = ConnectFilters(pTest->GetSplitter(), m_pFilter);
    if (result != TST_PASS) {
        throw  CTestError(TST_FAIL);
    }

    /*  Instantiate our sink filter */
    hr = S_OK;
    m_pSink = new CTestSink(pTest, &hr);
    ASSERT(hr == S_OK && m_pSink != NULL);
    m_pSink->AddRef();
    m_pSink->SetSyncSource(pClock);
    if (pmt != NULL) {
        m_pSink->SetMediaType(pmt);
    }
    m_pSink->QueryInterface(IID_IMediaSeeking, (void **)&m_pSeeking);

    /*  Try to connect them */
    result = ConnectFilters(m_pFilter, m_pSink);
    if (result != TST_PASS) {
        throw CTestError(TST_FAIL);
    }
}

CTestOutputConnection::~CTestOutputConnection()
{
    if (m_pSink != NULL) {
        DisconnectFilter(m_pSink);
        m_pSink->Release();
    }
    if (m_pFilter != NULL) {
        DisconnectFilter(m_pFilter);
        m_pFilter->Release();
    }
    if (m_pSeeking != NULL) {
        m_pSeeking->Release();
    }
}

CTestPosition::CTestPosition(IStream *pStream, LONG lSize, LONG lCount) :
    CTestSplt(pStream, TRUE, lSize, lCount),
    m_pAudio(NULL),
    m_pVideo(NULL)
{
}
CTestPosition::~CTestPosition()
{
    delete m_pAudio;
    delete m_pVideo;
}

void CTestPosition::SetConnections(BOOL bAudio, BOOL bVideo, const AM_MEDIA_TYPE *Type)
{
    delete m_pAudio;
    m_pAudio = NULL;
    delete m_pVideo;
    m_pVideo = NULL;
    if (bAudio) {
        m_pAudio = new CTestOutputConnection(this, CLSID_CMpegAudioCodec, m_pClock);
    }
    if (bVideo) {
        m_pVideo = new CTestOutputConnection(this, CLSID_CMpegVideoCodec, m_pClock, Type);
    }
}

int CTestPosition::TestSeek(BOOL bAudio, BOOL bVideo)
{
    tstLog(TERSE, "Testing seeking of %s",
           bAudio && !bVideo ? "Audio" :
           bVideo && !bAudio ? "Video" :
           bVideo && bAudio ? "Audio and Video" : "No streams");
    TestDisconnect();
    TestConnectInput();
    SetConnections(bAudio, bVideo);
    if (m_pAudio) {
        m_pAudio->GetSinkSeeking()->GetDuration(&m_tDuration);
    }
    if (m_pVideo) {
        m_pVideo->GetSinkSeeking()->GetDuration(&m_tDuration);
    }
    tstLog(VERBOSE, "Duration is %s", (LPCTSTR)CDisp(m_tDuration));
    if (TST_PASS != TestPlay(CRefTime(0L), CRefTime(0L))) { return TST_FAIL; }
    if (TST_PASS != TestPlay(CRefTime(0L), CRefTime(1L))) { return TST_FAIL; }
    if (TST_PASS != TestPlay(CRefTime(1L), CRefTime(0L))) { return TST_FAIL; }
    if (TST_PASS != TestPlay(m_tDuration, m_tDuration)) { return TST_FAIL; }
    if (TST_PASS != TestPlay(CRefTime(m_tDuration) - CRefTime(100L), m_tDuration)) { return TST_FAIL; }
    if (TST_PASS != TestPlay(CRefTime(300L), CRefTime(500L))) { return TST_FAIL; }
    if (TST_PASS != TestPlay(CRefTime(600L), CRefTime(600L))) { return TST_FAIL; }
    if (TST_PASS != TestPlay(CRefTime(600L), CRefTime(5600L))) { return TST_FAIL; }
    return TST_PASS;
}

int CTestPosition::TestPlay(REFERENCE_TIME tStart, REFERENCE_TIME tStop)
{
    m_iResult = TST_PASS;
    tstLog(VERBOSE, "Playing from %s to %s",
           (LPCTSTR)CDisp(tStart),
           (LPCTSTR)CDisp(tStop));
    m_bMedium = FALSE;
    m_tPlayStart = tStart;
    m_tPlayStop  = tStop;
    if (m_pAudio) {
        m_pAudio->GetSinkSeeking()->SetPositions(
            &tStart, AM_SEEKING_AbsolutePositioning,
            &tStop, AM_SEEKING_AbsolutePositioning);
    }
    if (m_pVideo) {
        m_pVideo->GetSinkSeeking()->SetPositions(
            &tStart, AM_SEEKING_AbsolutePositioning,
            &tStop, AM_SEEKING_AbsolutePositioning);
    }

    /*  Now play everything (!) */
    SetState(State_Running);

    /*  Wait until all the streams are complete */
    if (m_pAudio) {
        m_pAudio->Wait();
    }
    if (m_pVideo) {
        m_pVideo->Wait();
    }

    SetState(State_Stopped);
    return m_iResult;
}

int CTestPosition::TestMediumSeek(BOOL bAudio, BOOL bVideo, const GUID *TimeFormat)
{
    tstLog(TERSE, "Testing medium seeking of %s Time Format %s",
           bAudio && !bVideo ? "Audio" :
           bVideo && !bAudio ? "Video" :
           bVideo && bAudio ? "Audio and Video" : "No streams",
           GuidNames[*TimeFormat]);
    TestDisconnect();
    TestConnectInput();
    SetConnections(bAudio, bVideo);
    /*  See if the format is supported */
    IMediaSeeking *pSeeking = NULL;
    if (m_pAudio && S_OK == m_pAudio->GetSinkSeeking()->IsFormatSupported(TimeFormat)) {
        pSeeking = m_pAudio->GetSinkSeeking();
    } else
    if (m_pVideo && S_OK == m_pVideo->GetSinkSeeking()->IsFormatSupported(TimeFormat)) {
        pSeeking = m_pVideo->GetSinkSeeking();
    } else {
        tstLog(TERSE, "Time format %s is not supported", GuidNames[*TimeFormat]);
        return TST_PASS;
    }
    tstLog(TERSE, "Time format %s is supported", GuidNames[*TimeFormat]);
    pSeeking->SetTimeFormat(TimeFormat);
    pSeeking->GetDuration(&m_llDuration);
    tstLog(VERBOSE, "Duration is %s", (LPCTSTR)CDisp(m_llDuration, CDISP_DEC));
    if (TST_PASS != TestMediumPlay((0L), (0L), TimeFormat, pSeeking)) { return TST_FAIL; }
    if (TST_PASS != TestMediumPlay((0L), (1L), TimeFormat, pSeeking)) { return TST_FAIL; }
    if (TST_PASS != TestMediumPlay((1L), (0L), TimeFormat, pSeeking)) { return TST_FAIL; }
    //if (TST_PASS != TestMediumPlay(m_llDuration, m_llDuration, TimeFormat, pSeeking)) { return TST_FAIL; }
    if (TST_PASS != TestMediumPlay((m_llDuration) - m_llDuration / 6, m_llDuration, TimeFormat, pSeeking)) { return TST_FAIL; }
    if (TST_PASS != TestMediumPlay(m_llDuration / 12, m_llDuration / 10, TimeFormat, pSeeking)) { return TST_FAIL; }
    if (TST_PASS != TestMediumPlay(m_llDuration / 5, m_llDuration / 5, TimeFormat, pSeeking)) { return TST_FAIL; }
    if (TST_PASS != TestMediumPlay(m_llDuration / 5, m_llDuration, TimeFormat, pSeeking)) { return TST_FAIL; }
    return TST_PASS;
}

int CTestPosition::TestMediumPlay(LONGLONG llStart,
                                  LONGLONG llStop,
                                  const GUID *TimeFormat,
                                  IMediaSeeking *pSeeking)
{
    m_iResult = TST_PASS;
    m_llPlayStart = llStart;
    m_llPlayStop  = llStop;
    pSeeking->SetPositions(
        &llStart, AM_SEEKING_AbsolutePositioning,
        &llStop, AM_SEEKING_AbsolutePositioning);

    tstLog(VERBOSE, "Playing Medium from %d to %d in format %s",
           (LONG)llStart, (LONG)llStop, GuidNames[*TimeFormat]);

    /*  Now play everything (!) */
    SetState(State_Running);

    /*  Wait until all the streams are complete */
    if (m_pAudio) {
        m_pAudio->Wait();
    }
    if (m_pVideo) {
        m_pVideo->Wait();
    }

    SetState(State_Stopped);
    return m_iResult;
}

int CTestPosition::PerfPlay(BOOL bAudio, BOOL bVideo, const GUID *VideoType)
{
    /*  Connect up the stream */
    tstLog(TERSE, "Testing playing %s",
           bAudio && !bVideo ? "Audio" :
           bVideo && !bAudio ? "Video" :
           bVideo && bAudio ? "Audio and Video" : "No streams");
    TestDisconnect();
    TestConnectInput();
    CMediaType cmt(&MEDIATYPE_Video);
    if (VideoType != NULL) {
        cmt.SetSubtype(VideoType);
    }

    SetConnections(bAudio, bVideo, &cmt);
    if (m_pAudio) {
        m_pAudio->GetSink()->SetDisplay(FALSE);
        m_pAudio->GetSinkSeeking()->GetDuration(&m_tDuration);
    }
    if (m_pVideo) {
        m_pVideo->GetSink()->SetDisplay(FALSE);
        m_pVideo->GetSinkSeeking()->GetDuration(&m_tDuration);
    }
    tstLog(VERBOSE, "Duration is %s", (LPCTSTR)CDisp(m_tDuration));
    tstLogFlush();  // Don't interfere with play
    timeBeginPeriod(1);
    DWORD dwTime = timeGetTime();
    TestPlay(CRefTime(0L), m_tDuration);
    dwTime = timeGetTime() - dwTime;
    timeEndPeriod(1);
    double cpupercent = dwTime / ((double)COARefTime(m_tDuration) * 10.0);
    if (bVideo) {
        int nFrames = m_pVideo->GetSink()->GetSamples();
        tstLog(TERSE, "Took %d milliseconds for %d frames at %s fps - cpu %s%%",
               dwTime,
               nFrames,
               (LPCTSTR)CDisp((double)nFrames * 1000.0 / dwTime),
               (LPCTSTR)CDisp(cpupercent));
    } else {
        tstLog(TERSE, "Took %d milliseconds for %s, cpu %s%%",
               dwTime,
               (LPCTSTR)CDisp(m_tDuration),
               (LPCTSTR)CDisp(cpupercent));
    }
    return TST_PASS;
}
int CTestPosition::TestFrame(CRefTime tFrame)
{
    tstLogFlush();  // Don't interfere with play
    TestPlay(tFrame, tFrame);
    int nFrames = m_pVideo->GetSink()->GetSamples();
    if (nFrames != 1) {
        tstLog(TERSE, "Got %d frames trying to play frame at %s",
               nFrames, (LPCTSTR)CDisp(tFrame));
        if (nFrames == 0) {
            return TST_OTHER;
        }
    }
    return TST_PASS;
}
int CTestPosition::TestVideoFrames()
{
    /*  Connect up the stream */
    tstLog(TERSE, "Testing video frames at 33ms intervals");
    TestDisconnect();
    TestConnectInput();

    SetConnections(FALSE, TRUE, NULL);
    REFERENCE_TIME rtDuration;
    REFTIME dDuration;
    //m_pVideo->GetSink()->SetDisplay(FALSE);
    m_pVideo->GetSinkSeeking()->GetDuration(&rtDuration);
    dDuration = ((double)rtDuration) / UNITS;
    for (double d=0.0; d < dDuration; d += 0.033) {
        tstLog(TERSE | FLUSH, "    %s", (LPCTSTR)CDisp((REFERENCE_TIME)COARefTime(d)));
        int result = TestFrame(COARefTime(d));
        if (result == TST_FAIL) {
            return TST_FAIL;
        }
    }
    return TST_PASS;
}
int CTestPosition::TestVideoFrame(REFTIME d)
{
    /*  Connect up the stream */
    tstLog(TERSE, "Testing video frames");
    TestDisconnect();
    TestConnectInput();

    SetConnections(FALSE, TRUE, NULL);
    int result = TestFrame(COARefTime(d));
    if (result == TST_FAIL) {
        return TST_FAIL;
    }
    return TST_PASS;
}
int TestVideoFrames()
{
    HRESULT hr = S_OK;
    CStreamOnFile *pStream = new CStreamOnFile(NAME("Stream"), NULL, &hr);
    ASSERT(pStream != NULL && hr == S_OK);

    if (lstrlen(szSourceFile) == 0) {
        SelectFile();
    }
    if (FAILED(pStream->Open(szSourceFile))) {
#ifdef UNICODE
        tstLog(TERSE, "Failed to open file %s code 0x%8.8X", szSourceFile, hr);
#else
        tstLog(TERSE, "Failed to open file %ls code 0x%8.8X", szSourceFile, hr);
#endif
        DbgLog((LOG_ERROR, 1, TEXT("Failed to open file %s code 0x%8.8X"), szSourceFile, hr));
        throw CTestError(TST_FAIL);
    }
    CTestPosition TestObj(pStream, 65536, 4);
    return TestObj.TestVideoFrames();
}
int TestVideoFrame()
{
    HRESULT hr = S_OK;
    CStreamOnFile *pStream = new CStreamOnFile(NAME("Stream"), NULL, &hr);
    ASSERT(pStream != NULL && hr == S_OK);

    if (lstrlen(szSourceFile) == 0) {
        SelectFile();
    }
    if (FAILED(pStream->Open(szSourceFile))) {
#ifdef UNICODE
        tstLog(TERSE, "Failed to open file %s code 0x%8.8X", szSourceFile, hr);
#else
        tstLog(TERSE, "Failed to open file %ls code 0x%8.8X", szSourceFile, hr);
#endif
        DbgLog((LOG_ERROR, 1, TEXT("Failed to open file %s code 0x%8.8X"), szSourceFile, hr));
        throw CTestError(TST_FAIL);
    }
    double dFrameTime;
    DialogBoxParam(hinst,
                   MAKEINTRESOURCE(DLG_FRAMETIME),
                   ghwndTstShell,
                   FrameTimeDlg,
                   (LPARAM)&dFrameTime);
    CTestPosition TestObj(pStream, 65536, 4);
    return TestObj.TestVideoFrame(dFrameTime);
}
int TestPosition(LONG lSize, LONG lCount)
{
    HRESULT hr = S_OK;
    CStreamOnFile *pStream = new CStreamOnFile(NAME("Stream"), NULL, &hr);
    ASSERT(pStream != NULL && hr == S_OK);

    if (lstrlen(szSourceFile) == 0) {
        SelectFile();
    }
    if (FAILED(pStream->Open(szSourceFile))) {
#ifdef UNICODE
        tstLog(TERSE, "Failed to open file %s code 0x%8.8X", szSourceFile, hr);
#else
        tstLog(TERSE, "Failed to open file %ls code 0x%8.8X", szSourceFile, hr);
#endif
        DbgLog((LOG_ERROR, 1, TEXT("Failed to open file %s code 0x%8.8X"), szSourceFile, hr));
        throw CTestError(TST_FAIL);
    }
    CTestPosition TestObj(pStream, lSize, lCount);
    if (TST_PASS != TestObj.TestSeek(FALSE, TRUE)) { return TST_FAIL; }
    if (TST_PASS != TestObj.TestSeek(TRUE, FALSE)) { return TST_FAIL; }
    if (TST_PASS != TestObj.TestSeek(TRUE, TRUE)) { return TST_FAIL; }
    return TST_PASS;
}

int TestMediumPosition(LONG lSize, LONG lCount, const GUID *TimeFormat)
{
    HRESULT hr = S_OK;
    CStreamOnFile *pStream = new CStreamOnFile(NAME("Stream"), NULL, &hr);
    ASSERT(pStream != NULL && hr == S_OK);

    if (lstrlen(szSourceFile) == 0) {
        SelectFile();
    }
    if (FAILED(pStream->Open(szSourceFile))) {
#ifdef UNICODE
        tstLog(TERSE, "Failed to open file %s code 0x%8.8X", szSourceFile, hr);
#else
        tstLog(TERSE, "Failed to open file %ls code 0x%8.8X", szSourceFile, hr);
#endif
        DbgLog((LOG_ERROR, 1, TEXT("Failed to open file %s code 0x%8.8X"), szSourceFile, hr));
        throw CTestError(TST_FAIL);
    }
    CTestPosition TestObj(pStream, lSize, lCount);
    if (TST_PASS != TestObj.TestMediumSeek(TRUE, TRUE, TimeFormat)) { return TST_FAIL; }
    return TST_PASS;
}

int TestPerformance(BOOL bAudio, BOOL bVideo, const GUID *VideoType)
{
    HRESULT hr = S_OK;
    CStreamOnFile *pStream = new CStreamOnFile(NAME("Stream"), NULL, &hr);
    ASSERT(pStream != NULL && hr == S_OK);

    if (lstrlen(szSourceFile) == 0) {
        SelectFile();
    }
    if (FAILED(pStream->Open(szSourceFile))) {
#ifdef UNICODE
        tstLog(TERSE, "Failed to open file %s code 0x%8.8X", szSourceFile, hr);
#else
        tstLog(TERSE, "Failed to open file %ls code 0x%8.8X", szSourceFile, hr);
#endif
        DbgLog((LOG_ERROR, 1, TEXT("Failed to open file %s code 0x%8.8X"), szSourceFile, hr));
        throw CTestError(TST_FAIL);
    }
    CTestPosition TestObj(pStream, 65536, 4);
    return TestObj.PerfPlay(bAudio, bVideo, VideoType);
}
/*  Actually do some tests! */

/*  Test simple instantiation and connect of input pin */
STDAPI_(int) execTest1()
{
    int result = TST_PASS;
    try {
        BasicTest(TRUE, 100, 20);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #1");
    tstLogFlush();
    return result;
}

/*   */
STDAPI_(int) execTest2()
{
    int result;
    try {
        result = TestPosition(65536, 5);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #2");
    tstLogFlush();
    return result;
}
/*   */
STDAPI_(int) execTest4()
{
    int result;
    try {
        result = TestMediumPosition(65536, 5, &TIME_FORMAT_BYTE);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #4");
    tstLogFlush();
    return result;
}
/*   */
STDAPI_(int) execTest5()
{
    int result;
    try {
        result = TestMediumPosition(65536, 5, &TIME_FORMAT_FRAME);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #5");
    tstLogFlush();
    return result;
}
STDAPI_(int) execPerfTestAudio()
{
    int result = TST_PASS;
    try {
        result = TestPerformance(TRUE, FALSE, NULL);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #6");
    tstLogFlush();
    return result;
}
/*   */
STDAPI_(int) execPerfTestVideoYUV422()
{
    int result = TST_PASS;
    try {
        result = TestPerformance(FALSE, TRUE, &MEDIASUBTYPE_UYVY);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #7");
    tstLogFlush();
    return result;
}
/*   */
STDAPI_(int) execPerfTestVideoRGB565()
{
    int result = TST_PASS;
    try {
        result = TestPerformance(FALSE, TRUE, &MEDIASUBTYPE_RGB565);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #8");
    tstLogFlush();
    return result;
}
STDAPI_(int) execPerfTestVideoRGB24()
{
    int result = TST_PASS;
    try {
        result = TestPerformance(FALSE, TRUE, &MEDIASUBTYPE_RGB24);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #9");
    tstLogFlush();
    return result;
}

STDAPI_(int) execPerfTestVideoRGB8()
{
    int result = TST_PASS;
    try {
        result = TestPerformance(FALSE, TRUE, &MEDIASUBTYPE_RGB24);
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #10");
    tstLogFlush();
    return result;
}

STDAPI_(int) execTestVideoFrames()
{
    int result = TST_PASS;
    try {
        result = TestVideoFrames();
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #11");
    tstLogFlush();
    return result;
}

STDAPI_(int) execTestVideoFrame()
{
    int result = TST_PASS;
    try {
        result = TestVideoFrame();
    }
    catch (CTestError te)
    {
        result = te.ErrorCode();
    }
    tstLog(TERSE, "Exiting test #12");
    tstLogFlush();
    return result;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testsplt\tstwrap.cpp ===
//--------------------------------------------------------------------------;
//
//  File: tstwrap.cpp
//
//  Copyright (c) 1996 Microsoft Corporation.  All rights reserved
//
//  Abstract:
//
//  Contents:
//      tstGetTestInfo()
//      MenuProc()
//      InitOptionsMenu()
//      tstInit()
//      execTest()
//      tstTerminate()
//      tstAppWndProc()
//      SaveCustomProfile()
//      LoadCustomProfile()
//
//  History:
//      08/03/93    T-OriG   - sample test app
//      9-Mar-95    v-mikere - adapted for Quartz source filter tests
//      22-Mar-95   v-mikere - added SaveCustomProfile(), LoadCustomProfile()
//
//--------------------------------------------------------------------------;

#include <streams.h>    // Streams architecture
#include <windowsx.h>   // Windows macros etc.
#include <tstshell.h>   // Include file for the test shell's APIs
#include "tstwrap.h"    // Various includes, constants, prototypes, globals
#include "dialogs.h"
#include "tchar.h"


// Globals

HWND    ghwndTstShell;  // A handle to the main window of the test shell.
                        // It's not used here, but may be used by test apps.

HINSTANCE hinst;        // A handle to the running instance of the test
                        // shell.  It's not used here, but may be used by
                        // test apps.

HMENU   hmenuOptions;   // A handle to the options menu

// App Name
LPTSTR          szAppName = TEXT("Quartz MPEG splitter filter tests - Win32");

extern TCHAR szSourceFile[];

//--------------------------------------------------------------------------;
//
//  int tstGetTestInfo
//
//  Description:
//      Called by the test shell to get information about the test.  Also
//      saves a copy of the running instance of the test shell.
//
//      We also do most basic initialisation here (including instantiating
//      the test sink object) so that the custom profile handler can set
//      everything up when running automatically from a profile.
//
//  Arguments:
//      HINSTANCE hinstance: A handle to the running instance of the test
//          shell
//
//      LPSTR lpszTestName: Pointer to buffer of name for test.  Among
//          other things, it is used as a caption for the main window and
//          as the name of its class.  Always ANSI.
//
//      LPSTR lpszPathSection: Pointer to buffer of name of section in
//          win.ini in which the default input and output paths are
//          stored.  Always ANSI.
//
//      LPWORD wPlatform: The platform on which the tests are to be run,
//          which may be determined dynamically.  In order for a test to
//          be shown on the run list, it must have all the bits found in
//          wPlatform turned on.  It is enough for one bit to be turned off
//          to disqualify the test.  This also means that if this value is
//          zero, all tests will be run.  In order to make this more
//          mathematically precise, I shall give the relation which Test
//          Shell uses to decide whether a test with platform flags
//          wTestPlatform may run:  It may run if the following is TRUE:
//          ((wTestPlatform & wPlatform) == wPlatform)
//
//  Return (int):
//      The value which identifies the test list resouce (found in the
//      resource file).
//
//  History:
//      08/03/93    T-OriG   - sample test app
//      9-Mar-95    v-mikere - adapted for Quartz source filter tests
//
//--------------------------------------------------------------------------;

int tstGetTestInfo
(
    HINSTANCE   hinstance,
    LPSTR       lpszTestName,
    LPSTR       lpszPathSection,
    LPWORD      wPlatform
)
{
    hinst = hinstance;      // Save a copy of a handle to the running instance

    CoInitialize(NULL);            // Initialise COM library
    DbgInitialise(hinst);

    // It might have been nice to have this a few lines earlier
    // - but we gotta do DbgInitialise first!
    DbgLog((LOG_TRACE, 1, TEXT("Entering tstInit")));

    // Install profile handlers for custom data
    tstInstallWriteCustomInfo(SaveCustomProfile);
    tstInstallReadCustomInfo(LoadCustomProfile);

    // Pass app name to test shell
#ifdef UNICODE
    WideCharToMultiByte(CP_ACP, 0, szAppName, -1, lpszTestName, 100, NULL, NULL);
    WideCharToMultiByte(CP_ACP, 0, szAppName, -1, lpszPathSection, 100, NULL, NULL);
#else
    lstrcpy(lpszTestName, szAppName);
    lstrcpy(lpszPathSection, szAppName);
#endif

    *wPlatform = 0;         // The platform the test is running on, to be
                            // determined dynamically.
    return TEST_LIST;
} // tstGetTestInfo()



//--------------------------------------------------------------------------;
//
//  void InitOptionsMenu
//
//  Description:
//      Creates an additional app-specific menu.  Note that this
//      function is called from within tstInit as all menu installations
//      MUST be done in tstInit or else the app's behavior is undefined.
//      Also note the calls to tstInstallCustomTest which is a shell API
//      that allows custom installation of tests.  From tstshell version
//      2.0 on, it is possible to install menus the usual way and trap the
//      appropriate window messages, though the method presented here is
//      still the preferred one for Test Applications to use.
//
//      For the Quartz tests, complete menu structures and window procs
//      exist, so it is simpler to just load and append the existing menu
//      resources than to call tstInstallCustomTest once for each menu
//      option.  The window message handling is incorporated in
//      tstAppWndProc.
//
//  Arguments:
//      LRESULT (CALLBACK* MenuProc)(HWND,UINT,WPARAM,LPARAM):
//          The menu function (not used in the Quartz tests).
//
//  Return (BOOL):
//      TRUE if menu installation is successful, FALSE otherwise
//
//  History:
//      06/08/93    T-OriG   - sample test app
//      9-Mar-95    v-mikere - adapted for Quartz source filter tests
//
//--------------------------------------------------------------------------;

BOOL InitOptionsMenu
(
    LRESULT (CALLBACK* MenuProc)(HWND, UINT, WPARAM, LPARAM)
)
{
    HMENU   hSpltTestMenu;

    if (NULL == (hSpltTestMenu = LoadMenu(hinst, TEXT("SpltTestMenu"))))
    {
        return(FALSE);
    }

    if
    (
        !AppendMenu(GetMenu(ghwndTstShell),
                    MF_POPUP,
                    (UINT) hSpltTestMenu,
                    TEXT("SpltTestMenu"))
    )
    {
        return(FALSE);
    }

    DrawMenuBar(ghwndTstShell);
    return TRUE;
}



//--------------------------------------------------------------------------;
//
//  BOOL tstInit
//
//  Description:
//      Called by the test shell to provide the test program with an
//      opportunity to do whatever initialization it needs to do before
//      user interaction is initiated.  It also provides the test program
//      with an opportunity to keep a copy of a handle to the main window,
//      if the test program needs it.  In order to use some of the more
//      advanced features of test shell, several installation must be done
//      here:
//
//      -- All menu installation must be done here by calling
//          tstInstallCustomTest (that is, all menus that the test
//          application wants to add).
//
//      -- If the test application wants to trap the window messages of
//          the main test shell window, it must install its default
//          window procedure here by calling tstInstallDefWindowProc.
//
//      -- If the test application would like to use the status bar for
//          displaying the name of the currently running test, it must
//          call tstDisplayCurrentTest here.
//
//      -- If the test application would like to change the stop key from
//          ESC to something else, it must do so here by calling
//          tstChangeStopVKey.
//
//      -- If the test application would like to add dynamic test cases
//          to the test list, it must first add their names to the
//          virtual string table using tstAddNewString (and add their
//          group's name too), and then add the actual tests using
//          tstAddTestCase.  The virtual string table is an abstraction
//          which behaves just like a string table from the outside with
//          the exception that it accepts dynamically added string.
//
//  Arguments:
//      HWND hwndMain: A handle to the main window
//
//  Return (BOOL):
//      TRUE if initialization went well, FALSE otherwise which will abort
//      execution.
//
//  History:
//      06/08/93    T-OriG   - sample test app
//      9-Mar-95    v-mikere - adapted for Quartz source filter tests
//
//--------------------------------------------------------------------------;

BOOL tstInit
(
    HWND    hwndMain
)
{
   // Keep a copy of a handle to the main window
    ghwndTstShell = hwndMain;

    // Installs a default windows procedure which may handle messages
    // directed to Test Shell's main window.  It is vital to note that
    // this window function is substituted for DefWindowProc and not in
    // addition to it, and therefore DefWindowProc MUST be called from
    // within it in the default case (look at tstAppWndProc for an example).
    tstInstallDefWindowProc (tstAppWndProc);

    // Install the custom menus.  Look at InitOptionsMenu for more details.
    if (InitOptionsMenu(NULL)==FALSE)
        return FALSE;  // If menu installation failed, abort execution

    // This is a shell API which tells Test Shell to display the name of
    // the currenly executing API in its status bar.  It is a really nice
    // feature for test applications which do not use the toolbar for any
    // other purpose, as it comfortably notifies the user of the progress
    // of the tests.
    tstDisplayCurrentTest();

    // Change the stop key from ESC to SPACE
    tstChangeStopVKey (VSTOPKEY);

    // Add the names of the dynamic tests and dynamic groups to the
    // virtual string table.  Before the tests are added, it is important
    // to add their names, as the name ID is required by tstAddTestCase.
//    tstAddNewString (ID_TESTLAST + 1, (LPSTR) "The first test added dynamically");
//    tstAddNewString (GRP_LAST + 1, (LPSTR) "A dynamically added group");
//    tstAddNewString (ID_TESTLAST + 2, (LPSTR) "The first test in a dynamically added group");

    // Add test cases dynamically.  Note that these test cases will execute
    // on any platform, since they are added dynamically.  Real test
    // applications probably want to check the run environment and then
    // add dynamic test cases selectively.
//    tstAddTestCase (ID_TESTLAST + 1, TST_AUTOMATIC, FX_TEST1, GRP_ONE);
//    tstAddTestCase (ID_TESTLAST + 2, TST_AUTOMATIC, FX_TEST1, GRP_LAST + 1);

    DbgLog((LOG_TRACE,1, TEXT("Exiting tstInit")));
    return(TRUE);
} // tstInit()




//--------------------------------------------------------------------------;
//
//  int execTest
//
//  Description:
//      This is the actual test function which is called from within the
//      test shell.  It is passed various information about the test case
//      it is asked to run, and branches off to the appropriate test
//      function.  Note that it needs not switch on nFxID, but may also
//      use iCase or wID.
//
//  Arguments:
//      int nFxID: The test case identifier, also found in the third column
//          in the third column of the test list in the resource file
//
//      int iCase: The test case's number, which expresses the ordering
//          used by the test shell.
//
//      UINT wID: The test case's string ID, which identifies the string
//          containing the description of the test case.  Note that it is
//          also a good candidate for use in the switch statement, as it
//          is unique to each test case.
//
//      UINT wGroupID: The test case's group's string ID, which identifies
//          the string containing the description of the test case's group.
//
//  Return (int): Indicates the result of the test by using TST_FAIL,
//          TST_PASS, TST_OTHER, TST_ABORT, TST_TNYI, TST_TRAN, or TST_TERR
//
//  History:
//      06/08/93    T-OriG   - sample test app
//      9-Mar-95    v-mikere - adapted for Quartz source filter tests
//
//--------------------------------------------------------------------------;

int execTest
(
    int     nFxID,
    int     iCase,
    UINT    wID,
    UINT    wGroupID
)
{
    int ret = TST_OTHER;

    tstBeginSection(" ");

    switch(nFxID)
    {
        //
        //  The test cases
        //

        case FX_TEST1:
            ret = execTest1();
            break;

        case FX_TEST2:
            ret = execTest2();
            break;

        case FX_TEST3:
            ret = execTest3();
            break;

        case FX_TEST4:
            ret = execTest4();
            break;

        case FX_TEST5:
            ret = execTest5();
            break;

        case FX_TEST6:
            ret = execPerfTestAudio();
            break;

        case FX_TEST7:
            ret = execPerfTestVideoYUV422();
            break;

        case FX_TEST8:
            ret = execPerfTestVideoRGB565();
            break;

        case FX_TEST9:
            ret = execPerfTestVideoRGB24();
            break;

        case FX_TEST10:
            ret = execPerfTestVideoRGB8();
            break;

        case FX_TEST11:
            ret = execTestVideoFrames();
            break;

        case FX_TEST12:
            ret = execTestVideoFrame();
            break;

        case FX_TEST13:
            ret = execTest6();
            break;

        default:
            break;
    }

    tstEndSection();

    return(ret);

//Abort:
    return(TST_ABORT);
} // execTest()




//--------------------------------------------------------------------------;
//
//  void tstTerminate
//
//  Description:
//      This function is called when the test series is finished to free
//      structures and do whatever cleanup work it needs to do.  If it
//      needs not do anything, it may just return.
//
//  Arguments:
//      None.
//
//  Return (void):
//
//  History:
//      06/08/93    T-OriG   - sample test app
//      9-Mar-95    v-mikere - adapted for Quartz source filter tests
//
//--------------------------------------------------------------------------;

void tstTerminate
(
    void
)
{
    DbgLog((LOG_TRACE, 1, TEXT("Entering tstTerminate")));

    DbgTerminate();
    CoUninitialize();

    DbgLog((LOG_TRACE, 1, TEXT("Exiting tstTerminate")));
    return;
} // tstTerminate()




//--------------------------------------------------------------------------;
//
//  LRESULT tstAppWndProc
//
//  Description:
//      This shows how a test application can trap the window messages
//      received by the main Test Shell window.  It is installed in
//      in tstInit by calling tstInstallDefWindowProc, and receives
//      all window messages since.  This allows the test application to
//      be notified of certain event via a window without creating its
//      own hidden window or waiting in a tight PeekMessage() loop.  Note
//      that it is extremely important to call DefWindowProcA in the default
//      case as that is NOT done in tstshell's main window procedure if
//      tstInstallDefWindowProc is used.  DefWindowProcA has to be used as the
//      test shell main window is an ANSI window.
//
//  Arguments:
//      HWND hWnd: A handle to the window
//
//      UINT msg: The message to be processed
//
//      WPARAM wParam: The first parameters, meaning depends on msg
//
//      LPARAM lParam: The second parameter, meaning depends on msg
//
//  Return (LRESULT):
//
//  History:
//      08/03/93    T-OriG   - sample test app
//      9-Mar-95    v-mikere - adapted for Quartz source filter tests
//
//--------------------------------------------------------------------------;

LRESULT FAR PASCAL tstAppWndProc
(
    HWND    hWnd,
    UINT    msg,
    WPARAM  wParam,
    LPARAM  lParam
)
{
    switch (msg)
    {
        case WM_COMMAND:

        switch (GET_WM_COMMAND_ID(wParam, lParam)) {

            case IDM_SELECTFILE:
                SelectFile();
                return 0;
        }
        break;
    }
    return DefWindowProcA (hWnd, msg, wParam, lParam);
}




/***************************************************************************\
*                                                                           *
*   void SaveCustomProfile                                                  *
*                                                                           *
*   Description:                                                            *
*       This function saves custom environment info into a profile.  It is  *
*       installed by calling tstInstallWriteCustomInfo from tstInit, and is *
*       called during normal profile handling in SaveProfile.               *
*                                                                           *
*       Assumes the profile file was created from scratch by the calling    *
*       function.                                                           *
*                                                                           *
*       Custom data for this app:                                           *
*           [test data]      - section for info relating to test data       *
*               SourceFile   - name of AVI file read by source filter       *
*                                                                           *
*   Arguments:                                                              *
*           LPCSTR szProfileName: name of profile file                      *
*                                                                           *
*   Return (void):                                                          *
*                                                                           *
*   History:                                                                *
*       16-Mar-95    v-mikere                                               *
*                                                                           *
\***************************************************************************/


VOID CALLBACK SaveCustomProfile
(
    LPCSTR pszProfileName
)
{
    HANDLE      hProfile;
    TCHAR       szLine[128];
    CHAR        szBuf[128];
    DWORD       dwNumberOfBytesWritten;
    LPCTSTR     tszProfileName;

#ifdef UNICODE
    WCHAR   wszProfileName[128];

    if (!MultiByteToWideChar(CP_ACP, 0, pszProfileName, -1,
                                                        wszProfileName, 128))
    {
        MessageBox(ghwndTstShell,
                   TEXT("Could not convert profile name to ANSI"),
                   szAppName,
                   MB_ICONEXCLAMATION | MB_OK);
        return;
    }

    tszProfileName = wszProfileName;
#else
    tszProfileName = pszProfileName;
#endif

    if (0 == lstrlen(szSourceFile))
    {
        return;     // No custom data to store
    }

    hProfile = CreateFile(tszProfileName,
                          GENERIC_WRITE,
                          0,
                          NULL,
                          OPEN_ALWAYS,
                          FILE_ATTRIBUTE_NORMAL,
                          NULL);

    if (INVALID_HANDLE_VALUE == hProfile)
    {
        wsprintf(szLine, TEXT("Cannot open %s for writing"), tszProfileName);
        MessageBox(ghwndTstShell, szLine, szAppName,
                                                MB_ICONEXCLAMATION | MB_OK);
        return;
    }

    if (0xFFFFFFFF == SetFilePointer(hProfile, 0, NULL, FILE_END))
    {
        wsprintf(szLine, TEXT("Could not seek to end of %s"), tszProfileName);
        MessageBox(ghwndTstShell, szLine, szAppName,
                                                MB_ICONEXCLAMATION | MB_OK);
        return;
    }

    wsprintfA(szBuf, "[test data]\r\n");
    WriteFile(hProfile, szBuf, lstrlenA(szBuf), &dwNumberOfBytesWritten, NULL);

#ifdef UNICODE
    wsprintfA(szBuf, "SourceFile=%ls\r\n", szSourceFile);
#else
    wsprintfA(szBuf, "SourceFile=%hs\r\n", szSourceFile);
#endif
    WriteFile(hProfile, szBuf, lstrlenA(szBuf), &dwNumberOfBytesWritten, NULL);

    CloseHandle(hProfile);

} /* end of SaveCustomProfile */




/***************************************************************************\
*                                                                           *
*   BOOL LoadCustomProfile                                                  *
*                                                                           *
*   Description:                                                            *
*       This function loads custom environment info from a profile.  It is  *
*       installed by calling tstInstallReadCustomInfo from tstInit, and is  *
*       called during normal profile handling in LoadProfile.               *
*                                                                           *
*       Custom data for this app:                                           *
*           [test data]      - section for info relating to test data       *
*               SourceFile   - name of AVI file read by source filter       *
*                                                                           *
*   Arguments:                                                              *
*           LPCSTR szProfileName: name of profile file                      *
*                                                                           *
*   Return (void):                                                          *
*                                                                           *
*   History:                                                                *
*       16-Mar-95    v-mikere                                               *
*                                                                           *
\***************************************************************************/

VOID CALLBACK LoadCustomProfile
(
    LPCSTR pszProfileName
)
{
    TCHAR       szBuf[128];
    HANDLE      hProfile;
    LPCTSTR     tszProfileName;


#ifdef UNICODE
    WCHAR   wszProfileName[128];

    if (!MultiByteToWideChar(CP_ACP, 0, pszProfileName, -1,
                                                        wszProfileName, 128))
    {
        MessageBox(ghwndTstShell,
                   TEXT("Could not convert profile name to ANSI"),
                   szAppName,
                   MB_ICONEXCLAMATION | MB_OK);
        return;
    }

    tszProfileName = wszProfileName;
#else
    tszProfileName = pszProfileName;
#endif

    hProfile = CreateFile(tszProfileName,
                          GENERIC_READ,
                          0,
                          NULL,
                          OPEN_EXISTING,
                          FILE_ATTRIBUTE_NORMAL,
                          NULL);

    if (INVALID_HANDLE_VALUE == hProfile)
    {
        wsprintf(szBuf, TEXT("Cannot open profile %hs"), pszProfileName);
        MessageBox(ghwndTstShell, szBuf, szAppName,
                                                MB_ICONEXCLAMATION | MB_OK);
        return;
    }

    CloseHandle(hProfile);


    if
    (
        GetPrivateProfileString(TEXT("test data"),
                                TEXT("SourceFile"),
                                szSourceFile,
                                szBuf,
                                sizeof(szBuf),
                                tszProfileName)
    )
    {
        lstrcpy(szSourceFile, szBuf);
    }
} /* end of LoadCustomProfile */


// Prompt user for name of the source filter's file

void
SelectFile()
{
    OPENFILENAME    ofn;

    // Initialise the data fields

    ZeroMemory (&ofn, sizeof ofn);	

    ofn.lStructSize = sizeof(OPENFILENAME);
    ofn.hwndOwner = ghwndTstShell;
    ofn.lpstrFilter = TEXT("MPEG files\0*.MPG\0\0");
    ofn.nFilterIndex = 1;
    ofn.lpstrFile = szSourceFile;
    ofn.nMaxFile = MAX_PATH;
    ofn.lpstrTitle = TEXT("Select Source File");
    ofn.Flags = OFN_FILEMUSTEXIST;

    // Get the user's selection

    if (!GetOpenFileName(&ofn))
    {
        ASSERT(0 == CommDlgExtendedError());
    }
}

BOOL CALLBACK FrameTimeDlg(HWND hwnd, UINT uiMsg, WPARAM wParam, LPARAM lParam)
{
    UINT uID;
    TCHAR szText[100];
    TCHAR *pszText;

    /*  Just get a number out of the user ! */
    switch (uiMsg) {
    case WM_INITDIALOG:
        SetWindowLong(hwnd, DWL_USER, (LONG)lParam);
        SetDlgItemText(hwnd, ID_TIME, TEXT("0.0"));
        SetFocus(GetDlgItem(hwnd, ID_TIME));
        break;

    case WM_COMMAND:
        uID = GET_WM_COMMAND_ID(wParam, lParam);
        switch (uID) {
        case IDOK:
            /*  Get the number */
            GetDlgItemText(hwnd, ID_TIME, szText, sizeof(szText) / sizeof(szText[0]));
            *(double *)GetWindowLong(hwnd, DWL_USER) = _tcstod(szText, &pszText);
            EndDialog(hwnd, FALSE);
        }
        break;
    }
    return FALSE;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\netshow\inc\jconfig.h ===
/* jconfig.h --- generated by ckconfig.c */
/* see jconfig.doc for explanations */

/*
 * We want to use the standard windows boolean; I think the following
 * should accomplish this trick. 
 *
 * 8-28-96 - geoffdu
 */
#include <wtypes.h>
#define HAVE_BOOLEAN

#define HAVE_PROTOTYPES
#define HAVE_UNSIGNED_CHAR
#define HAVE_UNSIGNED_SHORT
/* #define void char */
/* #define const */
#undef CHAR_IS_UNSIGNED
#define HAVE_STDDEF_H
#define HAVE_STDLIB_H
#undef NEED_BSD_STRINGS
#undef NEED_SYS_TYPES_H
#undef NEED_FAR_POINTERS
#undef NEED_SHORT_EXTERNAL_NAMES
#undef INCOMPLETE_TYPES_BROKEN

#ifdef JPEG_INTERNALS

#undef RIGHT_SHIFT_IS_UNSIGNED

#endif /* JPEG_INTERNALS */

#ifdef JPEG_CJPEG_DJPEG

#define BMP_SUPPORTED		/* BMP image file format */
#define GIF_SUPPORTED		/* GIF image file format */
#define PPM_SUPPORTED		/* PBMPLUS PPM/PGM image file format */
#undef RLE_SUPPORTED		/* Utah RLE image file format */
#define TARGA_SUPPORTED		/* Targa image file format */

#undef TWO_FILE_COMMANDLINE	/* You may need this on non-Unix systems */
#undef NEED_SIGNAL_CATCHER	/* Define this if you use jmemname.c */
#undef DONT_USE_B_MODE
/* #define PROGRESS_REPORT */	/* optional */

#endif /* JPEG_CJPEG_DJPEG */
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\netshow\inc\jmorecfg.h ===
/*
 * jmorecfg.h
 *
 * Copyright (C) 1991-1996, Thomas G. Lane.
 * This file is part of the Independent JPEG Group's software.
 * For conditions of distribution and use, see the accompanying README file.
 *
 * This file contains additional configuration options that customize the
 * JPEG software for special applications or support machine-dependent
 * optimizations.  Most users will not need to touch this file.
 */


/*
 * Define BITS_IN_JSAMPLE as either
 *   8   for 8-bit sample values (the usual setting)
 *   12  for 12-bit sample values
 * Only 8 and 12 are legal data precisions for lossy JPEG according to the
 * JPEG standard, and the IJG code does not support anything else!
 * We do not support run-time selection of data precision, sorry.
 */

#define BITS_IN_JSAMPLE  8	/* use 8 or 12 */


/*
 * Maximum number of components (color channels) allowed in JPEG image.
 * To meet the letter of the JPEG spec, set this to 255.  However, darn
 * few applications need more than 4 channels (maybe 5 for CMYK + alpha
 * mask).  We recommend 10 as a reasonable compromise; use 4 if you are
 * really short on memory.  (Each allowed component costs a hundred or so
 * bytes of storage, whether actually used in an image or not.)
 */

#define MAX_COMPONENTS  10	/* maximum number of image components */


/*
 * Basic data types.
 * You may need to change these if you have a machine with unusual data
 * type sizes; for example, "char" not 8 bits, "short" not 16 bits,
 * or "long" not 32 bits.  We don't care whether "int" is 16 or 32 bits,
 * but it had better be at least 16.
 */

/* Representation of a single sample (pixel element value).
 * We frequently allocate large arrays of these, so it's important to keep
 * them small.  But if you have memory to burn and access to char or short
 * arrays is very slow on your hardware, you might want to change these.
 */

#if BITS_IN_JSAMPLE == 8
/* JSAMPLE should be the smallest type that will hold the values 0..255.
 * You can use a signed char by having GETJSAMPLE mask it with 0xFF.
 */

#ifdef HAVE_UNSIGNED_CHAR

typedef unsigned char JSAMPLE;
#define GETJSAMPLE(value)  ((int) (value))

#else /* not HAVE_UNSIGNED_CHAR */

typedef char JSAMPLE;
#ifdef CHAR_IS_UNSIGNED
#define GETJSAMPLE(value)  ((int) (value))
#else
#define GETJSAMPLE(value)  ((int) (value) & 0xFF)
#endif /* CHAR_IS_UNSIGNED */

#endif /* HAVE_UNSIGNED_CHAR */

#define MAXJSAMPLE	255
#define CENTERJSAMPLE	128

#endif /* BITS_IN_JSAMPLE == 8 */


#if BITS_IN_JSAMPLE == 12
/* JSAMPLE should be the smallest type that will hold the values 0..4095.
 * On nearly all machines "short" will do nicely.
 */

typedef short JSAMPLE;
#define GETJSAMPLE(value)  ((int) (value))

#define MAXJSAMPLE	4095
#define CENTERJSAMPLE	2048

#endif /* BITS_IN_JSAMPLE == 12 */


/* Representation of a DCT frequency coefficient.
 * This should be a signed value of at least 16 bits; "short" is usually OK.
 * Again, we allocate large arrays of these, but you can change to int
 * if you have memory to burn and "short" is really slow.
 */

typedef short JCOEF;


/* Compressed datastreams are represented as arrays of JOCTET.
 * These must be EXACTLY 8 bits wide, at least once they are written to
 * external storage.  Note that when using the stdio data source/destination
 * managers, this is also the data type passed to fread/fwrite.
 */

#ifdef HAVE_UNSIGNED_CHAR

typedef unsigned char JOCTET;
#define GETJOCTET(value)  (value)

#else /* not HAVE_UNSIGNED_CHAR */

typedef char JOCTET;
#ifdef CHAR_IS_UNSIGNED
#define GETJOCTET(value)  (value)
#else
#define GETJOCTET(value)  ((value) & 0xFF)
#endif /* CHAR_IS_UNSIGNED */

#endif /* HAVE_UNSIGNED_CHAR */


/* These typedefs are used for various table entries and so forth.
 * They must be at least as wide as specified; but making them too big
 * won't cost a huge amount of memory, so we don't provide special
 * extraction code like we did for JSAMPLE.  (In other words, these
 * typedefs live at a different point on the speed/space tradeoff curve.)
 */

/* UINT8 must hold at least the values 0..255. */

#ifdef HAVE_UNSIGNED_CHAR
typedef unsigned char UINT8;
#else /* not HAVE_UNSIGNED_CHAR */
#ifdef CHAR_IS_UNSIGNED
typedef char UINT8;
#else /* not CHAR_IS_UNSIGNED */
typedef short UINT8;
#endif /* CHAR_IS_UNSIGNED */
#endif /* HAVE_UNSIGNED_CHAR */

/* UINT16 must hold at least the values 0..65535. */

#ifdef HAVE_UNSIGNED_SHORT
typedef unsigned short UINT16;
#else /* not HAVE_UNSIGNED_SHORT */
typedef unsigned int UINT16;
#endif /* HAVE_UNSIGNED_SHORT */

/* INT16 must hold at least the values -32768..32767. */

#ifndef XMD_H			/* X11/xmd.h correctly defines INT16 */
typedef short INT16;
#endif

/* INT32 must hold at least signed 32-bit values. */

#if !defined( XMD_H ) && !defined( _INT32_DEFINED ) /* X11/xmd.h correctly defines INT32 */
#if _MSC_VER > 1100
#pragma warning( push )
#endif
#pragma warning( disable : 4142 ) // benign redefinition of type
typedef long INT32;
#if _MSC_VER > 1100
#pragma warning( pop )
#endif
#endif

/* Datatype used for image dimensions.  The JPEG standard only supports
 * images up to 64K*64K due to 16-bit fields in SOF markers.  Therefore
 * "unsigned int" is sufficient on all machines.  However, if you need to
 * handle larger images and you don't mind deviating from the spec, you
 * can change this datatype.
 */

typedef unsigned int JDIMENSION;

#define JPEG_MAX_DIMENSION  65500L  /* a tad under 64K to prevent overflows */


/* These macros are used in all function definitions and extern declarations.
 * You could modify them if you need to change function linkage conventions;
 * in particular, you'll need to do that to make the library a Windows DLL.
 * Another application is to make all functions global for use with debuggers
 * or code profilers that require it.
 */

/* a function called through method pointers: */
#define METHODDEF(type)		static type
/* a function used only in its module: */
#define LOCAL(type)		static type
/* a function referenced thru EXTERNs: */
#define GLOBAL(type)		type
/* a reference to a GLOBAL function: */
#define EXTERN(type)		extern type


/* This macro is used to declare a "method", that is, a function pointer.
 * We want to supply prototype parameters if the compiler can cope.
 * Note that the arglist parameter must be parenthesized!
 * Again, you can customize this if you need special linkage keywords.
 */

#ifdef HAVE_PROTOTYPES
#define JMETHOD(type,methodname,arglist)  type (*methodname) arglist
#else
#define JMETHOD(type,methodname,arglist)  type (*methodname) ()
#endif


/* Here is the pseudo-keyword for declaring pointers that must be "far"
 * on 80x86 machines.  Most of the specialized coding for 80x86 is handled
 * by just saying "FAR *" where such a pointer is needed.  In a few places
 * explicit coding is needed; see uses of the NEED_FAR_POINTERS symbol.
 */

/*
 * Don't redefine FAR if it is already defined
 *
 * 8-28-96 geoffdu
 */

#ifdef NEED_FAR_POINTERS
#define FAR  far
#else
#if (!defined(FAR))
#define FAR
#endif
#endif

/*
 * On a few systems, type boolean and/or its values FALSE, TRUE may appear
 * in standard header files.  Or you may have conflicts with application-
 * specific header files that you want to include together with these files.
 * Defining HAVE_BOOLEAN before including jpeglib.h should make it work.
 */

#ifndef HAVE_BOOLEAN
typedef int boolean;
#endif
#ifndef FALSE			/* in case these macros already exist */
#define FALSE	0		/* values of boolean */
#endif
#ifndef TRUE
#define TRUE	1
#endif


/*
 * The remaining options affect code selection within the JPEG library,
 * but they don't need to be visible to most applications using the library.
 * To minimize application namespace pollution, the symbols won't be
 * defined unless JPEG_INTERNALS or JPEG_INTERNAL_OPTIONS has been defined.
 */

#ifdef JPEG_INTERNALS
#define JPEG_INTERNAL_OPTIONS
#endif

#ifdef JPEG_INTERNAL_OPTIONS


/*
 * These defines indicate whether to include various optional functions.
 * Undefining some of these symbols will produce a smaller but less capable
 * library.  Note that you can leave certain source files out of the
 * compilation/linking process if you've #undef'd the corresponding symbols.
 * (You may HAVE to do that if your compiler doesn't like null source files.)
 */

/* Arithmetic coding is unsupported for legal reasons.  Complaints to IBM. */

/* Capability options common to encoder and decoder: */

#define DCT_ISLOW_SUPPORTED	/* slow but accurate integer algorithm */
#define DCT_IFAST_SUPPORTED	/* faster, less accurate integer method */
#define DCT_FLOAT_SUPPORTED	/* floating-point: accurate, fast on fast HW */

/* Encoder capability options: */

#undef  C_ARITH_CODING_SUPPORTED    /* Arithmetic coding back end? */
#define C_MULTISCAN_FILES_SUPPORTED /* Multiple-scan JPEG files? */
#define C_PROGRESSIVE_SUPPORTED	    /* Progressive JPEG? (Requires MULTISCAN)*/
#define ENTROPY_OPT_SUPPORTED	    /* Optimization of entropy coding parms? */
/* Note: if you selected 12-bit data precision, it is dangerous to turn off
 * ENTROPY_OPT_SUPPORTED.  The standard Huffman tables are only good for 8-bit
 * precision, so jchuff.c normally uses entropy optimization to compute
 * usable tables for higher precision.  If you don't want to do optimization,
 * you'll have to supply different default Huffman tables.
 * The exact same statements apply for progressive JPEG: the default tables
 * don't work for progressive mode.  (This may get fixed, however.)
 */
#define INPUT_SMOOTHING_SUPPORTED   /* Input image smoothing option? */

/* Decoder capability options: */

#undef  D_ARITH_CODING_SUPPORTED    /* Arithmetic coding back end? */
#define D_MULTISCAN_FILES_SUPPORTED /* Multiple-scan JPEG files? */
#define D_PROGRESSIVE_SUPPORTED	    /* Progressive JPEG? (Requires MULTISCAN)*/
#define BLOCK_SMOOTHING_SUPPORTED   /* Block smoothing? (Progressive only) */
#define IDCT_SCALING_SUPPORTED	    /* Output rescaling via IDCT? */
#undef  UPSAMPLE_SCALING_SUPPORTED  /* Output rescaling at upsample stage? */
#define UPSAMPLE_MERGING_SUPPORTED  /* Fast path for sloppy upsampling? */
#define QUANT_1PASS_SUPPORTED	    /* 1-pass color quantization? */
#define QUANT_2PASS_SUPPORTED	    /* 2-pass color quantization? */

/* more capability options later, no doubt */


/*
 * Ordering of RGB data in scanlines passed to or from the application.
 * If your application wants to deal with data in the order B,G,R, just
 * change these macros.  You can also deal with formats such as R,G,B,X
 * (one extra byte per pixel) by changing RGB_PIXELSIZE.  Note that changing
 * the offsets will also change the order in which colormap data is organized.
 * RESTRICTIONS:
 * 1. The sample applications cjpeg,djpeg do NOT support modified RGB formats.
 * 2. These macros only affect RGB<=>YCbCr color conversion, so they are not
 *    useful if you are using JPEG color spaces other than YCbCr or grayscale.
 * 3. The color quantizer modules will not behave desirably if RGB_PIXELSIZE
 *    is not 3 (they don't understand about dummy color components!).  So you
 *    can't use color quantization if you change that value.
 */

/*
 * Apparently, MS bitmaps are BGR format???
 * Switch these values and see what happens...
 *
 * 9/7/96 - geoffdu
 */
#define RGB_RED		2	/* Offset of Red in an RGB scanline element */
#define RGB_GREEN	1	/* Offset of Green */
#define RGB_BLUE	0	/* Offset of Blue */
#define RGB_PIXELSIZE	3	/* JSAMPLEs per RGB scanline element */


/* Definitions for speed-related optimizations. */


/* If your compiler supports inline functions, define INLINE
 * as the inline keyword; otherwise define it as empty.
 */

#ifndef INLINE
#ifdef __GNUC__			/* for instance, GNU C knows about inline */
#define INLINE __inline__
#endif
#ifndef INLINE
#define INLINE			/* default is to define it as empty */
#endif
#endif


/* On some machines (notably 68000 series) "int" is 32 bits, but multiplying
 * two 16-bit shorts is faster than multiplying two ints.  Define MULTIPLIER
 * as short on such a machine.  MULTIPLIER must be at least 16 bits wide.
 */

#ifndef MULTIPLIER
#define MULTIPLIER  short	/* type for fastest integer multiply */
#endif


/* FAST_FLOAT should be either float or double, whichever is done faster
 * by your compiler.  (Note that this type is only used in the floating point
 * DCT routines, so it only matters if you've defined DCT_FLOAT_SUPPORTED.)
 * Typically, float is faster in ANSI C compilers, while double is faster in
 * pre-ANSI compilers (because they insist on converting to double anyway).
 * The code below therefore chooses float if we have ANSI-style prototypes.
 */

#ifndef FAST_FLOAT
#ifdef HAVE_PROTOTYPES
#define FAST_FLOAT  float
#else
#define FAST_FLOAT  double
#endif
#endif

#endif /* JPEG_INTERNAL_OPTIONS */
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\mpeg1\test\testsplt\tstwrap.h ===
/***************************************************************************\
*                                                                           *
*   File: TstWrap.h                                                         *
*                                                                           *
*   Copyright (c) 1993,1996 Microsoft Corporation.  All rights reserved     *
*                                                                           *
*   Abstract:                                                               *
*       This header file contains various constants and prototypes used     *
*       in the Quartz source filter tests - test shell version.             *
*                                                                           *
*   Contents:                                                               *
*                                                                           *
*   History:                                                                *
*       06/08/93    T-OriG   - sample code                                  *
*       9-Mar-95    v-mikere - adapted for Quartz source filter tests       *
*       22-Mar-95   v-mikere - deleted DPF, added custom profile handlers   *
*                                                                           *
\***************************************************************************/


// Prototypes

// From SrcTest.cpp
VOID CALLBACK SaveCustomProfile(LPCSTR pszProfileName);
VOID CALLBACK LoadCustomProfile(LPCSTR pszProfileName);
void SelectFile(void);

extern LRESULT FAR PASCAL MenuProc (HWND hwnd, UINT msg, WPARAM wParam, LPARAM lParam);
extern BOOL InitOptionsMenu (LRESULT (CALLBACK* ManuProc)(HWND, UINT, WPARAM, LPARAM));
extern LRESULT FAR PASCAL tstAppWndProc (HWND hWnd, UINT msg, WPARAM wParam, LPARAM lParam);



// From testsplt.cpp
STDAPI_(int) execTest1(void);
STDAPI_(int) execTest2(void);
STDAPI_(int) execTest3(void);
STDAPI_(int) execTest4(void);
STDAPI_(int) execTest5(void);
STDAPI_(int) execTest6(void);
STDAPI_(int) execPerfTestAudio(void);
STDAPI_(int) execPerfTestVideoYUV422(void);
STDAPI_(int) execPerfTestVideoRGB565(void);
STDAPI_(int) execPerfTestVideoRGB24(void);
STDAPI_(int) execPerfTestVideoRGB8(void);
STDAPI_(int) execTestVideoFrames(void);
STDAPI_(int) execTestVideoFrame(void);

// Constants

// Stops the logging intensive test
#define VSTOPKEY            VK_SPACE

// The string identifiers for the group's names
#define GRP_BASIC           100
#define GRP_FG              101
#define GRP_MEDIUM          102
#define GRP_PERF            103
#define GRP_FRAME           104
#define GRP_FGSEL           105
#define GRP_LAST            GRP_FGSEL

// The string identifiers for the test's names
#define ID_TEST1           200
#define ID_TEST2           201
#define ID_TEST3           202
#define ID_TEST4           203
#define ID_TEST5           204
#define ID_TEST6           205
#define ID_TEST7           206
#define ID_TEST8           207
#define ID_TEST9           208
#define ID_TEST10          209
#define ID_TEST11          210
#define ID_TEST12          211
#define ID_TEST13          212
#define ID_TESTLAST        ID_TEST13

// The test case identifier (used in the switch statement in execTest)
#define FX_TEST1            300
#define FX_TEST2            301
#define FX_TEST3            302
#define FX_TEST4            303
#define FX_TEST5            304
#define FX_TEST6            305
#define FX_TEST7            306
#define FX_TEST8            307
#define FX_TEST9            308
#define FX_TEST10           309
#define FX_TEST11           310
#define FX_TEST12           311
#define FX_TEST13           312

// Menu identifiers
#define IDM_SELECTFILE      108

// Identifies the test list section of the resource file
#define TEST_LIST           500

// Multiple platform support
#define PLATFORM1           1
#define PLATFORM2           2
#define PLATFORM3           4

extern TCHAR szSourceFile[];

extern HINSTANCE hinst;
extern HWND      ghwndTstShell;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\netshow\inc\jpeglib.h ===
/*
 * jpeglib.h
 *
 * Copyright (C) 1991-1996, Thomas G. Lane.
 * This file is part of the Independent JPEG Group's software.
 * For conditions of distribution and use, see the accompanying README file.
 *
 * This file defines the application interface for the JPEG library.
 * Most applications using the library need only include this file,
 * and perhaps jerror.h if they want to know the exact error codes.
 */

#ifndef JPEGLIB_H
#define JPEGLIB_H

#ifdef __cplusplus
extern "C" {
#endif

/*
 * First we include the configuration files that record how this
 * installation of the JPEG library is set up.  jconfig.h can be
 * generated automatically for many systems.  jmorecfg.h contains
 * manual configuration options that most people need not worry about.
 */

#ifndef JCONFIG_INCLUDED	/* in case jinclude.h already did */
#include "jconfig.h"		/* widely used configuration options */
#endif
#include "jmorecfg.h"		/* seldom changed options */


/* Version ID for the JPEG library.
 * Might be useful for tests like "#if JPEG_LIB_VERSION >= 60".
 */

#define JPEG_LIB_VERSION  61	/* Version 6a */


/* Various constants determining the sizes of things.
 * All of these are specified by the JPEG standard, so don't change them
 * if you want to be compatible.
 */

#define DCTSIZE		    8	/* The basic DCT block is 8x8 samples */
#define DCTSIZE2	    64	/* DCTSIZE squared; # of elements in a block */
#define NUM_QUANT_TBLS      4	/* Quantization tables are numbered 0..3 */
#define NUM_HUFF_TBLS       4	/* Huffman tables are numbered 0..3 */
#define NUM_ARITH_TBLS      16	/* Arith-coding tables are numbered 0..15 */
#define MAX_COMPS_IN_SCAN   4	/* JPEG limit on # of components in one scan */
#define MAX_SAMP_FACTOR     4	/* JPEG limit on sampling factors */
/* Unfortunately, it seems Adobe doesn't always follow the standard;
 * the PostScript DCT filter can emit files with many more than 10 blocks/MCU.
 * If you happen to run across such a file, you can up D_MAX_BLOCKS_IN_MCU
 * to handle it.  We even let you do this from the jconfig.h file.  However,
 * we strongly discourage changing C_MAX_BLOCKS_IN_MCU; just because Adobe
 * sometimes emits noncompliant files doesn't mean you should too.
 */
#define C_MAX_BLOCKS_IN_MCU   10 /* compressor's limit on blocks per MCU */
#ifndef D_MAX_BLOCKS_IN_MCU
#define D_MAX_BLOCKS_IN_MCU   10 /* decompressor's limit on blocks per MCU */
#endif


/* Data structures for images (arrays of samples and of DCT coefficients).
 * On 80x86 machines, the image arrays are too big for near pointers,
 * but the pointer arrays can fit in near memory.
 */

typedef JSAMPLE FAR *JSAMPROW;	/* ptr to one image row of pixel samples. */
typedef JSAMPROW *JSAMPARRAY;	/* ptr to some rows (a 2-D sample array) */
typedef JSAMPARRAY *JSAMPIMAGE;	/* a 3-D sample array: top index is color */

typedef JCOEF JBLOCK[DCTSIZE2];	/* one block of coefficients */
typedef JBLOCK FAR *JBLOCKROW;	/* pointer to one row of coefficient blocks */
typedef JBLOCKROW *JBLOCKARRAY;		/* a 2-D array of coefficient blocks */
typedef JBLOCKARRAY *JBLOCKIMAGE;	/* a 3-D array of coefficient blocks */

typedef JCOEF FAR *JCOEFPTR;	/* useful in a couple of places */


/* Types for JPEG compression parameters and working tables. */


/* DCT coefficient quantization tables. */

typedef struct {
  /* This array gives the coefficient quantizers in natural array order
   * (not the zigzag order in which they are stored in a JPEG DQT marker).
   * CAUTION: IJG versions prior to v6a kept this array in zigzag order.
   */
  UINT16 quantval[DCTSIZE2];	/* quantization step for each coefficient */
  /* This field is used only during compression.  It's initialized FALSE when
   * the table is created, and set TRUE when it's been output to the file.
   * You could suppress output of a table by setting this to TRUE.
   * (See jpeg_suppress_tables for an example.)
   */
  boolean sent_table;		/* TRUE when table has been output */
} JQUANT_TBL;


/* Huffman coding tables. */

typedef struct {
  /* These two fields directly represent the contents of a JPEG DHT marker */
  UINT8 bits[17];		/* bits[k] = # of symbols with codes of */
				/* length k bits; bits[0] is unused */
  UINT8 huffval[256];		/* The symbols, in order of incr code length */
  /* This field is used only during compression.  It's initialized FALSE when
   * the table is created, and set TRUE when it's been output to the file.
   * You could suppress output of a table by setting this to TRUE.
   * (See jpeg_suppress_tables for an example.)
   */
  boolean sent_table;		/* TRUE when table has been output */
} JHUFF_TBL;


/* Basic info about one component (color channel). */

typedef struct {
  /* These values are fixed over the whole image. */
  /* For compression, they must be supplied by parameter setup; */
  /* for decompression, they are read from the SOF marker. */
  int component_id;		/* identifier for this component (0..255) */
  int component_index;		/* its index in SOF or cinfo->comp_info[] */
  int h_samp_factor;		/* horizontal sampling factor (1..4) */
  int v_samp_factor;		/* vertical sampling factor (1..4) */
  int quant_tbl_no;		/* quantization table selector (0..3) */
  /* These values may vary between scans. */
  /* For compression, they must be supplied by parameter setup; */
  /* for decompression, they are read from the SOS marker. */
  /* The decompressor output side may not use these variables. */
  int dc_tbl_no;		/* DC entropy table selector (0..3) */
  int ac_tbl_no;		/* AC entropy table selector (0..3) */

  /* Remaining fields should be treated as private by applications. */

  /* These values are computed during compression or decompression startup: */
  /* Component's size in DCT blocks.
   * Any dummy blocks added to complete an MCU are not counted; therefore
   * these values do not depend on whether a scan is interleaved or not.
   */
  JDIMENSION width_in_blocks;
  JDIMENSION height_in_blocks;
  /* Size of a DCT block in samples.  Always DCTSIZE for compression.
   * For decompression this is the size of the output from one DCT block,
   * reflecting any scaling we choose to apply during the IDCT step.
   * Values of 1,2,4,8 are likely to be supported.  Note that different
   * components may receive different IDCT scalings.
   */
  int DCT_scaled_size;
  /* The downsampled dimensions are the component's actual, unpadded number
   * of samples at the main buffer (preprocessing/compression interface), thus
   * downsampled_width = ceil(image_width * Hi/Hmax)
   * and similarly for height.  For decompression, IDCT scaling is included, so
   * downsampled_width = ceil(image_width * Hi/Hmax * DCT_scaled_size/DCTSIZE)
   */
  JDIMENSION downsampled_width;	 /* actual width in samples */
  JDIMENSION downsampled_height; /* actual height in samples */
  /* This flag is used only for decompression.  In cases where some of the
   * components will be ignored (eg grayscale output from YCbCr image),
   * we can skip most computations for the unused components.
   */
  boolean component_needed;	/* do we need the value of this component? */

  /* These values are computed before starting a scan of the component. */
  /* The decompressor output side may not use these variables. */
  int MCU_width;		/* number of blocks per MCU, horizontally */
  int MCU_height;		/* number of blocks per MCU, vertically */
  int MCU_blocks;		/* MCU_width * MCU_height */
  int MCU_sample_width;		/* MCU width in samples, MCU_width*DCT_scaled_size */
  int last_col_width;		/* # of non-dummy blocks across in last MCU */
  int last_row_height;		/* # of non-dummy blocks down in last MCU */

  /* Saved quantization table for component; NULL if none yet saved.
   * See jdinput.c comments about the need for this information.
   * This field is currently used only for decompression.
   */
  JQUANT_TBL * quant_table;

  /* Private per-component storage for DCT or IDCT subsystem. */
  void * dct_table;
} jpeg_component_info;


/* The script for encoding a multiple-scan file is an array of these: */

typedef struct {
  int comps_in_scan;		/* number of components encoded in this scan */
  int component_index[MAX_COMPS_IN_SCAN]; /* their SOF/comp_info[] indexes */
  int Ss, Se;			/* progressive JPEG spectral selection parms */
  int Ah, Al;			/* progressive JPEG successive approx. parms */
} jpeg_scan_info;


/* Known color spaces. */

typedef enum {
	JCS_UNKNOWN,		/* error/unspecified */
	JCS_GRAYSCALE,		/* monochrome */
	JCS_RGB,		/* red/green/blue */
	JCS_YCbCr,		/* Y/Cb/Cr (also known as YUV) */
	JCS_CMYK,		/* C/M/Y/K */
	JCS_YCCK		/* Y/Cb/Cr/K */
} J_COLOR_SPACE;

/* DCT/IDCT algorithm options. */

typedef enum {
	JDCT_ISLOW,		/* slow but accurate integer algorithm */
	JDCT_IFAST,		/* faster, less accurate integer method */
	JDCT_FLOAT		/* floating-point: accurate, fast on fast HW */
} J_DCT_METHOD;

#ifndef JDCT_DEFAULT		/* may be overridden in jconfig.h */
#define JDCT_DEFAULT  JDCT_ISLOW
#endif
#ifndef JDCT_FASTEST		/* may be overridden in jconfig.h */
#define JDCT_FASTEST  JDCT_IFAST
#endif

/* Dithering options for decompression. */

typedef enum {
	JDITHER_NONE,		/* no dithering */
	JDITHER_ORDERED,	/* simple ordered dither */
	JDITHER_FS		/* Floyd-Steinberg error diffusion dither */
} J_DITHER_MODE;


/* Common fields between JPEG compression and decompression master structs. */

#define jpeg_common_fields \
  struct jpeg_error_mgr * err;	/* Error handler module */\
  struct jpeg_memory_mgr * mem;	/* Memory manager module */\
  struct jpeg_progress_mgr * progress; /* Progress monitor, or NULL if none */\
  boolean is_decompressor;	/* so common code can tell which is which */\
  boolean has_mmx;		/* is processor w/MMX present? */\
  int global_state		/* for checking call sequence validity */

/* Routines that are to be used by both halves of the library are declared
 * to receive a pointer to this structure.  There are no actual instances of
 * jpeg_common_struct, only of jpeg_compress_struct and jpeg_decompress_struct.
 */
struct jpeg_common_struct {
  jpeg_common_fields;		/* Fields common to both master struct types */
  /* Additional fields follow in an actual jpeg_compress_struct or
   * jpeg_decompress_struct.  All three structs must agree on these
   * initial fields!  (This would be a lot cleaner in C++.)
   */
};

typedef struct jpeg_common_struct * j_common_ptr;
typedef struct jpeg_compress_struct * j_compress_ptr;
typedef struct jpeg_decompress_struct * j_decompress_ptr;


/* Master record for a compression instance */

struct jpeg_compress_struct {
  jpeg_common_fields;		/* Fields shared with jpeg_decompress_struct */

  /* Destination for compressed data */
  struct jpeg_destination_mgr * dest;

  /* Description of source image --- these fields must be filled in by
   * outer application before starting compression.  in_color_space must
   * be correct before you can even call jpeg_set_defaults().
   */

  JDIMENSION image_width;	/* input image width */
  JDIMENSION image_height;	/* input image height */
  int input_components;		/* # of color components in input image */
  J_COLOR_SPACE in_color_space;	/* colorspace of input image */

  double input_gamma;		/* image gamma of input image */

  /* Compression parameters --- these fields must be set before calling
   * jpeg_start_compress().  We recommend calling jpeg_set_defaults() to
   * initialize everything to reasonable defaults, then changing anything
   * the application specifically wants to change.  That way you won't get
   * burnt when new parameters are added.  Also note that there are several
   * helper routines to simplify changing parameters.
   */

  int data_precision;		/* bits of precision in image data */

  int num_components;		/* # of color components in JPEG image */
  J_COLOR_SPACE jpeg_color_space; /* colorspace of JPEG image */

  jpeg_component_info * comp_info;
  /* comp_info[i] describes component that appears i'th in SOF */

  JQUANT_TBL * quant_tbl_ptrs[NUM_QUANT_TBLS];
  /* ptrs to coefficient quantization tables, or NULL if not defined */

  JHUFF_TBL * dc_huff_tbl_ptrs[NUM_HUFF_TBLS];
  JHUFF_TBL * ac_huff_tbl_ptrs[NUM_HUFF_TBLS];
  /* ptrs to Huffman coding tables, or NULL if not defined */

  UINT8 arith_dc_L[NUM_ARITH_TBLS]; /* L values for DC arith-coding tables */
  UINT8 arith_dc_U[NUM_ARITH_TBLS]; /* U values for DC arith-coding tables */
  UINT8 arith_ac_K[NUM_ARITH_TBLS]; /* Kx values for AC arith-coding tables */

  int num_scans;		/* # of entries in scan_info array */
  const jpeg_scan_info * scan_info; /* script for multi-scan file, or NULL */
  /* The default value of scan_info is NULL, which causes a single-scan
   * sequential JPEG file to be emitted.  To create a multi-scan file,
   * set num_scans and scan_info to point to an array of scan definitions.
   */

  boolean raw_data_in;		/* TRUE=caller supplies downsampled data */
  boolean arith_code;		/* TRUE=arithmetic coding, FALSE=Huffman */
  boolean optimize_coding;	/* TRUE=optimize entropy encoding parms */
  boolean CCIR601_sampling;	/* TRUE=first samples are cosited */
  int smoothing_factor;		/* 1..100, or 0 for no input smoothing */
  J_DCT_METHOD dct_method;	/* DCT algorithm selector */

  /* The restart interval can be specified in absolute MCUs by setting
   * restart_interval, or in MCU rows by setting restart_in_rows
   * (in which case the correct restart_interval will be figured
   * for each scan).
   */
  unsigned int restart_interval; /* MCUs per restart, or 0 for no restart */
  int restart_in_rows;		/* if > 0, MCU rows per restart interval */

  /* Parameters controlling emission of special markers. */

  boolean write_JFIF_header;	/* should a JFIF marker be written? */
  /* These three values are not used by the JPEG code, merely copied */
  /* into the JFIF APP0 marker.  density_unit can be 0 for unknown, */
  /* 1 for dots/inch, or 2 for dots/cm.  Note that the pixel aspect */
  /* ratio is defined by X_density/Y_density even when density_unit=0. */
  UINT8 density_unit;		/* JFIF code for pixel size units */
  UINT16 X_density;		/* Horizontal pixel density */
  UINT16 Y_density;		/* Vertical pixel density */
  boolean write_Adobe_marker;	/* should an Adobe marker be written? */

  /* State variable: index of next scanline to be written to
   * jpeg_write_scanlines().  Application may use this to control its
   * processing loop, e.g., "while (next_scanline < image_height)".
   */

  JDIMENSION next_scanline;	/* 0 .. image_height-1  */

  /* Remaining fields are known throughout compressor, but generally
   * should not be touched by a surrounding application.
   */

  /*
   * These fields are computed during compression startup
   */
  boolean progressive_mode;	/* TRUE if scan script uses progressive mode */
  int max_h_samp_factor;	/* largest h_samp_factor */
  int max_v_samp_factor;	/* largest v_samp_factor */

  JDIMENSION total_iMCU_rows;	/* # of iMCU rows to be input to coef ctlr */
  /* The coefficient controller receives data in units of MCU rows as defined
   * for fully interleaved scans (whether the JPEG file is interleaved or not).
   * There are v_samp_factor * DCTSIZE sample rows of each component in an
   * "iMCU" (interleaved MCU) row.
   */

  /*
   * These fields are valid during any one scan.
   * They describe the components and MCUs actually appearing in the scan.
   */
  int comps_in_scan;		/* # of JPEG components in this scan */
  jpeg_component_info * cur_comp_info[MAX_COMPS_IN_SCAN];
  /* *cur_comp_info[i] describes component that appears i'th in SOS */

  JDIMENSION MCUs_per_row;	/* # of MCUs across the image */
  JDIMENSION MCU_rows_in_scan;	/* # of MCU rows in the image */

  int blocks_in_MCU;		/* # of DCT blocks per MCU */
  int MCU_membership[C_MAX_BLOCKS_IN_MCU];
  /* MCU_membership[i] is index in cur_comp_info of component owning */
  /* i'th block in an MCU */

  int Ss, Se, Ah, Al;		/* progressive JPEG parameters for scan */

  /*
   * Links to compression subobjects (methods and private variables of modules)
   */
  struct jpeg_comp_master * master;
  struct jpeg_c_main_controller * main;
  struct jpeg_c_prep_controller * prep;
  struct jpeg_c_coef_controller * coef;
  struct jpeg_marker_writer * marker;
  struct jpeg_color_converter * cconvert;
  struct jpeg_downsampler * downsample;
  struct jpeg_forward_dct * fdct;
  struct jpeg_entropy_encoder * entropy;
};


/* Master record for a decompression instance */

struct jpeg_decompress_struct {
  jpeg_common_fields;		/* Fields shared with jpeg_compress_struct */

  /* Source of compressed data */
  struct jpeg_source_mgr * src;

  /* Basic description of image --- filled in by jpeg_read_header(). */
  /* Application may inspect these values to decide how to process image. */

  JDIMENSION image_width;	/* nominal image width (from SOF marker) */
  JDIMENSION image_height;	/* nominal image height */
  int num_components;		/* # of color components in JPEG image */
  J_COLOR_SPACE jpeg_color_space; /* colorspace of JPEG image */

  /* Decompression processing parameters --- these fields must be set before
   * calling jpeg_start_decompress().  Note that jpeg_read_header() initializes
   * them to default values.
   */

  J_COLOR_SPACE out_color_space; /* colorspace for output */

  unsigned int scale_num, scale_denom; /* fraction by which to scale image */

  double output_gamma;		/* image gamma wanted in output */

  boolean buffered_image;	/* TRUE=multiple output passes */
  boolean raw_data_out;		/* TRUE=downsampled data wanted */

  J_DCT_METHOD dct_method;	/* IDCT algorithm selector */
  boolean do_fancy_upsampling;	/* TRUE=apply fancy upsampling */
  boolean do_block_smoothing;	/* TRUE=apply interblock smoothing */

  boolean quantize_colors;	/* TRUE=colormapped output wanted */
  /* the following are ignored if not quantize_colors: */
  J_DITHER_MODE dither_mode;	/* type of color dithering to use */
  boolean two_pass_quantize;	/* TRUE=use two-pass color quantization */
  int desired_number_of_colors;	/* max # colors to use in created colormap */
  /* these are significant only in buffered-image mode: */
  boolean enable_1pass_quant;	/* enable future use of 1-pass quantizer */
  boolean enable_external_quant;/* enable future use of external colormap */
  boolean enable_2pass_quant;	/* enable future use of 2-pass quantizer */

  /* Description of actual output image that will be returned to application.
   * These fields are computed by jpeg_start_decompress().
   * You can also use jpeg_calc_output_dimensions() to determine these values
   * in advance of calling jpeg_start_decompress().
   */

  JDIMENSION output_width;	/* scaled image width */
  JDIMENSION output_height;	/* scaled image height */
  int out_color_components;	/* # of color components in out_color_space */
  int output_components;	/* # of color components returned */
  /* output_components is 1 (a colormap index) when quantizing colors;
   * otherwise it equals out_color_components.
   */
  int rec_outbuf_height;	/* min recommended height of scanline buffer */
  /* If the buffer passed to jpeg_read_scanlines() is less than this many rows
   * high, space and time will be wasted due to unnecessary data copying.
   * Usually rec_outbuf_height will be 1 or 2, at most 4.
   */

  /* When quantizing colors, the output colormap is described by these fields.
   * The application can supply a colormap by setting colormap non-NULL before
   * calling jpeg_start_decompress; otherwise a colormap is created during
   * jpeg_start_decompress or jpeg_start_output.
   * The map has out_color_components rows and actual_number_of_colors columns.
   */
  int actual_number_of_colors;	/* number of entries in use */
  JSAMPARRAY colormap;		/* The color map as a 2-D pixel array */

  /* State variables: these variables indicate the progress of decompression.
   * The application may examine these but must not modify them.
   */

  /* Row index of next scanline to be read from jpeg_read_scanlines().
   * Application may use this to control its processing loop, e.g.,
   * "while (output_scanline < output_height)".
   */
  JDIMENSION output_scanline;	/* 0 .. output_height-1  */

  /* Current input scan number and number of iMCU rows completed in scan.
   * These indicate the progress of the decompressor input side.
   */
  int input_scan_number;	/* Number of SOS markers seen so far */
  JDIMENSION input_iMCU_row;	/* Number of iMCU rows completed */

  /* The "output scan number" is the notional scan being displayed by the
   * output side.  The decompressor will not allow output scan/row number
   * to get ahead of input scan/row, but it can fall arbitrarily far behind.
   */
  int output_scan_number;	/* Nominal scan number being displayed */
  JDIMENSION output_iMCU_row;	/* Number of iMCU rows read */

  /* Current progression status.  coef_bits[c][i] indicates the precision
   * with which component c's DCT coefficient i (in zigzag order) is known.
   * It is -1 when no data has yet been received, otherwise it is the point
   * transform (shift) value for the most recent scan of the coefficient
   * (thus, 0 at completion of the progression).
   * This pointer is NULL when reading a non-progressive file.
   */
  int (*coef_bits)[DCTSIZE2];	/* -1 or current Al value for each coef */

  /* Internal JPEG parameters --- the application usually need not look at
   * these fields.  Note that the decompressor output side may not use
   * any parameters that can change between scans.
   */

  /* Quantization and Huffman tables are carried forward across input
   * datastreams when processing abbreviated JPEG datastreams.
   */

  JQUANT_TBL * quant_tbl_ptrs[NUM_QUANT_TBLS];
  /* ptrs to coefficient quantization tables, or NULL if not defined */

  JHUFF_TBL * dc_huff_tbl_ptrs[NUM_HUFF_TBLS];
  JHUFF_TBL * ac_huff_tbl_ptrs[NUM_HUFF_TBLS];
  /* ptrs to Huffman coding tables, or NULL if not defined */

  /* These parameters are never carried across datastreams, since they
   * are given in SOF/SOS markers or defined to be reset by SOI.
   */

  int data_precision;		/* bits of precision in image data */

  jpeg_component_info * comp_info;
  /* comp_info[i] describes component that appears i'th in SOF */

  boolean progressive_mode;	/* TRUE if SOFn specifies progressive mode */
  boolean arith_code;		/* TRUE=arithmetic coding, FALSE=Huffman */

  UINT8 arith_dc_L[NUM_ARITH_TBLS]; /* L values for DC arith-coding tables */
  UINT8 arith_dc_U[NUM_ARITH_TBLS]; /* U values for DC arith-coding tables */
  UINT8 arith_ac_K[NUM_ARITH_TBLS]; /* Kx values for AC arith-coding tables */

  unsigned int restart_interval; /* MCUs per restart interval, or 0 for no restart */

  /* These fields record data obtained from optional markers recognized by
   * the JPEG library.
   */
  boolean saw_JFIF_marker;	/* TRUE iff a JFIF APP0 marker was found */
  /* Data copied from JFIF marker: */
  UINT8 density_unit;		/* JFIF code for pixel size units */
  UINT16 X_density;		/* Horizontal pixel density */
  UINT16 Y_density;		/* Vertical pixel density */
  boolean saw_Adobe_marker;	/* TRUE iff an Adobe APP14 marker was found */
  UINT8 Adobe_transform;	/* Color transform code from Adobe marker */

  boolean CCIR601_sampling;	/* TRUE=first samples are cosited */

  /* Remaining fields are known throughout decompressor, but generally
   * should not be touched by a surrounding application.
   */

  /*
   * These fields are computed during decompression startup
   */
  int max_h_samp_factor;	/* largest h_samp_factor */
  int max_v_samp_factor;	/* largest v_samp_factor */

  int min_DCT_scaled_size;	/* smallest DCT_scaled_size of any component */

  JDIMENSION total_iMCU_rows;	/* # of iMCU rows in image */
  /* The coefficient controller's input and output progress is measured in
   * units of "iMCU" (interleaved MCU) rows.  These are the same as MCU rows
   * in fully interleaved JPEG scans, but are used whether the scan is
   * interleaved or not.  We define an iMCU row as v_samp_factor DCT block
   * rows of each component.  Therefore, the IDCT output contains
   * v_samp_factor*DCT_scaled_size sample rows of a component per iMCU row.
   */

  JSAMPLE * sample_range_limit; /* table for fast range-limiting */

  /*
   * These fields are valid during any one scan.
   * They describe the components and MCUs actually appearing in the scan.
   * Note that the decompressor output side must not use these fields.
   */
  int comps_in_scan;		/* # of JPEG components in this scan */
  jpeg_component_info * cur_comp_info[MAX_COMPS_IN_SCAN];
  /* *cur_comp_info[i] describes component that appears i'th in SOS */

  JDIMENSION MCUs_per_row;	/* # of MCUs across the image */
  JDIMENSION MCU_rows_in_scan;	/* # of MCU rows in the image */

  int blocks_in_MCU;		/* # of DCT blocks per MCU */
  int MCU_membership[D_MAX_BLOCKS_IN_MCU];
  /* MCU_membership[i] is index in cur_comp_info of component owning */
  /* i'th block in an MCU */

  int Ss, Se, Ah, Al;		/* progressive JPEG parameters for scan */

  /* This field is shared between entropy decoder and marker parser.
   * It is either zero or the code of a JPEG marker that has been
   * read from the data source, but has not yet been processed.
   */
  int unread_marker;

  /*
   * Links to decompression subobjects (methods, private variables of modules)
   */
  struct jpeg_decomp_master * master;
  struct jpeg_d_main_controller * main;
  struct jpeg_d_coef_controller * coef;
  struct jpeg_d_post_controller * post;
  struct jpeg_input_controller * inputctl;
  struct jpeg_marker_reader * marker;
  struct jpeg_entropy_decoder * entropy;
  struct jpeg_inverse_dct * idct;
  struct jpeg_upsampler * upsample;
  struct jpeg_color_deconverter * cconvert;
  struct jpeg_color_quantizer * cquantize;
/*
 * Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack
 *
 * Additional method to allow the low level guts of the jpeg decoder to ask
 * an application if a particular row is present in the input data.
 *
 * jpeg_create_decompress will zero out the field when the decompress struct
 * is created, and decode_mcu will ignore the refal stuff if the pointer is
 * NULL.
 *
 * CraigDo -- 7/29/96
 *
 * Change row_present to mcu_present
 *
 * geoffdu -- 12/12/96
 *
 * Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack Hack
 */

  JMETHOD(boolean, mcu_present, (j_decompress_ptr cinfo, int col,
      int row, int *skip_bytes));

    /*
     * Hack Hack Hack etc etc
     *
     * Pull this out of jdhuff.c (where it was a global) and stick it
     * in here, so that the decompression library will be reentrant
     *
     * GeoffDu -- 8/30/96
     *
     * Another hack: keep track of which MCU column we are working on
     *
     * GeoffDu -- 12/12/96
     *
     * Hack Hack Cough Wheeze
     */

  boolean data_whacked;
  JDIMENSION current_MCU_col;
};


/* "Object" declarations for JPEG modules that may be supplied or called
 * directly by the surrounding application.
 * As with all objects in the JPEG library, these structs only define the
 * publicly visible methods and state variables of a module.  Additional
 * private fields may exist after the public ones.
 */


/* Error handler object */

struct jpeg_error_mgr {
  /* Error exit handler: does not return to caller */
  JMETHOD(void, error_exit, (j_common_ptr cinfo));
  /* Conditionally emit a trace or warning message */
  JMETHOD(void, emit_message, (j_common_ptr cinfo, int msg_level));
  /* Routine that actually outputs a trace or error message */
  JMETHOD(void, output_message, (j_common_ptr cinfo));
  /* Format a message string for the most recent JPEG error or message */
  JMETHOD(void, format_message, (j_common_ptr cinfo, char * buffer));
#define JMSG_LENGTH_MAX  200	/* recommended size of format_message buffer */
  /* Reset error state variables at start of a new image */
  JMETHOD(void, reset_error_mgr, (j_common_ptr cinfo));

  /* The message ID code and any parameters are saved here.
   * A message can have one string parameter or up to 8 int parameters.
   */
  int msg_code;
#define JMSG_STR_PARM_MAX  80
  union {
    int i[8];
    char s[JMSG_STR_PARM_MAX];
  } msg_parm;

  /* Standard state variables for error facility */

  int trace_level;		/* max msg_level that will be displayed */

  /* For recoverable corrupt-data errors, we emit a warning message,
   * but keep going unless emit_message chooses to abort.  emit_message
   * should count warnings in num_warnings.  The surrounding application
   * can check for bad data by seeing if num_warnings is nonzero at the
   * end of processing.
   */
  long num_warnings;		/* number of corrupt-data warnings */

  /* These fields point to the table(s) of error message strings.
   * An application can change the table pointer to switch to a different
   * message list (typically, to change the language in which errors are
   * reported).  Some applications may wish to add additional error codes
   * that will be handled by the JPEG library error mechanism; the second
   * table pointer is used for this purpose.
   *
   * First table includes all errors generated by JPEG library itself.
   * Error code 0 is reserved for a "no such error string" message.
   */
  const char * const * jpeg_message_table; /* Library errors */
  int last_jpeg_message;    /* Table contains strings 0..last_jpeg_message */
  /* Second table can be added by application (see cjpeg/djpeg for example).
   * It contains strings numbered first_addon_message..last_addon_message.
   */
  const char * const * addon_message_table; /* Non-library errors */
  int first_addon_message;	/* code for first string in addon table */
  int last_addon_message;	/* code for last string in addon table */
};


/* Progress monitor object */

struct jpeg_progress_mgr {
  JMETHOD(void, progress_monitor, (j_common_ptr cinfo));

  long pass_counter;		/* work units completed in this pass */
  long pass_limit;		/* total number of work units in this pass */
  int completed_passes;		/* passes completed so far */
  int total_passes;		/* total number of passes expected */
};


/* Data destination object for compression */

struct jpeg_destination_mgr {
  JOCTET * next_output_byte;	/* => next byte to write in buffer */
  size_t free_in_buffer;	/* # of byte spaces remaining in buffer */

  JMETHOD(void, init_destination, (j_compress_ptr cinfo));
  JMETHOD(boolean, empty_output_buffer, (j_compress_ptr cinfo));
  JMETHOD(void, term_destination, (j_compress_ptr cinfo));
};


/* Data source object for decompression */

struct jpeg_source_mgr {
  const JOCTET * next_input_byte; /* => next byte to read from buffer */
  size_t bytes_in_buffer;	/* # of bytes remaining in buffer */

  JMETHOD(void, init_source, (j_decompress_ptr cinfo));
  JMETHOD(boolean, fill_input_buffer, (j_decompress_ptr cinfo));
  JMETHOD(void, skip_input_data, (j_decompress_ptr cinfo, long num_bytes));
  JMETHOD(boolean, resync_to_restart, (j_decompress_ptr cinfo, int desired));
  JMETHOD(void, term_source, (j_decompress_ptr cinfo));
};


/* Memory manager object.
 * Allocates "small" objects (a few K total), "large" objects (tens of K),
 * and "really big" objects (virtual arrays with backing store if needed).
 * The memory manager does not allow individual objects to be freed; rather,
 * each created object is assigned to a pool, and whole pools can be freed
 * at once.  This is faster and more convenient than remembering exactly what
 * to free, especially where malloc()/free() are not too speedy.
 * NB: alloc routines never return NULL.  They exit to error_exit if not
 * successful.
 */

#define JPOOL_PERMANENT	0	/* lasts until master record is destroyed */
#define JPOOL_IMAGE	1	/* lasts until done with image/datastream */
#define JPOOL_NUMPOOLS	2

typedef struct jvirt_sarray_control * jvirt_sarray_ptr;
typedef struct jvirt_barray_control * jvirt_barray_ptr;


struct jpeg_memory_mgr {
  /* Method pointers */
  JMETHOD(void *, alloc_small, (j_common_ptr cinfo, int pool_id,
				size_t sizeofobject));
  JMETHOD(void FAR *, alloc_large, (j_common_ptr cinfo, int pool_id,
				     size_t sizeofobject));
  JMETHOD(JSAMPARRAY, alloc_sarray, (j_common_ptr cinfo, int pool_id,
				     JDIMENSION samplesperrow,
				     JDIMENSION numrows));
  JMETHOD(JBLOCKARRAY, alloc_barray, (j_common_ptr cinfo, int pool_id,
				      JDIMENSION blocksperrow,
				      JDIMENSION numrows));
  JMETHOD(jvirt_sarray_ptr, request_virt_sarray, (j_common_ptr cinfo,
						  int pool_id,
						  boolean pre_zero,
						  JDIMENSION samplesperrow,
						  JDIMENSION numrows,
						  JDIMENSION maxaccess));
  JMETHOD(jvirt_barray_ptr, request_virt_barray, (j_common_ptr cinfo,
						  int pool_id,
						  boolean pre_zero,
						  JDIMENSION blocksperrow,
						  JDIMENSION numrows,
						  JDIMENSION maxaccess));
  JMETHOD(void, realize_virt_arrays, (j_common_ptr cinfo));
  JMETHOD(JSAMPARRAY, access_virt_sarray, (j_common_ptr cinfo,
					   jvirt_sarray_ptr ptr,
					   JDIMENSION start_row,
					   JDIMENSION num_rows,
					   boolean writable));
  JMETHOD(JBLOCKARRAY, access_virt_barray, (j_common_ptr cinfo,
					    jvirt_barray_ptr ptr,
					    JDIMENSION start_row,
					    JDIMENSION num_rows,
					    boolean writable));
  JMETHOD(void, free_pool, (j_common_ptr cinfo, int pool_id));
  JMETHOD(void, self_destruct, (j_common_ptr cinfo));

  /* Limit on memory allocation for this JPEG object.  (Note that this is
   * merely advisory, not a guaranteed maximum; it only affects the space
   * used for virtual-array buffers.)  May be changed by outer application
   * after creating the JPEG object.
   */
  long max_memory_to_use;
};


/* Routine signature for application-supplied marker processing methods.
 * Need not pass marker code since it is stored in cinfo->unread_marker.
 */
typedef JMETHOD(boolean, jpeg_marker_parser_method, (j_decompress_ptr cinfo));


/* Declarations for routines called by application.
 * The JPP macro hides prototype parameters from compilers that can't cope.
 * Note JPP requires double parentheses.
 */

#ifdef HAVE_PROTOTYPES
#define JPP(arglist)	arglist
#else
#define JPP(arglist)	()
#endif


/* Short forms of external names for systems with poor linkers.
 * We shorten external names to be unique in the first six letters, which
 * is good enough for all known systems.
 * (If your compiler itself needs names to be unique in less than 15
 * characters, you are out of luck.  Get a better compiler.)
 */

#ifdef NEED_SHORT_EXTERNAL_NAMES
#define jpeg_std_error		jStdError
#define jpeg_CreateCompress	jCreaCompress
#define jpeg_CreateDecompress	jCreaDecompress
#define jpeg_destroy_compress	jDestCompress
#define jpeg_destroy_decompress	jDestDecompress
#define jpeg_stdio_dest		jStdDest
#define jpeg_stdio_src		jStdSrc
#define jpeg_set_defaults	jSetDefaults
#define jpeg_set_colorspace	jSetColorspace
#define jpeg_default_colorspace	jDefColorspace
#define jpeg_set_quality	jSetQuality
#define jpeg_set_linear_quality	jSetLQuality
#define jpeg_add_quant_table	jAddQuantTable
#define jpeg_quality_scaling	jQualityScaling
#define jpeg_simple_progression	jSimProgress
#define jpeg_suppress_tables	jSuppressTables
#define jpeg_alloc_quant_table	jAlcQTable
#define jpeg_alloc_huff_table	jAlcHTable
#define jpeg_start_compress	jStrtCompress
#define jpeg_write_scanlines	jWrtScanlines
#define jpeg_finish_compress	jFinCompress
#define jpeg_write_raw_data	jWrtRawData
#define jpeg_write_marker	jWrtMarker
#define jpeg_write_tables	jWrtTables
#define jpeg_read_header	jReadHeader
#define jpeg_start_decompress	jStrtDecompress
#define jpeg_read_scanlines	jReadScanlines
#define jpeg_finish_decompress	jFinDecompress
#define jpeg_read_raw_data	jReadRawData
#define jpeg_has_multiple_scans	jHasMultScn
#define jpeg_start_output	jStrtOutput
#define jpeg_finish_output	jFinOutput
#define jpeg_input_complete	jInComplete
#define jpeg_new_colormap	jNewCMap
#define jpeg_consume_input	jConsumeInput
#define jpeg_calc_output_dimensions	jCalcDimensions
#define jpeg_set_marker_processor	jSetMarker
#define jpeg_read_coefficients	jReadCoefs
#define jpeg_write_coefficients	jWrtCoefs
#define jpeg_copy_critical_parameters	jCopyCrit
#define jpeg_abort_compress	jAbrtCompress
#define jpeg_abort_decompress	jAbrtDecompress
#define jpeg_abort		jAbort
#define jpeg_destroy		jDestroy
#define jpeg_resync_to_restart	jResyncRestart
#endif /* NEED_SHORT_EXTERNAL_NAMES */


/* Default error-management setup */
EXTERN(struct jpeg_error_mgr *) jpeg_std_error
	JPP((struct jpeg_error_mgr * err));

/* Initialization of JPEG compression objects.
 * jpeg_create_compress() and jpeg_create_decompress() are the exported
 * names that applications should call.  These expand to calls on
 * jpeg_CreateCompress and jpeg_CreateDecompress with additional information
 * passed for version mismatch checking.
 * NB: you must set up the error-manager BEFORE calling jpeg_create_xxx.
 */
#define jpeg_create_compress(cinfo) \
    jpeg_CreateCompress((cinfo), JPEG_LIB_VERSION, \
			(size_t) sizeof(struct jpeg_compress_struct))
#define jpeg_create_decompress(cinfo) \
    jpeg_CreateDecompress((cinfo), JPEG_LIB_VERSION, \
			  (size_t) sizeof(struct jpeg_decompress_struct))
EXTERN(void) jpeg_CreateCompress JPP((j_compress_ptr cinfo,
				      int version, size_t structsize));
EXTERN(void) jpeg_CreateDecompress JPP((j_decompress_ptr cinfo,
					int version, size_t structsize));
/* Destruction of JPEG compression objects */
EXTERN(void) jpeg_destroy_compress JPP((j_compress_ptr cinfo));
EXTERN(void) jpeg_destroy_decompress JPP((j_decompress_ptr cinfo));

/* Standard data source and destination managers: stdio streams. */
/* Caller is responsible for opening the file before and closing after. */
EXTERN(void) jpeg_stdio_dest JPP((j_compress_ptr cinfo, FILE * outfile));
EXTERN(void) jpeg_stdio_src JPP((j_decompress_ptr cinfo, FILE * infile));

/* Default parameter setup for compression */
EXTERN(void) jpeg_set_defaults JPP((j_compress_ptr cinfo));
/* Compression parameter setup aids */
EXTERN(void) jpeg_set_colorspace JPP((j_compress_ptr cinfo,
				      J_COLOR_SPACE colorspace));
EXTERN(void) jpeg_default_colorspace JPP((j_compress_ptr cinfo));
EXTERN(void) jpeg_set_quality JPP((j_compress_ptr cinfo, int quality,
				   boolean force_baseline));
EXTERN(void) jpeg_set_linear_quality JPP((j_compress_ptr cinfo,
					  int scale_factor,
					  boolean force_baseline));
EXTERN(void) jpeg_add_quant_table JPP((j_compress_ptr cinfo, int which_tbl,
				       const unsigned int *basic_table,
				       int scale_factor,
				       boolean force_baseline));
EXTERN(int) jpeg_quality_scaling JPP((int quality));
EXTERN(void) jpeg_simple_progression JPP((j_compress_ptr cinfo));
EXTERN(void) jpeg_suppress_tables JPP((j_compress_ptr cinfo,
				       boolean suppress));
EXTERN(JQUANT_TBL *) jpeg_alloc_quant_table JPP((j_common_ptr cinfo));
EXTERN(JHUFF_TBL *) jpeg_alloc_huff_table JPP((j_common_ptr cinfo));

/* Main entry points for compression */
EXTERN(void) jpeg_start_compress JPP((j_compress_ptr cinfo,
				      boolean write_all_tables));
EXTERN(JDIMENSION) jpeg_write_scanlines JPP((j_compress_ptr cinfo,
					     JSAMPARRAY scanlines,
					     JDIMENSION num_lines));
EXTERN(void) jpeg_finish_compress JPP((j_compress_ptr cinfo));

/* Replaces jpeg_write_scanlines when writing raw downsampled data. */
EXTERN(JDIMENSION) jpeg_write_raw_data JPP((j_compress_ptr cinfo,
					    JSAMPIMAGE data,
					    JDIMENSION num_lines));

/* Write a special marker.  See libjpeg.doc concerning safe usage. */
EXTERN(void) jpeg_write_marker
	JPP((j_compress_ptr cinfo, int marker,
	     const JOCTET * dataptr, unsigned int datalen));

/* Alternate compression function: just write an abbreviated table file */
EXTERN(void) jpeg_write_tables JPP((j_compress_ptr cinfo));

/* Decompression startup: read start of JPEG datastream to see what's there */
EXTERN(int) jpeg_read_header JPP((j_decompress_ptr cinfo,
				  boolean require_image));
/* Return value is one of: */
#define JPEG_SUSPENDED		0 /* Suspended due to lack of input data */
#define JPEG_HEADER_OK		1 /* Found valid image datastream */
#define JPEG_HEADER_TABLES_ONLY	2 /* Found valid table-specs-only datastream */
/* If you pass require_image = TRUE (normal case), you need not check for
 * a TABLES_ONLY return code; an abbreviated file will cause an error exit.
 * JPEG_SUSPENDED is only possible if you use a data source module that can
 * give a suspension return (the stdio source module doesn't).
 */

/* Main entry points for decompression */
EXTERN(boolean) jpeg_start_decompress JPP((j_decompress_ptr cinfo));
EXTERN(JDIMENSION) jpeg_read_scanlines JPP((j_decompress_ptr cinfo,
					    JSAMPARRAY scanlines,
					    JDIMENSION max_lines));
EXTERN(boolean) jpeg_finish_decompress JPP((j_decompress_ptr cinfo));

/* Replaces jpeg_read_scanlines when reading raw downsampled data. */
EXTERN(JDIMENSION) jpeg_read_raw_data JPP((j_decompress_ptr cinfo,
					   JSAMPIMAGE data,
					   JDIMENSION max_lines));

/* Additional entry points for buffered-image mode. */
EXTERN(boolean) jpeg_has_multiple_scans JPP((j_decompress_ptr cinfo));
EXTERN(boolean) jpeg_start_output JPP((j_decompress_ptr cinfo,
				       int scan_number));
EXTERN(boolean) jpeg_finish_output JPP((j_decompress_ptr cinfo));
EXTERN(boolean) jpeg_input_complete JPP((j_decompress_ptr cinfo));
EXTERN(void) jpeg_new_colormap JPP((j_decompress_ptr cinfo));
EXTERN(int) jpeg_consume_input JPP((j_decompress_ptr cinfo));
/* Return value is one of: */
/* #define JPEG_SUSPENDED	0    Suspended due to lack of input data */
#define JPEG_REACHED_SOS	1 /* Reached start of new scan */
#define JPEG_REACHED_EOI	2 /* Reached end of image */
#define JPEG_ROW_COMPLETED	3 /* Completed one iMCU row */
#define JPEG_SCAN_COMPLETED	4 /* Completed last iMCU row of a scan */

/* Precalculate output dimensions for current decompression parameters. */
EXTERN(void) jpeg_calc_output_dimensions JPP((j_decompress_ptr cinfo));

/* Install a special processing method for COM or APPn markers. */
EXTERN(void) jpeg_set_marker_processor
	JPP((j_decompress_ptr cinfo, int marker_code,
	     jpeg_marker_parser_method routine));

/* Read or write raw DCT coefficients --- useful for lossless transcoding. */
EXTERN(jvirt_barray_ptr *) jpeg_read_coefficients JPP((j_decompress_ptr cinfo));
EXTERN(void) jpeg_write_coefficients JPP((j_compress_ptr cinfo,
					  jvirt_barray_ptr * coef_arrays));
EXTERN(void) jpeg_copy_critical_parameters JPP((j_decompress_ptr srcinfo,
						j_compress_ptr dstinfo));

/* If you choose to abort compression or decompression before completing
 * jpeg_finish_(de)compress, then you need to clean up to release memory,
 * temporary files, etc.  You can just call jpeg_destroy_(de)compress
 * if you're done with the JPEG object, but if you want to clean it up and
 * reuse it, call this:
 */
EXTERN(void) jpeg_abort_compress JPP((j_compress_ptr cinfo));
EXTERN(void) jpeg_abort_decompress JPP((j_decompress_ptr cinfo));

/* Generic versions of jpeg_abort and jpeg_destroy that work on either
 * flavor of JPEG object.  These may be more convenient in some places.
 */
EXTERN(void) jpeg_abort JPP((j_common_ptr cinfo));
EXTERN(void) jpeg_destroy JPP((j_common_ptr cinfo));

/* Default restart-marker-resync procedure for use by data source modules */
EXTERN(boolean) jpeg_resync_to_restart JPP((j_decompress_ptr cinfo,
					    int desired));


/* These marker codes are exported since applications and data source modules
 * are likely to want to use them.
 */

#define JPEG_RST0	0xD0	/* RST0 marker code */
#define JPEG_EOI	0xD9	/* EOI marker code */
#define JPEG_APP0	0xE0	/* APP0 marker code */
#define JPEG_COM	0xFE	/* COM marker code */


/* If we have a bad compiler that emits warnings (or worse, errors)
 * for structure definitions that are never filled in, keep it quiet by
 * supplying dummy definitions for the various substructures.
 */

#ifdef INCOMPLETE_TYPES_BROKEN
#ifndef JPEG_INTERNALS		/* will be defined in jpegint.h */
struct jvirt_sarray_control { long dummy; };
struct jvirt_barray_control { long dummy; };
struct jpeg_comp_master { long dummy; };
struct jpeg_c_main_controller { long dummy; };
struct jpeg_c_prep_controller { long dummy; };
struct jpeg_c_coef_controller { long dummy; };
struct jpeg_marker_writer { long dummy; };
struct jpeg_color_converter { long dummy; };
struct jpeg_downsampler { long dummy; };
struct jpeg_forward_dct { long dummy; };
struct jpeg_entropy_encoder { long dummy; };
struct jpeg_decomp_master { long dummy; };
struct jpeg_d_main_controller { long dummy; };
struct jpeg_d_coef_controller { long dummy; };
struct jpeg_d_post_controller { long dummy; };
struct jpeg_input_controller { long dummy; };
struct jpeg_marker_reader { long dummy; };
struct jpeg_entropy_decoder { long dummy; };
struct jpeg_inverse_dct { long dummy; };
struct jpeg_upsampler { long dummy; };
struct jpeg_color_deconverter { long dummy; };
struct jpeg_color_quantizer { long dummy; };
#endif /* JPEG_INTERNALS */
#endif /* INCOMPLETE_TYPES_BROKEN */


/*
 * The JPEG library modules define JPEG_INTERNALS before including this file.
 * The internal structure declarations are read only when that is true.
 * Applications using the library should not include jpegint.h, but may wish
 * to include jerror.h.
 */

#ifdef JPEG_INTERNALS
#include "jpegint.h"		/* fetch private declarations */
#include "jerror.h"		/* fetch error codes too */
#endif

#ifdef __cplusplus
};
#endif

#endif /* JPEGLIB_H */
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\analysis\dvranalysisutil\dvranalysisutil.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        dvrutil.cpp

    Abstract:

        This module the ts/dvr-wide utility code; compiles into a .LIB

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#include "dvrall.h"
#include "dvranalysis.h"
#include "dvranalysisutil.h"

HRESULT
CopyDVRAnalysisDescriptor (
    IN  LONG                    lCount,
    IN  DVR_ANALYSIS_DESC_INT * pDVRAnalysisDescIntMaster,
    OUT DVR_ANALYSIS_DESC **    ppDVRAnalysisDescCopy
    )
{
    HRESULT hr ;
    LONG    i ;

    ASSERT (lCount > 0) ;
    ASSERT (pDVRAnalysisDescIntMaster) ;
    ASSERT (ppDVRAnalysisDescCopy) ;

    hr = S_OK ;

    (* ppDVRAnalysisDescCopy) = reinterpret_cast <DVR_ANALYSIS_DESC *> (CoTaskMemAlloc (lCount * sizeof DVR_ANALYSIS_DESC)) ;

    if (* ppDVRAnalysisDescCopy) {
        for (i = 0; i < lCount; i++) {

            //  analysis GUID
            (* ppDVRAnalysisDescCopy) [i].guidAnalysis = (* pDVRAnalysisDescIntMaster [i].pguidAnalysis) ;

            //  descriptive string
            ASSERT (pDVRAnalysisDescIntMaster [i].pszDescription) ;
            (* ppDVRAnalysisDescCopy) [i].pszDescription = reinterpret_cast <LPWSTR> (
                CoTaskMemAlloc ((wcslen (pDVRAnalysisDescIntMaster [i].pszDescription) + 1) * sizeof WCHAR)
                ) ;
            if ((* ppDVRAnalysisDescCopy) [i].pszDescription) {
                wcscpy (
                    (* ppDVRAnalysisDescCopy) [i].pszDescription,
                    pDVRAnalysisDescIntMaster [i].pszDescription
                    ) ;
            }
            else {
                FreeDVRAnalysisDescriptor (
                    i,
                    (* ppDVRAnalysisDescCopy)
                    ) ;

                hr = E_OUTOFMEMORY ;

                break ;
            }
        }
    }
    else {
        hr = E_OUTOFMEMORY ;
    }

    return hr ;
}

void
FreeDVRAnalysisDescriptor (
    IN  LONG                    lCount,
    IN  DVR_ANALYSIS_DESC *     pDVRAnalysisDesc
    )
{
    LONG    i ;

    for (i = 0; i < lCount; i++) {
        CoTaskMemFree (pDVRAnalysisDesc [i].pszDescription) ;
    }

    CoTaskMemFree (pDVRAnalysisDesc) ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\analysis\dvranalysis\dvranalysishost.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        dvranalysishost.cpp

    Abstract:

        This module contains the dvranalysishost filter code.

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        19-Feb-2001     created

--*/

#include "dvrall.h"

#include "dvranalysis.h"            //  analysis CLSID & CF interface
#include "dvranalysisutil.h"
#include "dvranalysishost.h"


//  disable so we can use 'this' in the initializer list
#pragma warning (disable:4355)

//  ============================================================================

HRESULT
CreateDVRAnalysisHostFilter (
    IN  IUnknown *  punkOuter,
    IN  IUnknown *  punkAnalysisLogic,
    IN  REFCLSID    rCLSID,
    OUT CUnknown ** punkAnalysisFilterHost
    )
{
    HRESULT                 hr ;
    LPWSTR                  pszFilterName ;
    IDVRAnalysisLogicProp * pILogicProp ;
    CDVRAnalysis *          pAnalysisFilter ;

    ASSERT (punkAnalysisLogic) ;
    ASSERT (punkAnalysisFilterHost) ;

    (* punkAnalysisFilterHost) = NULL ;

    hr = punkAnalysisLogic -> QueryInterface (
                                IID_IDVRAnalysisLogicProp,
                                (void **) & pILogicProp
                                ) ;
    if (SUCCEEDED (hr)) {
        hr = pILogicProp -> GetDisplayName (& pszFilterName) ;
        if (SUCCEEDED (hr)) {

#ifdef UNICODE
            pAnalysisFilter = new CDVRAnalysis (
                                    pszFilterName,
                                    punkOuter,
                                    punkAnalysisLogic,
                                    rCLSID,
                                    & hr
                                    ) ;
#else
            //  BUGBUG: unicode only .. for now at least
            pAnalysisFilter = NULL ;
#endif

            if (pAnalysisFilter &&
                SUCCEEDED (hr)) {

                (* punkAnalysisFilterHost) = pAnalysisFilter ;
            }
            else {
                hr = (pAnalysisFilter ? hr : E_OUTOFMEMORY) ;
                delete pAnalysisFilter ;
            }

            CoTaskMemFree (pszFilterName) ;
        }

        pILogicProp -> Release () ;
    }

    return hr ;
}

//  ============================================================================

CDVRAnalysisBuffer::CDVRAnalysisBuffer (
    CDVRAnalysisBufferPool *    pOwningDVRPool
    ) : m_pIMediaSample         (NULL),
        m_pOwningDVRPool        (pOwningDVRPool),
        m_lRef                  (0),
        m_lLastIndexAttribute   (UNDEFINED)
{
    TRACE_CONSTRUCTOR (TEXT ("CDVRAnalysisBuffer")) ;

    ASSERT (pOwningDVRPool) ;

    InitializeCriticalSection (& m_crt) ;
}

CDVRAnalysisBuffer::~CDVRAnalysisBuffer (
    )
{
    TRACE_DESTRUCTOR (TEXT ("CDVRAnalysisBuffer")) ;

    DeleteCriticalSection (& m_crt) ;

    RELEASE_AND_CLEAR (m_pIMediaSample) ;
}

STDMETHODIMP_ (ULONG)
CDVRAnalysisBuffer::AddRef (
    )
{
    O_TRACE_ENTER_0 (TEXT ("CDVRAnalysisBuffer::AddRef ()")) ;

    return InterlockedIncrement (& m_lRef) ;
}

STDMETHODIMP_ (ULONG)
CDVRAnalysisBuffer::Release (
    )
{
    LONG    lRef ;

    O_TRACE_ENTER_0 (TEXT ("CDVRAnalysisBuffer::Release ()")) ;

    lRef = InterlockedDecrement (& m_lRef) ;

    if (lRef == 0) {
        Reset () ;
        m_pOwningDVRPool -> Recycle (this) ;
        return 0 ;
    }

    return m_lRef ;
}

STDMETHODIMP
CDVRAnalysisBuffer::QueryInterface (
    IN  REFIID  riid,
    IN  void ** ppv
    )
{
    O_TRACE_ENTER_0 (TEXT ("CDVRAnalysisBuffer::QueryInterface ()")) ;

    if (!ppv) {
        return E_POINTER ;
    }

    if (riid == IID_IUnknown) {
        (* ppv) = static_cast <IUnknown *> (this) ;
    }
    else if (riid == IID_IDVRAnalysisBuffer) {
        (* ppv) = static_cast <IDVRAnalysisBuffer *> (this) ;
    }
    else if (riid == IID_IDVRAnalysisBufferPriv) {
        (* ppv) = static_cast <IDVRAnalysisBufferPriv *> (this) ;
    }
    else {
        return E_NOINTERFACE ;
    }

    reinterpret_cast <IUnknown *> (* ppv) -> AddRef () ;

    return S_OK ;
}

HRESULT
CDVRAnalysisBuffer::GetBuffer (
    OUT BYTE ** ppbBuffer
    )
{
    HRESULT hr ;

    if (!ppbBuffer) {
        return E_POINTER ;
    }

    Lock_ () ;

    if (m_pIMediaSample) {
        (* ppbBuffer) = m_pbMediaSampleBuffer ;
        hr = S_OK ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

HRESULT
CDVRAnalysisBuffer::GetBufferLength (
    IN  LONG *  plBufferLen
    )
{
    HRESULT hr ;

    if (!plBufferLen) {
        return E_POINTER ;
    }

    Lock_ () ;

    if (m_pIMediaSample) {
        (* plBufferLen) = m_lMediaSampleBufferLength ;
        hr = S_OK ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

void
CDVRAnalysisBuffer::ClearDuplicateAttributes_ (
    IN  REFGUID rguid,
    IN  LONG    lOffset
    )
{
    ANALYSIS_RESULT *   pInListResult ;
    DWORD               dw ;

    //  from the start of the list
    dw = m_AnalysisResultList.SetPointer (0) ;
    while (dw == NOERROR) {
        dw = m_AnalysisResultList.GetCur (& pInListResult) ;
        if (dw == NOERROR) {
            ASSERT (pInListResult) ;
            if (pInListResult -> lOffset > lOffset) {
                //  gone beyond; break
                break ;
            }
            else if (pInListResult -> lOffset == lOffset &&
                     pInListResult -> DVRAttribute.IsEqual (rguid)) {

                TRACE_1 (LOG_AREA_DVRANALYSIS, 5,
                    TEXT ("CDVRAnalysisBuffer::ClearDuplicateAttributes_ (); clearing duplicate attribute %d offset"),
                    lOffset) ;

                //  same offset; same guid; pop and recycle
                m_AnalysisResultList.PopCur () ;    //  advances implicitely
                Recycle (pInListResult) ;
            }
            else {
                //  less than, or of different guid
                //  advance explicitely
                dw = m_AnalysisResultList.Advance () ;
            }
        }
    }
}

HRESULT
CDVRAnalysisBuffer::Mark (
    IN  LONG            lBufferOffset,
    IN  const GUID *    pguidAttribute,
    IN  BYTE *          pbAttributeData,
    IN  DWORD           dwAttributeDataLen
    )
{
    ANALYSIS_RESULT *   pAnalysisResult ;
    HRESULT             hr ;
    DWORD               dw ;

    if (lBufferOffset >= m_lMediaSampleBufferLength ||
        !pguidAttribute) {

        return E_INVALIDARG ;
    }

    TRACE_2 (LOG_AREA_DVRANALYSIS, 7,
        TEXT ("CDVRAnalysisBuffer::Mark (); %d offset, %d size attribute"),
        lBufferOffset, dwAttributeDataLen) ;

    Lock_ () ;

    pAnalysisResult = Get () ;
    if (pAnalysisResult) {

        pAnalysisResult -> lOffset = lBufferOffset ;

        hr = pAnalysisResult -> DVRAttribute.SetAttributeData (
                (* pguidAttribute),
                pbAttributeData,
                dwAttributeDataLen
                ) ;
        if (SUCCEEDED (hr)) {

            ClearDuplicateAttributes_ (
                (* pguidAttribute),
                lBufferOffset
                ) ;

            dw = m_AnalysisResultList.Insert (
                    pAnalysisResult,
                    pAnalysisResult -> lOffset
                    ) ;
            if (dw == NOERROR) {
                hr = S_OK ;
            }
            else {
                hr = HRESULT_FROM_WIN32 (dw) ;
            }
        }

        //  any failures - recycle
        if (FAILED (hr)) {
            Recycle (pAnalysisResult) ;
        }
    }
    else {
        hr = E_OUTOFMEMORY ;
    }

    Unlock_ () ;

    return hr ;
}

HRESULT
CDVRAnalysisBuffer::GetAttribute (
    IN      LONG    lIndex,
    OUT     LONG *  plBufferOffset,
    OUT     GUID *  pguidAttribute,
    IN OUT  BYTE *  pbAttributeData,
    OUT     DWORD * pdwAttributeDataLen
    )
{
    ANALYSIS_RESULT *   pAnalysisResult ;
    DWORD               dw ;
    LONG                i ;
    HRESULT             hr ;

    //  we're the caller so these better be valid
    ASSERT (plBufferOffset) ;
    ASSERT (pguidAttribute) ;

    Lock_ () ;

    //  position
    if (m_lLastIndexAttribute != UNDEFINED &&
        m_lLastIndexAttribute < lIndex) {

        for (i = 0, dw = NOERROR;
             dw == NOERROR && i < lIndex - m_lLastIndexAttribute;
             i++) {
            dw = m_AnalysisResultList.Advance () ;
        }
    }
    else {
        dw = m_AnalysisResultList.SetPointer (lIndex) ;
    }

    //  and retrieve
    if (dw == NOERROR) {
        m_lLastIndexAttribute = lIndex ;

        dw = m_AnalysisResultList.GetCur (& pAnalysisResult) ;
        if (dw == NOERROR) {
            //  set the offset
            (* plBufferOffset) = pAnalysisResult -> lOffset ;

            //  data is valid until the analysis buffer is recycled, so we can
            //   set pointers directly vs. making copies
            hr = pAnalysisResult -> DVRAttribute.GetAttributeData (
                    pguidAttribute,
                    pbAttributeData,
                    pdwAttributeDataLen
                    ) ;

            ASSERT (m_pIMediaSample) ;
            ASSERT (pAnalysisResult -> lOffset < m_lMediaSampleBufferLength) ;
        }
        else {
            //  error
            hr = HRESULT_FROM_WIN32 (dw) ;
        }
    }
    else {
        //  error
        hr = HRESULT_FROM_WIN32 (dw) ;
    }

    Unlock_ () ;

    return hr ;
}

void
CDVRAnalysisBuffer::SetMediaSample (
    IN  IMediaSample *  pIMS
    )
{
    Lock_ () ;

    Reset () ;

    if (pIMS) {
        m_pIMediaSample = pIMS ;
        m_pIMediaSample -> AddRef () ;

        m_lMediaSampleBufferLength = m_pIMediaSample -> GetActualDataLength () ;
        m_pIMediaSample -> GetPointer (& m_pbMediaSampleBuffer) ;
    }

    Unlock_ () ;

    return ;
}

HRESULT
CDVRAnalysisBuffer::IsDiscontinuity (
    OUT BOOL *  pfDiscontinuity
    )
{
    HRESULT hr ;

    if (!pfDiscontinuity) {
        return E_POINTER ;
    }

    Lock_ () ;

    if (m_pIMediaSample) {
        (* pfDiscontinuity) = (m_pIMediaSample -> IsDiscontinuity () == S_OK ? TRUE : FALSE) ;
        hr = S_OK ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

void
CDVRAnalysisBuffer::Reset (
    )
{
    ANALYSIS_RESULT *   pAnalysisResult ;
    DWORD               dw ;

    Lock_ () ;

    dw = m_AnalysisResultList.SetPointer (0) ;
    while (dw == NOERROR) {
        dw = m_AnalysisResultList.GetCur (& pAnalysisResult) ;
        if (dw == NOERROR) {
            Recycle (pAnalysisResult) ;

            dw = m_AnalysisResultList.PopCur () ;
        }
    }

    m_lLastIndexAttribute = UNDEFINED ;

    RELEASE_AND_CLEAR (m_pIMediaSample) ;

    m_pbMediaSampleBuffer       = NULL ;
    m_lMediaSampleBufferLength  = 0 ;

    Unlock_ () ;
}

STDMETHODIMP
CDVRAnalysisBuffer::GetWrappedMediaSample (
    OUT IMediaSample ** ppIMS
    )
{
    HRESULT hr ;

    ASSERT (ppIMS) ;

    Lock_ () ;

    if (m_pIMediaSample) {
        (* ppIMS) = m_pIMediaSample ;
        (* ppIMS) -> AddRef () ;

        hr = S_OK ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

//  ============================================================================

CDVRAnalysisBufferPool::CDVRAnalysisBufferPool (
    )
{
}

CDVRAnalysisBufferPool::~CDVRAnalysisBufferPool (
    )
{
    CDVRAnalysisBuffer *    pDVRBuffer ;
    DWORD                   dw ;

    for (;;) {
        dw = m_DVRBufferPool.TryPop (& pDVRBuffer) ;
        if (dw == NOERROR) {
            ASSERT (pDVRBuffer) ;
            delete pDVRBuffer ;
        }
        else {
            break ;
        }
    }
}

CDVRAnalysisBuffer *
CDVRAnalysisBufferPool::Get (
    )
{
    CDVRAnalysisBuffer *    pDVRBuffer ;
    DWORD                   dw ;

    dw = m_DVRBufferPool.TryPop (& pDVRBuffer) ;
    if (dw == NOERROR) {
        ASSERT (pDVRBuffer) ;
        pDVRBuffer -> AddRef () ;
    }
    else {
        pDVRBuffer = new CDVRAnalysisBuffer (this) ;
        if (pDVRBuffer) {
            pDVRBuffer -> AddRef () ;
        }
    }

    return pDVRBuffer ;
}

void
CDVRAnalysisBufferPool::Recycle (
    IN  CDVRAnalysisBuffer *    pDVRBuffer
    )
{
    DWORD   dw ;

    dw = m_DVRBufferPool.Push (pDVRBuffer) ;
    if (dw != NOERROR) {
        delete pDVRBuffer ;
    }
}

//  ============================================================================

CDVRAnalysisInput::CDVRAnalysisInput (
    IN  TCHAR *         pszPinName,
    IN  CDVRAnalysis *  pAnalysisFilter,
    IN  CCritSec *      pFilterLock,
    OUT HRESULT *       phr
    ) : CBaseInputPin       (NAME ("CDVRAnalysisInput"),
                             pAnalysisFilter,
                             pFilterLock,
                             phr,
                             pszPinName
                             ),
    m_pHostAnalysisFilter   (pAnalysisFilter)
{
    TRACE_CONSTRUCTOR (TEXT ("CDVRAnalysisInput")) ;
}

HRESULT
CDVRAnalysisInput::CheckMediaType (
    IN  const CMediaType *  pmt
    )
{
    BOOL    f ;

    FilterLock_ () ;

    f = m_pHostAnalysisFilter -> CheckAnalysisMediaType (m_dir, pmt) ;

    FilterUnlock_ () ;

    return (f ? S_OK : S_FALSE) ;
}

HRESULT
CDVRAnalysisInput::CompleteConnect (
    IN  IPin *  pIPin
    )
{
    HRESULT hr ;

    hr = CBaseInputPin::CompleteConnect (pIPin) ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostAnalysisFilter -> OnCompleteConnect (m_dir) ;
    }

    return hr ;
}

HRESULT
CDVRAnalysisInput::BreakConnect (
    )
{
    HRESULT hr ;

    hr = CBaseInputPin::BreakConnect () ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostAnalysisFilter -> OnBreakConnect (m_dir) ;
    }

    return hr ;
}

HRESULT
CDVRAnalysisInput::SetAllocatorProperties (
    IN  ALLOCATOR_PROPERTIES *  ppropInputRequest
    )
{
    HRESULT hr ;

    if (IsConnected ()) {
        ASSERT (m_pAllocator) ;
        hr = m_pAllocator -> GetProperties (ppropInputRequest) ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

STDMETHODIMP
CDVRAnalysisInput::Receive (
    IN  IMediaSample * pIMediaSample
    )
{
    HRESULT hr ;

#ifdef EHOME_WMI_INSTRUMENTATION
    PERFLOG_STREAMTRACE( 1, PERFINFO_STREAMTRACE_SBE_DVRANALYSISINPUT_RECEIVE,
        0, 0, 0, 0, 0 );
#endif
    hr = CBaseInputPin::Receive (pIMediaSample) ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostAnalysisFilter -> Process (pIMediaSample) ;
    }

    return hr ;
}

HRESULT
CDVRAnalysisInput::GetRefdConnectionAllocator (
    OUT IMemAllocator **    ppAlloc
    )
{
    HRESULT hr ;

    if (m_pAllocator) {
        (* ppAlloc) = m_pAllocator ;
        (* ppAlloc) -> AddRef () ;

        hr = S_OK ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

STDMETHODIMP
CDVRAnalysisInput::BeginFlush (
    )
{
    HRESULT hr ;

    hr = CBaseInputPin::BeginFlush () ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostAnalysisFilter -> DeliverBeginFlush () ;
    }

    return hr ;
}

STDMETHODIMP
CDVRAnalysisInput::EndFlush (
    )
{
    HRESULT hr ;

    hr = CBaseInputPin::EndFlush () ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostAnalysisFilter -> DeliverEndFlush () ;
    }

    return hr ;
}

//  ============================================================================

CDVRAnalysisOutput::CDVRAnalysisOutput (
    IN  TCHAR *         pszPinName,
    IN  CDVRAnalysis *  pAnalysisFilter,
    IN  CCritSec *      pFilterLock,
    OUT HRESULT *       phr
    ) : CBaseOutputPin      (NAME ("CDVRAnalysisOutput"),
                             pAnalysisFilter,
                             pFilterLock,
                             phr,
                             pszPinName
                             ),
    m_pHostAnalysisFilter   (pAnalysisFilter)
{
    TRACE_CONSTRUCTOR (TEXT ("CDVRAnalysisOutput")) ;
}

HRESULT
CDVRAnalysisOutput::DecideBufferSize (
    IN  IMemAllocator *         pAlloc,
    IN  ALLOCATOR_PROPERTIES *  ppropInputRequest
    )
{
    HRESULT hr ;

    hr = m_pHostAnalysisFilter -> UpdateAllocatorProperties (
            ppropInputRequest
            ) ;

    return hr ;
}

HRESULT
CDVRAnalysisOutput::GetMediaType (
    IN  int             iPosition,
    OUT CMediaType *    pmt
    )
{
    HRESULT hr ;

    FilterLock_ () ;

    if (iPosition == 0) {
        hr = m_pHostAnalysisFilter -> OnOutputGetMediaType (pmt) ;
    }
    else {
        hr = VFW_S_NO_MORE_ITEMS ;
    }

    FilterUnlock_ () ;

    return hr ;
}

HRESULT
CDVRAnalysisOutput::CheckMediaType (
    IN  const CMediaType *  pmt
    )
{
    BOOL    f ;

    FilterLock_ () ;

    f = m_pHostAnalysisFilter -> CheckAnalysisMediaType (m_dir, pmt) ;

    FilterUnlock_ () ;

    return (f ? S_OK : S_FALSE) ;
}

HRESULT
CDVRAnalysisOutput::CompleteConnect (
    IN  IPin *  pIPin
    )
{
    HRESULT hr ;

    hr = CBaseOutputPin::CompleteConnect (pIPin) ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostAnalysisFilter -> OnCompleteConnect (m_dir) ;
    }

    return hr ;
}

HRESULT
CDVRAnalysisOutput::BreakConnect (
    )
{
    HRESULT hr ;

    hr = CBaseOutputPin::BreakConnect () ;
    if (SUCCEEDED (hr)) {
        hr = m_pHostAnalysisFilter -> OnBreakConnect (m_dir) ;
    }

    return hr ;
}

HRESULT
CDVRAnalysisOutput::DecideAllocator (
    IN  IMemInputPin *      pPin,
    IN  IMemAllocator **    ppAlloc
    )
{
    HRESULT hr ;

    hr = m_pHostAnalysisFilter -> GetRefdInputAllocator (ppAlloc) ;
    if (SUCCEEDED (hr)) {
        //  input pin must be connected i.e. have an allocator; preserve
        //   all properties and pass them through to the output
        hr = pPin -> NotifyAllocator ((* ppAlloc), FALSE) ;
    }

    return hr ;
}

HRESULT
CDVRAnalysisOutput::SendSample (
    IN  IMediaSample *  pIMS
    )
{
    HRESULT hr ;

    ASSERT (pIMS) ;

#if 0
    REFERENCE_TIME  rtStart ;
    REFERENCE_TIME  rtStop ;
    LONGLONG        llStart ;
    LONGLONG        llStop ;

    TRACE_2 (TEXT ("-------- %08xh %d"), pIMS, pIMS -> GetActualDataLength ()) ;

    hr = pIMS -> GetTime (& rtStart, & rtStop) ;
    if (SUCCEEDED (hr)) {
        TRACE_2 (TEXT ("start/stop %I64016x %I64016x"), rtStart, rtStop) ;
    }
    else {
        TRACE_0 (TEXT ("start/stop ")) ;
    }

    hr = pIMS -> GetMediaTime (& llStart, & llStop) ;
    if (SUCCEEDED (hr)) {
    }
    else {
    }
#endif

#ifdef EHOME_WMI_INSTRUMENTATION
    PERFLOG_STREAMTRACE( 1, PERFINFO_STREAMTRACE_SBE_DVRANALYSISINPUT_DELIVER,
        0, 0, 0, 0, 0 );
#endif
    hr = Deliver (pIMS) ;

    return hr ;
}

STDMETHODIMP
CDVRAnalysisOutput::GetAnalysisLogic (
    OUT IDVRAnalyze **  ppIDVRAnalyze
    )
{
    if (!ppIDVRAnalyze) {
        return E_POINTER ;
    }

    return E_NOTIMPL ;
}

STDMETHODIMP
CDVRAnalysisOutput::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    OUT void ** ppv
    )
{
    //  ------------------------------------------------------------------------
    //  IDVRAnalysisConfig; allows the shell to be configured from the sink

    if (riid == IID_IDVRAnalysisConfig) {

        return GetInterface (
                    (IDVRAnalysisConfig *) this,
                    ppv
                    ) ;
    }

    return CBaseOutputPin::NonDelegatingQueryInterface (riid, ppv) ;
}

//  ============================================================================

CDVRAnalysis::CDVRAnalysis (
    IN  TCHAR *     pszFilterName,
    IN  IUnknown *  punkControlling,
    IN  IUnknown *  punkAnalysisLogic,
    IN  REFCLSID    rCLSID,
    OUT HRESULT *   phr
    ) : CBaseFilter             (pszFilterName,
                                 punkControlling,
                                 new CCritSec,
                                 rCLSID
                                ),
        m_pInputPin             (NULL),
        m_pOutputPin            (NULL),
        m_pIDVRAnalysisProp     (NULL),
        m_pIDVRAnalyze          (NULL),
        m_pAnalysisTagger       (NULL)
{
    DVR_ANALYSIS_DESC * pAnalysisDesc ;
    LONG                lAnalysisDescCount ;
    LONG                i ;

    TRACE_CONSTRUCTOR (TEXT ("CDVRAnalysis")) ;

    if (!m_pLock) {
        (* phr) = E_OUTOFMEMORY ;
        goto cleanup ;
    }

    m_pInputPin = new CDVRAnalysisInput (
                        TEXT ("in"),
                        this,
                        m_pLock,
                        phr
                        ) ;
    if (!m_pInputPin ||
        FAILED (* phr)) {

        (* phr) = (m_pInputPin ? (* phr) : E_OUTOFMEMORY) ;
        goto cleanup ;
    }

    m_pOutputPin = new CDVRAnalysisOutput (
                        TEXT ("out"),
                        this,
                        m_pLock,
                        phr
                        ) ;
    if (!m_pOutputPin ||
        FAILED (* phr)) {

        (* phr) = (m_pOutputPin ? (* phr) : E_OUTOFMEMORY) ;
        goto cleanup ;
    }

    (* phr) = punkAnalysisLogic -> QueryInterface (
                    IID_IDVRAnalysisLogicProp,
                    (void **) & m_pIDVRAnalysisProp
                    ) ;
    if (FAILED (* phr)) { goto cleanup ; }

    (* phr) = m_pIDVRAnalysisProp -> EnumAnalysis (
                & lAnalysisDescCount,
                & pAnalysisDesc
                ) ;
    if (SUCCEEDED (* phr)) {
        for (i = 0; i < lAnalysisDescCount && m_pAnalysisTagger == NULL; i++) {
            m_pAnalysisTagger = GetAnalysisTagger (pAnalysisDesc [i].guidAnalysis) ;
        }

        FreeDVRAnalysisDescriptor (lAnalysisDescCount, pAnalysisDesc) ;
    }

    if (m_pAnalysisTagger == NULL) { (* phr) = E_FAIL ; goto cleanup ; }


    (* phr) = m_pIDVRAnalysisProp -> SetPostAnalysisSend (this) ;
    if (FAILED (* phr)) { goto cleanup ; }

    (* phr) = punkAnalysisLogic -> QueryInterface (
                    IID_IDVRAnalyze,
                    (void **) & m_pIDVRAnalyze
                    ) ;
    if (FAILED (* phr)) { goto cleanup ; }

    //  success
    ASSERT (SUCCEEDED (* phr)) ;
    ASSERT (m_pInputPin) ;
    ASSERT (m_pOutputPin) ;
    ASSERT (m_pIDVRAnalysisProp) ;
    ASSERT (m_pIDVRAnalyze) ;

    cleanup :

    return ;
}

CDVRAnalysis::~CDVRAnalysis (
    )
{
    RELEASE_AND_CLEAR (m_pIDVRAnalysisProp) ;
    RELEASE_AND_CLEAR (m_pIDVRAnalyze) ;

    RecycleAnalysisTagger (m_pAnalysisTagger) ;

    delete m_pInputPin ;
    delete m_pOutputPin ;
}

int
CDVRAnalysis::GetPinCount (
    )
{
    int i ;

    Lock_ () ;

    //  don't show the output pin if the input pin is not connected
    i = (m_pInputPin -> IsConnected () ? 2 : 1) ;

    Unlock_ () ;

    return i ;
}

CBasePin *
CDVRAnalysis::GetPin (
    IN  int iIndex
    )
{
    CBasePin *  pPin ;

    Lock_ () ;

    if (iIndex == 0) {
        pPin = m_pInputPin ;
    }
    else if (iIndex == 1) {
        pPin = (m_pInputPin -> IsConnected () ? m_pOutputPin : NULL) ;
    }
    else {
        pPin = NULL ;
    }

    Unlock_ () ;

    return pPin ;
}

BOOL
CDVRAnalysis::CompareConnectionMediaType_ (
    IN  const AM_MEDIA_TYPE *   pmt,
    IN  CBasePin *              pPin
    )
{
    BOOL        f ;
    HRESULT     hr ;
    CMediaType  cmtConnection ;
    CMediaType  cmtCompare ;

    ASSERT (pPin -> IsConnected ()) ;

    hr = pPin -> ConnectionMediaType (& cmtConnection) ;
    if (SUCCEEDED (hr)) {
        cmtCompare = (* pmt) ;
        f = (cmtConnection == cmtCompare ? TRUE : FALSE) ;
    }
    else {
        f = FALSE ;
    }

    return f ;
}

BOOL
CDVRAnalysis::CheckInputMediaType_ (
    IN  const AM_MEDIA_TYPE *   pmt
    )
{
    BOOL    f ;
    HRESULT hr ;

    if (!m_pOutputPin -> IsConnected ()) {
        hr = m_pIDVRAnalysisProp -> CheckMediaType (pmt, & f) ;
        if (FAILED (hr)) {
            f = FALSE ;
        }
    }
    else {
        f = CompareConnectionMediaType_ (pmt, m_pOutputPin) ;
    }

    return f ;
}

BOOL
CDVRAnalysis::CheckOutputMediaType_ (
    IN  const AM_MEDIA_TYPE *   pmt
    )
{
    BOOL    f ;
    HRESULT hr ;

    Lock_ () ;

    if (m_pInputPin -> IsConnected ()) {
        f = CompareConnectionMediaType_ (pmt, m_pInputPin) ;
    }
    else {
        f = FALSE ;
    }

    Unlock_ () ;

    return f ;
}

BOOL
CDVRAnalysis::CheckAnalysisMediaType (
    IN  PIN_DIRECTION       PinDir,
    IN  const CMediaType *  pmt
    )
{
    BOOL    f ;

    //  both pins must have identical media types, so we check with the pin that
    //   is not calling; if it's connected, we measure against the connection's
    //   media type

    if (PinDir == PINDIR_INPUT) {
        f = CheckInputMediaType_ (pmt) ;
    }
    else {
        ASSERT (PinDir == PINDIR_OUTPUT) ;
        f = CheckOutputMediaType_ (pmt) ;
    }

    return f ;
}

STDMETHODIMP
CDVRAnalysis::Pause (
    )
{
    HRESULT                 hr ;
    ALLOCATOR_PROPERTIES    AllocProp ;

    O_TRACE_ENTER_0 (TEXT("CDVRAnalysis::Pause ()")) ;

    Lock_ () ;

    if (m_State == State_Stopped) {
        hr = CBaseFilter::Pause () ;
        if (SUCCEEDED (hr)) {
            hr = m_pInputPin -> SetAllocatorProperties (& AllocProp) ;
            if (SUCCEEDED (hr)) {
                m_MSWrappers.SetMaxAllocate (AllocProp.cBuffers) ;
            }
            else {
                //  don't fail if the input is not connected
                hr = (m_pInputPin -> IsConnected () ? hr : S_OK) ;
            }
        }
    } else {
        m_State = State_Paused ;

        hr = S_OK ;
    }

    Unlock_ () ;

    return hr ;
}

HRESULT
CDVRAnalysis::Process (
    IN  IMediaSample *  pIMediaSample
    )
{
    CDVRAnalysisBuffer *    pDVRBuffer ;
    HRESULT                 hr ;

    pDVRBuffer = m_DVRBuffers.Get () ;
    if (pDVRBuffer) {
        //  DVRBuffer is ref'd by m_DVRBuffers before return

        pDVRBuffer -> SetMediaSample (
            pIMediaSample
            ) ;

        hr = m_pIDVRAnalyze -> Analyze (
                pDVRBuffer,
                pIMediaSample -> IsDiscontinuity () == S_OK ? TRUE : FALSE
                ) ;

        pDVRBuffer -> Release () ;
    }
    else {
        hr = E_OUTOFMEMORY ;
    }

    return hr ;
}

HRESULT
CDVRAnalysis::WrapAndSend_ (
    IN  IMediaSample *          pIMSCore,
    IN  BYTE *                  pbBuffer,
    IN  LONG                    lBufferLen,
    IN  CMediaSampleWrapper *   pMSWrapper
    )
{
    HRESULT hr ;

    //  wrap for the send
    hr = pMSWrapper -> Wrap (
            pIMSCore,
            pbBuffer,
            lBufferLen
            ) ;
    if (SUCCEEDED (hr)) {
        hr = m_pOutputPin -> SendSample (pMSWrapper) ;

        TRACE_1 (LOG_AREA_DVRANALYSIS, 8,
            TEXT ("CDVRAnalysis::WrapAndSend_; %d bytes"),
            pMSWrapper -> GetActualDataLength ()) ;
    }

    return hr ;
}

HRESULT
CDVRAnalysis::CompleteAnalysis (
    IN  IDVRAnalysisBuffer *    pIOwningAnalysisBuffer
    )
{
    CMediaSampleWrapper *       pMSWrapper ;
    IDVRAnalysisBufferPriv *    pIDVRBufferPriv ;
    IMediaSample *              pICoreMediaSample ;
    HRESULT                     hr ;
    LONG                        lIndex ;
    LONG                        lAttribCoreBufferOffset ;       //  core buffer attrib offset
    LONG                        lLastSentCoreBufferOffset ;     //  last wrapped ms sent core buffer offset
    GUID                        guidAttribute ;
    BYTE *                      pbCoreBuffer ;
    LONG                        lCoreBufferLength ;
    DWORD                       dw ;
    DWORD                       dwDVRAttribLen ;

    ASSERT (m_pAnalysisTagger) ;

    hr = pIOwningAnalysisBuffer -> QueryInterface (
            IID_IDVRAnalysisBufferPriv,
            (void **) & pIDVRBufferPriv
            ) ;
    if (FAILED (hr)) {
        return hr ;
    }

    pMSWrapper          = NULL ;
    pICoreMediaSample   = NULL ;

    hr = pIDVRBufferPriv -> GetWrappedMediaSample (& pICoreMediaSample) ;
    if (SUCCEEDED (hr)) {

        ASSERT (pIDVRBufferPriv) ;

        //  initialize our local variables
        lLastSentCoreBufferOffset   = 0 ;                                   //  start at offset 0
        lCoreBufferLength   = pICoreMediaSample -> GetActualDataLength () ; //  get the length
        pICoreMediaSample -> GetPointer (& pbCoreBuffer) ;                  //  and core pointer

        //  get first wrapper
        pMSWrapper = m_MSWrappers.Get () ;
        if (!pMSWrapper) {
            hr = E_OUTOFMEMORY ;
            goto cleanup ;
        }

        //  cannot wrap -- we don't know how long it will be, but we do
        //    know that it will be aligned with the first byte of the
        //    buffer, so we transfer the standard goop over now
        hr = m_pAnalysisTagger -> Transfer (
                pICoreMediaSample,
                pMSWrapper
                ) ;
        if (FAILED (hr)) {
            pMSWrapper -> Release () ;
            goto cleanup ;
        }

        TRACE_1 (LOG_AREA_DVRANALYSIS, 7,
            TEXT ("analyzed DVRAnalysisBuffer received; core media sample length = %d"),
            lCoreBufferLength) ;

        //  wrapper now has the flags etc.. of the core MS, but there's no
        //  link between the two yet
        for (lIndex = 0; SUCCEEDED (hr); lIndex++) {
            hr = pIDVRBufferPriv -> GetAttribute (
                    lIndex,
                    & lAttribCoreBufferOffset,
                    & guidAttribute,
                    NULL,
                    & dwDVRAttribLen
                    ) ;

            if (SUCCEEDED (hr)) {

                //  make sure we have enough to retrieve the attribute in
                dw = m_RatchetBuffer.SetMinLen (dwDVRAttribLen) ;
                if (dw != NOERROR) {
                    hr = HRESULT_FROM_WIN32 (dw) ;
                    goto cleanup ;
                }

                ASSERT (m_RatchetBuffer.GetBufferLength () >= dwDVRAttribLen) ;

                //  retrieve
                hr = pIDVRBufferPriv -> GetAttribute (
                        lIndex,
                        & lAttribCoreBufferOffset,
                        & guidAttribute,
                        m_RatchetBuffer.Buffer (),
                        & dwDVRAttribLen
                        ) ;
                ASSERT (SUCCEEDED (hr)) ;       //  succeeded above

                if (lAttribCoreBufferOffset > lLastSentCoreBufferOffset) {
                    //  wrap and send
                    hr = WrapAndSend_ (
                            pICoreMediaSample,                                      //  media sample
                            pbCoreBuffer + lLastSentCoreBufferOffset,               //  buffer (end of last sent)
                            lAttribCoreBufferOffset - lLastSentCoreBufferOffset,    //  length (since last)
                            pMSWrapper
                            ) ;

                    TRACE_3 (LOG_AREA_DVRANALYSIS, 7,
                        TEXT ("(%08xh) media sample fragmented; %d -> %d"),
                        pICoreMediaSample, lLastSentCoreBufferOffset,
                        lLastSentCoreBufferOffset + lAttribCoreBufferOffset - lLastSentCoreBufferOffset) ;

                    //  done with the wrapper regardless
                    RELEASE_AND_CLEAR (pMSWrapper) ;

                    //  if anything failed, bail
                    if (FAILED (hr)) { goto cleanup ; }

                    //  last buffer offset updated
                    lLastSentCoreBufferOffset = lAttribCoreBufferOffset ;

                    //  get the next wrapper
                    pMSWrapper = m_MSWrappers.Get () ;
                    if (!pMSWrapper) {
                        hr = E_OUTOFMEMORY ;
                        goto cleanup ;
                    }
                }

                hr = m_pAnalysisTagger -> Mark (
                        pMSWrapper,
                        & guidAttribute,
                        m_RatchetBuffer.Buffer (),
                        dwDVRAttribLen
                        ) ;

                TRACE_3 (LOG_AREA_DVRANALYSIS, 7,
                    TEXT ("attribute recovered: %d bytes at offset %d; Mark retval = %08xh"),
                    dwDVRAttribLen, lAttribCoreBufferOffset, hr) ;

                if (FAILED (hr)) { goto cleanup ; }
            }
        }

        hr = WrapAndSend_ (
                pICoreMediaSample,                              //  media sample
                pbCoreBuffer + lLastSentCoreBufferOffset,       //  buffer (end of last sent)
                lCoreBufferLength - lLastSentCoreBufferOffset,  //  length (what's left)
                pMSWrapper
                ) ;

        //  done with the wrapper regardless
        RELEASE_AND_CLEAR (pMSWrapper) ;
    }

    cleanup :

    RELEASE_AND_CLEAR (pICoreMediaSample) ;
    RELEASE_AND_CLEAR (pMSWrapper) ;
    RELEASE_AND_CLEAR (pIDVRBufferPriv) ;

    return hr ;
}

HRESULT
CDVRAnalysis::OnCompleteConnect (
    IN  PIN_DIRECTION   PinDir
    )
{
    Lock_ () ;

    if (PinDir == PINDIR_INPUT) {
        //  time to display the output pin
        IncrementPinVersion () ;
    }

    Unlock_ () ;

    return S_OK ;
}

HRESULT
CDVRAnalysis::OnBreakConnect (
    IN  PIN_DIRECTION   PinDir
    )
{
    HRESULT hr ;

    Lock_ () ;

    if (PinDir == PINDIR_INPUT) {
        if (m_pOutputPin -> IsConnected ()) {
            m_pOutputPin -> GetConnected () -> Disconnect () ;
            m_pOutputPin -> Disconnect () ;

            IncrementPinVersion () ;
        }
    }

    Unlock_ () ;

    return S_OK ;
}

HRESULT
CDVRAnalysis::UpdateAllocatorProperties (
    IN  ALLOCATOR_PROPERTIES *  ppropInputRequest
    )
{
    HRESULT hr ;

    if (m_pInputPin -> IsConnected ()) {
        hr = m_pInputPin -> SetAllocatorProperties (ppropInputRequest) ;
    }
    else {
        hr = S_OK ;
    }

    return hr ;
}

HRESULT
CDVRAnalysis::OnOutputGetMediaType (
    OUT CMediaType *    pmt
    )
{
    HRESULT hr ;

    ASSERT (pmt) ;

    if (m_pInputPin -> IsConnected ()) {
        hr = m_pInputPin -> ConnectionMediaType (pmt) ;
    }
    else {
        //  BUGBUG
        //  does this prevent the output from connecting when the input is not
        //   connected ?  yes
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

HRESULT
CDVRAnalysis::GetRefdInputAllocator (
    OUT IMemAllocator **    ppAlloc
    )
{
    HRESULT hr ;

    Lock_ () ;
    hr = m_pInputPin -> GetRefdConnectionAllocator (ppAlloc) ;
    Unlock_ () ;

    return hr ;
}

HRESULT
CDVRAnalysis::DeliverBeginFlush (
    )
{
    HRESULT hr ;

    Lock_ () ;

    if (m_pOutputPin) {
        hr = m_pOutputPin -> DeliverBeginFlush () ;
    }
    else {
        hr = S_OK ;
    }

    if (SUCCEEDED (hr)) {
        ASSERT (m_pIDVRAnalyze) ;
        hr = m_pIDVRAnalyze -> Flush () ;
    }

    Unlock_ () ;

    return hr ;
}

HRESULT
CDVRAnalysis::DeliverEndFlush (
    )
{
    HRESULT hr ;

    Lock_ () ;

    if (m_pOutputPin) {
        hr = m_pOutputPin -> DeliverEndFlush () ;
    }
    else {
        hr = S_OK ;
    }

    Unlock_ () ;

    return hr ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\analysis\dvranalysis\dvranalysishost.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        DVRAnalysisHost.h

    Abstract:

        This module contains the DVRAnalysis filter declarations

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        19-Feb-2001     created

--*/

#ifndef __tsdvr__dvranalysishost_h
#define __tsdvr__dvranalysishost_h

struct ANALYSIS_RESULT {
    LONG            lOffset ;
    CDVRAttribute   DVRAttribute ;
} ;

class CDVRAnalysisBuffer :
    public IDVRAnalysisBufferPriv,
    public TCDynamicProdCons <ANALYSIS_RESULT>
{
    IMediaSample *                          m_pIMediaSample ;
    LONG                                    m_lMediaSampleBufferLength ;
    BYTE *                                  m_pbMediaSampleBuffer ;
    CRITICAL_SECTION                        m_crt ;
    LONG                                    m_lRef ;
    CDVRAnalysisBufferPool *                m_pOwningDVRPool ;
    LONG                                    m_lLastIndexAttribute ;
    CTSortedList <ANALYSIS_RESULT *, LONG>  m_AnalysisResultList ;

    void Lock_ ()       { EnterCriticalSection (& m_crt) ; }
    void Unlock_ ()     { LeaveCriticalSection (& m_crt) ; }

    HRESULT
    FixupList_ (
        ) ;

    virtual
    ANALYSIS_RESULT *
    NewObj_ (
        )
    {
        return new ANALYSIS_RESULT ;
    }

    void
    ClearDuplicateAttributes_ (
        IN  REFGUID rguid,
        IN  LONG    lOffset
        ) ;

    public :

        CDVRAnalysisBuffer (
            CDVRAnalysisBufferPool *    pOwningDVRPool
            ) ;

        virtual
        ~CDVRAnalysisBuffer (
            ) ;

        STDMETHODIMP_ (ULONG) AddRef () ;
        STDMETHODIMP_ (ULONG) Release () ;
        STDMETHODIMP QueryInterface (REFIID, void **) ;

        DECLARE_IDVRANALYSISBUFFERPRIV () ;

        void
        SetMediaSample (
            IN  IMediaSample *  pIMS
            ) ;

        void
        Reset (
            ) ;
} ;

class CDVRAnalysisBufferPool
{
    TCProducerConsumer <CDVRAnalysisBuffer *>   m_DVRBufferPool ;

    public :

        CDVRAnalysisBufferPool (
            ) ;

        ~CDVRAnalysisBufferPool (
            ) ;

        CDVRAnalysisBuffer *
        Get (
            ) ;

        void
        Recycle (
            IN  CDVRAnalysisBuffer *
            ) ;
} ;

class CDVRAnalysisInput :
    public CBaseInputPin
{
    CDVRAnalysis *  m_pHostAnalysisFilter ;

    void FilterLock_ ()         { m_pLock -> Lock () ;      }
    void FilterUnlock_ ()       { m_pLock -> Unlock () ;    }

    public :

        CDVRAnalysisInput (
            IN  TCHAR *         pszPinName,
            IN  CDVRAnalysis *  pAnalysisFilter,
            IN  CCritSec *      pFilterLock,
            OUT HRESULT *       phr
            ) ;

        //  --------------------------------------------------------------------
        //  CBasePin methods

        HRESULT
        CheckMediaType (
            IN  const CMediaType *
            ) ;

        HRESULT
        CompleteConnect (
            IN  IPin *  pIPin
            ) ;

        HRESULT
        BreakConnect (
            ) ;

        //  --------------------------------------------------------------------
        //  CBaseInputPin methods

        STDMETHODIMP
        Receive (
            IN  IMediaSample * pIMediaSample
            ) ;

        STDMETHODIMP
        BeginFlush (
            ) ;

        STDMETHODIMP
        EndFlush (
            ) ;

        //  --------------------------------------------------------------------
        //  class methods

        HRESULT
        SetAllocatorProperties (
            IN  ALLOCATOR_PROPERTIES *  ppropInputRequest
            ) ;

        HRESULT
        GetRefdConnectionAllocator (
            OUT IMemAllocator **    ppAlloc
            ) ;
} ;

class CDVRAnalysisOutput :
    public CBaseOutputPin,
    public IDVRAnalysisConfig
{
    CDVRAnalysis *  m_pHostAnalysisFilter ;

    void FilterLock_ ()         { m_pLock -> Lock () ;      }
    void FilterUnlock_ ()       { m_pLock -> Unlock () ;    }

    public :

        CDVRAnalysisOutput (
            IN  TCHAR *         pszPinName,
            IN  CDVRAnalysis *  pAnalysisFilter,
            IN  CCritSec *      pFilterLock,
            OUT HRESULT *       phr
            ) ;

        DECLARE_IUNKNOWN ;
        IMPLEMENT_IDVRANALYSISCONFIG () ;

        HRESULT
        SendSample (
            IN  IMediaSample *  pIMS
            ) ;

        STDMETHODIMP
        NonDelegatingQueryInterface (
            IN  REFIID  riid,
            OUT void ** ppv
            ) ;

        //  --------------------------------------------------------------------
        //  CBasePin methods

        HRESULT
        DecideBufferSize (
            IN  IMemAllocator *         pAlloc,
            IN  ALLOCATOR_PROPERTIES *  ppropInputRequest
            ) ;

        HRESULT
        GetMediaType (
            IN  int             iPosition,
            OUT CMediaType *    pmt
            ) ;

        HRESULT
        CheckMediaType (
            IN  const CMediaType *
            ) ;

        HRESULT
        CompleteConnect (
            IN  IPin *  pIPin
            ) ;

        HRESULT
        BreakConnect (
            ) ;

        HRESULT
        DecideAllocator (
            IN  IMemInputPin *      pPin,
            IN  IMemAllocator **    ppAlloc
            ) ;
} ;

class CDVRAnalysis :
    public CBaseFilter,             //  dshow base class
    public IDVRPostAnalysisSend
{
    CDVRAnalysisInput *     m_pInputPin ;
    CDVRAnalysisOutput *    m_pOutputPin ;
    IDVRAnalysisLogicProp * m_pIDVRAnalysisProp ;
    IDVRAnalyze *           m_pIDVRAnalyze ;
    CDVRAnalysisBufferPool  m_DVRBuffers ;
    CMediaSampleWrapperPool m_MSWrappers ;
    CDVRAnalysisFlags *     m_pAnalysisTagger ;
    CRatchetBuffer          m_RatchetBuffer ;

    void Lock_ ()           { m_pLock -> Lock () ;      }
    void Unlock_ ()         { m_pLock -> Unlock () ;    }

    HRESULT
    ConfirmBufferPoolStocked_ (
        ) ;

    BOOL
    CompareConnectionMediaType_ (
        IN  const AM_MEDIA_TYPE *   pmt,
        IN  CBasePin *              pPin
        ) ;

    BOOL
    CheckInputMediaType_ (
        IN  const AM_MEDIA_TYPE *   pmt
        ) ;

    BOOL
    CheckOutputMediaType_ (
        IN  const AM_MEDIA_TYPE *   pmt
        ) ;

    HRESULT
    WrapAndSend_ (
        IN  IMediaSample *          pIMSCore,
        IN  BYTE *                  pbBuffer,
        IN  LONG                    lBufferLen,
        IN  CMediaSampleWrapper *   pMSWrapper
        ) ;

    public :

        CDVRAnalysis (
            IN  TCHAR *     pszFilterName,
            IN  IUnknown *  punkControlling,
            IN  IUnknown *  punkAnalysisLogic,
            IN  REFCLSID    rCLSID,
            OUT HRESULT *   phr
            ) ;

        ~CDVRAnalysis (
            ) ;

        DECLARE_IUNKNOWN ;
        DECLARE_IDVRPOSTANALYSISSEND () ;

        //  ====================================================================
        //  pure virtual methods in base class

        int
        GetPinCount (
            ) ;

        CBasePin *
        GetPin (
            IN  int
            ) ;

        STDMETHODIMP
        Pause (
            ) ;

        //  ====================================================================
        //  class methods

        HRESULT
        DeliverBeginFlush (
            ) ;

        HRESULT
        DeliverEndFlush (
            ) ;

        BOOL
        CheckAnalysisMediaType (
            IN  PIN_DIRECTION,          //  caller
            IN  const CMediaType *
            ) ;

        HRESULT
        Process (
            IN  IMediaSample *
            ) ;

        HRESULT
        OnCompleteConnect (
            IN  PIN_DIRECTION           //  caller
            ) ;

        HRESULT
        OnBreakConnect (
            IN  PIN_DIRECTION           //  caller
            ) ;

        HRESULT
        UpdateAllocatorProperties (
            IN  ALLOCATOR_PROPERTIES *
            ) ;

        HRESULT
        OnOutputGetMediaType (
            OUT CMediaType *    pmt
            ) ;

        HRESULT
        GetRefdInputAllocator (
            OUT IMemAllocator **
            ) ;
} ;

#endif  //  __tsdvr__dvranalysishost_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\analysis\filtercf\dvranalysisfiltercf.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        DVRAnalysisFilterCF.h

    Abstract:

        This module contains the COM server that instantiates an analysis
         filter host i.e. a generic filter that hosts the analysis logic
         component.  Analysis logic component instantiates this filter in
         its class factory.

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        19-Feb-2001     created

--*/

#ifndef __analysis__dvranalysisfiltercf_h
#define __analysis__dvranalysisfiltercf_h

class CDVRAnalysisFilterCF :
    public CUnknown,
    public IDVRAnalysisFilterHostFactory
{
    public :

        CDVRAnalysisFilterCF (
            IN  IUnknown *  punkControlling,
            OUT HRESULT *   phr
            ) : CUnknown    (TEXT ("CDVRAnalysisFilterCF"),
                             punkControlling
                             )
        {
            (* phr) = S_OK ;
        }

        ~CDVRAnalysisFilterCF (
            ) {}

        DECLARE_IUNKNOWN ;
        DECLARE_IDVRANALYSISFILTERHOSTFACTORY () ;

        STDMETHODIMP
        NonDelegatingQueryInterface (
            IN  REFIID  riid,
            OUT void ** ppv
            ) ;

        static
        CUnknown *
        WINAPI
        CreateInstance (
            IN  IUnknown *  pIUnknown,
            IN  HRESULT *   phr
            )
        {
            CDVRAnalysisFilterCF *  pIDVRHost ;

            pIDVRHost = new CDVRAnalysisFilterCF (
                            pIUnknown,
                            phr
                            ) ;
            if (FAILED (* phr) ||
                !pIDVRHost) {
                (* phr) = (FAILED (* phr) ? (* phr) : E_OUTOFMEMORY) ;
                DELETE_RESET (pIDVRHost) ;
            }

            return pIDVRHost ;
        }
} ;

#endif  //  #define __analysis__dvranalysisfiltercf_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\analysis\filtercf\dvranalysisfiltercf.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        dvranalysisfiltercf.cpp

    Abstract:

        This module contains

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        19-Feb-2001     created

--*/

#include "dvrall.h"

#include "dvranalysis.h"
#include "dvranalysisfiltercf.h"

STDMETHODIMP
CDVRAnalysisFilterCF::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    OUT void ** ppv
    )
{
    if (riid == IID_IDVRAnalysisFilterHostFactory) {

        return GetInterface (
                    (IDVRAnalysisFilterHostFactory *) this,
                    ppv
                    ) ;
    }

    return CUnknown::NonDelegatingQueryInterface (riid, ppv) ;
}

HRESULT
CDVRAnalysisFilterCF::InstantiateFilterHost (
    IN  IUnknown *  punkAnalysisLogic,
    IN  LPCWSTR     pszLogicName,
    OUT IUnknown ** ppunkAnalysisHostFilter
    )
{
    return E_NOTIMPL ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\analysis\dvranalysisutil\dvranalysisutil.h ===
#ifndef __dvranalysisutil_h
#define __dvranalysisutil_h

struct DVR_ANALYSIS_DESC_INT {
    const GUID *    pguidAnalysis ;
    LPWSTR          pszDescription ;
} ;

HRESULT
CopyDVRAnalysisDescriptor (
    IN  LONG                    lCount,
    IN  DVR_ANALYSIS_DESC_INT * pDVRAnalysisDescMaster,
    OUT DVR_ANALYSIS_DESC **    ppDVRAnalysisDescCopy
    ) ;

void
FreeDVRAnalysisDescriptor (
    IN  LONG                    lCount,
    IN  DVR_ANALYSIS_DESC *     pDVRAnalysisDesc
    ) ;

#endif  //  __dvranalysisutil_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\analysis\mp2frame\dvriframe.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        dvriframe.cpp

    Abstract:

        This module contains the mpeg-2 I-Frame detection code; part of the
            analysis framework

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#include "dvrall.h"
#include "dvranalysis.h"
#include "dvrperf.h"
#include "dvranalysisutil.h"
#include "dvriframe.h"

static
DVR_ANALYSIS_DESC_INT
g_Mpeg2VideoFrameAnalysis [] = {
    {
        //  ====================================================================
        //  GOP header, if there is one (first frame is guaranteed to be
        //   an I-frame: H.262, 6.1.1.7 "I-pictures and group of pictures
        //   header", last paragraph)
        //
        //  -or-
        //
        //  I-frame if there is no GOP header
        & DVRAnalysis_Mpeg2GOP,
        L"Mpeg2 Group Of Pictures (GOP)"
    },
    {
        //  ====================================================================
        //  P-frame
        & DVRAnalysis_Mpeg2_PFrame,
        L"Mpeg2 video P Frame"
    },
    {
        //  ====================================================================
        //  B-frame
        & DVRAnalysis_Mpeg2_BFrame,
        L"Mpeg2 video B Frame"
    },
} ;

static
LONG
g_Mpeg2VideoFrameAnalysisEnum = sizeof g_Mpeg2VideoFrameAnalysis / sizeof DVR_ANALYSIS_DESC_INT ;

//  ============================================================================

AMOVIESETUP_FILTER
g_sudMpeg2VideoFrame = {
    & CLSID_Mpeg2VideoStreamAnalyzer,
    TEXT (DVR_MPEG2_FRAME_ANALYSIS),
    MERIT_DO_NOT_USE,
    0,                                          //  no pins advertized
    NULL                                        //  no pins details
} ;

CUnknown *
WINAPI
CMpeg2VideoFrame::CreateInstance (
    IN  IUnknown *  punkOuter,
    IN  HRESULT *   phr
    )
{
    CMpeg2VideoFrame *  pIFrame ;
    CUnknown *          punkFilterHost ;
    IUnknown *          punkThis ;

    pIFrame = new CMpeg2VideoFrame (
                    NULL,               //  don't aggregate this one
                    phr
                    ) ;

    if (FAILED (* phr) ||
        !pIFrame) {

        (* phr) = (FAILED (* phr) ? (* phr) : E_OUTOFMEMORY) ;
        delete pIFrame ;
        return NULL ;
    }

    //  refcount: pIFrame now has a ref of 0

    (* phr) = pIFrame -> QueryInterface (IID_IUnknown, (void **) & punkThis) ;
    ASSERT (SUCCEEDED (* phr)) ;
    ASSERT (punkThis) ;

    //  refcount: pIFrame now has a ref of 1

    (* phr) = CreateDVRAnalysisHostFilter (
                punkOuter,
                punkThis,
                CLSID_Mpeg2VideoStreamAnalyzer,
                & punkFilterHost
                ) ;

    //  release our ref to the object
    punkThis -> Release () ;

    return punkFilterHost ;
}

STDMETHODIMP
CMpeg2VideoFrame::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    OUT void ** ppv
    )
{
    if (riid == IID_IDVRAnalysisLogicProp) {

        return GetInterface (
                    (IDVRAnalysisLogicProp *) this,
                    ppv
                    ) ;
    }

    else if (riid == IID_IDVRAnalyze) {

        return GetInterface (
                    (IDVRAnalyze *) this,
                    ppv
                    ) ;
    }

    return CUnknown::NonDelegatingQueryInterface (riid, ppv) ;
}

HRESULT
CMpeg2VideoFrame::CompleteQueuedBuffers_ (
    )
{
    IDVRAnalysisBuffer *    pIDVRAnalysisBuffer ;
    HRESULT                 hr ;

    hr = S_OK ;

    while (m_BufferQueue.Length () > 0 &&
           SUCCEEDED (hr)) {

        pIDVRAnalysisBuffer = NULL ;
        m_BufferQueue.Pop (& pIDVRAnalysisBuffer) ;
        ASSERT (pIDVRAnalysisBuffer) ;

        //  keep the queue's ref until we've completed it
        hr = m_pIDVRPostAnalysisSend -> CompleteAnalysis (pIDVRAnalysisBuffer) ;
        pIDVRAnalysisBuffer -> Release () ;
    }

    return hr ;
}

CMpeg2VideoFrame::PICTURE_CODING_TYPE
CMpeg2VideoFrame::PictureCodingType_ (
    IN  BYTE *  pbBuffer
    )
{
    PICTURE_CODING_TYPE CodingType ;

    ASSERT (IsStartCodePrefix (pbBuffer)) ;
    ASSERT (StartCode (pbBuffer) == PICTURE_HEADER_START_CODE) ;

    switch ((pbBuffer [5] >> 3) & 0x07) {
        case INTRA_CODED_VALUE :
            CodingType = I_FRAME ;
            m_Mpeg2VideoStreamStats.I_Frame_Observed () ;
            break ;

        case PREDICTIVE_CODED_VALUE :
            CodingType = P_FRAME ;
            m_Mpeg2VideoStreamStats.P_Frame_Observed () ;
            break ;

        case BIDIRECTIONALLY_PREDICTIVE_CODED_VALUE :
            CodingType = B_FRAME ;
            m_Mpeg2VideoStreamStats.B_Frame_Observed () ;
            break ;

        default :
            CodingType = OTHER ;
            break ;
    } ;

    return CodingType ;
}

HRESULT
CMpeg2VideoFrame::MarkFrameBoundary_ (
    IN  IDVRAnalysisBuffer *    pIDVRAnalysisBuffer,
    IN  DWORD                   dwFrameType,
    IN  LONG                    lBufferOffset
    )
{
    HRESULT hr ;

    DVR_ANALYSIS_MP2_SET_MP2FRAME_ATTRIB (m_dwDVRAnalysisMpeg2Video, dwFrameType) ;
    DVR_ANALYSIS_MP2_SET_BOUNDARY (m_dwDVRAnalysisMpeg2Video, TRUE) ;

    hr = pIDVRAnalysisBuffer -> Mark (
            lBufferOffset,
            & DVRAnalysis_Mpeg2Video,
            reinterpret_cast <BYTE *> (& m_dwDVRAnalysisMpeg2Video),
            sizeof m_dwDVRAnalysisMpeg2Video
            ) ;

    DVR_ANALYSIS_MP2_SET_BOUNDARY (m_dwDVRAnalysisMpeg2Video, FALSE) ;

    return hr ;
}

HRESULT
CMpeg2VideoFrame::Process_ (
    IN  IDVRAnalysisBuffer *    pIDVRAnalysisBuffer,
    OUT BOOL *                  pfAnalysisComplete
    )
{
    BOOL                r ;
    BYTE *              pbCur ;
    LONG                lAdvance ;
    LONG                lBufferLen ;
    LONG                lBufferLeft ;
    LONG                lBufferOffset ;
    BYTE                bStartCode ;
    HRESULT             hr ;
    PICTURE_CODING_TYPE PictureCodingType ;
    BYTE                bFrameRate ;
    LONG                lSequenceHeaderJustPassedOffset ;

    //  BUGBUG: rewrite

    //  if there's a sequence_header that immediately precedes a frame
    //   boundary, we flag the frame boundary there vs. on the actual
    //   frame

    ASSERT (m_pIDVRPostAnalysisSend) ;

    //  undefine this until
    lSequenceHeaderJustPassedOffset = UNDEFINED ;

    //  restart this every time for now
    m_LastMarked = LAST_MARKED_RESTART ;

    hr = pIDVRAnalysisBuffer -> GetBufferLength (& lBufferLen) ;
    if (SUCCEEDED (hr)) {
        lBufferLeft = lBufferLen ;
        hr = pIDVRAnalysisBuffer -> GetBuffer (& pbCur) ;
        if (SUCCEEDED (hr)) {
            //  mark the content in the buffer with what we currently know -
            //    though assume we're not on a frame boundary; if we are, it
            //    will be overwritten shortly
            DVR_ANALYSIS_MP2_SET_BOUNDARY (m_dwDVRAnalysisMpeg2Video, FALSE) ;
            hr = pIDVRAnalysisBuffer -> Mark (
                    0,
                    & DVRAnalysis_Mpeg2Video,
                    reinterpret_cast <BYTE *> (& m_dwDVRAnalysisMpeg2Video),
                    sizeof m_dwDVRAnalysisMpeg2Video
                    ) ;
        }

        //  ====================================================================
        //  BUGBUG: ignore the case where a GOP header or I-frame picture
        //   header spans across DVR Buffers

        while (lBufferLeft > START_CODE_LENGTH &&
               SUCCEEDED (hr)) {

            r = SeekToPrefix (
                    & pbCur,
                    & lBufferLeft
                    ) ;

            if (r &&
                lBufferLeft >= START_CODE_LENGTH) {

                //  ------------------------------------------------------------
                //  sequence header ?
                if (StartCode (pbCur) == SEQUENCE_HEADER_START_CODE) {

                    m_Mpeg2VideoStreamStats.SequenceHeader_Observed () ;

                    if (lBufferLeft >= MIN_FRAME_RATE_BUFFER_REQ) {
                        //  save the frame rate; apply to the next frames
                        bFrameRate = (pbCur [7] & 0x0f) ;
                        DVR_ANALYSIS_MP2_SET_FRAME_RATE (m_dwDVRAnalysisMpeg2Video, bFrameRate) ;

                        //  we now know when we saw our last sequence header
                        lSequenceHeaderJustPassedOffset = lBufferLen - lBufferLeft ;

                        TRACE_3 (LOG_AREA_DVRANALYSIS, 6,
                            TEXT ("mpeg-2 analysis: sequence_header found at %d buffer offset; lBufferLen = %d; lBufferLeft = %d"),
                            lSequenceHeaderJustPassedOffset, lBufferLen, lBufferLeft) ;

                        m_Mpeg2VideoStreamStats.FrameRate (bFrameRate) ;
                    }
                    else {
                        //  BUGBUG: ignore spanning case for now
                    }

                    //  onwards ..
                    lAdvance = Min <LONG> (lBufferLeft, MIN_SEQ_HEADER_LENGTH) ;
                }
                //  ------------------------------------------------------------
                //  GOP header ?
                else if (StartCode (pbCur) == GOP_HEADER_START_CODE) {

                    if (lSequenceHeaderJustPassedOffset != UNDEFINED) {
                        lBufferOffset = lSequenceHeaderJustPassedOffset ;
                    }
                    else {
                        lBufferOffset = lBufferLen - lBufferLeft ;
                    }

                    hr = MarkFrameBoundary_ (
                            pIDVRAnalysisBuffer,
                            DVR_ANALYSIS_MPEG2_VIDEO_CONTENT_GOP_HEADER,
                            lBufferOffset
                            ) ;

                    TRACE_4 (LOG_AREA_DVRANALYSIS, 6,
                        TEXT ("mpeg-2 analysis: GOP header found at %d buffer offset; lBufferLen = %d; lBufferLeft = %d %s"),
                        lBufferOffset, lBufferLen, lBufferLeft, (lSequenceHeaderJustPassedOffset != UNDEFINED ? TEXT ("SEQUENCE_HEADER") : TEXT (""))) ;

                    if (SUCCEEDED (hr)) {
                        lSequenceHeaderJustPassedOffset = UNDEFINED ;
                        m_LastMarked = LAST_MARKED_GOP_HEADER ;
                        m_Mpeg2VideoStreamStats.GOPBoundary_Flagged () ;
                    }

                    lAdvance = Min <LONG> (lBufferLeft, MIN_GOP_HEADER_LENGTH) ;

                    m_Mpeg2VideoStreamStats.GOPHeader_Observed () ;

                }
                //  ------------------------------------------------------------
                //  picture header i.e. I,P,B frame ?
                else if (StartCode (pbCur) == PICTURE_HEADER_START_CODE) {
                    if (lBufferLeft >= MIN_I_FRAME_BUFFER_REQ) {

                        PictureCodingType = PictureCodingType_ (pbCur) ;

                        switch (PictureCodingType) {

                            //  I-frame
                            case I_FRAME :
                                //  ============================================
                                //  only mark it if it was *not* immediately
                                //   preceded by a marked GOP header; we prefer to
                                //   mark a GOP header, but if there is none, or if
                                //   we get consecutive I-frames, we'll mark those
                                if (m_LastMarked != LAST_MARKED_GOP_HEADER) {

                                    if (lSequenceHeaderJustPassedOffset != UNDEFINED) {
                                        lBufferOffset = lSequenceHeaderJustPassedOffset ;
                                    }
                                    else {
                                        lBufferOffset = lBufferLen - lBufferLeft ;
                                    }

                                    hr = MarkFrameBoundary_ (
                                            pIDVRAnalysisBuffer,
                                            DVR_ANALYSIS_MPEG2_VIDEO_CONTENT_I_FRAME,
                                            lBufferOffset
                                            ) ;

                                    TRACE_4 (LOG_AREA_DVRANALYSIS, 6,
                                        TEXT ("mpeg-2 analysis: I-frame found (MARKED) at %d buffer offset; lBufferLen = %d; lBufferLeft = %d %s"),
                                        lBufferOffset, lBufferLen, lBufferLeft, (lSequenceHeaderJustPassedOffset != UNDEFINED ? TEXT ("SEQUENCE_HEADER") : TEXT (""))) ;

                                    if (SUCCEEDED (hr)) {
                                        lSequenceHeaderJustPassedOffset = UNDEFINED ;
                                        m_Mpeg2VideoStreamStats.GOPBoundary_Flagged () ;
                                        m_LastMarked = LAST_MARKED_I_FRAME ;
                                    }
                                }
                                else {
                                    //  flag this anyways ..
                                    m_LastMarked = LAST_MARKED_I_FRAME ;

                                    lSequenceHeaderJustPassedOffset = UNDEFINED ;

                                    TRACE_3 (LOG_AREA_DVRANALYSIS, 6,
                                        TEXT ("mpeg-2 analysis: I-frame found (NOT MARKED) at %d buffer offset; lBufferLen = %d; lBufferLeft = %d"),
                                        lBufferOffset, lBufferLen, lBufferLeft) ;
                                }

                                break ;

                            case P_FRAME :

                                if (lSequenceHeaderJustPassedOffset != UNDEFINED) {
                                    lBufferOffset = lSequenceHeaderJustPassedOffset ;
                                }
                                else {
                                    lBufferOffset = lBufferLen - lBufferLeft ;
                                }

                                hr = MarkFrameBoundary_ (
                                        pIDVRAnalysisBuffer,
                                        DVR_ANALYSIS_MPEG2_VIDEO_CONTENT_P_FRAME,
                                        lBufferOffset
                                        ) ;

                                TRACE_4 (LOG_AREA_DVRANALYSIS, 6,
                                    TEXT ("mpeg-2 analysis: P-frame found at %d buffer offset; lBufferLen = %d; lBufferLeft = %d  %s"),
                                    lBufferOffset, lBufferLen, lBufferLeft, (lSequenceHeaderJustPassedOffset != UNDEFINED ? TEXT ("SEQUENCE_HEADER") : TEXT (""))) ;

                                if (SUCCEEDED (hr)) {
                                    lSequenceHeaderJustPassedOffset = UNDEFINED ;
                                    m_LastMarked = LAST_MARKED_P_FRAME ;
                                    m_Mpeg2VideoStreamStats.P_Frame_Flagged () ;
                                }

                                break ;

                            case B_FRAME :

                                if (lSequenceHeaderJustPassedOffset != UNDEFINED) {
                                    lBufferOffset = lSequenceHeaderJustPassedOffset ;
                                }
                                else {
                                    lBufferOffset = lBufferLen - lBufferLeft ;
                                }

                                hr = MarkFrameBoundary_ (
                                        pIDVRAnalysisBuffer,
                                        DVR_ANALYSIS_MPEG2_VIDEO_CONTENT_B_FRAME,
                                        lBufferOffset
                                        ) ;

                                TRACE_4 (LOG_AREA_DVRANALYSIS, 6,
                                    TEXT ("mpeg-2 analysis: B-frame found at %d buffer offset; lBufferLen = %d; lBufferLeft = %d  %s"),
                                    lBufferOffset, lBufferLen, lBufferLeft, (lSequenceHeaderJustPassedOffset != UNDEFINED ? TEXT ("SEQUENCE_HEADER") : TEXT (""))) ;

                                if (SUCCEEDED (hr)) {
                                    lSequenceHeaderJustPassedOffset = UNDEFINED ;
                                    m_LastMarked = LAST_MARKED_B_FRAME ;
                                    m_Mpeg2VideoStreamStats.B_Frame_Flagged () ;
                                }

                                break ;

                            case OTHER :
                                break ;
                        } ;
                    }
                    else {
                        //  BUGBUG: ignore spanning case for now
                    }

                    lAdvance = Min <LONG> (lBufferLeft, MIN_PICTURE_HEADER_LENGTH) ;
                }
                else {
                    lAdvance = Min <LONG> (lBufferLeft, START_CODE_PREFIX_LENGTH) ;
                }

                pbCur       += lAdvance ;
                lBufferLeft -= lAdvance ;
            }
        }
    }

    //  BUGBUG: we're ignoring the spanning case for now
    (* pfAnalysisComplete) = TRUE ;

    return hr ;
}

HRESULT
CMpeg2VideoFrame::Complete_ (
    IN  IDVRAnalysisBuffer *    pIDVRAnalysisBuffer
    )
{
    HRESULT hr ;

    ASSERT (m_pIDVRPostAnalysisSend) ;

    CompleteQueuedBuffers_ () ;
    hr = m_pIDVRPostAnalysisSend -> CompleteAnalysis (pIDVRAnalysisBuffer) ;

    return hr ;
}

HRESULT
CMpeg2VideoFrame::QueueBuffer_ (
    IN  IDVRAnalysisBuffer *    pIDVRAnalysisBuffer
    )
{
    DWORD   dw ;
    HRESULT hr ;

    dw = m_BufferQueue.Push (pIDVRAnalysisBuffer) ;
    if (dw == NOERROR) {
        //  queue's ref
        pIDVRAnalysisBuffer -> AddRef () ;
    }

    hr = HRESULT_FROM_WIN32 (dw) ;

    return hr ;
}

HRESULT
CMpeg2VideoFrame::Restart_ (
    )
{
    //  reset everything
    //  send any queued buffers we may have
    CompleteQueuedBuffers_ () ;

    m_LastMarked            = LAST_MARKED_RESTART ;
    m_Mpeg2VideoStreamState = IN_UNKNOWN_CONTENT ;

    DVR_ANALYSIS_MP2_SET_NONE (m_dwDVRAnalysisMpeg2Video) ;

    return S_OK ;
}


STDMETHODIMP
CMpeg2VideoFrame::Flush (
    )
{
    HRESULT hr ;

    hr = Restart_ () ;

    return hr ;
}

STDMETHODIMP
CMpeg2VideoFrame::Analyze (
    IN  IDVRAnalysisBuffer *    pIDVRAnalysisBuffer,
    IN  BOOL                    fDiscontinuity
    )
{
    HRESULT hr ;
    BOOL    fAnalysisComplete ;

    if (m_pIDVRPostAnalysisSend) {

        if (fDiscontinuity) {
            Restart_ () ;
        }

        hr = Process_ (
                pIDVRAnalysisBuffer,
                & fAnalysisComplete
                ) ;
        if (SUCCEEDED (hr)) {
            if (fAnalysisComplete) {
                hr = Complete_ (pIDVRAnalysisBuffer) ;
            }
            else {
                hr = QueueBuffer_ (pIDVRAnalysisBuffer) ;
                if (FAILED (hr)) {
                    //  failed to queue; complete what's queued + this one
                    hr = Complete_ (pIDVRAnalysisBuffer) ;
                }
            }
        }
        else {
            //  failed while processing this one; send it through anyways
            hr = Complete_ (pIDVRAnalysisBuffer) ;
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

STDMETHODIMP
CMpeg2VideoFrame::GetDisplayName (
    IN  LPWSTR *    ppszFilterName
    )
{
    int     iLen ;
    HRESULT hr ;

    if (!ppszFilterName) {
        return E_POINTER ;
    }

    iLen = wcslen (DVR_MPEG2_FRAME_ANALYSIS_W) ;

    (* ppszFilterName) = reinterpret_cast <LPWSTR> (CoTaskMemAlloc ((iLen + 1) * sizeof WCHAR)) ;
    if (* ppszFilterName) {
        wcscpy ((* ppszFilterName), DVR_MPEG2_FRAME_ANALYSIS_W) ;
        (* ppszFilterName) [iLen] = L'\0' ;

        hr = S_OK ;
    }
    else {
        hr = E_OUTOFMEMORY ;
    }

    return hr ;
}

HRESULT
CMpeg2VideoFrame::CheckMediaType (
    IN  const AM_MEDIA_TYPE *   pMediaType,
    OUT BOOL *                  pfAccept
    )
{
    if (!pMediaType ||
        !pfAccept) {

        return E_POINTER ;
    }

    (* pfAccept) = (pMediaType -> majortype == MEDIATYPE_Video &&
                    pMediaType -> subtype   == MEDIASUBTYPE_MPEG2_VIDEO ? TRUE : FALSE) ;

    return S_OK ;
}

HRESULT
CMpeg2VideoFrame::SetPostAnalysisSend (
    IN  IDVRPostAnalysisSend *  pIDVRPostAnalysisSend
    )
{
    Lock_ () ;

    //  weak ref !!
    m_pIDVRPostAnalysisSend = pIDVRPostAnalysisSend ;

    Unlock_ () ;

    return S_OK ;
}

HRESULT
CMpeg2VideoFrame::EnumAnalysis (
    OUT LONG *                  plCount,
    OUT DVR_ANALYSIS_DESC **    ppDVRAnalysisDesc    //  callee allocates; caller deallocates
    )
{
    HRESULT hr ;

    if (!plCount ||
        !ppDVRAnalysisDesc) {

        return E_POINTER ;
    }

    (* plCount) = g_Mpeg2VideoFrameAnalysisEnum ;
    hr = CopyDVRAnalysisDescriptor (
            (* plCount),
            g_Mpeg2VideoFrameAnalysis,
            ppDVRAnalysisDesc
            ) ;

    return hr ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\dvrplay\dvrplay.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        DVRPlay.cpp

    Abstract:

        This module contains the DVRPlay code.

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#include "dvrall.h"

#include "dvrclock.h"           //  IReferenceClock
#include "dvrprof.h"            //  WM Profiles
#include "dvrdsseek.h"
#include "dvrpins.h"            //  pins & pin collections
#include "dvrdsrec.h"
#include "DVRPlay.h"            //  filter declarations
#include "dvrdsread.h"          //  reader
#include "MultiGraphHost.h"     //  Multi Graph Host Service

#pragma warning (disable:4355)

AMOVIESETUP_FILTER
g_sudDVRPlay = {
    & CLSID_StreamBufferSource,
    TEXT (STREAMBUFFER_PLAY_FILTER_NAME),
    MERIT_DO_NOT_USE,
    0,                                          //  no pins advertized
    NULL                                        //  no pins details
} ;

//  ============================================================================

CDVRPlay::CDVRPlay (
    IN  IUnknown *  punkControlling,
    IN  REFCLSID    rclsid,
    OUT HRESULT *   phr
    ) : CBaseFilter                 (TEXT (STREAMBUFFER_PLAY_FILTER_NAME),
                                     punkControlling,
                                     new CCritSec,
                                     rclsid
                                     ),
        m_pOutputPins               (NULL),
        m_pPolicy                   (NULL),
        m_pReader                   (NULL),
        m_pszFilename               (NULL),
        m_bAnchoredToZero           (TRUE),
        m_SeekingCore               (m_pLock,
                                     this
                                     ),
        m_IMediaSeeking             (GetOwner (),
                                     & m_SeekingCore,
                                     this
                                     ),
        m_pDVRRecordingAttributes   (NULL),
        m_pPVRIOCounters            (NULL),
        m_pDVRClock                 (NULL)
{
    DWORD   dwDisposition ;
    DWORD   dw ;
    LONG    l ;

    TRACE_CONSTRUCTOR (TEXT ("CDVRPlay")) ;

    if (FAILED (* phr)) {
        goto cleanup ;
    }

    m_pPVRIOCounters = new CPVRIOCounters () ;
    if (!m_pPVRIOCounters) {
        (* phr) = E_OUTOFMEMORY ;
        goto cleanup ;
    }

    //  our ref
    m_pPVRIOCounters -> AddRef () ;

    //  settings object
    m_pPolicy = new CDVRPolicy (REG_DVR_PLAY_ROOT, phr) ;
    if (!m_pLock ||
        !m_pPolicy ||
        FAILED (* phr)) {

        (* phr) = (m_pLock && m_pPolicy ? (* phr) : E_OUTOFMEMORY) ;

        goto cleanup ;
    }

    //  initialize our stats writer; ignore the return code so we don't fail
    //    the filter load if there's a problem initializing stats
    m_DVRSendStatsWriter.Initialize (m_pPolicy -> Settings () -> StatsEnabled ()) ;
    m_pPVRIOCounters -> Initialize  (m_pPolicy -> Settings () -> StatsEnabled ()) ;

    //  clock
    m_pDVRClock = new CDVRClock (
                        GetOwner (),
                        m_pPolicy -> Settings () -> ClockSlaveSampleBracketMillis (),
                        m_pPolicy -> Settings () -> ClockSlaveMinSlavable (),
                        m_pPolicy -> Settings () -> ClockSlaveMaxSlavable (),
                        & m_DVRSendStatsWriter,
                        phr
                        ) ;
    if (!m_pDVRClock ||
        FAILED (* phr)) {

        (* phr) = (m_pDVRClock ? (* phr) : E_OUTOFMEMORY) ;

        goto cleanup ;
    }

    m_pOutputPins = new CDVRSourcePinManager (
                            m_pPolicy,
                            & m_DVRSendStatsWriter,
                            this,
                            m_pLock,
                            & m_SeekingCore
                            ) ;
    if (!m_pOutputPins) {
        (* phr) = E_OUTOFMEMORY ;
        goto cleanup ;
    }

    m_SeekingCore.SetDVRSourcePinManager    (m_pOutputPins) ;
    m_SeekingCore.SetDVRPolicy              (m_pPolicy) ;
    m_SeekingCore.SetStatsWriter            (& m_DVRSendStatsWriter) ;

    //  success
    (* phr) = S_OK ;

    cleanup :

    return ;
}

CDVRPlay::~CDVRPlay (
    )
{
    int         i ;
    CBasePin *  pPin ;

    TRACE_DESTRUCTOR (TEXT ("CDVRPlay")) ;

    UnloadASFFile_ () ;

    delete m_pDVRRecordingAttributes ;
    delete m_pReader ;
    delete m_pOutputPins ;
    delete m_pDVRClock ;

    RELEASE_AND_CLEAR (m_pPVRIOCounters) ;
    RELEASE_AND_CLEAR (m_pPolicy) ;
    DELETE_RESET_ARRAY (m_pszFilename) ;
}

STDMETHODIMP
CDVRPlay::SetSyncSource (
    IN  IReferenceClock *   pRefClock
    )
{
    HRESULT hr ;

    hr = CBaseFilter::SetSyncSource (pRefClock) ;
    if (SUCCEEDED (hr)) {
        m_SeekingCore.SetRefClock (pRefClock) ;
    }

    return hr ;
}

STDMETHODIMP
CDVRPlay::SetSIDs (
    IN  DWORD   cSIDs,
    IN  PSID *  ppSID
    )
{
    HRESULT hr ;

    if (!ppSID) {
        return E_POINTER ;
    }

    LockFilter_ () ;

    ASSERT (m_pPolicy) ;
    hr = m_pPolicy -> SetSIDs (cSIDs, ppSID) ;

    UnlockFilter_ () ;

    return hr ;
}

STDMETHODIMP
CDVRPlay::SetHKEY (
    IN  HKEY    hkeyRoot
    )
{
    HRESULT hr ;

    if (m_pReader) {
        hr = E_UNEXPECTED ;
        return hr ;
    }

    LockFilter_ () ;

    ASSERT (m_pPolicy) ;
    hr = m_pPolicy -> SetRootHKEY (hkeyRoot, REG_DVR_PLAY_ROOT) ;

    UnlockFilter_ () ;

    return hr ;
}

STDMETHODIMP
CDVRPlay::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    OUT void ** ppv
    )
{
    HRESULT hr ;

    LockFilter_ () ;

    //  ------------------------------------------------------------------------
    //  ISpecifyPropertyPages; allows an app to enumerate CLSIDs for our
    //   property pages

    if (riid == IID_ISpecifyPropertyPages) {

        hr = GetInterface (
                    (ISpecifyPropertyPages *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IStreamBufferSource

    else if (riid == IID_IStreamBufferSource) {

        hr = GetInterface (
                    (IStreamBufferSource *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IFileSourceFilter;

    else if (riid == IID_IFileSourceFilter) {

        hr = GetInterface (
                    (IFileSourceFilter *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IStreamBufferMediaSeeking

    else if (riid == IID_IStreamBufferMediaSeeking
             //&& !m_pPolicy -> Settings () -> ImplementIMediaSeekingOnFilter ()
             ) {

        hr = GetInterface (
                    (IStreamBufferMediaSeeking *) & m_IMediaSeeking,
                    ppv
                    ) ;
    }

#if 0
    //  ------------------------------------------------------------------------
    //  IStreamBufferPlayrate

    else if (riid == IID_IStreamBufferPlayrate) {
        hr = GetInterface (
                    (IStreamBufferPlayrate *) & m_IMediaSeeking,
                    ppv
                    ) ;
    }
#endif

    //  ------------------------------------------------------------------------
    //  IReferenceClock

    else if (riid == IID_IReferenceClock    &&
             ImplementIRefClock_ ()) {

        hr = GetInterface (
                    (IReferenceClock *) m_pDVRClock,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IStreamBufferInitialize

    else if (riid == IID_IStreamBufferInitialize) {

        hr = GetInterface (
                    (IStreamBufferInitialize *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IStreamBufferRecordingAttribute

    else if (riid == IID_IStreamBufferRecordingAttribute) {

        //  make sure the file is loaded first (might be gettign QI'ed before
        //    we're in a filtergraph)
        hr = LoadASFFile_ () ;
        if (SUCCEEDED (hr)) {

            ASSERT (m_pDVRRecordingAttributes) ;
            hr = GetInterface (
                        (IStreamBufferRecordingAttribute *) m_pDVRRecordingAttributes,
                        ppv
                        ) ;
        }
    }

    //  ------------------------------------------------------------------------
    //  IAMFilterMiscFlags; must implement this interface if we're to be picked
    //   as graph clock; same conditions as IReferenceClock since these are
    //   related

    else if (riid == IID_IAMFilterMiscFlags &&
             ImplementIRefClock_ ()) {

        hr = GetInterface (
                    (IAMFilterMiscFlags *) this,
                    ppv
                    ) ;
    }

    else {
        hr = CBaseFilter::NonDelegatingQueryInterface (riid, ppv) ;
    }

    UnlockFilter_ () ;

    return hr ;
}

int
CDVRPlay::GetPinCount (
    )
{
    int i ;

    LockFilter_ () ;

    i = m_pOutputPins -> PinCount () ;

    UnlockFilter_ () ;

    return i ;
}

CBasePin *
CDVRPlay::GetPin (
    IN  int i
    )
{
    CBasePin *  pPin ;

    LockFilter_ () ;

    pPin = m_pOutputPins -> GetPin (i) ;

    UnlockFilter_ () ;

    return pPin ;
}

STDMETHODIMP
CDVRPlay::GetPages (
    CAUUID * pPages
    )
{
    HRESULT hr ;

    if (pPages) {
        pPages -> cElems = 2 ;
        pPages -> pElems = reinterpret_cast <GUID *> (CoTaskMemAlloc (pPages -> cElems * sizeof GUID)) ;

        if (pPages -> pElems) {
            (pPages -> pElems) [0] = CLSID_DVRPlayProp ;
            (pPages -> pElems) [1] = CLSID_DVRStreamSourceProp ;
            hr = S_OK ;
        }
        else {
            hr = E_OUTOFMEMORY ;
        }
    }
    else {
        hr = E_POINTER ;
    }

    return hr ;
}

STDMETHODIMP
CDVRPlay::JoinFilterGraph (
    IN  IFilterGraph *  pGraph,
    IN  LPCWSTR         pName
    )
{
    HRESULT hr ;

    if (pGraph) {
        //  on our way in
        hr = CBaseFilter::JoinFilterGraph (pGraph, pName) ;
        if (SUCCEEDED (hr) &&
            m_pszFilename) {

            hr = LoadASFFile_ () ;
            if (FAILED (hr)) {
                CBaseFilter::JoinFilterGraph (NULL, NULL) ;
            }
        }
    }
    else {
        //  on our way out
        IFilterGraph * pFilterGraph = m_pGraph ;

        hr = CBaseFilter::JoinFilterGraph (pGraph, pName) ;
        if (SUCCEEDED (hr) &&
            m_pszFilename) {

            UnloadASFFile_ () ;
            UpdateMultiGraphHost_ (pFilterGraph);
        }
    }

    return hr ;
}

STDMETHODIMP
CDVRPlay::Load (
    IN  LPCOLESTR               pszFilename,
    IN  const AM_MEDIA_TYPE *   pmt             //  can be NULL
    )
{
    HRESULT hr ;
    DWORD   dw ;

    if (!pszFilename) {
        return E_POINTER ;
    }

    LockFilter_ () ;

    //  validate that the file exists; typically the DVRIO layer performs
    //    this for us, but we don't present the file to the DVRIO layer
    //    until we join the filtergraph
    dw = ::GetFileAttributes (pszFilename) ;
    if (dw != -1) {
        DELETE_RESET_ARRAY (m_pszFilename) ;

        m_pszFilename = new WCHAR [lstrlenW (pszFilename) + 1] ;
        if (m_pszFilename) {
            lstrcpyW (m_pszFilename, pszFilename) ;
            hr = LoadASFFile_ () ;
        }
        else {
            hr = E_OUTOFMEMORY ;
        }
    }
    else {
        dw = GetLastError () ;
        hr = HRESULT_FROM_WIN32 (dw) ;
    }

    UnlockFilter_ () ;

    return hr ;
}

STDMETHODIMP
CDVRPlay::GetCurFile (
    OUT LPOLESTR *      ppszFilename,
    OUT AM_MEDIA_TYPE * pmt
    )
{
    HRESULT hr ;

    if (!ppszFilename ||
        !pmt) {

        return E_POINTER ;
    }

    LockFilter_ () ;

    if (m_pszFilename) {
        (* ppszFilename) = reinterpret_cast <LPOLESTR> (CoTaskMemAlloc ((lstrlenW (m_pszFilename) + 1) * sizeof OLECHAR)) ;
        if (* ppszFilename) {

            //  outgoing filename
            lstrcpyW ((* ppszFilename), m_pszFilename) ;

            //  and media type
            pmt->majortype      = GUID_NULL;
            pmt->subtype        = GUID_NULL;
            pmt->pUnk           = NULL;
            pmt->lSampleSize    = 0;
            pmt->cbFormat       = 0;

            hr = S_OK ;
        }
        else {
            hr = E_OUTOFMEMORY ;
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    UnlockFilter_ () ;

    return hr ;
}

CUnknown *
WINAPI
CDVRPlay::CreateInstance (
    IN  IUnknown *  punkControlling,
    IN  HRESULT *   phr
    )
{
    CDVRPlay *    pCDVRPlay ;

    pCDVRPlay = NULL ;

    if (::CheckOS ()) {
        pCDVRPlay = new CDVRPlay (
                                punkControlling,
                                CLSID_StreamBufferSource,
                                phr
                                ) ;
        if (!pCDVRPlay) {
            (* phr) = E_OUTOFMEMORY ;
        }
        else if (FAILED (* phr)) {
            DELETE_RESET (pCDVRPlay) ;
        }
    }
    else {
        (* phr) = E_FAIL ;
    }

    return pCDVRPlay ;
}

HRESULT
CDVRPlay::UpdateMultiGraphHost_ (
        IFilterGraph * pGraph   // = NULL
    )
{
    if (!pGraph) {
        pGraph = m_pGraph ;
    }
    if (!pGraph) {
        m_bAnchoredToZero = TRUE ;
        return S_OK ;
    }
    if (!m_pReader) {
        if (m_bAnchoredToZero) {
            return S_OK ;
        }
        m_bAnchoredToZero = TRUE ;
    }
    else {
        BOOL bAnchored = m_pReader -> SourceAnchoredToZeroTime () ? 1 : 0 ;
        if (bAnchored == m_bAnchoredToZero ) {
            return S_OK ;
        }
        m_bAnchoredToZero = bAnchored ;
    }

    HRESULT hrTmp ;
    IServiceProvider * pSvcProvider ;
    IMultiGraphHost *  pSvc ;

    hrTmp = pGraph -> QueryInterface (
                            IID_IServiceProvider,
                            (void **) & pSvcProvider
                            ) ;
    if (FAILED (hrTmp)) {
        return S_OK ;
    }
    hrTmp = pSvcProvider -> QueryService (
                                GUID_MultiGraphHostService,
                                IID_IMultiGraphHost,
                                (void **) & pSvc
                                ) ;
    pSvcProvider -> Release () ;

    if (FAILED (hrTmp)) {
        return S_OK ;
    }

    IGraphBuilder    * pGraphBuilder  = NULL ;

    hrTmp = pGraph -> QueryInterface (
                            IID_IGraphBuilder,
                            (void **) & pGraphBuilder
                            ) ;
    if (FAILED (hrTmp)) {
        pSvc -> Release () ;
        return S_OK ;
    }
    pSvc -> LiveSourceReader (
                m_bAnchoredToZero? 0 : 1,
                pGraphBuilder
                ) ;


    pGraphBuilder -> Release ();
    pSvc -> Release () ;

    return S_OK ;
}

BOOL
CDVRPlay::ImplementIRefClock_ (
    )
{
    BOOL    r ;

    if (m_pPolicy -> Settings () -> CanImplementIReferenceClock ()) {
        r = (m_pPolicy -> Settings () -> AlwaysImplementIReferenceClock () ||
             (m_pReader && m_pReader -> IsLiveSource ()) ? TRUE : FALSE) ;
    }
    else {
        r = FALSE ;
    }

    return r ;
}

HRESULT
CDVRPlay::InitFilterLocked_ (
    )
{
    HRESULT             hr ;
    CDVRReaderProfile * pDVRReaderProfile ;

    ASSERT (m_pReader) ;
    ASSERT (m_pOutputPins) ;

    hr = m_pReader -> GetRefdReaderProfile (& pDVRReaderProfile) ;
    if (SUCCEEDED (hr)) {
        ASSERT (pDVRReaderProfile) ;
        hr = m_pOutputPins -> SetReaderProfile (pDVRReaderProfile) ;
        pDVRReaderProfile -> Release () ;
    }

    if (SUCCEEDED (hr)) {
        m_SeekingCore.SetDVRReadManager (m_pReader) ;
        m_pOutputPins -> SetLiveSource (m_pReader -> IsLiveSource ()) ;
    }
    else {
        //  reset if anything failed
        DELETE_RESET (m_pReader) ;
        m_pOutputPins -> SetLiveSource (FALSE) ;
    }

    return hr ;
}

HRESULT
CDVRPlay::LoadASFFile_ (
    )
{
    HRESULT                     hr ;
    CDVRReaderProfile *         pDVRReaderProfile ;
    IDVRIORecordingAttributes * pIDVRIORecReader ;

    hr = S_OK ;

    LockFilter_ () ;

    //  if we're in a graph and have a filename
    if (m_pGraph &&
        m_pszFilename) {

        //  and have not yet instantiated a reader
        if (!m_pReader) {


            ASSERT (!m_pDVRRecordingAttributes) ;

            //  instantiate now
            m_pReader = new CDVRRecordingReader (
                                m_pszFilename,
                                m_pPolicy,
                                & m_SeekingCore,
                                m_pOutputPins,
                                & m_DVRSendStatsWriter,
                                m_pPVRIOCounters,
                                m_pDVRClock,
                                & pIDVRIORecReader,
                                & hr
                                ) ;

            if (m_pReader &&
                SUCCEEDED (hr)) {

                ASSERT (pIDVRIORecReader) ;
                m_pDVRRecordingAttributes = new CDVRRecordingAttributes (
                                                    GetOwner (),
                                                    pIDVRIORecReader,
                                                    TRUE                    //  readonly from this filter
                                                    ) ;
                pIDVRIORecReader -> Release () ;

                //  ignore memory allocation failure; we just won't implement
                //    the interface

                hr = InitFilterLocked_ () ;
                UpdateMultiGraphHost_ ();
            }

            //  m_pReader is deleted if InitFilterLocked call fails
        }
    }

    UnlockFilter_ () ;

    return hr ;
}

HRESULT
CDVRPlay::UnloadASFFile_ (
    )
{
    DELETE_RESET (m_pReader) ;
    DELETE_RESET (m_pDVRRecordingAttributes) ;
    return S_OK ;
}

STDMETHODIMP
CDVRPlay::SetStreamSink (
    IN  IStreamBufferSink *    pIStreamBufferSink
    )
{
    HRESULT                 hr ;
    CDVRReaderProfile *     pDVRReaderProfile ;

    //  PREFIX
    hr = S_OK ;

    if (!pIStreamBufferSink) {
        return E_POINTER ;
    }

    if (m_pReader ||
        !m_pGraph) {

        //  we've already been set, or we're not in a graph yet
        return E_UNEXPECTED ;
    }

    delete [] m_pszFilename ;
    m_pszFilename = NULL ;

    LockFilter_ () ;

    m_pReader = new CDVRBroadcastStreamReader (
                        pIStreamBufferSink,
                        m_pPolicy,
                        & m_SeekingCore,
                        m_pOutputPins,
                        & m_DVRSendStatsWriter,
                        m_pDVRClock,
                        & hr
                        ) ;
    if (m_pReader &&
        SUCCEEDED (hr)) {

        hr = InitFilterLocked_ () ;
    }

    //  m_pReader is deleted if InitFilterLocked call fails

    UnlockFilter_ () ;

    return hr ;
}

STDMETHODIMP
CDVRPlay::Pause (
    )
{
    HRESULT hr ;

    TRACE_0 (LOG_TRACE, 1, TEXT ("DVRPlay: Pause")) ;

    //  hold the seeking lock across this call as state can have an effect on
    //    how we seek or set rates
    m_SeekingCore.Lock () ;

    //  prevent others from manipulating the reader thread
    m_pReader -> ReaderThreadLock () ;

    LockFilter_ () ;

    m_SeekingCore.OnFilterStateChange (State_Paused) ;
    m_pReader -> OnStatePaused () ;

    if (m_State == State_Stopped) {
        //  transition to running

        ASSERT (m_pOutputPins) ;
        hr = m_pOutputPins -> Active () ;
        if (SUCCEEDED (hr)) {
            hr = m_pReader -> Active (m_pClock) ;
            m_pPolicy -> EventSink () -> Initialize (m_pGraph) ;
            if (SUCCEEDED (hr)) {
                m_State = State_Paused ;
            }
        }
    }
    else {
        m_State = State_Paused ;
        hr = S_OK ;
    }

    UnlockFilter_ () ;

    m_pReader -> ReaderThreadUnlock () ;

    m_SeekingCore.Unlock () ;

    return hr ;
}

STDMETHODIMP
CDVRPlay::Stop (
    )
{
    HRESULT hr ;

    TRACE_0 (LOG_TRACE, 1, TEXT ("DVRPlay: Stop")) ;

    //  hold the seeking lock across this call as state can have an effect on
    //    how we seek or set rates
    m_SeekingCore.Lock () ;

    //  prevent others from manipulating the reader thread
    m_pReader -> ReaderThreadLock () ;

    //  don't grab the filter lock while this happens or we expose ourselves
    //   to a deadlock scenario (we've got the filter lock, and we're waiting
    //   synchronously for reader thread to pause, and it's blocked waiting for
    //   the filter lock)
    hr = m_pReader -> Inactive () ;

    //
    //  reader thread is now terminated, and no one is going to start it (we've
    //   got the reader thread lock); it's safe to grab the filter lock
    //

    if (SUCCEEDED (hr)) {

        LockFilter_ () ;

        //  bug workaround
        m_SeekingCore.GetStreamTimeDShow (& m_rtAtStop) ;

        m_SeekingCore.OnFilterStateChange (State_Stopped) ;

        m_SeekingCore.SeekTo (& m_rtAtStop) ;

        ASSERT (m_pOutputPins) ;
        m_pOutputPins -> Inactive () ;

        m_pPolicy -> EventSink () -> Initialize (NULL) ;

        m_State = State_Stopped ;

        m_pReader -> OnStateStopped () ;

        UnlockFilter_ () ;
    }

    m_pReader -> ReaderThreadUnlock () ;

    m_SeekingCore.Unlock () ;

    return hr ;
}

STDMETHODIMP
CDVRPlay::Run (
    IN  REFERENCE_TIME  rtStart
    )
{
    HRESULT hr ;

    TRACE_0 (LOG_TRACE, 1, TEXT ("DVRPlay: Run")) ;

    //  PREFIX
    hr = S_OK ;

    //  hold the seeking lock across this call as state can have an effect on
    //    how we seek or set rates
    m_SeekingCore.Lock () ;

    LockFilter_ () ;

    m_pReader -> OnStateRunning (rtStart) ;

    if (m_State == State_Paused) {
        //  expected
        m_SeekingCore.OnFilterStateChange (State_Running, rtStart) ;
        hr = CBaseFilter::Run (rtStart) ;
    }
    else if (m_State == State_Stopped) {
        //  --------------------------------------------------------------------
        //  work around bug 443144 whereby the graph is restarted and
        //    transitions to run directly from the stopped state; set the
        //    segment start first to our last read position, then transition
        //    the baseclass to run (this will pause the filter first)

        //hr = m_SeekingCore.SeekTo (& m_rtAtStop, 0) ;
        hr = S_OK ;
        if (SUCCEEDED (hr)) {
            hr = CBaseFilter::Run (rtStart) ;
            if (SUCCEEDED (hr)) {
                m_SeekingCore.OnFilterStateChange (State_Running, rtStart) ;
            }
        }
    }

    UnlockFilter_ () ;

    m_SeekingCore.Unlock () ;

    return hr ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\dvrplay\dvrplay.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        DVRPlay.h

    Abstract:

        This module contains the DVRPlay declarations.

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#ifndef __dvrplay__dvrplay_h
#define __dvrplay__dvrplay_h

extern AMOVIESETUP_FILTER   g_sudDVRPlay ;

class CDVRPlay :
    public CBaseFilter,
    public ISpecifyPropertyPages,
    public IAMFilterMiscFlags,
    public IFileSourceFilter,
    public IStreamBufferSource,
    public IStreamBufferInitialize
{
    CDVRSourcePinManager *      m_pOutputPins ;
    CDVRPolicy *                m_pPolicy ;
    CDVRReadManager *           m_pReader ;
    WCHAR *                     m_pszFilename ;
    CDVRDShowSeekingCore        m_SeekingCore ;
    CDVRFilterIMediaSeeking     m_IMediaSeeking ;
    CDVRClock *                 m_pDVRClock ;
    BOOL                        m_bAnchoredToZero ;
    CDVRSendStatsWriter         m_DVRSendStatsWriter ;
    CPVRIOCounters *            m_pPVRIOCounters ;
    CDVRRecordingAttributes *   m_pDVRRecordingAttributes ;

    //  work around for bug 443144
    REFERENCE_TIME              m_rtAtStop ;

    void LockFilter_ ()         { m_pLock -> Lock () ; }
    void UnlockFilter_ ()       { m_pLock -> Unlock () ; }

    HRESULT
    UpdateMultiGraphHost_ (
            IFilterGraph * pGraph = NULL
        ) ;

    HRESULT
    InitFilterLocked_ (
        ) ;

    HRESULT
    LoadASFFile_ (
        ) ;

    HRESULT
    UnloadASFFile_ (
        ) ;

    BOOL
    ImplementIRefClock_ (
        ) ;

    public :

        CDVRPlay (
            IN  IUnknown *  punkControlling,
            IN  REFCLSID    rclsid,
            OUT HRESULT *   phr
            ) ;

        ~CDVRPlay (
            ) ;

        DECLARE_IUNKNOWN ;

        STDMETHODIMP
        NonDelegatingQueryInterface (
            IN  REFIID  riid,
            OUT void ** ppv
             ) ;

        STDMETHODIMP
        JoinFilterGraph (
            IN  IFilterGraph *  pGraph,
            IN  LPCWSTR         pName
            ) ;

        STDMETHODIMP
        Pause (
            ) ;

        STDMETHODIMP
        Stop (
            ) ;

        STDMETHODIMP
        Run (
            IN  REFERENCE_TIME  rtStart
            ) ;

        STDMETHODIMP
        SetSyncSource (
            IN  IReferenceClock *
            ) ;

        //  ====================================================================
        //  IStreamBufferInitialize

        STDMETHODIMP
        SetHKEY (
            IN  HKEY    hkeyRoot
            ) ;

        STDMETHODIMP
        SetSIDs (
            IN  DWORD   cSIDs,
            IN  PSID *  ppSID
            ) ;

        //  ====================================================================
        //  IStreamBufferSource

        STDMETHODIMP
        SetStreamSink (
            IN  IStreamBufferSink *     pIStreamBufferSink
            ) ;

        //  ====================================================================
        //  pure virtual methods in base class

        int
        GetPinCount (
            ) ;

        CBasePin *
        GetPin (
            IN  int
            ) ;

        //  ====================================================================
        //  IFileSourceFilter

        STDMETHODIMP
        Load (
            IN  LPCOLESTR               pszFilename,
            IN  const AM_MEDIA_TYPE *   pmt
            ) ;

        STDMETHODIMP
        GetCurFile (
            OUT LPOLESTR *      ppszFilename,
            OUT AM_MEDIA_TYPE * pmt
            ) ;

        //  ====================================================================
        //  IAMFilterMiscFlags method

        STDMETHODIMP_(ULONG)
        GetMiscFlags (
            )
        {
            //  we must implement this interface and return this value if we
            //  want to be selected as graph clock
            return AM_FILTER_MISC_FLAGS_IS_SOURCE ;
        }

        //  ====================================================================
        //  ISpecifyPropertyPages

        STDMETHODIMP
        GetPages (
            CAUUID * pPages
            ) ;

        //  ====================================================================
        //  class-factory method

        static
        CUnknown *
        WINAPI
        CreateInstance (
            IN  IUnknown *  punkControlling,
            IN  HRESULT *   phr
            ) ;
} ;

#endif  //  __dvrplay__dvrplay_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\analysis\mp2frame\dvriframe.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        dvriframe.h

    Abstract:

        This module contains the mpeg-2 I-Frame detection code; part of
            the analysis framework

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#ifndef __analysis__dvriframe_h
#define __analysis__dvriframe_h

extern AMOVIESETUP_FILTER g_sudMpeg2VideoFrame ;

class CMpeg2VideoFrame :
    public CUnknown,
    public IDVRAnalyze,
    public IDVRAnalysisLogicProp
{
    //  ========================================================================
    //
    //  GOP detection:
    //      1. start code prefix "00 00 01"
    //      2. followed by start code "B8"
    //          --> 4 bytes total
    //
    //  I-frame detection:
    //      1. start code prefix "00 00 01"
    //      2. followed by start code "00"
    //      3. followed by 1 byte (don't care):     temporal_reference
    //      4. followed by (bits) "xx00 1xxxx":     mask is 0x38, value is 0x08
    //          --> 6 bytes total
    //
    //  ========================================================================

    enum {
        //  H.262 6.2.2.6
        //  [group_start_code] : 32 bits
        MIN_GOP_HEADER_BUFFER_REQ   = 4,

        //  H.262 6.2.3
        //  [picture_start_code, picture_coding_type] : 45 bits
        MIN_I_FRAME_BUFFER_REQ      = 6,

        //  h.262 6.2.2.1
        //  [sequence_header_code, frame_rate_code] : 64 bits
        MIN_FRAME_RATE_BUFFER_REQ   = 8,
    } ;

    enum {
        //  H.262 6.2.2.6
        //  [group_start_code, next_start_code()]
        MIN_GOP_HEADER_LENGTH       = 8,

        //  H.262 6.2.3
        //  [picture_start_code, next_start_code()]
        MIN_PICTURE_HEADER_LENGTH   = 8,

        //  h.262 6.2.2.1
        //  [sequence_header_code, load_non_intra_quantiser_matrix]
        MIN_SEQ_HEADER_LENGTH       = 12,
    } ;

    enum {
        //  H.262 6.3.3
        //  sequence_header_code
        SEQUENCE_HEADER_START_CODE  = 0xB3,

        //  H.262 6.3.8
        //  group_start_code
        GOP_HEADER_START_CODE       = 0xB8,

        //  H.262 6.3.9
        //  picture_start_code
        PICTURE_HEADER_START_CODE   = 0x00,
    } ;

    enum LAST_MARKED {
        LAST_MARKED_SEQUENCE_HEADER = 1,
        LAST_MARKED_GOP_HEADER      = 2,
        LAST_MARKED_I_FRAME         = 3,
        LAST_MARKED_P_FRAME         = 4,
        LAST_MARKED_B_FRAME         = 5,
        LAST_MARKED_RESTART         = 6,
    } ;

    enum PICTURE_CODING_TYPE {
        I_FRAME     = 1,
        B_FRAME     = 2,
        P_FRAME     = 3,
        OTHER       = 4,            //  i.e. no frame
    } ;

    //  stream states - so we can flag non-boundary packets
    enum MPEG2_STREAM_STATE {
        IN_UNKNOWN_CONTENT,
        IN_I_FRAME,
        IN_P_FRAME,
        IN_B_FRAME
    } ;

    //  H.262, table 6-12
    enum {
        INTRA_CODED_VALUE                       = 0x01,
        PREDICTIVE_CODED_VALUE                  = 0x02,
        BIDIRECTIONALLY_PREDICTIVE_CODED_VALUE  = 0x03,
    } ;

    IDVRPostAnalysisSend *                      m_pIDVRPostAnalysisSend ;
    CRITICAL_SECTION                            m_crt ;
    TSizedDataCache <MIN_I_FRAME_BUFFER_REQ>    m_Cache ;
    CTDynQueue <IDVRAnalysisBuffer *>           m_BufferQueue ;
    LAST_MARKED                                 m_LastMarked ;
    CMpeg2VideoStreamStatsWriter                m_Mpeg2VideoStreamStats ;
    CDVRPolicy *                                m_pPolicy ;
    DWORD                                       m_dwDVRAnalysisMpeg2Video ;
    MPEG2_STREAM_STATE                          m_Mpeg2VideoStreamState ;

    void Lock_ ()       { EnterCriticalSection (& m_crt) ; }
    void Unlock_ ()     { LeaveCriticalSection (& m_crt) ; }

    HRESULT
    CompleteQueuedBuffers_ (
        ) ;

    HRESULT
    Process_ (
        IN  IDVRAnalysisBuffer *,
        OUT BOOL *
        ) ;

    HRESULT
    Complete_ (
        IN  IDVRAnalysisBuffer *
        ) ;

    HRESULT
    QueueBuffer_ (
        IN  IDVRAnalysisBuffer *
        ) ;

    HRESULT
    Restart_ (
        ) ;

    PICTURE_CODING_TYPE
    PictureCodingType_ (
        IN  BYTE *
        ) ;

    HRESULT
    MarkFrameBoundary_ (
        IN  IDVRAnalysisBuffer *    pIDVRAnalysisBuffer,
        IN  DWORD                   dwFrameType,
        IN  LONG                    lBufferOffset
        ) ;

    public :

        CMpeg2VideoFrame (
            IN  IUnknown *  punkControlling,
            OUT HRESULT *   phr
            ) : CUnknown                    (TEXT (DVR_MPEG2_FRAME_ANALYSIS),
                                             punkControlling
                                             ),
                m_LastMarked                (LAST_MARKED_RESTART),
                m_pPolicy                   (NULL),
                m_BufferQueue               (MIN_I_FRAME_BUFFER_REQ),
                m_dwDVRAnalysisMpeg2Video   (0),
                m_Mpeg2VideoStreamState     (IN_UNKNOWN_CONTENT)
        {
            LONG    l ;
            DWORD   dwDisposition ;
            DWORD   dw ;

            (* phr) = S_OK ;

            InitializeCriticalSection (& m_crt) ;

            Restart_ () ;

            m_pPolicy = new CDVRPolicy (REG_DVR_ANALYSIS_LOGIC_MPEG2_VIDEO, phr) ;
            if (!m_pPolicy ||
                FAILED (* phr)) {

                (* phr) = (m_pPolicy ? (* phr) : E_OUTOFMEMORY) ;
                RELEASE_AND_CLEAR (m_pPolicy) ;
                goto cleanup ;
            }

            m_Mpeg2VideoStreamStats.Initialize (m_pPolicy -> Settings () -> StatsEnabled ()) ;

            cleanup :

            return ;
        }

        ~CMpeg2VideoFrame (
            )
        {
            RELEASE_AND_CLEAR (m_pPolicy) ;
            DeleteCriticalSection (& m_crt) ;
        }

        DECLARE_IUNKNOWN ;
        DECLARE_IDVRANALYZE () ;
        DECLARE_IDVRANALYSISLOGICPROP () ;

        STDMETHODIMP
        NonDelegatingQueryInterface (
            IN  REFIID  riid,
            OUT void ** ppv
            ) ;

        static
        CUnknown *
        WINAPI
        CreateInstance (
            IN  IUnknown *  pIUnknown,
            IN  HRESULT *   phr
            ) ;
} ;

#endif  //  __analysis__dvriframe_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dll\sbe.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        sbe.cpp

    Abstract:

        This module contains ts/dvr registration data and entry points

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#include <nt.h>
#include <ntrtl.h>
#include <nturtl.h>
#include <windef.h>
#include <winbase.h>
#include <tchar.h>
#include <limits.h>
#include <delayimp.h>

//  dshow
#include <streams.h>
#include <dvdmedia.h>       //  MPEG2VIDEOINFO

//  WMSDK
#include <wmsdk.h>

#include "dvrdef.h"
#include "dvrfor.h"
#include "dvrtrace.h"
#include "dvrmacros.h"
#include "dvrioidl.h"
#include "sbe.h"

//  link in CLSIDs
#include <initguid.h>

#include "dxmperf.h"

#include "dvranalysis.h"
#include "sbeattrib.h"
#include "dvrdspriv.h"
#include "dvrw32.h"
#include "dvrutil.h"
#include "dvrpolicy.h"
#include "dvranalysis.h"
#include "dvrioidl.h"
#include "dvrperf.h"
#include "MultiGraphHost.h"

//  I-frame analysis COM server
#include "dvriframe.h"

//  analysis filter class factory
#include "dvranalysisfiltercf.h"

//  required for all filters
#include "dvrprof.h"
#include "dvrdsseek.h"
#include "dvrpins.h"
#include "dvrdsrec.h"

//  DVRStreamSink filter
#include "DVRStreamSink.h"

//  DVRPlay filter
#include "DVRPlay.h"

//  all stats info
#include "dvrperf.h"

//  registration templates
CFactoryTemplate
g_Templates[] = {
    //  ========================================================================
    //  analysis: I-frame
    //  code in ..\analysis\iframe
    {   L"Mpeg-2 Video Stream Analysis",                //  display name
        & CLSID_Mpeg2VideoStreamAnalyzer,               //  CLSID
        CMpeg2VideoFrame::CreateInstance,               //  CF CreateInstance method
        NULL,
        & g_sudMpeg2VideoFrame                          //  not dshow related
    },

    //  ========================================================================
    //  filter: StreamBufferStreamSink
    //  code in ..\filters\StreamRWStreamSink
    {   L"StreamBufferSink",                                //  display name
        & CLSID_StreamBufferSink,                           //  CLSID
        CDVRStreamSink::CreateInstance,                     //  CF CreateInstance method
        NULL,
        & g_sudDVRStreamSink
    },

    //  ========================================================================
    //  config COM object
    //  ..\inc\dvrpolicy.h
    {   L"StreamBufferConfig",                              //  display name
        & CLSID_StreamBufferConfig,                         //  CLSID
        CDVRConfigure::CreateInstance,                      //  CF CreateInstance method
        NULL,
        NULL
    },

    //  ========================================================================
    //  recording attributes object
    //  ..\dvrfilters\shared\dvrdsrec.h

    {   L"StreamBufferRecordingAttributes",                 //  display name
        & CLSID_StreamBufferRecordingAttributes,            //  CLSID
        CDVRRecordingAttributes::CreateInstance,            //  CF CreateInstance method
        NULL,
        NULL
    },

    //  ========================================================================
    //  recording composition (concatenation) object
    //  ..\dvrfilters\shared\dvrdsrec.h

    {   L"StreamBufferComposeRecordingObj",                 //  display name
        & CLSID_StreamBufferComposeRecording,               //  CLSID
        CSBECompositionRecording::CreateInstance,           //  CF CreateInstance method
        NULL,
        NULL
    },

    //  ========================================================================
    //  filter: StreamBufferStreamSource
    //  code in ..\filters\DVRPlay
    {   L"StreamBufferSource",                              //  display name
        & CLSID_StreamBufferSource,                         //  CLSID
        CDVRPlay::CreateInstance,                           //  CF CreateInstance method
        NULL,
        & g_sudDVRPlay
    },

    //  ========================================================================
    //  stats: receiver side
    //  code in ..\util\dvrperf.cpp
    {   L"SBE Stats - receiver side",               //  display name
        & CLSID_DVRReceiverSideStats,               //  CLSID
        CDVRReceiveStatsReader::CreateInstance,     //  CF CreateInstance method
        NULL,
        NULL
    },

    //  ========================================================================
    //  stats: send side
    //  code in ..\util\dvrperf.cpp
    {   L"SBE Stats - sender side",                 //  display name
        & CLSID_DVRSenderSideStats,                 //  CLSID
        CDVRSendStatsReader::CreateInstance,        //  CF CreateInstance method
        NULL,
        NULL
    },

    //  ========================================================================
    //  counters: PVRIO
    //  code in ..\util\dvrperf.cpp
    {   L"SBE IO counters",                         //  display name
        & CLSID_PVRIOCounters,                      //  CLSID
        CPVRIOCountersReader::CreateInstance,       //  CF CreateInstance method
        NULL,
        NULL
    },

    //  ========================================================================
    //  stats: mpeg-2 video stream analysis
    //  code in ..\util\dvrperf.cpp
    {   L"SBE Stats - Mpeg2 Video Stream Analysis",     //  display name
        & CLSID_DVRMpeg2VideoStreamAnalysisStats,       //  CLSID
        CMpeg2VideoStreamStatsReader::CreateInstance,   //  CF CreateInstance method
        NULL,
        NULL
    },

    //  ========================================================================
    //  analysis logic filter host's class factory
    //  code in ..\analysis\filtercf
    {   L"SBE Analysis Filter Class Factory",       //  display name
        & CLSID_DVRAnalysisFilterFactory,           //  CLSID
        CDVRAnalysisFilterCF::CreateInstance,       //  CF CreateInstance method
        NULL,
        NULL
    },
} ;

int g_cTemplates = NUMELMS(g_Templates);

//
// DllRegisterSever
//
// Handle the registration of this filter
//
STDAPI DllRegisterServer()
{
    if (!::CheckOS ()) {
        return E_UNEXPECTED ;
    }

    return AMovieDllRegisterServer2 (TRUE);
}

//
// DllUnregsiterServer
//
STDAPI DllUnregisterServer()
{
    return AMovieDllRegisterServer2 (FALSE);
}

//  ============================================================================
//  perf-related follows (largely stolen from quartz.cpp)

extern "C" BOOL WINAPI DllEntryPoint(HINSTANCE hInstance, ULONG ulReason, LPVOID pv);

BOOL
WINAPI
DllMain (
    HINSTANCE   hInstance,
    ULONG       ulReason,
    LPVOID      pv
    )
{
    switch (ulReason)
    {
        case DLL_PROCESS_ATTACH :
            //DVRPerfInit () ;

#ifdef EHOME_WMI_INSTRUMENTATION
            PERFLOG_LOGGING_PARAMS        Params;
            Params.ControlGuid = GUID_DSHOW_CTL;
            Params.OnStateChanged = NULL;
            Params.NumberOfTraceGuids = 1;
            Params.TraceGuids[0].Guid = &GUID_STREAMTRACE;
            PerflogInitIfEnabled( hInstance, &Params );
#endif
            break;

        case DLL_PROCESS_DETACH:
            //DVRPerfUninit () ;
#ifdef EHOME_WMI_INSTRUMENTATION
              PerflogShutdown();
#endif
            break;
    }

    return DllEntryPoint (
                hInstance,
                ulReason,
                pv
                ) ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\shared\dvrclock.cpp ===
/*++

    Copyright (c) 2001  Microsoft Corporation.  All Rights Reserved.

    Module Name:

        clock.cpp

    Abstract:

        This module contains the IReferenceClock implementation

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        24-May-2001     mgates

    Notes:

--*/

#include "dvrall.h"

#include "dvrclock.h"

#pragma warning (disable:4355)

//  ============================================================================
//  CTCClockSlave
//  ============================================================================

template <class HostClock,class MasterClock>
CTCClockSlave <HostClock, MasterClock>::CTCClockSlave <HostClock, MasterClock> (
    IN  CTIGetTime <HostClock> *    pICTGetTime,
    IN  DWORD                       dwBracketMillis,        //  milliseconds per bracket
    IN  MasterClock                 MasterClockFreq,        //  ticks per second
    IN  DWORD                       MinSlavable,            //  min % we consider "slavable"
    IN  DWORD                       MaxSlavable,            //  max % we consider "slavable"
    IN  CDVRSendStatsWriter *       pDVRStats
    ) : m_hcStart           (UNDEFINED),
        m_mcStart           (UNDEFINED),
        m_pICTGetTime       (pICTGetTime),
        m_HostNormalizerVal (0),
        m_HostFreq          (1),
        m_MasterFreq        (MasterClockFreq),
        m_pDVRStats         (pDVRStats),
        m_hcLastReturned    (0),
        m_dInUseRatio       (CLOCKS_SAME_SCALING_VALUE),
        m_Bracket           (pICTGetTime, MasterClockFreq),
        m_dwBracketMillis   (dwBracketMillis),
        m_fSettling         (TRUE),
        m_cResetTicks       (UNDEFINED),
        m_cSettlingTicks    (10 * 1000)
{
    ASSERT (m_pDVRStats) ;

    ::InitializeCriticalSection (& m_crt) ;

    m_HostNormalizerVal = m_pICTGetTime -> SampleClock () ;
    m_HostFreq          = m_pICTGetTime -> GetFreq () ;

    ASSERT (MasterClockFreq != 0) ;

    //  make sure min is <= 1.0 (CLOCKS_SAME_SCALING_VAL)
    m_dMinSlavableRatio = double (Min <DWORD> (100, MinSlavable)) / 100.0 ;

    //  make sure max is >= 1.0 (CLOCKS_SAME_SCALING_VAL)
    m_dMaxSlavableRatio = double (Max <DWORD> (100, MaxSlavable)) / 100.0 ;

    Reset () ;
}

template <class HostClock,class MasterClock>
CTCClockSlave <HostClock, MasterClock>::~CTCClockSlave <HostClock, MasterClock> (
    )
{
    ::DeleteCriticalSection (& m_crt) ;
}

template <class HostClock,class MasterClock>
void
CTCClockSlave <HostClock, MasterClock>::OnMasterTime (
    IN  MasterClock   MasterTime
    )
{
    HostClock   hcNow ;
    double      dBracketRatio ;
    double      dRecomputedRatio ;
    BOOL        fInBoundsBracket ;

    Lock_ () ;

    hcNow = HostTimeNow_ () ;

    //  might still be waiting for our starting tuple; check now
    if (m_mcStart == UNDEFINED) {
        ASSERT (m_hcStart == UNDEFINED) ;
        if (MasterTime != 0) {
            //  save off our starting tuple
            m_mcStart = MasterTime ;
            m_hcStart = hcNow ;

            m_Bracket.Start (MasterTime, hcNow) ;
        }

        //  even if we logged the master time, the delta will be 0, so we
        //    ignore this tuple even if no time has elapsed on the capture
        //    graph
        goto cleanup ;
    }

    //  if our bracket has elapsed
    if (m_Bracket.ElapsedMillis () >= m_dwBracketMillis) {

        if (m_fSettling) {

            if (m_cResetTicks == UNDEFINED) {
                m_cResetTicks = ::timeGetTime () ;
            }

            if (::timeGetTime () - m_cResetTicks >= m_cSettlingTicks) {
                m_fSettling = FALSE ;

                TRACE_3 (LOG_AREA_TIME, 1,
                    TEXT ("out of settling: now = %d; reset = %d; settling = %d"),
                    ::timeGetTime (), m_cResetTicks, m_cSettlingTicks) ;
            }
            else {
                goto cleanup ;
            }
        }

        //  compute the bracket's ratio
        dBracketRatio = m_Bracket.Ratio (MasterTime, hcNow) ;
        fInBoundsBracket = InBounds_ (dBracketRatio) ;

        //  if it's in bounds
        if (fInBoundsBracket) {

            //  compute ratio for lifetime
            dRecomputedRatio = CTRatioBracket <HostClock, MasterClock> ::ComputeRatio (
                                m_mcStart, m_hcStart,
                                MasterTime, hcNow,
                                m_MasterFreq, m_HostFreq
                                ) ;

            //  and if it's in bounds, use it
            if (InBounds_ (dRecomputedRatio)) {
                m_dInUseRatio = dRecomputedRatio ;
                m_pDVRStats -> ClockSlaving () ;
            }
            else {
                m_pDVRStats -> ClockSettling () ;
            }
        }
        else {
            m_pDVRStats -> ClockSettling () ;
        }

        //  start our next bracket, regardless of whether or not we used it
        m_Bracket.Start (MasterTime, hcNow) ;

        m_pDVRStats -> BracketCompleted (dBracketRatio, fInBoundsBracket, m_dInUseRatio) ;
    }

    cleanup :

    Unlock_ () ;
}

template <class HostClock,class MasterClock>
void
CTCClockSlave <HostClock, MasterClock>::Reset (
    )
{
    Lock_ () ;

    m_hcStart           = UNDEFINED ;
    m_mcStart           = UNDEFINED ;
    m_hcLastReturned    = 0 ;
    m_dInUseRatio       = CLOCKS_SAME_SCALING_VALUE ;
    m_fSettling         = TRUE ;
    m_cResetTicks       = UNDEFINED ;

    m_Bracket.Reset () ;

    Unlock_ () ;
}

template <class HostClock,class MasterClock>
HostClock
CTCClockSlave <HostClock, MasterClock>::SlavedTimeNow (
    )
{
    HostClock   hcSlaved ;

    Lock_ () ;

    //  compute ratio of our timeline
    hcSlaved = (HostClock) (((double) HostTimeNow_ ()) * m_dInUseRatio) ;

    //  make sure we never run backwards
    hcSlaved = Max <HostClock> (hcSlaved, m_hcLastReturned) ;
    m_hcLastReturned = hcSlaved ;

    Unlock_ () ;

    return hcSlaved ;
}

//  ============================================================================
//  CDVRClock
//  ============================================================================

CDVRClock::CDVRClock (
    IN  IUnknown *              punkOwning,
    IN  DWORD                   dwSampleBracketMillis,
    IN  DWORD                   MinSlavable,
    IN  DWORD                   MaxSlavable,
    IN  CDVRSendStatsWriter *   pDVRStats,
    OUT HRESULT *               pHr
    ) : m_QPCTicksPerSecond             (1),
        m_hThread                       (NULL),
        m_pAdviseListHead               (NULL),
        m_pAdviseNodeFreePool           (NULL),
        m_uiTimerResolution             (0),
        m_rtGraphStart                  (0),
        m_punkOwning                    (punkOwning),
        m_hEventUnblockThread           (NULL),
        m_fThreadExit                   (FALSE),
        m_ClockSlave                    (this,
                                         dwSampleBracketMillis,
                                         10 * 1000000,              //  wmsdk is 10 Mhz
                                         MinSlavable,
                                         MaxSlavable,
                                         pDVRStats
                                         ),
        m_pDVRStats                     (pDVRStats)
{
    LONG            l ;
    LARGE_INTEGER   li ;
    DWORD           dw ;
    DWORD           dwSlaveMult ;

    TRACE_CONSTRUCTOR (TEXT ("CDVRClock")) ;

    ASSERT (pHr) ;
    ASSERT (m_punkOwning) ;     //  weak ref !!
    ASSERT (m_pDVRStats) ;

    (* pHr) = S_OK ;

    InitializeCriticalSection (& m_crtIRefConfig) ;

    //  need the QPC functionality
    if (QueryPerformanceCounter (& li) == 0 ||
        QueryPerformanceFrequency (& li) == 0) {

        (* pHr) = E_FAIL ;
        goto cleanup ;
    }

    m_hEventUnblockThread = CreateEvent (NULL, TRUE, FALSE, NULL) ;
    if (m_hEventUnblockThread == NULL) {
        dw = GetLastError () ;
        (* pHr) = HRESULT_FROM_WIN32 (dw) ;
        goto cleanup ;
    }

    //  qpc frequency (filter makes sure that QueryPerformance_ calls
    //  succeed on the host system)
    QueryPerformanceFrequency (& li) ;
    m_QPCTicksPerSecond = li.QuadPart ;
    ASSERT (m_QPCTicksPerSecond > 0) ;

    cleanup :

    return ;
}

LONGLONG
CDVRClock::SampleClock (
    )
{
    LARGE_INTEGER   li ;

    QueryPerformanceCounter (& li) ;

    //  ignore the return code of the above call; we check for functionality
    //    in the constructor anyways; if this call fails, constructor of this
    //    object will return a failure, so we won't be "usable"

    return li.QuadPart ;
}

LONGLONG
CDVRClock::GetFreq (
    )
{
    LARGE_INTEGER   li ;
    BOOL            r ;

    r = QueryPerformanceFrequency (& li) ;
    if (!r) {
        //  don't get a divide-by-0..
        li.QuadPart = 1 ;
    }

    return li.QuadPart ;
}

CDVRClock::~CDVRClock (
    )
{
    SINGLE_LIST_ENTRY * pSListEntry ;
    ADVISE_NODE *       pAdviseNode ;
    DWORD               dw ;

    TRACE_DESTRUCTOR (TEXT ("CDVRClock")) ;

    //  exit the thread
    if (m_hThread) {

        //  set these two while holding the lock
        LockIRefConfig_ () ;
        m_fThreadExit = TRUE ;
        SetEvent (m_hEventUnblockThread) ;
        UnlockIRefConfig_ () ;

        WaitForSingleObject (m_hThread, INFINITE) ;
        CloseHandle (m_hThread) ;
    }

    if (m_hEventUnblockThread) {
        CloseHandle (m_hEventUnblockThread) ;
    }

    //  reset the timer resolution
    if (m_uiTimerResolution != 0) {
        timeBeginPeriod (m_uiTimerResolution) ;
    }

    //  free up what's in our free pool list
    while (m_pAdviseNodeFreePool != NULL) {
        //  pull the entry off the front
        pSListEntry = m_pAdviseNodeFreePool ;

        //  advance the list head
        m_pAdviseNodeFreePool  = m_pAdviseNodeFreePool  -> Next ;

        //  free the resources
        pAdviseNode = CONTAINING_RECORD (pSListEntry, ADVISE_NODE, SListEntry) ;
        delete pAdviseNode ;
    }

    //  and in case there are filters that have not canceled their advise requests
    //  we free those too; but we don't expect any
    ASSERT (m_pAdviseListHead == NULL) ;
    while (m_pAdviseListHead != NULL) {
        //  pull entry off the front
        pSListEntry = m_pAdviseListHead ;

        //  move the listhead ahead
        m_pAdviseListHead = m_pAdviseListHead -> Next ;

        //  free the resources
        pAdviseNode = CONTAINING_RECORD (pSListEntry, ADVISE_NODE, SListEntry) ;
        delete pAdviseNode ;
    }

    DeleteCriticalSection (& m_crtIRefConfig) ;
}

void
CDVRClock::AdviseThreadBody (
    )
{
    DWORD           dwWaitRetVal ;
    DWORD           dwWait ;
    REFERENCE_TIME  rtNow ;
    HRESULT         hr ;

    TRACE_ENTER_0 (TEXT ("CDVRClock::AdviseThreadBody ()")) ;

    dwWait = INFINITE ;

    for (;;) {
        dwWaitRetVal = WaitForSingleObject (m_hEventUnblockThread, dwWait) ;

        LockIRefConfig_ () ;

        if (m_fThreadExit) {
            UnlockIRefConfig_ () ;
            break ;
        }

        hr = GetTime (& rtNow) ;
        if (SUCCEEDED (hr)) {
            switch (dwWaitRetVal) {
                case WAIT_TIMEOUT :
                    //  add on 1 millisecond so we won't spin freely if there's another
                    //   advise node that is less than 1 millisecond from now (giving
                    //   us dwWait of 0)
                    dwWait = ProcessNotificationTimeoutLocked_ (rtNow + 10000) ;
                    break ;

                case WAIT_OBJECT_0 :
                    dwWait = ResetWaitTimeLocked_ (rtNow) ;
                    ResetEvent (m_hEventUnblockThread) ;
                    break ;

                default :
                    //  exit on all others - prevents us from spinning at 100% cpu
                    //   in case of some os error
                    m_fThreadExit = TRUE ;
                    break ;
            } ;
        }

        UnlockIRefConfig_ () ;
    }

    return ;
}

void
CDVRClock::QueueAdviseTimeout_ (
    IN  ADVISE_NODE *   pNewAdviseNode
    )
//  must hold the list lock
{
    SINGLE_LIST_ENTRY **    ppCurSListEntry ;
    ADVISE_NODE *           pCurAdviseNode ;

    TRACE_ENTER_0 (TEXT ("CDVRClock::QueueAdviseTimeout_ ()")) ;

    ASSERT (pNewAdviseNode) ;

    //  list is sorted by advise time; find the slot
    for (ppCurSListEntry = & m_pAdviseListHead;
         (* ppCurSListEntry) != NULL;
         ppCurSListEntry = & (* ppCurSListEntry) -> Next) {

        pCurAdviseNode = CONTAINING_RECORD (* ppCurSListEntry, ADVISE_NODE, SListEntry) ;
        if (pCurAdviseNode -> rtAdviseTime >= pNewAdviseNode -> rtAdviseTime) {
            break ;
        }
    }

    //  and insert it
    pNewAdviseNode -> SListEntry.Next = (* ppCurSListEntry) ;
    (* ppCurSListEntry) = & pNewAdviseNode -> SListEntry ;

    m_pDVRStats -> ClockQueuedAdvise () ;
}

HRESULT
CDVRClock::CancelAdviseTimeout_ (
    IN  ADVISE_NODE *   pAdviseNode
    )
//  searches the list of advise nodes, and removes it if found
{
    SINGLE_LIST_ENTRY **    ppCurSListEntry ;
    ADVISE_NODE *           pCurAdviseNode ;

    TRACE_ENTER_0 (TEXT ("CDVRClock::CanceldviseTimeout_ ()")) ;

    //  search from beginning to end for the advise node; unfortunately there's
    //   no way to ensure that the caller has not given us a bogus pointer
    for (ppCurSListEntry = & m_pAdviseListHead;
         (* ppCurSListEntry) != NULL;
         ppCurSListEntry = & ((* ppCurSListEntry) -> Next)) {

        pCurAdviseNode = CONTAINING_RECORD (*ppCurSListEntry, ADVISE_NODE, SListEntry) ;

        if (pCurAdviseNode == pAdviseNode) {

            //  unhook
            (* ppCurSListEntry) = pCurAdviseNode -> SListEntry.Next ;
            RecycleAdviseNode_ (pCurAdviseNode) ;

            //  success
            return S_OK ;
        }
    }

    //  failure
    return E_FAIL ;
}

DWORD
CDVRClock::ProcessNotificationTimeoutLocked_ (
    IN  REFERENCE_TIME  rtNow
    )
//  locks held: list lock
{
    SINGLE_LIST_ENTRY * pSListEntry ;
    ADVISE_NODE *       pAdviseNode ;
    REFERENCE_TIME      rtDelta ;
    LONG                lPreviousCount ;

    TRACE_ENTER_1 (TEXT ("CDVRClock::ProcessNotificationTimeoutLocked_ (%016I64x)"), rtNow) ;

    for (pSListEntry = m_pAdviseListHead ;
         pSListEntry != NULL ;
         pSListEntry = m_pAdviseListHead) {

        //  recover the advise_node
        pAdviseNode = CONTAINING_RECORD (pSListEntry, ADVISE_NODE, SListEntry) ;

        //  break from the loop if we are into notifications which must be
        //   signaled in the future.
        if (pAdviseNode -> rtAdviseTime > rtNow) {
            break ;
        }

        //  the list head points to a node that has a notification that must be made
        //  now or in the past

        //  and remove it from the front
        m_pAdviseListHead = pAdviseNode -> SListEntry.Next ;

        //  if it's a period advise
        if (pAdviseNode -> rtPeriodTime != 0) {
            //  signal the semaphore
            ReleaseSemaphore (
                pAdviseNode -> hSignal,
                1,
                & lPreviousCount
                ) ;

            m_pDVRStats -> ClockSignaledAdvise () ;

            #ifdef DEBUG
            REFERENCE_TIME  rtNowDbg ;
            REFERENCE_TIME  rtDeltaDbg ;
            HRESULT         hr ;
            hr = GetTime (& rtNowDbg) ;
            rtDeltaDbg = rtNowDbg - pAdviseNode -> rtAdviseTime ;
            TRACE_4 (LOG_AREA_TIME, 9,
                TEXT ("Periodic: now - advise = %10I64d %5I64d; %08xh; %08xh"),
                rtDeltaDbg, DShowTimeToMilliseconds (rtDeltaDbg), pAdviseNode -> hSignal, hr) ;
            #endif

            //  increment to the next time we need to notify
            pAdviseNode -> rtAdviseTime += pAdviseNode -> rtPeriodTime ;

            //  and queue for the next timeout
            QueueAdviseTimeout_ (
                pAdviseNode
                ) ;
        }
        else {
            //  otherwise, it's a one shot notification

            //  signal the event
            SetEvent (pAdviseNode -> hSignal) ;

            m_pDVRStats -> ClockSignaledAdvise () ;

            #ifdef DEBUG
            REFERENCE_TIME  rtNowDbg2 ;
            REFERENCE_TIME  rtDeltaDbg2 ;
            HRESULT         hr ;
            hr = GetTime (& rtNowDbg2) ;
            rtDeltaDbg2 = rtNowDbg2 - pAdviseNode -> rtAdviseTime ;
            TRACE_4 (LOG_AREA_TIME, 9,
                TEXT ("Single: now - advise = %10I64d %5I64d; %08xh; %08xh"),
                rtDeltaDbg2, DShowTimeToMilliseconds (rtDeltaDbg2), pAdviseNode -> hSignal, hr) ;
            #endif

            RecycleAdviseNode_ (pAdviseNode) ;
        }
    }

    return ResetWaitTimeLocked_ (rtNow) ;
}

DWORD
CDVRClock::ResetWaitTimeLocked_ (
    IN  REFERENCE_TIME  rtNow
    )
//  locks held: list lock
{
    REFERENCE_TIME  rtDelta ;
    ADVISE_NODE *   pAdviseNode ;

    TRACE_ENTER_0 (TEXT ("CDVRClock::ResetWaitTimeLocked_ ()")) ;

    //  figure out how long we must wait until the next one
    if (m_pAdviseListHead) {
        pAdviseNode = CONTAINING_RECORD (m_pAdviseListHead, ADVISE_NODE, SListEntry) ;
        rtDelta = pAdviseNode -> rtAdviseTime > rtNow ? pAdviseNode -> rtAdviseTime - rtNow : 0 ;

        TRACE_3 (LOG_AREA_TIME, 9,
            TEXT ("WaitNext() : rtAdviseTime = %I64d, rtNow = %I64d, rtAdviseTime - rtNow = %I64d"),
            pAdviseNode -> rtAdviseTime, rtNow, pAdviseNode -> rtAdviseTime - rtNow) ;

        //  safe cast because we are dealing with a delta vs. an absolute time
        return (DWORD) ::DShowTimeToMilliseconds (rtDelta) ;
    }
    else {
        //  there are none queued to be processed; wait infinitely long
        return INFINITE ;
    }
}

HRESULT
CDVRClock::AdvisePeriodicLocked_ (
    IN  REFERENCE_TIME  rtStartTime,
    IN  REFERENCE_TIME  rtPeriodTime,
    IN  HANDLE          hSemaphore,
    OUT DWORD_PTR *     pdwpContext
    )
{
    ADVISE_NODE *   pAdviseNode ;
    HRESULT         hr ;

    TRACE_ENTER_4 (TEXT ("CDVRClock::AdvisePeriodicLocked_ (%016I64x, %016I64x, %08xh, %8xh)"), rtStartTime, rtPeriodTime, hSemaphore, pdwpContext) ;

    //  confirm that this is a valid request
    if (rtStartTime     < 0     ||
        rtPeriodTime    <= 0    ||
        rtStartTime     == MAX_REFERENCE_TIME) {

        return E_INVALIDARG ;
    }

    //  make sure our advisory thread is up and running
    hr = ConfirmAdviseThreadRunning_ () ;
    if (FAILED (hr)) {
        return hr ;
    }

    //  get a node
    pAdviseNode = GetAdviseNode_ () ;
    if (pAdviseNode == NULL) {
        return E_OUTOFMEMORY ;
    }

    //  set the fields
    pAdviseNode -> hSignal      = hSemaphore ;
    pAdviseNode -> rtAdviseTime = rtStartTime ;
    pAdviseNode -> rtPeriodTime = rtPeriodTime ;

    QueueAdviseTimeout_ (pAdviseNode) ;

    //  if we inserted at the head, processing thread will need to reset its
    //   wait period
    if (m_pAdviseListHead == & pAdviseNode -> SListEntry) {
        SetEvent (m_hEventUnblockThread) ;
    }

    (* pdwpContext) = (DWORD_PTR) pAdviseNode ;

    return S_OK ;
}

HRESULT
CDVRClock::AdviseTimeLocked_ (
    IN  REFERENCE_TIME  rtBaseTime,
    IN  REFERENCE_TIME  rtStreamTime,
    IN  HANDLE          hEvent,
    OUT DWORD_PTR *     pdwpContext
    )
{
    ADVISE_NODE *   pAdviseNode ;
    REFERENCE_TIME  rtAdviseTime ;
    REFERENCE_TIME  rtNow ;
    HRESULT         hr ;

    TRACE_ENTER_4 (TEXT ("CDVRClock::AdviseTimeLocked_ (%016I64x, %016I64x, %08xh, %8xh)"), rtBaseTime, rtStreamTime, hEvent, pdwpContext) ;

    //  confirm that this is a valid request
    rtAdviseTime = rtBaseTime + rtStreamTime ;
    if (rtAdviseTime    <= 0                    ||
        rtAdviseTime    == MAX_REFERENCE_TIME   ||
        rtStreamTime    < 0) {

        return E_INVALIDARG ;
    }

    //  check for an advise time that's now or in the past; if this is the case
    //   we don't need to queue anything
    hr = GetTime (& rtNow) ;
    if (SUCCEEDED (hr) &&
        rtAdviseTime <= rtNow) {

        m_pDVRStats -> ClockStaleAdvise () ;

        //  already there; signal & return
        SetEvent (hEvent) ;
        return hr ;
    }

    //  make sure our advisory thread is up and running
    hr = ConfirmAdviseThreadRunning_ () ;
    if (FAILED (hr)) {
        return hr ;
    }

    //  get a node
    pAdviseNode = GetAdviseNode_ () ;
    if (pAdviseNode == NULL) {
        return E_OUTOFMEMORY ;
    }

    //  set the fields
    pAdviseNode -> hSignal      = hEvent ;
    pAdviseNode -> rtAdviseTime = rtAdviseTime ;

    ASSERT (pAdviseNode -> rtPeriodTime == 0) ;

    QueueAdviseTimeout_ (pAdviseNode) ;

    //  if we inserted at the head, processing thread will need to reset its
    //   wait period
    if (m_pAdviseListHead == & pAdviseNode -> SListEntry) {
        SetEvent (m_hEventUnblockThread) ;
    }

    (* pdwpContext) = (DWORD_PTR) pAdviseNode ;

    return S_OK ;
}

//  ============================================================================
//      CDVRClock
//  ============================================================================

STDMETHODIMP
CDVRClock::QueryInterface (
    IN  REFIID  riid,
    OUT void ** ppv
    )
{
    //  delegate always
    return m_punkOwning -> QueryInterface (riid, ppv) ;
}

STDMETHODIMP_(ULONG)
CDVRClock::AddRef (
    )
{
    //  delegate always
    return m_punkOwning -> AddRef () ;
}

STDMETHODIMP_(ULONG)
CDVRClock::Release (
    )
{
    //  delegate always
    return m_punkOwning -> Release () ;
}

STDMETHODIMP
CDVRClock::AdvisePeriodic (
    IN  REFERENCE_TIME  rtStartTime,
    IN  REFERENCE_TIME  rtPeriodTime,
    IN  HSEMAPHORE      hSemaphore,
    OUT DWORD_PTR *     pdwpContext
    )
{
    HRESULT hr ;

    TRACE_ENTER_0 (TEXT ("CDVRClock::AdvisePeriodic ()")) ;

    //  validate the parameters
    if (pdwpContext     == NULL ||
        hSemaphore      == NULL ||
        rtPeriodTime    == 0) {

        return E_INVALIDARG ;
    }

    LockIRefConfig_ () ;
    hr = AdvisePeriodicLocked_ (
            rtStartTime,
            rtPeriodTime,
            reinterpret_cast <HANDLE> (hSemaphore),
            pdwpContext
            ) ;
    UnlockIRefConfig_ () ;

    return hr ;
}

STDMETHODIMP
CDVRClock::AdviseTime (
    IN  REFERENCE_TIME  rtBaseTime,
    IN  REFERENCE_TIME  rtStreamTime,
    IN  HEVENT          hEvent,
    OUT DWORD_PTR *     pdwpContext
    )
{
    HRESULT hr ;

    TRACE_ENTER_0 (TEXT ("CDVRClock::AdviseTime ()")) ;

    if (hEvent      == NULL ||
        pdwpContext == NULL) {

        return E_INVALIDARG ;
    }

    LockIRefConfig_ () ;
    hr = AdviseTimeLocked_ (
            rtBaseTime,
            rtStreamTime,
            reinterpret_cast <HANDLE> (hEvent),
            pdwpContext
            ) ;
    UnlockIRefConfig_ () ;

    return hr ;
}

STDMETHODIMP
CDVRClock::GetTime (
    OUT REFERENCE_TIME *    pTime
    )
/*++
    purpose:
    parameters:
    return values:
    notes:
--*/
{
    LONGLONG    llNow ;

    TRACE_ENTER_0 (TEXT ("CDVRClock::GetTime ()")) ;

    if (pTime == NULL) {
        return E_POINTER ;
    }

    llNow = m_ClockSlave.SlavedTimeNow () ;

    //  set the return value & scale
    (* pTime) = QPCToDShow (llNow, m_QPCTicksPerSecond) ;

    //  make sure we return a time that is no earlier than graph start;
    //  filtergraph pads the start time (first call to ::GetTime) by 10 ms
    //  to allow each filter to get up and running; if we blindly return
    //  the time before that first 10 ms has elapsed, we'll start the whole
    //  graph up in catchup mode
    (* pTime) = Max <REFERENCE_TIME> (m_rtGraphStart, (* pTime)) ;

    return S_OK ;
}

STDMETHODIMP
CDVRClock::Unadvise (
    IN  DWORD_PTR   dwpContext
    )
{
    HRESULT hr ;

    TRACE_ENTER_0 (TEXT ("CDVRClock::Unadvise ()")) ;

    if (dwpContext == 0) {
        return E_INVALIDARG ;
    }

    LockIRefConfig_ () ;
    hr = CancelAdviseTimeout_ (reinterpret_cast <ADVISE_NODE *> (dwpContext)) ;
    UnlockIRefConfig_ () ;

    return hr ;
}

void
CDVRClock::FilterStateChanged (
    IN  FILTER_STATE    OldFilterState,
    IN  FILTER_STATE    NewFilterState,
    IN  REFERENCE_TIME  rtStart             //  0 if not start run
    )
{
    TRACE_ENTER_2 (TEXT ("CDVRClock::FilterStateChanged (%08xh, %08xh)"), OldFilterState, NewFilterState) ;

    switch (NewFilterState) {
        case State_Running :

            //  not sure if it's possible to get ::Run twice .. should be an
            //   assert if it isn't
            if (OldFilterState != State_Running) {
                m_ClockSlave.Reset () ;
                m_rtGraphStart = rtStart ;
            }

            break ;

        case State_Paused :
            break ;

        case State_Stopped :
            m_rtGraphStart = 0 ;
            break ;
    } ;
}

void
CDVRClock::OnSample (
    IN  QWORD * pcnsStream           //  stream time
    )
{
    m_ClockSlave.OnMasterTime (* pcnsStream) ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\dvrstreamsink\dvrstreamsink.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        DVRStreamSink.cpp

    Abstract:

        This module contains the DVRStreamSink filter code.

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#include "dvrall.h"

#include "dvrprof.h"            //  WM Profiles
#include "dvrdsseek.h"          //  pins reference seeking interfaces
#include "dvrpins.h"            //  pins & pin collections
#include "dvrdswrite.h"         //  writer
#include "DVRStreamSink.h"      //  filter declarations
#include "dvrdsrec.h"           //  recordings object

//  disable so we can use 'this' in the initializer list
#pragma warning (disable:4355)

AMOVIESETUP_FILTER
g_sudDVRStreamSink = {
    & CLSID_StreamBufferSink,
    TEXT (STREAMBUFFER_SINK_FILTER_NAME),
    MERIT_DO_NOT_USE,
    0,                                          //  no pins advertized
    NULL                                        //  no pins details
} ;

//  ============================================================================

CDVRStreamSink::CDVRStreamSink (
    IN  IUnknown *  punkControlling,
    IN  REFCLSID    rclsid,
    OUT HRESULT *   phr
    ) : CBaseFilter     (TEXT (STREAMBUFFER_SINK_FILTER_NAME),
                         punkControlling,
                         new CCritSec,
                         rclsid
                         ),
        m_pInputPins    (NULL),
        m_pWriteManager (NULL),
        m_pDVRWriter    (NULL),
        m_pPolicy       (NULL)
{
    LONG    l ;
    DWORD   dwDisposition ;
    DWORD   dw ;

    TRACE_CONSTRUCTOR (TEXT ("CDVRStreamSink")) ;

    m_pPolicy = new CDVRPolicy (REG_DVR_STREAM_SINK_ROOT, phr) ;

    if (!m_pLock ||
        !m_pPolicy ||
        FAILED (* phr)) {

        (* phr) = E_FAIL ;
        goto cleanup ;
    }

    m_pWriteManager = new CDVRWriteManager (
                            m_pPolicy,
                            phr
                            ) ;
    if (!m_pWriteManager) {
        (* phr) = E_OUTOFMEMORY ;
        goto cleanup ;
    }
    else if (FAILED (* phr)) {
        delete m_pWriteManager ;
        m_pWriteManager = NULL ;
        goto cleanup ;
    }

    m_pInputPins = new CDVRSinkPinManager (
                            m_pPolicy,
                            this,
                            m_pLock,
                            & m_RecvLock,
                            m_pWriteManager,
                            phr
                            ) ;
    if (!m_pInputPins ||
        FAILED (* phr)) {

        (* phr) = (m_pInputPins ? (* phr) : E_OUTOFMEMORY) ;
        goto cleanup ;
    }

    //  need at least 1 input pin to successfully instantiate
    (* phr) = (m_pInputPins -> PinCount () > 0 ? S_OK : E_FAIL) ;

    cleanup :

    return ;
}

CDVRStreamSink::~CDVRStreamSink (
    )
{
    CBasePin *  pPin ;
    int         i ;

    TRACE_DESTRUCTOR (TEXT ("CDVRStreamSink")) ;

    SetWriterInactive_ () ;
    ASSERT (m_pDVRWriter == NULL) ;

    //  clear out the input pins
    if (m_pInputPins) {
        i = 0 ;
        do {
            pPin = m_pInputPins -> GetPin (i++) ;
            delete pPin ;
        } while (pPin) ;
    }

    delete m_pInputPins ;
    delete m_pWriteManager ;

    RELEASE_AND_CLEAR (m_pPolicy) ;
}

STDMETHODIMP
CDVRStreamSink::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    OUT void ** ppv
    )
{
    //  ------------------------------------------------------------------------
    //  ISpecifyPropertyPages; allows an app to enumerate CLSIDs for our
    //   property pages

    if (riid == IID_ISpecifyPropertyPages) {

        return GetInterface (
                    (ISpecifyPropertyPages *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IStreamBufferSink

    if (riid == IID_IStreamBufferSink) {

        return GetInterface (
                    (IStreamBufferSink *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IStreamBufferInitialize

    if (riid == IID_IStreamBufferInitialize) {

        return GetInterface (
                    (IStreamBufferInitialize *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IDVRStreamSinkPriv

    if (riid == IID_IDVRStreamSinkPriv) {

        if (m_pDVRWriter) {
            return GetInterface (
                        (IDVRStreamSinkPriv *) m_pDVRWriter,
                        ppv
                        ) ;
        }
        else {
            return E_UNEXPECTED ;
        }
    }

    return CBaseFilter::NonDelegatingQueryInterface (riid, ppv) ;
}

int
CDVRStreamSink::GetPinCount (
    )
{
    int i ;

    TRACE_ENTER_0 (TEXT ("CDVRStreamSink::GetPinCount ()")) ;

    m_pLock -> Lock () ;

    //  input + output pins
    i = m_pInputPins -> PinCount () ;

    m_pLock -> Unlock () ;

    return i ;
}

CBasePin *
CDVRStreamSink::GetPin (
    IN  int iIndex
    )
{
    CBasePin *  pPin ;
    DWORD       dw ;

    TRACE_ENTER_1 (
        TEXT ("CDVRStreamSink::GetPin (%d)"),
        iIndex
        ) ;

    m_pLock -> Lock () ;

    pPin = m_pInputPins -> GetPin (
            iIndex
            ) ;

    //
    //  don't refcount the pin; this is one of dshow's quazi-COM calls
    //

    m_pLock -> Unlock () ;

    return pPin ;
}

STDMETHODIMP
CDVRStreamSink::GetPages (
    CAUUID * pPages
    )
{
    HRESULT hr ;

    if (pPages) {
        pPages -> cElems = 1 ;
        pPages -> pElems = reinterpret_cast <GUID *> (CoTaskMemAlloc (pPages -> cElems * sizeof GUID)) ;

        if (pPages -> pElems) {
            (pPages -> pElems) [0] = CLSID_DVRStreamSinkProp ;
            hr = S_OK ;
        }
        else {
            hr = E_OUTOFMEMORY ;
        }
    }
    else {
        hr = E_POINTER ;
    }

    return hr ;
}

CUnknown *
WINAPI
CDVRStreamSink::CreateInstance (
    IN  IUnknown *  punkControlling,
    IN  HRESULT *   phr
    )
{
    CDVRStreamSink *    pCDVRStreamSink ;

    TRACE_ENTER_0 (TEXT ("CDVRStreamSink::CreateInstance ()")) ;

    pCDVRStreamSink = NULL ;

    if (::CheckOS ()) {
        pCDVRStreamSink = new CDVRStreamSink (
                                punkControlling,
                                CLSID_StreamBufferSink,
                                phr
                                ) ;
        if (!pCDVRStreamSink) {
            (* phr) = E_OUTOFMEMORY ;
        }
        else if (FAILED (* phr)) {
            DELETE_RESET (pCDVRStreamSink) ;
        }
    }
    else {
        (* phr) = E_FAIL ;
    }

    return pCDVRStreamSink ;
}

STDMETHODIMP
CDVRStreamSink::SetSIDs (
    IN  DWORD   cSIDs,
    IN  PSID *  ppSID
    )
{
    HRESULT hr ;

    if (!ppSID) {
        return E_POINTER ;
    }

    FilterLock_ () ;

    ASSERT (m_pPolicy) ;
    hr = m_pPolicy -> SetSIDs (cSIDs, ppSID) ;

    FilterUnlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRStreamSink::SetHKEY (
    IN  HKEY    hkeyRoot
    )
{
    HRESULT hr ;

    if (m_pDVRWriter) {
        hr = E_UNEXPECTED ;
        return hr ;
    }

    FilterLock_ () ;

    ASSERT (m_pPolicy) ;
    hr = m_pPolicy -> SetRootHKEY (hkeyRoot, REG_DVR_STREAM_SINK_ROOT) ;

    FilterUnlock_ () ;

    return hr ;
}

CDVRWriter *
CDVRStreamSink::GetWriter_ (
    IN  IWMProfile *    pIWMProfile,
    IN  LPCWSTR         pszDVRDirectory,        //  can be NULL
    IN  LPCWSTR         pszDVRFilename          //  can be NULL
    )
{
    HRESULT         hr ;
    CDVRWriter *    pWMWriter ;

    ASSERT (m_pWriteManager) ;

    //  don't inline attributes
    pWMWriter = new CDVRIOWriter (
                        m_pWriteManager -> PVRIOCounters (),
                        static_cast <IStreamBufferSink *> (this),       //  punk, MH forces us to pick
                        m_pPolicy,
                        pIWMProfile,
                        pszDVRDirectory,
                        pszDVRFilename,
                        & hr
                        ) ;

    if (!pWMWriter ||
        FAILED (hr)) {

        DELETE_RESET (pWMWriter) ;
    }

    return pWMWriter ;
}

HRESULT
CDVRStreamSink::SetWriterActive_ (
    )
{
    HRESULT hr ;

    hr = LockProfile (NULL) ;
    if (SUCCEEDED (hr)) {
        ASSERT (m_pDVRWriter) ;
        hr = m_pWriteManager -> Active (
                m_pDVRWriter,
                m_pClock
                ) ;

        if (SUCCEEDED (hr)) {
            m_pWriteManager -> StartStreaming () ;
        }
    }

    return hr ;
}

HRESULT
CDVRStreamSink::SetWriterInactive_ (
    )
{
    HRESULT hr ;

    if (m_pWriteManager) {
        hr = m_pWriteManager -> Inactive () ;
    }
    else {
        hr = S_OK ;
    }

    DELETE_RESET (m_pDVRWriter) ;

    return hr ;
}

STDMETHODIMP
CDVRStreamSink::Pause (
    )
{
    HRESULT hr ;

    //  must have a graph clock
    if (!m_pClock) {
        return E_FAIL ;
    }

    FilterLock_ () ;

    if (m_State == State_Stopped) {

        //  stopped -> paused

        //  don't try to activate the writer unless we've got at least 1
        //   stream; if this check was not here, an inert DVRStreamSink sitting
        //   in a filtergraph would prevent it from running
        if (m_pInputPins -> GetProfileStreamCount () > 0) {
            hr = SetWriterActive_ () ;
        }
        else {
            hr = S_OK ;
        }

        if (SUCCEEDED (hr)) {
            hr = m_pInputPins -> Active () ;
        }

        m_pPolicy -> EventSink () -> Initialize (m_pGraph) ;
    }
    else {
        //  run -> paused

        //  BUGBUG: we're a rendering filter, so we really need to pause here
        hr = S_OK ;
    }

    if (SUCCEEDED (hr)) {
        m_State = State_Paused ;
    }

    FilterUnlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRStreamSink::Stop (
    )
{
    HRESULT hr ;

    hr = S_OK ;

    RecvLock_ () ;
    FilterLock_ () ;

    hr = SetWriterInactive_ () ;
    if (SUCCEEDED (hr)) {
        hr = m_pInputPins -> Inactive () ;
        m_pPolicy -> EventSink () -> Initialize (NULL) ;
        if (SUCCEEDED (hr)) {
            m_State = State_Stopped ;
        }
    }

    FilterUnlock_ () ;
    RecvUnlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRStreamSink::Run (
    IN  REFERENCE_TIME  rtStart
    )
{
    if (!m_pDVRWriter) {
        ASSERT (m_pInputPins -> GetProfileStreamCount () == 0) ;
    }

    return CBaseFilter::Run (rtStart) ;
}

STDMETHODIMP
CDVRStreamSink::CreateRecorder (
    IN  LPCWSTR     pszFilename,
    IN  DWORD       dwRecordType,
    OUT IUnknown ** ppRecordingIUnknown
    )
{
    HRESULT         hr ;
    CDVRRecording * pDVRRecording ;
    IDVRRecorder *  pIDVRRecorder ;
    DWORD           dwFlags ;

    if (!ppRecordingIUnknown) {
        return E_POINTER ;
    }

    if (!pszFilename) {
        return E_INVALIDARG ;
    }

    //  set the flags we're going to send down the DVRIO layer
    switch (dwRecordType) {
        case RECORDING_TYPE_CONTENT :
            dwFlags = 0 ;
            break ;

        case RECORDING_TYPE_REFERENCE :
            dwFlags = (DVR_RECORDING_FLAG_MULTI_FILE_RECORDING |
                       DVR_RECORDING_FLAG_PERSISTENT_RECORDING) ;
            break ;

        default :
            return E_INVALIDARG ;
    } ;

    FilterLock_ () ;

    if (m_pDVRWriter) {
        hr = m_pDVRWriter -> CreateRecorder (
                pszFilename,
                dwFlags,
                & pIDVRRecorder
                ) ;

        if (SUCCEEDED (hr)) {

            //  instantiate the right type of a recording
            switch (dwRecordType) {
                case RECORDING_TYPE_CONTENT :
                    pDVRRecording = new CDVRContentRecording (
                                            m_pPolicy,
                                            pIDVRRecorder,
                                            m_pDVRWriter -> GetID (),
                                            m_pWriteManager,
                                            & m_RecvLock,
                                            GetOwner ()
                                            ) ;

                    TRACE_1 (LOG_AREA_RECORDING, 1,
                         TEXT ("CDVRStreamSink::CreateRecorder (); created CONTENT recording: %s"),
                         pszFilename
                         ) ;

                    break ;

                case RECORDING_TYPE_REFERENCE :
                    pDVRRecording = new CDVRReferenceRecording (
                                            m_pPolicy,
                                            pIDVRRecorder,
                                            m_pDVRWriter -> GetID (),
                                            m_pWriteManager,
                                            & m_RecvLock,
                                            GetOwner ()
                                            ) ;

                    TRACE_1 (LOG_AREA_RECORDING, 1,
                         TEXT ("CDVRStreamSink::CreateRecorder (); created REFERENCE recording: %s"),
                         pszFilename
                         ) ;

                    break ;

                default :
                    ASSERT (0) ;
                    pDVRRecording = NULL ;
                    break ;
            } ;

            if (pDVRRecording) {
                (* ppRecordingIUnknown) = NULL ;
                hr = pDVRRecording -> QueryInterface (IID_IUnknown, (void **) ppRecordingIUnknown) ;
            }
            else {
                hr = E_OUTOFMEMORY ;
            }

            pIDVRRecorder -> Release () ;
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    FilterUnlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRStreamSink::LockProfile (
    IN  LPCWSTR pszDVRFilename
    )
{
    HRESULT         hr ;
    IWMProfile *    pIWMProfile ;

    FilterLock_ () ;

    if (m_pDVRWriter == NULL) {
        if (m_pInputPins -> GetProfileStreamCount () > 0) {
            hr = m_pInputPins -> GetRefdWMProfile (& pIWMProfile) ;
            if (SUCCEEDED (hr)) {
                ASSERT (pIWMProfile) ;

                //  returns ref'd writer
                m_pDVRWriter = GetWriter_ (
                                    pIWMProfile,
                                    NULL,               //  use registry-specified directory
                                    pszDVRFilename
                                    ) ;

                if (!m_pDVRWriter) {
                    hr = E_FAIL ;
                }

                pIWMProfile -> Release () ;
            }
        }
        else {
            //  must have at least 1 stream in order to lock the profile
            hr = VFW_E_UNSUPPORTED_STREAM ;
        }

        if (FAILED (hr) &&
            m_pDVRWriter) {

            DELETE_RESET (m_pDVRWriter) ;
        }
    }
    else if (pszDVRFilename) {

        //  already locked; caller has specified a filename, which means they're
        //    trying to lock it after having locked it already; if this is a
        //    state transition for the filter, these parameters will be NULL
        //    and we'll be fine with whatever has been used to lock the profile;
        //    we then won't hit this clause

        hr = E_UNEXPECTED ;
    }
    else {
        //  already locked
        hr = S_OK ;
    }

    FilterUnlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRStreamSink::IsProfileLocked (
    )
{
    HRESULT         hr ;

    FilterLock_ () ;

    if (m_pDVRWriter == NULL) {
        // not locked
        hr = S_FALSE;
    }
    else {
        //  already locked
        hr = S_OK ;
    }

    FilterUnlock_ () ;

    return hr ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\dvrstreamsink\dvrstreamsink.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        DVRStreamSink.h

    Abstract:

        This module contains the DVRStreamSink filter declarations.

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        01-Feb-2001     created

--*/

#ifndef __DVRStreamSink__DVRStreamSink_h
#define __DVRStreamSink__DVRStreamSink_h

extern AMOVIESETUP_FILTER   g_sudDVRStreamSink ;

class CDVRStreamSink :
    public CBaseFilter,             //  dshow base classes
    public ISpecifyPropertyPages,
    public IStreamBufferSink,
    public IStreamBufferInitialize
{
    CDVRSinkPinManager *    m_pInputPins ;
    CDVRWriteManager *      m_pWriteManager ;
    CDVRPolicy *            m_pPolicy ;
    CDVRWriter *            m_pDVRWriter ;
    CCritSec                m_RecvLock ;

    //  if both: RECV lock first

    void FilterLock_ ()     { m_pLock -> Lock () ;      }
    void FilterUnlock_ ()   { m_pLock -> Unlock () ;    }

    void RecvLock_ ()       { m_RecvLock.Lock () ; }
    void RecvUnlock_ ()     { m_RecvLock.Unlock () ; }

    HRESULT
    SetWriterActive_ (
        ) ;

    HRESULT
    SetWriterInactive_ (
        ) ;

    CDVRWriter *
    GetWriter_ (
        IN  IWMProfile *    pIWMProfile,
        IN  LPCWSTR         pszDVRDirectory,        //  can be NULL
        IN  LPCWSTR         pszDVRFilename          //  can be NULL
        ) ;

    public :

        CDVRStreamSink (
            IN  IUnknown *  punkControlling,
            IN  REFCLSID    rclsid,
            OUT HRESULT *   phr
            ) ;

        ~CDVRStreamSink (
            ) ;

        DECLARE_IUNKNOWN ;

        STDMETHODIMP
        NonDelegatingQueryInterface (
            IN  REFIID  riid,
            OUT void ** ppv
            ) ;

        //  ====================================================================
        //  IStreamBufferInitialize

        STDMETHODIMP
        SetHKEY (
            IN  HKEY    hkeyRoot
            ) ;

        STDMETHODIMP
        SetSIDs (
            IN  DWORD   cSIDs,
            IN  PSID *  ppSID
            ) ;

        //  ====================================================================
        //  IStreamBufferSink methods

        STDMETHODIMP
        CreateRecorder (
            IN  LPCWSTR     pszFilename,
            IN  DWORD       dwReserved,
            OUT IUnknown ** ppRecordingIUnknown
            ) ;

        STDMETHODIMP
        LockProfile (
            IN  LPCWSTR pszDVRFilename
            ) ;

        STDMETHODIMP
        IsProfileLocked (
            ) ;

        //  ====================================================================
        //  pure virtual methods in base class

        int
        GetPinCount (
            ) ;

        CBasePin *
        GetPin (
            IN  int
            ) ;

        STDMETHODIMP
        Pause (
            ) ;

        STDMETHODIMP
        Stop (
            ) ;

        STDMETHODIMP
        Run (
            IN  REFERENCE_TIME  rtStart
            ) ;

        //  ====================================================================
        //  ISpecifyPropertyPages
        STDMETHODIMP
        GetPages (
            CAUUID * pPages
            ) ;

        //  ====================================================================
        //  class-factory method

        static
        CUnknown *
        WINAPI
        CreateInstance (
            IN  IUnknown *  punkControlling,
            IN  HRESULT *   phr
            ) ;
} ;

#endif  //  __DVRStreamSink__DVRStreamSink_h
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\shared\dvrclock.h ===
/*++

    Copyright (c) 2001  Microsoft Corporation.  All Rights Reserved.

    Module Name:

        dvrclock.h

    Abstract:

        This module contains the IReferenceClock declarations and the clock
          slaving

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        24-May-2001     mgates
        14-Aug-2001     mgates      added clock slaving

    Notes:

        How clock slaving works
        =======================

        We want to compute a scaling value that we apply to calls to GetTime ().
        The scaling value is applied to host-based clock deltas, and will scale
        them in such a way that they increment at a rate = master clock.

        Definitions:
        ------------------------------------------------------------------------
        "host clock" : a host-based high-performance multimedia timer that we
                        will scale to the master clock

        "host time" : value obtained by sampling the host clock

        "master clock" : remote clock; we'll slave to this

        "master time" : value obtained by sampling the master clock

        Scaling value:
        ------------------------------------------------------------------------
        We compute a scaling value for every bracket (default duration is
        2000ms).  When the bracket completes, we measure the scaling value of
        the bracket, and recompute the lifetime scaling value if the bracket
        is within bounds, and use the lifetime ration if the bracket is within
        bounds.
--*/

//  ============================================================================
//  ============================================================================

template <class T>
class CTIGetTime
{
    public :

        virtual T SampleClock () = 0 ;      //  can wrap
        virtual T GetFreq () = 0 ;      //  in ticks/sec; cannot change per run
} ;

//  ============================================================================
//  ============================================================================

template <
    class HostClock,        //  host clock; ratio slaves this clock to the master clock
    class MasterClock       //  master clock; we'll have a ratio that is host-slaved to this
    >
class CTCClockSlave
{
    enum {
        ADJUST_REFRESH_MILLIS = 2000
    } ;

    //  not serialized
    template <
        class HostClock,
        class MasterClock
        >
    class CTRatioBracket
    {
        MasterClock m_mcTimeStart ;
        MasterClock m_mcFreq ;
        HostClock   m_hcTimeStart ;
        HostClock   m_hcFreq ;
        DWORD       m_dwStartTicks ;

        public :

            CTRatioBracket (
                IN  CTIGetTime <HostClock> *    pICTGetTime,
                IN  MasterClock                 mcFreq
                ) : m_mcTimeStart   (UNDEFINED),
                    m_mcFreq        (mcFreq),
                    m_hcTimeStart   (UNDEFINED),
                    m_hcFreq        (1)
            {
                ASSERT (pICTGetTime) ;
                m_hcFreq = pICTGetTime -> GetFreq () ;
                m_dwStartTicks = UNDEFINED ;
            }

            void
            Reset (
                )
            {
                m_mcTimeStart   = UNDEFINED ;
                m_hcTimeStart   = UNDEFINED ;
            }

            void
            Start (
                IN  MasterClock mcTime,
                IN  HostClock   hcTime
                )
            {
                m_mcTimeStart = mcTime ;
                m_hcTimeStart = hcTime ;
                m_dwStartTicks = ::timeGetTime () ;
            }

            DWORD
            ElapsedMillis (
                )
            {
                if (m_dwStartTicks != UNDEFINED) {
                    return ::timeGetTime () - m_dwStartTicks ;
                }
                else {
                    return 0 ;
                }
            }

            double
            Ratio (
                IN  MasterClock mcTime,
                IN  HostClock   hcTime
                )
            {
                ASSERT (m_mcTimeStart != UNDEFINED) ;
                ASSERT (m_hcTimeStart != UNDEFINED) ;

                return ComputeRatio (
                            m_mcTimeStart, m_hcTimeStart,
                            mcTime, hcTime,
                            m_mcFreq, m_hcFreq
                            ) ;
            }

            static
            double
            ComputeRatio (
                IN  MasterClock mcTimeStart,
                IN  HostClock   hcHostStart,
                IN  MasterClock mcTimeEnd,
                IN  HostClock   hcTimeEnd,
                IN  MasterClock mcFreq,
                IN  HostClock   hcFreq
                )
            {

                double  dmcDelta ;
                double  dhcDelta ;
                double  dRatio ;

                dmcDelta = (double) (mcTimeEnd - mcTimeStart) / (double) mcFreq ;
                dhcDelta = (double) (hcTimeEnd - hcHostStart) / (double) hcFreq ;

                if (dhcDelta != 0) {
                    dRatio = dmcDelta / dhcDelta ;
                }
                else {
                    //  strange..
                    dRatio = 2 ;
                }

                return dRatio ;
            }
    } ;

    CTRatioBracket <HostClock, MasterClock> m_Bracket ;
    HostClock                               m_hcStart ;
    MasterClock                             m_mcStart ;
    CRITICAL_SECTION                        m_crt ;
    CTIGetTime <HostClock> *                m_pICTGetTime ;
    HostClock                               m_HostNormalizerVal ;
    HostClock                               m_HostFreq ;
    MasterClock                             m_MasterFreq ;
    CDVRSendStatsWriter *                   m_pDVRStats ;
    double                                  m_dMinSlavableRatio ;
    double                                  m_dMaxSlavableRatio ;
    double                                  m_dInUseRatio ;
    HostClock                               m_hcLastReturned ;
    DWORD                                   m_dwBracketMillis ;
    BOOL                                    m_fSettling ;
    DWORD                                   m_cResetTicks ;
    DWORD                                   m_cSettlingTicks ;

    void Lock_ ()       { ::EnterCriticalSection (& m_crt) ; }
    void Unlock_ ()     { ::LeaveCriticalSection (& m_crt) ; }

    HostClock
    HostTimeNow_ (
        )
    {
        return m_pICTGetTime -> SampleClock () - m_HostNormalizerVal ;
    }

    BOOL
    InBounds_ (
        IN  double  dRatio
        )
    {
        return (dRatio >= m_dMinSlavableRatio &&
                dRatio <= m_dMaxSlavableRatio) ;

    }

    public :

        CTCClockSlave (
            IN  CTIGetTime <HostClock> *    pICTGetTime,
            IN  DWORD                       dwBracketMillis,        //  milliseconds per bracket
            IN  MasterClock                 MasterClockFreq,        //  ticks per second
            IN  DWORD                       MinSlavable,            //  min % we consider "slavable"
            IN  DWORD                       MaxSlavable,            //  max % we consider "slavable"
            IN  CDVRSendStatsWriter *       pDVRStats
            ) ;

        ~CTCClockSlave (
            ) ;

        void
        OnMasterTime (
            IN  MasterClock   MasterTime
            ) ;

        void
        Reset (
            ) ;

        //  guaranteed to never run backwards
        HostClock
        SlavedTimeNow (
            ) ;
} ;

//  ============================================================================
//  ============================================================================

class CDVRClock :
    public IReferenceClock,         //  reference clock interface
    public CTIGetTime <LONGLONG>
{
    struct ADVISE_NODE {
        SINGLE_LIST_ENTRY   SListEntry ;        //  link
        HANDLE              hSignal ;           //  semaphore or event
        REFERENCE_TIME      rtAdviseTime ;      //  when to advise
        REFERENCE_TIME      rtPeriodTime ;      //  what the period is; 0 in non-periodic advise nodes
    } ;

    CDVRSendStatsWriter *   m_pDVRStats ;
    IUnknown *              m_punkOwning ;                      //  always aggregated; weak ref !!
    REFERENCE_TIME          m_rtGraphStart ;                    //  graph start time; ::GetTime() returns 0 if earlier than this
    SINGLE_LIST_ENTRY *     m_pAdviseListHead ;                 //  list head to the advise list nodes
    SINGLE_LIST_ENTRY *     m_pAdviseNodeFreePool ;             //  list head to free pool of list nodes
    HANDLE                  m_hThread ;                         //  adviser thread
    HANDLE                  m_hEventUnblockThread ;             //  new advise has been posted
    BOOL                    m_fThreadExit ;                     //  TRUE if the thread must exit
    CRITICAL_SECTION        m_crtIRefConfig ;                   //  IReferenceClock configuration lock
    CRITICAL_SECTION        m_crtGetTime ;                      //  IReferenceClock::GetTime () lock
    LONGLONG                m_QPCTicksPerSecond ;               //  set at initialization to scale the qpc-raw numbers
    UINT                    m_uiTimerResolution ;               //  for timeBeginPeriod and timeEndPeriod calls

    CTCClockSlave <LONGLONG, QWORD> m_ClockSlave ;

    void LockIRefConfig_ ()     { EnterCriticalSection (& m_crtIRefConfig) ; }
    void UnlockIRefConfig_ ()   { LeaveCriticalSection (& m_crtIRefConfig) ; }

    HRESULT
    ConfirmAdviseThreadRunning_ (
        )
    {
        TIMECAPS    tc ;
        MMRESULT    mmRes ;
        DWORD       dw ;

        if (m_hThread == NULL) {

            m_fThreadExit = FALSE ;

            mmRes = timeGetDevCaps (& tc, sizeof tc) ;
            if (mmRes == TIMERR_NOERROR) {
                m_uiTimerResolution = tc.wPeriodMin ;
            }
            else {
                m_uiTimerResolution = 1 ;
            }

            timeBeginPeriod (m_uiTimerResolution) ;

            m_hThread = CreateThread (
                            NULL,                       //  security
                            0,                          //  calling thread's stack size
                            CDVRClock::ThreadEntry,     //  entry point
                            (LPVOID) this,              //  parameter
                            NULL,                       //  flags
                            NULL                        //  thread id
                            ) ;

            if (m_hThread == NULL) {
                //  failure
                dw = GetLastError () ;
                return HRESULT_FROM_WIN32 (dw) ;
            }

            SetThreadPriority (m_hThread, THREAD_PRIORITY_TIME_CRITICAL) ;
        }

        ASSERT (m_hEventUnblockThread != NULL) ;

        //  thread is running
        return S_OK ;
    }

    //  returns the milliseconds until the next timeout
    DWORD
    ProcessNotificationTimeoutLocked_ (
        IN  REFERENCE_TIME  rtNow
        ) ;

    //  returns the milliseconds until the next timeout
    DWORD
    ResetWaitTimeLocked_ (
        IN  REFERENCE_TIME  rtNow
        ) ;

    HRESULT
    AdvisePeriodicLocked_ (
        IN  REFERENCE_TIME  rtStartTime,
        IN  REFERENCE_TIME  rtPeriodTime,
        IN  HANDLE          hSemaphore,
        OUT DWORD_PTR *     pdwpContext
        ) ;

    HRESULT
    AdviseTimeLocked_ (
        IN  REFERENCE_TIME  rtBaseTime,
        IN  REFERENCE_TIME  rtStreamTime,
        IN  HANDLE          hEvent,
        OUT DWORD_PTR *     pdwpContext
        ) ;

    void
    QueueAdviseTimeout_ (
        IN  ADVISE_NODE *   pAdviseNode
        ) ;

    HRESULT
    CancelAdviseTimeout_ (
        IN  ADVISE_NODE *   pAdviseNode
        ) ;

    ADVISE_NODE *
    GetAdviseNode_ (
        )
    //  locks held: the list lock
    {
        ADVISE_NODE *       pAdviseNode ;
        SINGLE_LIST_ENTRY * pSListEntry ;

        if (m_pAdviseNodeFreePool != NULL) {

            pSListEntry = m_pAdviseNodeFreePool ;
            m_pAdviseNodeFreePool = m_pAdviseNodeFreePool -> Next ;

            pAdviseNode = CONTAINING_RECORD (pSListEntry, ADVISE_NODE, SListEntry) ;
            ZeroMemory (pAdviseNode, sizeof ADVISE_NODE) ;
        }
        else {
            pAdviseNode = new ADVISE_NODE ;
            if (pAdviseNode) {
                ZeroMemory (pAdviseNode, sizeof ADVISE_NODE) ;
            }
        }

        return pAdviseNode ;
    }

    void
    RecycleAdviseNode_ (
        IN  ADVISE_NODE *   pAdviseNode
        )
    //  locks held: the list lock
    {
        ASSERT (pAdviseNode) ;
        pAdviseNode -> SListEntry.Next = m_pAdviseNodeFreePool ;
        m_pAdviseNodeFreePool = & pAdviseNode -> SListEntry ;
    }

    void
    UnblockAllWaitingLocked_ (
        ) ;

    public :

        CDVRClock (
            IN  IUnknown *              punkOwning,
            IN  DWORD                   dwSampleBracketMillis,
            IN  DWORD                   MinSlavable,
            IN  DWORD                   MaxSlavable,
            IN  CDVRSendStatsWriter *   pDVRStats,
            OUT HRESULT *               pHr
            ) ;

        ~CDVRClock (
            ) ;

        //  -------------------------------------------------------------------
        //  called by the filter when there's a graph state transition

        void
        FilterStateChanged (
            IN  FILTER_STATE    OldFilterState,
            IN  FILTER_STATE    NewFilterState,
            IN  REFERENCE_TIME  rtStart             //  0 if not start run
            ) ;

        void
        OnSample (
            IN  QWORD * cnsMasterTime
            ) ;

        void Reset ()           { m_ClockSlave.Reset () ; }

        //  -------------------------------------------------------------------
        //  clock sampling interface; used by the clock slaving module

        virtual
        LONGLONG
        SampleClock (
            ) ;

        virtual
        LONGLONG
        GetFreq (
            ) ;

        //  -------------------------------------------------------------------
        //  Advise thread entry point and worker method

        void
        AdviseThreadBody (
            ) ;

        static
        DWORD
        WINAPI
        ThreadEntry (
            IN  LPVOID  pv
            )
        {
            (reinterpret_cast <CDVRClock *> (pv)) -> AdviseThreadBody () ;
            return EXIT_SUCCESS ;
        }

        //  -------------------------------------------------------------------
        //  IReferenceClock methods, including IUnknown

        STDMETHODIMP
        QueryInterface (
            IN  REFIID  riid,
            OUT void ** ppv
            ) ;

        STDMETHODIMP_(ULONG)
        AddRef (
            ) ;

        STDMETHODIMP_(ULONG)
        Release (
            ) ;

        STDMETHODIMP
        AdvisePeriodic (
            IN  REFERENCE_TIME  rtStartTime,
            IN  REFERENCE_TIME  rtPeriodTime,
            IN  HSEMAPHORE      hSemaphore,
            OUT DWORD_PTR *     pdwpContext
            ) ;

        STDMETHODIMP
        AdviseTime (
            IN  REFERENCE_TIME  rtBaseTime,
            IN  REFERENCE_TIME  rtStreamTime,
            IN  HEVENT          hEvent,
            OUT DWORD_PTR *     pdwpContext
            ) ;

        STDMETHODIMP
        GetTime (
            OUT REFERENCE_TIME *    pTime
            ) ;

        STDMETHODIMP
        Unadvise (
            IN  DWORD_PTR   dwpContext
            ) ;
} ;
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\shared\dvrdsread.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        dvrdsread.cpp

    Abstract:

        This module contains the code for our reading layer.

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        02-Apr-2001     created

--*/

#include "dvrall.h"

#include "dvrprof.h"
#include "dvrdsseek.h"          //  pins reference seeking interfaces
#include "dvrpins.h"
#include "dvrdsread.h"
#include "dvrclock.h"

#pragma warning (disable:4355)

//  ============================================================================
//  CDVRDShowReader
//  ============================================================================

CDVRDShowReader::CDVRDShowReader (
    IN  CDVRPolicy *        pPolicy,
    IN  IDVRReader *        pIDVRReader,
    OUT HRESULT *           phr
    ) : m_pIDVRReader   (pIDVRReader),
        m_pPolicy     (pPolicy)
{
    ASSERT (m_pIDVRReader) ;
    m_pIDVRReader -> AddRef () ;

    ASSERT (m_pPolicy) ;
    m_pPolicy -> AddRef () ;

    (* phr) = S_OK ;

    return ;
}

CDVRDShowReader::~CDVRDShowReader (
    )
{
    m_pPolicy -> Release () ;
    m_pIDVRReader -> Release () ;
}

HRESULT
CDVRDShowReader::GetRefdReaderProfile (
    OUT CDVRReaderProfile **    ppDVRReaderProfile
    )
{
    HRESULT hr ;

    ASSERT (ppDVRReaderProfile) ;

    //  this is a low frequency operation, so it's ok to allocate
    (* ppDVRReaderProfile) = new CDVRReaderProfile (m_pPolicy, m_pIDVRReader, & hr) ;
    if (!(* ppDVRReaderProfile) ||
        FAILED (hr)) {

        hr = ((* ppDVRReaderProfile) ? hr : E_OUTOFMEMORY) ;
        DELETE_RESET (* ppDVRReaderProfile) ;
    }

    return hr ;
}

HRESULT
CDVRDShowReader::Read (
    OUT INSSBuffer **   ppINSSBuffer,
    OUT QWORD *         pcnsStreamTimeOfSample,
    OUT QWORD *         pcnsSampleDuration,
    OUT DWORD *         pdwFlags,
    OUT WORD *          pwStreamNum
    )
{
    QWORD qwDuration;

    ASSERT (m_pIDVRReader) ;
    return m_pIDVRReader -> GetNextSample (
                ppINSSBuffer,
                pcnsStreamTimeOfSample,
                pcnsSampleDuration,
                pdwFlags,
                pwStreamNum
                ) ;
}

//  ============================================================================
//  CDVRDReaderThread
//  ============================================================================

HRESULT
CDVRDReaderThread::ThreadCmd_ (
    IN  DWORD   dwCmd
    )
{
    HRESULT hr ;

    //
    //  caller must lock & unlock wrt calls to CmdWait !!
    //

    if (ThreadExists ()) {

        //  send to the worker thread
        m_dwParam = dwCmd ;
        m_EventSend.Set() ;

        //  but don't wait for him to ack

        hr = S_OK ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

HRESULT
CDVRDReaderThread::CmdWaitAck_ (
    IN  DWORD   dwCmd
    )
{
    HRESULT hr ;

    //
    //  caller must lock & unlock wrt calls to ThreadCmd !!
    //

    if (ThreadExists ()) {

        //  make sure we're waiting on the right command
        if (m_dwParam == dwCmd) {
            // wait for the completion to be signalled
            m_EventComplete.Wait() ;

            // done - this is the thread's return value
            hr = HRESULT_FROM_WIN32 (m_dwReturnVal) ;
        }
        else {
            hr = E_UNEXPECTED ;
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

HRESULT
CDVRDReaderThread::WaitThreadExited_ (
    )
{
    HRESULT hr ;

    ASSERT (m_dwParam == THREAD_MSG_EXIT) ;

    if (m_hThread) {
        WaitForSingleObject (m_hThread, INFINITE) ;
        CloseHandle (m_hThread) ;
        m_hThread = NULL ;
        hr = S_OK ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

HRESULT
CDVRDReaderThread::StartThread_ (
    IN  DWORD   dwInitialCmd
    )
{
    BOOL    r ;
    HRESULT hr ;

    m_AccessLock.Lock () ;

    r = Create () ;
    if (!r && !ThreadExists ()) {
        hr = E_FAIL ;
        goto cleanup ;
    }

    hr = ThreadCmdWaitAck_ (dwInitialCmd) ;

    cleanup :

    m_AccessLock.Unlock () ;

    return hr ;
}

void
CDVRDReaderThread::RuntimeThreadProc_ (
    )
{
    DWORD   dw ;
    HRESULT hr ;

    hr = S_OK ;

    while (SUCCEEDED (hr) &&
           !CheckRequest (& dw)) {

        hr = m_pHost -> Process () ;
        if (FAILED (hr) &&
            !CheckRequest (& dw)) {

            TRACE_ERROR_1 (TEXT ("CDVRDReaderThread::RuntimeThreadProc_ : ReadWrapAndSend_ returned %08xh"), hr) ;

            hr = m_pHost -> ErrorHandler (hr) ;
            if (FAILED (hr)             &&
                !CheckRequest (& dw)    &&
                !m_pHost -> IsFlushing ()) {

                //  send out an event if nobody is trying to issue a request
                //    and we've encountered an unrecoverable error; the case
                //    here is always that we'll park ourselves without someone
                //    requesting it;
                m_pHost -> OnFatalError (hr) ;
            }
        }

        TRACE_1 (LOG_AREA_DSHOW, 8,
            TEXT ("CDVRDReaderThread::RuntimeThreadProc_ () : thread return code = %08hx"),
            hr) ;
    }
}

DWORD
CDVRDReaderThread::ThreadProc (
    )
{
    DWORD   dwCmd ;
    DWORD   dwRet ;

    for (;;) {

        dwCmd = GetRequest () ;

        switch (dwCmd) {
            case THREAD_MSG_EXIT :
                Reply (S_OK) ;
                return 0 ;

            case THREAD_MSG_GO_PAUSED :
            case THREAD_MSG_PAUSE :
                Reply (S_OK) ;
                break ;

            case THREAD_MSG_GO :
                Reply (S_OK) ;
                RuntimeThreadProc_ () ;
                break ;

            default :
                return 0 ;
        } ;
    }
}

//  ============================================================================
//  CDVRReadController
//  ============================================================================

CDVRReadController::CDVRReadController (
    IN  CDVRReadManager *       pDVRReadManager,
    IN  CDVRSourcePinManager *  pDVRSourcePinManager,
    IN  CDVRPolicy *            pPolicy,
    IN  CDVRSendStatsWriter *   pDVRSendStatsWriter,
    IN  DWORD                   dwMaxSeekingProbeMillis
    ) : m_pDVRReadManager           (pDVRReadManager),
        m_pDVRSourcePinManager      (pDVRSourcePinManager),
        m_pPolicy                   (pPolicy),
        m_pDVRSendStatsWriter       (pDVRSendStatsWriter),
        m_dwMaxSeekFailureProbes    (0)
{
    ASSERT (m_pDVRReadManager) ;
    ASSERT (m_pDVRSourcePinManager) ;
    ASSERT (m_pPolicy) ;
    ASSERT (m_pDVRSendStatsWriter) ;
    ASSERT (m_pPolicy -> Settings () -> IndexGranularityMillis () != 0) ;

    m_pPolicy -> AddRef () ;

    m_dwMaxSeekFailureProbes = ::AlignUp <DWORD> (dwMaxSeekingProbeMillis, m_pPolicy -> Settings () -> IndexGranularityMillis ()) /
                               m_pPolicy -> Settings () -> IndexGranularityMillis () ;
}

CDVRReadController::~CDVRReadController (
    )
{
    InternalFlush_ () ;
    m_pPolicy -> Release () ;
}

HRESULT
CDVRReadController::ErrorHandler (
    IN  HRESULT hr
    )
{
    switch (hr) {
        case NS_E_NO_MORE_SAMPLES :

            TRACE_0 (LOG_AREA_DSHOW, 1,
                TEXT ("CDVRReadController::ErrorHandler got NS_E_NO_MORE_SAMPLES, calling OnEndOfStream_ ()")) ;

            OnEndOfStream_ () ;
            //  leave the failure code so the reader thread exits upon
            //    return
            break ;

        case VFW_E_SAMPLE_REJECTED :
            //  we're probably on a new segment boundary and just tried to
            //   send down a sample that was rejected because it is not
            //   acceptable as a first media sample of a segment
            hr = S_OK ;

            TRACE_0 (LOG_AREA_DSHOW, 1,
                TEXT ("CDVRReadController::ErrorHandler got VFW_E_SAMPLE_REJECTED, setting hr to S_OK")) ;

            break ;

        case VFW_E_CHANGING_FORMAT :
            //  dynamic format change failed; don't fail if there is more than
            //    1 pin in our source manager
            if (m_pDVRSourcePinManager -> SendingPinCount () > 1) {
                hr = S_OK ;

                TRACE_0 (LOG_AREA_DSHOW, 1,
                    TEXT ("CDVRReadController::ErrorHandler got VFW_E_CHANGING_FORMAT, setting hr = S_OK")) ;
            }
            else {
                TRACE_0 (LOG_AREA_DSHOW, 1,
                    TEXT ("CDVRReadController::ErrorHandler got VFW_E_CHANGING_FORMAT, no other sending pins - propagating error back out")) ;
            }

            break ;

        case VFW_E_DVD_WRONG_SPEED :
            //  tried to set a speed that the decoder rejected; since the speed
            //    is applied asynchronously to the call, the call might succeed,
            //    but the actual operation (on the next key frame boundary) may
            //    fail, and this is what has happened here; try to set it to
            //    the default (1x) speed
            hr = m_pDVRReadManager -> ConfigureForRate (_1X_PLAYBACK_RATE) ;

            TRACE_1 (LOG_AREA_DSHOW, 1,
                TEXT ("CDVRReadController::ErrorHandler got VFW_E_DVD_WRONG_SPEED; attempted rate reset to %1.1f"),
                _1X_PLAYBACK_RATE) ;

            break ;

        case HRESULT_FROM_WIN32 (ERROR_SEEK_ON_DEVICE) :
            //  this might be recoverable if we're not at 1x and the reader
            //    thread was trying to seek forward or backwards during trick
            //    mode play; this error can occur if there's any type of seeking
            //    error such as when this error is returned out of DVRIO (i.e.
            //    from a WMSDK NS_E_INVALID_REQUEST error), or if a timehole was
            //    too big to try to probe across (i.e. it was bigger than our
            //    normal seekahead/back and we could not crank the seek delta
            //    up sufficiently to cross it); in all cases, from our current
            //    position we try to return to 1x play; may or may not succeed
            if (m_pDVRReadManager -> GetPlaybackRate () != _1X_PLAYBACK_RATE) {
                TRACE_0 (LOG_AREA_SEEKING_AND_TRICK, 1,
                    TEXT ("CDVRReadController::ErrorHandler got HRESULT_FROM_WIN32 (ERROR_SEEK_ON_DEVICE); attempting to return to 1x")) ;

                hr = m_pDVRReadManager -> ConfigureForRate (_1X_PLAYBACK_RATE) ;
            }

            break ;

        default :

            TRACE_1 (LOG_AREA_DSHOW, 1,
                TEXT ("CDVRReadController::ErrorHandler got %08xh, calling ReadControllerFailure_"),
                hr) ;

            //  all others are punted to child classes
            hr = ReadFailure_ (hr) ;
            break ;
    }

    TRACE_1 (LOG_AREA_DSHOW, 1,
        TEXT ("CDVRReadController::ErrorHandler : returning %08xh"),
        hr) ;

    return hr ;
}

HRESULT
CDVRReadController::SendSample_ (
    IN  IMediaSample2 * pIMediaSample2,
    IN  CDVROutputPin * pDVROutputPin,
    IN  AM_MEDIA_TYPE * pmtNew,
    IN  QWORD           cnsStreamTime
    )
{
    HRESULT         hr ;
    REFERENCE_TIME  rtNow ;

    hr = pDVROutputPin -> SendSample (pIMediaSample2, pmtNew) ;

    SampleSent (
        hr,
        pIMediaSample2
        ) ;

    rtNow = m_pDVRReadManager -> RefTime () ;

    m_pDVRSendStatsWriter -> SampleOut (
        hr,
        pDVROutputPin -> GetBankStoreIndex (),
        pIMediaSample2,
        & rtNow
        )  ;

    return hr ;
}

HRESULT
CDVRReadController::SetWithinContentBoundaries_ (
    IN OUT  QWORD * pcnsOffset
    )
{
    return m_pDVRReadManager -> CheckSetStartWithinContentBoundaries (pcnsOffset) ;
}

HRESULT
CDVRReadController::Seek_ (
    IN OUT  QWORD * pcnsSeekRequest
    )
{
    HRESULT hr ;
    QWORD   cnsSeekTo ;
    QWORD   cnsSeekToDesired ;
    DWORD   i ;
    QWORD   cnsLastSeek ;
    BOOL    r ;

    ASSERT (pcnsSeekRequest) ;
    ASSERT (m_pDVRReadManager) ;

    cnsSeekToDesired    = (* pcnsSeekRequest) ;
    i                   = 0 ;
    cnsLastSeek         = MAXQWORD ;

    do {
        //  make the seek
        cnsSeekTo = cnsSeekToDesired ;
        hr = m_pDVRReadManager -> SeekReader (& cnsSeekTo) ;
        if (SUCCEEDED (hr)) {
            //  if that succeeded; set the outgoing and break from the loop
            (* pcnsSeekRequest) = cnsSeekTo ;
            break ;
        }
        else if (hr == HRESULT_FROM_WIN32 (ERROR_SEEK_ON_DEVICE)) {

            //  well-known error; we get this if we might seek into content that
            //    is not valid e.g. at the end of a TEMP file there may be no
            //    content but our end marker has it on the logical timeline in
            //    which case we ask for a seek into non-valid content

            TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                     TEXT ("Invalid seeking offset ; %u, %I64d ms"),
                     i, ::WMSDKTimeToMilliseconds (cnsSeekToDesired)
                     ) ;

            //  make sure it's within bounds before updating to our next seek
            //    offset; controllers determine if we're going forward or
            //    backwards
            hr = SetWithinContentBoundaries_ (& cnsSeekToDesired) ;
            if (SUCCEEDED (hr)) {

                //  adjust (forward or backwards; this is a virtual call)
                r = SeekOnDeviceFailure_Adjust (& cnsSeekToDesired) ;
                if (r) {
                    //  check for the case that we've just been adjusted to the same
                    //    position we last seeked to; we're obviously done trying to
                    //    probe in that case;
                    if (cnsSeekToDesired == cnsLastSeek) {
                        hr = HRESULT_FROM_WIN32 (ERROR_SEEK_ON_DEVICE) ;
                        break ;
                    }

                    //  remember this position so we can check for duplicate
                    //    seek case we handle in the clause above
                    cnsLastSeek = cnsSeekToDesired ;
                }
                else {
                    //  fail the call outright
                    hr = HRESULT_FROM_WIN32 (ERROR_SEEK_ON_DEVICE) ;
                    break ;
                }
            }
            else {
                //  fail the call outright
                hr = HRESULT_FROM_WIN32 (ERROR_SEEK_ON_DEVICE) ;
                break ;
            }
        }
        else {
            //  some other failure that we cannot recover from here; bail
            break ;
        }

    } while (i++ < m_dwMaxSeekFailureProbes) ;

    return hr ;
}

//  ============================================================================
//  CDVR_Forward_ReadController
//  ============================================================================

CDVR_Forward_ReadController::CDVR_Forward_ReadController (
    IN  CDVRReadManager *       pDVRReadManager,
    IN  CDVRSourcePinManager *  pDVRSourcePinManager,
    IN  CDVRPolicy *            pPolicy,
    IN  CDVRSendStatsWriter *   pDVRSendStatsWriter
    ) : CDVRReadController          (pDVRReadManager,
                                     pDVRSourcePinManager,
                                     pPolicy,
                                     pDVRSendStatsWriter,
                                     pPolicy -> Settings () -> F_MaxSeekingProbeMillis ()
                                     ),
        m_cnsCheckTimeRemaining     (DShowToWMSDKTime (MAX_REFERENCE_TIME)) {}

HRESULT
CDVR_Forward_ReadController::CheckForContentOverrun_ (
    IN      QWORD   cnsCurrentRead,
    IN OUT  QWORD * pcnsSeekAhead   //  IN  current; OUT new
    )
{
    QWORD           cnsStart ;
    QWORD           cnsCurEOF ;
    HRESULT         hr ;
    REFERENCE_TIME  rtCurStreamtime ;
    REFERENCE_TIME  rtEOF ;

    if (cnsCurrentRead >= m_cnsCheckTimeRemaining) {

        //  only perform this check on a sustained basis if we're at > 1x
        //    playback speed
        if (m_pDVRReadManager -> GetPlaybackRate () > _1X_PLAYBACK_RATE) {

            //  update the EOF time
            hr = m_pDVRReadManager -> GetReaderContentBoundaries (
                    & cnsStart,
                    & cnsCurEOF
                    ) ;

            TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                TEXT ("CDVR_Forward_ReadController::CheckForContentOverrun_ () -- updating EOF; old = %I64d ms; newly queried EOF = %I64d ms"),
                m_cnsCheckTimeRemaining, cnsCurEOF) ;

            if (SUCCEEDED (hr)) {

                //  if we're within the threshold go back to 1x
                ASSERT (cnsCurEOF >= cnsCurrentRead) ;

                //  ------------------------------------------------------------
                //  first make sure we don't try to seek ahead out of bounds of
                //   the file

                if (ARGUMENT_PRESENT (pcnsSeekAhead)) {
                    if ((cnsCurEOF - cnsCurrentRead) <= (* pcnsSeekAhead)) {
                        //  stop seek aheads since we'd seek beyond the current
                        //    content

                        TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 1,
                            TEXT ("CDVR_Forward_ReadController::CheckForContentOverrun_ () closing on live & stopping seekaheads; %I64d ms --> 0 ms"),
                            ::WMSDKTimeToMilliseconds (* pcnsSeekAhead)) ;

                        (* pcnsSeekAhead) = 0 ;
                    }
                }

                //  ------------------------------------------------------------
                //  next check if it's time to revert to 1x

                //  EOF
                rtEOF = ::WMSDKToDShowTime (cnsCurEOF) ;

                //  check the playtime against the PTS and see if we are
                //    within the threshold whereby we revert to 1x play
                hr = m_pDVRReadManager -> GetCurStreamtime (& rtCurStreamtime) ;
                if (SUCCEEDED (hr)) {

                    TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                        TEXT ("CDVR_Forward_ReadController::CheckForContentOverrun_ () -- > checking (eof = %I64d ms; stream = %I64d ms)"),
                        ::DShowTimeToMilliseconds (rtEOF), ::DShowTimeToMilliseconds (rtCurStreamtime)) ;

                    //  if our playtime (computed) has exceeded the EOF (actual), or
                    //    if EOF & playtime are within our threshold, then
                    //    go back to 1x
                    if (rtCurStreamtime >= rtEOF ||
                        ::DShowTimeToMilliseconds (rtEOF - rtCurStreamtime) <= BACK_TO_1X_THRESHOLD_MILLIS) {

                        //  BUGBUG: if greater than, really should resync the clock so it's current with what we're reading in

                        TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                            TEXT ("CDVR_Forward_ReadController::CheckForContentOverrun_ () -- > caught up to live (eof = %I64d ms; stream = %I64d ms) slowing to 1x"),
                        ::DShowTimeToMilliseconds (rtEOF), ::DShowTimeToMilliseconds (rtCurStreamtime)) ;

                        hr = m_pDVRReadManager -> ConfigureForRate (_1X_PLAYBACK_RATE) ;
                    }
                }

                //  we'll check next at this time
                m_cnsCheckTimeRemaining = cnsCurEOF ;
            }
        }
        else {
            //  push this out so we don't check it again
            m_cnsCheckTimeRemaining = MAX_REFERENCE_TIME ;

            //  and succeed the call
            hr = S_OK ;
        }
    }
    else {
        //  not yet caught up to our next checkpoint
        hr = S_OK ;
    }

    return hr ;
}

BOOL
CDVR_Forward_ReadController::SeekOnDeviceFailure_Adjust (
    IN OUT QWORD *  pcnsSeek
    )
{
    ASSERT (pcnsSeek) ;

    //  move forward (but don't wrap)
    (* pcnsSeek) += Min <QWORD> (
                        ::MillisToWMSDKTime (m_pPolicy -> Settings () -> IndexGranularityMillis ()),
                        MAXQWORD - (* pcnsSeek)
                        ) ;

    return TRUE ;
}

//  ============================================================================
//  CDVR_F_KeyFrame_ReadController
//  ============================================================================

CDVR_F_KeyFrame_ReadController::CDVR_F_KeyFrame_ReadController (
    IN  CDVRReadManager *       pDVRReadManager,
    IN  CDVRSourcePinManager *  pDVRSourcePinManager,
    IN  CDVRPolicy *            pPolicy,
    IN  CDVRSendStatsWriter *   pDVRSendStatsWriter
    ) : CDVR_Forward_ReadController (pDVRReadManager,
                                     pDVRSourcePinManager,
                                     pPolicy,
                                     pDVRSendStatsWriter
                                     ),
        m_dwMaxSeekAheadBoosts      (MAX_SEEKAHEAD_BOOSTS)
{
    //  non-failable call; we know this
    InitFKeyController (
        0,                  //  PTS base
        UNDEFINED           //  primary stream
        ) ;
}

CDVR_F_KeyFrame_ReadController::~CDVR_F_KeyFrame_ReadController (
    )
{
}

HRESULT
CDVR_F_KeyFrame_ReadController::Initialize (
    IN REFERENCE_TIME   rtPTSBase
    )
{
    TRACE_1 (LOG_AREA_DSHOW, 1,
        TEXT ("CDVR_F_KeyFrame_ReadController::Initialize (%I64d ms)"),
        DShowTimeToMilliseconds (rtPTSBase)) ;

    CDVRReadController::Initialize (rtPTSBase) ;

    m_rtPTSBase             = rtPTSBase ;
    m_rtPTSNormalizer       = UNDEFINED ;   //  discover the normalizing PTS
    m_State                 = WAIT_KEY ;    //  wait for the first key
    m_dwSamplesDropped      = 0 ;           //  primary stream only
    m_dwKeyFrames           = 0 ;           //  number of starts
    m_cnsLastSeek           = UNDEFINED ;   //  last position seeked to (check for dup seeks)

    InitContentOverrunCheck_ () ;

    return S_OK ;
}

HRESULT
CDVR_F_KeyFrame_ReadController::Fixup_ (
    IN  IMediaSample2 * pIMediaSample2
    )
{
    HRESULT         hr ;
    REFERENCE_TIME  rtStart ;
    REFERENCE_TIME  rtStop ;

    //  get the timestamp
    hr = pIMediaSample2 -> GetTime (& rtStart, & rtStop) ;

    if (hr != VFW_E_SAMPLE_TIME_NOT_SET) {

        //  set our normalizer if it's not yet set
        if (m_rtPTSNormalizer == UNDEFINED) {
            m_rtPTSNormalizer = rtStart ;
        }

        //  there's at least a start time; normalize both
        rtStart -= Min <REFERENCE_TIME> (rtStart, m_rtPTSNormalizer) ;
        rtStop  -= Min <REFERENCE_TIME> (rtStop, m_rtPTSNormalizer) ;

        //  add the baseline
        rtStart += m_rtPTSBase ;
        rtStop  += m_rtPTSBase ;

        //  save off our last PTS (we're about to queue this sample out)
        m_rtLastPTS = rtStart ;

        //  set the normalized start/stop values on the media sample
        hr = pIMediaSample2 -> SetTime (
                & rtStart,
                (hr == S_OK ? & rtStop : NULL)
                ) ;
    }
    else {
        //  no timestamp; so nothing to normalize; success
        hr = S_OK ;
    }

    return hr ;
}

HRESULT
CDVR_F_KeyFrame_ReadController::FixupAndSend_ (
    IN  IMediaSample2 * pIMediaSample2,
    IN  CDVROutputPin * pDVROutputPin,
    IN  AM_MEDIA_TYPE * pmtNew,
    IN  QWORD           cnsStreamTime
    )
{
    HRESULT hr ;
    BOOL    r ;

    ASSERT (pIMediaSample2) ;
    ASSERT (pDVROutputPin) ;
    ASSERT (pDVROutputPin -> CanSend ()) ;
    ASSERT (pDVROutputPin -> GetBankStoreIndex () == m_iPrimaryStream) ;

    if (pmtNew) {
        //  dynamic format change .. go
        r = pDVROutputPin -> QueryAcceptDynamicChange (pmtNew) ;
        pDVROutputPin -> SetMediaCompatible (r) ;

        if (!r) {
            //  we just turned off the primary stream; reset to 1x and resume
            hr = m_pDVRReadManager -> ConfigureForRate (_1X_PLAYBACK_RATE) ;
            goto cleanup ;
        }
    }

    //  fixup
    hr = Fixup_ (pIMediaSample2) ;
    if (SUCCEEDED (hr)) {

        //  and send
        hr = SendSample_ (
                    pIMediaSample2,
                    pDVROutputPin,
                    pmtNew,
                    cnsStreamTime
                    ) ;
    }

    cleanup :

    return hr ;
}

//  steady state call
HRESULT
CDVR_F_KeyFrame_ReadController::Process (
    )
{
    HRESULT         hr ;
    IMediaSample2 * pIMediaSample2 ;
    INSSBuffer *    pINSSBuffer ;
    CDVROutputPin * pDVROutputPin ;
    AM_MEDIA_TYPE * pmtNew ;
    QWORD           cnsCurrentRead ;
    QWORD           cnsLastSeekToDesired ;
    QWORD           cnsLastSeekToActual ;
    DWORD           i ;
    DWORD           dwMuxedStreamStats ;

    //  read and get an IMediaSample2-wrapped INSSBuffer; blocking call
    hr = m_pDVRReadManager -> ReadAndWaitWrapForward (
            & pIMediaSample2,
            & pINSSBuffer,
            & pDVROutputPin,
            & dwMuxedStreamStats,
            & pmtNew,
            & cnsCurrentRead
            ) ;
    if (FAILED (hr))    { goto cleanup ; }

    ASSERT (pIMediaSample2) ;
    ASSERT (pDVROutputPin) ;
    ASSERT (m_iPrimaryStream != UNDEFINED) ;

    //  hr initialized via call to read the content

    if (pDVROutputPin -> GetBankStoreIndex () == m_iPrimaryStream) {

        //  if this is a discontinuity, wait for the next keyframe boundary,
        //    always
        if (pIMediaSample2 -> IsDiscontinuity () == S_OK) {
            m_State = WAIT_KEY ;
        }

        //  sample goes into the primary stream; process it
        switch (m_State) {

            //  ================================================================
            //  waiting

            case WAIT_KEY :

                //  we're waiting; check if this is the start
                if (!pDVROutputPin -> IsKeyFrameStart (pIMediaSample2)) {
                    m_dwSamplesDropped++ ;
                    break ;
                }

                //
                //  we're on a keyframe boundary
                //

                //  set the discontinuity correctly; make sure it's not erased
                //    if it already was one
                pIMediaSample2 -> SetDiscontinuity (
                    pIMediaSample2 -> IsDiscontinuity () == S_OK ||
                    m_dwSamplesDropped > 0
                    ) ;

                //  set state
                m_State = IN_KEY ;

                //  fall

            //  ================================================================
            //  in a key (start or middle)

            case IN_KEY :

                if (pDVROutputPin -> IsKeyFrameStart (pIMediaSample2)) {
                    //  --------------------------------------------------------
                    //  keyframe start

                    //  we're on a boundary; if we're in a sparse keyframe
                    //    keyframe stream, we should have fallen from above;
                    //    perform Nth check

                    ASSERT (m_dwNthKeyFrame != 0) ;
                    if ((m_dwKeyFrames % m_dwNthKeyFrame) == 0) {
                        //  send it
                        hr = FixupAndSend_ (
                                pIMediaSample2,
                                pDVROutputPin,
                                pmtNew,
                                cnsCurrentRead
                                ) ;

                        //  reset the counter
                        m_dwSamplesDropped = 0 ;

                        TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 5,
                            TEXT ("CDVR_F_KeyFrame_ReadController::Process () [START] KeyFrame (CurrentRead = %I64d ms)"),
                            ::WMSDKTimeToMilliseconds (cnsCurrentRead)) ;
                    }
                    else {
                        //  not Nth; drop it; reset state to wait for next
                        m_State = WAIT_KEY ;
                        m_dwSamplesDropped++ ;

                        hr = S_OK ;
                    }

                    //  bump the counter
                    m_dwKeyFrames++ ;
                }
                else if (pDVROutputPin -> IsKeyFrame (pIMediaSample2)) {
                    //  --------------------------------------------------------
                    //  inside a keyframe

                    //  inside a keyframe; send it on, if there was nothing
                    //    dropped before this one; if there was dropped content
                    //    we're somehow in the middle of a keyframe with no
                    //    discontinuity .. ??  reset state to wait for the next
                    //    keyframe boundary

                    if (m_dwSamplesDropped == 0) {
                        //  as expected
                        hr = FixupAndSend_ (
                                pIMediaSample2,
                                pDVROutputPin,
                                pmtNew,
                                cnsCurrentRead
                                ) ;

                        TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 5,
                            TEXT ("CDVR_F_KeyFrame_ReadController::Process () [IN] KeyFrame (CurrentRead = %I64d ms)"),
                            WMSDKTimeToMilliseconds (cnsCurrentRead)) ;
                    }
                    else {
                        //  nothing dropped, but we're not a boundary ?? reset
                        //    to wait for the next boundary
                        m_dwSamplesDropped = 0 ;
                        m_State = WAIT_KEY ;
                    }
                }
                else {
                    //  --------------------------------------------------------
                    //  not a keyframe; drop it; might seek forward

                    TRACE_3 (LOG_AREA_SEEKING_AND_TRICK, 5,
                        TEXT ("CDVR_F_KeyFrame_ReadController::Process () [POST] KeyFrame; seeking ahead %I64d ms (CurrentRead = %I64d ms; intrakey seek = %I64d ms)"),
                        ::WMSDKTimeToMilliseconds (m_cnsIntraKeyFSeek), ::WMSDKTimeToMilliseconds (cnsCurrentRead), ::WMSDKTimeToMilliseconds (m_cnsIntraKeyFSeek)) ;

                    if (m_cnsIntraKeyFSeek > 0) {

                        //  PREFIX workaround; there's no way to tell PREFIX that
                        //    we'll loop below at least once
                        cnsLastSeekToActual = 0 ;

                        //  put this in a loop so we try to advance the reader
                        //    if our configured intra-keyframe seek is too small
                        //    for whatever reason (timehole; small seeks; etc..);
                        //    if we encounter this situation we seek further and
                        //    further, up to a max # of times, to try to seek
                        //    beyond the last seek
                        for (i = 0;
                             i < m_dwMaxSeekAheadBoosts;
                             i++) {

                            //  we haven't seeked forward yet; go from the last read
                            cnsLastSeekToDesired = cnsCurrentRead + m_cnsIntraKeyFSeek + i * ::MillisToWMSDKTime (m_pPolicy -> Settings () -> IndexGranularityMillis ()) ;
                            cnsLastSeekToActual = cnsLastSeekToDesired ;

                            //  make the seek (which might round down to our
                            //    last seeked-to position
                            hr = Seek_ (& cnsLastSeekToActual) ;
                            if (FAILED (hr)) { break ; }

                            //  if we moved beyond where we seeked to the last
                            //    time we're done (success)
                            if (cnsLastSeekToActual != m_cnsLastSeek) {
                                break ;
                            }

                            //
                            //  seek succeeded but we're back to where we seeked
                            //    the last time; try again with a more aggressive
                            //    seek to get ourselves unstalled
                            //

                            TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                                    TEXT ("DUPE: Seeking rounddown; %u; %I64d ms"),
                                    i, WMSDKTimeToMilliseconds (cnsLastSeekToActual)
                                    ) ;
                        }

                        //  if we successively seeked
                        if (SUCCEEDED (hr)) {

                            //  compare against our last seek-to point; if we've
                            //    advanced this is considered a success
                            if (m_cnsLastSeek != cnsLastSeekToActual) {

                                //  remember where we seeked to so we can check the next
                                //    time through and make sure we're moving onwards
                                m_cnsLastSeek = cnsLastSeekToActual ;

                                //  if we didn't go as far as we wanted, we might be
                                //    running up against the EOF; force a check, regardless
                                if (cnsLastSeekToActual < cnsLastSeekToDesired) {
                                    UpdateNextOnContentOverrunCheck_ () ;
                                }
                            }
                            else {
                                //  we've  stalled on our seeks; return a well-
                                //    known error back out

                                hr = HRESULT_FROM_WIN32 (ERROR_SEEK_ON_DEVICE) ;
                                goto cleanup ;
                            }
                        }
                        else {
                            goto cleanup ;
                        }

                        //  fixup "current read" to our current offset into the
                        //    backing store; this will trigger an appropriate
                        //    correction when we check for content overrun
                        cnsCurrentRead = cnsLastSeekToActual ;
                    }

                    //  wait for the next

                    m_State = WAIT_KEY ;
                }
        }
    }

    //  we're done with it
    pIMediaSample2 -> Release () ;

    //  this *might* reset the rate to 1x if we've caught up to live
    CheckForContentOverrun_ (
        cnsCurrentRead,
        & m_cnsIntraKeyFSeek
        ) ;

    cleanup :

    return hr ;
}

DWORD
CDVR_F_KeyFrame_ReadController::IntraKeyframeSeekMillis_ (
    IN  double  dRate
    )
{
    DWORD   dwSeekAheadMillis ;
    DWORD   dwIndexGranularity ;
    DWORD   dwAccel ;
    double  dMaxNonSkippingRate ;

    ASSERT (dRate >= _1X_PLAYBACK_RATE) ;

    dMaxNonSkippingRate = m_pPolicy -> Settings () -> MaxNonSkippingRate () ;

    if (dRate > dMaxNonSkippingRate) {
        //  multiply the rate delta by the indexing granularity; this
        //    accelerates how far ahead we seek

        dwIndexGranularity = m_pPolicy -> Settings () -> IndexGranularityMillis () ;

        //  accelerator can be 0 in which case we'll seek by 1 index granularity
        //    each time; the class handles that fine by seeking again if we land
        //    in the same place
        dwAccel = (DWORD) ((dRate - dMaxNonSkippingRate) / dMaxNonSkippingRate) ;

        dwSeekAheadMillis = dwIndexGranularity + (dwIndexGranularity * dwAccel) ;

        TRACE_4 (LOG_AREA_SEEKING_AND_TRICK, 1,
            TEXT ("CDVR_F_KeyFrame_ReadController::IntraKeyframeSeekMillis_ (%2.1f) returning %d SeekAhead ms; granularity = %d ms; accelerator = %d"),
            dRate, dwSeekAheadMillis, dwIndexGranularity, dwAccel) ;
    }
    else {
        dwSeekAheadMillis = 0 ;

        TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
            TEXT ("CDVR_F_KeyFrame_ReadController::IntraKeyframeSeekMillis_ (%2.1f) returning %d SeekAhead ms"),
            dRate, dwSeekAheadMillis) ;
    }

    return dwSeekAheadMillis ;
}

DWORD
CDVR_F_KeyFrame_ReadController::NthKeyframe_ (
    IN  double  dRate
    )
{
    DWORD   dwNthKeyFrame ;
    double  dMaxFullFrameRate ;

    dMaxFullFrameRate = m_pPolicy -> Settings () -> MaxFullFrameRate () ;

    ASSERT (dRate >= _1X_PLAYBACK_RATE) ;
    ASSERT (dRate > dMaxFullFrameRate) ;

    //  compute
    dwNthKeyFrame = (DWORD) ((dRate - dMaxFullFrameRate) / dMaxFullFrameRate) ;

    //  make sure we don't return 0
    dwNthKeyFrame = (dwNthKeyFrame != 0 ? dwNthKeyFrame : 1) ;

    TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
        TEXT ("CDVR_F_KeyFrame_ReadController::NthKeyframe_ (%2.1f) returning %d"),
        dRate, dwNthKeyFrame) ;

    return dwNthKeyFrame ;
}

void
CDVR_F_KeyFrame_ReadController::NotifyNewRate (
    IN  double  dRate
    )
{
    CDVR_Forward_ReadController::NotifyNewRate (dRate) ;

    m_cnsIntraKeyFSeek  = ::MillisToWMSDKTime (IntraKeyframeSeekMillis_ (dRate)) ;
    m_dwNthKeyFrame     = (m_cnsIntraKeyFSeek == 0 ? NthKeyframe_ (dRate) : 1) ;
    ASSERT (m_dwNthKeyFrame != 0) ;
}

HRESULT
CDVR_F_KeyFrame_ReadController::InitFKeyController (
    IN  REFERENCE_TIME  rtPTSBase,
    IN  int             iPrimaryStream
    )
{
    HRESULT hr ;

    hr = Initialize (rtPTSBase) ;
    if (SUCCEEDED (hr)) {
        m_iPrimaryStream = iPrimaryStream ;
    }

    return hr ;
}

//  ============================================================================
//  CDVR_F_FullFrame_ReadController
//  ============================================================================

CDVR_F_FullFrame_ReadController::CDVR_F_FullFrame_ReadController (
    IN  CDVRReadManager *       pDVRReadManager,
    IN  CDVRSourcePinManager *  pDVRSourcePinManager,
    IN  CDVRPolicy *            pPolicy,
    IN  CDVRSendStatsWriter *   pDVRSendStatsWriter
    ) : CDVR_Forward_ReadController (pDVRReadManager,
                                     pDVRSourcePinManager,
                                     pPolicy,
                                     pDVRSendStatsWriter
                                     ),
        m_rtPTSNormalizer           (MAX_REFERENCE_TIME),
        m_rtAVNormalizer            (MAX_REFERENCE_TIME),
        m_rtNonAVNormalizer         (MAX_REFERENCE_TIME),
        m_rtPTSBase                 (0),
        m_pStreamsBitField          (NULL),
        m_rtMinNearLivePTSPadding   (0),
        m_lNearLivePaddingMillis    (0),
        m_cnsMinNearLive            (0)
{
    m_rtMinNearLivePTSPadding   = ::MillisToDShowTime (m_pPolicy -> Settings () -> MinNearLiveMillis ()) ;
    m_cnsMinNearLive            = ::MillisToWMSDKTime (m_pPolicy -> Settings () -> MinNearLiveMillis ()) ;

    Initialize () ;
}

HRESULT
CDVR_F_FullFrame_ReadController::ReadFailure_ (
    IN  HRESULT hr
    )
{
    //  forward read failure - might have tried to read stale data

    QWORD   qwCurReadPos ;
    QWORD   qwValid ;
    LONG    lCurReadPosMillis ;
    LONG    lTimeholeMillis ;

    TRACE_1 (LOG_AREA_DSHOW, 1,
        TEXT ("CDVR_F_FullFrame_ReadController::ReadFailure_ : got %08xh"),
        hr) ;

    m_pDVRReadManager -> ReaderReset () ;

    //
    //  may have tried to read from a time hole, or stale location; the HR
    //   code will tell us this & it's something we can recover from
    //

    if (hr == HRESULT_FROM_WIN32 (ERROR_SEEK)) {

        //  we'll try to restart from where we read last
        qwCurReadPos = m_pDVRReadManager -> GetCurReadPos () ;

        TRACE_1 (LOG_AREA_DSHOW, 1,
            TEXT ("CDVR_F_FullFrame_ReadController::ReadFailure_ : got HRESULT_FROM_WIN32 (ERROR_SEEK) .. handling; check/set %I64u"),
            qwCurReadPos) ;

        qwValid = qwCurReadPos ;
        hr = m_pDVRReadManager -> CheckSetStartWithinContentBoundaries (& qwValid) ;
        if (SUCCEEDED (hr) &&
            qwValid == qwCurReadPos) {

            //  looks like a timehole; we errored during the read, but nothing
            //    has changed; make sure we're on valid content
            hr = m_pDVRReadManager -> GetNextValidRead (& qwValid) ;
            if (SUCCEEDED (hr) &&
                qwValid - qwCurReadPos >= m_pDVRReadManager -> TimeholeThreshold ()) {

                lCurReadPosMillis = (LONG) ::WMSDKTimeToMilliseconds (qwCurReadPos) ;
                lTimeholeMillis = (LONG) ::WMSDKTimeToMilliseconds (qwValid - qwCurReadPos) ;

                //  time hole event
                m_pPolicy -> EventSink () -> OnEvent (
                    STREAMBUFFER_EC_TIMEHOLE,
                    lCurReadPosMillis,
                    lTimeholeMillis
                    ) ;

                TRACE_2 (LOG_AREA_DSHOW, 1,
                    TEXT ("timehole detected: last read = %I64d ms; next valid = %I64d ms"),
                    WMSDKTimeToMilliseconds (qwCurReadPos), WMSDKTimeToMilliseconds (qwValid)) ;
            }
        }

        if (SUCCEEDED (hr)) {

            TRACE_1 (LOG_AREA_DSHOW, 1,
                TEXT ("CDVR_F_FullFrame_ReadController::ReadFailure_ : CheckSetStartWithinContentBoundaries reset qwValid to %I64u; seeking to .."),
                qwValid) ;

            //  now seek the reader to the start
            hr = Seek_ (& qwValid) ;
            if (SUCCEEDED (hr)) {
                //  all went well: update, notify new segment, and resume

                TRACE_0 (LOG_AREA_DSHOW, 1,
                    TEXT ("CDVR_F_FullFrame_ReadController::ReadFailure_ : SeekReader success; setting & notifying new segment")) ;

                //  notify new segment boundaries (only start should change)
                m_pDVRReadManager -> SetNewSegmentStart (qwValid) ;
                m_pDVRReadManager -> NotifyNewSegment () ;
            }
        }
    }

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::ReadWrapFixupAndSend_ (
    )
{
    HRESULT         hr ;
    IMediaSample2 * pIMediaSample2 ;
    INSSBuffer *    pINSSBuffer ;
    CDVROutputPin * pDVROutputPin ;
    AM_MEDIA_TYPE * pmtNew ;
    QWORD           cnsCurrentRead ;
    DWORD           dwMuxedStreamStats ;

    //  read and get an IMediaSample2-wrapped INSSBuffer; blocking call
    hr = m_pDVRReadManager -> ReadAndWaitWrapForward (
            & pIMediaSample2,
            & pINSSBuffer,
            & pDVROutputPin,
            & dwMuxedStreamStats,
            & pmtNew,
            & cnsCurrentRead
            ) ;

    if (SUCCEEDED (hr)) {

        ASSERT (pIMediaSample2) ;
        ASSERT (pDVROutputPin) ;

        hr = FixupAndSend_ (
                pIMediaSample2,
                pDVROutputPin,
                dwMuxedStreamStats,
                pmtNew,
                cnsCurrentRead
                ) ;

        pIMediaSample2 -> Release () ;

        //  this *might* reset the rate to 1x if we're full-frame trick mode
        //    >1x and have caught up to live
        CheckForContentOverrun_ (cnsCurrentRead) ;
    }

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::Process (
    )
{
    HRESULT hr ;
    QWORD   cnsStart ;
    QWORD   cnsStop ;

    //enum F_READ_STATE {
    //    SEEK_TO_SEGMENT_START,
    //    DISCOVER_PTS_NORMALIZER,
    //    DISCOVER_QUEUE_SEND,
    //    STEADY_STATE
    //} ;

    //  for PREFIX: this should be an ASSERT, not a runtime error; and we thus
    //    will always hit one of the case statements
    ASSERT (m_F_ReadState >= SEEK_TO_SEGMENT_START &&
            m_F_ReadState <= STEADY_STATE) ;

    switch (m_F_ReadState) {
        //  --------------------------------------------------------------------
        //  seek the reader to our first read offset
        case SEEK_TO_SEGMENT_START :

            //  seek to segment start
            m_pDVRReadManager -> GetCurSegmentBoundaries (& cnsStart, & cnsStop) ;
            hr = SeekReader_ (& cnsStart) ;
            if (SUCCEEDED (hr)) {
                //  setup for next state, & update state
                hr = NormalizerDiscPrep_ () ;
                if (SUCCEEDED (hr)) {
                    m_F_ReadState = DISCOVER_PTS_NORMALIZER ;

                    //  synchronize the timeline to our actual stream offset; in the
                    //    the case where we might have overshot during a >1x playback
                    //    this will reset the stream time so we're all in sync
                    hr = m_pDVRReadManager -> SetStreamSegmentStart (
                                ::WMSDKToDShowTime (cnsStart),
                                m_pDVRReadManager -> GetPlaybackRate ()
                                ) ;
                }
            }

            //  always break so the reader thread has a sufficiently fine
            //   granularity of check against pending commands
            break ;

        //  --------------------------------------------------------------------
        //  discovering the PTS normalizing val make take a few iterations - we
        //   may be started before the writer goes, in which case we'll
        //   encounter a recoverable error, but won't discover the value on that
        //   iteration
        case DISCOVER_PTS_NORMALIZER :

            ASSERT (!EndNormalizerDiscover_ ()) ;
            hr = NormalizerDisc_ ()  ;

            //  if we've collected what we need, OR
            //  if there are no more samples, try to tally what we have
            if ((SUCCEEDED (hr) && EndNormalizerDiscover_ ()) ||
                hr == (HRESULT) NS_E_NO_MORE_SAMPLES) {

                hr = NormalizerDiscTally_ () ;
                if (SUCCEEDED (hr)) {
                    //  setup for the next state

                    //  cannot have discover the normalizer val without having
                    //   read in (and queued) >= 1 media sample
                    ASSERT (!MediaSampleQueueEmpty_ ()) ;

                    //  mark off our segment boundaries & notify
                    m_pDVRReadManager ->  SetNewSegmentStart (m_cnsLastSeek) ;
                    m_pDVRReadManager ->  NotifyNewSegment () ;

                    //  we've discovered the PTS normalizing val
                    m_F_ReadState = DISCOVER_QUEUE_SEND ;
                }
                else {
                    //  failed to tally; make sure we're not holding any media
                    //    samples
                    FlushMediaSampleQueue_ () ;

                    //  setup for the initial state
                    m_F_ReadState = SEEK_TO_SEGMENT_START ;
                }
            }
            else if (FAILED (hr)) {
                //  fail out to previous state

                //  failed; make sure we're not holding any media samples
                FlushMediaSampleQueue_ () ;

                //  setup for the initial state
                m_F_ReadState = SEEK_TO_SEGMENT_START ;
            }

            //  always break so the reader thread has a sufficiently fine
            //   granularity of check against pending commands
            break ;

        //  --------------------------------------------------------------------
        //  we've now discovered the normalizing val & queued a number of media
        //   samples in the process; send them out
        case DISCOVER_QUEUE_SEND :

            ASSERT (m_rtPTSNormalizer != MAX_REFERENCE_TIME) ;
            if (!MediaSampleQueueEmpty_ ()) {
                hr = SendNextQueued_ () ;
            }
            else {
                //  we've somehow ended up in this state, with an empty media
                //   sample queue; don't fail, but we'll move to the next state
                //   the next time around
                hr = S_OK ;
            }

            //  check if we're done for this state
            if (SUCCEEDED (hr) &&
                MediaSampleQueueEmpty_ ()) {

                //  we've sent the queue we built up during PTS normalizer val
                //   discovery
                m_F_ReadState = STEADY_STATE ;
            }

            //  always break so the reader thread has a sufficiently fine
            //   granularity of check against pending commands
            break ;

        //  --------------------------------------------------------------------
        //  then transition to runtime state
        case STEADY_STATE :
            hr = ReadWrapFixupAndSend_ () ;
            break ;

        //  --------------------------------------------------------------------
        //  should never happen
        default :
            ASSERT (0) ;
            hr = E_FAIL ;
            break ;
    } ;

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::InternalInitialize_ (
    IN  REFERENCE_TIME      rtPTSBase,
    IN  REFERENCE_TIME      rtNormalizer,
    IN  F_READ_STATE        F_ReadState,
    IN  REFERENCE_TIME      rtLastPTS
    )
{
    m_F_ReadState       = F_ReadState ;
    m_rtPTSNormalizer   = rtNormalizer ;
    m_rtPTSBase         = rtPTSBase ;
    m_rtLastPTS         = rtLastPTS ;
    m_rtNearLivePadding = 0L ;

    ::InterlockedExchange (& m_lNearLivePaddingMillis, 0) ;

    FlushMediaSampleQueue_ () ;

    InitContentOverrunCheck_ () ;

    return S_OK ;
}

HRESULT
CDVR_F_FullFrame_ReadController::Initialize (
    IN  REFERENCE_TIME  rtPTSBase
    )
{
    HRESULT hr ;

    TRACE_1 (LOG_AREA_DSHOW, 1,
        TEXT ("CDVR_F_FullFrame_ReadController::Initialize (%I64d ms)"),
        DShowTimeToMilliseconds (rtPTSBase)) ;

    CDVRReadController::Initialize (rtPTSBase) ;

    hr = InternalInitialize_ (
                rtPTSBase,
                UNDEFINED,                  //  new normalizer val
                SEEK_TO_SEGMENT_START,      //  seek & play from segment start
                UNDEFINED                   //  last PTS
                ) ;

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::FlushMediaSampleQueue_ (
    )
{
    IMediaSample2 * pIMediaSample2 ;
    INSSBuffer *    pINSSBuffer ;
    CDVROutputPin * pDVROutputPin ;
    AM_MEDIA_TYPE * pmtNew ;
    HRESULT         hr ;

    hr = S_OK ;

    while (!m_PTSNormDiscQueue.Empty () &&
           SUCCEEDED (hr)) {

        hr = m_PTSNormDiscQueue.Pop (& pIMediaSample2, & pINSSBuffer, & pDVROutputPin, & pmtNew) ;
        if (SUCCEEDED (hr)) {
            //  we manage the queue's refs on COM interfaces
            pIMediaSample2 -> Release () ;
            delete pmtNew ;

            TRACE_3 (LOG_AREA_DSHOW, 5,
                TEXT ("CDVR_F_FullFrame_ReadController::::FlushMediaSampleQueue_ : flushed %08xh %08xh %08xh"),
                pIMediaSample2, pDVROutputPin, pmtNew) ;
        }
    }

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::SendNextQueued_ (
    )
{
    IMediaSample2 * pIMediaSample2 ;
    CDVROutputPin * pDVROutputPin ;
    AM_MEDIA_TYPE * pmtNew ;
    HRESULT         hr ;

    //  should not be getting called if the queue is empty
    ASSERT (!MediaSampleQueueEmpty_ ()) ;
    hr = m_PTSNormDiscQueue.Pop (& pIMediaSample2, NULL, & pDVROutputPin, & pmtNew) ;

    //  PREFIX note: pmtNew is assigned the value of NULL when the sample is pushed
    //      onto the queue, so it's not uninitialized; also the returned HRESULT
    //      is ASSERTed on lower because it should never fail if the call to
    //      MediaSampleQueueEmpty_ () returns FALSE, as is ASSERTed on above

    TRACE_3 (LOG_AREA_DSHOW, 5,
        TEXT ("CDVR_F_FullFrame_ReadController::::SendNextQueued_ : popped %08xh %08xh %08xh"),
        pIMediaSample2, pDVROutputPin, pmtNew) ;

    //  queue is not empty per the first assert
    ASSERT (SUCCEEDED (hr)) ;
    ASSERT (pIMediaSample2) ;
    ASSERT (pDVROutputPin) ;
    //  pmtNew can, and usually will, be NULL

    hr = FixupAndSend_ (pIMediaSample2, pDVROutputPin, UNDEFINED, pmtNew, 0) ;
    pIMediaSample2 -> Release () ;

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::FixupAndSend_ (
    IN  IMediaSample2 * pIMediaSample2,
    IN  CDVROutputPin * pDVROutputPin,
    IN  DWORD           dwMuxedStreamStats,
    IN  AM_MEDIA_TYPE * pmtNew,
    IN  QWORD           cnsStreamTime
    )
{
    HRESULT hr ;
    BOOL    r ;

    if (pmtNew) {
        r = pDVROutputPin -> QueryAcceptDynamicChange (pmtNew) ;
        pDVROutputPin -> SetMediaCompatible (r) ;
    }

    //  only send it if it's on
    if (pDVROutputPin -> CanSend ()) {

        //  fixup
        hr = Fixup_ (
                pDVROutputPin,
                pIMediaSample2,
                cnsStreamTime,
                dwMuxedStreamStats
                ) ;

        if (SUCCEEDED (hr)) {
            //  and send
            hr = SendSample_ (
                        pIMediaSample2,
                        pDVROutputPin,
                        pmtNew,
                        cnsStreamTime
                        ) ;
        }
    }
    else {
        //  don't fail the call
        hr = S_OK ;
    }

    return hr ;
}

BOOL
CDVR_F_FullFrame_ReadController::NearLive_ (
    IN  QWORD   cnsStreamTime
    )
{
    BOOL    r ;
    QWORD   cnsStart ;
    QWORD   cnsEOF ;
    HRESULT hr ;

    r = FALSE ;

    if (m_pDVRReadManager -> IsLiveSource ()) {
        hr = m_pDVRReadManager -> GetReaderContentBoundaries (& cnsStart, & cnsEOF) ;
        if (SUCCEEDED (hr)) {
            //  near live if we have less total content than our threshold, OR
            //  we're closer to live than the threshold
            r = (cnsEOF <= m_cnsMinNearLive ||
                 cnsStreamTime >= cnsEOF - m_cnsMinNearLive) ;
        }
    }

    return r ;
}

HRESULT
CDVR_F_FullFrame_ReadController::Fixup_ (
    IN  CDVROutputPin * pDVROutputPin,
    IN  IMediaSample2 * pIMediaSample2,
    IN  QWORD           cnsStreamTime,
    IN  DWORD           dwMuxedStreamStats
    )
{
    HRESULT         hr ;
    REFERENCE_TIME  rtStart ;
    REFERENCE_TIME  rtStop ;
    REFERENCE_TIME  rtPlaytime ;
    REFERENCE_TIME  rtPadDelta ;
    REFERENCE_TIME  rtBuffering ;
    WORD            wMuxedPacketsPerSec ;

    //  get the timestamp
    hr = pIMediaSample2 -> GetTime (& rtStart, & rtStop) ;

    if (hr != VFW_E_SAMPLE_TIME_NOT_SET) {

        //  there's at least a start time; normalize both
        rtStart -= Min <REFERENCE_TIME> (rtStart, m_rtPTSNormalizer) ;
        rtStop  -= Min <REFERENCE_TIME> (rtStop, m_rtPTSNormalizer) ;

        //  add the baseline
        rtStart += m_rtPTSBase ;
        rtStop  += m_rtPTSBase ;

        //  add near-live padding
        rtStart += m_rtNearLivePadding ;
        rtStop  += m_rtNearLivePadding ;

#if 0
        //  --------------------------------------------------------------------
        //
        //  use these traces to troubleshoot clock-slaving issues
        //

        static DWORD    dwLast_TEMP = 0 ;
        REFERENCE_TIME  rtPlaytime_TEMP ;
        QWORD           cnsCurContentDuration_TEMP ;
        if (GetTickCount () - dwLast_TEMP > 1000) {
            dwLast_TEMP = ::GetTickCount () ;
            cnsCurContentDuration_TEMP = m_pDVRReadManager -> GetContentDuration () ;
            m_pDVRReadManager -> GetCurPlaytime (& rtPlaytime_TEMP) ;
            TRACE_4 (LOG_TIMING, 1, TEXT (",%I64d,%I64d,%I64d,%I64d,"), rtStart - rtPlaytime_TEMP, rtPlaytime_TEMP, cnsCurContentDuration_TEMP, ((REFERENCE_TIME) cnsCurContentDuration_TEMP) - rtPlaytime_TEMP) ;
        }

        //  --------------------------------------------------------------------
#endif

        //  check for underflow first, and maybe pad out the timestamps
        if (m_pDVRReadManager -> GetPlaybackRate () == _1X_PLAYBACK_RATE &&
            pDVROutputPin -> IsAV ()) {

            //  get current playtime and check if we've encroached into the critical
            //    region within live in which we leave ourselves too little time
            //    to process downstream
            m_pDVRReadManager -> GetCurPlaytime (& rtPlaytime) ;

            rtBuffering = rtStart - rtPlaytime ;

            //  if we're near live, we might need to pad out timestamps so we
            //    can back off of live
            if (rtBuffering < m_rtMinNearLivePTSPadding &&
                NearLive_ (cnsStreamTime)) {

                //  we've encroached; compute how much we need to pad out the
                //    timestamps; adjust our nearlive padding, and notify the
                //    output pins (audio will insert an explicit discontinuity
                //    when we do this)

                rtPadDelta = m_rtMinNearLivePTSPadding - rtBuffering ;

                //  add in some padding so we pad out just a bit more than only
                //    what's required
                rtPadDelta += ::MillisToDShowTime (m_pPolicy -> Settings () -> LowBufferPaddingMillis ()) ;

                //  adjust our near live padding now
                m_rtNearLivePadding += rtPadDelta ;

                //  safe cast because we certainly don't expect this number to be big;
                //    note 2^32 millis ~= 1193 hours
                ::InterlockedExchange (& m_lNearLivePaddingMillis, (LONG) ::DShowTimeToMilliseconds (m_rtNearLivePadding)) ;

                TRACE_2 (LOG_AREA_TIME, 1,
                    TEXT ("underflow detected; padding + %I64d ms = %I64d ms"),
                    ::DShowTimeToMilliseconds (rtPadDelta), ::DShowTimeToMilliseconds (m_rtNearLivePadding)) ;

                //  readjust the timestamps to buffer in the additional padding
                //    we want
                rtStart += rtPadDelta ;
                rtStop  += rtPadDelta ;

                //  notify the pin bank that we've padded the timestamps; some
                //    streams may want to insert a discontinuity in this case
                m_pDVRSourcePinManager -> OnPTSPaddingIncrement () ;

                //  stats
                m_pDVRSendStatsWriter -> Underflow (pDVROutputPin -> GetBankStoreIndex ()) ;
            }
        }
        else {
            //  set it to a bogus value
            rtBuffering = MAX_REFERENCE_TIME ;
        }

        //  adjust our buffer pool based on observed capture buffer rate
        wMuxedPacketsPerSec = GET_MUXED_STREAM_STATS_PACKET_RATE (dwMuxedStreamStats) ;
        if (wMuxedPacketsPerSec != (WORD) UNDEFINED) {
            m_pDVRReadManager -> AdjustBufferPool (wMuxedPacketsPerSec) ;
        }

        m_pDVRSendStatsWriter -> Buffering (
            pDVROutputPin -> GetBankStoreIndex (),
            & rtBuffering,
            m_pDVRReadManager -> GetAvailableWrappers (),
            m_pDVRReadManager -> CurWrapperCount (),
            m_pDVRReadManager -> MaxWrapperCount ()
            ) ;

        //  save off our last PTS (we're about to queue this sample out)
        m_rtLastPTS = rtStart ;

        //  set the normalized start/stop values on the media sample
        hr = pIMediaSample2 -> SetTime (
                & rtStart,
                (hr == S_OK ? & rtStop : NULL)
                ) ;
    }
    else {
        //  no timestamp; so nothing to normalize; succes
        hr = S_OK ;
    }

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::SeekReader_ (
    IN OUT  QWORD * pcnsSeekTo
    )
{
    HRESULT hr ;

    hr = Seek_ (pcnsSeekTo) ;
    if (SUCCEEDED (hr)) {
        m_cnsLastSeek = (* pcnsSeekTo) ;
    }

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::NormalizerDiscPrep_ (
    )
{
    HRESULT hr ;

    //  should always start this with an empty queue
    ASSERT (MediaSampleQueueEmpty_ ()) ;

    //  this method discovers the smallest timestamp, by reading from the
    //  specified starting point and ratcheting a value down

    //  make sure we have a bitfield
    if (m_pStreamsBitField == NULL ||
        m_pStreamsBitField -> BitfieldSize () < m_pDVRReadManager -> StreamCount ()) {

        DELETE_RESET (m_pStreamsBitField) ;

        m_pStreamsBitField = new CSimpleBitfield (m_pDVRReadManager -> StreamCount (), & hr) ;
        if (m_pStreamsBitField == NULL ||
            FAILED (hr)) {

            hr = (m_pStreamsBitField ? hr : E_OUTOFMEMORY) ;

            DELETE_RESET (m_pStreamsBitField) ;

            return hr ;
        }
    }

    //  clear the bitfield
    m_pStreamsBitField -> ClearAll () ;

    //  undefine whatever normalizing val we currently use
    m_rtPTSNormalizer   = MAX_REFERENCE_TIME ;
    m_rtAVNormalizer    = MAX_REFERENCE_TIME ;
    m_rtNonAVNormalizer = MAX_REFERENCE_TIME ;

    ASSERT (m_pStreamsBitField -> BitsSet () == 0) ;

    return S_OK ;
}

BOOL
CDVR_F_FullFrame_ReadController::EndNormalizerDiscover_ (
    )
{
    BOOL    r ;

    //  complete if we've read a PTS from all of our streams, OR we've made the
    //    the max number of reads
    r = (m_pStreamsBitField -> BitsSet () == m_pDVRReadManager -> StreamCount ()  ||
         m_PTSNormDiscQueue.Length () >= m_pPolicy -> Settings () -> MaxNormalizerPTSDiscReads ()) ;

    return r ;
}

HRESULT
CDVR_F_FullFrame_ReadController::NormalizerDiscTally_ (
    )
{
    HRESULT hr ;

    if (m_rtAVNormalizer    != MAX_REFERENCE_TIME ||
        m_rtNonAVNormalizer != MAX_REFERENCE_TIME) {

        //  we at least have 1 normalizer val; might be AV or not, but we can
        //    proceed

        //  prefer the AV normalizer
        if (m_rtAVNormalizer != MAX_REFERENCE_TIME) {
            m_rtPTSNormalizer = m_rtAVNormalizer ;
        }
        else {
            m_rtPTSNormalizer = m_rtNonAVNormalizer ;
        }

        TRACE_1 (LOG_AREA_DSHOW, 1,
            TEXT ("CDVR_F_FullFrame_ReadController::::FindPTSNormalizerVal_ : m_rtPTSBase (BEFORE) = %I64d ms"),
            ::DShowTimeToMilliseconds (m_rtPTSBase)) ;

        m_pDVRReadManager -> GetCurPlaytime (& m_rtPTSBase) ;

        TRACE_1 (LOG_AREA_DSHOW, 1,
            TEXT ("CDVR_F_FullFrame_ReadController::::FindPTSNormalizerVal_ : m_rtPTSBase (AFTER) = %I64d ms"),
            ::DShowTimeToMilliseconds (m_rtPTSBase)) ;

        m_rtNearLivePadding = 0L ;

        m_pDVRSendStatsWriter -> SetNormalizer (m_rtPTSNormalizer, m_rtPTSBase) ;

        hr = S_OK ;
    }
    else {
        //  discovered nothing, so fail the call
        hr = E_FAIL ;
    }

    TRACE_7 (LOG_AREA_DSHOW, 2,
        TEXT ("CDVR_F_FullFrame_ReadController::::FindPTSNormalizerVal_ : hr = %08xh; iReads = %d; m_rtPTSNormalizer = %I64d ms (AV = %I64d ms, non AV = %I64d ms); tallied = %d; streams = %d"),
        hr, m_PTSNormDiscQueue.Length (), ::DShowTimeToMilliseconds (m_rtPTSNormalizer),
        ::DShowTimeToMilliseconds (m_rtAVNormalizer), ::DShowTimeToMilliseconds (m_rtNonAVNormalizer),
        m_pStreamsBitField -> BitsSet (), m_pDVRReadManager -> StreamCount ()
        ) ;

    return hr ;
}

HRESULT
CDVR_F_FullFrame_ReadController::NormalizerDisc_ (
    )
{
    HRESULT         hr ;
    INSSBuffer *    pINSSBuffer ;
    IMediaSample2 * pIMediaSample2 ;
    CDVROutputPin * pDVROutputPin ;
    AM_MEDIA_TYPE * pmtNew ;
    QWORD           cnsLastRead ;
    REFERENCE_TIME  rtStart ;
    REFERENCE_TIME  rtStop ;
    DWORD           dwMuxedStreamStats ;

    hr = m_pDVRReadManager -> ReadAndTryWrapForward (
            & pIMediaSample2,
            & pINSSBuffer,
            & pDVROutputPin,
            & dwMuxedStreamStats,
            & pmtNew,
            & cnsLastRead
            ) ;
    if (SUCCEEDED (hr)) {

        ASSERT (pIMediaSample2) ;
        ASSERT (pDVROutputPin) ;

        hr = pIMediaSample2 -> GetTime (& rtStart, & rtStop) ;
        if (hr != VFW_E_SAMPLE_TIME_NOT_SET) {
            //  sample has a time;
            //  have we seen this stream yet ?
            if (!m_pStreamsBitField -> IsSet (pDVROutputPin -> GetBankStoreIndex ())) {
                m_pStreamsBitField -> Set (pDVROutputPin -> GetBankStoreIndex ()) ;
            }

            //  ratchet down
            if (pDVROutputPin -> IsAV ()) {
                m_rtAVNormalizer = Min <REFERENCE_TIME> (rtStart, m_rtAVNormalizer) ;
            }
            else {
                m_rtNonAVNormalizer = Min <REFERENCE_TIME> (rtStart, m_rtNonAVNormalizer) ;
            }
        }
        else if (!m_pStreamsBitField -> IsSet (pDVROutputPin -> GetBankStoreIndex ())) {
            //  we haven't found what we want for this stream yet; if we've found an
            //    AV timestamp, and this is not AV, we toggle it now since we won't
            //    use it anyways
            if (!pDVROutputPin -> IsAV () &&
                m_rtAVNormalizer != MAX_REFERENCE_TIME) {

                //  not an AV stream, AND
                //    we have an AV normalizer PTS already
                //  => toggle this so we don't read packets trying to discover
                //    this one
                m_pStreamsBitField -> Set (pDVROutputPin -> GetBankStoreIndex ()) ;

                TRACE_1 (LOG_AREA_DSHOW, 5,
                    TEXT ("CDVR_F_FullFrame_ReadController::::FindPTSNormalizerVal_ : non AV stream bit toggled: %d"),
                    pDVROutputPin -> GetBankStoreIndex ()
                    ) ;
            }
        }

        //  queue will ref
        hr = m_PTSNormDiscQueue.Push (
                pIMediaSample2,
                NULL,
                pDVROutputPin,
                pmtNew
                ) ;

        TRACE_3 (LOG_AREA_DSHOW, 5,
            TEXT ("CDVR_F_FullFrame_ReadController::::FindPTSNormalizerVal_ : queued %08xh %08xh %08xh"),
            pIMediaSample2, pDVROutputPin, pmtNew) ;

        //  sample is only ref'd by queue now
        pIMediaSample2 -> Release () ;
    }

    return hr ;
}

//  ============================================================================
//  CDVRReverseSender
//  ============================================================================

HRESULT
CDVRReverseSender::Fixup_ (
    IN  IMediaSample2 * pIMediaSample2,
    IN  BOOL            fKeyFrame
    )
{
    REFERENCE_TIME  rtStart ;
    REFERENCE_TIME  rtStop ;
    REFERENCE_TIME  rtDuration ;
    REFERENCE_TIME  rtMirrorStartDelta ;
    HRESULT         hr ;

    if (fKeyFrame) {
        //  keyframes that are timestamped, must be mirrored so timestamps
        //    continue to increase
        hr = pIMediaSample2 -> GetTime (& rtStart, & rtStop) ;
        if (SUCCEEDED (hr)) {
            //  normalizer takes on 1st pts seen following an initialization
            if (m_rtNormalizer == UNDEFINED) {
                m_rtNormalizer = rtStart ;
            }

            TRACE_3 (LOG_AREA_TIME, 7,
                TEXT ("CDVRReverseSender::Fixup_ () -- mirroring (FROM) start %I64d ms; stop %I64d ms; (mirror = %I64d ms)"),
                ::DShowTimeToMilliseconds (rtStart), ::DShowTimeToMilliseconds (rtStop), ::DShowTimeToMilliseconds (m_rtMirrorTime)) ;

            //  snap the duration of the sample
            rtDuration = rtStop - rtStart ;

            //  normalizer should be bigger than the start timestamp, except
            //    possibly right at the start when different streams have
            //    timestamps that jitter just a bit
            rtMirrorStartDelta = Min <REFERENCE_TIME> (rtStart - m_rtNormalizer, 0) ;
            ASSERT (rtMirrorStartDelta <= 0) ;

            //  minus negative is positive; basetime is the base and we increase
            rtStart = m_rtMirrorTime - rtMirrorStartDelta ;

            //  preserve the forward duration of this sample
            rtStop  = rtStart + rtDuration ;

            TRACE_2 (LOG_AREA_TIME, 7,
                TEXT ("CDVRReverseSender::Fixup_ () -- (TO) start %I64d ms; stop %I64d ms"),
                ::DShowTimeToMilliseconds (rtStart), ::DShowTimeToMilliseconds (rtStop)) ;

            //  set the normalized start/stop values on the media sample
            hr = pIMediaSample2 -> SetTime (
                    & rtStart,
                    (hr == S_OK ? & rtStop : NULL)
                    ) ;
        }
    }
    else {
        //  all non-keyframes are stipped of timestamps in reverse mode
        pIMediaSample2 -> SetTime (NULL, NULL) ;
    }

    return S_OK ;
}

HRESULT
CDVRReverseSender::Send (
    IN  IMediaSample2 * pIMediaSample2,
    IN  CDVROutputPin * pDVROutputPin,
    IN  QWORD           cnsCurrentRead
    )
{
    HRESULT hr ;

    ASSERT (pIMediaSample2) ;
    ASSERT (pDVROutputPin) ;

    hr = Fixup_ (
            pIMediaSample2,
            pDVROutputPin -> IsKeyFrame (pIMediaSample2)
            ) ;
    if (SUCCEEDED (hr)) {
        hr = SendSample_ (
                pIMediaSample2,
                pDVROutputPin,
                NULL,
                cnsCurrentRead
                ) ;
    }

    return hr ;
}

HRESULT
CDVRReverseSender::SendSample_ (
    IN  IMediaSample2 * pIMediaSample2,
    IN  CDVROutputPin * pDVROutputPin,
    IN  AM_MEDIA_TYPE * pmtNew,
    IN  QWORD           cnsStreamTime
    )
{
    HRESULT hr ;

    ASSERT (m_pHostingReadController) ;
    hr = m_pHostingReadController -> SendSample_ (
                pIMediaSample2,
                pDVROutputPin,
                pmtNew,
                cnsStreamTime
                ) ;

    return hr ;
}

//  ============================================================================
//  CDVRMpeg2ReverseSender
//  ============================================================================

HRESULT
CDVRMpeg2ReverseSender::SendQueuedGOP_ (
    )
{
    HRESULT         hr ;
    IMediaSample2 * pIMediaSample2 ;
    CDVROutputPin * pDVROutputPin ;
    DWORD           dw ;
    int             i ;

    //
    //  when this method is called, we assume the m_Mpeg2GOP has at least an
    //    I-frame; in fact it must *start* with an I-frame boundary, or we'll
    //    flush the entire GOP
    //

    for (hr = S_OK, i = 0;
         !m_Mpeg2GOP.Empty () && SUCCEEDED (hr);
         i++) {

        dw = m_Mpeg2GOP.Pop (
                & pIMediaSample2,
                NULL,
                & pDVROutputPin,
                NULL
                ) ;
        ASSERT (dw == NOERROR) ;

        //  if this is an I-frame boundary (first sample in I-frame AND it's
        //    the first sample we've popped
        if (pDVROutputPin -> IsKeyFrameStart (pIMediaSample2) &&        //  I-frame boundary
            i == 0                                                      //  first sample in GOP
            ) {

            //  force a discontinuity each time we see a boundary
            pIMediaSample2 -> SetDiscontinuity (TRUE) ;

            //  send it
            hr = SendSample_ (pIMediaSample2, pDVROutputPin, NULL, 0) ;

            TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 7,
                TEXT ("CDVRMpeg2ReverseSender::SendQueuedGOP_ () -- I-frame *start* sent, %08xh (%d)"),
                pIMediaSample2, i + 1) ;
        }
        //  if this is an I-frame sample that is not a boundary (
        else if (pDVROutputPin -> IsKeyFrame (pIMediaSample2)       &&  //  I-frame content
                 !pDVROutputPin -> IsKeyFrameStart (pIMediaSample2) &&  //  not an I-frame boundary
                 i > 0                                                  //  and we sent the first
                 ) {

            //  send it (I-frame content)
            hr = SendSample_ (pIMediaSample2, pDVROutputPin, NULL, 0) ;

            TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 7,
                TEXT ("CDVRMpeg2ReverseSender::SendQueuedGOP_ () -- I-frame *content* sent, %08xh (%d)"),
                pIMediaSample2, i + 1) ;
        }
        //  if we're not to send I-frames *only* and we've sent at least 1 sample
        //    i.e. at least the I-frame
        else if (!IFramesOnly_ () &&                                    //  non i-frame content
                 i > 0                                                  //  presumed to have sent i-frame already
                 ) {

            //  send the sample (non I-frame)
            hr = SendSample_ (pIMediaSample2, pDVROutputPin, NULL, 0) ;

            TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 7,
                TEXT ("CDVRMpeg2ReverseSender::SendQueuedGOP_ () -- non I-frame sent; %08xh (%d)"),
                pIMediaSample2, i + 1) ;
        }
        else {
            //  I-frames only or we haven't sent anything yet; in this case we
            //    we are done sending; break from the loop - we'll flush when we
            //    are done (later in this method); release the sample since we
            //    breaking from the loop; the sample is normally released after
            //    this if-then-else etc... clause
            pIMediaSample2 -> Release () ;

            TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 7,
                TEXT ("CDVRMpeg2ReverseSender::SendQueuedGOP_ () -- all I-frames have been sent; dropped %08xh; flushing the rest"),
                pIMediaSample2) ;

            break ;
        }

        //  we are done with this sample; continue looping until one of the above
        //    conditions is met, or the GOP is empty
        pIMediaSample2 -> Release () ;
    }

    //  make sure that GOP is empty; we might have sent just the I-frame and
    //    have aborted, or we may have failed a send operation
    Flush () ;

    return hr ;
}

HRESULT
CDVRMpeg2ReverseSender::Fixup_ (
    IN  IMediaSample2 * pIMediaSample2,
    IN  BOOL            fKeyFrame
    )
{
    return CDVRReverseSender::Fixup_ (pIMediaSample2, fKeyFrame) ;
}

HRESULT
CDVRMpeg2ReverseSender::Send (
    IN  IMediaSample2 * pIMediaSample2,
    IN  CDVROutputPin * pDVROutputPin,
    IN  QWORD           cnsCurrentRead
    )
{
    HRESULT hr ;
    DWORD   dw ;

#if 0
    ::DumpINSSBuffer3Attributes (
        pINSSBuffer,
        cnsCurrentRead,
        wStreamNum,
        7
        ) ;
#endif

    ASSERT (pIMediaSample2) ;
    ASSERT (pDVROutputPin) ;

    if ((IFramesOnly_ () && pDVROutputPin -> IsKeyFrame (pIMediaSample2)) ||
        !IFramesOnly_ ()) {

        hr = Fixup_ (
                pIMediaSample2,
                pDVROutputPin -> IsKeyFrame (pIMediaSample2)
                ) ;
        if (SUCCEEDED (hr)) {

            //  if we encounter the discontinuity (true discontinuity; the seek-
            //    created discontinuity gets masked by the reverse send
            //    controller), we must flush the GOP; we don't know how any of
            //    the contents we have in the GOP relate to this sample
            if (pIMediaSample2 -> IsDiscontinuity () == S_OK) {

                TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 4,
                    TEXT ("CDVRMpeg2ReverseSender::Send () -- %08xh is a discontinuity; flushing"),
                    pIMediaSample2) ;

                Flush () ;
            }

            //  push this one onto the GOP
            dw = m_Mpeg2GOP.Push (
                    pIMediaSample2,
                    NULL,
                    pDVROutputPin,
                    NULL
                    ) ;

            hr = HRESULT_FROM_WIN32 (dw) ;

            if (SUCCEEDED (hr)) {

                //  if we just pushed a keyframe start, GOP is at least partially
                //    full, even if it holds just the first part of the I-frame;
                //    regardless, we send the GOP; during send the GOP will be
                //    flushed so the next sample we get will be the first (last
                //    sample of the GOP if playing forward) of the previous GOP
                if (pDVROutputPin -> IsKeyFrameStart (pIMediaSample2)) {

                    TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 7,
                        TEXT ("CDVRMpeg2ReverseSender::Send () -- pushed %08xh (I-frame start); sending the GOP"),
                        pIMediaSample2) ;

                    //  we found an I-frame boundary; send the GOP we've accumulated
                    //    so far (might be entire GOP)
                    hr = SendQueuedGOP_ () ;
                }
                else {
                    TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 7,
                        TEXT ("CDVRMpeg2ReverseSender::Send () -- pushed %08xh (non I-frame start)"),
                        pIMediaSample2) ;
                }
            }
        }
    }
    else {
        hr = S_OK ;

        TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 7,
            TEXT ("CDVRMpeg2ReverseSender::Send () -- dropping %08xh (non I-frame)"),
            pIMediaSample2) ;
    }

    return hr ;
}

void
CDVRMpeg2ReverseSender::Flush (
    )
{
    IMediaSample2 * pIMediaSample2 ;
    INSSBuffer *    pINSSBuffer ;
    CDVROutputPin * pDVROutputPin ;
    AM_MEDIA_TYPE * pmtNew ;
    DWORD           dw ;

    while (!m_Mpeg2GOP.Empty ()) {
        dw = m_Mpeg2GOP.Pop (
                & pIMediaSample2,
                & pINSSBuffer,
                & pDVROutputPin,
                & pmtNew
                ) ;
        ASSERT (dw == NOERROR) ;

        //  only the sample's ref counts in the list
        pIMediaSample2 -> Release () ;

        TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 7,
            TEXT ("CDVRMpeg2ReverseSender::Flush () -- %08xh"),
            pIMediaSample2) ;
    }
}

//  ============================================================================
//  CDVR_Reverse_ReadController
//  ============================================================================

CDVR_Reverse_ReadController::CDVR_Reverse_ReadController  (
    IN  CDVRReadManager *       pDVRReadManager,
    IN  CDVRSourcePinManager *  pDVRSourcePinManager,
    IN  CDVRPolicy *            pPolicy,
    IN  CDVRSendStatsWriter *   pDVRSendStatsWriter
    ) : CDVRReadController          (pDVRReadManager,
                                     pDVRSourcePinManager,
                                     pPolicy,
                                     pDVRSendStatsWriter,
                                     pPolicy -> Settings () -> R_MaxSeekingProbeMillis ()
                                     ),
        m_Senders                   (NULL,
                                     5
                                     ),
        m_State                     (STATE_SEEK),
        m_cnsIndexGranularity       (0),
        m_iPrimaryStream            (UNDEFINED),
        m_cnsReadStop               (0),
        m_cnsReadStart              (0),
        m_wReadStopStream           (0),
        m_dwReadStopCounter         (0),
        m_wLastReadStream           (0),
        m_dwSeekbackMultiplier      (1)
{
    m_cnsIndexGranularity = ::MillisToWMSDKTime (m_pPolicy -> Settings () -> IndexGranularityMillis ()) ;
}

CDVR_Reverse_ReadController::~CDVR_Reverse_ReadController (
    )
{
    CDVRReverseSender * pDVRReverseSender ;
    int                 i ;
    DWORD               dw ;

    //  initialize the senders
    for (i = 0;
         i < m_Senders.ValCount ();
         i++) {

        pDVRReverseSender = NULL ;
        dw = m_Senders.GetVal (i, & pDVRReverseSender) ;
        ASSERT (dw == NOERROR) ;
        ASSERT (pDVRReverseSender) ;

        delete pDVRReverseSender ;
    }
}

BOOL
CDVR_Reverse_ReadController::SeekOnDeviceFailure_Adjust (
    IN OUT QWORD *  pcnsSeek
    )
{
    ASSERT (pcnsSeek) ;

    //  move back (but don't wrap)
    (* pcnsSeek) -= Min <QWORD> (
                        ::MillisToWMSDKTime (m_pPolicy -> Settings () -> IndexGranularityMillis ()),
                        (* pcnsSeek)
                        ) ;

    return TRUE ;
}

HRESULT
CDVR_Reverse_ReadController::ReadFailure_ (
    IN  HRESULT hr
    )
{
    //  forward read failure - might have tried to read stale data

    QWORD   qwCurReadPos ;
    QWORD   qwValid ;
    LONG    lCurReadPosMillis ;
    long    lTimeholeMillis ;

    TRACE_1 (LOG_AREA_DSHOW, 1,
        TEXT ("CDVR_F_FullFrame_ReadController::ReadFailure_ : got %08xh"),
        hr) ;

    m_pDVRReadManager -> ReaderReset () ;

    //
    //  may have tried to read from a time hole, or stale location; the HR
    //   code will tell us this & it's something we can recover from
    //

    if (hr == HRESULT_FROM_WIN32 (ERROR_SEEK)) {

        //  we'll try to restart from where we read last
        qwCurReadPos = m_pDVRReadManager -> GetCurReadPos () ;

        TRACE_1 (LOG_AREA_DSHOW, 1,
            TEXT ("CDVR_F_FullFrame_ReadController::ReadFailure_ : got HRESULT_FROM_WIN32 (ERROR_SEEK) .. handling; check/set %I64u"),
            qwCurReadPos) ;

        qwValid = qwCurReadPos ;
        hr = m_pDVRReadManager -> CheckSetStartWithinContentBoundaries (& qwValid) ;
        if (SUCCEEDED (hr) &&
            qwValid == qwCurReadPos) {

            //  looks like a timehole; we errored during the read, but nothing
            //    has changed; make sure we're on valid content
            hr = m_pDVRReadManager -> GetPrevValidTime (& qwValid) ;
            if (SUCCEEDED (hr) &&
                qwCurReadPos - qwValid >= m_pDVRReadManager -> TimeholeThreshold ()) {

                lCurReadPosMillis = (LONG) ::WMSDKTimeToMilliseconds (qwCurReadPos) ;
                lTimeholeMillis = (LONG) ::WMSDKTimeToMilliseconds (qwCurReadPos - qwValid) ;

                //  time hole event
                m_pPolicy -> EventSink () -> OnEvent (
                    STREAMBUFFER_EC_TIMEHOLE,
                    lCurReadPosMillis,
                    lTimeholeMillis
                    ) ;

                TRACE_2 (LOG_AREA_DSHOW, 1,
                    TEXT ("timehole detected: last read = %I64d ms; prev valid = %I64d ms"),
                    WMSDKTimeToMilliseconds (qwCurReadPos), WMSDKTimeToMilliseconds (qwValid)) ;
            }
        }

        if (SUCCEEDED (hr)) {

            TRACE_1 (LOG_AREA_DSHOW, 1,
                TEXT ("CDVR_F_FullFrame_ReadController::ReadFailure_ : CheckSetStartWithinContentBoundaries reset qwValid to %I64u; seeking to .."),
                qwValid) ;

            //  now seek the reader to the start
            hr = Seek_ (& qwValid) ;
            if (SUCCEEDED (hr)) {
                //  all went well: update, notify new segment, and resume

                TRACE_0 (LOG_AREA_DSHOW, 1,
                    TEXT ("CDVR_F_FullFrame_ReadController::ReadFailure_ : SeekReader success; setting & notifying new segment")) ;

                //  notify new segment boundaries (only start should change)
                m_pDVRReadManager -> SetNewSegmentStart (qwValid) ;
                m_pDVRReadManager -> NotifyNewSegment () ;
            }
        }
    }

    return hr ;
}

void
CDVR_Reverse_ReadController::InternalFlush_ (
    )
{
    INSSBuffer *        pINSSBuffer ;
    QWORD               cnsRead ;
    DWORD               dwReadFlags ;
    WORD                wStreamNum ;
    HRESULT             hr ;
    int                 i ;
    CDVRReverseSender * pDVRReverseSender ;
    DWORD               dw ;

    //  first flush our INSSBuffer LIFO
    while (!m_ReadINSSBuffers.Empty ()) {
        hr = m_ReadINSSBuffers.Pop (
                & pINSSBuffer,
                & cnsRead,
                & dwReadFlags,
                & wStreamNum
                ) ;
        ASSERT (SUCCEEDED (hr)) ;
        ASSERT (pINSSBuffer) ;

        pINSSBuffer -> Release () ;
    }

    //  next flush out all the senders
    for (i = 0; i < m_Senders.ValCount (); i++) {
        dw = m_Senders.GetVal (i, & pDVRReverseSender) ;
        ASSERT (dw == NOERROR) ;
        ASSERT (pDVRReverseSender) ;

        pDVRReverseSender -> Flush () ;
    }
}

CDVRReverseSender *
CDVR_Reverse_ReadController::GetDVRReverseSender_ (
    IN  AM_MEDIA_TYPE * pmt
    )
{
    CDVRReverseSender * pDVRReverseSender ;

    pDVRReverseSender = new CDVRReverseSender (
                                m_pDVRReadManager,
                                this,
                                m_pDVRSourcePinManager,
                                m_pPolicy,
                                m_pDVRSendStatsWriter
                                ) ;

    return pDVRReverseSender ;
}

HRESULT
CDVR_Reverse_ReadController::InitializeSenders_ (
    IN  REFERENCE_TIME  rtPTSBase
    )
{
    CDVRReverseSender * pDVRReverseSender ;
    HRESULT             hr ;
    int                 i ;
    AM_MEDIA_TYPE       mt ;
    DWORD               dw ;

    //  populate the senders if necessary
    if (m_Senders.ValCount () == 0) {

        hr = S_OK ;

        for (i = 0;
             i < m_pDVRSourcePinManager -> PinCount () && SUCCEEDED (hr) ;
             i++) {

            ZeroMemory (& mt, sizeof mt) ;

            ASSERT (m_pDVRSourcePinManager -> GetPin (i)) ;

            //  PREFIX note: there is an ASSERT there because this is an ASSERT,
            //      not a runtime error; the pins are densely packed, so if the
            //      count is out of sync with what is in the pin bank, it's a bug,
            //      not a runtime error

            hr = m_pDVRSourcePinManager -> GetPin (i) -> GetPinMediaType (& mt) ;
            if (SUCCEEDED (hr)) {
                pDVRReverseSender = GetDVRReverseSender_ (& mt) ;
                if (pDVRReverseSender) {
                    dw = m_Senders.SetVal (pDVRReverseSender, i) ;
                    hr = HRESULT_FROM_WIN32 (dw) ;
                    if (FAILED (hr)) {
                        delete pDVRReverseSender ;
                    }
                }
                else {
                    hr = E_OUTOFMEMORY ;
                }

                FreeMediaType (mt) ;
            }
        }
    }
    else {
        hr = S_OK ;
    }

    //  initialize the senders
    for (i = 0;
         i < m_Senders.ValCount () && SUCCEEDED (hr);
         i++) {

        pDVRReverseSender = NULL ;
        dw = m_Senders.GetVal (i, & pDVRReverseSender) ;
        ASSERT (dw == NOERROR) ;
        ASSERT (pDVRReverseSender) ;

        pDVRReverseSender -> Initialize (
                rtPTSBase
                ) ;
    }

    return hr ;
}

HRESULT
CDVR_Reverse_ReadController::Initialize (
    IN  REFERENCE_TIME  rtPTSBase
    )
{
    HRESULT hr ;

    TRACE_1 (LOG_AREA_DSHOW, 1,
        TEXT ("CDVR_Reverse_ReadController::Initialize (%I64d ms)"),
        DShowTimeToMilliseconds (rtPTSBase)) ;

    CDVRReadController::Initialize (rtPTSBase) ;

    //  first time around, we'll know to stop reading here
    m_cnsReadStop = m_pDVRReadManager -> GetCurReadPos () ;
    if (m_cnsReadStop == 0) {
        //  we're at the start; forget about it
        return E_FAIL ;
    }

    //  after the first time, we'll have a stream and a counter
    m_wReadStopStream = UNDEFINED ;

    //  init this so we first seek back from this position
    m_cnsReadStart = m_cnsReadStop ;

    //  init last seeked to offset
    m_cnsLastSeekTo = m_cnsReadStart ;

    //  we'll first seek back
    m_State = STATE_SEEK ;

    //  general purpose - we don't have a primary stream
    m_iPrimaryStream = UNDEFINED ;

    hr = InitializeSenders_ (rtPTSBase) ;

    return hr ;
}

HRESULT
CDVR_Reverse_ReadController::Initialize (
    IN  REFERENCE_TIME  rtPTSBase,
    IN  int             iPrimaryStream
    )
{
    HRESULT hr ;

    hr = Initialize (rtPTSBase) ;
    if (SUCCEEDED (hr)) {
        m_iPrimaryStream = iPrimaryStream ;
    }

    return hr ;
}

void
CDVR_Reverse_ReadController::NotifyNewRate (
    IN  double  dRate
    )
{
    CDVRReadController::NotifyNewRate (dRate) ;
    //  BUGBUG: set multiplier
}

HRESULT
CDVR_Reverse_ReadController::SeekReader_ (
    )
{
    QWORD   cnsSeekTo ;
    HRESULT hr ;

    //  only seek if the last read stretch wasn't from the start of content; note
    //    in the live case, this might be non-zero, but we deal with the condition
    //    fine below
    if (m_cnsReadStart != 0) {

        //  compute where we will seek to
        cnsSeekTo = m_cnsReadStart - Min <QWORD> (m_cnsReadStart, m_cnsIndexGranularity) ;

        //  make the seek
        hr = Seek_ (& cnsSeekTo) ;
        if (SUCCEEDED (hr)) {
            //  make sure that we did in fact seek backwards from where our last
            //    read stretch started from
            if (cnsSeekTo < m_cnsLastSeekTo) {

                //  we'll want to stop where we started last time
                m_cnsReadStop = m_cnsReadStart ;

                //  flag read start; this will be set by the first read (because
                //    it's set to UNDEFINED); first read can be different from
                //    the seeked to point
                m_cnsReadStart = UNDEFINED ;

                //  set this so the next time we seek, we'll know if we're progressing
                m_cnsLastSeekTo = cnsSeekTo ;

                TRACE_3 (LOG_AREA_SEEKING_AND_TRICK, 7,
                    TEXT ("CDVR_Reverse_ReadController::SeekReader_ () -- seeked to %I64d ms; [%I64d ms, %I64d ms]"),
                    ::WMSDKTimeToMilliseconds (cnsSeekTo), ::WMSDKTimeToMilliseconds (m_cnsReadStart), ::WMSDKTimeToMilliseconds (m_cnsReadStop)) ;
            }
            else {
                //  we failed to seek further back from than our last read
                //    stretch; assume we're out of content; position reader
                //    where we started our last read stretch, and post EOS

                TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 1,
                    TEXT ("CDVR_Reverse_ReadController::SeekReader_ () -- seeked to last read stretch offset; posting EOS (%I64 ms)"),
                    ::WMSDKTimeToMilliseconds (cnsSeekTo)) ;

                //  flush our internal queues
                InternalFlush_ () ;

                //  seek the reader back
                cnsSeekTo = m_cnsLastSeekTo ;
                Seek_ (& cnsSeekTo) ;

                //  code is EOS
                hr = NS_E_NO_MORE_SAMPLES ;
            }
        }
    }
    else {
        //  last read stretch was from the start; we're done; post EOS and exit

        TRACE_0 (LOG_AREA_SEEKING_AND_TRICK, 1,
            TEXT ("CDVR_Reverse_ReadController::SeekReader_ () -- last read stretch was from offset 0; posting EOS")) ;

        //  flush our internal queues
        InternalFlush_ () ;

        //  seek the reader back
        cnsSeekTo = 0 ;
        Seek_ (& cnsSeekTo) ;

        //  code is EOS
        hr = NS_E_NO_MORE_SAMPLES ;
    }

    return hr ;
}

HRESULT
CDVR_Reverse_ReadController::SendISSBufferLIFO_ (
    )
{
    HRESULT                 hr ;
    INSSBuffer *            pINSSBuffer ;
    QWORD                   cnsRead ;
    DWORD                   dwFlags ;
    WORD                    wStreamNum ;
    int                     iPinIndex ;
    CDVRReverseSender *     pDVRReverseSender ;
    DWORD                   dw ;
    CMediaSampleWrapper *   pMSWrapper ;
    IMediaSample2 *         pIMediaSample2 ;
    CDVROutputPin *         pDVROutputPin ;
    AM_MEDIA_TYPE *         pmtNew ;
    DWORD                   dwMuxedStreamStats ;

    hr = m_pDVRReadManager -> GetMSWrapperBlocking (& pMSWrapper) ;
    if (SUCCEEDED (hr)) {

        ASSERT (pMSWrapper) ;

        hr = m_ReadINSSBuffers.Pop (
                & pINSSBuffer,
                & cnsRead,
                & dwFlags,
                & wStreamNum
                ) ;
        if (SUCCEEDED (hr)) {

            TRACE_3 (LOG_AREA_SEEKING_AND_TRICK, 7,
                TEXT ("CDVR_Reverse_ReadController::SendISSBufferLIFO_ () -- popped %08xh (read = %I64d ms); stream %u"),
                pINSSBuffer, WMSDKTimeToMilliseconds (cnsRead), wStreamNum) ;

            iPinIndex = m_pDVRSourcePinManager -> PinIndexFromStreamNumber (wStreamNum) ;
            ASSERT (iPinIndex != UNDEFINED) ;

            if (ShouldSend_ (iPinIndex)) {
                dw = m_Senders.GetVal (iPinIndex, & pDVRReverseSender) ;
                if (dw == NOERROR) {

                    hr = m_pDVRReadManager -> Wrap (
                            pMSWrapper,
                            pINSSBuffer,
                            wStreamNum,
                            dwFlags,
                            cnsRead,
                            0,                      //  sample duration
                            & pDVROutputPin,
                            & pIMediaSample2,
                            & dwMuxedStreamStats,
                            & pmtNew
                            ) ;

                    if (SUCCEEDED (hr)) {
                        ASSERT (pDVRReverseSender) ;
                        ASSERT (pIMediaSample2) ;

                        hr = pDVRReverseSender -> Send (
                                pIMediaSample2,
                                pDVROutputPin,
                                cnsRead
                                ) ;

                        pIMediaSample2 -> Release () ;
                    }
                }
            }

            pINSSBuffer -> Release () ;
        }

        pMSWrapper -> Release () ;
    }

    return hr ;
}

HRESULT
CDVR_Reverse_ReadController::Process (
    )
{
    HRESULT         hr ;
    HRESULT         hr2 ;
    INSSBuffer *    pINSSBuffer ;
    QWORD           cnsCurrentRead ;
    DWORD           dwFlags ;
    WORD            wStreamNum ;
    QWORD           cnsStart ;
    QWORD           cnsStop ;

    //enum REV_CONTROLLER_STATE {
    //    STATE_SEEK,                 //  seek to our next read offset
    //    STATE_READ,                 //  read into our LIFO
    //    STATE_SEND                  //  send contents of LIFO
    //} ;

    //  PREFIX note: this is an ASSERT, not a runtime error; if we hit this
    //      the state has gotten wacky in our code, and testing should uncover
    //      those types of bugs
    ASSERT (m_State >= STATE_SEEK &&
            m_State <= STATE_SEND) ;

    switch (m_State) {

        case STATE_SEEK :

            hr = SeekReader_ () ;
            if (SUCCEEDED (hr)) {
                //  update to next state
                m_State = STATE_READ ;

                //  first read will set this
                ASSERT (m_cnsReadStart == UNDEFINED) ;
            }

            break ;

        case STATE_READ :

            hr = m_pDVRReadManager -> Read (
                    & pINSSBuffer,
                    & cnsCurrentRead,
                    & dwFlags,
                    & wStreamNum
                    ) ;

            if (SUCCEEDED (hr)) {
                ASSERT (pINSSBuffer) ;

                if (m_cnsReadStart == UNDEFINED) {
                    //  first read; set it
                    m_cnsReadStart = cnsCurrentRead ;

                    TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 7,
                        TEXT ("CDVR_Reverse_ReadController::Process () -- first read of read stretch; m_cnsReadStart = %I64d ms"),
                        ::WMSDKTimeToMilliseconds (m_cnsReadStart)) ;
                }

                //  until we read back up to where we started the last reads
                if (cnsCurrentRead < m_cnsReadStop) {

                    //  if this is the first, remove the discontinuity that has
                    //    been introduced by the seek since we're not
                    //    discontinuous based on what we are sending out
                    if (m_ReadINSSBuffers.Empty ()) {
                        dwFlags &= ~WM_SF_DISCONTINUITY ;
                    }

                    hr = m_ReadINSSBuffers.Push (
                            pINSSBuffer,
                            cnsCurrentRead,
                            dwFlags,
                            wStreamNum
                            ) ;

                    TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 7,
                        TEXT ("CDVR_Reverse_ReadController::Process () -- read & pushed INSSBuffer; %08xh (read = %I64d ms)"),
                        pINSSBuffer, WMSDKTimeToMilliseconds (cnsCurrentRead)) ;

#ifdef DEBUG
                    ::DumpINSSBuffer3Attributes (
                        pINSSBuffer,
                        cnsCurrentRead,
                        wStreamNum,
                        7
                        ) ;
#endif
                }
                else {
                    //  drop the buffer;
                    //  update state
                    m_State = STATE_SEND ;
                }

                pINSSBuffer -> Release () ;
            }
            else {
                //  might be something we can handle - check if we're trying to
                //    read from stale data
                hr2 = m_pDVRReadManager -> GetReaderContentBoundaries (& cnsStart, & cnsStop) ;
                if (SUCCEEDED (hr2)) {
                    if (cnsStart > m_cnsReadStart) {
                        //  valid content is now further forward than where we
                        //    started reading from; seek to start of content
                        //    and transition to 1x playback
                        m_pDVRReadManager -> SetNewSegmentStart (cnsStart) ;
                        hr = m_pDVRReadManager -> ConfigureForRate (_1X_PLAYBACK_RATE) ;
                    }
                }
            }

            break ;

        case STATE_SEND :
            if (!m_ReadINSSBuffers.Empty ()) {
                hr = SendISSBufferLIFO_ () ;
            }
            else {
                //  time for the next seek
                m_State = STATE_SEEK ;
            }

            break ;
    } ;

    return hr ;
}

//  ============================================================================
//  CDVR_R_FullFrame_ReadController
//  ============================================================================

CDVRReverseSender *
CDVR_R_FullFrame_ReadController::GetDVRReverseSender_ (
    IN  AM_MEDIA_TYPE * pmt
    )
{
    CDVRReverseSender * pDVRReverseSender ;

    //  check if this is mpeg-2 video
    if (IsMpeg2Video (pmt)) {

        //  mpeg-2 video; use the GOP sender
        pDVRReverseSender = new CDVRMpeg2_GOP_ReverseSender (
                                    m_pDVRReadManager,
                                    this,
                                    m_pDVRSourcePinManager,
                                    m_pPolicy,
                                    m_pDVRSendStatsWriter
                                    ) ;

    }
    else {
        //  punt
        pDVRReverseSender = CDVR_Reverse_ReadController::GetDVRReverseSender_ (pmt) ;
    }

    return pDVRReverseSender ;
}

//  ============================================================================
//  CDVR_R_KeyFrame_ReadController
//  ============================================================================

CDVRReverseSender *
CDVR_R_KeyFrame_ReadController::GetDVRReverseSender_ (
    IN  AM_MEDIA_TYPE * pmt
    )
{
    CDVRReverseSender * pDVRReverseSender ;

    //  check if this is mpeg-2 video
    if (IsMpeg2Video (pmt)) {

        //  mpeg-2 video; use the I-frame sender
        pDVRReverseSender = new CDVRMpeg2_IFrame_ReverseSender (
                                    m_pDVRReadManager,
                                    this,
                                    m_pDVRSourcePinManager,
                                    m_pPolicy,
                                    m_pDVRSendStatsWriter
                                    ) ;

    }
    else {
        //  punt
        pDVRReverseSender = CDVR_Reverse_ReadController::GetDVRReverseSender_ (pmt) ;
    }

    return pDVRReverseSender ;
}

//  ============================================================================
//  CDVRReadManager
//  ============================================================================

CDVRReadManager::CDVRReadManager (
    IN  CDVRPolicy *            pPolicy,
    IN  CDVRDShowSeekingCore *  pSeekingCore,
    IN  CDVRSourcePinManager *  pDVRSourcePinManager,
    IN  CDVRSendStatsWriter *   pDVRSendStatsWriter,
    IN  CDVRClock *             pDVRClock,
    OUT HRESULT *               phr
    ) : m_pDVRDShowReader       (NULL),
        m_ReaderThread          (this),
        m_pDVRSourcePinManager  (pDVRSourcePinManager),
        m_cnsCurrentPlayStart   (0),
        m_cnsCurrentPlayStop    (FURTHER),
        m_pPolicy               (pPolicy),
        m_cnsLastReadPos        (m_cnsCurrentPlayStart),
        m_pIRefClock            (NULL),
        m_pDVRClock             (pDVRClock),
        m_dCurRate              (_1X_PLAYBACK_RATE),
        m_CurController         (FORWARD_FULLFRAME),
        m_pSeekingCore          (pSeekingCore),
        m_pDVRSendStatsWriter   (pDVRSendStatsWriter),
        m_DVRIMediaSamplePool   (pDVRSendStatsWriter)
{
    TRACE_CONSTRUCTOR (TEXT ("CDVRReadManager")) ;

    ASSERT (m_pDVRSourcePinManager) ;
    ASSERT (m_pPolicy) ;
    ASSERT (m_pSeekingCore) ;
    ASSERT (m_pDVRSendStatsWriter) ;
    ASSERT (m_pDVRClock) ;

    m_pPolicy -> AddRef () ;

    ZeroMemory (m_ppDVRReadController, sizeof m_ppDVRReadController) ;

    InitializeCriticalSection (& m_crtTime) ;

    m_dDesiredBufferPoolSec = (double) (m_pPolicy -> Settings () -> BufferPoolMillis ()) / 1000.0 ;

    //  initialize this to a valid value; we reset it when we are activated
    m_dwMaxBufferPool = m_pPolicy -> Settings () -> AllocatorGetBufferCount () ;

    //  initialize size we're going to set our buffer pool to
    m_cBufferPool = m_pPolicy -> Settings () -> AllocatorGetBufferCount () ;

    //  set the initial buffer count; this may get upped if the stream is such that
    //    we cannot read sufficiently fast
    m_DVRIMediaSamplePool.SetMaxAllocate (m_cBufferPool) ;

    (* phr) = GetDVRReadController_ (
                m_CurController,
                this,
                m_pDVRSourcePinManager,
                m_pPolicy,
                m_pDVRSendStatsWriter,
                & m_ppDVRReadController [m_CurController]
                ) ;

    return ;
}

CDVRReadManager::~CDVRReadManager (
    )
{
    DWORD   i ;

    TRACE_DESTRUCTOR (TEXT ("CDVRReadManager")) ;

    //  terminate our reader thread
    TerminateReaderThread_ () ;
    RecycleReader_ (m_pDVRDShowReader) ;
    m_pDVRDShowReader = NULL ;

    //  free our read controllers
    for (i = 0; i < CONTROLLER_COUNT; i++) {
        delete m_ppDVRReadController [i] ;
    }

    //  done with the clock
    RELEASE_AND_CLEAR (m_pIRefClock) ;

    //  done with the policy object
    m_pPolicy -> Release () ;

    DeleteCriticalSection (& m_crtTime) ;
}

void
CDVRReadManager::OnStateRunning (
    IN  REFERENCE_TIME  rtStart
    )
{
    TimeLock_ () ;

    m_Runtime.Run (rtStart) ;

    TRACE_2 (LOG_AREA_TIME, 1,
        TEXT ("CDVRReadManager::OnStateRunning () - rtStart = %I64d ms; now = %I64d ms"),
        ::DShowTimeToMilliseconds (rtStart), ::DShowTimeToMilliseconds (RefTime ())) ;

    TimeUnlock_ () ;
}

void
CDVRReadManager::OnStatePaused (
    )
{
    TimeLock_ () ;

    m_Runtime.Pause (RefTime ()) ;

    TRACE_1 (LOG_AREA_TIME, 1,
        TEXT ("CDVRReadManager::OnStatePaused () - RunningTime = %I64d ms"),
        ::DShowTimeToMilliseconds (m_Runtime.RunningTime (RefTime ()))) ;

    TimeUnlock_ () ;
}

void
CDVRReadManager::OnStateStopped (
    )
{
    TimeLock_ () ;

    m_Runtime.Stop () ;

    TRACE_0 (LOG_AREA_TIME, 1,
        TEXT ("CDVRReadManager::OnStateStopped ()")) ;

    TimeUnlock_ () ;
}

REFERENCE_TIME
CDVRReadManager::RefTime (
    )
{
    REFERENCE_TIME  rtRefTime ;

    TimeLock_ () ;

    if (m_pIRefClock) {
        m_pIRefClock -> GetTime (& rtRefTime) ;
    }
    else {
        rtRefTime = 0 ;
    }

    TimeUnlock_ () ;

    return rtRefTime ;
}

HRESULT
CDVRReadManager::GetNextValidRead (
    IN OUT  QWORD *     pcns
    )
{
    HRESULT hr ;

    hr = m_pDVRDShowReader -> GetIDVRReader () -> GetFirstValidTimeAfter (
            (* pcns),
            pcns
            ) ;

    return hr ;
}

HRESULT
CDVRReadManager::GetPrevValidTime (
    IN OUT  QWORD *     pcns
    )
{
    HRESULT hr ;

    hr = m_pDVRDShowReader -> GetIDVRReader () -> GetLastValidTimeBefore (
            (* pcns),
            pcns
            ) ;

    return hr ;
}

HRESULT
CDVRReadManager::Process (
    )
{
    HRESULT hr ;

    ASSERT (m_ppDVRReadController [m_CurController]) ;
    hr = m_ppDVRReadController [m_CurController] -> Process () ;

    return hr ;
}

void
CDVRReadManager::SetCurTimelines (
    IN OUT  CTimelines *    pTimelines
    )
{
    ASSERT (m_pSeekingCore) ;
    m_pSeekingCore -> SetCurTimelines (pTimelines) ;
}

HRESULT
CDVRReadManager::QueueRateSegment (
    IN  double          dRate,
    IN  REFERENCE_TIME  rtPTSEffective
    )
{
    HRESULT hr ;

    ASSERT (m_pSeekingCore) ;
    hr = m_pSeekingCore -> QueueRateSegment (dRate, rtPTSEffective) ;

    return hr ;
}

HRESULT
CDVRReadManager::GetCurPlaytime (
    OUT     REFERENCE_TIME *    prtCurPlaytime
    )
{
    HRESULT hr ;

    ASSERT (m_pSeekingCore) ;
    hr = m_pSeekingCore -> GetCurPlaytime (prtCurPlaytime) ;

    return hr ;
}

HRESULT
CDVRReadManager::GetCurStreamtime (
    OUT REFERENCE_TIME *    prtCurStreamtime
    )
{
    HRESULT hr ;

    ASSERT (m_pSeekingCore) ;
    hr = m_pSeekingCore -> GetStreamTimeDShow (prtCurStreamtime) ;

    return hr ;
}

HRESULT
CDVRReadManager::GetCurRuntime (
    OUT REFERENCE_TIME *    prtCurRuntime
    )
{
    HRESULT hr ;

    ASSERT (m_pSeekingCore) ;
    hr = m_pSeekingCore -> GetRuntimeDShow (prtCurRuntime) ;

    return hr ;
}

void
CDVRReadManager::NotifyNewSegment (
    )
{
    REFERENCE_TIME  rtSegmentStart ;
    REFERENCE_TIME  rtSegmentStop ;

    GetCurrentStart (& rtSegmentStart) ;
    GetCurrentStop  (& rtSegmentStop) ;

    m_pDVRSourcePinManager -> NotifyNewSegment (rtSegmentStart, rtSegmentStop, m_dCurRate) ;
}

HRESULT
CDVRReadManager::GetDVRReadController_ (
    IN  CONTROLLER_CATEGORY     ControllerCat,
    IN  CDVRReadManager *       pDVRReadManager,
    IN  CDVRSourcePinManager *  pDVRSourcePinManager,
    IN  CDVRPolicy *            pPolicy,
    IN  CDVRSendStatsWriter *   pDVRSendStatsWriter,
    OUT CDVRReadController **   ppCDVRReadController
    )
{
    HRESULT hr ;

    ASSERT (pPolicy) ;
    ASSERT (pDVRReadManager) ;
    ASSERT (pDVRSourcePinManager) ;
    ASSERT (ppCDVRReadController) ;
    ASSERT (pDVRSendStatsWriter) ;

    (* ppCDVRReadController) = NULL ;

    //enum CONTROLLER_CATEGORY {
    //    FORWARD_FULLFRAME,          //  1x or trick; full-frame decode & render
    //    FORWARD_KEYFRAME,           //  > 1x; key frames only
    //    BACKWARD_FULLFRAME,         //  < 0; full-frame decode & render
    //    BACKWARD_KEYFRAME,          //  < 0; key-frame only
    //} ;

    //  yes PREFIX, these are validated elsewhere
    ASSERT (ControllerCat >= FORWARD_FULLFRAME &&
            ControllerCat <= BACKWARD_KEYFRAME) ;

    switch (ControllerCat) {

        case FORWARD_FULLFRAME :
            (* ppCDVRReadController) = new CDVR_F_FullFrame_ReadController (
                                                pDVRReadManager,
                                                pDVRSourcePinManager,
                                                pPolicy,
                                                pDVRSendStatsWriter
                                                ) ;
            hr = ((* ppCDVRReadController) ? S_OK : E_OUTOFMEMORY) ;
            break ;

        case FORWARD_KEYFRAME :
            (* ppCDVRReadController) = new CDVR_F_KeyFrame_ReadController (
                                                pDVRReadManager,
                                                pDVRSourcePinManager,
                                                pPolicy,
                                                pDVRSendStatsWriter
                                                ) ;
            hr = ((* ppCDVRReadController) ? S_OK : E_OUTOFMEMORY) ;
            break ;

        case BACKWARD_FULLFRAME :
            (* ppCDVRReadController) = new CDVR_R_FullFrame_ReadController (
                                                pDVRReadManager,
                                                pDVRSourcePinManager,
                                                pPolicy,
                                                pDVRSendStatsWriter
                                                ) ;
            hr = ((* ppCDVRReadController) ? S_OK : E_OUTOFMEMORY) ;
            break ;

        case BACKWARD_KEYFRAME :
            (* ppCDVRReadController) = new CDVR_R_KeyFrame_ReadController (
                                                pDVRReadManager,
                                                pDVRSourcePinManager,
                                                pPolicy,
                                                pDVRSendStatsWriter
                                                ) ;
            hr = ((* ppCDVRReadController) ? S_OK : E_OUTOFMEMORY) ;
            break ;

        //  for PREFIX
        default :
            ASSERT (0) ;
            hr = E_FAIL ;
            break ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::SetPinRates_ (
    IN  double          dPinRate,
    IN  REFERENCE_TIME  rtRateStart,
    IN  BOOL            fFullFramePlay,
    IN  int             iPrimaryStream
    )
{
    CDVROutputPin * pDVROutputPin ;
    HRESULT         hr ;
    int             i ;

    ASSERT (m_pDVRSourcePinManager) ;

    //  process each pin
    for (i = 0, hr = S_OK;
         i < m_pDVRSourcePinManager -> PinCount () && SUCCEEDED (hr);
         i++) {

        pDVROutputPin = m_pDVRSourcePinManager -> GetNonRefdOutputPin (i) ;
        ASSERT (pDVROutputPin) ;

        //  PREFIX note: there is an ASSERT there because this is an ASSERT,
        //      not a runtime error; the pins are densely packed, so if the
        //      count is out of sync with what is in the pin bank, it's a bug,
        //      not a runtime error

        //  set the rate always, even if we're not going to play it; if we
        //   don't set set it on all streams, including those that won't play
        //   it, streams will then be different timelines
        if (pDVROutputPin -> IsConnected ()) {

            hr = pDVROutputPin -> SetCurRate (dPinRate, rtRateStart) ;

            TRACE_6 (LOG_AREA_SEEKING_AND_TRICK, 1,
                TEXT ("CDVRReadManager::SetPinRates_ (%2.1f, %I64d, %08xh, %d); pin [%d] -> SetCurRate() call returned %08xh"),
                dPinRate, rtRateStart, fFullFramePlay, iPrimaryStream, i, hr) ;

            //  successfully setting the pin rate should have toggled the pin's
            //    rate-compatibility state
            ASSERT (SUCCEEDED (hr) ? ((pDVROutputPin -> IsPlayrateCompatible () && pDVROutputPin -> IsFrameRateSupported (dPinRate)) ||
                                      (pDVROutputPin -> IsNotPlayrateCompatible () && !pDVROutputPin -> IsFrameRateSupported (dPinRate))) :
                                      TRUE) ;
        }
        else {
            ASSERT (pDVROutputPin -> GetBankStoreIndex () != iPrimaryStream) ;
        }
    }

    return hr ;
}

HRESULT
CDVRReadManager::Read (
    OUT INSSBuffer **   ppINSSBuffer,
    OUT QWORD *         pcnsCurrentRead,
    OUT DWORD *         pdwFlags,
    OUT WORD *          pwStreamNum
    )
{
    QWORD   cnsSampleDuration ;
    HRESULT hr ;
    LONG    lLastReadPosMillis ;
    LONG    lTimeholeMillis ;
    QWORD   cnsCurContentDuration ;

    ASSERT (m_pDVRDShowReader) ;
    hr = m_pDVRDShowReader -> Read (
            ppINSSBuffer,
            pcnsCurrentRead,
            & cnsSampleDuration,
            pdwFlags,
            pwStreamNum
            ) ;
    m_pDVRSendStatsWriter -> INSSBufferRead (hr) ;

    if (SUCCEEDED (hr)) {

        //
        //  check for a timehole; after a seek, it's possible to "jitter"
        //    slightly from the seeked to position, so we make sure that we
        //    we're only looking if we're moving ahead; steady state this will
        //    be the case; DVRIO ensures that these timestamps monotonically
        //    increase inside the file
        //

        if ((* pcnsCurrentRead) >= m_cnsLastReadPos &&
            (* pcnsCurrentRead) - m_cnsLastReadPos >= m_cnsTimeholeThreshole) {

            lLastReadPosMillis = (LONG) ::WMSDKTimeToMilliseconds (m_cnsLastReadPos) ;
            lTimeholeMillis = (LONG) ::WMSDKTimeToMilliseconds ((* pcnsCurrentRead) - m_cnsLastReadPos) ;

            //  time hole event
            m_pPolicy -> EventSink () -> OnEvent (
                STREAMBUFFER_EC_TIMEHOLE,
                lLastReadPosMillis,
                lTimeholeMillis
                ) ;

            TRACE_4 (LOG_AREA_DSHOW, 1,
                TEXT ("timehole detected: last read = %I64d (%I64d ms); next valid = %I64d (%I64d ms)"),
                m_cnsLastReadPos, ::WMSDKTimeToMilliseconds (m_cnsLastReadPos),
                (* pcnsCurrentRead), ::WMSDKTimeToMilliseconds (* pcnsCurrentRead)) ;
        }

        //  last read
        m_cnsLastReadPos = (* pcnsCurrentRead) ;
    }
    else {
        TRACE_ERROR_1 (TEXT ("CDVRReadManager::Read () : m_pDVRDShowReader -> Read () returned %08xh"), hr) ;
    }

    //  if this is a live source, clock-slave
    if (IsLiveSource ()) {
        cnsCurContentDuration = GetContentDuration () ;

        ASSERT (m_pDVRClock) ;
        m_pDVRClock -> OnSample (& cnsCurContentDuration) ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::Wrap (
    IN  CMediaSampleWrapper *   pMSWrapper,
    IN  INSSBuffer *            pINSSBuffer,            //  !not! ref'd
    IN  WORD                    wStreamNum,
    IN  DWORD                   dwFlags,                //  from the read
    IN  QWORD                   cnsCurrentRead,
    IN  QWORD                   cnsSampleDuration,
    OUT CDVROutputPin **        ppDVROutputPin,
    OUT IMediaSample2 **        ppIMS2,
    OUT DWORD *                 pdwMuxedStreamStats,
    OUT AM_MEDIA_TYPE **        ppmtNew                 //  dynamic format change
    )
{
    HRESULT hr ;
    BYTE *  pbBuffer ;
    DWORD   dwBufferLength ;

    ASSERT (ppIMS2) ;
    ASSERT (ppDVROutputPin) ;
    ASSERT (pMSWrapper) ;

    //  get the pin
    (* ppDVROutputPin) = m_pDVRSourcePinManager -> GetNonRefdOutputPin (wStreamNum) ;

    //  only go through the drill if the pin is connected
    if (* ppDVROutputPin) {
        hr = pINSSBuffer -> GetBufferAndLength (
                & pbBuffer,
                & dwBufferLength
                ) ;
        if (SUCCEEDED (hr)) {
            //  wrap the INSSBuffer in an IMediaSample2
            hr = pMSWrapper -> Init (
                    pINSSBuffer,
                    pbBuffer,
                    dwBufferLength
                    ) ;
            if (SUCCEEDED (hr)) {
                //  translate the flags
                ASSERT ((* ppDVROutputPin) -> GetTranslator ()) ;
                hr = (* ppDVROutputPin) -> GetTranslator () -> SetAttributesDShow (
                        m_pDVRSendStatsWriter,
                        pINSSBuffer,
                        cnsCurrentRead,
                        cnsSampleDuration,
                        dwFlags,
                        m_dCurRate,
                        pdwMuxedStreamStats,
                        pMSWrapper,
                        ppmtNew
                        ) ;

                if (SUCCEEDED (hr)) {
                    (* ppIMS2) = pMSWrapper ;
                    (* ppIMS2) -> AddRef () ;
                }
            }
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::GetMSWrapper (
    IN  BOOL                    fBlocking,
    OUT CMediaSampleWrapper **  ppMSWrapper     //  ref'd if success
    )
{
    HRESULT hr ;

    hr = S_OK ;

    if (fBlocking) {
        (* ppMSWrapper) = m_DVRIMediaSamplePool.Get () ;
    }
    else {
        (* ppMSWrapper) = m_DVRIMediaSamplePool.TryGet () ;
    }

    if (!(* ppMSWrapper)) {
        //  getlasterror
        hr = E_OUTOFMEMORY ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::ReadAndWrapForward_ (
    IN  BOOL                fWaitMediaSample,       //  vs. fail
    OUT INSSBuffer **       ppINSSBuffer,           //  !not! ref'd
    OUT IMediaSample2 **    ppIMS2,
    OUT CDVROutputPin **    ppDVROutputPin,
    OUT DWORD *             pdwMuxedStreamStats,
    OUT AM_MEDIA_TYPE **    ppmtNew,                //  dynamic format change
    OUT QWORD *             pcnsCurrentRead
    )
{
    HRESULT                 hr ;
    DWORD                   dwFlags ;
    WORD                    wStreamNum ;
    CMediaSampleWrapper *   pMSWrapper ;
    BYTE *                  pbBuffer ;
    DWORD                   dwBufferLength ;

    ASSERT (ppIMS2) ;
    ASSERT (m_pDVRDShowReader) ;
    ASSERT (ppINSSBuffer) ;

    (* ppINSSBuffer)    = NULL ;
    (* ppIMS2)          = NULL ;
    (* ppmtNew)         = NULL ;
    (* pcnsCurrentRead) = 0 ;

    hr = GetMSWrapper (fWaitMediaSample, & pMSWrapper) ;
    if (FAILED (hr)) { goto cleanup ; }

    hr = Read (
            ppINSSBuffer,
            pcnsCurrentRead,
            & dwFlags,
            & wStreamNum
            ) ;

    if (SUCCEEDED (hr)) {

        ASSERT (* ppINSSBuffer) ;

        //  make sure we're within our playback boundaries
        if ((* pcnsCurrentRead) < m_cnsCurrentPlayStop) {

            hr = Wrap (
                    pMSWrapper,
                    (* ppINSSBuffer),
                    wStreamNum,
                    dwFlags,
                    (* pcnsCurrentRead),
                    0,                      //  sample duration; don't care
                    ppDVROutputPin,
                    ppIMS2,
                    pdwMuxedStreamStats,
                    ppmtNew
                    ) ;
        }
        else {
            //  we're at or beyond our play stop; post an end of stream
            hr = NS_E_NO_MORE_SAMPLES ;
        }

        (* ppINSSBuffer) -> Release () ;
    }

    if (FAILED (hr)) {
        (* ppINSSBuffer) = NULL ;
    }

    cleanup :

    RELEASE_AND_CLEAR (pMSWrapper) ;

    return hr ;
}

void
CDVRReadManager::OnFatalError (
    IN  HRESULT hr
    )
{
    //  only post up a read failure if we hit a case that is not controlled i.e.
    //    an intentional failure
    if (hr != (HRESULT) NS_E_NO_MORE_SAMPLES) {

        //  fatal error event
        m_pPolicy -> EventSink () -> OnEvent (
            STREAMBUFFER_EC_READ_FAILURE,
            (LONG_PTR) hr,
            0
            ) ;
    }
}

HRESULT
CDVRReadManager::ErrorHandler (
    IN  HRESULT hr
    )
{
    ASSERT (m_ppDVRReadController [m_CurController]) ;
    hr = m_ppDVRReadController [m_CurController] -> ErrorHandler (hr) ;

    return hr ;
}

void
CDVRReadManager::SetReader_ (
    IN CDVRDShowReader *    pDVRDShowReader
    )
{
    ASSERT (pDVRDShowReader) ;
    m_pDVRDShowReader = pDVRDShowReader ;
}

HRESULT
CDVRReadManager::CancelReads_ (
    )
{
    HRESULT hr ;

    if (m_pDVRDShowReader) {
        hr = m_pDVRDShowReader -> GetIDVRReader () -> Cancel () ;
    }
    else {
        hr = S_OK ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::PauseReaderThread_ (
    )
{
    HRESULT hr ;

    m_ReaderThread.Lock () ;

    hr = m_ReaderThread.NotifyPause () ;
    if (SUCCEEDED (hr)) {
        m_DVRIMediaSamplePool.SetStateNonBlocking () ;
        hr = CancelReads_ () ;
        if (SUCCEEDED (hr)) {
            hr = m_ReaderThread.WaitPaused () ;
        }
    }

    m_ReaderThread.Unlock () ;

    return hr ;
}

HRESULT
CDVRReadManager::TerminateReaderThread_ (
    )
{
    HRESULT hr ;

    m_ReaderThread.Lock () ;

    hr = m_ReaderThread.NotifyExit () ;
    if (SUCCEEDED (hr)) {
        hr = CancelReads_ () ;
        if (SUCCEEDED (hr)) {
            hr = m_ReaderThread.WaitExited () ;
        }
    }

    m_ReaderThread.Unlock () ;

    return hr ;
}

HRESULT
CDVRReadManager::RunReaderThread_ (
    IN  BOOL    fRunPaused
    )
{
    HRESULT hr ;

    m_ReaderThread.Lock () ;

    //  make sure reader thread will start at least close within the ballpark;
    //   don't check return code here - reader thread will do this as well,
    //   and may loop a few times on recoverable errors, all of which are
    //   checked in its loop; we just try and go
    CheckSetStartWithinContentBoundaries_ (& m_cnsCurrentPlayStart, m_cnsCurrentPlayStop) ;

    //  make sure this one's reset
    ReaderReset () ;

    //  never run the reader thread without setting this
    m_DVRIMediaSamplePool.SetStateBlocking () ;

    ASSERT (m_ppDVRReadController [m_CurController]) ;

    //  now resume the thread, though we may resume it as paused if we're going
    //   to wait for a first seek
    if (!fRunPaused) {
        hr = m_ReaderThread.GoThreadGo () ;
    }
    else {
        hr = m_ReaderThread.GoThreadPause () ;
    }

    m_ReaderThread.Unlock () ;

    return hr ;
}

HRESULT
CDVRReadManager::SeekReader (
    IN OUT  QWORD * pcnsSeekStreamTime,
    IN      QWORD   cnsStop
    )
{
    HRESULT hr ;
    int     i ;
    QWORD   qwEarliest ;
    QWORD   qwEarliestValid ;
    QWORD   qwLatestValid ;

    //  these values should make sense ..
    ASSERT ((* pcnsSeekStreamTime) < cnsStop) ;

    for (i = 0; i < MAX_STALE_SEEK_ATTEMPTS; i++) {
        hr = m_pDVRDShowReader -> GetIDVRReader () -> Seek (* pcnsSeekStreamTime) ;
        if (SUCCEEDED (hr)) {

            m_cnsLastReadPos = (* pcnsSeekStreamTime) ;

            TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 4,
                TEXT ("CDVRReadManager::SeekReader(); succeeded : %I64d (%d sec)"),
                (* pcnsSeekStreamTime), WMSDKTimeToSeconds (* pcnsSeekStreamTime)) ;

            break ;
        }

        //  something failed; there are some failures we can recover from such
        //   as seeking to a time that has been overwritten by the ringbuffer
        //   logic;

        if (hr == HRESULT_FROM_WIN32 (ERROR_SEEK)) {

            TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 1,
                TEXT ("CDVRReadManager::SeekReader(%d sec); tried to seek out of bounds - checking .."),
                WMSDKTimeToSeconds (* pcnsSeekStreamTime)) ;

            //  try to adjust start position forward/backwards
            hr = CheckSetStartWithinContentBoundaries_ (pcnsSeekStreamTime, cnsStop) ;
            if (FAILED (hr)) {

                //  unrecoverable; we are most likely being asked to seek outside
                //   the valid boundaries, but our stop value makes this impossible;
                //   bail

                TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 1,
                    TEXT ("CDVRReadManager::SeekReader(); .. checked; unrecoverable error (%08xh); aborting"),
                    hr) ;

                break ;
            }
            else {
                m_cnsLastReadPos = (* pcnsSeekStreamTime) ;
            }
        }
        else {
            //  an unrecoverable error has occured; abort
            break ;
        }
    }

    return hr ;
}

HRESULT
CDVRReadManager::Active (
    IN  IReferenceClock *   pIRefClock
    )
{
    HRESULT hr ;
    BOOL    fRunPaused ;

    if (!m_ppDVRReadController [m_CurController]) {
        hr = E_UNEXPECTED ;
        return hr ;
    }

    //  compute how much buffering we'll grow to if necessary
    m_dwMaxBufferPool = m_pPolicy -> Settings () -> MaxBufferPoolPerStream () * m_pDVRSourcePinManager -> ConnectedCount () ;
    TRACE_1 (LOG_TRACE, 1, TEXT ("ACTIVE: %u wrappers in pool"), CurMaxWrapperCount ()) ;

    //  initialize size we're going to set our buffer pool to
    m_cBufferPool = m_pPolicy -> Settings () -> AllocatorGetBufferCount () ;

    m_pIRefClock = pIRefClock ;
    if (m_pIRefClock) {
        m_pIRefClock -> AddRef () ;
    }

    TRACE_3 (LOG_AREA_TIME, 1,
        TEXT ("CDVRReadManager::Active -- pIRefClock (%08xh) ?= pDVRClock (%08xh) -- %s"),
        pIRefClock, m_pDVRClock, ((LPVOID) pIRefClock == (LPVOID) m_pDVRClock ? TEXT ("TRUE") : TEXT ("FALSE"))) ;    //  IRefClock is first in v-table of CDVRClock ..

    //  we may start the thread paused
    fRunPaused = OnActiveWaitFirstSeek_ () ;

    if (m_pDVRSourcePinManager -> SupportTrickMode ()) {
        ConfigureForRate (_1X_PLAYBACK_RATE) ;
    }

    hr = m_ppDVRReadController [m_CurController] -> Initialize () ;
    if (SUCCEEDED (hr)) {
        hr = RunReaderThread_ (fRunPaused) ;
    }

    m_cnsTimeholeThreshole = ::MillisToWMSDKTime (m_pPolicy -> Settings () -> TimeholeThresholdMillis ()) ;

    return hr ;
}

HRESULT
CDVRReadManager::Inactive (
    )
{
    HRESULT hr ;

    hr = TerminateReaderThread_ () ;

    if (m_ppDVRReadController [m_CurController]) {

        m_ppDVRReadController [m_CurController] -> Reset () ;

        //  setup the right controller for 1x playback when we restart; output
        //    pins will reset themselves as well
        if (m_pDVRSourcePinManager -> SupportTrickMode ()) {
            SetPlaybackRate (_1X_PLAYBACK_RATE) ;
        }
    }

    RELEASE_AND_CLEAR (m_pIRefClock) ;

    return hr ;
}

HRESULT
CDVRReadManager::CheckSetStartWithinContentBoundaries_ (
    IN OUT  QWORD * pcnsStart,
    IN      QWORD   cnsStop
    )
{
    HRESULT hr ;
    QWORD   qwContentStart ;
    QWORD   qwContentStop ;

    //  retrieve the valid boundaries
    hr = GetReaderContentBoundaries (& qwContentStart, & qwContentStop) ;

    if (SUCCEEDED (hr)) {

        //  are we earlier than valid ?
        if ((* pcnsStart) < qwContentStart) {

            //  given our stop time, can we adjust ?
            if (qwContentStart < cnsStop) {

                TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                    TEXT ("CDVRReadManager::CheckSetStartWithinContentBoundaries_ (); OOB(-) start moved from %d sec -> %d sec"),
                    ::WMSDKTimeToMilliseconds ((* pcnsStart)), ::WMSDKTimeToMilliseconds (qwContentStart)) ;

                //  adjust time forward - we may adjust to most forward
                if (AdjustStaleReaderToEarliest_ ()) {
                    //  adjust start up to earliest good position
                    (* pcnsStart) = qwContentStart ;
                }
                else {
                    //  adjust start to latest good
                    (* pcnsStart) = qwContentStop ;
                }

                //  success
                hr = S_OK ;
            }
            else {
                //  no wiggle room wrt our stop time; fail
                hr = VFW_E_START_TIME_AFTER_END ;
            }
        }
        //  are we later than valid ?
        else if ((* pcnsStart) > qwContentStop) {

            //  given our stop time, can we adjust ?
            if (cnsStop > qwContentStop) {

                TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                    TEXT ("CDVRReadManager::CheckSetStartWithinContentBoundaries_ (); OOB(+) start moved from %d sec -> %d sec"),
                    ::WMSDKTimeToMilliseconds ((* pcnsStart)), ::WMSDKTimeToMilliseconds (qwContentStop)) ;

                //  adjust start time backwards
                (* pcnsStart) = qwContentStop ;

                //  success
                hr = S_OK ;
            }
            else {
                //  no wiggle room wrt our stop time; fail
                hr = VFW_E_START_TIME_AFTER_END ;
            }
        }
        else {
            //  start time is within the legal boundaries; so we're ok
            hr = S_OK ;

            TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                TEXT ("CDVRReadManager::CheckSetStartWithinContentBoundaries_ (); IN BOUNDS - %I64d ms"),
                ::WMSDKTimeToMilliseconds ((* pcnsStart)), ::WMSDKTimeToMilliseconds (qwContentStop)) ;
        }
    }

    return hr ;
}

#if 0

HRESULT
CDVRReadManager::ReaderThreadSeekTo  (
    IN  REFERENCE_TIME *    prtStart,
    IN  REFERENCE_TIME *    prtStop,
    IN  double              dPlaybackRate,
    IN  REFERENCE_TIME      rtPTSBase
    )
{
    HRESULT hr ;
    BOOL    fThreadRunning ;

    ASSERT (prtStart) ;
    //  prtStop can be NULL

    //  validate that the start & stop times make sense wrt each other, if
    //   a stop time is specified
    if (prtStop &&
        (* prtStart) >= (* prtStop)) {

        return VFW_E_START_TIME_AFTER_END ;
    }

    //  this call may have no effect i.e. if we're already at this rate, this
    //    does nothing; if it does change, this call will queue a new segment
    //    out
    hr = ConfigureForRate (dPlaybackRate) ;
    if (SUCCEEDED (hr)) {

        //  set the start/stop times; stop time only if specified; must do this
        //    after after we set the playback rate, because it generates a new
        //    segment at "current" position
        m_cnsCurrentPlayStart   = DShowToWMSDKTime (* prtStart) ;
        m_cnsCurrentPlayStop    = (prtStop ? DShowToWMSDKTime (* prtStop) : m_cnsCurrentPlayStop) ;

        //  make sure we're at least in the ballpark with start/stop
        CheckSetStartWithinContentBoundaries_ (& m_cnsCurrentPlayStart, m_cnsCurrentPlayStop) ;

        //  if the playback rate changed, controller may have been initialized
        //    specifically for playback rate change; but controllers must be
        //    able to be initialized > once, from a rate change & from a seek,
        //    and have the initializations cummulative;
        //  BUGBUG: have a seeking init & a rate change init ?
        hr = m_ppDVRReadController [m_CurController] -> Initialize (rtPTSBase) ;
    }

    TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 1,
        TEXT ("CDVRReadManager::ReaderThreadSeekTo (); seeked to %I64d ms"),
        ::WMSDKTimeToMilliseconds (m_cnsCurrentPlayStart)) ;

    return hr ;
}

#endif

BOOL
CDVRReadManager::SeekIsNoop_ (
    IN  REFERENCE_TIME *    prtSeekTo,
    IN  double              dPlaybackRate
    )
{
    HRESULT         hr ;
    BOOL            r ;
    REFERENCE_TIME  rtStart ;
    REFERENCE_TIME  rtEOF ;
    REFERENCE_TIME  rtCurPos ;
    REFERENCE_TIME  rtDelta ;

    r = FALSE ;

    if (m_dCurRate == dPlaybackRate) {
        //  only apply this if there's not going to be a coinciding rate change

        hr = GetContentExtent (& rtStart, & rtEOF) ;
        if (SUCCEEDED (hr)) {
            //  adjust our target seek point to be within bounds
            if ((* prtSeekTo) > rtEOF) {
                (* prtSeekTo) = rtEOF ;
            }
            else if ((* prtSeekTo) < rtStart) {
                (* prtSeekTo) = rtStart ;
            }

            //  get current position
            hr = GetCurStreamtime (& rtCurPos) ;
            if (SUCCEEDED (hr)) {

                //  special case the 1x, seek to live case (i.e. within min
                //    near live)
                if (m_dCurRate == _1X_PLAYBACK_RATE &&
                    (* prtSeekTo) > rtEOF - Min <REFERENCE_TIME> (MillisToDShowTime (m_pPolicy -> Settings () -> MinNearLiveMillis ()), rtEOF)) {

                    if (m_ppDVRReadController [m_CurController]) {
                        ASSERT (m_CurController == FORWARD_FULLFRAME) ;
                        //  don't count the PTS padding in our current position
                        rtCurPos -= Min <REFERENCE_TIME> (
                                        rtCurPos,
                                        ::MillisToDShowTime (m_ppDVRReadController [m_CurController] -> GetCurPTSPaddingMillis ())
                                        ) ;
                    }

                    //  if we've overpadded ourselves i.e. pushed the real cur position
                    //    out of the min near live position, then we should be able
                    //    to seek; if we've padded ourselves with <= the min near
                    //    live, then that's what we'd immediately have to do again,
                    //    so noop that case
                    r = (rtCurPos > rtEOF - Min <REFERENCE_TIME> (
                                                MillisToDShowTime (m_pPolicy -> Settings () -> MinNearLiveMillis () + m_pPolicy -> Settings () -> LowBufferPaddingMillis ()),
                                                rtEOF)
                                                ) ;

                    TRACE_3 (LOG_AREA_SEEKING_AND_TRICK, 1,
                        TEXT ("CDVRReadManager::SeekIsNoop_ () [NEAR LIVE] returning %s; now = %I64d ms; seekto = %I64d ms"),
                        r ? TEXT ("TRUE") : TEXT ("FALSE"),
                        ::DShowTimeToMilliseconds (rtCurPos),
                        ::DShowTimeToMilliseconds ((* prtSeekTo)),
                        ) ;
                }
                else {
                    //  otherwise we just measure the delta between cur pos and
                    //    where we're going
                    rtDelta = Abs <REFERENCE_TIME> ((* prtSeekTo) - rtCurPos) ;

                    //  if within threshold, seek will be a noop
                    r = (rtDelta <= ::MillisToDShowTime (m_pPolicy -> Settings () -> SeekNoopMillis ())) ;

                    TRACE_3 (LOG_AREA_SEEKING_AND_TRICK, 1,
                        TEXT ("CDVRReadManager::SeekIsNoop_ () [NOT NEAR LIVE] returning %s; now = %I64d ms; seekto = %I64d ms"),
                        r ? TEXT ("TRUE") : TEXT ("FALSE"),
                        ::DShowTimeToMilliseconds (rtCurPos),
                        ::DShowTimeToMilliseconds ((* prtSeekTo)),
                        ) ;
                }
            }
        }
    }

    return r ;
}

HRESULT
CDVRReadManager::SeekTo (
    IN OUT  REFERENCE_TIME *    prtStart,
    IN OUT  REFERENCE_TIME *    prtStop,            //  OPTIONAL
    IN      double              dPlaybackRate,
    OUT     BOOL *              pfSeekIsNoop
    )
{
    HRESULT     hr ;
    BOOL        fThreadRunning ;
    CTimelines  Timelines ;

    ASSERT (pfSeekIsNoop) ;
    ASSERT (prtStart) ;
    //  prtStop can be NULL

    //  validate that the start & stop times make sense wrt each other, if
    //   a stop time is specified
    if (prtStop &&
        (* prtStart) >= (* prtStop)) {

        return VFW_E_START_TIME_AFTER_END ;
    }

    //  all is valid, run the drill
    m_ReaderThread.Lock () ;

    (* pfSeekIsNoop) = SeekIsNoop_ (prtStart, dPlaybackRate) ;
    if (!(* pfSeekIsNoop)) {
        //  if the thread is running
        fThreadRunning = m_ReaderThread.IsRunning () ;
        if (fThreadRunning) {
            //  begin flush before pausing thread; downstream components will
            //   then be able to fail pended deliveries
            DeliverBeginFlush () ;

            //  pause the reader thread (synchronous call)
            PauseReaderThread_ () ;

            //  flush internally
            m_ppDVRReadController [m_CurController] -> Reset () ;

            //  done flushing
            DeliverEndFlush () ;

            //  reset our buffer pool
            m_cBufferPool = m_pPolicy -> Settings () -> AllocatorGetBufferCount () ;
            m_DVRIMediaSamplePool.SetMaxAllocate (m_cBufferPool) ;
        }

        SetCurTimelines (& Timelines) ;

        //  this call may have no effect i.e. if we're already at this rate, this
        //    does nothing; if it does change, this call will queue a new segment
        //    out
        hr = ConfigureForRate (
                dPlaybackRate,
                & Timelines,
                !m_ReaderThread.IsStopped ()
                ) ;

        if (SUCCEEDED (hr)) {

            //  set the start/stop times; stop time only if specified; must do this
            //    after after we set the playback rate, because it generates a new
            //    segment at "current" position
            m_cnsCurrentPlayStart   = ::DShowToWMSDKTime (* prtStart) ;
            m_cnsCurrentPlayStop    = (prtStop ? ::DShowToWMSDKTime (* prtStop) : m_cnsCurrentPlayStop) ;

            //  make sure we're at least in the ballpark with start/stop
            CheckSetStartWithinContentBoundaries_ (& m_cnsCurrentPlayStart, m_cnsCurrentPlayStop) ;

            //  set outgoing
            (* prtStart) = ::WMSDKToDShowTime (m_cnsCurrentPlayStart) ;
            if (prtStop) {
                (* prtStop) = ::WMSDKToDShowTime (m_cnsCurrentPlayStop) ;
            }

            //  if the playback rate changed, controller may have been initialized
            //    specifically for playback rate change; but controllers must be
            //    able to be initialized > once, from a rate change & from a seek,
            //    and have the initializations cummulative;
            hr = m_ppDVRReadController [m_CurController] -> Initialize (Timelines.get_Playtime ()) ;
        }

        if (SUCCEEDED (hr) &&
            fThreadRunning) {

            //  resume it
            hr = RunReaderThread_ () ;
        }
    }
    else {
        hr = S_OK ;
    }

    m_ReaderThread.Unlock () ;

    TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 1,
        TEXT ("CDVRReadManager::SeekTo (); seeked to %I64d ms"),
        ::WMSDKTimeToMilliseconds (m_cnsCurrentPlayStart)) ;

    return hr ;
}

HRESULT
CDVRReadManager::SetStop (
    IN REFERENCE_TIME rtStop
    )
{
    HRESULT hr ;
    BOOL    r ;
    QWORD   cnsStop ;

    //  convert
    cnsStop = DShowToWMSDKTime (rtStop) ;

    m_ReaderThread.Lock () ;

    r = m_ReaderThread.IsRunning () ;
    if (r) {
        //  the reader thread is running; we can set this value on the fly
        //   as long as it isn't behind the last read; if it is, there'd be
        //   1 extra read, which would immediately cause the reader thread
        //   to fall out; not catastrophic but there's sufficient level of
        //   bogosity to warrant a failed call; make the check now -- for now
        //   with 0 tolerance
        if (cnsStop > m_cnsLastReadPos) {
            m_cnsCurrentPlayStop = cnsStop ;
            hr = S_OK ;
        }
        else {
            //  nope .. fail the call
            hr = VFW_E_TIME_ALREADY_PASSED ;
        }
    }
    else {
        //  only enforce that stop occurs after start; it's legal to set it
        //   to a time that will never occur
        if (cnsStop > m_cnsCurrentPlayStart) {
            m_cnsCurrentPlayStop = cnsStop ;
            hr = S_OK ;
        }
        else {
            hr = VFW_E_START_TIME_AFTER_END ;
        }
    }

    m_ReaderThread.Unlock () ;

    return hr ;
}

HRESULT
CDVRReadManager::GetCurrentStart (
    OUT REFERENCE_TIME * prtStart
    )
{
    ASSERT (prtStart) ;

    (* prtStart) = WMSDKToDShowTime (m_cnsCurrentPlayStart) ;

    return S_OK ;
}

HRESULT
CDVRReadManager::GetCurrentStop (
    OUT REFERENCE_TIME * prtStop
    )
{
    ASSERT (prtStop) ;

    //  m_cnsCurrentPlayStop might be FURTHER, with means EOS; if that's the
    //   case we'll translate it to MAX_REFERENCE_TIME
    (* prtStop) = WMSDKToDShowTime (m_cnsCurrentPlayStop) ;

    return S_OK ;
}

QWORD
CDVRReadManager::GetContentDuration  (
    )
{
    QWORD   cnsDuration ;
    QWORD   cnsStart ;
    HRESULT hr ;

    hr = GetReaderContentBoundaries (& cnsStart, & cnsDuration) ;
    if (FAILED (hr)) {
        cnsDuration = 0L ;
    }

    return cnsDuration ;
}

HRESULT
CDVRReadManager::GetContentExtent (
    OUT REFERENCE_TIME * prtStart,
    OUT REFERENCE_TIME * prtStop
    )
{
    HRESULT hr ;
    QWORD   cnsStart ;
    QWORD   cnsStop ;

    ASSERT (prtStart) ;
    ASSERT (prtStop) ;

    hr = GetReaderContentBoundaries (& cnsStart, & cnsStop) ;
    if (SUCCEEDED (hr)) {
        (* prtStart)    = WMSDKToDShowTime (cnsStart) ;
        (* prtStop)     = WMSDKToDShowTime (cnsStop) ;

        //TRACE_4 (LOG_AREA_SEEKING_AND_TRICK, 8,
        //    TEXT ("CDVRReadManager::GetContentExtent(): start = %d sec; stop_actual = %d sec; stop_reported = %d sec; duration = %d sec"),
        //    WMSDKTimeToSeconds (* prtStart), WMSDKTimeToSeconds (WMSDKToDShowTime (cnsStop)), WMSDKTimeToSeconds (* prtStop), WMSDKTimeToSeconds ((* prtStop) - (* prtStart))) ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::GetPlayrateRange (
    OUT double *    pdMaxReverseRate,
    OUT double *    pdMaxForwardRate
    )
{
    ASSERT (pdMaxReverseRate) ;
    ASSERT (pdMaxForwardRate) ;

    (* pdMaxReverseRate) = GetMaxReverseRate_ () ;
    (* pdMaxForwardRate) = GetMaxForwardRate_ () ;

    return S_OK ;
}

int
CDVRReadManager::DiscoverPrimaryTrickModeStream_ (
    IN  double  dRate
    )
{
    CDVROutputPin * pDVROutputPin ;
    int             iTrickModeStream ;
    int             i ;

    ASSERT (m_pDVRSourcePinManager) ;

    iTrickModeStream = UNDEFINED ;

    for (i = 0;
         i < m_pDVRSourcePinManager -> PinCount () ;
         i++) {

        pDVROutputPin = m_pDVRSourcePinManager -> GetNonRefdOutputPin (i) ;
        ASSERT (pDVROutputPin) ;

        //  PREFIX note: there is an ASSERT there because this is an ASSERT,
        //      not a runtime error; the pins are densely packed, so if the
        //      count is out of sync with what is in the pin bank, it's a bug,
        //      not a runtime error

        if (pDVROutputPin -> IsFrameRateSupported (dRate)   &&      //  simple enough
            pDVROutputPin -> IsConnected ()                 &&      //  make sure it will send the content
            pDVROutputPin -> IsMediaCompatible ()) {                //  primary trick mode stream

            if (pDVROutputPin -> IsPrimaryTrickModeStream ()) {
                //  found primary
                iTrickModeStream = i ;
                break ;
            }

            //  found one that supports it, but keep looking for primary
            iTrickModeStream = i ;
        }
    }

    return iTrickModeStream ;
}

BOOL
CDVRReadManager::IsFullFrameRate_ (
    IN  CDVROutputPin * pPrimaryPin,
    IN  double          dRate
    )
{
    double  dMaxFullFrameRate ;
    BOOL    r ;

    if (dRate > 0) {

        dMaxFullFrameRate = m_pPolicy -> Settings () -> MaxFullFrameRate () ;

        //  pin must be capable, but settings might ratchet it lower
        r = (pPrimaryPin -> IsFullFrameRateSupported (dRate) &&
             dRate <= dMaxFullFrameRate ? TRUE : FALSE) ;
    }
    else {
        //  v1: reverse trick mode is (key) I-frame only
        r = FALSE ;
    }

    return r ;
}

HRESULT
CDVRReadManager::FinalizeRateConfig_ (
    IN  double          dActualRate,
    IN  double          dPinRate,
    IN  int             iPrimaryStream,
    IN  BOOL            fFullFramePlay,
    IN  BOOL            fSeekingRateChange,
    IN  REFERENCE_TIME  rtRateStart,
    IN  REFERENCE_TIME  rtRuntimeStart
    )
{
    HRESULT hr ;

    //
    //  We've now got the primary stream.  We can transition 2 ways into
    //    a rate change play sequence: (1) no seek, (2) seek-based.  In
    //    the first, the transition will be more smooth
    //

    //  make sure all our queues are empty; if they are not empty, and we
    //    hold something there before we turn a pin off, we'll initially
    //    send stale data out
    m_pDVRSourcePinManager -> SendAllQueued () ;

    //
    //  we now have empty queues, a primary stream, have a starting PTS
    //    (1x) and we're set to go
    //

    TRACE_5 (LOG_AREA_SEEKING_AND_TRICK, 1,
        TEXT ("CDVRReadManager::FinalizeRateConfig_ (%2.1f) -- rtRateStart = %I64d (%d ms); primary = %d; full-frame = %u"),
        dActualRate, rtRateStart, DShowTimeToMilliseconds (rtRateStart), iPrimaryStream, fFullFramePlay) ;

    //  set the new rate
    hr = SetPinRates_ (
            dPinRate,
            rtRateStart,
            fFullFramePlay,
            iPrimaryStream
            ) ;

    if (SUCCEEDED (hr)) {
        //  update our stream time; we're starting a new rate at the specified
        //    time (runtime)
        QueueRateSegment (
            ::CompatibleRateValue (dActualRate),
            rtRuntimeStart
            ) ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::GetRateConfigInfo_ (
    IN  double      dActualRate,
    OUT double *    pdPinRate,
    OUT int *       piPrimaryStream,
    OUT BOOL *      pfFullFramePlay,
    OUT BOOL *      pfSeekingRateChange
    )
{
    HRESULT         hr ;
    HRESULT         hr2 ;
    BOOL            r ;
    CDVROutputPin * pDVRPrimaryOutputPin ;
    REFERENCE_TIME  rtStreamtime ;
    REFERENCE_TIME  rtRuntimeNow ;

    //  we might tell the pins that we play forward no matter what;
    if (m_pPolicy -> Settings () -> AllNotifiedRatesPositive ()) {
        (* pdPinRate) = (dActualRate > 0 ? dActualRate : 0 - dActualRate) ;
    }
    else {
        (* pdPinRate) = dActualRate ;
    }

    TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
        TEXT ("CDVRReadManager::GetRateConfigInfo_ actualrate = %2.1f; pinrate = %2.1f"),
        dActualRate, (* pdPinRate)) ;

    //
    //  iPrimaryStream is the index to the stream that is selected to be the
    //    main stream for this rate; typically this stream is video; we use
    //    the primary stream to determine the timestamp which will be the
    //    applicable new bitrate; also if the primary stream is not able to
    //    go at the full-frame rate (vs. keyframes only) SetPinRates_() will
    //    mute all the other streams
    //

    (* piPrimaryStream) = DiscoverPrimaryTrickModeStream_ (* pdPinRate) ;

    TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
        TEXT ("CDVRReadManager::GetRateConfigInfo_ (%2.1f) -- primary stream = %d"),
        dActualRate, (* piPrimaryStream)) ;

    if ((* piPrimaryStream) != UNDEFINED) {

        //
        //  We've now got the primary stream.  We can transition 2 ways into
        //    a rate change play sequence: (1) no seek, (2) seek-based.  In
        //    the first, the transition will be more smooth
        //

        //  get the primary pin
        pDVRPrimaryOutputPin = m_pDVRSourcePinManager -> GetNonRefdOutputPin (* piPrimaryStream) ;

        //  full-frame or keyframes only ?
        (* pfFullFramePlay) = IsFullFrameRate_ (pDVRPrimaryOutputPin, dActualRate) ;

        //  determine if this will be a seeking rate change or not
        (* pfSeekingRateChange) = ((pDVRPrimaryOutputPin -> AlwaysSeekOnRateChange () || (* pdPinRate) != dActualRate) ? TRUE : FALSE) ;
    }
    else {
        //
        //  no primary stream was found that supports the desired rate; fail
        //    the call
        //

        TRACE_1 (LOG_AREA_SEEKING_AND_TRICK, 1,
            TEXT ("CDVRReadManager::GetRateConfigInfo_ (%2.1f) -- failing; primary stream not found; VFW_E_DVD_WRONG_SPEED error"),
            dActualRate) ;

        hr = VFW_E_DVD_WRONG_SPEED ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::ConfigureForRate (
    IN  double          dPlaybackRate,
    IN  CTimelines *    pTimelines,
    IN  BOOL            fReaderActive
    )
{
    HRESULT     hr ;
    int         iPrimaryStream ;        //  key-frame only we always have a primary stream
    BOOL        fFullFramePlay ;        //  if trick mode, we might just decode & render keyframes
    BOOL        fSeekingRateChange ;    //  might force a seek
    double      dPinRate ;              //  might be positive
    CTimelines  Timelines ;

    ASSERT (dPlaybackRate != 0.0) ;

    if (dPlaybackRate != m_dCurRate) {

        //  if this is not set, obtain current timelines
        if (!pTimelines) {
            SetCurTimelines (& Timelines) ;
            pTimelines = & Timelines ;
        }

        ASSERT (pTimelines) ;

        hr = GetRateConfigInfo_ (
                dPlaybackRate,
                & dPinRate,
                & iPrimaryStream,
                & fFullFramePlay,
                & fSeekingRateChange
                ) ;
        if (SUCCEEDED (hr)) {

            //  for now, we *always* seek on rate change -> 1x
            fSeekingRateChange = (dPlaybackRate == _1X_PLAYBACK_RATE ? TRUE : fSeekingRateChange) ;

            hr = SetController_ (
                    dPlaybackRate,
                    iPrimaryStream,
                    fFullFramePlay,
                    fSeekingRateChange,
                    pTimelines,
                    fReaderActive
                    ) ;

            if (SUCCEEDED (hr)) {
                hr = FinalizeRateConfig_ (
                        dPlaybackRate,
                        dPinRate,
                        iPrimaryStream,
                        fFullFramePlay,
                        fSeekingRateChange,
                        pTimelines -> get_RateStart_PTS (),
                        pTimelines -> get_RateStart_Runtime ()
                        ) ;
            }
        }

        if (SUCCEEDED (hr)) {

            //  rate has changed
            m_pPolicy -> EventSink () -> OnEvent (
                STREAMBUFFER_EC_RATE_CHANGED,
                (LONG_PTR) (m_dCurRate * 10000),
                (LONG_PTR) (dPlaybackRate * 10000)
                ) ;

            m_dCurRate = dPlaybackRate ;
            m_ppDVRReadController [m_CurController] -> NotifyNewRate (m_dCurRate) ;
        }
    }
    else {
        hr = S_OK ;
    }

    return hr ;
}

HRESULT
CDVRReadManager::SetController_ (
    IN  double          dNewRate,
    IN  int             iPrimaryStream,
    IN  BOOL            fFullFramePlay,
    IN  BOOL            fSeekingRateChange,
    IN  CTimelines *    pTimelines,
    IN  BOOL            fReaderActive
    )
{
    HRESULT             hr ;
    CONTROLLER_CATEGORY Controller ;
    REFERENCE_TIME      rtStreamtime ;
    QWORD               cnsStreamtime ;
    REFERENCE_TIME      rtStart ;
    REFERENCE_TIME      rtEOF ;
    CTimelines          Timelines ;

    ASSERT (dNewRate != 0) ;

    if (fFullFramePlay) {
        Controller = (dNewRate > 0 ? FORWARD_FULLFRAME : BACKWARD_FULLFRAME) ;
    }
    else {
        Controller = (dNewRate > 0 ? FORWARD_KEYFRAME : BACKWARD_KEYFRAME) ;
    }

    if (!pTimelines) {
        SetCurTimelines (& Timelines) ;
        pTimelines = & Timelines ;
    }

    //  might need to instantiate a new one
    if (!m_ppDVRReadController [Controller]) {
        hr = GetDVRReadController_ (
                Controller,
                this,
                m_pDVRSourcePinManager,
                m_pPolicy,
                m_pDVRSendStatsWriter,
                & m_ppDVRReadController [Controller]
                ) ;
        if (FAILED (hr)) { goto cleanup ; }

        ASSERT (m_ppDVRReadController [Controller]) ;
    }

    //
    //  old controllers never die; they just get destroyed in our destructor
    //

    switch (Controller) {

        case FORWARD_FULLFRAME :
            //  need to run the drill for this if it's a seeking rate change,
            //    of we're switching to it
            if (fSeekingRateChange ||
                Controller != m_CurController) {

                //  this one needs to be reset
                ASSERT (m_ppDVRReadController [m_CurController]) ;
                m_ppDVRReadController [m_CurController] -> Reset () ;

                //  setup for the next
                if (fReaderActive) {
                    m_pDVRSourcePinManager -> DeliverBeginFlush () ;
                    m_pDVRSourcePinManager -> DeliverEndFlush () ;
                }

                //  set our segment boundaries to where we are *now* (stream time)
                rtStreamtime = pTimelines -> get_Streamtime () ;

                //  get the content extent in case we've overrun at +1x rates
                //    and have now caught live; stream time cannot be > than the
                //    content of course
                hr = GetContentExtent (& rtStart, & rtEOF) ;
                if (SUCCEEDED (hr)) {

                    //  make sure we didn't overrun, or underrun
                    if (rtStreamtime > rtEOF) {
                        rtStreamtime = rtEOF ;
                    }
                    else if (rtStreamtime < rtStart) {
                        rtStreamtime = rtStart ;
                    }

                    TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                        TEXT ("CDVRReadManager::SetController_ () -- setting FORWARD_FULLFRAME; streamtime = %I64d ms; EOF = %I64d ms"),
                        ::DShowTimeToMilliseconds (rtStreamtime), ::DShowTimeToMilliseconds (rtEOF)) ;

                    cnsStreamtime = ::DShowToWMSDKTime (rtStreamtime) ;
                    hr = SeekReader (& cnsStreamtime) ;
                    if (SUCCEEDED (hr)) {
                        //  set the segment boundaries
                        SetNewSegmentStart (cnsStreamtime) ;

                        //  seeking rate change; essentially start over
                        hr = m_ppDVRReadController [Controller] -> Initialize (pTimelines -> get_RateStart_PTS ()) ;
                    }
                }
            }
            else {
                hr = S_OK ;
            }

            break ;

        case FORWARD_KEYFRAME :

            if (fSeekingRateChange ||
                Controller != m_CurController) {

                //  this one needs to be reset
                ASSERT (m_ppDVRReadController [m_CurController]) ;
                m_ppDVRReadController [m_CurController] -> Reset () ;

                if (fReaderActive) {
                    m_pDVRSourcePinManager -> DeliverBeginFlush () ;
                    m_pDVRSourcePinManager -> DeliverEndFlush () ;
                }

                //  set our segment boundaries to where we are *now* (stream time)
                rtStreamtime = pTimelines -> get_Streamtime () ;

                //  get the content extent in case we've overrun at +1x rates
                //    and have now caught live; stream time cannot be > than the
                //    content of course
                hr = GetContentExtent (& rtStart, & rtEOF) ;
                if (SUCCEEDED (hr)) {

                    //  make sure we didn't overrun, or underrun
                    if (rtStreamtime > rtEOF) {
                        rtStreamtime = rtEOF ;
                    }
                    else if (rtStreamtime < rtStart) {
                        rtStreamtime = rtStart ;
                    }

                    TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                        TEXT ("CDVRReadManager::SetController_ () -- setting FORWARD_KEYFRAME; streamtime = %I64d ms; EOF = %I64d ms"),
                        ::DShowTimeToMilliseconds (rtStreamtime), ::DShowTimeToMilliseconds (rtEOF)) ;

                    cnsStreamtime = ::DShowToWMSDKTime (rtStreamtime) ;
                    hr = SeekReader (& cnsStreamtime) ;
                    if (SUCCEEDED (hr)) {
                        //  set the segment boundaries
                        SetNewSegmentStart (cnsStreamtime) ;

                        //  seeking rate change; essentially start over
                        hr = reinterpret_cast <CDVR_F_KeyFrame_ReadController *> (m_ppDVRReadController [Controller]) -> InitFKeyController (
                                pTimelines -> get_RateStart_PTS (),
                                iPrimaryStream
                                ) ;
                    }
                }
            }
            else {
                hr = S_OK ;
            }
            break ;

        case BACKWARD_KEYFRAME :

            //  reset current
            ASSERT (m_ppDVRReadController [m_CurController]) ;
            m_ppDVRReadController [m_CurController] -> Reset () ;

            //  setup for the next
            if (fReaderActive) {
                m_pDVRSourcePinManager -> DeliverBeginFlush () ;
                m_pDVRSourcePinManager -> DeliverEndFlush () ;
            }

            //  set our segment boundaries to where we are *now* (stream time)
            rtStreamtime = pTimelines -> get_Streamtime () ;

            //  get the content extent in case we've overrun at +1x rates
            //    and have now caught live; stream time cannot be > than the
            //    content of course
            hr = GetContentExtent (& rtStart, & rtEOF) ;
            if (SUCCEEDED (hr)) {

                //  make sure we didn't overrun, or underrun
                if (rtStreamtime > rtEOF) {
                    rtStreamtime = rtEOF ;
                }
                else if (rtStreamtime < rtStart) {
                    rtStreamtime = rtStart ;
                }

                TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                    TEXT ("CDVRReadManager::SetController_ () -- setting BACKWARD_KEYFRAME; streamtime = %I64d ms; EOF = %I64d ms"),
                    ::DShowTimeToMilliseconds (rtStreamtime), ::DShowTimeToMilliseconds (rtEOF)) ;

                cnsStreamtime = ::DShowToWMSDKTime (rtStreamtime) ;
                hr = SeekReader (& cnsStreamtime) ;
                if (SUCCEEDED (hr)) {
                    //  set the segment boundaries
                    SetNewSegmentStart (cnsStreamtime) ;

                    //  seeking rate change; essentially start over
                    hr = reinterpret_cast <CDVR_R_KeyFrame_ReadController *> (m_ppDVRReadController [Controller]) -> Initialize (
                            pTimelines -> get_RateStart_PTS (),
                            iPrimaryStream
                            ) ;
                }
            }

            break ;

        case BACKWARD_FULLFRAME :

            //  reset current
            ASSERT (m_ppDVRReadController [m_CurController]) ;
            m_ppDVRReadController [m_CurController] -> Reset () ;

            //  setup for the next
            if (fReaderActive) {
                m_pDVRSourcePinManager -> DeliverBeginFlush () ;
                m_pDVRSourcePinManager -> DeliverEndFlush () ;
            }

            //  set our segment boundaries to where we are *now* (stream time)
            rtStreamtime = pTimelines -> get_Streamtime () ;

            //  get the content extent in case we've overrun at +1x rates
            //    and have now caught live; stream time cannot be > than the
            //    content of course
            hr = GetContentExtent (& rtStart, & rtEOF) ;
            if (SUCCEEDED (hr)) {

                //  make sure we didn't overrun, or underrun
                if (rtStreamtime > rtEOF) {
                    rtStreamtime = rtEOF ;
                }
                else if (rtStreamtime < rtStart) {
                    rtStreamtime = rtStart ;
                }

                TRACE_2 (LOG_AREA_SEEKING_AND_TRICK, 1,
                    TEXT ("CDVRReadManager::SetController_ () -- setting BACKWARD_FULLFRAME; streamtime = %I64d ms; EOF = %I64d ms"),
                    ::DShowTimeToMilliseconds (rtStreamtime), ::DShowTimeToMilliseconds (rtEOF)) ;

                cnsStreamtime = ::DShowToWMSDKTime (rtStreamtime) ;
                hr = SeekReader (& cnsStreamtime) ;
                if (SUCCEEDED (hr)) {
                    //  set the segment boundaries
                    SetNewSegmentStart (cnsStreamtime) ;

                    //  initialize everything
                    hr = reinterpret_cast <CDVR_R_FullFrame_ReadController *> (m_ppDVRReadController [Controller]) -> Initialize (
                                pTimelines -> get_RateStart_PTS (),
                                iPrimaryStream
                                ) ;
                }
            }

            break ;

        default :
            ASSERT (0) ;
            hr = E_UNEXPECTED ;
    } ;

    if (SUCCEEDED (hr)) {
        //  success: make the switch
        m_CurController = Controller ;
    }

    cleanup :

    return hr ;
}

BOOL
CDVRReadManager::ValidRateRequest_ (
    IN  double  dPlaybackRate
    )
{
    HRESULT         hr ;
    BOOL            r ;
    REFERENCE_TIME  rtCurPos ;
    REFERENCE_TIME  rtStart ;
    REFERENCE_TIME  rtCurEOF ;

    if (dPlaybackRate != _1X_PLAYBACK_RATE) {

        r = FALSE ;

        hr = m_pSeekingCore -> GetStreamTimeDShow (& rtCurPos) ;
        if (SUCCEEDED (hr)) {
            hr = GetContentExtent (& rtStart, & rtCurEOF) ;
            if (SUCCEEDED (hr)) {
                if (dPlaybackRate > 1) {
                    //  FF; make sure we have sufficient room to go FF
                    r = (rtCurPos + ::MillisToDShowTime (m_pPolicy -> Settings () -> FFRateMinBufferMillis ()) < rtCurEOF) ;
                }
                else {
                    //  RW, or slow motion; make sure we have enough room to
                    //    rewind or fall back
                    r = (rtStart + ::MillisToDShowTime (m_pPolicy -> Settings () -> RWRateMinBufferMillis ()) < rtCurPos) ;
                }
            }
        }
    }
    else {
        //  all are fine for 1x
        r = TRUE ;
    }

    return r ;
}

HRESULT
CDVRReadManager::SetPlaybackRate (
    IN  double  dPlaybackRate
    )
{
    HRESULT     hr ;
    BOOL        fReaderRunning ;
    BOOL        r ;
    CTimelines  Timelines ;

    if (dPlaybackRate == 0.0) {
        return E_INVALIDARG ;
    }

    if (m_dCurRate == dPlaybackRate) {
        return S_OK ;
    }

    r = ValidRateRequest_ (dPlaybackRate) ;
    if (r) {
        //  rate request seems to be valid wrt our current pos
        m_ReaderThread.Lock () ;

        fReaderRunning = m_ReaderThread.IsRunning () ;
        if (fReaderRunning) {
            //  pause the reader thread (synchronous call)
            PauseReaderThread_ () ;
        }

        SetCurTimelines (& Timelines) ;

        //  configure
        hr = ConfigureForRate (
                dPlaybackRate,
                & Timelines,
                !m_ReaderThread.IsStopped ()
                ) ;

        //  if above call failed, and we tried for a non-1x rate, fall back to 1x
        //    and try again
        if (FAILED (hr) &&
            dPlaybackRate != _1X_PLAYBACK_RATE) {

            dPlaybackRate = _1X_PLAYBACK_RATE ;
            hr = ConfigureForRate (
                    dPlaybackRate,
                    & Timelines,
                    !m_ReaderThread.IsStopped ()
                    ) ;
        }

        if (SUCCEEDED (hr) &&
            fReaderRunning) {

            RunReaderThread_ () ;
        }

        m_ReaderThread.Unlock () ;
    }
    else {
        //  rate request is invalid wrt our current position
        hr = VFW_E_DVD_WRONG_SPEED ;
    }

    return hr ;
}

void
CDVRReadManager::ReaderReset (
    )
{
    m_pDVRDShowReader -> GetIDVRReader () -> ResetCancel () ;
}

HRESULT
CDVRReadManager::GetReaderContentBoundaries (
    OUT QWORD * pcnsStart,
    OUT QWORD * pcnsStop
    )
{
    return m_pDVRDShowReader -> GetIDVRReader () -> GetStreamTimeExtent (pcnsStart, pcnsStop) ;
}

double
CDVRReadManager::GetMaxForwardRate_ (
    )
{
    return m_pPolicy -> Settings () -> MaxForwardRate () ;
}

double
CDVRReadManager::GetMaxReverseRate_ (
    )
{
    return m_pPolicy -> Settings () -> MaxReverseRate () ;
}

DWORD
CDVRReadManager::SetMaxWrapperCount (
    IN  DWORD   cNewMax
    )
{
    //  make sure that we don't go too low
    if (cNewMax < m_pPolicy -> Settings () -> AllocatorGetBufferCount ()) {
        cNewMax = m_pPolicy -> Settings () -> AllocatorGetBufferCount () ;
    }
    //  or too high
    else if (cNewMax > MaxWrapperCount ()) {
        cNewMax = MaxWrapperCount () ;
    }

    m_cBufferPool = Max <DWORD> (cNewMax, m_cBufferPool) ;

    if (m_cBufferPool != m_DVRIMediaSamplePool.GetCurMaxAllocate ()) {
        TRACE_2 (LOG_TRACE, 1, TEXT ("changing the bufferpool allocation from %u ==> %u"), m_DVRIMediaSamplePool.GetCurMaxAllocate (), m_cBufferPool) ;
        m_DVRIMediaSamplePool.SetMaxAllocate (m_cBufferPool) ;
    }

    return cNewMax ;
}

void
CDVRReadManager::AdjustBufferPool (
    IN DWORD    dwMuxBuffersPerSec
    )
{
    DWORD   cDesiredBufferSamples ;

    cDesiredBufferSamples = (DWORD) (m_dDesiredBufferPoolSec * (double) dwMuxBuffersPerSec) ;
    SetMaxWrapperCount (cDesiredBufferSamples) ;
}

//  ============================================================================
//  CDVRRecordingReader
//  ============================================================================

CDVRRecordingReader::CDVRRecordingReader (
    IN  WCHAR *                         pszDVRFilename,
    IN  CDVRPolicy *                    pPolicy,
    IN  CDVRDShowSeekingCore *          pSeekingCore,
    IN  CDVRSourcePinManager *          pDVRSourcePinManager,
    IN  CDVRSendStatsWriter *           pDVRSendStatsWriter,
    IN  CPVRIOCounters *                pPVRIOCounters,
    IN  CDVRClock *                     pDVRClock,
    OUT IDVRIORecordingAttributes **    ppIDVRIORecReader,
    OUT HRESULT *                       phr
    ) : CDVRReadManager (pPolicy,
                         pSeekingCore,
                         pDVRSourcePinManager,
                         pDVRSendStatsWriter,
                         pDVRClock,
                         phr)
{
    IDVRReader *        pIDVRReader ;
    CDVRDShowReader *   pDVRDShowReader ;
    SYSTEM_INFO         SystemInfo ;
    DWORD               dwIoSize ;
    DWORD               dwBufferCount ;
    CW32SID *           pW32SID ;
    HRESULT             hr ;

    TRACE_CONSTRUCTOR (TEXT ("CDVRRecordingReader")) ;

    ASSERT (pszDVRFilename) ;
    ASSERT (pPolicy) ;
    ASSERT (DVRPolicies_ ()) ;
    ASSERT (ppIDVRIORecReader) ;

    pDVRDShowReader         = NULL ;
    pIDVRReader             = NULL ;
    (* ppIDVRIORecReader)   = NULL ;
    pW32SID                 = NULL ;

    //  base class might have failed us
    if (FAILED (* phr)) { goto cleanup ; }

    hr = pPolicy -> GetSIDs (& pW32SID) ;
    if (FAILED (hr)) {
        pW32SID = NULL ;
    }
    else {
        ASSERT (pW32SID) ;
    }

    //  collect our async IO settings
    dwIoSize            = pPolicy -> Settings () -> AsyncIoBufferLen () ;
    dwBufferCount       = pPolicy -> Settings () -> AsyncIoReadBufferCount () ;

    //  everything is going to be aligned on page boundaries
    ::GetSystemInfo (& SystemInfo) ;

    //  make the alignments
    dwIoSize = ::AlignUp (dwIoSize, SystemInfo.dwPageSize) ;

    (* phr) = DVRCreateReader (
                    pPVRIOCounters,
                    pszDVRFilename,
                    pPolicy -> Settings () -> UseUnbufferedIo (),
                    dwIoSize,
                    dwBufferCount,
                    CDVREventSink::DVRIOCallback,
                    (LPVOID) DVRPolicies_ () -> EventSink (),
                    pPolicy -> Settings () -> GetDVRRegKey (),
                    (pW32SID ? pW32SID -> Count () : 0),
                    (pW32SID ? pW32SID -> ppSID () : NULL),
                    & pIDVRReader
                    ) ;
    if (FAILED (* phr)) { goto cleanup ; }

    ASSERT (pIDVRReader) ;

    pDVRDShowReader = new CDVRDShowReader (
                                pPolicy,
                                pIDVRReader,
                                phr
                                ) ;

    if (SUCCEEDED (* phr)) {
        //  init this so we can get the attributes from the recording
        pIDVRReader -> Seek (0) ;

        (* phr) = pIDVRReader -> QueryInterface (
                                    IID_IDVRIORecordingAttributes,
                                    (void **) ppIDVRIORecReader
                                    ) ;

        pIDVRReader -> Release () ;     //  we're done with this regardless

        if (FAILED (* phr)) {
            (* ppIDVRIORecReader) = NULL ;  //  make sure this is NULL
            delete pDVRDShowReader ;
            goto cleanup ;
        }
    }
    else {
        pIDVRReader -> Release () ;
        (* phr) = (pDVRDShowReader ? (* phr) : E_OUTOFMEMORY) ;
        goto cleanup ;
    }

    //  success
    SetReader_ (pDVRDShowReader) ;

    cleanup :

    RELEASE_AND_CLEAR (pW32SID) ;

    return ;
}

CDVRRecordingReader::~CDVRRecordingReader (
    )
{
    TRACE_DESTRUCTOR (TEXT ("CDVRRecordingReader")) ;
}

//  ============================================================================
//  CDVRBroadcastStreamReader
//  ============================================================================

CDVRBroadcastStreamReader::CDVRBroadcastStreamReader (
    IN  IStreamBufferSink *     pIStreamBufferSink,
    IN  CDVRPolicy *            pPolicy,
    IN  CDVRDShowSeekingCore *  pSeekingCore,
    IN  CDVRSourcePinManager *  pDVRSourcePinManager,
    IN  CDVRSendStatsWriter *   pDVRSendStatsWriter,
    IN  CDVRClock *             pDVRClock,
    OUT HRESULT *               phr
    ) : CDVRReadManager (pPolicy,
                         pSeekingCore,
                         pDVRSourcePinManager,
                         pDVRSendStatsWriter,
                         pDVRClock,
                         phr)
{
    IDVRStreamSinkPriv *    pIDVRStreamSinkPriv ;
    IDVRRingBufferWriter *  pIDVRRingBufferWriter ;
    IDVRReader *            pIDVRReader ;
    CDVRDShowReader *       pDVRDShowReader ;

    TRACE_CONSTRUCTOR (TEXT ("CDVRBroadcastStreamReader")) ;

    pIDVRStreamSinkPriv     = NULL ;
    pIDVRReader             = NULL ;
    pIDVRRingBufferWriter   = NULL ;

    //  base class might have failed us
    if (FAILED (* phr)) { goto cleanup ; }

    ASSERT (pIStreamBufferSink) ;
    (* phr) = pIStreamBufferSink -> QueryInterface (
                    IID_IDVRStreamSinkPriv,
                    (void **) & pIDVRStreamSinkPriv
                    ) ;
    if (FAILED (* phr)) { goto cleanup ; }

    ASSERT (pIDVRStreamSinkPriv) ;
    (* phr) = pIDVRStreamSinkPriv -> GetDVRRingBufferWriter (& pIDVRRingBufferWriter) ;
    if (FAILED (* phr)) { goto cleanup ; }

    ASSERT (pIDVRRingBufferWriter) ;
    (* phr) = pIDVRRingBufferWriter -> CreateReader (
                CDVREventSink::DVRIOCallback,
                (LPVOID) DVRPolicies_ () -> EventSink (),
                & pIDVRReader
                ) ;
    if (FAILED (* phr)) { goto cleanup ; }

    ASSERT (pIDVRReader) ;
    pDVRDShowReader = new CDVRDShowReader (
                                pPolicy,
                                pIDVRReader,
                                phr
                                ) ;

    if (!pDVRDShowReader ||
        FAILED (* phr)) {

        (* phr) = (pDVRDShowReader ? (* phr) : E_OUTOFMEMORY) ;
        goto cleanup ;
    }

    //  success
    SetReader_ (pDVRDShowReader) ;

    cleanup :

    RELEASE_AND_CLEAR (pIDVRRingBufferWriter) ; //  done with the ringbuffer writer
    RELEASE_AND_CLEAR (pIDVRStreamSinkPriv) ;   //  done with the interface
    RELEASE_AND_CLEAR (pIDVRReader) ;           //  pDVRDShowReader has ref'd this

    return ;
}

CDVRBroadcastStreamReader::~CDVRBroadcastStreamReader (
    )
{
    TRACE_DESTRUCTOR (TEXT ("CDVRBroadcastStreamReader")) ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\shared\dvrdsrec.cpp ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        dvrdsrec.cpp

    Abstract:

        This module contains the code for our recording objects

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        23-Apr-2001     created

--*/

#include "dvrall.h"
#include "dvrprof.h"
#include "dvrdsseek.h"          //  pins reference seeking interfaces
#include "dvrpins.h"
#include "dvrdswrite.h"
#include "dvrdsrec.h"

CDVRRecordingAttributes::CDVRRecordingAttributes (
    IN  IUnknown *                  punkOwning,
    IN  IDVRIORecordingAttributes * pIDVRIOAttributes,
    IN  BOOL                        fReadonly
    ) : CUnknown            (DVR_ATTRIBUTES,
                             punkOwning
                             ),
        m_pIDVRIOAttributes (pIDVRIOAttributes),
        m_fReadonly         (fReadonly),
        m_pszFilename       (NULL),
        m_pW32SID           (NULL)
{
    if (m_pIDVRIOAttributes) {
        m_pIDVRIOAttributes -> AddRef () ;
    }

    ::InitializeCriticalSection (& m_crt) ;
}

CDVRRecordingAttributes::~CDVRRecordingAttributes (
    )
{
    RELEASE_AND_CLEAR (m_pIDVRIOAttributes) ;
    RELEASE_AND_CLEAR (m_pW32SID) ;
    DELETE_RESET_ARRAY (m_pszFilename) ;

    ::DeleteCriticalSection (& m_crt) ;
}

STDMETHODIMP
CDVRRecordingAttributes::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    OUT VOID ** ppv
    )
{
    HRESULT hr ;

    Lock_ () ;

    //  ------------------------------------------------------------------------
    //  IStreamBufferRecordingAttribute

    if (riid == IID_IStreamBufferRecordingAttribute) {

        hr = GetInterface (
                    (IStreamBufferRecordingAttribute *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------
    //  IFileSourceFilter
    //
    //  only implement if it looks like it's the only way we're going to get
    //    new file

    else if (riid == IID_IFileSourceFilter  &&
             !m_pszFilename                 &&
             !m_pIDVRIOAttributes) {

        hr = GetInterface (
                    (IFileSourceFilter *) this,
                    ppv
                    ) ;
    }

    //  ------------------------------------------------------------------------

    else {
        hr = CUnknown::NonDelegatingQueryInterface (riid, ppv) ;
    }

    Unlock_ () ;

    return hr ;
}

HRESULT
CDVRRecordingAttributes::LoadASFFile_ (
    )
{
    HRESULT             hr ;
    IDVRReader *        pIDVRReader ;
    CPVRIOCounters *    pPVRIOCounters ;

    pIDVRReader = NULL ;
    hr          = S_OK ;

    //  if we're in a graph and have a filename
    if (m_pszFilename) {

        pPVRIOCounters = new CPVRIOCounters () ;
        if (!pPVRIOCounters) {
            hr = E_OUTOFMEMORY ;
            goto cleanup ;
        }

        //  ours
        pPVRIOCounters -> AddRef () ;

        hr = ::DVRCreateReader (
                        pPVRIOCounters,
                        m_pszFilename,
                        FALSE,                              //  no unbuffered IO; we just want to look at the attributes in the header
                        REG_DEF_ASYNC_IO_BUFFER_SIZE,
                        REG_DEF_ASYNC_READER_BUFFER_POOL,
                        NULL,
                        NULL,
                        NULL,
                        (m_pW32SID ? m_pW32SID -> Count () : 0),
                        (m_pW32SID ? m_pW32SID -> ppSID () : NULL),
                        & pIDVRReader
                        ) ;

        //  regardless
        pPVRIOCounters -> Release () ;

        if (SUCCEEDED (hr)) {
            ASSERT (pIDVRReader) ;

            //  init this so we can get the attributes from the recording
            pIDVRReader -> Seek (0) ;

            hr = pIDVRReader -> QueryInterface (
                                        IID_IDVRIORecordingAttributes,
                                        (void **) & m_pIDVRIOAttributes
                                        ) ;

            pIDVRReader -> Release () ;
        }

    }

    cleanup :

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttributes::Load (
    IN  LPCOLESTR               pszFilename,
    IN  const AM_MEDIA_TYPE *   pmt             //  can be NULL
    )
{
    HRESULT hr ;
    DWORD   dw ;

    if (!pszFilename) {
        return E_POINTER ;
    }

    Lock_ () ;

    //  validate that the file exists; typically the DVRIO layer performs
    //    this for us, but we don't present the file to the DVRIO layer
    //    until we join the filtergraph
    dw = ::GetFileAttributes (pszFilename) ;
    if (dw != -1) {
        RELEASE_AND_CLEAR (m_pIDVRIOAttributes) ;
        DELETE_RESET_ARRAY (m_pszFilename) ;

        m_pszFilename = new WCHAR [lstrlenW (pszFilename) + 1] ;
        if (m_pszFilename) {
            lstrcpyW (m_pszFilename, pszFilename) ;
            hr = LoadASFFile_ () ;
        }
        else {
            hr = E_OUTOFMEMORY ;
        }
    }
    else {
        dw = GetLastError () ;
        hr = HRESULT_FROM_WIN32 (dw) ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttributes::GetCurFile (
    OUT LPOLESTR *      ppszFilename,
    OUT AM_MEDIA_TYPE * pmt
    )
{
    HRESULT hr ;

    if (!ppszFilename ||
        !pmt) {

        return E_POINTER ;
    }

    Lock_ () ;

    if (m_pszFilename) {
        (* ppszFilename) = reinterpret_cast <LPOLESTR> (CoTaskMemAlloc ((lstrlenW (m_pszFilename) + 1) * sizeof OLECHAR)) ;
        if (* ppszFilename) {

            //  outgoing filename
            lstrcpyW ((* ppszFilename), m_pszFilename) ;

            //  and media type
            pmt->majortype      = GUID_NULL;
            pmt->subtype        = GUID_NULL;
            pmt->pUnk           = NULL;
            pmt->lSampleSize    = 0;
            pmt->cbFormat       = 0;

            hr = S_OK ;
        }
        else {
            hr = E_OUTOFMEMORY ;
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttributes::SetSIDs (
    IN  DWORD   cSIDs,
    IN  PSID *  ppSID
    )
{
    HRESULT hr ;
    DWORD   dw ;

    if (!ppSID) {
        return E_POINTER ;
    }

    if ((ppSID && !cSIDs) ||
        (!ppSID && cSIDs)) {

        return E_INVALIDARG ;
    }

    Lock_ () ;

    RELEASE_AND_CLEAR (m_pW32SID) ;

    ASSERT (cSIDs) ;
    m_pW32SID = new CW32SID (ppSID, cSIDs, & dw) ;
    if (!m_pW32SID) {
        hr = E_OUTOFMEMORY ;
    }
    else if (dw != NOERROR) {
        hr = HRESULT_FROM_WIN32 (dw) ;
        delete m_pW32SID ;
        m_pW32SID = NULL ;
    }
    else {
        hr = S_OK ;
        m_pW32SID -> AddRef () ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttributes::SetHKEY (
    IN  HKEY    hkeyRoot
    )
{
    return E_NOTIMPL ;
}

STDMETHODIMP
CDVRRecordingAttributes::SetAttribute (
    IN  ULONG                       ulReserved,
    IN  LPCWSTR                     pszAttributeName,
    IN  STREAMBUFFER_ATTR_DATATYPE  DVRAttributeType,
    IN  BYTE *                      pbAttribute,
    IN  WORD                        cbAttributeLength
    )
{
    HRESULT hr ;
    WORD    wStreamNum ;

    if (m_fReadonly) {
        return E_UNEXPECTED ;
    }

    //
    //  all parameter validation is done either in the DVRIO layer, in the case
    //    of reference recordings, or in the WMSDK, in th case of content
    //    recordings, when these calls are pass-through calls into the SDK
    //

    //
    //  don't monitor and explicitely block calls if the recording has started;
    //    it is assumed that if lower layers (DVRIO or WMSDK) determine if
    //    there's room at time-of-call for the attributes
    //

    //  always
    wStreamNum = 0 ;

    Lock_ () ;

    if (m_pIDVRIOAttributes) {
        if (!m_fReadonly) {
            hr = m_pIDVRIOAttributes -> SetDVRIORecordingAttribute (
                        pszAttributeName,
                        wStreamNum,
                        DVRAttributeType,
                        pbAttribute,
                        cbAttributeLength
                        ) ;
        }
        else {
            hr = E_UNEXPECTED ;
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttributes::GetAttributeCount (
    IN  ULONG   ulReserved,
    OUT WORD *  pcAttributes
    )
{
    HRESULT hr ;
    WORD    wStreamNum ;

    //  WMSDK doesn't check this one.. well almost.. it ASSERTs in checked
    //    builds
    if (!pcAttributes) {
        return E_POINTER ;
    }

    //
    //  don't monitor and explicitely block calls if the recording has started;
    //    it is assumed that if lower layers (DVRIO or WMSDK) determine if
    //    there's room at time-of-call for the attributes
    //

    //  always
    wStreamNum = 0 ;

    Lock_ () ;

    if (m_pIDVRIOAttributes) {
        hr = m_pIDVRIOAttributes -> GetDVRIORecordingAttributeCount (
                    wStreamNum,
                    pcAttributes
                    ) ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttributes::GetAttributeByName (
    IN      LPCWSTR                         pszAttributeName,
    IN      ULONG *                         pulReserved,
    OUT     STREAMBUFFER_ATTR_DATATYPE *    pDVRAttributeType,
    OUT     BYTE *                          pbAttribute,
    IN OUT  WORD *                          pcbLength
    )
{
    WORD    wStreamNum ;
    HRESULT hr ;

    //
    //  all parameter validation is done either in the DVRIO layer, in the case
    //    of reference recordings, or in the WMSDK, in th case of content
    //    recordings, when these calls are pass-through calls into the SDK
    //
    //  don't monitor and explicitely block calls if the recording has started;
    //    it is assumed that if lower layers (DVRIO or WMSDK) determine if
    //    there's room at time-of-call for the attributes
    //

    //  always
    wStreamNum = 0 ;

    Lock_ () ;

    if (m_pIDVRIOAttributes) {
        hr = m_pIDVRIOAttributes -> GetDVRIORecordingAttributeByName (
                    pszAttributeName,
                    & wStreamNum,
                    pDVRAttributeType,
                    pbAttribute,
                    pcbLength
                    ) ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttributes::GetAttributeByIndex (
    IN      WORD                            wIndex,
    IN      ULONG *                         pulReserved,
    OUT     WCHAR *                         pszAttributeName,
    IN OUT  WORD *                          pcchNameLength,
    OUT     STREAMBUFFER_ATTR_DATATYPE *    pDVRAttributeType,
    OUT     BYTE *                          pbAttribute,
    IN OUT  WORD *                          pcbLength
    )
{
    WORD    wStreamNum ;
    HRESULT hr ;

    //
    //  all parameter validation is done either in the DVRIO layer, in the case
    //    of reference recordings, or in the WMSDK, in th case of content
    //    recordings, when these calls are pass-through calls into the SDK
    //
    //  don't monitor and explicitely block calls if the recording has started;
    //    it is assumed that if lower layers (DVRIO or WMSDK) determine if
    //    there's room at time-of-call for the attributes
    //

    //  always
    wStreamNum = 0 ;

    Lock_ () ;

    if (m_pIDVRIOAttributes) {
        hr = m_pIDVRIOAttributes -> GetDVRIORecordingAttributeByIndex (
                    wIndex,
                    & wStreamNum,
                    pszAttributeName,
                    pcchNameLength,
                    pDVRAttributeType,
                    pbAttribute,
                    pcbLength
                    ) ;
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttributes::EnumAttributes (
    OUT IEnumStreamBufferRecordingAttrib **   ppIEnumDVRAttrib
    )
{
    HRESULT hr ;

    if (!ppIEnumDVRAttrib) {
        return E_POINTER ;
    }

    Lock_ () ;

    if (m_pIDVRIOAttributes) {
        (* ppIEnumDVRAttrib) = new CDVRRecordingAttribEnum (m_pIDVRIOAttributes) ;

        //  outgoing; CUnknowns are not instantiated with a ref
        (* ppIEnumDVRAttrib) -> AddRef () ;

        if (* ppIEnumDVRAttrib) {
            hr = S_OK ;
        }
        else {
            hr = E_OUTOFMEMORY ;
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

CUnknown *
WINAPI
CDVRRecordingAttributes::CreateInstance (
    IN  IUnknown *  punkControlling,
    IN  HRESULT *   phr
    )
{
    CDVRRecordingAttributes *   pDVRRecordingAttributes ;

    pDVRRecordingAttributes = new CDVRRecordingAttributes (
                                        punkControlling,
                                        NULL,
                                        TRUE            //  read-only
                                        ) ;
    if (pDVRRecordingAttributes) {
        (* phr) = S_OK ;
    }
    else {
        (* phr) = E_OUTOFMEMORY ;
    }

    return pDVRRecordingAttributes ;
}

//  ============================================================================
CDVRRecording::CDVRRecording (
    IN  CDVRPolicy *        pDVRPolicy,
    IN  IDVRRecorder *      pIDVRRecorder,
    IN  DWORD               dwWriterID,         //  write manager will use this
    IN  CDVRWriteManager *  pWriteManager,
    IN  CCritSec *          pRecvLock,
    IN  IUnknown *          punkFilter          //  write manager & recv lock live as long as filter, so we need to be able to ref
    ) : m_pIDVRIORecorder           (pIDVRRecorder),
        CUnknown                    (TEXT ("CDVRRecording"),
                                     NULL
                                     ),
        m_pWriteManager             (pWriteManager),
        m_dwWriterID                (dwWriterID),
        m_punkFilter                (punkFilter),
        m_pDVRPolicy                (pDVRPolicy),
        m_pRecvLock                 (pRecvLock),
        m_pDVRRecordingAttributes   (NULL)
{
    IDVRIORecordingAttributes * pIDVRIORecAttr ;
    HRESULT                     hr ;

    ASSERT (m_pWriteManager) ;
    ASSERT (m_pIDVRIORecorder) ;
    ASSERT (m_punkFilter) ;
    ASSERT (m_pDVRPolicy) ;
    ASSERT (m_pRecvLock) ;

    m_pDVRPolicy        -> AddRef () ;
    m_pIDVRIORecorder   -> AddRef () ;

    //  required so we can use the write manager
    m_punkFilter -> AddRef () ;

    hr = m_pIDVRIORecorder -> QueryInterface (
            IID_IDVRIORecordingAttributes,
            (void **) & pIDVRIORecAttr
            ) ;
    if (SUCCEEDED (hr)) {
        ASSERT (pIDVRIORecAttr) ;
        m_pDVRRecordingAttributes = new CDVRRecordingAttributes (
                                            this,
                                            pIDVRIORecAttr,
                                            FALSE                   //  not readonly
                                            ) ;
        //  done with this anyways
        pIDVRIORecAttr -> Release () ;

        //  m_pDVRRecordingAttributes object now has 0-refcount on it, so we
        //    must delete it ourselves directly from our destructor
    }
}

CDVRRecording::~CDVRRecording (
    )
{
    DELETE_RESET (m_pDVRRecordingAttributes) ;

    m_pIDVRIORecorder -> Release () ;
    m_punkFilter -> Release () ;
    m_pDVRPolicy -> Release () ;
}

STDMETHODIMP
CDVRRecording::NonDelegatingQueryInterface (
    REFIID  riid,
    void ** ppv
    )
{
    if (!ppv) {
        return E_POINTER ;
    }

    //  ========================================================================
    //  IStreamBufferRecordControl

    if (riid == IID_IStreamBufferRecordControl) {

        return GetInterface (
                    (IStreamBufferRecordControl *) this,
                    ppv
                    ) ;
    }

    //  ========================================================================
    //  IStreamBufferRecordingAttribute

    else if (riid == IID_IStreamBufferRecordingAttribute &&
             ImplementRecordingAttributes_ ()   &&
             m_pDVRRecordingAttributes) {

        //  if successful, this call will ref us
        return m_pDVRRecordingAttributes -> NonDelegatingQueryInterface (
                    IID_IStreamBufferRecordingAttribute,
                    ppv
                    ) ;
    }

    return CUnknown::NonDelegatingQueryInterface (riid, ppv) ;
}

//  ============================================================================
//  IStreamBufferRecordControl

STDMETHODIMP
CDVRRecording::Start (
    IN OUT  REFERENCE_TIME *    prtStartRelative
    )
{
    HRESULT         hr ;
    REFERENCE_TIME  rtNow ;
    REFERENCE_TIME  rtLastWrite ;
    REFERENCE_TIME  rtStart ;
    QWORD           cnsStart ;
    BOOL            r ;

    if (!prtStartRelative) {
        return E_POINTER ;
    }

    r = ValidateRelativeTime_ (* prtStartRelative) ;
    if (r) {

        //  lock so we don't race deliveries
        LockRecv_ () ;

        ASSERT (m_pWriteManager) ;
        hr = m_pWriteManager -> RecordingStreamTime (
                m_dwWriterID,
                & rtNow,
                & rtLastWrite
                ) ;
        if (SUCCEEDED (hr)) {
            //  make sure it's still a relative start that is positive
            rtStart = Max <REFERENCE_TIME> (rtNow + (* prtStartRelative), 0) ;

            SetValidStartStopTime_ (& rtStart, rtLastWrite) ;

            cnsStart = ::DShowToWMSDKTime (rtStart) ;

            hr = m_pIDVRIORecorder -> StartRecording (& cnsStart) ;

            if (SUCCEEDED (hr)) {
                //  set outgoing
                (* prtStartRelative) = ::WMSDKToDShowTime (cnsStart) - rtNow ;
            }

            TRACE_4 (LOG_AREA_RECORDING, 1,
                 TEXT ("CDVRRecording::Start ([out] %I64d sec); running time = %I64d (%I64d ms); returning %08xh"),
                 ::DShowTimeToSeconds (* prtStartRelative), rtStart, ::DShowTimeToMilliseconds (rtStart), hr) ;
        }
        else {
            //  failed to get the running time -- might mean that we're not
            //    active
            if (!m_pWriteManager -> IsActive ()) {
                //  start relative is pure delta wrt 0; pass it through unshifted to "now"

                cnsStart = ::DShowToWMSDKTime (* prtStartRelative) ;

                hr = m_pIDVRIORecorder -> StartRecording (& cnsStart) ;

                if (SUCCEEDED (hr) &&
                    cnsStart != ::WMSDKToDShowTime (* prtStartRelative)) {

                    //  time changed, so we need to set outgoing to actual start
                    (* prtStartRelative) = ::WMSDKToDShowTime (cnsStart) ;
                }
            }
        }

        UnlockRecv_ () ;
    }
    else {
        hr = E_INVALIDARG ;
    }

    return hr ;
}

STDMETHODIMP
CDVRRecording::Stop (
    IN  REFERENCE_TIME  rtStopRelative
    )
{
    HRESULT         hr ;
    REFERENCE_TIME  rtNow ;
    REFERENCE_TIME  rtLastWrite ;
    REFERENCE_TIME  rtStop ;
    BOOL            r ;

    r = ValidateRelativeTime_ (rtStopRelative) ;
    if (r) {

        //  lock so we don't race deliveries
        LockRecv_ () ;

        ASSERT (m_pWriteManager) ;
        hr = m_pWriteManager -> RecordingStreamTime (
                m_dwWriterID,
                & rtNow,
                & rtLastWrite
                ) ;
        if (SUCCEEDED (hr)) {
            rtStop = rtNow + rtStopRelative ;

            SetValidStartStopTime_ (& rtStop, rtLastWrite) ;

            hr = m_pIDVRIORecorder -> StopRecording (
                    DShowToWMSDKTime (rtStop)
                    ) ;

            TRACE_4 (LOG_AREA_RECORDING, 1,
                 TEXT ("CDVRRecording::Stop (%d sec); running time = %I64d (%I64d ms); returning %08xh"),
                 ::DShowTimeToSeconds (rtStopRelative), rtStop, ::DShowTimeToMilliseconds (rtStop), hr) ;
        }
        else {
            //  failed to get the running time -- might mean that we're not
            //    active
            if (!m_pWriteManager -> IsActive ()) {
                //  stop relative is pure delta wrt 0; pass it through unshifted to "now"
                hr = m_pIDVRIORecorder -> StopRecording (
                        DShowToWMSDKTime (rtStopRelative)
                        ) ;
            }
        }

        UnlockRecv_ () ;
    }
    else {
        hr = E_INVALIDARG ;
    }

    return hr ;
}

STDMETHODIMP
CDVRRecording::GetRecordingStatus (
    OUT HRESULT* phResult  /* optional */,
    OUT BOOL*    pbStarted /* optional */,
    OUT BOOL*    pbStopped /* optional */
    )
{
    if ( m_pIDVRIORecorder )
    {
        return m_pIDVRIORecorder -> GetRecordingStatus (phResult, pbStarted, pbStopped) ;

    }
    else
    {
        return E_UNEXPECTED ;
    }
}

BOOL
CDVRRecording::ValidateRelativeTime_ (
    IN  REFERENCE_TIME  rtStartRelative
    )
{
    BOOL            r ;
    REFERENCE_TIME  rtSeconds ;
    REFERENCE_TIME  rtMaxScheduledRelSec ;

    rtMaxScheduledRelSec = (REFERENCE_TIME) m_pDVRPolicy -> Settings () -> MaxScheduledRecordRelativeSeconds () ;

    //  can be negative for multi-file recordings
    rtSeconds = ::DShowTimeToSeconds (rtStartRelative) ;

    if (rtSeconds <= rtMaxScheduledRelSec) {
        r = TRUE ;
    }
    else {
        r = FALSE ;
    }

    return r ;
}

//  ============================================================================

BOOL
CDVRContentRecording::ValidateRelativeTime_ (
    IN  REFERENCE_TIME  rtRelative
    )
{
    BOOL    r ;

    if (rtRelative >= 0) {
        r = CDVRRecording::ValidateRelativeTime_ (rtRelative) ;
    }
    else {
        //  content cannot accept times in the past
        r = FALSE ;
    }

    return r ;
}

void
CDVRContentRecording::SetValidStartStopTime_ (
    IN OUT  REFERENCE_TIME *    prtStartStop,
    IN      REFERENCE_TIME      rtLastWrite
    )
{
    //  content recordings cannot set a start stop time that is old, so we
    //    make sure they occur in the future;  the DVRIO layer adjusts the
    //    stream times that are presented so the WMSDK gets a monotonically
    //    increasing stream of samples; what can happen is that this layer
    //    presents times that are >= vs. >, so the DVRIO will bump the sample
    //    times; if we present a time that is >= to something we've provided
    //    in the past, it might be <= to what the DVRIO layer is using and we
    //    run into problems

    (* prtStartStop) = Max <REFERENCE_TIME> (
                        (* prtStartStop),
                        rtLastWrite + ::MillisToDShowTime (1)
                        ) ;
}

//  ============================================================================

BOOL
CDVRReferenceRecording::ValidateRelativeTime_ (
    IN  REFERENCE_TIME  rtRelative
    )
{
    BOOL    r ;

    r = CDVRRecording::ValidateRelativeTime_ (rtRelative) ;

    return r ;
}

//  ============================================================================

CDVRRecordingAttribEnum::CDVRRecordingAttribEnum (
    IN  IDVRIORecordingAttributes * pIDVRIOAttributes
    ) : CUnknown            (TEXT ("CDVRRecordingAttribEnum"),
                             NULL
                            ),
        m_pIDVRIOAttributes (pIDVRIOAttributes),
        m_wNextIndex        (0)
{
    ASSERT (m_pIDVRIOAttributes) ;
    m_pIDVRIOAttributes -> AddRef () ;

    ::InitializeCriticalSection (& m_crt) ;
}

CDVRRecordingAttribEnum::CDVRRecordingAttribEnum (
    IN  CDVRRecordingAttribEnum *   pCDVRRecordingAttribEnum
    ) : CUnknown            (TEXT ("CDVRRecordingAttribEnum"),
                             NULL
                            ),
        m_pIDVRIOAttributes (pCDVRRecordingAttribEnum -> m_pIDVRIOAttributes),
        m_wNextIndex        (0)
{
    m_pIDVRIOAttributes -> AddRef () ;

    ::InitializeCriticalSection (& m_crt) ;
}

CDVRRecordingAttribEnum::~CDVRRecordingAttribEnum (
    )
{
    m_pIDVRIOAttributes -> Release () ;

    ::DeleteCriticalSection (& m_crt) ;
}

STDMETHODIMP
CDVRRecordingAttribEnum::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    OUT void ** ppv
    )
{
    if (!ppv) {
        return E_POINTER ;
    }

    //  ========================================================================
    //  IEnumStreamBufferRecordingAttrib

    if (riid == IID_IEnumStreamBufferRecordingAttrib) {

        return GetInterface (
                    (IEnumStreamBufferRecordingAttrib *) this,
                    ppv
                    ) ;
    }

    return CUnknown::NonDelegatingQueryInterface (riid, ppv) ;
}

STDMETHODIMP
CDVRRecordingAttribEnum::Next (
    IN      ULONG                       cRequest,
    IN OUT  STREAMBUFFER_ATTRIBUTE *    pDVRAttribute,
    OUT     ULONG *                     pcReceivedParam
    )
{
    HRESULT hr ;
    WORD    wRequest ;
    WORD    cNameLength ;
    WORD    wCount ;
    WORD    wStreamNum ;
    ULONG * pcReceived ;
    ULONG   cReceived ;         //  if pcReceivedParam is NULL (valid if cRequest
                                //    == 1), then we use this

    //  for all calls; required by IWMHeaderInfo
    wStreamNum = 0 ;

    Lock_ () ;

    //
    //  assumption: attribute count cannot be reduced during this call
    //

    hr = m_pIDVRIOAttributes -> GetDVRIORecordingAttributeCount (
                0,
                & wCount
                ) ;
    if (SUCCEEDED (hr)) {
        if (wCount > 0) {
            //  first check if the caller just wants to know how many are left
            if (cRequest == 0 &&
                pcReceivedParam) {

                //  m_wNextIndex is 1-based for the count of indeces read, so
                //    there's no need to shift wCount
                (* pcReceivedParam) = (wCount > m_wNextIndex ? wCount - m_wNextIndex : 0) ;
            }
            else if (cRequest > 0) {
                //  validate the parameters before proceeding
                if (pDVRAttribute &&
                    ((pcReceivedParam && cRequest >= 1) || (!pcReceivedParam && cRequest == 1))
                     ) {

                    //  if caller is reqesting just 1, it is ok for them to not
                    //    request the number they actually retreived
                    if (pcReceivedParam) {
                        pcReceived = pcReceivedParam ;
                    }
                    else {
                        ASSERT (cRequest == 1) ;
                        pcReceived = & cReceived ;
                    }

                    //  initialize
                    (* pcReceived) = 0 ;

                    //  now make sure that we can return at least 1
                    if (m_wNextIndex < wCount) {

                        //  have at least 1 more to go
                        for ((* pcReceived) = 0; (* pcReceived) < cRequest; (* pcReceived)++, m_wNextIndex++) {

                            //  always NULL these before starting
                            pDVRAttribute [(* pcReceived)].pszName      = NULL ;
                            pDVRAttribute [(* pcReceived)].pbAttribute  = NULL ;

                            //  figure out what we're going to have to allocate
                            hr = m_pIDVRIOAttributes -> GetDVRIORecordingAttributeByIndex (
                                    m_wNextIndex,
                                    & wStreamNum,
                                    NULL,
                                    & cNameLength,
                                    & pDVRAttribute [(* pcReceived)].StreamBufferAttributeType,
                                    NULL,
                                    & pDVRAttribute [(* pcReceived)].cbLength
                                    ) ;
                            if (SUCCEEDED (hr)) {

                                if (cNameLength > 0) {
                                    pDVRAttribute [(* pcReceived)].pszName = (LPWSTR) ::CoTaskMemAlloc (cNameLength * sizeof WCHAR) ;
                                }
                                else {
                                    //  should be NULLed each time through
                                    ASSERT (!pDVRAttribute [(* pcReceived)].pszName) ;
                                }

                                if (pDVRAttribute [(* pcReceived)].pszName ||
                                    cNameLength == 0) {

                                    if (pDVRAttribute [(* pcReceived)].cbLength > 0) {
                                        pDVRAttribute [(* pcReceived)].pbAttribute = (BYTE *) ::CoTaskMemAlloc (pDVRAttribute [(* pcReceived)].cbLength) ;
                                    }
                                    else {
                                        //  should be NULLed each time through
                                        ASSERT (!pDVRAttribute [(* pcReceived)].pbAttribute) ;
                                    }

                                    //  if there's an attribute there and we needed to allocate, make
                                    //    sure the operation succeeded
                                    if (pDVRAttribute [(* pcReceived)].cbLength > 0 &&
                                        !pDVRAttribute [(* pcReceived)].pbAttribute) {

                                        //  free up the name string before breaking
                                        ::CoTaskMemFree (pDVRAttribute [(* pcReceived)].pszName) ;
                                        pDVRAttribute [(* pcReceived)].pszName = NULL ;

                                        hr = E_OUTOFMEMORY ;

                                        //  failed to allocate the attribute memory
                                        break ;
                                    }

                                    //  we've allocated everything we need; retrieve the
                                    //    attribute

                                    ASSERT (pDVRAttribute [(* pcReceived)].pbAttribute || pDVRAttribute [(* pcReceived)].cbLength == 0) ;
                                    ASSERT (pDVRAttribute [(* pcReceived)].pszName || cNameLength == 0) ;

                                    hr = m_pIDVRIOAttributes -> GetDVRIORecordingAttributeByIndex (
                                            m_wNextIndex,
                                            & wStreamNum,
                                            pDVRAttribute [(* pcReceived)].pszName,
                                            & cNameLength,
                                            & pDVRAttribute [(* pcReceived)].StreamBufferAttributeType,
                                            pDVRAttribute [(* pcReceived)].pbAttribute,
                                            & pDVRAttribute [(* pcReceived)].cbLength
                                            ) ;
                                    if (FAILED (hr)) {
                                        //  above call failed; we're going to break but
                                        //   we first need to free the memory

                                        ::CoTaskMemFree (pDVRAttribute [(* pcReceived)].pszName) ;
                                        pDVRAttribute [(* pcReceived)].pszName = NULL ;

                                        ::CoTaskMemFree (pDVRAttribute [(* pcReceived)].pbAttribute) ;
                                        pDVRAttribute [(* pcReceived)].pbAttribute = NULL ;

                                        //  failed to retrieve the attribute
                                        break ;
                                    }
                                }
                                else {
                                    hr = E_OUTOFMEMORY ;

                                    //  failed to allocate the memory for the attribute name
                                    break ;
                                }
                            }
                            else {
                                //  failed the call to learn the length of the attribute
                                //    and its name
                                break ;
                            }
                        }
                    }
                    else {
                        //  we're maxed; nothing more to return
                        hr = S_FALSE ;
                    }
                }
                else {
                    //  caller wants something, but did not send in pointers
                    hr = E_POINTER ;
                }
            }
        }
        else {
            //  there are no attributes
            hr = E_FAIL ;
        }
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttribEnum::Skip (
    IN  ULONG   cRecords
    )
{
    HRESULT hr ;
    WORD    wCount ;
    WORD    wRecords ;
    WORD    wStreamNum ;

    //  ULONG -> WORD
    if ((m_wNextIndex + cRecords) & 0xffff0000) {
        return E_FAIL ;
    }

    wRecords = (WORD) cRecords ;

    //  always
    wStreamNum = 0  ;

    Lock_ () ;

    hr = m_pIDVRIOAttributes -> GetDVRIORecordingAttributeCount (
                wStreamNum,
                & wCount
                ) ;
    if (SUCCEEDED (hr)) {
        if (wCount > 0 &&                               //  attributes exist
            m_wNextIndex + wRecords < wCount) {         //  in bounds (0-based)

            m_wNextIndex += wRecords ;
        }
        else {
            hr = E_FAIL ;
        }
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CDVRRecordingAttribEnum::Reset (
    )
{
    Lock_ () ;

    m_wNextIndex = 0 ;

    Unlock_ () ;

    return S_OK ;
}

STDMETHODIMP
CDVRRecordingAttribEnum::Clone (
    OUT IEnumStreamBufferRecordingAttrib **   ppIEnumDVRAttrib
    )
{
    HRESULT hr ;

    if (!ppIEnumDVRAttrib) {
        return E_POINTER ;
    }

    Lock_ () ;

    (* ppIEnumDVRAttrib) = new CDVRRecordingAttribEnum (this) ;

    if (* ppIEnumDVRAttrib) {
        //  set outgoing
        (* ppIEnumDVRAttrib) -> AddRef () ;
        hr = S_OK ;
    }
    else {
        hr = E_OUTOFMEMORY ;
    }

    Unlock_ () ;

    return hr ;
}

//  ============================================================================
//  ============================================================================

CSBECompositionRecording::CSBECompositionRecording (
    IN  IUnknown *  punkControlling,
    IN  HRESULT *   phr
    ) : CUnknown                    (COMP_REC_OBJ_NAME,
                                     punkControlling
                                     ),
        m_pRecordingWriter          (NULL),
        m_pRecProfile               (NULL),
        m_pPVRIOCounters            (NULL),
        m_pPolicy                   (NULL),
        m_cRecSamples               (0),
        m_pDVRRecordingAttributes   (NULL)
{
    InitializeCriticalSection (& m_crt) ;

    m_pPVRIOCounters = new CPVRIOCounters () ;
    if (!m_pPVRIOCounters) {
        (* phr) = E_OUTOFMEMORY ;
        goto cleanup ;
    }

    //  ours
    m_pPVRIOCounters -> AddRef () ;

    m_pPolicy = new CDVRPolicy (REG_DVR_PLAY_ROOT, phr) ;
    if (!m_pPolicy) {
        (* phr) = E_OUTOFMEMORY ;
        goto cleanup ;
    }
    else if (FAILED (* phr)) {
        delete m_pPolicy ;
        m_pPolicy = NULL ;
        goto cleanup ;
    }

    //  success
    (* phr) = S_OK ;

    cleanup :

    return ;
}

CSBECompositionRecording::~CSBECompositionRecording (
    )
{
    Close () ;

    ASSERT (!m_pRecordingWriter) ;

    RELEASE_AND_CLEAR (m_pRecProfile) ;
    RELEASE_AND_CLEAR (m_pPVRIOCounters) ;
    RELEASE_AND_CLEAR (m_pPolicy) ;

    //  close this out in our destructor because we aggregate it
    DELETE_RESET (m_pDVRRecordingAttributes) ;

    DeleteCriticalSection (& m_crt) ;
}

STDMETHODIMP
CSBECompositionRecording::NonDelegatingQueryInterface (
    IN  REFIID  riid,
    IN  void ** ppv
    )
{
    HRESULT hr ;

    //  ------------------------------------------------------------------------
    //  IStreamBufferRecComp

    if (riid == IID_IStreamBufferRecComp) {

        hr = GetInterface (
                    (IStreamBufferRecComp *) this,
                    ppv
                    ) ;

        return hr ;
    }

    //  ========================================================================
    //  IStreamBufferRecordingAttribute

    else if (riid == IID_IStreamBufferRecordingAttribute &&
             m_pDVRRecordingAttributes) {

        //  if successful, this call will ref us
        return m_pDVRRecordingAttributes -> NonDelegatingQueryInterface (
                    IID_IStreamBufferRecordingAttribute,
                    ppv
                    ) ;
    }

    return CUnknown::NonDelegatingQueryInterface (riid, ppv) ;
}

STDMETHODIMP
CSBECompositionRecording::Initialize (
    IN  LPCWSTR pszFilename,
    IN  LPCWSTR pszSBRecording
    )
{
    HRESULT hr ;
    DWORD   dwLen ;

    if (!pszFilename ||
        !pszSBRecording) {

        return E_POINTER ;
    }

    if (m_pDVRRecordingAttributes) {
        //  cannot be initialized more than once i.e. 1 instance per target
        //  recording
        return E_UNEXPECTED ;
    }

    Lock_ () ;

    if (!m_pRecordingWriter) {

        ASSERT (!m_pRecProfile) ;

        hr = InitializeProfileLocked_ (pszSBRecording) ;
        if (SUCCEEDED (hr)) {
            ASSERT (m_pRecProfile) ;
            hr = InitializeWriterLocked_ (pszFilename) ;
        }
    }
    else {
        hr = E_UNEXPECTED ;
    }

    //  if anything failed, make sure we're completely uninitialized
    if (FAILED (hr)) {
        RELEASE_AND_CLEAR (m_pRecProfile) ;
        DELETE_RESET (m_pRecordingWriter) ;
    }

    Unlock_ () ;

    return hr ;
}

//  sets the enforcement profile
HRESULT
CSBECompositionRecording::InitializeProfileLocked_ (
    IN  LPCWSTR pszSBRecording
    )
{
    IDVRReader *    pIDVRReader ;
    HRESULT         hr ;
    IWMProfile *    pIWMNewProfile ;
    IWMProfile *    pIWMReaderProfile ;

    ASSERT (pszSBRecording) ;
    ASSERT (!m_pRecordingWriter) ;

    pIWMNewProfile      = NULL ;
    pIWMReaderProfile   = NULL ;
    pIDVRReader         = NULL ;

    hr = ::DVRCreateReader (
                    m_pPVRIOCounters,
                    pszSBRecording,
                    FALSE,                              //  no unbuffered IO; we just want to look at the attributes in the header
                    REG_DEF_ASYNC_IO_BUFFER_SIZE,
                    REG_DEF_ASYNC_READER_BUFFER_POOL,
                    NULL,
                    NULL,
                    NULL,
                    0,
                    NULL,
                    & pIDVRReader
                    ) ;
    if (SUCCEEDED (hr)) {
        ASSERT (pIDVRReader) ;

        hr = pIDVRReader -> GetProfile (& pIWMReaderProfile) ;
        if (FAILED (hr)) { goto cleanup ; }

        //  we have to make a copy of the profile because the extended
        //    props are not exposed in the reader profile (bug in zeusette)
        hr = ::CopyWMProfile (
                    m_pPolicy,
                    pIWMReaderProfile,
                    & pIWMNewProfile
                    ) ;
        if (FAILED (hr)) { goto cleanup ; }

        ASSERT (pIWMNewProfile) ;

        RELEASE_AND_CLEAR (m_pRecProfile) ;

        m_pRecProfile = new CDVRReaderProfile (
                                m_pPolicy,
                                pIWMNewProfile,
                                & hr
                                ) ;

        if (!m_pRecProfile) {
            hr = E_OUTOFMEMORY ;
        }
        else if (FAILED (hr)) {
            RELEASE_AND_CLEAR (m_pRecProfile) ;
        }
    }

    cleanup :

    if (pIWMReaderProfile) {
        ASSERT (pIDVRReader) ;
        pIDVRReader -> ReleaseProfile (pIWMReaderProfile) ;
    }

    RELEASE_AND_CLEAR (pIWMNewProfile) ;
    RELEASE_AND_CLEAR (pIDVRReader) ;

    return hr ;
}

BOOL
CSBECompositionRecording::IsValidTimeBracketLocked_ (
    IN  IDVRReader *    pIDVRReader,
    IN  REFERENCE_TIME  rtStart,
    IN  REFERENCE_TIME  rtStop
    )
{
    QWORD           cnsStart ;
    QWORD           cnsStop ;
    HRESULT         hr ;
    BOOL            r ;

    hr = pIDVRReader -> GetStreamTimeExtent (
            & cnsStart,
            & cnsStop
            ) ;
    if (SUCCEEDED (hr)) {
        r = ((::WMSDKToDShowTime (cnsStart)             <= rtStart)             &&      //  at least the real content
             (rtStop                                    >  rtStart)             &&      //  these cannot be reversed
             (::DShowTimeToSeconds (rtStop - rtStart)   >=  MIN_REC_WINDOW_SEC) &&      //  min explicit threshold
             (::WMSDKTimeToSeconds (cnsStop - cnsStart) >=  MIN_REC_WINDOW_SEC)         //  recording must have sufficient content
             ) ? TRUE : FALSE ;
    }
    else {
        r = FALSE ;
    }

    return r ;
}

BOOL
CSBECompositionRecording::IsValidProfileLocked_ (
    IN  IDVRReader *    pIDVRReader
    )
{
    HRESULT             hr ;
    BOOL                r ;
    CDVRReaderProfile * pReaderProfile ;

    if (!m_pRecProfile) {
        return FALSE ;
    }

    //  default to FAIL
    r = FALSE ;

    //  init
    pReaderProfile = NULL ;

    pReaderProfile = new CDVRReaderProfile (
                            m_pPolicy,
                            pIDVRReader,
                            & hr
                            ) ;
    if (!pReaderProfile) {
        goto cleanup ;
    }
    else if (FAILED (hr)) {
        goto cleanup ;
    }

    r = m_pRecProfile -> IsEqual (pReaderProfile) ;

    cleanup :

    RELEASE_AND_CLEAR (pReaderProfile) ;

    return r ;
}

BOOL
CSBECompositionRecording::IsValidLocked_ (
    IN  IDVRReader *    pIDVRReader,
    IN  REFERENCE_TIME  rtStart,
    IN  REFERENCE_TIME  rtStop
    )
{
    BOOL    r ;

    r = (IsValidTimeBracketLocked_ (pIDVRReader, rtStart, rtStop) &&
         IsValidProfileLocked_ (pIDVRReader)) ? TRUE : FALSE ;

    return r ;
}

HRESULT
CSBECompositionRecording::InitializeWriterLocked_ (
    IN  LPCWSTR pszFilename
    )
{
    HRESULT                     hr ;
    IWMProfile *                pIWMProfile ;
    IDVRIORecordingAttributes * pIDVRIORecAttr ;

    ASSERT (pszFilename) ;
    ASSERT (!m_pRecordingWriter) ;
    ASSERT (m_pRecProfile) ;
    ASSERT (!m_pDVRRecordingAttributes) ;

    hr          = S_OK ;
    pIWMProfile = NULL ;

    pIWMProfile = m_pRecProfile -> GetRefdProfile () ;
    ASSERT (pIWMProfile) ;

    m_pRecordingWriter = new CSBERecordingWriter (
                                m_pPVRIOCounters,
                                pszFilename,
                                pIWMProfile,
                                m_pPolicy,
                                & hr
                                ) ;

    if (!m_pRecordingWriter) {
        hr = E_OUTOFMEMORY ;
        goto cleanup ;
    }
    else if (FAILED (hr)) {
        DELETE_RESET (m_pRecordingWriter) ;
        goto cleanup ;
    }

    m_INSSBufferHolderPool.SetMaxAllocate (INSSBUFFERHOLDER_POOL_SIZE) ;

    hr = m_pRecordingWriter -> QueryWriter (
            IID_IDVRIORecordingAttributes,
            (void **) & pIDVRIORecAttr
            ) ;
    if (SUCCEEDED (hr)) {
        ASSERT (pIDVRIORecAttr) ;
        m_pDVRRecordingAttributes = new CDVRRecordingAttributes (
                                            this,
                                            pIDVRIORecAttr,
                                            FALSE                   //  not readonly
                                            ) ;
        //  done with this anyways
        pIDVRIORecAttr -> Release () ;

        //  m_pDVRRecordingAttributes object now has 0-refcount on it, so we
        //    must delete it ourselves directly from our destructor
    }
    else {
        //  don't fail the whole thing
        hr = S_OK ;
    }

    cleanup :

    RELEASE_AND_CLEAR (pIWMProfile) ;

    return hr ;
}

HRESULT
CSBECompositionRecording::WriteToRecordingLocked_ (
    IN INSSBuffer * pINSSBuffer,
    IN QWORD        cnsStreamTime,
    IN DWORD        dwFlags,
    IN WORD         wStreamNum
    )
{
    HRESULT hr ;

    hr = m_pRecordingWriter -> Write (
                m_cRecSamples,
                wStreamNum,
                cnsStreamTime,
                dwFlags,
                pINSSBuffer
                ) ;

    m_cRecSamples++ ;

    return hr ;
}

HRESULT
CSBECompositionRecording::AppendRecordingLocked_ (
    IN  IDVRReader *    pIDVRReader,
    IN  REFERENCE_TIME  rtStart,
    IN  REFERENCE_TIME  rtStop
    )
{
    HRESULT                         hr ;
    BOOL                            r ;
    INSSBuffer *                    pINSSBuffer ;
    QWORD                           cnsStreamTime ;
    QWORD                           cnsSampleDuration ;
    DWORD                           dwFlags ;
    WORD                            wStreamNum ;
    QWORD                           cnsStart ;
    QWORD                           cnsStop ;
    CWMPooledINSSBuffer3Holder *    pINSSBuffer3Holder ;

    ASSERT (pIDVRReader) ;

    if (pIDVRReader -> IsLive ()) {
        //  don't allow live files
        return E_INVALIDARG ;
    }

    //  make sure we're ready to write
    if (!m_pRecordingWriter) {
        return E_UNEXPECTED ;
    }

    r = IsValidLocked_ (pIDVRReader, rtStart, rtStop) ;
    if (r) {
        m_cRecSamples = 0 ;

        cnsStart    = ::DShowToWMSDKTime (rtStart) ;
        cnsStop     = ::DShowToWMSDKTime (rtStop) ;

        hr = pIDVRReader -> Seek (cnsStart) ;
        if (FAILED (hr)) { goto cleanup ; }

        for (;;) {
            hr = pIDVRReader -> GetNextSample (
                    & pINSSBuffer,
                    & cnsStreamTime,
                    & cnsSampleDuration,
                    & dwFlags,
                    & wStreamNum
                    ) ;
            if (FAILED (hr)) {
                if (hr == (HRESULT) NS_E_NO_MORE_SAMPLES) {
                    //  EOS; not an error
                    hr = S_OK ;
                }

                //  regardless
                break ;
            }

            ASSERT (pINSSBuffer) ;

            //  check if we've read past our stop point
            if (cnsStreamTime >= cnsStop) {
                pINSSBuffer -> Release () ;
                break ;
            }

            //  this call throttles us because we're drawing from a fixed
            //   size pool
            pINSSBuffer3Holder = m_INSSBufferHolderPool.Get () ;
            if (!pINSSBuffer3Holder) {
                pINSSBuffer -> Release () ;
                hr = E_OUTOFMEMORY ;
                break ;
            }

            pINSSBuffer3Holder -> Init (pINSSBuffer) ;
            pINSSBuffer -> Release () ;

            //  and write to new target
            hr = WriteToRecordingLocked_ (
                    pINSSBuffer3Holder,
                    cnsStreamTime,
                    dwFlags,
                    wStreamNum
                    ) ;

            pINSSBuffer3Holder -> Release () ;

            if (FAILED (hr)) {
                break ;
            }
        }
    }
    else {
        hr = E_INVALIDARG ;
    }

    cleanup :

    return hr ;
}

//  fails if recording is not closed
STDMETHODIMP
CSBECompositionRecording::Append (
    IN  LPCWSTR pszSBRecording
    )
{
    HRESULT         hr ;
    IDVRReader *    pIDVRReader ;

    if (!pszSBRecording) {
        return E_POINTER ;
    }

    Lock_ () ;

    hr = ::DVRCreateReader (
                    m_pPVRIOCounters,
                    pszSBRecording,
                    FALSE,                              //  no unbuffered IO; we just want to look at the attributes in the header
                    REG_DEF_ASYNC_IO_BUFFER_SIZE,
                    REG_DEF_ASYNC_READER_BUFFER_POOL,
                    NULL,
                    NULL,
                    NULL,
                    0,
                    NULL,
                    & pIDVRReader
                    ) ;
    if (SUCCEEDED (hr)) {

        hr = AppendRecordingLocked_ (
                pIDVRReader,
                0,
                MAX_REFERENCE_TIME
                ) ;

        pIDVRReader -> Release () ;
    }

    Unlock_ () ;

    return hr ;
}

//  fails if recording is not closed
STDMETHODIMP
CSBECompositionRecording::AppendEx (
    IN  LPCWSTR         pszSBRecording,
    IN  REFERENCE_TIME  rtStart,
    IN  REFERENCE_TIME  rtStop
    )
{
    HRESULT         hr ;
    IDVRReader *    pIDVRReader ;

    if (!pszSBRecording) {
        return E_POINTER ;
    }

    Lock_ () ;

    hr = ::DVRCreateReader (
                    m_pPVRIOCounters,
                    pszSBRecording,
                    FALSE,                              //  no unbuffered IO; we just want to look at the attributes in the header
                    REG_DEF_ASYNC_IO_BUFFER_SIZE,
                    REG_DEF_ASYNC_READER_BUFFER_POOL,
                    NULL,
                    NULL,
                    NULL,
                    0,
                    NULL,
                    & pIDVRReader
                    ) ;
    if (SUCCEEDED (hr)) {
        hr = AppendRecordingLocked_ (
                pIDVRReader,
                rtStart,
                rtStop
                ) ;

        pIDVRReader -> Release () ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CSBECompositionRecording::GetCurrentLength (
    OUT DWORD * pcSeconds
    )
{
    if (!pcSeconds) {
        return E_POINTER ;
    }

    if (m_pRecordingWriter) {
        (* pcSeconds) = ::WMSDKTimeToSeconds (m_pRecordingWriter -> GetLength ()) ;
    }
    else {
        (* pcSeconds) = 0 ;
    }

    return S_OK ;
}

STDMETHODIMP
CSBECompositionRecording::Close (
    )
{
    HRESULT hr ;

    Lock_ () ;

    if (m_pRecordingWriter) {
        hr = m_pRecordingWriter -> Close () ;

        DELETE_RESET (m_pRecordingWriter) ;

        //  don't delete m_pDVRRecordingAttributes because we've aggregated
        //  it; so we need to close in our destructor
    }
    else {
        hr = E_UNEXPECTED ;
    }

    Unlock_ () ;

    return hr ;
}

STDMETHODIMP
CSBECompositionRecording::Cancel (
    )
{
    return E_NOTIMPL ;
}

CUnknown *
WINAPI
CSBECompositionRecording::CreateInstance (
    IN  IUnknown *  punkControlling,
    IN  HRESULT *   phr
    )
{
    CSBECompositionRecording *  pNewCompRec ;

    pNewCompRec = new CSBECompositionRecording (
                        punkControlling,
                        phr
                        ) ;

    if (!pNewCompRec) {
        (* phr) = E_OUTOFMEMORY ;
    }
    else if (FAILED (* phr)) {
        DELETE_RESET (pNewCompRec) ;
    }

    return pNewCompRec ;
}
=== C:/Users/treeman/Desktop/windows nt source code\Source\XPSP1\NT\multimedia\dshow\filters\sbe\dvrfilters\shared\dvrdsread.h ===
/*++

    Copyright (c) 2001 Microsoft Corporation

    Module Name:

        dvrdsread.h

    Abstract:

        This module contains the declarations for our reading layer.

    Author:

        Matthijs Gates  (mgates)

    Revision History:

        02-Apr-2001     created

--*/

#ifndef __tsdvr__shared__dvrdsread_h
#define __tsdvr__shared__dvrdsread_h

//  ============================================================================
//  CDVRDShowReader
//  ============================================================================

class CDVRDShowReader
{
    protected :

        IDVRReader *    m_pIDVRReader ;
        CDVRPolicy *    m_pPolicy ;

    public :

        CDVRDShowReader (
            IN  CDVRPolicy *        pPolicy,
            IN  IDVRReader *        pIDVRReader,
            OUT HRESULT *           phr
            ) ;

        virtual
        ~CDVRDShowReader (
            ) ;

        HRESULT
        GetRefdReaderProfile (
            OUT CDVRReaderProfile **
            ) ;

        IDVRReader * GetIDVRReader ()       { return m_pIDVRReader ; }

        virtual BOOL IsLiveSource ()        { return m_pIDVRReader -> IsLive () ; }

        virtual BOOL SourceAnchoredToZeroTime ()  { return m_pIDVRReader -> StartTimeAnchoredAtZero () ; }

        virtual
        HRESULT
        Read (
            OUT INSSBuffer **   ppINSSBuffer,
            OUT QWORD *         pcnsStreamTimeOfSample,
            OUT QWORD *         pcnsSampleDuration,
            OUT DWORD *         pdwFlags,
            OUT WORD *          pwStreamNum
            ) ;
} ;

//  ============================================================================
//  CDVRDReaderThread
//  ============================================================================

class CDVRDReaderThread :
    public CDVRThread
{
    enum {
        THREAD_MSG_EXIT         = 0,    //  thread terminates
        THREAD_MSG_PAUSE        = 1,    //  thread pauses
        THREAD_MSG_GO           = 2,    //  thread is started, and runs
        THREAD_MSG_GO_PAUSED    = 3,    //  thread is started, but begins paused
    } ;

    CDVRReadManager *   m_pHost ;

    void
    RuntimeThreadProc_ (
        ) ;

    HRESULT
    ThreadCmdWaitAck_ (
        IN  DWORD   dwCmd
        )
    {
        HRESULT hr ;

        Lock () ;

        hr = ThreadCmd_ (dwCmd) ;
        if (SUCCEEDED (hr)) {
            hr = CmdWaitAck_ (dwCmd) ;
        }

        Unlock () ;

        return hr ;
    }

    //  must hold the lock to serialize & call in conjunction with CmdWait_ (),
    //   after which the lock can be released (see ThreadCmdWait implementation
    //   above)
    HRESULT
    ThreadCmd_ (
        IN  DWORD   dwCmd
        ) ;

    HRESULT
    CmdWaitAck_ (
        IN  DWORD   dwCmd
        ) ;

    HRESULT
    WaitThreadExited_ (
        ) ;

    HRESULT
    StartThread_ (
        IN  DWORD   dwInitialCmd
        ) ;

    public :

        CDVRDReaderThread (
            CDVRReadManager *   pHost
            ) : m_pHost (pHost)
        {
            m_dwParam = THREAD_MSG_EXIT ;
        }

        HRESULT
        GoThreadGo (
            )
        {
            return StartThread_ (THREAD_MSG_GO) ;
        }

        HRESULT
        GoThreadPause (
            )
        {
            return StartThread_ (THREAD_MSG_GO_PAUSED) ;
        }

        HRESULT Pause ()        { return ThreadCmdWaitAck_ (THREAD_MSG_PAUSE) ; }

        HRESULT NotifyPause ()  { return ThreadCmd_ (THREAD_MSG_PAUSE) ; }
        HRESULT WaitPaused ()   { return CmdWaitAck_ (THREAD_MSG_PAUSE) ; }

        HRESULT NotifyExit ()   { return ThreadCmd_ (THREAD_MSG_EXIT) ; }
        HRESULT WaitExited ()   { return WaitThreadExited_ () ; }           //  wait for the thread to really exit

        BOOL IsRunning ()       { return (m_dwParam == THREAD_MSG_GO || m_dwParam == THREAD_MSG_GO_PAUSED ? TRUE : FALSE) ; }
        BOOL IsStopped ()       { return (m_dwParam == THREAD_MSG_EXIT ? TRUE : FALSE) ; }

        void Lock ()            { m_AccessLock.Lock () ; }
        void Unlock ()          { m_AccessLock.Unlock () ; }

        virtual
        DWORD
        ThreadProc (
            ) ;
} ;

//  ============================================================================
//  CMediaSampleList
//  ============================================================================

struct DVR_MEDIASAMPLE_REC {
    IMediaSample2 * pIMS2 ;
    INSSBuffer *    pINSSBuffer ;
    CDVROutputPin * pDVROutputPin ;
    AM_MEDIA_TYPE * pmtNew ;
} ;

class CMediaSampleList
{
    enum {
        ALLOC_QUANTUM = 10
    } ;

    TStructPool <DVR_MEDIASAMPLE_REC, ALLOC_QUANTUM>    m_MediaSampleRecPool ;
    CTDynArray <DVR_MEDIASAMPLE_REC *> *                m_pMSRecList ;

    public :

        CMediaSampleList (
            IN  CTDynArray <DVR_MEDIASAMPLE_REC *> *    pMSRecList
            ) : m_pMSRecList (pMSRecList) {}

        BOOL    Empty ()    { return m_pMSRecList -> Empty () ; }
        DWORD   Length ()   { return m_pMSRecList -> Length () ; }

        //  does not refcount either !!
        HRESULT
        Push (
            IN  IMediaSample2 * pIMS2,
            IN  INSSBuffer *    pINSSBuffer,        //  OPTIONAL
            IN  CDVROutputPin * pDVROutputPin,
            IN  AM_MEDIA_TYPE * pmtNew              //  OPTIONAL
            )
        {
            HRESULT                 hr ;
            DVR_MEDIASAMPLE_REC *   pMediaSampleRec ;
            DWORD                   dw ;

            ASSERT (pIMS2) ;
       