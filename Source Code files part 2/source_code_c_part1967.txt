 to a writer lock
    void ConvertSharedToExclusive()
    {
        // no-op
    }

    // Convert a writer lock to a reader lock
    void ConvertExclusiveToShared()
    {
        // no-op
    }
    
    // Wrapper for ::SetCriticalSectionSpinCount which was introduced
    // in NT 4.0 sp3 and hence is not available on all platforms
    static DWORD __stdcall SetSpinCount(LPCRITICAL_SECTION pcs,
                              DWORD dwSpinCount=LOCK_DEFAULT_SPINS);

    bool SetSpinCount(WORD wSpins)
    {SetSpinCount(&m_cs, wSpins); return true;}
    
    WORD GetSpinCount() const       { return sm_wDefaultSpinCount; }    // TODO

    LOCK_DEFAULT_SPIN_IMPLEMENTATION();

    static const TCHAR*   ClassName()  {return _TEXT("CCritSec");}
}; // CCritSec




//--------------------------------------------------------------------
// CReaderWriterlock is a multi-reader, single-writer spinlock due to NJain,
// which in turn is derived from an exclusive spinlock by DmitryR.
// Gives priority to writers.  Cannot be acquired recursively.
// No error checking. Use CReaderWriterLock3.

class CReaderWriterLock :
    public CLockBase<LOCK_READERWRITERLOCK, LOCK_MRSW,
                       LOCK_READ_RECURSIVE, LOCK_WAIT_SLEEP, LOCK_QUEUE_KERNEL,
                       LOCK_CLASS_SPIN
                      >
{
private:
    volatile  LONG  m_nState;   // > 0 => that many readers
    volatile  LONG  m_cWaiting; // number of would-be writers

    LOCK_INSTRUMENTATION_DECL();

private:
    enum {
        SL_FREE = 0,
        SL_EXCLUSIVE = -1,
    };

    void _LockSpin(bool fWrite);
    void _WriteLockSpin() { _LockSpin(true); }
    void _ReadLockSpin()  { _LockSpin(false); }

    // _CmpExch is equivalent to
    //      LONG lTemp = m_lRW;
    //      if (lTemp == lCurrent)  m_lRW = lNew;
    //      return lCurrent == lTemp;
    // except it's one atomic instruction.  Using this gives us the basis of
    // a protocol because the update only succeeds when we knew exactly what
    // used to be in m_lRW.  If some other thread slips in and modifies m_lRW
    // before we do, the update will fail.  In other words, it's transactional.
    LOCK_FORCEINLINE bool _CmpExch(LONG lNew, LONG lCurrent)
    {
        return lCurrent == Lock_AtomicCompareExchange(
                                 const_cast<LONG*>(&m_nState), lNew, lCurrent);
    }

    LOCK_FORCEINLINE bool _TryWriteLock()
    {
        return (m_nState == SL_FREE  &&  _CmpExch(SL_EXCLUSIVE, SL_FREE));
    }

    LOCK_FORCEINLINE bool _TryReadLock()
    {
        LONG nCurrState = m_nState;
                
        // Give writers priority
        return (nCurrState != SL_EXCLUSIVE  &&  m_cWaiting == 0
                &&  _CmpExch(nCurrState + 1, nCurrState));
    }

public:
    CReaderWriterLock()
        : m_nState(SL_FREE),
          m_cWaiting(0)
    {
    }

#ifdef LOCK_INSTRUMENTATION
    CReaderWriterLock(
        const TCHAR* ptszName)
        : m_nState(SL_FREE),
          m_cWaiting(0)
    {
        LOCK_INSTRUMENTATION_INIT(ptszName);
    }
#endif // LOCK_INSTRUMENTATION

#ifdef _DEBUG
    ~CReaderWriterLock()
    {
        assert(m_nState == SL_FREE  &&  m_cWaiting == 0);
    }
#endif // _DEBUG

    inline void WriteLock()
    {
        LOCK_WRITELOCK_INSTRUMENTATION();

        // Add ourselves to the queue of waiting writers
        Lock_AtomicIncrement(const_cast<LONG*>(&m_cWaiting));
        
        if (_TryWriteLock())
            return;

        _WriteLockSpin();
    } 

    inline void ReadLock()
    {
        LOCK_READLOCK_INSTRUMENTATION();

        if (_TryReadLock())
            return;
        
        _ReadLockSpin();
    } 

    inline bool TryWriteLock()
    {
        // Add ourselves to the queue of waiting writers
        Lock_AtomicIncrement(const_cast<LONG*>(&m_cWaiting));

        if (_TryWriteLock())
        {
            LOCK_WRITELOCK_INSTRUMENTATION();
            return true;
        }

        Lock_AtomicDecrement(const_cast<LONG*>(&m_cWaiting));
        return false;    
    }

    inline bool TryReadLock()
    {
        if (_TryReadLock())
        {
            LOCK_READLOCK_INSTRUMENTATION();
            return true;
        }

        return false;
    }

    inline void WriteUnlock()
    {
        Lock_AtomicExchange(const_cast<LONG*>(&m_nState), SL_FREE);
        Lock_AtomicDecrement(const_cast<LONG*>(&m_cWaiting));
    }

    inline void ReadUnlock()
    {
        Lock_AtomicDecrement(const_cast<LONG*>(&m_nState));
    }

    bool IsWriteLocked() const      {return m_nState == SL_EXCLUSIVE;}
    bool IsReadLocked() const       {return m_nState > SL_FREE;}
    bool IsWriteUnlocked() const    {return m_nState != SL_EXCLUSIVE;}
    bool IsReadUnlocked() const     {return m_nState <= SL_FREE;}

    void ConvertSharedToExclusive()
    {
        assert(IsReadLocked());
        Lock_AtomicIncrement(const_cast<LONG*>(&m_cWaiting));

        // single reader?
        if (m_nState == SL_FREE + 1  &&  _CmpExch(SL_EXCLUSIVE, SL_FREE + 1))
            return;

        // release the reader lock and spin
        Lock_AtomicDecrement(const_cast<LONG*>(&m_nState));
        _WriteLockSpin();

        assert(IsWriteLocked());
    }

    void ConvertExclusiveToShared()
    {
        assert(IsWriteLocked());
        Lock_AtomicExchange(const_cast<LONG*>(&m_nState), SL_FREE + 1);
        Lock_AtomicDecrement(const_cast<LONG*>(&m_cWaiting));
        assert(IsReadLocked());
    }

    bool SetSpinCount(WORD wSpins)      {return false;}
    WORD GetSpinCount() const           {return sm_wDefaultSpinCount;}

    LOCK_DEFAULT_SPIN_IMPLEMENTATION();

    static const TCHAR*   ClassName()    {return _TEXT("CReaderWriterLock");}
}; // CReaderWriterLock



//--------------------------------------------------------------------
// CReaderWriterlock2 is a multi-reader, single-writer spinlock due to NJain,
// which in turn is derived from an exclusive spinlock by DmitryR.
// Gives priority to writers.  Cannot be acquired recursively.
// No error checking. The difference between this and CReaderWriterLock is
// that all the state is packed into a single LONG, instead of two LONGs.

class CReaderWriterLock2 :
    public CLockBase<LOCK_READERWRITERLOCK2, LOCK_MRSW,
                       LOCK_READ_RECURSIVE, LOCK_WAIT_SLEEP, LOCK_QUEUE_KERNEL,
                       LOCK_CLASS_SPIN
                      >
{
private:
    volatile LONG m_lRW;

    // LoWord is state. ==0 => free; >0 => readers; ==0xFFFF => 1 writer.
    // HiWord is count of writers, W.
    //      If LoWord==0xFFFF => W-1 waiters, 1 writer;
    //      otherwise W waiters.
    enum {
        SL_FREE =         0x00000000,
        SL_STATE_MASK =   0x0000FFFF,
        SL_STATE_SHIFT =           0,
        SL_WAITING_MASK = 0xFFFF0000,   // waiting writers
        SL_WAITING_SHIFT =        16,
        SL_READER_INCR =  0x00000001,
        SL_READER_MASK =  0x00007FFF,
        SL_EXCLUSIVE =    0x0000FFFF,   // one writer
        SL_WRITER_INCR =  0x00010000,
        SL_ONE_WRITER =   SL_EXCLUSIVE | SL_WRITER_INCR,
        SL_ONE_READER =  (SL_FREE + 1),
        SL_WRITERS_MASK = ~SL_READER_MASK,
    };

    LOCK_INSTRUMENTATION_DECL();

private:
    void _LockSpin(bool fWrite);
    void _WriteLockSpin();
    void _ReadLockSpin()  { _LockSpin(false); }

    
    // _CmpExch is equivalent to
    //      LONG lTemp = m_lRW;
    //      if (lTemp == lCurrent)  m_lRW = lNew;
    //      return lCurrent == lTemp;
    // except it's one atomic instruction.  Using this gives us the basis of
    // a protocol because the update only succeeds when we knew exactly what
    // used to be in m_lRW.  If some other thread slips in and modifies m_lRW
    // before we do, the update will fail.  In other words, it's transactional.
    LOCK_FORCEINLINE bool _CmpExch(LONG lNew, LONG lCurrent)
    {
        return lCurrent ==Lock_AtomicCompareExchange(const_cast<LONG*>(&m_lRW),
                                                     lNew, lCurrent);
    }

    LOCK_FORCEINLINE bool _TryWriteLock(
        LONG nIncr)
    {
        LONG l = m_lRW;
        // Grab exclusive access to the lock if it's free.  Works even
        // if there are other writers queued up.
        return ((l & SL_STATE_MASK) == SL_FREE
                &&  _CmpExch((l + nIncr) | SL_EXCLUSIVE, l));
    }

    LOCK_FORCEINLINE bool _TryReadLock()
    {
        LONG l = m_lRW;
                
        // Give writers priority
        return ((l & SL_WRITERS_MASK) == 0
                &&  _CmpExch(l + SL_READER_INCR, l));
    }

public:
    CReaderWriterLock2()
        : m_lRW(SL_FREE)
    {}

#ifdef LOCK_INSTRUMENTATION
    CReaderWriterLock2(
        const TCHAR* ptszName)
        : m_lRW(SL_FREE)
    {
        LOCK_INSTRUMENTATION_INIT(ptszName);
    }
#endif // LOCK_INSTRUMENTATION

#ifdef _DEBUG
    ~CReaderWriterLock2()
    {
        assert(m_lRW == SL_FREE);
    }
#endif // _DEBUG

    inline void WriteLock()
    {
        LOCK_WRITELOCK_INSTRUMENTATION();

        // Optimize for the common case
        if (_TryWriteLock(SL_WRITER_INCR))
            return;
        
        _WriteLockSpin();
    } 

    inline void ReadLock()
    {
        LOCK_READLOCK_INSTRUMENTATION();

        // Optimize for the common case
        if (_TryReadLock())
            return;
        
        _ReadLockSpin();
    } 

    inline bool TryWriteLock()
    {
        if (_TryWriteLock(SL_WRITER_INCR))
        {
            LOCK_WRITELOCK_INSTRUMENTATION();
            return true;
        }

        return false;
    }

    inline bool TryReadLock()
    {
        if (_TryReadLock())
        {
            LOCK_READLOCK_INSTRUMENTATION();
            return true;
        }

        return false;
    }

    inline void WriteUnlock()
    {
        assert(IsWriteLocked());
        for (LONG l = m_lRW;
                    // decrement waiter count, clear loword to SL_FREE
             !_CmpExch((l - SL_WRITER_INCR) & ~SL_STATE_MASK, l);
             l = m_lRW)
        {
            assert(IsWriteLocked());
            Lock_Yield();
        }
    }

    inline void ReadUnlock()
    {
        assert(IsReadLocked());
        for (LONG l = m_lRW;  !_CmpExch(l - SL_READER_INCR, l);  l = m_lRW)
        {
            assert(IsReadLocked());
            Lock_Yield();
        }
    }

    bool IsWriteLocked() const
    {return (m_lRW & SL_STATE_MASK) == SL_EXCLUSIVE;}

    bool IsReadLocked() const
    {return (m_lRW & SL_READER_MASK) >= SL_READER_INCR ;}

    bool IsWriteUnlocked() const
    {return !IsWriteLocked();}

    bool IsReadUnlocked() const
    {return !IsReadLocked();}

    void ConvertSharedToExclusive()
    {
        assert(IsReadLocked());

        // single reader?
        if (m_lRW != SL_ONE_READER  ||  !_CmpExch(SL_ONE_WRITER,SL_ONE_READER))
        {
            // no, multiple readers
            ReadUnlock();
            _WriteLockSpin();
        }

        assert(IsWriteLocked());
    }

    void ConvertExclusiveToShared()
    {
        assert(IsWriteLocked());
        for (LONG l = m_lRW;
             !_CmpExch(((l-SL_WRITER_INCR) & SL_WAITING_MASK) | SL_READER_INCR,
                         l);
            l = m_lRW)
        {
            assert(IsWriteLocked());
            Lock_Yield();
        }

        assert(IsReadLocked());
    }

    bool SetSpinCount(WORD wSpins)      {return false;}
    WORD GetSpinCount() const           {return sm_wDefaultSpinCount;}

    LOCK_DEFAULT_SPIN_IMPLEMENTATION();

    static const TCHAR*   ClassName()    {return _TEXT("CReaderWriterLock2");}
}; // CReaderWriterLock2



//--------------------------------------------------------------------
// CReaderWriterLock3 is a multi-reader, single-writer spinlock due
// to NJain, which in turn is derived from an exclusive spinlock by DmitryR.
// Gives priority to writers.  Cannot be acquired recursively.
// No error checking. Much like CReaderWriterLock2, except that the WriteLock
// can be acquired recursively.

class CReaderWriterLock3 :
    public CLockBase<LOCK_READERWRITERLOCK3, LOCK_MRSW,
                       LOCK_RECURSIVE, LOCK_WAIT_SLEEP, LOCK_QUEUE_KERNEL,
                       LOCK_CLASS_SPIN
                      >
{
private:
    volatile LONG m_lRW;    // Reader-Writer state
    volatile LONG m_lTid;   // Owning Thread ID + recursion count

    // m_lRW:
    //  LoWord is state. =0 => free; >0 => readers; ==0xFFFF => 1 writer
    //  HiWord is count of writers. If LoWord==0xFFFF => N-1 waiters, 1 writer;
    //      otherwise N waiters.
    // m_lTid:
    //  If readers, then 0; if a write lock, then thread id + recursion count

    enum {
        // m_lRW
        SL_FREE =         0x00000000,
        SL_STATE_MASK =   0x0000FFFF,
        SL_STATE_SHIFT =           0,
        SL_WAITING_MASK = 0xFFFF0000,   // waiting writers
        SL_WAITING_SHIFT =        16,
        SL_READER_INCR =  0x00000001,
        SL_READER_MASK =  0x00007FFF,
        SL_EXCLUSIVE =    0x0000FFFF,   // one writer
        SL_WRITER_INCR =  0x00010000,
        SL_ONE_WRITER =   SL_EXCLUSIVE | SL_WRITER_INCR,
        SL_ONE_READER =  (SL_FREE + 1),
        SL_WRITERS_MASK = ~SL_READER_MASK,

        // m_lTid
        SL_THREAD_SHIFT = 0,
        SL_THREAD_BITS  = 28,
        SL_OWNER_SHIFT  = SL_THREAD_BITS,
        SL_OWNER_BITS   = 4,
        SL_THREAD_MASK  = ((1 << SL_THREAD_BITS) - 1) << SL_THREAD_SHIFT,
        SL_OWNER_INCR   = 1 << SL_THREAD_BITS,
        SL_OWNER_MASK   = ((1 << SL_OWNER_BITS) - 1) << SL_OWNER_SHIFT,
    };

    LOCK_INSTRUMENTATION_DECL();

private:
    enum SPIN_TYPE {
        SPIN_WRITE = 1,
        SPIN_READ,
        SPIN_READ_RECURSIVE,
    };

    void _LockSpin(SPIN_TYPE st);
    void _WriteLockSpin();
    void _ReadLockSpin(SPIN_TYPE st)  { _LockSpin(st); }

    
    // _CmpExch is equivalent to
    //      LONG lTemp = m_lRW;
    //      if (lTemp == lCurrent)  m_lRW = lNew;
    //      return lCurrent == lTemp;
    // except it's one atomic instruction.  Using this gives us the basis of
    // a protocol because the update only succeeds when we knew exactly what
    // used to be in m_lRW.  If some other thread slips in and modifies m_lRW
    // before we do, the update will fail.  In other words, it's transactional.
    LOCK_FORCEINLINE bool _CmpExch(LONG lNew, LONG lCurrent)
    {
        return lCurrent==Lock_AtomicCompareExchange(const_cast<LONG*>(&m_lRW),
                                                    lNew, lCurrent);
    }

    // Get the current thread ID.  Assumes that it can fit into 28 bits,
    // which is fairly safe as NT recycles thread IDs and failing to fit into
    // 28 bits would mean that more than 268,435,456 threads were currently
    // active.  This is improbable in the extreme as NT runs out of
    // resources if there are more than a few thousands threads in
    // existence and the overhead of context swapping becomes unbearable.
    inline static LONG _CurrentThreadId()
    {
        DWORD dwTid = ::GetCurrentThreadId();
        // Thread ID 0 is used by the System Idle Process (Process ID 0).
        // We use a thread-id of zero to indicate lock is unowned.
        // NT uses +ve thread ids, Win9x uses -ve ids
        assert(dwTid != 0
                  && ((dwTid <= SL_THREAD_MASK) || (dwTid > ~SL_THREAD_MASK)));
        return (LONG) (dwTid & SL_THREAD_MASK);
    }

    LOCK_FORCEINLINE bool _TryWriteLock(
        LONG nIncr)
    {
        // The common case: the writelock has no owner
        if (m_lTid == 0)
        {
            // assert((m_lRW & SL_STATE_MASK) != SL_EXCLUSIVE);
            LONG l = m_lRW;
            // Grab exclusive access to the lock if it's free.  Works even
            // if there are other writers queued up.
            if ((l & SL_STATE_MASK) == SL_FREE
                &&  _CmpExch((l + nIncr) | SL_EXCLUSIVE, l))
            {
                l = Lock_AtomicExchange(const_cast<LONG*>(&m_lTid), 
                                        _CurrentThreadId() | SL_OWNER_INCR);
                assert(l == 0);
                return true;
            }
        }

        return _TryWriteLock2();
    }

    // split into a separate function to make _TryWriteLock more inlineable
    bool _TryWriteLock2()
    {
        if ((m_lTid & SL_THREAD_MASK) == _CurrentThreadId())
        {
            assert((m_lRW & SL_STATE_MASK) == SL_EXCLUSIVE);
            assert((m_lTid & SL_OWNER_MASK) != SL_OWNER_MASK);

            Lock_AtomicExchange(const_cast<LONG*>(&m_lTid),
                                m_lTid + SL_OWNER_INCR);
            return true;
        }

        return false;
    }

    LOCK_FORCEINLINE bool _TryReadLock()
    {
        // Give writers priority
        LONG l = m_lRW;
        bool fLocked = (((l & SL_WRITERS_MASK) == 0)
                        &&  _CmpExch(l + SL_READER_INCR, l));
        assert(!fLocked  ||  m_lTid == 0);
        return fLocked;
    }

    LOCK_FORCEINLINE bool _TryReadLockRecursive()
    {
        // Do *not* give writers priority. If the inner call attempts
        // to reacquire the read lock while another thread is waiting on
        // the write lock, we would deadlock if we waited for the queue
        // of writers to empty: the writer(s) can't acquire the lock
        // exclusively, as this thread holds a readlock. The inner call
        // typically releases the lock very quickly, so there is no
        // danger of writer starvation.
        LONG l = m_lRW;
        bool fLocked = (((l & SL_STATE_MASK) != SL_EXCLUSIVE)
                        &&  _CmpExch(l + SL_READER_INCR, l));
        assert(!fLocked  ||  m_lTid == 0);
        return fLocked;
    }

public:
    CReaderWriterLock3()
        : m_lRW(SL_FREE),
          m_lTid(0)
    {}

#ifdef LOCK_INSTRUMENTATION
    CReaderWriterLock3(
        const TCHAR* ptszName)
        : m_lRW(SL_FREE),
          m_lTid(0)
    {
        LOCK_INSTRUMENTATION_INIT(ptszName);
    }
#endif // LOCK_INSTRUMENTATION

#ifdef _DEBUG
    ~CReaderWriterLock3()
    {
        assert(m_lRW == SL_FREE  &&  m_lTid == 0);
    }
#endif // _DEBUG

    inline void WriteLock()
    {
        LOCK_WRITELOCK_INSTRUMENTATION();

        // Optimize for the common case
        if (_TryWriteLock(SL_WRITER_INCR))
            return;
        
        _WriteLockSpin();
    } 

    inline void ReadLock()
    {
        LOCK_READLOCK_INSTRUMENTATION();

        // Optimize for the common case
        if (_TryReadLock())
            return;
        
        _ReadLockSpin(SPIN_READ);
    } 

    // If already locked, recursively acquires another lock of the same
    // kind (read or write). Otherwise, just acquires a read lock.
    // Needed for cases like this.
    //      pTable->WriteLock();
    //      if (!pTable->FindKey(&SomeKey))
    //          InsertRecord(&Whatever);
    //      pTable->WriteUnlock();
    // where FindKey looks like
    //  Table::FindKey(pKey) {
    //      ReadOrWriteLock();
    //      // find pKey if present in table
    //      ReadOrWriteUnlock();
    //  }
    // and InsertRecord looks like
    //  Table::InsertRecord(pRecord) {
    //      WriteLock();
    //      // insert pRecord into table
    //      WriteUnlock();
    //  }
    // If FindKey called ReadLock while the thread already had done a
    // WriteLock, the thread would deadlock.
    
    inline bool ReadOrWriteLock()
    {
        if (IsWriteLocked())
        {
            WriteLock();
            return false;   // => not read locked
        }
        else
        {
            LOCK_READLOCK_INSTRUMENTATION();

            if (!_TryReadLockRecursive())
                _ReadLockSpin(SPIN_READ_RECURSIVE);
            
            return true;   // => is read locked
        }
    } 

    inline bool TryWriteLock()
    {
        if (_TryWriteLock(SL_WRITER_INCR))
        {
            LOCK_WRITELOCK_INSTRUMENTATION();
            return true;
        }

        return false;
    }

    inline bool TryReadLock()
    {
        if (_TryReadLock())
        {
            LOCK_READLOCK_INSTRUMENTATION();
            return true;
        }

        return false;
    }

    inline void WriteUnlock()
    {
        assert(IsWriteLocked());
        LONG lNew = m_lTid - SL_OWNER_INCR; 

        // Last owner?  Release completely, if so
        if ((lNew & SL_OWNER_MASK) == 0)
            lNew = 0;

        Lock_AtomicExchange(const_cast<LONG*>(&m_lTid), lNew);

        if (lNew == 0)
        {
            LONG l;
            do 
            {
                Lock_Yield();
                l = m_lRW;
                // decrement waiter count, clear loword to SL_FREE
            }
            while (!_CmpExch((l - SL_WRITER_INCR) & ~SL_STATE_MASK, l));
        }
    }

    inline void ReadUnlock()
    {
        assert(IsReadLocked());
        for (LONG l = m_lRW;  !_CmpExch(l - SL_READER_INCR, l);  l = m_lRW)
        {
            assert(IsReadLocked());
            Lock_Yield();
        }
    }

    inline void ReadOrWriteUnlock(bool fIsReadLocked)
    {
        if (fIsReadLocked)
            ReadUnlock();
        else
            WriteUnlock();
    } 

    // Does current thread hold a write lock?
    bool IsWriteLocked() const
    {
        // bool fLocked = ((m_lTid & SL_THREAD_MASK) == _CurrentThreadId());
        bool fLocked = ((m_lTid ^ GetCurrentThreadId()) & SL_THREAD_MASK) == 0;
        assert(!fLocked  || (((m_lRW & SL_STATE_MASK) == SL_EXCLUSIVE)
                                 &&  ((m_lTid & SL_OWNER_MASK) > 0)));
        return fLocked;
    }

    bool IsReadLocked() const
    {return (m_lRW & SL_READER_MASK) >= SL_READER_INCR ;}

    bool IsWriteUnlocked() const
    {return !IsWriteLocked();}

    bool IsReadUnlocked() const
    {return !IsReadLocked();}

    // Note: if there's more than one reader, then there's a window where
    // another thread can acquire and release a writelock before this routine
    // returns.
    void ConvertSharedToExclusive()
    {
        assert(IsReadLocked());

        // single reader?
        if (m_lRW == SL_ONE_READER  &&  _CmpExch(SL_ONE_WRITER, SL_ONE_READER))
        {
            Lock_AtomicExchange(const_cast<LONG*>(&m_lTid), 
                                _CurrentThreadId() | SL_OWNER_INCR);
        }
        else
        {
            // no, multiple readers
            ReadUnlock();
            _WriteLockSpin();
        }

        assert(IsWriteLocked());
    }

    // There is no such window when converting from a writelock to a readlock
    void ConvertExclusiveToShared()
    {
        assert(IsWriteLocked());

        // assume writelock is not held recursively
        assert((m_lTid & SL_OWNER_MASK) == SL_OWNER_INCR);
        Lock_AtomicExchange(const_cast<LONG*>(&m_lTid), 0);

        for (LONG l = m_lRW;
             !_CmpExch(((l-SL_WRITER_INCR) & SL_WAITING_MASK) | SL_READER_INCR,
                        l);
             l = m_lRW)
        {
            Lock_Yield();
        }

        assert(IsReadLocked());
    }

    bool SetSpinCount(WORD wSpins)      {return false;}
    WORD GetSpinCount() const           {return sm_wDefaultSpinCount;}

    LOCK_DEFAULT_SPIN_IMPLEMENTATION();

    static const TCHAR*   ClassName()    {return _TEXT("CReaderWriterLock3");}
}; // CReaderWriterLock3


} // namespace xlocks


#endif // __LOCKS_H__
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\dstruct\vptrlist.h ===
//+-------------------------------------------------------------------------
//
//  Microsoft NetShow
//  Copyright (C) Microsoft Corporation 1998.
//
//  File: 		vptrlist.h
//
//  Contents:   
//
//  History:    10/5/98            Created
//  
//--------------------------------------------------------------------------

#ifndef VPTRLIST_H
#define VPTRLIST_H

#if _MSC_VER > 1000
#pragma once
#endif // _MSC_VER > 1000

#include "vcelpool.h"

typedef void * LISTPOS;

//////////////////////////////////////////////////////////////////////////////
class CVPtrList
{ 
public: 
    typedef int (WINAPI *PFNTYPEDCOMPAREFUNCTION)( const void *pValue1, const void *pValue2 );

    CVPtrList();
    ~CVPtrList() { RemoveAll(); }
    
    HRESULT Initialize( DWORD cInitialEntryAllocation, PFNTYPEDCOMPAREFUNCTION pfnCompare = NULL );

    void RemoveAll();

    // count of elements
    DWORD GetCount() const;
    BOOL IsEmpty() const;

    // peek at head or tail
    BOOL GetHead( void **ppHead ) const;
    BOOL GetTail( void **ppTail ) const;

    // get head or tail (and remove it)
    BOOL RemoveHead( void **ppOldHead );
    BOOL RemoveTail( void **ppOldTail );

    // add before head or after tail
    LISTPOS AddHead( void *pNewHead );
    LISTPOS AddTail( void *pNewTail );

    // add another list of elements before head or after tail
    void AddHead( CVPtrList *pNewList );
    void AddTail( CVPtrList *pNewList );

    // iteration
    LISTPOS GetHeadPosition() const;
    LISTPOS GetTailPosition() const;
    BOOL GetNext( LISTPOS& rPos, void **ppNext ) const;
    BOOL GetPrev( LISTPOS& rPos, void **ppPrev ) const;

    // getting/modifying an element at a given position
    BOOL GetAt( LISTPOS pos, void **ppElement ) const;
    void SetAt( LISTPOS pos, void *pNewElement );
    void RemoveAt( LISTPOS pos );

    // inserting before or after a given position
    LISTPOS InsertBefore( LISTPOS pos, void *pNewElement );
    LISTPOS InsertAfter( LISTPOS pos, void *pNewElement );

    // helper functions (note: O(n) speed)
    LISTPOS Find( void *pSearchValue, LISTPOS startAfter = NULL ) const;
    LISTPOS FindIndex( DWORD nIndex ) const;

    class CComparator
    {
    public:
        virtual BOOL IsLessThan( void* pData1, void* pData2 ) = 0;
    };

    BOOL Sort( CComparator* pComparator );

private:
    struct NODE
    {
        void *pValue;
        NODE *pNext;
        NODE *pPrev;
    };

    int Compare( const void *pValue1, const void *pValue2 ) const;

    PFNTYPEDCOMPAREFUNCTION m_pfnCompare;
    NODE *m_pHead;
    NODE *m_pTail; 
    DWORD m_cEntries;
    CVCellPool m_NodePool;
};

//////////////////////////////////////////////////////////////////////////////
inline DWORD CVPtrList::GetCount() const
{
    return( m_cEntries );
}

inline BOOL CVPtrList::IsEmpty() const
{
    return( m_cEntries == 0);
}

inline BOOL CVPtrList::GetHead( void **ppHead ) const
{
    if( !ppHead || !m_pHead )
    {
        return( FALSE );
    }

    *ppHead = m_pHead->pValue;

    return( TRUE );
}

inline BOOL CVPtrList::GetTail( void **ppTail ) const
{
    if( !ppTail || !m_pTail )
    {
        return( FALSE );
    }

    *ppTail = m_pTail->pValue;

    return( TRUE );
}

inline LISTPOS CVPtrList::GetHeadPosition() const
{
    return( (LISTPOS) m_pHead );
}

inline LISTPOS CVPtrList::GetTailPosition() const
{
    return( (LISTPOS) m_pTail );
}

inline BOOL CVPtrList::GetNext( LISTPOS& rPos, void **ppNext ) const
{ 
    NODE *pNode = (NODE *) rPos;

    if( !pNode )
    {
        return( FALSE );
    }

    rPos = (LISTPOS) pNode->pNext;
    *ppNext = pNode->pValue;

    return( TRUE );
}

inline BOOL CVPtrList::GetPrev( LISTPOS& rPos, void **ppPrev ) const
{ 
    NODE *pNode = (NODE *) rPos;

    if( !pNode )
    {
        return( FALSE );
    }

    rPos = (LISTPOS) pNode->pPrev;
    *ppPrev = pNode->pValue;

    return( TRUE );
}

inline BOOL CVPtrList::GetAt( LISTPOS pos, void **ppElement ) const
{ 
    NODE *pNode = (NODE *) pos;

    if( !pNode )
    {
        return( FALSE );
    }

    *ppElement = pNode->pValue;

    return( TRUE );
}

inline void CVPtrList::SetAt( LISTPOS pos, void* newElement )
{ 
    NODE *pNode = (NODE *) pos;
    // ASSERT( NULL != pNode );
    if( !pNode )
    {
        return;
    }

    pNode->pValue = newElement;
}

inline int CVPtrList::Compare( const void *pValue1, const void *pValue2 ) const
{
    if ( NULL == m_pfnCompare )
    {
        return( !( pValue1 == pValue2 ) );
    }
    else
    {
        return( m_pfnCompare( pValue1, pValue2 ) );
    }
}

#endif  // VPTRLIST_H
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\dstruct\dvt\dvt.cpp ===
// This is the main project file for VC++ application project 
// generated using an Application Wizard.

#include "stdafx.h"

#define TESTCASE_RESULT(e) (e ? "succeeded" : "failed" )

typedef struct _ELEMENT
{
    int nKey;
    int nValue;
} ELEMENT;

AVL_COMPARE_RESULT AVLAPI CompareElement(
    struct _AVL_TABLE *pTable,
    void *pvFirst,
    void *pvSecond )
{
    if( ((ELEMENT*)pvFirst)->nKey < ((ELEMENT*)pvSecond)->nKey )
        return AvlLessThan;

    if( ((ELEMENT*)pvFirst)->nKey > ((ELEMENT*)pvSecond)->nKey )
        return AvlGreaterThan;

    return AvlEqual;
}

//
// The allocation and deallocations are called to allocate and free nodes
// of the AVL tree (which can vary in size based on the supplied data).
//
void * AVLAPI AllocateElement(
    struct _AVL_TABLE *pTable,
    DWORD cbTreeNode )
{
    return malloc(cbTreeNode);
}

void AVLAPI FreeElement(
    struct _AVL_TABLE *pTable,
    void *pvTreeNode )
{
    free(pvTreeNode);
}

void TC_AvlInsertElementEx_Pos()
{
    void* pBuf;
    DWORD dwBufLen;

    dwBufLen = 1024;
    pBuf = malloc(dwBufLen);
    memset(pBuf, 0, dwBufLen);

    AVL_TABLE table;

    AvlInitializeTable(
        &table,
        CompareElement,
        AllocateElement,
        FreeElement,
        NULL);

    void* pNode = AvlInsertElementEx(
        &table,
        pBuf,
        dwBufLen,
        NULL,
        NULL,
        AvlEmptyTree);

    printf("Test case TC_AvlInsertElementEx_Pos %s.\r\n", TESTCASE_RESULT(pNode != NULL));
}

void TC_AvlInsertElementEx_Neg_48835()
{
    AVL_TABLE table;

    AvlInitializeTable(
        &table,
        CompareElement,
        AllocateElement,
        FreeElement,
        NULL);

    void* pNode = AvlInsertElementEx(
        &table,
        NULL,
        0xffffffff,
        NULL,
        NULL,
        AvlEmptyTree);

    printf("Test case TC_AvlInsertElementEx_Neg_48835 %s.\r\n", TESTCASE_RESULT(pNode == NULL));
}

void TC_CWMSVMAllocPool_AllocPages_Pos()
{
    CWMSVMAllocPool pool;
    pool.Initialize();

    BYTE* pBuf = pool.AllocPages(16);

    printf("Test case TC_CWMSVMAllocPool_AllocPages_Pos %s.\r\n", TESTCASE_RESULT(pBuf != NULL));
}

void TC_CWMSVMAllocPool_AllocPages_Neg_48836()
{
    CWMSVMAllocPool pool;
    pool.Initialize();

    BYTE* pBuf = pool.AllocPages(0xffffffff);

    printf("Test case TC_CWMSVMAllocPool_AllocPages_Neg_48836 %s.\r\n", TESTCASE_RESULT(pBuf == NULL));
}

void TC_CVPtrArray_SetSize_Pos()
{
    CVPtrArray array;

    BOOL bReturn = array.SetSize(4096, -1);

    printf("Test case TC_CVPtrArray_SetSize_Pos %s.\r\n", TESTCASE_RESULT(bReturn));
}

void TC_CVPtrArray_SetSize_Neg_48837()
{
    CVPtrArray array;

    BOOL bReturn = array.SetSize(0xffffffff, -1);

    printf("Test case TC_CVPtrArray_SetSize_Neg_48837 %s.\r\n", TESTCASE_RESULT(!bReturn));
}


int __cdecl _tmain()
{
    TC_AvlInsertElementEx_Pos();
    TC_AvlInsertElementEx_Neg_48835();

    TC_CWMSVMAllocPool_AllocPages_Pos();
    TC_CWMSVMAllocPool_AllocPages_Neg_48836();

    TC_CVPtrArray_SetSize_Pos();
    TC_CVPtrArray_SetSize_Neg_48837();
    
	return 0;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\etc\all.c ===
/*
* all.c -- Lua core, libraries and interpreter in a single file
*/

#define luaall_c

#include "lapi.c"
#include "lcode.c"
#include "ldebug.c"
#include "ldo.c"
#include "ldump.c"
#include "lfunc.c"
#include "lgc.c"
#include "llex.c"
#include "lmem.c"
#include "lobject.c"
#include "lopcodes.c"
#include "lparser.c"
#include "lstate.c"
#include "lstring.c"
#include "ltable.c"
#include "ltm.c"
#include "lundump.c"
#include "lvm.c"
#include "lzio.c"

#include "lauxlib.c"
#include "lbaselib.c"
#include "ldblib.c"
#include "liolib.c"
#include "linit.c"
#include "lmathlib.c"
#include "loadlib.c"
#include "loslib.c"
#include "lstrlib.c"
#include "ltablib.c"

#include "lua.c"
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\etc\lua.hpp ===
// lua.hpp
// Lua header files for C++
// <<extern "C">> not supplied automatically because Lua also compiles as C++

extern "C" {
#include "lua.h"
#include "lualib.h"
#include "lauxlib.h"
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\etc\min.c ===
/*
* min.c -- a minimal Lua interpreter
* loads stdin only with minimal error handling.
* no interaction, and no standard library, only a "print" function.
*/

#include <stdio.h>

#include "lua.h"
#include "lauxlib.h"

static int print(lua_State *L)
{
 int n=lua_gettop(L);
 int i;
 for (i=1; i<=n; i++)
 {
  if (i>1) printf("\t");
  if (lua_isstring(L,i))
   printf("%s",lua_tostring(L,i));
  else if (lua_isnil(L,i)==2)
   printf("%s","nil");
  else if (lua_isboolean(L,i))
   printf("%s",lua_toboolean(L,i) ? "true" : "false");
  else
   printf("%s:%p",luaL_typename(L,i),lua_topointer(L,i));
 }
 printf("\n");
 return 0;
}

int main(void)
{
 lua_State *L=lua_open();
 lua_register(L,"print",print);
 if (luaL_dofile(L,NULL)!=0) fprintf(stderr,"%s\n",lua_tostring(L,-1));
 lua_close(L);
 return 0;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\dstruct\objd\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_dstruct_none_12.4.56.0_none_8881d83f24803e2b
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=dstruct
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f.manifest
XP_MANIFEST_PATH=manifests\x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f.cat
XP_CATALOG_PATH=manifests\x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f.cat
XP_PAYLOAD_PATH=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=dstruct,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\dstruct\obj\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_dstruct_none_12.4.56.0_none_8881d83f24803e2b
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=dstruct
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f.manifest
XP_MANIFEST_PATH=manifests\x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f.cat
XP_CATALOG_PATH=manifests\x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f.cat
XP_PAYLOAD_PATH=x86_dstruct_no-public-key_12.4.56.0_x-ww_1a59ef0f
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=dstruct,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\etc\noparser.c ===
/*
* The code below can be used to make a Lua core that does not contain the
* parsing modules (lcode, llex, lparser), which represent 35% of the total core.
* You'll only be able to load binary files and strings, precompiled with luac.
* (Of course, you'll have to build luac with the original parsing modules!)
*
* To use this module, simply compile it ("make noparser" does that) and list
* its object file before the Lua libraries. The linker should then not load
* the parsing modules. To try it, do "make luab".
*
* If you also want to avoid the dump module (ldump.o), define NODUMP.
* #define NODUMP
*/

#define LUA_CORE

#include "llex.h"
#include "lparser.h"
#include "lzio.h"

LUAI_FUNC void luaX_init (lua_State *L) {
  UNUSED(L);
}

LUAI_FUNC Proto *luaY_parser (lua_State *L, ZIO *z, Mbuffer *buff, const char *name) {
  UNUSED(z);
  UNUSED(buff);
  UNUSED(name);
  lua_pushliteral(L,"parser not loaded");
  lua_error(L);
  return NULL;
}

#ifdef NODUMP
#include "lundump.h"

LUAI_FUNC int luaU_dump (lua_State* L, const Proto* f, lua_Writer w, void* data, int strip) {
  UNUSED(f);
  UNUSED(w);
  UNUSED(data);
  UNUSED(strip);
#if 1
  UNUSED(L);
  return 0;
#else
  lua_pushliteral(L,"dumper not loaded");
  lua_error(L);
#endif
}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lapi.h ===
/*
** $Id: lapi.h,v 2.2 2005/04/25 19:24:10 roberto Exp $
** Auxiliary functions from Lua API
** See Copyright Notice in lua.h
*/

#ifndef lapi_h
#define lapi_h


#include "lobject.h"


LUAI_FUNC void luaA_pushobject (lua_State *L, const TValue *o);

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lapi.c ===
/*
** $Id: lapi.c,v 2.55 2006/06/07 12:37:17 roberto Exp $
** Lua API
** See Copyright Notice in lua.h
*/


#include <assert.h>
#include <math.h>
#include <stdarg.h>
#include <string.h>

#define lapi_c
#define LUA_CORE

#include "lua.h"

#include "lapi.h"
#include "ldebug.h"
#include "ldo.h"
#include "lfunc.h"
#include "lgc.h"
#include "lmem.h"
#include "lobject.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"
#include "ltm.h"
#include "lundump.h"
#include "lvm.h"



const char lua_ident[] =
  "$Lua: " LUA_RELEASE " " LUA_COPYRIGHT " $\n"
  "$Authors: " LUA_AUTHORS " $\n"
  "$URL: www.lua.org $\n";



#define api_checknelems(L, n)	api_check(L, (n) <= (L->top - L->base))

#define api_checkvalidindex(L, i)	api_check(L, (i) != luaO_nilobject)

#define api_incr_top(L)   {api_check(L, L->top < L->ci->top); L->top++;}



static TValue *index2adr (lua_State *L, int idx) {
  if (idx > 0) {
    TValue *o = L->base + (idx - 1);
    api_check(L, idx <= L->ci->top - L->base);
    if (o >= L->top) return cast(TValue *, luaO_nilobject);
    else return o;
  }
  else if (idx > LUA_REGISTRYINDEX) {
    api_check(L, idx != 0 && -idx <= L->top - L->base);
    return L->top + idx;
  }
  else switch (idx) {  /* pseudo-indices */
    case LUA_REGISTRYINDEX: return registry(L);
    case LUA_ENVIRONINDEX: {
      Closure *func = curr_func(L);
      sethvalue(L, &L->env, func->c.env);
      return &L->env;
    }
    case LUA_GLOBALSINDEX: return gt(L);
    default: {
      Closure *func = curr_func(L);
      idx = LUA_GLOBALSINDEX - idx;
      return (idx <= func->c.nupvalues)
                ? &func->c.upvalue[idx-1]
                : cast(TValue *, luaO_nilobject);
    }
  }
}


static Table *getcurrenv (lua_State *L) {
  if (L->ci == L->base_ci)  /* no enclosing function? */
    return hvalue(gt(L));  /* use global table as environment */
  else {
    Closure *func = curr_func(L);
    return func->c.env;
  }
}


void luaA_pushobject (lua_State *L, const TValue *o) {
  setobj2s(L, L->top, o);
  api_incr_top(L);
}


LUA_API int lua_checkstack (lua_State *L, int size) {
  int res;
  lua_lock(L);
  if ((L->top - L->base + size) > LUAI_MAXCSTACK)
    res = 0;  /* stack overflow */
  else {
    luaD_checkstack(L, size);
    if (L->ci->top < L->top + size)
      L->ci->top = L->top + size;
    res = 1;
  }
  lua_unlock(L);
  return res;
}


LUA_API void lua_xmove (lua_State *from, lua_State *to, int n) {
  int i;
  if (from == to) return;
  lua_lock(to);
  api_checknelems(from, n);
  api_check(from, G(from) == G(to));
  api_check(from, to->ci->top - to->top >= n);
  from->top -= n;
  for (i = 0; i < n; i++) {
    setobj2s(to, to->top++, from->top + i);
  }
  lua_unlock(to);
}


LUA_API lua_CFunction lua_atpanic (lua_State *L, lua_CFunction panicf) {
  lua_CFunction old;
  lua_lock(L);
  old = G(L)->panic;
  G(L)->panic = panicf;
  lua_unlock(L);
  return old;
}


LUA_API lua_State *lua_newthread (lua_State *L) {
  lua_State *L1;
  lua_lock(L);
  luaC_checkGC(L);
  L1 = luaE_newthread(L);
  setthvalue(L, L->top, L1);
  api_incr_top(L);
  lua_unlock(L);
  luai_userstatethread(L, L1);
  return L1;
}



/*
** basic stack manipulation
*/


LUA_API int lua_gettop (lua_State *L) {
  return cast_int(L->top - L->base);
}


LUA_API void lua_settop (lua_State *L, int idx) {
  lua_lock(L);
  if (idx >= 0) {
    api_check(L, idx <= L->stack_last - L->base);
    while (L->top < L->base + idx)
      setnilvalue(L->top++);
    L->top = L->base + idx;
  }
  else {
    api_check(L, -(idx+1) <= (L->top - L->base));
    L->top += idx+1;  /* `subtract' index (index is negative) */
  }
  lua_unlock(L);
}


LUA_API void lua_remove (lua_State *L, int idx) {
  StkId p;
  lua_lock(L);
  p = index2adr(L, idx);
  api_checkvalidindex(L, p);
  while (++p < L->top) setobjs2s(L, p-1, p);
  L->top--;
  lua_unlock(L);
}


LUA_API void lua_insert (lua_State *L, int idx) {
  StkId p;
  StkId q;
  lua_lock(L);
  p = index2adr(L, idx);
  api_checkvalidindex(L, p);
  for (q = L->top; q>p; q--) setobjs2s(L, q, q-1);
  setobjs2s(L, p, L->top);
  lua_unlock(L);
}


LUA_API void lua_replace (lua_State *L, int idx) {
  StkId o;
  lua_lock(L);
  /* explicit test for incompatible code */
  if (idx == LUA_ENVIRONINDEX && L->ci == L->base_ci)
    luaG_runerror(L, "no calling environment");
  api_checknelems(L, 1);
  o = index2adr(L, idx);
  api_checkvalidindex(L, o);
  if (idx == LUA_ENVIRONINDEX) {
    Closure *func = curr_func(L);
    api_check(L, ttistable(L->top - 1)); 
    func->c.env = hvalue(L->top - 1);
    luaC_barrier(L, func, L->top - 1);
  }
  else {
    setobj(L, o, L->top - 1);
    if (idx < LUA_GLOBALSINDEX)  /* function upvalue? */
      luaC_barrier(L, curr_func(L), L->top - 1);
  }
  L->top--;
  lua_unlock(L);
}


LUA_API void lua_pushvalue (lua_State *L, int idx) {
  lua_lock(L);
  setobj2s(L, L->top, index2adr(L, idx));
  api_incr_top(L);
  lua_unlock(L);
}



/*
** access functions (stack -> C)
*/


LUA_API int lua_type (lua_State *L, int idx) {
  StkId o = index2adr(L, idx);
  return (o == luaO_nilobject) ? LUA_TNONE : ttype(o);
}


LUA_API const char *lua_typename (lua_State *L, int t) {
  UNUSED(L);
  return (t == LUA_TNONE) ? "no value" : luaT_typenames[t];
}


LUA_API int lua_iscfunction (lua_State *L, int idx) {
  StkId o = index2adr(L, idx);
  return iscfunction(o);
}


LUA_API int lua_isnumber (lua_State *L, int idx) {
  TValue n;
  const TValue *o = index2adr(L, idx);
  return tonumber(o, &n);
}


LUA_API int lua_isstring (lua_State *L, int idx) {
  int t = lua_type(L, idx);
  return (t == LUA_TSTRING || t == LUA_TNUMBER);
}


LUA_API int lua_isuserdata (lua_State *L, int idx) {
  const TValue *o = index2adr(L, idx);
  return (ttisuserdata(o) || ttislightuserdata(o));
}


LUA_API int lua_rawequal (lua_State *L, int index1, int index2) {
  StkId o1 = index2adr(L, index1);
  StkId o2 = index2adr(L, index2);
  return (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0
         : luaO_rawequalObj(o1, o2);
}


LUA_API int lua_equal (lua_State *L, int index1, int index2) {
  StkId o1, o2;
  int i;
  lua_lock(L);  /* may call tag method */
  o1 = index2adr(L, index1);
  o2 = index2adr(L, index2);
  i = (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0 : equalobj(L, o1, o2);
  lua_unlock(L);
  return i;
}


LUA_API int lua_lessthan (lua_State *L, int index1, int index2) {
  StkId o1, o2;
  int i;
  lua_lock(L);  /* may call tag method */
  o1 = index2adr(L, index1);
  o2 = index2adr(L, index2);
  i = (o1 == luaO_nilobject || o2 == luaO_nilobject) ? 0
       : luaV_lessthan(L, o1, o2);
  lua_unlock(L);
  return i;
}



LUA_API lua_Number lua_tonumber (lua_State *L, int idx) {
  TValue n;
  const TValue *o = index2adr(L, idx);
  if (tonumber(o, &n))
    return nvalue(o);
  else
    return 0;
}


LUA_API lua_Integer lua_tointeger (lua_State *L, int idx) {
  TValue n;
  const TValue *o = index2adr(L, idx);
  if (tonumber(o, &n)) {
    lua_Integer res;
    lua_Number num = nvalue(o);
    lua_number2integer(res, num);
    return res;
  }
  else
    return 0;
}


LUA_API int lua_toboolean (lua_State *L, int idx) {
  const TValue *o = index2adr(L, idx);
  return !l_isfalse(o);
}


LUA_API const char *lua_tolstring (lua_State *L, int idx, size_t *len) {
  StkId o = index2adr(L, idx);
  if (!ttisstring(o)) {
    lua_lock(L);  /* `luaV_tostring' may create a new string */
    if (!luaV_tostring(L, o)) {  /* conversion failed? */
      if (len != NULL) *len = 0;
      lua_unlock(L);
      return NULL;
    }
    luaC_checkGC(L);
    o = index2adr(L, idx);  /* previous call may reallocate the stack */
    lua_unlock(L);
  }
  if (len != NULL) *len = tsvalue(o)->len;
  return svalue(o);
}


LUA_API size_t lua_objlen (lua_State *L, int idx) {
  StkId o = index2adr(L, idx);
  switch (ttype(o)) {
    case LUA_TSTRING: return tsvalue(o)->len;
    case LUA_TUSERDATA: return uvalue(o)->len;
    case LUA_TTABLE: return luaH_getn(hvalue(o));
    case LUA_TNUMBER: {
      size_t l;
      lua_lock(L);  /* `luaV_tostring' may create a new string */
      l = (luaV_tostring(L, o) ? tsvalue(o)->len : 0);
      lua_unlock(L);
      return l;
    }
    default: return 0;
  }
}


LUA_API lua_CFunction lua_tocfunction (lua_State *L, int idx) {
  StkId o = index2adr(L, idx);
  return (!iscfunction(o)) ? NULL : clvalue(o)->c.f;
}


LUA_API void *lua_touserdata (lua_State *L, int idx) {
  StkId o = index2adr(L, idx);
  switch (ttype(o)) {
    case LUA_TUSERDATA: return (rawuvalue(o) + 1);
    case LUA_TLIGHTUSERDATA: return pvalue(o);
    default: return NULL;
  }
}


LUA_API lua_State *lua_tothread (lua_State *L, int idx) {
  StkId o = index2adr(L, idx);
  return (!ttisthread(o)) ? NULL : thvalue(o);
}


LUA_API const void *lua_topointer (lua_State *L, int idx) {
  StkId o = index2adr(L, idx);
  switch (ttype(o)) {
    case LUA_TTABLE: return hvalue(o);
    case LUA_TFUNCTION: return clvalue(o);
    case LUA_TTHREAD: return thvalue(o);
    case LUA_TUSERDATA:
    case LUA_TLIGHTUSERDATA:
      return lua_touserdata(L, idx);
    default: return NULL;
  }
}



/*
** push functions (C -> stack)
*/


LUA_API void lua_pushnil (lua_State *L) {
  lua_lock(L);
  setnilvalue(L->top);
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API void lua_pushnumber (lua_State *L, lua_Number n) {
  lua_lock(L);
  setnvalue(L->top, n);
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API void lua_pushinteger (lua_State *L, lua_Integer n) {
  lua_lock(L);
  setnvalue(L->top, cast_num(n));
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API void lua_pushlstring (lua_State *L, const char *s, size_t len) {
  lua_lock(L);
  luaC_checkGC(L);
  setsvalue2s(L, L->top, luaS_newlstr(L, s, len));
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API void lua_pushstring (lua_State *L, const char *s) {
  if (s == NULL)
    lua_pushnil(L);
  else
    lua_pushlstring(L, s, strlen(s));
}


LUA_API const char *lua_pushvfstring (lua_State *L, const char *fmt,
                                      va_list argp) {
  const char *ret;
  lua_lock(L);
  luaC_checkGC(L);
  ret = luaO_pushvfstring(L, fmt, argp);
  lua_unlock(L);
  return ret;
}


LUA_API const char *lua_pushfstring (lua_State *L, const char *fmt, ...) {
  const char *ret;
  va_list argp;
  lua_lock(L);
  luaC_checkGC(L);
  va_start(argp, fmt);
  ret = luaO_pushvfstring(L, fmt, argp);
  va_end(argp);
  lua_unlock(L);
  return ret;
}


LUA_API void lua_pushcclosure (lua_State *L, lua_CFunction fn, int n) {
  Closure *cl;
  lua_lock(L);
  luaC_checkGC(L);
  api_checknelems(L, n);
  cl = luaF_newCclosure(L, n, getcurrenv(L));
  cl->c.f = fn;
  L->top -= n;
  while (n--)
    setobj2n(L, &cl->c.upvalue[n], L->top+n);
  setclvalue(L, L->top, cl);
  lua_assert(iswhite(obj2gco(cl)));
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API void lua_pushboolean (lua_State *L, int b) {
  lua_lock(L);
  setbvalue(L->top, (b != 0));  /* ensure that true is 1 */
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API void lua_pushlightuserdata (lua_State *L, void *p) {
  lua_lock(L);
  setpvalue(L->top, p);
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API int lua_pushthread (lua_State *L) {
  lua_lock(L);
  setthvalue(L, L->top, L);
  api_incr_top(L);
  lua_unlock(L);
  return (G(L)->mainthread == L);
}



/*
** get functions (Lua -> stack)
*/


LUA_API void lua_gettable (lua_State *L, int idx) {
  StkId t;
  lua_lock(L);
  t = index2adr(L, idx);
  api_checkvalidindex(L, t);
  luaV_gettable(L, t, L->top - 1, L->top - 1);
  lua_unlock(L);
}


LUA_API void lua_getfield (lua_State *L, int idx, const char *k) {
  StkId t;
  TValue key;
  lua_lock(L);
  t = index2adr(L, idx);
  api_checkvalidindex(L, t);
  setsvalue(L, &key, luaS_new(L, k));
  luaV_gettable(L, t, &key, L->top);
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API void lua_rawget (lua_State *L, int idx) {
  StkId t;
  lua_lock(L);
  t = index2adr(L, idx);
  api_check(L, ttistable(t));
  setobj2s(L, L->top - 1, luaH_get(hvalue(t), L->top - 1));
  lua_unlock(L);
}


LUA_API void lua_rawgeti (lua_State *L, int idx, int n) {
  StkId o;
  lua_lock(L);
  o = index2adr(L, idx);
  api_check(L, ttistable(o));
  setobj2s(L, L->top, luaH_getnum(hvalue(o), n));
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API void lua_createtable (lua_State *L, int narray, int nrec) {
  lua_lock(L);
  luaC_checkGC(L);
  sethvalue(L, L->top, luaH_new(L, narray, nrec));
  api_incr_top(L);
  lua_unlock(L);
}


LUA_API int lua_getmetatable (lua_State *L, int objindex) {
  const TValue *obj;
  Table *mt = NULL;
  int res;
  lua_lock(L);
  obj = index2adr(L, objindex);
  switch (ttype(obj)) {
    case LUA_TTABLE:
      mt = hvalue(obj)->metatable;
      break;
    case LUA_TUSERDATA:
      mt = uvalue(obj)->metatable;
      break;
    default:
      mt = G(L)->mt[ttype(obj)];
      break;
  }
  if (mt == NULL)
    res = 0;
  else {
    sethvalue(L, L->top, mt);
    api_incr_top(L);
    res = 1;
  }
  lua_unlock(L);
  return res;
}


LUA_API void lua_getfenv (lua_State *L, int idx) {
  StkId o;
  lua_lock(L);
  o = index2adr(L, idx);
  api_checkvalidindex(L, o);
  switch (ttype(o)) {
    case LUA_TFUNCTION:
      sethvalue(L, L->top, clvalue(o)->c.env);
      break;
    case LUA_TUSERDATA:
      sethvalue(L, L->top, uvalue(o)->env);
      break;
    case LUA_TTHREAD:
      setobj2s(L, L->top,  gt(thvalue(o)));
      break;
    default:
      setnilvalue(L->top);
      break;
  }
  api_incr_top(L);
  lua_unlock(L);
}


/*
** set functions (stack -> Lua)
*/


LUA_API void lua_settable (lua_State *L, int idx) {
  StkId t;
  lua_lock(L);
  api_checknelems(L, 2);
  t = index2adr(L, idx);
  api_checkvalidindex(L, t);
  luaV_settable(L, t, L->top - 2, L->top - 1);
  L->top -= 2;  /* pop index and value */
  lua_unlock(L);
}


LUA_API void lua_setfield (lua_State *L, int idx, const char *k) {
  StkId t;
  TValue key;
  lua_lock(L);
  api_checknelems(L, 1);
  t = index2adr(L, idx);
  api_checkvalidindex(L, t);
  setsvalue(L, &key, luaS_new(L, k));
  luaV_settable(L, t, &key, L->top - 1);
  L->top--;  /* pop value */
  lua_unlock(L);
}


LUA_API void lua_rawset (lua_State *L, int idx) {
  StkId t;
  lua_lock(L);
  api_checknelems(L, 2);
  t = index2adr(L, idx);
  api_check(L, ttistable(t));
  setobj2t(L, luaH_set(L, hvalue(t), L->top-2), L->top-1);
  luaC_barriert(L, hvalue(t), L->top-1);
  L->top -= 2;
  lua_unlock(L);
}


LUA_API void lua_rawseti (lua_State *L, int idx, int n) {
  StkId o;
  lua_lock(L);
  api_checknelems(L, 1);
  o = index2adr(L, idx);
  api_check(L, ttistable(o));
  setobj2t(L, luaH_setnum(L, hvalue(o), n), L->top-1);
  luaC_barriert(L, hvalue(o), L->top-1);
  L->top--;
  lua_unlock(L);
}


LUA_API int lua_setmetatable (lua_State *L, int objindex) {
  TValue *obj;
  Table *mt;
  lua_lock(L);
  api_checknelems(L, 1);
  obj = index2adr(L, objindex);
  api_checkvalidindex(L, obj);
  if (ttisnil(L->top - 1))
    mt = NULL;
  else {
    api_check(L, ttistable(L->top - 1));
    mt = hvalue(L->top - 1);
  }
  switch (ttype(obj)) {
    case LUA_TTABLE: {
      hvalue(obj)->metatable = mt;
      if (mt)
        luaC_objbarriert(L, hvalue(obj), mt);
      break;
    }
    case LUA_TUSERDATA: {
      uvalue(obj)->metatable = mt;
      if (mt)
        luaC_objbarrier(L, rawuvalue(obj), mt);
      break;
    }
    default: {
      G(L)->mt[ttype(obj)] = mt;
      break;
    }
  }
  L->top--;
  lua_unlock(L);
  return 1;
}


LUA_API int lua_setfenv (lua_State *L, int idx) {
  StkId o;
  int res = 1;
  lua_lock(L);
  api_checknelems(L, 1);
  o = index2adr(L, idx);
  api_checkvalidindex(L, o);
  api_check(L, ttistable(L->top - 1));
  switch (ttype(o)) {
    case LUA_TFUNCTION:
      clvalue(o)->c.env = hvalue(L->top - 1);
      break;
    case LUA_TUSERDATA:
      uvalue(o)->env = hvalue(L->top - 1);
      break;
    case LUA_TTHREAD:
      sethvalue(L, gt(thvalue(o)), hvalue(L->top - 1));
      break;
    default:
      res = 0;
      break;
  }
  luaC_objbarrier(L, gcvalue(o), hvalue(L->top - 1));
  L->top--;
  lua_unlock(L);
  return res;
}


/*
** `load' and `call' functions (run Lua code)
*/


#define adjustresults(L,nres) \
    { if (nres == LUA_MULTRET && L->top >= L->ci->top) L->ci->top = L->top; }


#define checkresults(L,na,nr) \
     api_check(L, (nr) == LUA_MULTRET || (L->ci->top - L->top >= (nr) - (na)))
	

LUA_API void lua_call (lua_State *L, int nargs, int nresults) {
  StkId func;
  lua_lock(L);
  api_checknelems(L, nargs+1);
  checkresults(L, nargs, nresults);
  func = L->top - (nargs+1);
  luaD_call(L, func, nresults);
  adjustresults(L, nresults);
  lua_unlock(L);
}



/*
** Execute a protected call.
*/
struct CallS {  /* data to `f_call' */
  StkId func;
  int nresults;
};


static void f_call (lua_State *L, void *ud) {
  struct CallS *c = cast(struct CallS *, ud);
  luaD_call(L, c->func, c->nresults);
}



LUA_API int lua_pcall (lua_State *L, int nargs, int nresults, int errfunc) {
  struct CallS c;
  int status;
  ptrdiff_t func;
  lua_lock(L);
  api_checknelems(L, nargs+1);
  checkresults(L, nargs, nresults);
  if (errfunc == 0)
    func = 0;
  else {
    StkId o = index2adr(L, errfunc);
    api_checkvalidindex(L, o);
    func = savestack(L, o);
  }
  c.func = L->top - (nargs+1);  /* function to be called */
  c.nresults = nresults;
  status = luaD_pcall(L, f_call, &c, savestack(L, c.func), func);
  adjustresults(L, nresults);
  lua_unlock(L);
  return status;
}


/*
** Execute a protected C call.
*/
struct CCallS {  /* data to `f_Ccall' */
  lua_CFunction func;
  void *ud;
};


static void f_Ccall (lua_State *L, void *ud) {
  struct CCallS *c = cast(struct CCallS *, ud);
  Closure *cl;
  cl = luaF_newCclosure(L, 0, getcurrenv(L));
  cl->c.f = c->func;
  setclvalue(L, L->top, cl);  /* push function */
  api_incr_top(L);
  setpvalue(L->top, c->ud);  /* push only argument */
  api_incr_top(L);
  luaD_call(L, L->top - 2, 0);
}


LUA_API int lua_cpcall (lua_State *L, lua_CFunction func, void *ud) {
  struct CCallS c;
  int status;
  lua_lock(L);
  c.func = func;
  c.ud = ud;
  status = luaD_pcall(L, f_Ccall, &c, savestack(L, L->top), 0);
  lua_unlock(L);
  return status;
}


LUA_API int lua_load (lua_State *L, lua_Reader reader, void *data,
                      const char *chunkname) {
  ZIO z;
  int status;
  lua_lock(L);
  if (!chunkname) chunkname = "?";
  luaZ_init(L, &z, reader, data);
  status = luaD_protectedparser(L, &z, chunkname);
  lua_unlock(L);
  return status;
}


LUA_API int lua_dump (lua_State *L, lua_Writer writer, void *data) {
  int status;
  TValue *o;
  lua_lock(L);
  api_checknelems(L, 1);
  o = L->top - 1;
  if (isLfunction(o))
    status = luaU_dump(L, clvalue(o)->l.p, writer, data, 0);
  else
    status = 1;
  lua_unlock(L);
  return status;
}


LUA_API int  lua_status (lua_State *L) {
  return L->status;
}


/*
** Garbage-collection function
*/

LUA_API int lua_gc (lua_State *L, int what, int data) {
  int res = 0;
  global_State *g;
  lua_lock(L);
  g = G(L);
  switch (what) {
    case LUA_GCSTOP: {
      g->GCthreshold = MAX_LUMEM;
      break;
    }
    case LUA_GCRESTART: {
      g->GCthreshold = g->totalbytes;
      break;
    }
    case LUA_GCCOLLECT: {
      luaC_fullgc(L);
      break;
    }
    case LUA_GCCOUNT: {
      /* GC values are expressed in Kbytes: #bytes/2^10 */
      res = cast_int(g->totalbytes >> 10);
      break;
    }
    case LUA_GCCOUNTB: {
      res = cast_int(g->totalbytes & 0x3ff);
      break;
    }
    case LUA_GCSTEP: {
      lu_mem a = (cast(lu_mem, data) << 10);
      if (a <= g->totalbytes)
        g->GCthreshold = g->totalbytes - a;
      else
        g->GCthreshold = 0;
      while (g->GCthreshold <= g->totalbytes)
        luaC_step(L);
      if (g->gcstate == GCSpause)  /* end of cycle? */
        res = 1;  /* signal it */
      break;
    }
    case LUA_GCSETPAUSE: {
      res = g->gcpause;
      g->gcpause = data;
      break;
    }
    case LUA_GCSETSTEPMUL: {
      res = g->gcstepmul;
      g->gcstepmul = data;
      break;
    }
    default: res = -1;  /* invalid option */
  }
  lua_unlock(L);
  return res;
}



/*
** miscellaneous functions
*/


LUA_API int lua_error (lua_State *L) {
  lua_lock(L);
  api_checknelems(L, 1);
  luaG_errormsg(L);
  lua_unlock(L);
  return 0;  /* to avoid warnings */
}


LUA_API int lua_next (lua_State *L, int idx) {
  StkId t;
  int more;
  lua_lock(L);
  t = index2adr(L, idx);
  api_check(L, ttistable(t));
  more = luaH_next(L, hvalue(t), L->top - 1);
  if (more) {
    api_incr_top(L);
  }
  else  /* no more elements */
    L->top -= 1;  /* remove key */
  lua_unlock(L);
  return more;
}


LUA_API void lua_concat (lua_State *L, int n) {
  lua_lock(L);
  api_checknelems(L, n);
  if (n >= 2) {
    luaC_checkGC(L);
    luaV_concat(L, n, cast_int(L->top - L->base) - 1);
    L->top -= (n-1);
  }
  else if (n == 0) {  /* push empty string */
    setsvalue2s(L, L->top, luaS_newlstr(L, "", 0));
    api_incr_top(L);
  }
  /* else n == 1; nothing to do */
  lua_unlock(L);
}


LUA_API lua_Alloc lua_getallocf (lua_State *L, void **ud) {
  lua_Alloc f;
  lua_lock(L);
  if (ud) *ud = G(L)->ud;
  f = G(L)->frealloc;
  lua_unlock(L);
  return f;
}


LUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud) {
  lua_lock(L);
  G(L)->ud = ud;
  G(L)->frealloc = f;
  lua_unlock(L);
}


LUA_API void *lua_newuserdata (lua_State *L, size_t size) {
  Udata *u;
  lua_lock(L);
  luaC_checkGC(L);
  u = luaS_newudata(L, size, getcurrenv(L));
  setuvalue(L, L->top, u);
  api_incr_top(L);
  lua_unlock(L);
  return u + 1;
}




static const char *aux_upvalue (StkId fi, int n, TValue **val) {
  Closure *f;
  if (!ttisfunction(fi)) return NULL;
  f = clvalue(fi);
  if (f->c.isC) {
    if (!(1 <= n && n <= f->c.nupvalues)) return NULL;
    *val = &f->c.upvalue[n-1];
    return "";
  }
  else {
    Proto *p = f->l.p;
    if (!(1 <= n && n <= p->sizeupvalues)) return NULL;
    *val = f->l.upvals[n-1]->v;
    return getstr(p->upvalues[n-1]);
  }
}


LUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n) {
  const char *name;
  TValue *val;
  lua_lock(L);
  name = aux_upvalue(index2adr(L, funcindex), n, &val);
  if (name) {
    setobj2s(L, L->top, val);
    api_incr_top(L);
  }
  lua_unlock(L);
  return name;
}


LUA_API const char *lua_setupvalue (lua_State *L, int funcindex, int n) {
  const char *name;
  TValue *val;
  StkId fi;
  lua_lock(L);
  fi = index2adr(L, funcindex);
  api_checknelems(L, 1);
  name = aux_upvalue(fi, n, &val);
  if (name) {
    L->top--;
    setobj(L, val, L->top);
    luaC_barrier(L, clvalue(fi), L->top);
  }
  lua_unlock(L);
  return name;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lcode.h ===
/*
** $Id: lcode.h,v 1.48 2006/03/21 19:28:03 roberto Exp $
** Code generator for Lua
** See Copyright Notice in lua.h
*/

#ifndef lcode_h
#define lcode_h

#include "llex.h"
#include "lobject.h"
#include "lopcodes.h"
#include "lparser.h"


/*
** Marks the end of a patch list. It is an invalid value both as an absolute
** address, and as a list link (would link an element to itself).
*/
#define NO_JUMP (-1)


/*
** grep "ORDER OPR" if you change these enums
*/
typedef enum BinOpr {
  OPR_ADD, OPR_SUB, OPR_MUL, OPR_DIV, OPR_MOD, OPR_POW,
  OPR_CONCAT,
  OPR_NE, OPR_EQ,
  OPR_LT, OPR_LE, OPR_GT, OPR_GE,
  OPR_AND, OPR_OR,
  OPR_NOBINOPR
} BinOpr;


typedef enum UnOpr { OPR_MINUS, OPR_NOT, OPR_LEN, OPR_NOUNOPR } UnOpr;


#define getcode(fs,e)	((fs)->f->code[(e)->u.s.info])

#define luaK_codeAsBx(fs,o,A,sBx)	luaK_codeABx(fs,o,A,(sBx)+MAXARG_sBx)

#define luaK_setmultret(fs,e)	luaK_setreturns(fs, e, LUA_MULTRET)

LUAI_FUNC int luaK_codeABx (FuncState *fs, OpCode o, int A, unsigned int Bx);
LUAI_FUNC int luaK_codeABC (FuncState *fs, OpCode o, int A, int B, int C);
LUAI_FUNC void luaK_fixline (FuncState *fs, int line);
LUAI_FUNC void luaK_nil (FuncState *fs, int from, int n);
LUAI_FUNC void luaK_reserveregs (FuncState *fs, int n);
LUAI_FUNC void luaK_checkstack (FuncState *fs, int n);
LUAI_FUNC int luaK_stringK (FuncState *fs, TString *s);
LUAI_FUNC int luaK_numberK (FuncState *fs, lua_Number r);
LUAI_FUNC void luaK_dischargevars (FuncState *fs, expdesc *e);
LUAI_FUNC int luaK_exp2anyreg (FuncState *fs, expdesc *e);
LUAI_FUNC void luaK_exp2nextreg (FuncState *fs, expdesc *e);
LUAI_FUNC void luaK_exp2val (FuncState *fs, expdesc *e);
LUAI_FUNC int luaK_exp2RK (FuncState *fs, expdesc *e);
LUAI_FUNC void luaK_self (FuncState *fs, expdesc *e, expdesc *key);
LUAI_FUNC void luaK_indexed (FuncState *fs, expdesc *t, expdesc *k);
LUAI_FUNC void luaK_goiftrue (FuncState *fs, expdesc *e);
LUAI_FUNC void luaK_storevar (FuncState *fs, expdesc *var, expdesc *e);
LUAI_FUNC void luaK_setreturns (FuncState *fs, expdesc *e, int nresults);
LUAI_FUNC void luaK_setoneret (FuncState *fs, expdesc *e);
LUAI_FUNC int luaK_jump (FuncState *fs);
LUAI_FUNC void luaK_ret (FuncState *fs, int first, int nret);
LUAI_FUNC void luaK_patchlist (FuncState *fs, int list, int target);
LUAI_FUNC void luaK_patchtohere (FuncState *fs, int list);
LUAI_FUNC void luaK_concat (FuncState *fs, int *l1, int l2);
LUAI_FUNC int luaK_getlabel (FuncState *fs);
LUAI_FUNC void luaK_prefix (FuncState *fs, UnOpr op, expdesc *v);
LUAI_FUNC void luaK_infix (FuncState *fs, BinOpr op, expdesc *v);
LUAI_FUNC void luaK_posfix (FuncState *fs, BinOpr op, expdesc *v1, expdesc *v2);
LUAI_FUNC void luaK_setlist (FuncState *fs, int base, int nelems, int tostore);


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lcode.c ===
/*
** $Id: lcode.c,v 2.25 2006/03/21 19:28:49 roberto Exp $
** Code generator for Lua
** See Copyright Notice in lua.h
*/


#include <stdlib.h>

#define lcode_c
#define LUA_CORE

#include "lua.h"

#include "lcode.h"
#include "ldebug.h"
#include "ldo.h"
#include "lgc.h"
#include "llex.h"
#include "lmem.h"
#include "lobject.h"
#include "lopcodes.h"
#include "lparser.h"
#include "ltable.h"


#define hasjumps(e) ((e)->t != (e)->f)


static int isnumeral(expdesc *e) {
  return (e->k == VKNUM && e->t == NO_JUMP && e->f == NO_JUMP);
}


void luaK_nil (FuncState *fs, int from, int n) {
  Instruction *previous;
  if (fs->pc > fs->lasttarget) {  /* no jumps to current position? */
    if (fs->pc == 0)  /* function start? */
      return;  /* positions are already clean */
    if (GET_OPCODE(*(previous = &fs->f->code[fs->pc-1])) == OP_LOADNIL) {
      int pfrom = GETARG_A(*previous);
      int pto = GETARG_B(*previous);
      if (pfrom <= from && from <= pto+1) {  /* can connect both? */
        if (from+n-1 > pto)
          SETARG_B(*previous, from+n-1);
        return;
      }
    }
  }
  luaK_codeABC(fs, OP_LOADNIL, from, from+n-1, 0);  /* else no optimization */
}


int luaK_jump (FuncState *fs) {
  int jpc = fs->jpc;  /* save list of jumps to here */
  int j;
  fs->jpc = NO_JUMP;
  j = luaK_codeAsBx(fs, OP_JMP, 0, NO_JUMP);
  luaK_concat(fs, &j, jpc);  /* keep them on hold */
  return j;
}


void luaK_ret (FuncState *fs, int first, int nret) {
  luaK_codeABC(fs, OP_RETURN, first, nret+1, 0);
}


static int condjump (FuncState *fs, OpCode op, int A, int B, int C) {
  luaK_codeABC(fs, op, A, B, C);
  return luaK_jump(fs);
}


static void fixjump (FuncState *fs, int pc, int dest) {
  Instruction *jmp = &fs->f->code[pc];
  int offset = dest-(pc+1);
  lua_assert(dest != NO_JUMP);
  if (abs(offset) > MAXARG_sBx)
    luaX_syntaxerror(fs->ls, "control structure too long");
  SETARG_sBx(*jmp, offset);
}


/*
** returns current `pc' and marks it as a jump target (to avoid wrong
** optimizations with consecutive instructions not in the same basic block).
*/
int luaK_getlabel (FuncState *fs) {
  fs->lasttarget = fs->pc;
  return fs->pc;
}


static int getjump (FuncState *fs, int pc) {
  int offset = GETARG_sBx(fs->f->code[pc]);
  if (offset == NO_JUMP)  /* point to itself represents end of list */
    return NO_JUMP;  /* end of list */
  else
    return (pc+1)+offset;  /* turn offset into absolute position */
}


static Instruction *getjumpcontrol (FuncState *fs, int pc) {
  Instruction *pi = &fs->f->code[pc];
  if (pc >= 1 && testTMode(GET_OPCODE(*(pi-1))))
    return pi-1;
  else
    return pi;
}


/*
** check whether list has any jump that do not produce a value
** (or produce an inverted value)
*/
static int need_value (FuncState *fs, int list) {
  for (; list != NO_JUMP; list = getjump(fs, list)) {
    Instruction i = *getjumpcontrol(fs, list);
    if (GET_OPCODE(i) != OP_TESTSET) return 1;
  }
  return 0;  /* not found */
}


static int patchtestreg (FuncState *fs, int node, int reg) {
  Instruction *i = getjumpcontrol(fs, node);
  if (GET_OPCODE(*i) != OP_TESTSET)
    return 0;  /* cannot patch other instructions */
  if (reg != NO_REG && reg != GETARG_B(*i))
    SETARG_A(*i, reg);
  else  /* no register to put value or register already has the value */
    *i = CREATE_ABC(OP_TEST, GETARG_B(*i), 0, GETARG_C(*i));

  return 1;
}


static void removevalues (FuncState *fs, int list) {
  for (; list != NO_JUMP; list = getjump(fs, list))
      patchtestreg(fs, list, NO_REG);
}


static void patchlistaux (FuncState *fs, int list, int vtarget, int reg,
                          int dtarget) {
  while (list != NO_JUMP) {
    int next = getjump(fs, list);
    if (patchtestreg(fs, list, reg))
      fixjump(fs, list, vtarget);
    else
      fixjump(fs, list, dtarget);  /* jump to default target */
    list = next;
  }
}


static void dischargejpc (FuncState *fs) {
  patchlistaux(fs, fs->jpc, fs->pc, NO_REG, fs->pc);
  fs->jpc = NO_JUMP;
}


void luaK_patchlist (FuncState *fs, int list, int target) {
  if (target == fs->pc)
    luaK_patchtohere(fs, list);
  else {
    lua_assert(target < fs->pc);
    patchlistaux(fs, list, target, NO_REG, target);
  }
}


void luaK_patchtohere (FuncState *fs, int list) {
  luaK_getlabel(fs);
  luaK_concat(fs, &fs->jpc, list);
}


void luaK_concat (FuncState *fs, int *l1, int l2) {
  if (l2 == NO_JUMP) return;
  else if (*l1 == NO_JUMP)
    *l1 = l2;
  else {
    int list = *l1;
    int next;
    while ((next = getjump(fs, list)) != NO_JUMP)  /* find last element */
      list = next;
    fixjump(fs, list, l2);
  }
}


void luaK_checkstack (FuncState *fs, int n) {
  int newstack = fs->freereg + n;
  if (newstack > fs->f->maxstacksize) {
    if (newstack >= MAXSTACK)
      luaX_syntaxerror(fs->ls, "function or expression too complex");
    fs->f->maxstacksize = cast_byte(newstack);
  }
}


void luaK_reserveregs (FuncState *fs, int n) {
  luaK_checkstack(fs, n);
  fs->freereg += n;
}


static void freereg (FuncState *fs, int reg) {
  if (!ISK(reg) && reg >= fs->nactvar) {
    fs->freereg--;
    lua_assert(reg == fs->freereg);
  }
}


static void freeexp (FuncState *fs, expdesc *e) {
  if (e->k == VNONRELOC)
    freereg(fs, e->u.s.info);
}


static int addk (FuncState *fs, TValue *k, TValue *v) {
  lua_State *L = fs->L;
  TValue *idx = luaH_set(L, fs->h, k);
  Proto *f = fs->f;
  int oldsize = f->sizek;
  if (ttisnumber(idx)) {
    lua_assert(luaO_rawequalObj(&fs->f->k[cast_int(nvalue(idx))], v));
    return cast_int(nvalue(idx));
  }
  else {  /* constant not found; create a new entry */
    setnvalue(idx, cast_num(fs->nk));
    luaM_growvector(L, f->k, fs->nk, f->sizek, TValue,
                    MAXARG_Bx, "constant table overflow");
    while (oldsize < f->sizek) setnilvalue(&f->k[oldsize++]);
    setobj(L, &f->k[fs->nk], v);
    luaC_barrier(L, f, v);
    return fs->nk++;
  }
}


int luaK_stringK (FuncState *fs, TString *s) {
  TValue o;
  setsvalue(fs->L, &o, s);
  return addk(fs, &o, &o);
}


int luaK_numberK (FuncState *fs, lua_Number r) {
  TValue o;
  setnvalue(&o, r);
  return addk(fs, &o, &o);
}


static int boolK (FuncState *fs, int b) {
  TValue o;
  setbvalue(&o, b);
  return addk(fs, &o, &o);
}


static int nilK (FuncState *fs) {
  TValue k, v;
  setnilvalue(&v);
  /* cannot use nil as key; instead use table itself to represent nil */
  sethvalue(fs->L, &k, fs->h);
  return addk(fs, &k, &v);
}


void luaK_setreturns (FuncState *fs, expdesc *e, int nresults) {
  if (e->k == VCALL) {  /* expression is an open function call? */
    SETARG_C(getcode(fs, e), nresults+1);
  }
  else if (e->k == VVARARG) {
    SETARG_B(getcode(fs, e), nresults+1);
    SETARG_A(getcode(fs, e), fs->freereg);
    luaK_reserveregs(fs, 1);
  }
}


void luaK_setoneret (FuncState *fs, expdesc *e) {
  if (e->k == VCALL) {  /* expression is an open function call? */
    e->k = VNONRELOC;
    e->u.s.info = GETARG_A(getcode(fs, e));
  }
  else if (e->k == VVARARG) {
    SETARG_B(getcode(fs, e), 2);
    e->k = VRELOCABLE;  /* can relocate its simple result */
  }
}


void luaK_dischargevars (FuncState *fs, expdesc *e) {
  switch (e->k) {
    case VLOCAL: {
      e->k = VNONRELOC;
      break;
    }
    case VUPVAL: {
      e->u.s.info = luaK_codeABC(fs, OP_GETUPVAL, 0, e->u.s.info, 0);
      e->k = VRELOCABLE;
      break;
    }
    case VGLOBAL: {
      e->u.s.info = luaK_codeABx(fs, OP_GETGLOBAL, 0, e->u.s.info);
      e->k = VRELOCABLE;
      break;
    }
    case VINDEXED: {
      freereg(fs, e->u.s.aux);
      freereg(fs, e->u.s.info);
      e->u.s.info = luaK_codeABC(fs, OP_GETTABLE, 0, e->u.s.info, e->u.s.aux);
      e->k = VRELOCABLE;
      break;
    }
    case VVARARG:
    case VCALL: {
      luaK_setoneret(fs, e);
      break;
    }
    default: break;  /* there is one value available (somewhere) */
  }
}


static int code_label (FuncState *fs, int A, int b, int jump) {
  luaK_getlabel(fs);  /* those instructions may be jump targets */
  return luaK_codeABC(fs, OP_LOADBOOL, A, b, jump);
}


static void discharge2reg (FuncState *fs, expdesc *e, int reg) {
  luaK_dischargevars(fs, e);
  switch (e->k) {
    case VNIL: {
      luaK_nil(fs, reg, 1);
      break;
    }
    case VFALSE:  case VTRUE: {
      luaK_codeABC(fs, OP_LOADBOOL, reg, e->k == VTRUE, 0);
      break;
    }
    case VK: {
      luaK_codeABx(fs, OP_LOADK, reg, e->u.s.info);
      break;
    }
    case VKNUM: {
      luaK_codeABx(fs, OP_LOADK, reg, luaK_numberK(fs, e->u.nval));
      break;
    }
    case VRELOCABLE: {
      Instruction *pc = &getcode(fs, e);
      SETARG_A(*pc, reg);
      break;
    }
    case VNONRELOC: {
      if (reg != e->u.s.info)
        luaK_codeABC(fs, OP_MOVE, reg, e->u.s.info, 0);
      break;
    }
    default: {
      lua_assert(e->k == VVOID || e->k == VJMP);
      return;  /* nothing to do... */
    }
  }
  e->u.s.info = reg;
  e->k = VNONRELOC;
}


static void discharge2anyreg (FuncState *fs, expdesc *e) {
  if (e->k != VNONRELOC) {
    luaK_reserveregs(fs, 1);
    discharge2reg(fs, e, fs->freereg-1);
  }
}


static void exp2reg (FuncState *fs, expdesc *e, int reg) {
  discharge2reg(fs, e, reg);
  if (e->k == VJMP)
    luaK_concat(fs, &e->t, e->u.s.info);  /* put this jump in `t' list */
  if (hasjumps(e)) {
    int final;  /* position after whole expression */
    int p_f = NO_JUMP;  /* position of an eventual LOAD false */
    int p_t = NO_JUMP;  /* position of an eventual LOAD true */
    if (need_value(fs, e->t) || need_value(fs, e->f)) {
      int fj = (e->k == VJMP) ? NO_JUMP : luaK_jump(fs);
      p_f = code_label(fs, reg, 0, 1);
      p_t = code_label(fs, reg, 1, 0);
      luaK_patchtohere(fs, fj);
    }
    final = luaK_getlabel(fs);
    patchlistaux(fs, e->f, final, reg, p_f);
    patchlistaux(fs, e->t, final, reg, p_t);
  }
  e->f = e->t = NO_JUMP;
  e->u.s.info = reg;
  e->k = VNONRELOC;
}


void luaK_exp2nextreg (FuncState *fs, expdesc *e) {
  luaK_dischargevars(fs, e);
  freeexp(fs, e);
  luaK_reserveregs(fs, 1);
  exp2reg(fs, e, fs->freereg - 1);
}


int luaK_exp2anyreg (FuncState *fs, expdesc *e) {
  luaK_dischargevars(fs, e);
  if (e->k == VNONRELOC) {
    if (!hasjumps(e)) return e->u.s.info;  /* exp is already in a register */
    if (e->u.s.info >= fs->nactvar) {  /* reg. is not a local? */
      exp2reg(fs, e, e->u.s.info);  /* put value on it */
      return e->u.s.info;
    }
  }
  luaK_exp2nextreg(fs, e);  /* default */
  return e->u.s.info;
}


void luaK_exp2val (FuncState *fs, expdesc *e) {
  if (hasjumps(e))
    luaK_exp2anyreg(fs, e);
  else
    luaK_dischargevars(fs, e);
}


int luaK_exp2RK (FuncState *fs, expdesc *e) {
  luaK_exp2val(fs, e);
  switch (e->k) {
    case VKNUM:
    case VTRUE:
    case VFALSE:
    case VNIL: {
      if (fs->nk <= MAXINDEXRK) {  /* constant fit in RK operand? */
        e->u.s.info = (e->k == VNIL)  ? nilK(fs) :
                      (e->k == VKNUM) ? luaK_numberK(fs, e->u.nval) :
                                        boolK(fs, (e->k == VTRUE));
        e->k = VK;
        return RKASK(e->u.s.info);
      }
      else break;
    }
    case VK: {
      if (e->u.s.info <= MAXINDEXRK)  /* constant fit in argC? */
        return RKASK(e->u.s.info);
      else break;
    }
    default: break;
  }
  /* not a constant in the right range: put it in a register */
  return luaK_exp2anyreg(fs, e);
}


void luaK_storevar (FuncState *fs, expdesc *var, expdesc *ex) {
  switch (var->k) {
    case VLOCAL: {
      freeexp(fs, ex);
      exp2reg(fs, ex, var->u.s.info);
      return;
    }
    case VUPVAL: {
      int e = luaK_exp2anyreg(fs, ex);
      luaK_codeABC(fs, OP_SETUPVAL, e, var->u.s.info, 0);
      break;
    }
    case VGLOBAL: {
      int e = luaK_exp2anyreg(fs, ex);
      luaK_codeABx(fs, OP_SETGLOBAL, e, var->u.s.info);
      break;
    }
    case VINDEXED: {
      int e = luaK_exp2RK(fs, ex);
      luaK_codeABC(fs, OP_SETTABLE, var->u.s.info, var->u.s.aux, e);
      break;
    }
    default: {
      lua_assert(0);  /* invalid var kind to store */
      break;
    }
  }
  freeexp(fs, ex);
}


void luaK_self (FuncState *fs, expdesc *e, expdesc *key) {
  int func;
  luaK_exp2anyreg(fs, e);
  freeexp(fs, e);
  func = fs->freereg;
  luaK_reserveregs(fs, 2);
  luaK_codeABC(fs, OP_SELF, func, e->u.s.info, luaK_exp2RK(fs, key));
  freeexp(fs, key);
  e->u.s.info = func;
  e->k = VNONRELOC;
}


static void invertjump (FuncState *fs, expdesc *e) {
  Instruction *pc = getjumpcontrol(fs, e->u.s.info);
  lua_assert(testTMode(GET_OPCODE(*pc)) && GET_OPCODE(*pc) != OP_TESTSET &&
                                           GET_OPCODE(*pc) != OP_TEST);
  SETARG_A(*pc, !(GETARG_A(*pc)));
}


static int jumponcond (FuncState *fs, expdesc *e, int cond) {
  if (e->k == VRELOCABLE) {
    Instruction ie = getcode(fs, e);
    if (GET_OPCODE(ie) == OP_NOT) {
      fs->pc--;  /* remove previous OP_NOT */
      return condjump(fs, OP_TEST, GETARG_B(ie), 0, !cond);
    }
    /* else go through */
  }
  discharge2anyreg(fs, e);
  freeexp(fs, e);
  return condjump(fs, OP_TESTSET, NO_REG, e->u.s.info, cond);
}


void luaK_goiftrue (FuncState *fs, expdesc *e) {
  int pc;  /* pc of last jump */
  luaK_dischargevars(fs, e);
  switch (e->k) {
    case VK: case VKNUM: case VTRUE: {
      pc = NO_JUMP;  /* always true; do nothing */
      break;
    }
    case VFALSE: {
      pc = luaK_jump(fs);  /* always jump */
      break;
    }
    case VJMP: {
      invertjump(fs, e);
      pc = e->u.s.info;
      break;
    }
    default: {
      pc = jumponcond(fs, e, 0);
      break;
    }
  }
  luaK_concat(fs, &e->f, pc);  /* insert last jump in `f' list */
  luaK_patchtohere(fs, e->t);
  e->t = NO_JUMP;
}


static void luaK_goiffalse (FuncState *fs, expdesc *e) {
  int pc;  /* pc of last jump */
  luaK_dischargevars(fs, e);
  switch (e->k) {
    case VNIL: case VFALSE: {
      pc = NO_JUMP;  /* always false; do nothing */
      break;
    }
    case VTRUE: {
      pc = luaK_jump(fs);  /* always jump */
      break;
    }
    case VJMP: {
      pc = e->u.s.info;
      break;
    }
    default: {
      pc = jumponcond(fs, e, 1);
      break;
    }
  }
  luaK_concat(fs, &e->t, pc);  /* insert last jump in `t' list */
  luaK_patchtohere(fs, e->f);
  e->f = NO_JUMP;
}


static void codenot (FuncState *fs, expdesc *e) {
  luaK_dischargevars(fs, e);
  switch (e->k) {
    case VNIL: case VFALSE: {
      e->k = VTRUE;
      break;
    }
    case VK: case VKNUM: case VTRUE: {
      e->k = VFALSE;
      break;
    }
    case VJMP: {
      invertjump(fs, e);
      break;
    }
    case VRELOCABLE:
    case VNONRELOC: {
      discharge2anyreg(fs, e);
      freeexp(fs, e);
      e->u.s.info = luaK_codeABC(fs, OP_NOT, 0, e->u.s.info, 0);
      e->k = VRELOCABLE;
      break;
    }
    default: {
      lua_assert(0);  /* cannot happen */
      break;
    }
  }
  /* interchange true and false lists */
  { int temp = e->f; e->f = e->t; e->t = temp; }
  removevalues(fs, e->f);
  removevalues(fs, e->t);
}


void luaK_indexed (FuncState *fs, expdesc *t, expdesc *k) {
  t->u.s.aux = luaK_exp2RK(fs, k);
  t->k = VINDEXED;
}


static int constfolding (OpCode op, expdesc *e1, expdesc *e2) {
  lua_Number v1, v2, r;
  if (!isnumeral(e1) || !isnumeral(e2)) return 0;
  v1 = e1->u.nval;
  v2 = e2->u.nval;
  switch (op) {
    case OP_ADD: r = luai_numadd(v1, v2); break;
    case OP_SUB: r = luai_numsub(v1, v2); break;
    case OP_MUL: r = luai_nummul(v1, v2); break;
    case OP_DIV:
      if (v2 == 0) return 0;  /* do not attempt to divide by 0 */
      r = luai_numdiv(v1, v2); break;
    case OP_MOD:
      if (v2 == 0) return 0;  /* do not attempt to divide by 0 */
      r = luai_nummod(v1, v2); break;
    case OP_POW: r = luai_numpow(v1, v2); break;
    case OP_UNM: r = luai_numunm(v1); break;
    case OP_LEN: return 0;  /* no constant folding for 'len' */
    default: lua_assert(0); r = 0; break;
  }
  if (luai_numisnan(r)) return 0;  /* do not attempt to produce NaN */
  e1->u.nval = r;
  return 1;
}


static void codearith (FuncState *fs, OpCode op, expdesc *e1, expdesc *e2) {
  if (constfolding(op, e1, e2))
    return;
  else {
    int o2 = (op != OP_UNM && op != OP_LEN) ? luaK_exp2RK(fs, e2) : 0;
    int o1 = luaK_exp2RK(fs, e1);
    if (o1 > o2) {
      freeexp(fs, e1);
      freeexp(fs, e2);
    }
    else {
      freeexp(fs, e2);
      freeexp(fs, e1);
    }
    e1->u.s.info = luaK_codeABC(fs, op, 0, o1, o2);
    e1->k = VRELOCABLE;
  }
}


static void codecomp (FuncState *fs, OpCode op, int cond, expdesc *e1,
                                                          expdesc *e2) {
  int o1 = luaK_exp2RK(fs, e1);
  int o2 = luaK_exp2RK(fs, e2);
  freeexp(fs, e2);
  freeexp(fs, e1);
  if (cond == 0 && op != OP_EQ) {
    int temp;  /* exchange args to replace by `<' or `<=' */
    temp = o1; o1 = o2; o2 = temp;  /* o1 <==> o2 */
    cond = 1;
  }
  e1->u.s.info = condjump(fs, op, cond, o1, o2);
  e1->k = VJMP;
}


void luaK_prefix (FuncState *fs, UnOpr op, expdesc *e) {
  expdesc e2;
  e2.t = e2.f = NO_JUMP; e2.k = VKNUM; e2.u.nval = 0;
  switch (op) {
    case OPR_MINUS: {
      if (!isnumeral(e))
        luaK_exp2anyreg(fs, e);  /* cannot operate on non-numeric constants */
      codearith(fs, OP_UNM, e, &e2);
      break;
    }
    case OPR_NOT: codenot(fs, e); break;
    case OPR_LEN: {
      luaK_exp2anyreg(fs, e);  /* cannot operate on constants */
      codearith(fs, OP_LEN, e, &e2);
      break;
    }
    default: lua_assert(0);
  }
}


void luaK_infix (FuncState *fs, BinOpr op, expdesc *v) {
  switch (op) {
    case OPR_AND: {
      luaK_goiftrue(fs, v);
      break;
    }
    case OPR_OR: {
      luaK_goiffalse(fs, v);
      break;
    }
    case OPR_CONCAT: {
      luaK_exp2nextreg(fs, v);  /* operand must be on the `stack' */
      break;
    }
    case OPR_ADD: case OPR_SUB: case OPR_MUL: case OPR_DIV:
    case OPR_MOD: case OPR_POW: {
      if (!isnumeral(v)) luaK_exp2RK(fs, v);
      break;
    }
    default: {
      luaK_exp2RK(fs, v);
      break;
    }
  }
}


void luaK_posfix (FuncState *fs, BinOpr op, expdesc *e1, expdesc *e2) {
  switch (op) {
    case OPR_AND: {
      lua_assert(e1->t == NO_JUMP);  /* list must be closed */
      luaK_dischargevars(fs, e2);
      luaK_concat(fs, &e2->f, e1->f);
      *e1 = *e2;
      break;
    }
    case OPR_OR: {
      lua_assert(e1->f == NO_JUMP);  /* list must be closed */
      luaK_dischargevars(fs, e2);
      luaK_concat(fs, &e2->t, e1->t);
      *e1 = *e2;
      break;
    }
    case OPR_CONCAT: {
      luaK_exp2val(fs, e2);
      if (e2->k == VRELOCABLE && GET_OPCODE(getcode(fs, e2)) == OP_CONCAT) {
        lua_assert(e1->u.s.info == GETARG_B(getcode(fs, e2))-1);
        freeexp(fs, e1);
        SETARG_B(getcode(fs, e2), e1->u.s.info);
        e1->k = VRELOCABLE; e1->u.s.info = e2->u.s.info;
      }
      else {
        luaK_exp2nextreg(fs, e2);  /* operand must be on the 'stack' */
        codearith(fs, OP_CONCAT, e1, e2);
      }
      break;
    }
    case OPR_ADD: codearith(fs, OP_ADD, e1, e2); break;
    case OPR_SUB: codearith(fs, OP_SUB, e1, e2); break;
    case OPR_MUL: codearith(fs, OP_MUL, e1, e2); break;
    case OPR_DIV: codearith(fs, OP_DIV, e1, e2); break;
    case OPR_MOD: codearith(fs, OP_MOD, e1, e2); break;
    case OPR_POW: codearith(fs, OP_POW, e1, e2); break;
    case OPR_EQ: codecomp(fs, OP_EQ, 1, e1, e2); break;
    case OPR_NE: codecomp(fs, OP_EQ, 0, e1, e2); break;
    case OPR_LT: codecomp(fs, OP_LT, 1, e1, e2); break;
    case OPR_LE: codecomp(fs, OP_LE, 1, e1, e2); break;
    case OPR_GT: codecomp(fs, OP_LT, 0, e1, e2); break;
    case OPR_GE: codecomp(fs, OP_LE, 0, e1, e2); break;
    default: lua_assert(0);
  }
}


void luaK_fixline (FuncState *fs, int line) {
  fs->f->lineinfo[fs->pc - 1] = line;
}


static int luaK_code (FuncState *fs, Instruction i, int line) {
  Proto *f = fs->f;
  dischargejpc(fs);  /* `pc' will change */
  /* put new instruction in code array */
  luaM_growvector(fs->L, f->code, fs->pc, f->sizecode, Instruction,
                  MAX_INT, "code size overflow");
  f->code[fs->pc] = i;
  /* save corresponding line information */
  luaM_growvector(fs->L, f->lineinfo, fs->pc, f->sizelineinfo, int,
                  MAX_INT, "code size overflow");
  f->lineinfo[fs->pc] = line;
  return fs->pc++;
}


int luaK_codeABC (FuncState *fs, OpCode o, int a, int b, int c) {
  lua_assert(getOpMode(o) == iABC);
  lua_assert(getBMode(o) != OpArgN || b == 0);
  lua_assert(getCMode(o) != OpArgN || c == 0);
  return luaK_code(fs, CREATE_ABC(o, a, b, c), fs->ls->lastline);
}


int luaK_codeABx (FuncState *fs, OpCode o, int a, unsigned int bc) {
  lua_assert(getOpMode(o) == iABx || getOpMode(o) == iAsBx);
  lua_assert(getCMode(o) == OpArgN);
  return luaK_code(fs, CREATE_ABx(o, a, bc), fs->ls->lastline);
}


void luaK_setlist (FuncState *fs, int base, int nelems, int tostore) {
  int c =  (nelems - 1)/LFIELDS_PER_FLUSH + 1;
  int b = (tostore == LUA_MULTRET) ? 0 : tostore;
  lua_assert(tostore != 0);
  if (c <= MAXARG_C)
    luaK_codeABC(fs, OP_SETLIST, base, b, c);
  else {
    luaK_codeABC(fs, OP_SETLIST, base, b, 0);
    luaK_code(fs, cast(Instruction, c), fs->ls->lastline);
  }
  fs->freereg = base + 1;  /* free registers with list values */
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lauxlib.h ===
/*
** $Id: lauxlib.h,v 1.88 2006/04/12 20:31:15 roberto Exp $
** Auxiliary functions for building Lua libraries
** See Copyright Notice in lua.h
*/


#ifndef lauxlib_h
#define lauxlib_h


#include <stddef.h>
#include <stdio.h>

#include "lua.h"


#if defined(LUA_COMPAT_GETN)
LUALIB_API int (luaL_getn) (lua_State *L, int t);
LUALIB_API void (luaL_setn) (lua_State *L, int t, int n);
#else
#define luaL_getn(L,i)          ((int)lua_objlen(L, i))
#define luaL_setn(L,i,j)        ((void)0)  /* no op! */
#endif

#if defined(LUA_COMPAT_OPENLIB)
#define luaI_openlib	luaL_openlib
#endif


/* extra error code for `luaL_load' */
#define LUA_ERRFILE     (LUA_ERRERR+1)


typedef struct luaL_Reg {
  const char *name;
  lua_CFunction func;
} luaL_Reg;



LUALIB_API void (luaI_openlib) (lua_State *L, const char *libname,
                                const luaL_Reg *l, int nup);
LUALIB_API void (luaL_register) (lua_State *L, const char *libname,
                                const luaL_Reg *l);
LUALIB_API int (luaL_getmetafield) (lua_State *L, int obj, const char *e);
LUALIB_API int (luaL_callmeta) (lua_State *L, int obj, const char *e);
LUALIB_API int (luaL_typerror) (lua_State *L, int narg, const char *tname);
LUALIB_API int (luaL_argerror) (lua_State *L, int numarg, const char *extramsg);
LUALIB_API const char *(luaL_checklstring) (lua_State *L, int numArg,
                                                          size_t *l);
LUALIB_API const char *(luaL_optlstring) (lua_State *L, int numArg,
                                          const char *def, size_t *l);
LUALIB_API lua_Number (luaL_checknumber) (lua_State *L, int numArg);
LUALIB_API lua_Number (luaL_optnumber) (lua_State *L, int nArg, lua_Number def);

LUALIB_API lua_Integer (luaL_checkinteger) (lua_State *L, int numArg);
LUALIB_API lua_Integer (luaL_optinteger) (lua_State *L, int nArg,
                                          lua_Integer def);

LUALIB_API void (luaL_checkstack) (lua_State *L, int sz, const char *msg);
LUALIB_API void (luaL_checktype) (lua_State *L, int narg, int t);
LUALIB_API void (luaL_checkany) (lua_State *L, int narg);

LUALIB_API int   (luaL_newmetatable) (lua_State *L, const char *tname);
LUALIB_API void *(luaL_checkudata) (lua_State *L, int ud, const char *tname);

LUALIB_API void (luaL_where) (lua_State *L, int lvl);
LUALIB_API int (luaL_error) (lua_State *L, const char *fmt, ...);

LUALIB_API int (luaL_checkoption) (lua_State *L, int narg, const char *def,
                                   const char *const lst[]);

LUALIB_API int (luaL_ref) (lua_State *L, int t);
LUALIB_API void (luaL_unref) (lua_State *L, int t, int ref);

LUALIB_API int (luaL_loadfile) (lua_State *L, const char *filename);
LUALIB_API int (luaL_loadbuffer) (lua_State *L, const char *buff, size_t sz,
                                  const char *name);
LUALIB_API int (luaL_loadstring) (lua_State *L, const char *s);

LUALIB_API lua_State *(luaL_newstate) (void);


LUALIB_API const char *(luaL_gsub) (lua_State *L, const char *s, const char *p,
                                                  const char *r);

LUALIB_API const char *(luaL_findtable) (lua_State *L, int idx,
                                         const char *fname, int szhint);




/*
** ===============================================================
** some useful macros
** ===============================================================
*/

#define luaL_argcheck(L, cond,numarg,extramsg)	\
		((void)((cond) || luaL_argerror(L, (numarg), (extramsg))))
#define luaL_checkstring(L,n)	(luaL_checklstring(L, (n), NULL))
#define luaL_optstring(L,n,d)	(luaL_optlstring(L, (n), (d), NULL))
#define luaL_checkint(L,n)	((int)luaL_checkinteger(L, (n)))
#define luaL_optint(L,n,d)	((int)luaL_optinteger(L, (n), (d)))
#define luaL_checklong(L,n)	((long)luaL_checkinteger(L, (n)))
#define luaL_optlong(L,n,d)	((long)luaL_optinteger(L, (n), (d)))

#define luaL_typename(L,i)	lua_typename(L, lua_type(L,(i)))

#define luaL_dofile(L, fn) \
	(luaL_loadfile(L, fn) || lua_pcall(L, 0, LUA_MULTRET, 0))

#define luaL_dostring(L, s) \
	(luaL_loadstring(L, s) || lua_pcall(L, 0, LUA_MULTRET, 0))

#define luaL_getmetatable(L,n)	(lua_getfield(L, LUA_REGISTRYINDEX, (n)))

#define luaL_opt(L,f,n,d)	(lua_isnoneornil(L,(n)) ? (d) : f(L,(n)))

/*
** {======================================================
** Generic Buffer manipulation
** =======================================================
*/



typedef struct luaL_Buffer {
  char *p;			/* current position in buffer */
  int lvl;  /* number of strings in the stack (level) */
  lua_State *L;
  char buffer[LUAL_BUFFERSIZE];
} luaL_Buffer;

#define luaL_addchar(B,c) \
  ((void)((B)->p < ((B)->buffer+LUAL_BUFFERSIZE) || luaL_prepbuffer(B)), \
   (*(B)->p++ = (char)(c)))

/* compatibility only */
#define luaL_putchar(B,c)	luaL_addchar(B,c)

#define luaL_addsize(B,n)	((B)->p += (n))

LUALIB_API void (luaL_buffinit) (lua_State *L, luaL_Buffer *B);
LUALIB_API char *(luaL_prepbuffer) (luaL_Buffer *B);
LUALIB_API void (luaL_addlstring) (luaL_Buffer *B, const char *s, size_t l);
LUALIB_API void (luaL_addstring) (luaL_Buffer *B, const char *s);
LUALIB_API void (luaL_addvalue) (luaL_Buffer *B);
LUALIB_API void (luaL_pushresult) (luaL_Buffer *B);


/* }====================================================== */


/* compatibility with ref system */

/* pre-defined references */
#define LUA_NOREF       (-2)
#define LUA_REFNIL      (-1)

#define lua_ref(L,lock) ((lock) ? luaL_ref(L, LUA_REGISTRYINDEX) : \
      (lua_pushstring(L, "unlocked references are obsolete"), lua_error(L), 0))

#define lua_unref(L,ref)        luaL_unref(L, LUA_REGISTRYINDEX, (ref))

#define lua_getref(L,ref)       lua_rawgeti(L, LUA_REGISTRYINDEX, (ref))


#define luaL_reg	luaL_Reg

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lauxlib.c ===
/*
** $Id: lauxlib.c,v 1.159 2006/03/21 19:31:09 roberto Exp $
** Auxiliary functions for building Lua libraries
** See Copyright Notice in lua.h
*/


#include <ctype.h>
#include <errno.h>
#include <stdarg.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>


/* This file uses only the official API of Lua.
** Any function declared here could be written as an application function.
*/

#define lauxlib_c
#define LUA_LIB

#include "lua.h"

#include "lauxlib.h"


#define FREELIST_REF	0	/* free list of references */


/* convert a stack index to positive */
#define abs_index(L, i)		((i) > 0 || (i) <= LUA_REGISTRYINDEX ? (i) : \
					lua_gettop(L) + (i) + 1)


/*
** {======================================================
** Error-report functions
** =======================================================
*/


LUALIB_API int luaL_argerror (lua_State *L, int narg, const char *extramsg) {
  lua_Debug ar;
  if (!lua_getstack(L, 0, &ar))  /* no stack frame? */
    return luaL_error(L, "bad argument #%d (%s)", narg, extramsg);
  lua_getinfo(L, "n", &ar);
  if (strcmp(ar.namewhat, "method") == 0) {
    narg--;  /* do not count `self' */
    if (narg == 0)  /* error is in the self argument itself? */
      return luaL_error(L, "calling " LUA_QS " on bad self (%s)",
                           ar.name, extramsg);
  }
  if (ar.name == NULL)
    ar.name = "?";
  return luaL_error(L, "bad argument #%d to " LUA_QS " (%s)",
                        narg, ar.name, extramsg);
}


LUALIB_API int luaL_typerror (lua_State *L, int narg, const char *tname) {
  const char *msg = lua_pushfstring(L, "%s expected, got %s",
                                    tname, luaL_typename(L, narg));
  return luaL_argerror(L, narg, msg);
}


static void tag_error (lua_State *L, int narg, int tag) {
  luaL_typerror(L, narg, lua_typename(L, tag));
}


LUALIB_API void luaL_where (lua_State *L, int level) {
  lua_Debug ar;
  if (lua_getstack(L, level, &ar)) {  /* check function at level */
    lua_getinfo(L, "Sl", &ar);  /* get info about it */
    if (ar.currentline > 0) {  /* is there info? */
      lua_pushfstring(L, "%s:%d: ", ar.short_src, ar.currentline);
      return;
    }
  }
  lua_pushliteral(L, "");  /* else, no information available... */
}


LUALIB_API int luaL_error (lua_State *L, const char *fmt, ...) {
  va_list argp;
  va_start(argp, fmt);
  luaL_where(L, 1);
  lua_pushvfstring(L, fmt, argp);
  va_end(argp);
  lua_concat(L, 2);
  return lua_error(L);
}

/* }====================================================== */


LUALIB_API int luaL_checkoption (lua_State *L, int narg, const char *def,
                                 const char *const lst[]) {
  const char *name = (def) ? luaL_optstring(L, narg, def) :
                             luaL_checkstring(L, narg);
  int i;
  for (i=0; lst[i]; i++)
    if (strcmp(lst[i], name) == 0)
      return i;
  return luaL_argerror(L, narg,
                       lua_pushfstring(L, "invalid option " LUA_QS, name));
}


LUALIB_API int luaL_newmetatable (lua_State *L, const char *tname) {
  lua_getfield(L, LUA_REGISTRYINDEX, tname);  /* get registry.name */
  if (!lua_isnil(L, -1))  /* name already in use? */
    return 0;  /* leave previous value on top, but return 0 */
  lua_pop(L, 1);
  lua_newtable(L);  /* create metatable */
  lua_pushvalue(L, -1);
  lua_setfield(L, LUA_REGISTRYINDEX, tname);  /* registry.name = metatable */
  return 1;
}


LUALIB_API void *luaL_checkudata (lua_State *L, int ud, const char *tname) {
  void *p = lua_touserdata(L, ud);
  if (p != NULL) {  /* value is a userdata? */
    if (lua_getmetatable(L, ud)) {  /* does it have a metatable? */
      lua_getfield(L, LUA_REGISTRYINDEX, tname);  /* get correct metatable */
      if (lua_rawequal(L, -1, -2)) {  /* does it have the correct mt? */
        lua_pop(L, 2);  /* remove both metatables */
        return p;
      }
    }
  }
  luaL_typerror(L, ud, tname);  /* else error */
  return NULL;  /* to avoid warnings */
}


LUALIB_API void luaL_checkstack (lua_State *L, int space, const char *mes) {
  if (!lua_checkstack(L, space))
    luaL_error(L, "stack overflow (%s)", mes);
}


LUALIB_API void luaL_checktype (lua_State *L, int narg, int t) {
  if (lua_type(L, narg) != t)
    tag_error(L, narg, t);
}


LUALIB_API void luaL_checkany (lua_State *L, int narg) {
  if (lua_type(L, narg) == LUA_TNONE)
    luaL_argerror(L, narg, "value expected");
}


LUALIB_API const char *luaL_checklstring (lua_State *L, int narg, size_t *len) {
  const char *s = lua_tolstring(L, narg, len);
  if (!s) tag_error(L, narg, LUA_TSTRING);
  return s;
}


LUALIB_API const char *luaL_optlstring (lua_State *L, int narg,
                                        const char *def, size_t *len) {
  if (lua_isnoneornil(L, narg)) {
    if (len)
      *len = (def ? strlen(def) : 0);
    return def;
  }
  else return luaL_checklstring(L, narg, len);
}


LUALIB_API lua_Number luaL_checknumber (lua_State *L, int narg) {
  lua_Number d = lua_tonumber(L, narg);
  if (d == 0 && !lua_isnumber(L, narg))  /* avoid extra test when d is not 0 */
    tag_error(L, narg, LUA_TNUMBER);
  return d;
}


LUALIB_API lua_Number luaL_optnumber (lua_State *L, int narg, lua_Number def) {
  return luaL_opt(L, luaL_checknumber, narg, def);
}


LUALIB_API lua_Integer luaL_checkinteger (lua_State *L, int narg) {
  lua_Integer d = lua_tointeger(L, narg);
  if (d == 0 && !lua_isnumber(L, narg))  /* avoid extra test when d is not 0 */
    tag_error(L, narg, LUA_TNUMBER);
  return d;
}


LUALIB_API lua_Integer luaL_optinteger (lua_State *L, int narg,
                                                      lua_Integer def) {
  return luaL_opt(L, luaL_checkinteger, narg, def);
}


LUALIB_API int luaL_getmetafield (lua_State *L, int obj, const char *event) {
  if (!lua_getmetatable(L, obj))  /* no metatable? */
    return 0;
  lua_pushstring(L, event);
  lua_rawget(L, -2);
  if (lua_isnil(L, -1)) {
    lua_pop(L, 2);  /* remove metatable and metafield */
    return 0;
  }
  else {
    lua_remove(L, -2);  /* remove only metatable */
    return 1;
  }
}


LUALIB_API int luaL_callmeta (lua_State *L, int obj, const char *event) {
  obj = abs_index(L, obj);
  if (!luaL_getmetafield(L, obj, event))  /* no metafield? */
    return 0;
  lua_pushvalue(L, obj);
  lua_call(L, 1, 1);
  return 1;
}


LUALIB_API void (luaL_register) (lua_State *L, const char *libname,
                                const luaL_Reg *l) {
  luaI_openlib(L, libname, l, 0);
}


static int libsize (const luaL_Reg *l) {
  int size = 0;
  for (; l->name; l++) size++;
  return size;
}


LUALIB_API void luaI_openlib (lua_State *L, const char *libname,
                              const luaL_Reg *l, int nup) {
  if (libname) {
    int size = libsize(l);
    /* check whether lib already exists */
    luaL_findtable(L, LUA_REGISTRYINDEX, "_LOADED", size);
    lua_getfield(L, -1, libname);  /* get _LOADED[libname] */
    if (!lua_istable(L, -1)) {  /* not found? */
      lua_pop(L, 1);  /* remove previous result */
      /* try global variable (and create one if it does not exist) */
      if (luaL_findtable(L, LUA_GLOBALSINDEX, libname, size) != NULL)
        luaL_error(L, "name conflict for module " LUA_QS, libname);
      lua_pushvalue(L, -1);
      lua_setfield(L, -3, libname);  /* _LOADED[libname] = new table */
    }
    lua_remove(L, -2);  /* remove _LOADED table */
    lua_insert(L, -(nup+1));  /* move library table to below upvalues */
  }
  for (; l->name; l++) {
    int i;
    for (i=0; i<nup; i++)  /* copy upvalues to the top */
      lua_pushvalue(L, -nup);
    lua_pushcclosure(L, l->func, nup);
    lua_setfield(L, -(nup+2), l->name);
  }
  lua_pop(L, nup);  /* remove upvalues */
}



/*
** {======================================================
** getn-setn: size for arrays
** =======================================================
*/

#if defined(LUA_COMPAT_GETN)

static int checkint (lua_State *L, int topop) {
  int n = (lua_type(L, -1) == LUA_TNUMBER) ? lua_tointeger(L, -1) : -1;
  lua_pop(L, topop);
  return n;
}


static void getsizes (lua_State *L) {
  lua_getfield(L, LUA_REGISTRYINDEX, "LUA_SIZES");
  if (lua_isnil(L, -1)) {  /* no `size' table? */
    lua_pop(L, 1);  /* remove nil */
    lua_newtable(L);  /* create it */
    lua_pushvalue(L, -1);  /* `size' will be its own metatable */
    lua_setmetatable(L, -2);
    lua_pushliteral(L, "kv");
    lua_setfield(L, -2, "__mode");  /* metatable(N).__mode = "kv" */
    lua_pushvalue(L, -1);
    lua_setfield(L, LUA_REGISTRYINDEX, "LUA_SIZES");  /* store in register */
  }
}


LUALIB_API void luaL_setn (lua_State *L, int t, int n) {
  t = abs_index(L, t);
  lua_pushliteral(L, "n");
  lua_rawget(L, t);
  if (checkint(L, 1) >= 0) {  /* is there a numeric field `n'? */
    lua_pushliteral(L, "n");  /* use it */
    lua_pushinteger(L, n);
    lua_rawset(L, t);
  }
  else {  /* use `sizes' */
    getsizes(L);
    lua_pushvalue(L, t);
    lua_pushinteger(L, n);
    lua_rawset(L, -3);  /* sizes[t] = n */
    lua_pop(L, 1);  /* remove `sizes' */
  }
}


LUALIB_API int luaL_getn (lua_State *L, int t) {
  int n;
  t = abs_index(L, t);
  lua_pushliteral(L, "n");  /* try t.n */
  lua_rawget(L, t);
  if ((n = checkint(L, 1)) >= 0) return n;
  getsizes(L);  /* else try sizes[t] */
  lua_pushvalue(L, t);
  lua_rawget(L, -2);
  if ((n = checkint(L, 2)) >= 0) return n;
  return (int)lua_objlen(L, t);
}

#endif

/* }====================================================== */



LUALIB_API const char *luaL_gsub (lua_State *L, const char *s, const char *p,
                                                               const char *r) {
  const char *wild;
  size_t l = strlen(p);
  luaL_Buffer b;
  luaL_buffinit(L, &b);
  while ((wild = strstr(s, p)) != NULL) {
    luaL_addlstring(&b, s, wild - s);  /* push prefix */
    luaL_addstring(&b, r);  /* push replacement in place of pattern */
    s = wild + l;  /* continue after `p' */
  }
  luaL_addstring(&b, s);  /* push last suffix */
  luaL_pushresult(&b);
  return lua_tostring(L, -1);
}


LUALIB_API const char *luaL_findtable (lua_State *L, int idx,
                                       const char *fname, int szhint) {
  const char *e;
  lua_pushvalue(L, idx);
  do {
    e = strchr(fname, '.');
    if (e == NULL) e = fname + strlen(fname);
    lua_pushlstring(L, fname, e - fname);
    lua_rawget(L, -2);
    if (lua_isnil(L, -1)) {  /* no such field? */
      lua_pop(L, 1);  /* remove this nil */
      lua_createtable(L, 0, (*e == '.' ? 1 : szhint)); /* new table for field */
      lua_pushlstring(L, fname, e - fname);
      lua_pushvalue(L, -2);
      lua_settable(L, -4);  /* set new table into field */
    }
    else if (!lua_istable(L, -1)) {  /* field has a non-table value? */
      lua_pop(L, 2);  /* remove table and value */
      return fname;  /* return problematic part of the name */
    }
    lua_remove(L, -2);  /* remove previous table */
    fname = e + 1;
  } while (*e == '.');
  return NULL;
}



/*
** {======================================================
** Generic Buffer manipulation
** =======================================================
*/


#define bufflen(B)	((B)->p - (B)->buffer)
#define bufffree(B)	((size_t)(LUAL_BUFFERSIZE - bufflen(B)))

#define LIMIT	(LUA_MINSTACK/2)


static int emptybuffer (luaL_Buffer *B) {
  size_t l = bufflen(B);
  if (l == 0) return 0;  /* put nothing on stack */
  else {
    lua_pushlstring(B->L, B->buffer, l);
    B->p = B->buffer;
    B->lvl++;
    return 1;
  }
}


static void adjuststack (luaL_Buffer *B) {
  if (B->lvl > 1) {
    lua_State *L = B->L;
    int toget = 1;  /* number of levels to concat */
    size_t toplen = lua_strlen(L, -1);
    do {
      size_t l = lua_strlen(L, -(toget+1));
      if (B->lvl - toget + 1 >= LIMIT || toplen > l) {
        toplen += l;
        toget++;
      }
      else break;
    } while (toget < B->lvl);
    lua_concat(L, toget);
    B->lvl = B->lvl - toget + 1;
  }
}


LUALIB_API char *luaL_prepbuffer (luaL_Buffer *B) {
  if (emptybuffer(B))
    adjuststack(B);
  return B->buffer;
}


LUALIB_API void luaL_addlstring (luaL_Buffer *B, const char *s, size_t l) {
  while (l--)
    luaL_addchar(B, *s++);
}


LUALIB_API void luaL_addstring (luaL_Buffer *B, const char *s) {
  luaL_addlstring(B, s, strlen(s));
}


LUALIB_API void luaL_pushresult (luaL_Buffer *B) {
  emptybuffer(B);
  lua_concat(B->L, B->lvl);
  B->lvl = 1;
}


LUALIB_API void luaL_addvalue (luaL_Buffer *B) {
  lua_State *L = B->L;
  size_t vl;
  const char *s = lua_tolstring(L, -1, &vl);
  if (vl <= bufffree(B)) {  /* fit into buffer? */
    memcpy(B->p, s, vl);  /* put it there */
    B->p += vl;
    lua_pop(L, 1);  /* remove from stack */
  }
  else {
    if (emptybuffer(B))
      lua_insert(L, -2);  /* put buffer before new value */
    B->lvl++;  /* add new value into B stack */
    adjuststack(B);
  }
}


LUALIB_API void luaL_buffinit (lua_State *L, luaL_Buffer *B) {
  B->L = L;
  B->p = B->buffer;
  B->lvl = 0;
}

/* }====================================================== */


LUALIB_API int luaL_ref (lua_State *L, int t) {
  int ref;
  t = abs_index(L, t);
  if (lua_isnil(L, -1)) {
    lua_pop(L, 1);  /* remove from stack */
    return LUA_REFNIL;  /* `nil' has a unique fixed reference */
  }
  lua_rawgeti(L, t, FREELIST_REF);  /* get first free element */
  ref = (int)lua_tointeger(L, -1);  /* ref = t[FREELIST_REF] */
  lua_pop(L, 1);  /* remove it from stack */
  if (ref != 0) {  /* any free element? */
    lua_rawgeti(L, t, ref);  /* remove it from list */
    lua_rawseti(L, t, FREELIST_REF);  /* (t[FREELIST_REF] = t[ref]) */
  }
  else {  /* no free elements */
    ref = (int)lua_objlen(L, t);
    ref++;  /* create new reference */
  }
  lua_rawseti(L, t, ref);
  return ref;
}


LUALIB_API void luaL_unref (lua_State *L, int t, int ref) {
  if (ref >= 0) {
    t = abs_index(L, t);
    lua_rawgeti(L, t, FREELIST_REF);
    lua_rawseti(L, t, ref);  /* t[ref] = t[FREELIST_REF] */
    lua_pushinteger(L, ref);
    lua_rawseti(L, t, FREELIST_REF);  /* t[FREELIST_REF] = ref */
  }
}



/*
** {======================================================
** Load functions
** =======================================================
*/

typedef struct LoadF {
  int extraline;
  FILE *f;
  char buff[LUAL_BUFFERSIZE];
} LoadF;


static const char *getF (lua_State *L, void *ud, size_t *size) {
  LoadF *lf = (LoadF *)ud;
  (void)L;
  if (lf->extraline) {
    lf->extraline = 0;
    *size = 1;
    return "\n";
  }
  if (feof(lf->f)) return NULL;
  *size = fread(lf->buff, 1, LUAL_BUFFERSIZE, lf->f);
  return (*size > 0) ? lf->buff : NULL;
}


static int errfile (lua_State *L, const char *what, int fnameindex) {
  const char *serr = strerror(errno);
  const char *filename = lua_tostring(L, fnameindex) + 1;
  lua_pushfstring(L, "cannot %s %s: %s", what, filename, serr);
  lua_remove(L, fnameindex);
  return LUA_ERRFILE;
}


LUALIB_API int luaL_loadfile (lua_State *L, const char *filename) {
  LoadF lf;
  int status, readstatus;
  int c;
  int fnameindex = lua_gettop(L) + 1;  /* index of filename on the stack */
  lf.extraline = 0;
  if (filename == NULL) {
    lua_pushliteral(L, "=stdin");
    lf.f = stdin;
  }
  else {
    lua_pushfstring(L, "@%s", filename);
    lf.f = fopen(filename, "r");
    if (lf.f == NULL) return errfile(L, "open", fnameindex);
  }
  c = getc(lf.f);
  if (c == '#') {  /* Unix exec. file? */
    lf.extraline = 1;
    while ((c = getc(lf.f)) != EOF && c != '\n') ;  /* skip first line */
    if (c == '\n') c = getc(lf.f);
  }
  if (c == LUA_SIGNATURE[0] && lf.f != stdin) {  /* binary file? */
    fclose(lf.f);
    lf.f = fopen(filename, "rb");  /* reopen in binary mode */
    if (lf.f == NULL) return errfile(L, "reopen", fnameindex);
    /* skip eventual `#!...' */
   while ((c = getc(lf.f)) != EOF && c != LUA_SIGNATURE[0]) ;
    lf.extraline = 0;
  }
  ungetc(c, lf.f);
  status = lua_load(L, getF, &lf, lua_tostring(L, -1));
  readstatus = ferror(lf.f);
  if (lf.f != stdin) fclose(lf.f);  /* close file (even in case of errors) */
  if (readstatus) {
    lua_settop(L, fnameindex);  /* ignore results from `lua_load' */
    return errfile(L, "read", fnameindex);
  }
  lua_remove(L, fnameindex);
  return status;
}


typedef struct LoadS {
  const char *s;
  size_t size;
} LoadS;


static const char *getS (lua_State *L, void *ud, size_t *size) {
  LoadS *ls = (LoadS *)ud;
  (void)L;
  if (ls->size == 0) return NULL;
  *size = ls->size;
  ls->size = 0;
  return ls->s;
}


LUALIB_API int luaL_loadbuffer (lua_State *L, const char *buff, size_t size,
                                const char *name) {
  LoadS ls;
  ls.s = buff;
  ls.size = size;
  return lua_load(L, getS, &ls, name);
}


LUALIB_API int (luaL_loadstring) (lua_State *L, const char *s) {
  return luaL_loadbuffer(L, s, strlen(s), s);
}



/* }====================================================== */


static void *l_alloc (void *ud, void *ptr, size_t osize, size_t nsize) {
  (void)ud;
  (void)osize;
  if (nsize == 0) {
    free(ptr);
    return NULL;
  }
  else
    return realloc(ptr, nsize);
}


static int panic (lua_State *L) {
  (void)L;  /* to avoid warnings */
  fprintf(stderr, "PANIC: unprotected error in call to Lua API (%s)\n",
                   lua_tostring(L, -1));
  return 0;
}


LUALIB_API lua_State *luaL_newstate (void) {
  lua_State *L = lua_newstate(l_alloc, NULL);
  if (L) lua_atpanic(L, &panic);
  return L;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lbaselib.c ===
/*
** $Id: lbaselib.c,v 1.191 2006/06/02 15:34:00 roberto Exp $
** Basic library
** See Copyright Notice in lua.h
*/



#include <ctype.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define lbaselib_c
#define LUA_LIB

#include "lua.h"

#include "lauxlib.h"
#include "lualib.h"




/*
** If your system does not support `stdout', you can just remove this function.
** If you need, you can define your own `print' function, following this
** model but changing `fputs' to put the strings at a proper place
** (a console window or a log file, for instance).
*/
static int luaB_print (lua_State *L) {
  int n = lua_gettop(L);  /* number of arguments */
  int i;
  lua_getglobal(L, "tostring");
  for (i=1; i<=n; i++) {
    const char *s;
    lua_pushvalue(L, -1);  /* function to be called */
    lua_pushvalue(L, i);   /* value to print */
    lua_call(L, 1, 1);
    s = lua_tostring(L, -1);  /* get result */
    if (s == NULL)
      return luaL_error(L, LUA_QL("tostring") " must return a string to "
                           LUA_QL("print"));
    if (i>1) fputs("\t", stdout);
    fputs(s, stdout);
    lua_pop(L, 1);  /* pop result */
  }
  fputs("\n", stdout);
  return 0;
}


static int luaB_tonumber (lua_State *L) {
  int base = luaL_optint(L, 2, 10);
  if (base == 10) {  /* standard conversion */
    luaL_checkany(L, 1);
    if (lua_isnumber(L, 1)) {
      lua_pushnumber(L, lua_tonumber(L, 1));
      return 1;
    }
  }
  else {
    const char *s1 = luaL_checkstring(L, 1);
    char *s2;
    unsigned long n;
    luaL_argcheck(L, 2 <= base && base <= 36, 2, "base out of range");
    n = strtoul(s1, &s2, base);
    if (s1 != s2) {  /* at least one valid digit? */
      while (isspace((unsigned char)(*s2))) s2++;  /* skip trailing spaces */
      if (*s2 == '\0') {  /* no invalid trailing characters? */
        lua_pushnumber(L, (lua_Number)n);
        return 1;
      }
    }
  }
  lua_pushnil(L);  /* else not a number */
  return 1;
}


static int luaB_error (lua_State *L) {
  int level = luaL_optint(L, 2, 1);
  lua_settop(L, 1);
  if (lua_isstring(L, 1) && level > 0) {  /* add extra information? */
    luaL_where(L, level);
    lua_pushvalue(L, 1);
    lua_concat(L, 2);
  }
  return lua_error(L);
}


static int luaB_getmetatable (lua_State *L) {
  luaL_checkany(L, 1);
  if (!lua_getmetatable(L, 1)) {
    lua_pushnil(L);
    return 1;  /* no metatable */
  }
  luaL_getmetafield(L, 1, "__metatable");
  return 1;  /* returns either __metatable field (if present) or metatable */
}


static int luaB_setmetatable (lua_State *L) {
  int t = lua_type(L, 2);
  luaL_checktype(L, 1, LUA_TTABLE);
  luaL_argcheck(L, t == LUA_TNIL || t == LUA_TTABLE, 2,
                    "nil or table expected");
  if (luaL_getmetafield(L, 1, "__metatable"))
    luaL_error(L, "cannot change a protected metatable");
  lua_settop(L, 2);
  lua_setmetatable(L, 1);
  return 1;
}


static void getfunc (lua_State *L, int opt) {
  if (lua_isfunction(L, 1)) lua_pushvalue(L, 1);
  else {
    lua_Debug ar;
    int level = opt ? luaL_optint(L, 1, 1) : luaL_checkint(L, 1);
    luaL_argcheck(L, level >= 0, 1, "level must be non-negative");
    if (lua_getstack(L, level, &ar) == 0)
      luaL_argerror(L, 1, "invalid level");
    lua_getinfo(L, "f", &ar);
    if (lua_isnil(L, -1))
      luaL_error(L, "no function environment for tail call at level %d",
                    level);
  }
}


static int luaB_getfenv (lua_State *L) {
  getfunc(L,1);
  if (lua_iscfunction(L, -1))  /* is a C function? */
    lua_pushvalue(L, LUA_GLOBALSINDEX);  /* return the thread's global env. */
  else
    lua_getfenv(L, -1);
  return 1;
}


static int luaB_setfenv (lua_State *L) {
  luaL_checktype(L, 2, LUA_TTABLE);
  getfunc(L,0);
  lua_pushvalue(L, 2);
  if (lua_isnumber(L, 1) && lua_tonumber(L, 1) == 0) {
    /* change environment of current thread */
    lua_pushthread(L);
    lua_insert(L, -2);
    lua_setfenv(L, -2);
    return 0;
  }
  else if (lua_iscfunction(L, -2) || lua_setfenv(L, -2) == 0)
    luaL_error(L,
          LUA_QL("setfenv") " cannot change environment of given object");
  return 1;
}


static int luaB_rawequal (lua_State *L) {
  luaL_checkany(L, 1);
  luaL_checkany(L, 2);
  lua_pushboolean(L, lua_rawequal(L, 1, 2));
  return 1;
}


static int luaB_rawget (lua_State *L) {
  luaL_checktype(L, 1, LUA_TTABLE);
  luaL_checkany(L, 2);
  lua_settop(L, 2);
  lua_rawget(L, 1);
  return 1;
}

static int luaB_rawset (lua_State *L) {
  luaL_checktype(L, 1, LUA_TTABLE);
  luaL_checkany(L, 2);
  luaL_checkany(L, 3);
  lua_settop(L, 3);
  lua_rawset(L, 1);
  return 1;
}


static int luaB_gcinfo (lua_State *L) {
  lua_pushinteger(L, lua_getgccount(L));
  return 1;
}


static int luaB_collectgarbage (lua_State *L) {
  static const char *const opts[] = {"stop", "restart", "collect",
    "count", "step", "setpause", "setstepmul", NULL};
  static const int optsnum[] = {LUA_GCSTOP, LUA_GCRESTART, LUA_GCCOLLECT,
    LUA_GCCOUNT, LUA_GCSTEP, LUA_GCSETPAUSE, LUA_GCSETSTEPMUL};
  int o = luaL_checkoption(L, 1, "collect", opts);
  int ex = luaL_optint(L, 2, 0);
  int res = lua_gc(L, optsnum[o], ex);
  switch (optsnum[o]) {
    case LUA_GCCOUNT: {
      int b = lua_gc(L, LUA_GCCOUNTB, 0);
      lua_pushnumber(L, res + ((lua_Number)b/1024));
      return 1;
    }
    case LUA_GCSTEP: {
      lua_pushboolean(L, res);
      return 1;
    }
    default: {
      lua_pushnumber(L, res);
      return 1;
    }
  }
}


static int luaB_type (lua_State *L) {
  luaL_checkany(L, 1);
  lua_pushstring(L, luaL_typename(L, 1));
  return 1;
}


static int luaB_next (lua_State *L) {
  luaL_checktype(L, 1, LUA_TTABLE);
  lua_settop(L, 2);  /* create a 2nd argument if there isn't one */
  if (lua_next(L, 1))
    return 2;
  else {
    lua_pushnil(L);
    return 1;
  }
}


static int luaB_pairs (lua_State *L) {
  luaL_checktype(L, 1, LUA_TTABLE);
  lua_pushvalue(L, lua_upvalueindex(1));  /* return generator, */
  lua_pushvalue(L, 1);  /* state, */
  lua_pushnil(L);  /* and initial value */
  return 3;
}


static int ipairsaux (lua_State *L) {
  int i = luaL_checkint(L, 2);
  luaL_checktype(L, 1, LUA_TTABLE);
  i++;  /* next value */
  lua_pushinteger(L, i);
  lua_rawgeti(L, 1, i);
  return (lua_isnil(L, -1)) ? 0 : 2;
}


static int luaB_ipairs (lua_State *L) {
  luaL_checktype(L, 1, LUA_TTABLE);
  lua_pushvalue(L, lua_upvalueindex(1));  /* return generator, */
  lua_pushvalue(L, 1);  /* state, */
  lua_pushinteger(L, 0);  /* and initial value */
  return 3;
}


static int load_aux (lua_State *L, int status) {
  if (status == 0)  /* OK? */
    return 1;
  else {
    lua_pushnil(L);
    lua_insert(L, -2);  /* put before error message */
    return 2;  /* return nil plus error message */
  }
}


static int luaB_loadstring (lua_State *L) {
  size_t l;
  const char *s = luaL_checklstring(L, 1, &l);
  const char *chunkname = luaL_optstring(L, 2, s);
  return load_aux(L, luaL_loadbuffer(L, s, l, chunkname));
}


static int luaB_loadfile (lua_State *L) {
  const char *fname = luaL_optstring(L, 1, NULL);
  return load_aux(L, luaL_loadfile(L, fname));
}


/*
** Reader for generic `load' function: `lua_load' uses the
** stack for internal stuff, so the reader cannot change the
** stack top. Instead, it keeps its resulting string in a
** reserved slot inside the stack.
*/
static const char *generic_reader (lua_State *L, void *ud, size_t *size) {
  (void)ud;  /* to avoid warnings */
  luaL_checkstack(L, 2, "too many nested functions");
  lua_pushvalue(L, 1);  /* get function */
  lua_call(L, 0, 1);  /* call it */
  if (lua_isnil(L, -1)) {
    *size = 0;
    return NULL;
  }
  else if (lua_isstring(L, -1)) {
    lua_replace(L, 3);  /* save string in a reserved stack slot */
    return lua_tolstring(L, 3, size);
  }
  else luaL_error(L, "reader function must return a string");
  return NULL;  /* to avoid warnings */
}


static int luaB_load (lua_State *L) {
  int status;
  const char *cname = luaL_optstring(L, 2, "=(load)");
  luaL_checktype(L, 1, LUA_TFUNCTION);
  lua_settop(L, 3);  /* function, eventual name, plus one reserved slot */
  status = lua_load(L, generic_reader, NULL, cname);
  return load_aux(L, status);
}


static int luaB_dofile (lua_State *L) {
  const char *fname = luaL_optstring(L, 1, NULL);
  int n = lua_gettop(L);
  if (luaL_loadfile(L, fname) != 0) lua_error(L);
  lua_call(L, 0, LUA_MULTRET);
  return lua_gettop(L) - n;
}


static int luaB_assert (lua_State *L) {
  luaL_checkany(L, 1);
  if (!lua_toboolean(L, 1))
    return luaL_error(L, "%s", luaL_optstring(L, 2, "assertion failed!"));
  return lua_gettop(L);
}


static int luaB_unpack (lua_State *L) {
  int i, e, n;
  luaL_checktype(L, 1, LUA_TTABLE);
  i = luaL_optint(L, 2, 1);
  e = luaL_opt(L, luaL_checkint, 3, luaL_getn(L, 1));
  n = e - i + 1;  /* number of elements */
  if (n <= 0) return 0;  /* empty range */
  luaL_checkstack(L, n, "table too big to unpack");
  for (; i<=e; i++)  /* push arg[i...e] */
    lua_rawgeti(L, 1, i);
  return n;
}


static int luaB_select (lua_State *L) {
  int n = lua_gettop(L);
  if (lua_type(L, 1) == LUA_TSTRING && *lua_tostring(L, 1) == '#') {
    lua_pushinteger(L, n-1);
    return 1;
  }
  else {
    int i = luaL_checkint(L, 1);
    if (i < 0) i = n + i;
    else if (i > n) i = n;
    luaL_argcheck(L, 1 <= i, 1, "index out of range");
    return n - i;
  }
}


static int luaB_pcall (lua_State *L) {
  int status;
  luaL_checkany(L, 1);
  status = lua_pcall(L, lua_gettop(L) - 1, LUA_MULTRET, 0);
  lua_pushboolean(L, (status == 0));
  lua_insert(L, 1);
  return lua_gettop(L);  /* return status + all results */
}


static int luaB_xpcall (lua_State *L) {
  int status;
  luaL_checkany(L, 2);
  lua_settop(L, 2);
  lua_insert(L, 1);  /* put error function under function to be called */
  status = lua_pcall(L, 0, LUA_MULTRET, 1);
  lua_pushboolean(L, (status == 0));
  lua_replace(L, 1);
  return lua_gettop(L);  /* return status + all results */
}


static int luaB_tostring (lua_State *L) {
  luaL_checkany(L, 1);
  if (luaL_callmeta(L, 1, "__tostring"))  /* is there a metafield? */
    return 1;  /* use its value */
  switch (lua_type(L, 1)) {
    case LUA_TNUMBER:
      lua_pushstring(L, lua_tostring(L, 1));
      break;
    case LUA_TSTRING:
      lua_pushvalue(L, 1);
      break;
    case LUA_TBOOLEAN:
      lua_pushstring(L, (lua_toboolean(L, 1) ? "true" : "false"));
      break;
    case LUA_TNIL:
      lua_pushliteral(L, "nil");
      break;
    default:
      lua_pushfstring(L, "%s: %p", luaL_typename(L, 1), lua_topointer(L, 1));
      break;
  }
  return 1;
}


static int luaB_newproxy (lua_State *L) {
  lua_settop(L, 1);
  lua_newuserdata(L, 0);  /* create proxy */
  if (lua_toboolean(L, 1) == 0)
    return 1;  /* no metatable */
  else if (lua_isboolean(L, 1)) {
    lua_newtable(L);  /* create a new metatable `m' ... */
    lua_pushvalue(L, -1);  /* ... and mark `m' as a valid metatable */
    lua_pushboolean(L, 1);
    lua_rawset(L, lua_upvalueindex(1));  /* weaktable[m] = true */
  }
  else {
    int validproxy = 0;  /* to check if weaktable[metatable(u)] == true */
    if (lua_getmetatable(L, 1)) {
      lua_rawget(L, lua_upvalueindex(1));
      validproxy = lua_toboolean(L, -1);
      lua_pop(L, 1);  /* remove value */
    }
    luaL_argcheck(L, validproxy, 1, "boolean or proxy expected");
    lua_getmetatable(L, 1);  /* metatable is valid; get it */
  }
  lua_setmetatable(L, 2);
  return 1;
}


static const luaL_Reg base_funcs[] = {
  {"assert", luaB_assert},
  {"collectgarbage", luaB_collectgarbage},
  {"dofile", luaB_dofile},
  {"error", luaB_error},
  {"gcinfo", luaB_gcinfo},
  {"getfenv", luaB_getfenv},
  {"getmetatable", luaB_getmetatable},
  {"loadfile", luaB_loadfile},
  {"load", luaB_load},
  {"loadstring", luaB_loadstring},
  {"next", luaB_next},
  {"pcall", luaB_pcall},
  {"print", luaB_print},
  {"rawequal", luaB_rawequal},
  {"rawget", luaB_rawget},
  {"rawset", luaB_rawset},
  {"select", luaB_select},
  {"setfenv", luaB_setfenv},
  {"setmetatable", luaB_setmetatable},
  {"tonumber", luaB_tonumber},
  {"tostring", luaB_tostring},
  {"type", luaB_type},
  {"unpack", luaB_unpack},
  {"xpcall", luaB_xpcall},
  {NULL, NULL}
};


/*
** {======================================================
** Coroutine library
** =======================================================
*/

static int auxresume (lua_State *L, lua_State *co, int narg) {
  int status;
  if (!lua_checkstack(co, narg))
    luaL_error(L, "too many arguments to resume");
  if (lua_status(co) == 0 && lua_gettop(co) == 0) {
    lua_pushliteral(L, "cannot resume dead coroutine");
    return -1;  /* error flag */
  }
  lua_xmove(L, co, narg);
  status = lua_resume(co, narg);
  if (status == 0 || status == LUA_YIELD) {
    int nres = lua_gettop(co);
    if (!lua_checkstack(L, nres))
      luaL_error(L, "too many results to resume");
    lua_xmove(co, L, nres);  /* move yielded values */
    return nres;
  }
  else {
    lua_xmove(co, L, 1);  /* move error message */
    return -1;  /* error flag */
  }
}


static int luaB_coresume (lua_State *L) {
  lua_State *co = lua_tothread(L, 1);
  int r;
  luaL_argcheck(L, co, 1, "coroutine expected");
  r = auxresume(L, co, lua_gettop(L) - 1);
  if (r < 0) {
    lua_pushboolean(L, 0);
    lua_insert(L, -2);
    return 2;  /* return false + error message */
  }
  else {
    lua_pushboolean(L, 1);
    lua_insert(L, -(r + 1));
    return r + 1;  /* return true + `resume' returns */
  }
}


static int luaB_auxwrap (lua_State *L) {
  lua_State *co = lua_tothread(L, lua_upvalueindex(1));
  int r = auxresume(L, co, lua_gettop(L));
  if (r < 0) {
    if (lua_isstring(L, -1)) {  /* error object is a string? */
      luaL_where(L, 1);  /* add extra info */
      lua_insert(L, -2);
      lua_concat(L, 2);
    }
    lua_error(L);  /* propagate error */
  }
  return r;
}


static int luaB_cocreate (lua_State *L) {
  lua_State *NL = lua_newthread(L);
  luaL_argcheck(L, lua_isfunction(L, 1) && !lua_iscfunction(L, 1), 1,
    "Lua function expected");
  lua_pushvalue(L, 1);  /* move function to top */
  lua_xmove(L, NL, 1);  /* move function from L to NL */
  return 1;
}


static int luaB_cowrap (lua_State *L) {
  luaB_cocreate(L);
  lua_pushcclosure(L, luaB_auxwrap, 1);
  return 1;
}


static int luaB_yield (lua_State *L) {
  return lua_yield(L, lua_gettop(L));
}


static int luaB_costatus (lua_State *L) {
  lua_State *co = lua_tothread(L, 1);
  luaL_argcheck(L, co, 1, "coroutine expected");
  if (L == co) lua_pushliteral(L, "running");
  else {
    switch (lua_status(co)) {
      case LUA_YIELD:
        lua_pushliteral(L, "suspended");
        break;
      case 0: {
        lua_Debug ar;
        if (lua_getstack(co, 0, &ar) > 0)  /* does it have frames? */
          lua_pushliteral(L, "normal");  /* it is running */
        else if (lua_gettop(co) == 0)
            lua_pushliteral(L, "dead");
        else
          lua_pushliteral(L, "suspended");  /* initial state */
        break;
      }
      default:  /* some error occured */
        lua_pushliteral(L, "dead");
        break;
    }
  }
  return 1;
}


static int luaB_corunning (lua_State *L) {
  if (lua_pushthread(L))
    return 0;  /* main thread is not a coroutine */
  else
    return 1;
}


static const luaL_Reg co_funcs[] = {
  {"create", luaB_cocreate},
  {"resume", luaB_coresume},
  {"running", luaB_corunning},
  {"status", luaB_costatus},
  {"wrap", luaB_cowrap},
  {"yield", luaB_yield},
  {NULL, NULL}
};

/* }====================================================== */


static void auxopen (lua_State *L, const char *name,
                     lua_CFunction f, lua_CFunction u) {
  lua_pushcfunction(L, u);
  lua_pushcclosure(L, f, 1);
  lua_setfield(L, -2, name);
}


static void base_open (lua_State *L) {
  /* set global _G */
  lua_pushvalue(L, LUA_GLOBALSINDEX);
  lua_setglobal(L, "_G");
  /* open lib into global table */
  luaL_register(L, "_G", base_funcs);
  lua_pushliteral(L, LUA_VERSION);
  lua_setglobal(L, "_VERSION");  /* set global _VERSION */
  /* `ipairs' and `pairs' need auxliliary functions as upvalues */
  auxopen(L, "ipairs", luaB_ipairs, ipairsaux);
  auxopen(L, "pairs", luaB_pairs, luaB_next);
  /* `newproxy' needs a weaktable as upvalue */
  lua_createtable(L, 0, 1);  /* new table `w' */
  lua_pushvalue(L, -1);  /* `w' will be its own metatable */
  lua_setmetatable(L, -2);
  lua_pushliteral(L, "kv");
  lua_setfield(L, -2, "__mode");  /* metatable(w).__mode = "kv" */
  lua_pushcclosure(L, luaB_newproxy, 1);
  lua_setglobal(L, "newproxy");  /* set global `newproxy' */
}


LUALIB_API int luaopen_base (lua_State *L) {
  base_open(L);
  luaL_register(L, LUA_COLIBNAME, co_funcs);
  return 2;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ldebug.h ===
/*
** $Id: ldebug.h,v 2.3 2005/04/25 19:24:10 roberto Exp $
** Auxiliary functions from Debug Interface module
** See Copyright Notice in lua.h
*/

#ifndef ldebug_h
#define ldebug_h


#include "lstate.h"


#define pcRel(pc, p)	(cast(int, (pc) - (p)->code) - 1)

#define getline(f,pc)	(((f)->lineinfo) ? (f)->lineinfo[pc] : 0)

#define resethookcount(L)	(L->hookcount = L->basehookcount)


LUAI_FUNC void luaG_typeerror (lua_State *L, const TValue *o,
                                             const char *opname);
LUAI_FUNC void luaG_concaterror (lua_State *L, StkId p1, StkId p2);
LUAI_FUNC void luaG_aritherror (lua_State *L, const TValue *p1,
                                              const TValue *p2);
LUAI_FUNC int luaG_ordererror (lua_State *L, const TValue *p1,
                                             const TValue *p2);
LUAI_FUNC void luaG_runerror (lua_State *L, const char *fmt, ...);
LUAI_FUNC void luaG_errormsg (lua_State *L);
LUAI_FUNC int luaG_checkcode (const Proto *pt);
LUAI_FUNC int luaG_checkopenop (Instruction i);

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ldebug.c ===
/*
** $Id: ldebug.c,v 2.29 2005/12/22 16:19:56 roberto Exp $
** Debug Interface
** See Copyright Notice in lua.h
*/


#include <stdarg.h>
#include <stddef.h>
#include <string.h>


#define ldebug_c
#define LUA_CORE

#include "lua.h"

#include "lapi.h"
#include "lcode.h"
#include "ldebug.h"
#include "ldo.h"
#include "lfunc.h"
#include "lobject.h"
#include "lopcodes.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"
#include "ltm.h"
#include "lvm.h"



static const char *getfuncname (lua_State *L, CallInfo *ci, const char **name);


static int currentpc (lua_State *L, CallInfo *ci) {
  if (!isLua(ci)) return -1;  /* function is not a Lua function? */
  if (ci == L->ci)
    ci->savedpc = L->savedpc;
  return pcRel(ci->savedpc, ci_func(ci)->l.p);
}


static int currentline (lua_State *L, CallInfo *ci) {
  int pc = currentpc(L, ci);
  if (pc < 0)
    return -1;  /* only active lua functions have current-line information */
  else
    return getline(ci_func(ci)->l.p, pc);
}


/*
** this function can be called asynchronous (e.g. during a signal)
*/
LUA_API int lua_sethook (lua_State *L, lua_Hook func, int mask, int count) {
  if (func == NULL || mask == 0) {  /* turn off hooks? */
    mask = 0;
    func = NULL;
  }
  L->hook = func;
  L->basehookcount = count;
  resethookcount(L);
  L->hookmask = cast_byte(mask);
  return 1;
}


LUA_API lua_Hook lua_gethook (lua_State *L) {
  return L->hook;
}


LUA_API int lua_gethookmask (lua_State *L) {
  return L->hookmask;
}


LUA_API int lua_gethookcount (lua_State *L) {
  return L->basehookcount;
}


LUA_API int lua_getstack (lua_State *L, int level, lua_Debug *ar) {
  int status;
  CallInfo *ci;
  lua_lock(L);
  for (ci = L->ci; level > 0 && ci > L->base_ci; ci--) {
    level--;
    if (f_isLua(ci))  /* Lua function? */
      level -= ci->tailcalls;  /* skip lost tail calls */
  }
  if (level == 0 && ci > L->base_ci) {  /* level found? */
    status = 1;
    ar->i_ci = cast_int(ci - L->base_ci);
  }
  else if (level < 0) {  /* level is of a lost tail call? */
    status = 1;
    ar->i_ci = 0;
  }
  else status = 0;  /* no such level */
  lua_unlock(L);
  return status;
}


static Proto *getluaproto (CallInfo *ci) {
  return (isLua(ci) ? ci_func(ci)->l.p : NULL);
}


static const char *findlocal (lua_State *L, CallInfo *ci, int n) {
  const char *name;
  Proto *fp = getluaproto(ci);
  if (fp && (name = luaF_getlocalname(fp, n, currentpc(L, ci))) != NULL)
    return name;  /* is a local variable in a Lua function */
  else {
    StkId limit = (ci == L->ci) ? L->top : (ci+1)->func;
    if (limit - ci->base >= n && n > 0)  /* is 'n' inside 'ci' stack? */
      return "(*temporary)";
    else
      return NULL;
  }
}


LUA_API const char *lua_getlocal (lua_State *L, const lua_Debug *ar, int n) {
  CallInfo *ci = L->base_ci + ar->i_ci;
  const char *name = findlocal(L, ci, n);
  lua_lock(L);
  if (name)
      luaA_pushobject(L, ci->base + (n - 1));
  lua_unlock(L);
  return name;
}


LUA_API const char *lua_setlocal (lua_State *L, const lua_Debug *ar, int n) {
  CallInfo *ci = L->base_ci + ar->i_ci;
  const char *name = findlocal(L, ci, n);
  lua_lock(L);
  if (name)
      setobjs2s(L, ci->base + (n - 1), L->top - 1);
  L->top--;  /* pop value */
  lua_unlock(L);
  return name;
}


static void funcinfo (lua_Debug *ar, Closure *cl) {
  if (cl->c.isC) {
    ar->source = "=[C]";
    ar->linedefined = -1;
    ar->lastlinedefined = -1;
    ar->what = "C";
  }
  else {
    ar->source = getstr(cl->l.p->source);
    ar->linedefined = cl->l.p->linedefined;
    ar->lastlinedefined = cl->l.p->lastlinedefined;
    ar->what = (ar->linedefined == 0) ? "main" : "Lua";
  }
  luaO_chunkid(ar->short_src, ar->source, LUA_IDSIZE);
}


static void info_tailcall (lua_Debug *ar) {
  ar->name = ar->namewhat = "";
  ar->what = "tail";
  ar->lastlinedefined = ar->linedefined = ar->currentline = -1;
  ar->source = "=(tail call)";
  luaO_chunkid(ar->short_src, ar->source, LUA_IDSIZE);
  ar->nups = 0;
}


static void collectvalidlines (lua_State *L, Closure *f) {
  if (f == NULL || f->c.isC) {
    setnilvalue(L->top);
  }
  else {
    Table *t = luaH_new(L, 0, 0);
    int *lineinfo = f->l.p->lineinfo;
    int i;
    for (i=0; i<f->l.p->sizelineinfo; i++)
      setbvalue(luaH_setnum(L, t, lineinfo[i]), 1);
    sethvalue(L, L->top, t);
  }
  incr_top(L);
}


static int auxgetinfo (lua_State *L, const char *what, lua_Debug *ar,
                    Closure *f, CallInfo *ci) {
  int status = 1;
  if (f == NULL) {
    info_tailcall(ar);
    return status;
  }
  for (; *what; what++) {
    switch (*what) {
      case 'S': {
        funcinfo(ar, f);
        break;
      }
      case 'l': {
        ar->currentline = (ci) ? currentline(L, ci) : -1;
        break;
      }
      case 'u': {
        ar->nups = f->c.nupvalues;
        break;
      }
      case 'n': {
        ar->namewhat = (ci) ? getfuncname(L, ci, &ar->name) : NULL;
        if (ar->namewhat == NULL) {
          ar->namewhat = "";  /* not found */
          ar->name = NULL;
        }
        break;
      }
      case 'L':
      case 'f':  /* handled by lua_getinfo */
        break;
      default: status = 0;  /* invalid option */
    }
  }
  return status;
}


LUA_API int lua_getinfo (lua_State *L, const char *what, lua_Debug *ar) {
  int status;
  Closure *f = NULL;
  CallInfo *ci = NULL;
  lua_lock(L);
  if (*what == '>') {
    StkId func = L->top - 1;
    luai_apicheck(L, ttisfunction(func));
    what++;  /* skip the '>' */
    f = clvalue(func);
    L->top--;  /* pop function */
  }
  else if (ar->i_ci != 0) {  /* no tail call? */
    ci = L->base_ci + ar->i_ci;
    lua_assert(ttisfunction(ci->func));
    f = clvalue(ci->func);
  }
  status = auxgetinfo(L, what, ar, f, ci);
  if (strchr(what, 'f')) {
    if (f == NULL) setnilvalue(L->top);
    else setclvalue(L, L->top, f);
    incr_top(L);
  }
  if (strchr(what, 'L'))
    collectvalidlines(L, f);
  lua_unlock(L);
  return status;
}


/*
** {======================================================
** Symbolic Execution and code checker
** =======================================================
*/

#define check(x)        if (!(x)) return 0;

#define checkjump(pt,pc)    check(0 <= pc && pc < pt->sizecode)

#define checkreg(pt,reg)    check((reg) < (pt)->maxstacksize)



static int precheck (const Proto *pt) {
  check(pt->maxstacksize <= MAXSTACK);
  lua_assert(pt->numparams+(pt->is_vararg & VARARG_HASARG) <= pt->maxstacksize);
  lua_assert(!(pt->is_vararg & VARARG_NEEDSARG) ||
              (pt->is_vararg & VARARG_HASARG));
  check(pt->sizeupvalues <= pt->nups);
  check(pt->sizelineinfo == pt->sizecode || pt->sizelineinfo == 0);
  check(GET_OPCODE(pt->code[pt->sizecode-1]) == OP_RETURN);
  return 1;
}


#define checkopenop(pt,pc)  luaG_checkopenop((pt)->code[(pc)+1])

int luaG_checkopenop (Instruction i) {
  switch (GET_OPCODE(i)) {
    case OP_CALL:
    case OP_TAILCALL:
    case OP_RETURN:
    case OP_SETLIST: {
      check(GETARG_B(i) == 0);
      return 1;
    }
    default: return 0;  /* invalid instruction after an open call */
  }
}


static int checkArgMode (const Proto *pt, int r, enum OpArgMask mode) {
  switch (mode) {
    case OpArgN: check(r == 0); break;
    case OpArgU: break;
    case OpArgR: checkreg(pt, r); break;
    case OpArgK:
      check(ISK(r) ? INDEXK(r) < pt->sizek : r < pt->maxstacksize);
      break;
  }
  return 1;
}


static Instruction symbexec (const Proto *pt, int lastpc, int reg) {
  int pc;
  int last;  /* stores position of last instruction that changed `reg' */
  last = pt->sizecode-1;  /* points to final return (a `neutral' instruction) */
  check(precheck(pt));
  for (pc = 0; pc < lastpc; pc++) {
    Instruction i = pt->code[pc];
    OpCode op = GET_OPCODE(i);
    int a = GETARG_A(i);
    int b = 0;
    int c = 0;
    check(op < NUM_OPCODES);
    checkreg(pt, a);
    switch (getOpMode(op)) {
      case iABC: {
        b = GETARG_B(i);
        c = GETARG_C(i);
        check(checkArgMode(pt, b, getBMode(op)));
        check(checkArgMode(pt, c, getCMode(op)));
        break;
      }
      case iABx: {
        b = GETARG_Bx(i);
        if (getBMode(op) == OpArgK) check(b < pt->sizek);
        break;
      }
      case iAsBx: {
        b = GETARG_sBx(i);
        if (getBMode(op) == OpArgR) {
          int dest = pc+1+b;
          check(0 <= dest && dest < pt->sizecode);
          if (dest > 0) {
            /* cannot jump to a setlist count */
            Instruction d = pt->code[dest-1];
            check(!(GET_OPCODE(d) == OP_SETLIST && GETARG_C(d) == 0));
          }
        }
        break;
      }
    }
    if (testAMode(op)) {
      if (a == reg) last = pc;  /* change register `a' */
    }
    if (testTMode(op)) {
      check(pc+2 < pt->sizecode);  /* check skip */
      check(GET_OPCODE(pt->code[pc+1]) == OP_JMP);
    }
    switch (op) {
      case OP_LOADBOOL: {
        check(c == 0 || pc+2 < pt->sizecode);  /* check its jump */
        break;
      }
      case OP_LOADNIL: {
        if (a <= reg && reg <= b)
          last = pc;  /* set registers from `a' to `b' */
        break;
      }
      case OP_GETUPVAL:
      case OP_SETUPVAL: {
        check(b < pt->nups);
        break;
      }
      case OP_GETGLOBAL:
      case OP_SETGLOBAL: {
        check(ttisstring(&pt->k[b]));
        break;
      }
      case OP_SELF: {
        checkreg(pt, a+1);
        if (reg == a+1) last = pc;
        break;
      }
      case OP_CONCAT: {
        check(b < c);  /* at least two operands */
        break;
      }
      case OP_TFORLOOP: {
        check(c >= 1);  /* at least one result (control variable) */
        checkreg(pt, a+2+c);  /* space for results */
        if (reg >= a+2) last = pc;  /* affect all regs above its base */
        break;
      }
      case OP_FORLOOP:
      case OP_FORPREP:
        checkreg(pt, a+3);
        /* go through */
      case OP_JMP: {
        int dest = pc+1+b;
        /* not full check and jump is forward and do not skip `lastpc'? */
        if (reg != NO_REG && pc < dest && dest <= lastpc)
          pc += b;  /* do the jump */
        break;
      }
      case OP_CALL:
      case OP_TAILCALL: {
        if (b != 0) {
          checkreg(pt, a+b-1);
        }
        c--;  /* c = num. returns */
        if (c == LUA_MULTRET) {
          check(checkopenop(pt, pc));
        }
        else if (c != 0)
          checkreg(pt, a+c-1);
        if (reg >= a) last = pc;  /* affect all registers above base */
        break;
      }
      case OP_RETURN: {
        b--;  /* b = num. returns */
        if (b > 0) checkreg(pt, a+b-1);
        break;
      }
      case OP_SETLIST: {
        if (b > 0) checkreg(pt, a + b);
        if (c == 0) pc++;
        break;
      }
      case OP_CLOSURE: {
        int nup, j;
        check(b < pt->sizep);
        nup = pt->p[b]->nups;
        check(pc + nup < pt->sizecode);
        for (j = 1; j <= nup; j++) {
          OpCode op1 = GET_OPCODE(pt->code[pc + j]);
          check(op1 == OP_GETUPVAL || op1 == OP_MOVE);
        }
        if (reg != NO_REG) /* tracing? */
          pc += nup; /* do not 'execute' these pseudo-instructions */
        break;
      }
      case OP_VARARG: {
        check((pt->is_vararg & VARARG_ISVARARG) &&
             !(pt->is_vararg & VARARG_NEEDSARG));
        b--;
        if (b == LUA_MULTRET) check(checkopenop(pt, pc));
        checkreg(pt, a+b-1);
        break;
      }
      default: break;
    }
  }
  return pt->code[last];
}

#undef check
#undef checkjump
#undef checkreg

/* }====================================================== */


int luaG_checkcode (const Proto *pt) {
  return (symbexec(pt, pt->sizecode, NO_REG) != 0);
}


static const char *kname (Proto *p, int c) {
  if (ISK(c) && ttisstring(&p->k[INDEXK(c)]))
    return svalue(&p->k[INDEXK(c)]);
  else
    return "?";
}


static const char *getobjname (lua_State *L, CallInfo *ci, int stackpos,
                               const char **name) {
  if (isLua(ci)) {  /* a Lua function? */
    Proto *p = ci_func(ci)->l.p;
    int pc = currentpc(L, ci);
    Instruction i;
    *name = luaF_getlocalname(p, stackpos+1, pc);
    if (*name)  /* is a local? */
      return "local";
    i = symbexec(p, pc, stackpos);  /* try symbolic execution */
    lua_assert(pc != -1);
    switch (GET_OPCODE(i)) {
      case OP_GETGLOBAL: {
        int g = GETARG_Bx(i);  /* global index */
        lua_assert(ttisstring(&p->k[g]));
        *name = svalue(&p->k[g]);
        return "global";
      }
      case OP_MOVE: {
        int a = GETARG_A(i);
        int b = GETARG_B(i);  /* move from `b' to `a' */
        if (b < a)
          return getobjname(L, ci, b, name);  /* get name for `b' */
        break;
      }
      case OP_GETTABLE: {
        int k = GETARG_C(i);  /* key index */
        *name = kname(p, k);
        return "field";
      }
      case OP_GETUPVAL: {
        int u = GETARG_B(i);  /* upvalue index */
        *name = p->upvalues ? getstr(p->upvalues[u]) : "?";
        return "upvalue";
      }
      case OP_SELF: {
        int k = GETARG_C(i);  /* key index */
        *name = kname(p, k);
        return "method";
      }
      default: break;
    }
  }
  return NULL;  /* no useful name found */
}


static const char *getfuncname (lua_State *L, CallInfo *ci, const char **name) {
  Instruction i;
  if ((isLua(ci) && ci->tailcalls > 0) || !isLua(ci - 1))
    return NULL;  /* calling function is not Lua (or is unknown) */
  ci--;  /* calling function */
  i = ci_func(ci)->l.p->code[currentpc(L, ci)];
  if (GET_OPCODE(i) == OP_CALL || GET_OPCODE(i) == OP_TAILCALL ||
      GET_OPCODE(i) == OP_TFORLOOP)
    return getobjname(L, ci, GETARG_A(i), name);
  else
    return NULL;  /* no useful name can be found */
}


/* only ANSI way to check whether a pointer points to an array */
static int isinstack (CallInfo *ci, const TValue *o) {
  StkId p;
  for (p = ci->base; p < ci->top; p++)
    if (o == p) return 1;
  return 0;
}


void luaG_typeerror (lua_State *L, const TValue *o, const char *op) {
  const char *name = NULL;
  const char *t = luaT_typenames[ttype(o)];
  const char *kind = (isinstack(L->ci, o)) ?
                         getobjname(L, L->ci, cast_int(o - L->base), &name) :
                         NULL;
  if (kind)
    luaG_runerror(L, "attempt to %s %s " LUA_QS " (a %s value)",
                op, kind, name, t);
  else
    luaG_runerror(L, "attempt to %s a %s value", op, t);
}


void luaG_concaterror (lua_State *L, StkId p1, StkId p2) {
  if (ttisstring(p1) || ttisnumber(p1)) p1 = p2;
  lua_assert(!ttisstring(p1) && !ttisnumber(p1));
  luaG_typeerror(L, p1, "concatenate");
}


void luaG_aritherror (lua_State *L, const TValue *p1, const TValue *p2) {
  TValue temp;
  if (luaV_tonumber(p1, &temp) == NULL)
    p2 = p1;  /* first operand is wrong */
  luaG_typeerror(L, p2, "perform arithmetic on");
}


int luaG_ordererror (lua_State *L, const TValue *p1, const TValue *p2) {
  const char *t1 = luaT_typenames[ttype(p1)];
  const char *t2 = luaT_typenames[ttype(p2)];
  if (t1[2] == t2[2])
    luaG_runerror(L, "attempt to compare two %s values", t1);
  else
    luaG_runerror(L, "attempt to compare %s with %s", t1, t2);
  return 0;
}


static void addinfo (lua_State *L, const char *msg) {
  CallInfo *ci = L->ci;
  if (isLua(ci)) {  /* is Lua code? */
    char buff[LUA_IDSIZE];  /* add file:line information */
    int line = currentline(L, ci);
    luaO_chunkid(buff, getstr(getluaproto(ci)->source), LUA_IDSIZE);
    luaO_pushfstring(L, "%s:%d: %s", buff, line, msg);
  }
}


void luaG_errormsg (lua_State *L) {
  if (L->errfunc != 0) {  /* is there an error handling function? */
    StkId errfunc = restorestack(L, L->errfunc);
    if (!ttisfunction(errfunc)) luaD_throw(L, LUA_ERRERR);
    setobjs2s(L, L->top, L->top - 1);  /* move argument */
    setobjs2s(L, L->top - 1, errfunc);  /* push function */
    incr_top(L);
    luaD_call(L, L->top - 2, 1);  /* call it */
  }
  luaD_throw(L, LUA_ERRRUN);
}


void luaG_runerror (lua_State *L, const char *fmt, ...) {
  va_list argp;
  va_start(argp, fmt);
  addinfo(L, luaO_pushvfstring(L, fmt, argp));
  va_end(argp);
  luaG_errormsg(L);
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ldo.c ===
/*
** $Id: ldo.c,v 2.38 2006/06/05 19:36:14 roberto Exp $
** Stack and Call structure of Lua
** See Copyright Notice in lua.h
*/


#include <setjmp.h>
#include <stdlib.h>
#include <string.h>

#define ldo_c
#define LUA_CORE

#include "lua.h"

#include "ldebug.h"
#include "ldo.h"
#include "lfunc.h"
#include "lgc.h"
#include "lmem.h"
#include "lobject.h"
#include "lopcodes.h"
#include "lparser.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"
#include "ltm.h"
#include "lundump.h"
#include "lvm.h"
#include "lzio.h"




/*
** {======================================================
** Error-recovery functions
** =======================================================
*/


/* chain list of long jump buffers */
struct lua_longjmp {
  struct lua_longjmp *previous;
  luai_jmpbuf b;
  volatile int status;  /* error code */
};


void luaD_seterrorobj (lua_State *L, int errcode, StkId oldtop) {
  switch (errcode) {
    case LUA_ERRMEM: {
      setsvalue2s(L, oldtop, luaS_newliteral(L, MEMERRMSG));
      break;
    }
    case LUA_ERRERR: {
      setsvalue2s(L, oldtop, luaS_newliteral(L, "error in error handling"));
      break;
    }
    case LUA_ERRSYNTAX:
    case LUA_ERRRUN: {
      setobjs2s(L, oldtop, L->top - 1);  /* error message on current top */
      break;
    }
  }
  L->top = oldtop + 1;
}


static void restore_stack_limit (lua_State *L) {
  lua_assert(L->stack_last - L->stack == L->stacksize - EXTRA_STACK - 1);
  if (L->size_ci > LUAI_MAXCALLS) {  /* there was an overflow? */
    int inuse = cast_int(L->ci - L->base_ci);
    if (inuse + 1 < LUAI_MAXCALLS)  /* can `undo' overflow? */
      luaD_reallocCI(L, LUAI_MAXCALLS);
  }
}


static void resetstack (lua_State *L, int status) {
  L->ci = L->base_ci;
  L->base = L->ci->base;
  luaF_close(L, L->base);  /* close eventual pending closures */
  luaD_seterrorobj(L, status, L->base);
  L->nCcalls = 0;
  L->allowhook = 1;
  restore_stack_limit(L);
  L->errfunc = 0;
  L->errorJmp = NULL;
}


void luaD_throw (lua_State *L, int errcode) {
  if (L->errorJmp) {
    L->errorJmp->status = errcode;
    LUAI_THROW(L, L->errorJmp);
  }
  else {
    L->status = cast_byte(errcode);
    if (G(L)->panic) {
      resetstack(L, errcode);
      lua_unlock(L);
      G(L)->panic(L);
    }
    exit(EXIT_FAILURE);
  }
}


int luaD_rawrunprotected (lua_State *L, Pfunc f, void *ud) {
  struct lua_longjmp lj;
  lj.status = 0;
  lj.previous = L->errorJmp;  /* chain new error handler */
  L->errorJmp = &lj;
  LUAI_TRY(L, &lj,
    (*f)(L, ud);
  );
  L->errorJmp = lj.previous;  /* restore old error handler */
  return lj.status;
}

/* }====================================================== */


static void correctstack (lua_State *L, TValue *oldstack) {
  CallInfo *ci;
  GCObject *up;
  L->top = (L->top - oldstack) + L->stack;
  for (up = L->openupval; up != NULL; up = up->gch.next)
    gco2uv(up)->v = (gco2uv(up)->v - oldstack) + L->stack;
  for (ci = L->base_ci; ci <= L->ci; ci++) {
    ci->top = (ci->top - oldstack) + L->stack;
    ci->base = (ci->base - oldstack) + L->stack;
    ci->func = (ci->func - oldstack) + L->stack;
  }
  L->base = (L->base - oldstack) + L->stack;
}


void luaD_reallocstack (lua_State *L, int newsize) {
  TValue *oldstack = L->stack;
  int realsize = newsize + 1 + EXTRA_STACK;
  lua_assert(L->stack_last - L->stack == L->stacksize - EXTRA_STACK - 1);
  luaM_reallocvector(L, L->stack, L->stacksize, realsize, TValue);
  L->stacksize = realsize;
  L->stack_last = L->stack+newsize;
  correctstack(L, oldstack);
}


void luaD_reallocCI (lua_State *L, int newsize) {
  CallInfo *oldci = L->base_ci;
  luaM_reallocvector(L, L->base_ci, L->size_ci, newsize, CallInfo);
  L->size_ci = newsize;
  L->ci = (L->ci - oldci) + L->base_ci;
  L->end_ci = L->base_ci + L->size_ci - 1;
}


void luaD_growstack (lua_State *L, int n) {
  if (n <= L->stacksize)  /* double size is enough? */
    luaD_reallocstack(L, 2*L->stacksize);
  else
    luaD_reallocstack(L, L->stacksize + n);
}


static CallInfo *growCI (lua_State *L) {
  if (L->size_ci > LUAI_MAXCALLS)  /* overflow while handling overflow? */
    luaD_throw(L, LUA_ERRERR);
  else {
    luaD_reallocCI(L, 2*L->size_ci);
    if (L->size_ci > LUAI_MAXCALLS)
      luaG_runerror(L, "stack overflow");
  }
  return ++L->ci;
}


void luaD_callhook (lua_State *L, int event, int line) {
  lua_Hook hook = L->hook;
  if (hook && L->allowhook) {
    ptrdiff_t top = savestack(L, L->top);
    ptrdiff_t ci_top = savestack(L, L->ci->top);
    lua_Debug ar;
    ar.event = event;
    ar.currentline = line;
    if (event == LUA_HOOKTAILRET)
      ar.i_ci = 0;  /* tail call; no debug information about it */
    else
      ar.i_ci = cast_int(L->ci - L->base_ci);
    luaD_checkstack(L, LUA_MINSTACK);  /* ensure minimum stack size */
    L->ci->top = L->top + LUA_MINSTACK;
    lua_assert(L->ci->top <= L->stack_last);
    L->allowhook = 0;  /* cannot call hooks inside a hook */
    lua_unlock(L);
    (*hook)(L, &ar);
    lua_lock(L);
    lua_assert(!L->allowhook);
    L->allowhook = 1;
    L->ci->top = restorestack(L, ci_top);
    L->top = restorestack(L, top);
  }
}


static StkId adjust_varargs (lua_State *L, Proto *p, int actual) {
  int i;
  int nfixargs = p->numparams;
  Table *htab = NULL;
  StkId base, fixed;
  for (; actual < nfixargs; ++actual)
    setnilvalue(L->top++);
#if defined(LUA_COMPAT_VARARG)
  if (p->is_vararg & VARARG_NEEDSARG) { /* compat. with old-style vararg? */
    int nvar = actual - nfixargs;  /* number of extra arguments */
    lua_assert(p->is_vararg & VARARG_HASARG);
    luaC_checkGC(L);
    htab = luaH_new(L, nvar, 1);  /* create `arg' table */
    for (i=0; i<nvar; i++)  /* put extra arguments into `arg' table */
      setobj2n(L, luaH_setnum(L, htab, i+1), L->top - nvar + i);
    /* store counter in field `n' */
    setnvalue(luaH_setstr(L, htab, luaS_newliteral(L, "n")), cast_num(nvar));
  }
#endif
  /* move fixed parameters to final position */
  fixed = L->top - actual;  /* first fixed argument */
  base = L->top;  /* final position of first argument */
  for (i=0; i<nfixargs; i++) {
    setobjs2s(L, L->top++, fixed+i);
    setnilvalue(fixed+i);
  }
  /* add `arg' parameter */
  if (htab) {
    sethvalue(L, L->top++, htab);
    lua_assert(iswhite(obj2gco(htab)));
  }
  return base;
}


static StkId tryfuncTM (lua_State *L, StkId func) {
  const TValue *tm = luaT_gettmbyobj(L, func, TM_CALL);
  StkId p;
  ptrdiff_t funcr = savestack(L, func);
  if (!ttisfunction(tm))
    luaG_typeerror(L, func, "call");
  /* Open a hole inside the stack at `func' */
  for (p = L->top; p > func; p--) setobjs2s(L, p, p-1);
  incr_top(L);
  func = restorestack(L, funcr);  /* previous call may change stack */
  setobj2s(L, func, tm);  /* tag method is the new function to be called */
  return func;
}



#define inc_ci(L) \
  ((L->ci == L->end_ci) ? growCI(L) : \
   (condhardstacktests(luaD_reallocCI(L, L->size_ci)), ++L->ci))


int luaD_precall (lua_State *L, StkId func, int nresults) {
  LClosure *cl;
  ptrdiff_t funcr;
  if (!ttisfunction(func)) /* `func' is not a function? */
    func = tryfuncTM(L, func);  /* check the `function' tag method */
  funcr = savestack(L, func);
  cl = &clvalue(func)->l;
  L->ci->savedpc = L->savedpc;
  if (!cl->isC) {  /* Lua function? prepare its call */
    CallInfo *ci;
    StkId st, base;
    Proto *p = cl->p;
    luaD_checkstack(L, p->maxstacksize);
    func = restorestack(L, funcr);
    if (!p->is_vararg) {  /* no varargs? */
      base = func + 1;
      if (L->top > base + p->numparams)
        L->top = base + p->numparams;
    }
    else {  /* vararg function */
      int nargs = cast_int(L->top - func) - 1;
      base = adjust_varargs(L, p, nargs);
      func = restorestack(L, funcr);  /* previous call may change the stack */
    }
    ci = inc_ci(L);  /* now `enter' new function */
    ci->func = func;
    L->base = ci->base = base;
    ci->top = L->base + p->maxstacksize;
    lua_assert(ci->top <= L->stack_last);
    L->savedpc = p->code;  /* starting point */
    ci->tailcalls = 0;
    ci->nresults = nresults;
    for (st = L->top; st < ci->top; st++)
      setnilvalue(st);
    L->top = ci->top;
    if (L->hookmask & LUA_MASKCALL) {
      L->savedpc++;  /* hooks assume 'pc' is already incremented */
      luaD_callhook(L, LUA_HOOKCALL, -1);
      L->savedpc--;  /* correct 'pc' */
    }
    return PCRLUA;
  }
  else {  /* if is a C function, call it */
    CallInfo *ci;
    int n;
    luaD_checkstack(L, LUA_MINSTACK);  /* ensure minimum stack size */
    ci = inc_ci(L);  /* now `enter' new function */
    ci->func = restorestack(L, funcr);
    L->base = ci->base = ci->func + 1;
    ci->top = L->top + LUA_MINSTACK;
    lua_assert(ci->top <= L->stack_last);
    ci->nresults = nresults;
    if (L->hookmask & LUA_MASKCALL)
      luaD_callhook(L, LUA_HOOKCALL, -1);
    lua_unlock(L);
    n = (*curr_func(L)->c.f)(L);  /* do the actual call */
    lua_lock(L);
    if (n < 0)  /* yielding? */
      return PCRYIELD;
    else {
      luaD_poscall(L, L->top - n);
      return PCRC;
    }
  }
}


static StkId callrethooks (lua_State *L, StkId firstResult) {
  ptrdiff_t fr = savestack(L, firstResult);  /* next call may change stack */
  luaD_callhook(L, LUA_HOOKRET, -1);
  if (f_isLua(L->ci)) {  /* Lua function? */
    while (L->ci->tailcalls--)  /* call hook for eventual tail calls */
      luaD_callhook(L, LUA_HOOKTAILRET, -1);
  }
  return restorestack(L, fr);
}


int luaD_poscall (lua_State *L, StkId firstResult) {
  StkId res;
  int wanted, i;
  CallInfo *ci;
  if (L->hookmask & LUA_MASKRET)
    firstResult = callrethooks(L, firstResult);
  ci = L->ci--;
  res = ci->func;  /* res == final position of 1st result */
  wanted = ci->nresults;
  L->base = (ci - 1)->base;  /* restore base */
  L->savedpc = (ci - 1)->savedpc;  /* restore savedpc */
  /* move results to correct place */
  for (i = wanted; i != 0 && firstResult < L->top; i--)
    setobjs2s(L, res++, firstResult++);
  while (i-- > 0)
    setnilvalue(res++);
  L->top = res;
  return (wanted - LUA_MULTRET);  /* 0 iff wanted == LUA_MULTRET */
}


/*
** Call a function (C or Lua). The function to be called is at *func.
** The arguments are on the stack, right after the function.
** When returns, all the results are on the stack, starting at the original
** function position.
*/ 
void luaD_call (lua_State *L, StkId func, int nResults) {
  if (++L->nCcalls >= LUAI_MAXCCALLS) {
    if (L->nCcalls == LUAI_MAXCCALLS)
      luaG_runerror(L, "C stack overflow");
    else if (L->nCcalls >= (LUAI_MAXCCALLS + (LUAI_MAXCCALLS>>3)))
      luaD_throw(L, LUA_ERRERR);  /* error while handing stack error */
  }
  if (luaD_precall(L, func, nResults) == PCRLUA)  /* is a Lua function? */
    luaV_execute(L, 1);  /* call it */
  L->nCcalls--;
  luaC_checkGC(L);
}


static void resume (lua_State *L, void *ud) {
  StkId firstArg = cast(StkId, ud);
  CallInfo *ci = L->ci;
  if (L->status == 0) {  /* start coroutine? */
    lua_assert(ci == L->base_ci && firstArg > L->base);
    if (luaD_precall(L, firstArg - 1, LUA_MULTRET) != PCRLUA)
      return;
  }
  else {  /* resuming from previous yield */
    lua_assert(L->status == LUA_YIELD);
    L->status = 0;
    if (!f_isLua(ci)) {  /* `common' yield? */
      /* finish interrupted execution of `OP_CALL' */
      lua_assert(GET_OPCODE(*((ci-1)->savedpc - 1)) == OP_CALL ||
                 GET_OPCODE(*((ci-1)->savedpc - 1)) == OP_TAILCALL);
      if (luaD_poscall(L, firstArg))  /* complete it... */
        L->top = L->ci->top;  /* and correct top if not multiple results */
    }
    else  /* yielded inside a hook: just continue its execution */
      L->base = L->ci->base;
  }
  luaV_execute(L, cast_int(L->ci - L->base_ci));
}


static int resume_error (lua_State *L, const char *msg) {
  L->top = L->ci->base;
  setsvalue2s(L, L->top, luaS_new(L, msg));
  incr_top(L);
  lua_unlock(L);
  return LUA_ERRRUN;
}


LUA_API int lua_resume (lua_State *L, int nargs) {
  int status;
  lua_lock(L);
  if (L->status != LUA_YIELD) {
    if (L->status != 0)
      return resume_error(L, "cannot resume dead coroutine");
    else if (L->ci != L->base_ci)
      return resume_error(L, "cannot resume non-suspended coroutine");
  }
  luai_userstateresume(L, nargs);
  lua_assert(L->errfunc == 0 && L->nCcalls == 0);
  status = luaD_rawrunprotected(L, resume, L->top - nargs);
  if (status != 0) {  /* error? */
    L->status = cast_byte(status);  /* mark thread as `dead' */
    luaD_seterrorobj(L, status, L->top);
    L->ci->top = L->top;
  }
  else
    status = L->status;
  lua_unlock(L);
  return status;
}


LUA_API int lua_yield (lua_State *L, int nresults) {
  luai_userstateyield(L, nresults);
  lua_lock(L);
  if (L->nCcalls > 0)
    luaG_runerror(L, "attempt to yield across metamethod/C-call boundary");
  L->base = L->top - nresults;  /* protect stack slots below */
  L->status = LUA_YIELD;
  lua_unlock(L);
  return -1;
}


int luaD_pcall (lua_State *L, Pfunc func, void *u,
                ptrdiff_t old_top, ptrdiff_t ef) {
  int status;
  unsigned short oldnCcalls = L->nCcalls;
  ptrdiff_t old_ci = saveci(L, L->ci);
  lu_byte old_allowhooks = L->allowhook;
  ptrdiff_t old_errfunc = L->errfunc;
  L->errfunc = ef;
  status = luaD_rawrunprotected(L, func, u);
  if (status != 0) {  /* an error occurred? */
    StkId oldtop = restorestack(L, old_top);
    luaF_close(L, oldtop);  /* close eventual pending closures */
    luaD_seterrorobj(L, status, oldtop);
    L->nCcalls = oldnCcalls;
    L->ci = restoreci(L, old_ci);
    L->base = L->ci->base;
    L->savedpc = L->ci->savedpc;
    L->allowhook = old_allowhooks;
    restore_stack_limit(L);
  }
  L->errfunc = old_errfunc;
  return status;
}



/*
** Execute a protected parser.
*/
struct SParser {  /* data to `f_parser' */
  ZIO *z;
  Mbuffer buff;  /* buffer to be used by the scanner */
  const char *name;
};

static void f_parser (lua_State *L, void *ud) {
  int i;
  Proto *tf;
  Closure *cl;
  struct SParser *p = cast(struct SParser *, ud);
  int c = luaZ_lookahead(p->z);
  luaC_checkGC(L);
  tf = ((c == LUA_SIGNATURE[0]) ? luaU_undump : luaY_parser)(L, p->z,
                                                             &p->buff, p->name);
  cl = luaF_newLclosure(L, tf->nups, hvalue(gt(L)));
  cl->l.p = tf;
  for (i = 0; i < tf->nups; i++)  /* initialize eventual upvalues */
    cl->l.upvals[i] = luaF_newupval(L);
  setclvalue(L, L->top, cl);
  incr_top(L);
}


int luaD_protectedparser (lua_State *L, ZIO *z, const char *name) {
  struct SParser p;
  int status;
  p.z = z; p.name = name;
  luaZ_initbuffer(L, &p.buff);
  status = luaD_pcall(L, f_parser, &p, savestack(L, L->top), L->errfunc);
  luaZ_freebuffer(L, &p.buff);
  return status;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ldblib.c ===
/*
** $Id: ldblib.c,v 1.104 2005/12/29 15:32:11 roberto Exp $
** Interface from Lua to its debug API
** See Copyright Notice in lua.h
*/


#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define ldblib_c
#define LUA_LIB

#include "lua.h"

#include "lauxlib.h"
#include "lualib.h"



static int db_getregistry (lua_State *L) {
  lua_pushvalue(L, LUA_REGISTRYINDEX);
  return 1;
}


static int db_getmetatable (lua_State *L) {
  luaL_checkany(L, 1);
  if (!lua_getmetatable(L, 1)) {
    lua_pushnil(L);  /* no metatable */
  }
  return 1;
}


static int db_setmetatable (lua_State *L) {
  int t = lua_type(L, 2);
  luaL_argcheck(L, t == LUA_TNIL || t == LUA_TTABLE, 2,
                    "nil or table expected");
  lua_settop(L, 2);
  lua_pushboolean(L, lua_setmetatable(L, 1));
  return 1;
}


static int db_getfenv (lua_State *L) {
  lua_getfenv(L, 1);
  return 1;
}


static int db_setfenv (lua_State *L) {
  luaL_checktype(L, 2, LUA_TTABLE);
  lua_settop(L, 2);
  if (lua_setfenv(L, 1) == 0)
    luaL_error(L, LUA_QL("setfenv")
                  " cannot change environment of given object");
  return 1;
}


static void settabss (lua_State *L, const char *i, const char *v) {
  lua_pushstring(L, v);
  lua_setfield(L, -2, i);
}


static void settabsi (lua_State *L, const char *i, int v) {
  lua_pushinteger(L, v);
  lua_setfield(L, -2, i);
}


static lua_State *getthread (lua_State *L, int *arg) {
  if (lua_isthread(L, 1)) {
    *arg = 1;
    return lua_tothread(L, 1);
  }
  else {
    *arg = 0;
    return L;
  }
}


static void treatstackoption (lua_State *L, lua_State *L1, const char *fname) {
  if (L == L1) {
    lua_pushvalue(L, -2);
    lua_remove(L, -3);
  }
  else
    lua_xmove(L1, L, 1);
  lua_setfield(L, -2, fname);
}


static int db_getinfo (lua_State *L) {
  lua_Debug ar;
  int arg;
  lua_State *L1 = getthread(L, &arg);
  const char *options = luaL_optstring(L, arg+2, "flnSu");
  if (lua_isnumber(L, arg+1)) {
    if (!lua_getstack(L1, (int)lua_tointeger(L, arg+1), &ar)) {
      lua_pushnil(L);  /* level out of range */
      return 1;
    }
  }
  else if (lua_isfunction(L, arg+1)) {
    lua_pushfstring(L, ">%s", options);
    options = lua_tostring(L, -1);
    lua_pushvalue(L, arg+1);
    lua_xmove(L, L1, 1);
  }
  else
    return luaL_argerror(L, arg+1, "function or level expected");
  if (!lua_getinfo(L1, options, &ar))
    return luaL_argerror(L, arg+2, "invalid option");
  lua_createtable(L, 0, 2);
  if (strchr(options, 'S')) {
    settabss(L, "source", ar.source);
    settabss(L, "short_src", ar.short_src);
    settabsi(L, "linedefined", ar.linedefined);
    settabsi(L, "lastlinedefined", ar.lastlinedefined);
    settabss(L, "what", ar.what);
  }
  if (strchr(options, 'l'))
    settabsi(L, "currentline", ar.currentline);
  if (strchr(options, 'u'))
    settabsi(L, "nups", ar.nups);
  if (strchr(options, 'n')) {
    settabss(L, "name", ar.name);
    settabss(L, "namewhat", ar.namewhat);
  }
  if (strchr(options, 'L'))
    treatstackoption(L, L1, "activelines");
  if (strchr(options, 'f'))
    treatstackoption(L, L1, "func");
  return 1;  /* return table */
}
    

static int db_getlocal (lua_State *L) {
  int arg;
  lua_State *L1 = getthread(L, &arg);
  lua_Debug ar;
  const char *name;
  if (!lua_getstack(L1, luaL_checkint(L, arg+1), &ar))  /* out of range? */
    return luaL_argerror(L, arg+1, "level out of range");
  name = lua_getlocal(L1, &ar, luaL_checkint(L, arg+2));
  if (name) {
    lua_xmove(L1, L, 1);
    lua_pushstring(L, name);
    lua_pushvalue(L, -2);
    return 2;
  }
  else {
    lua_pushnil(L);
    return 1;
  }
}


static int db_setlocal (lua_State *L) {
  int arg;
  lua_State *L1 = getthread(L, &arg);
  lua_Debug ar;
  if (!lua_getstack(L1, luaL_checkint(L, arg+1), &ar))  /* out of range? */
    return luaL_argerror(L, arg+1, "level out of range");
  luaL_checkany(L, arg+3);
  lua_settop(L, arg+3);
  lua_xmove(L, L1, 1);
  lua_pushstring(L, lua_setlocal(L1, &ar, luaL_checkint(L, arg+2)));
  return 1;
}


static int auxupvalue (lua_State *L, int get) {
  const char *name;
  int n = luaL_checkint(L, 2);
  luaL_checktype(L, 1, LUA_TFUNCTION);
  if (lua_iscfunction(L, 1)) return 0;  /* cannot touch C upvalues from Lua */
  name = get ? lua_getupvalue(L, 1, n) : lua_setupvalue(L, 1, n);
  if (name == NULL) return 0;
  lua_pushstring(L, name);
  lua_insert(L, -(get+1));
  return get + 1;
}


static int db_getupvalue (lua_State *L) {
  return auxupvalue(L, 1);
}


static int db_setupvalue (lua_State *L) {
  luaL_checkany(L, 3);
  return auxupvalue(L, 0);
}



static const char KEY_HOOK = 'h';


static void hookf (lua_State *L, lua_Debug *ar) {
  static const char *const hooknames[] =
    {"call", "return", "line", "count", "tail return"};
  lua_pushlightuserdata(L, (void *)&KEY_HOOK);
  lua_rawget(L, LUA_REGISTRYINDEX);
  lua_pushlightuserdata(L, L);
  lua_rawget(L, -2);
  if (lua_isfunction(L, -1)) {
    lua_pushstring(L, hooknames[(int)ar->event]);
    if (ar->currentline >= 0)
      lua_pushinteger(L, ar->currentline);
    else lua_pushnil(L);
    lua_assert(lua_getinfo(L, "lS", ar));
    lua_call(L, 2, 0);
  }
}


static int makemask (const char *smask, int count) {
  int mask = 0;
  if (strchr(smask, 'c')) mask |= LUA_MASKCALL;
  if (strchr(smask, 'r')) mask |= LUA_MASKRET;
  if (strchr(smask, 'l')) mask |= LUA_MASKLINE;
  if (count > 0) mask |= LUA_MASKCOUNT;
  return mask;
}


static char *unmakemask (int mask, char *smask) {
  int i = 0;
  if (mask & LUA_MASKCALL) smask[i++] = 'c';
  if (mask & LUA_MASKRET) smask[i++] = 'r';
  if (mask & LUA_MASKLINE) smask[i++] = 'l';
  smask[i] = '\0';
  return smask;
}


static void gethooktable (lua_State *L) {
  lua_pushlightuserdata(L, (void *)&KEY_HOOK);
  lua_rawget(L, LUA_REGISTRYINDEX);
  if (!lua_istable(L, -1)) {
    lua_pop(L, 1);
    lua_createtable(L, 0, 1);
    lua_pushlightuserdata(L, (void *)&KEY_HOOK);
    lua_pushvalue(L, -2);
    lua_rawset(L, LUA_REGISTRYINDEX);
  }
}


static int db_sethook (lua_State *L) {
  int arg;
  lua_State *L1 = getthread(L, &arg);
  if (lua_isnoneornil(L, arg+1)) {
    lua_settop(L, arg+1);
    lua_sethook(L1, NULL, 0, 0);  /* turn off hooks */
  }
  else {
    const char *smask = luaL_checkstring(L, arg+2);
    int count = luaL_optint(L, arg+3, 0);
    luaL_checktype(L, arg+1, LUA_TFUNCTION);
    lua_sethook(L1, hookf, makemask(smask, count), count);
  }
  gethooktable(L1);
  lua_pushlightuserdata(L1, L1);
  lua_pushvalue(L, arg+1);
  lua_xmove(L, L1, 1);
  lua_rawset(L1, -3);  /* set new hook */
  lua_pop(L1, 1);  /* remove hook table */
  return 0;
}


static int db_gethook (lua_State *L) {
  int arg;
  lua_State *L1 = getthread(L, &arg);
  char buff[5];
  int mask = lua_gethookmask(L1);
  lua_Hook hook = lua_gethook(L1);
  if (hook != NULL && hook != hookf)  /* external hook? */
    lua_pushliteral(L, "external hook");
  else {
    gethooktable(L1);
    lua_pushlightuserdata(L1, L1);
    lua_rawget(L1, -2);   /* get hook */
    lua_remove(L1, -2);  /* remove hook table */
    lua_xmove(L1, L, 1);
  }
  lua_pushstring(L, unmakemask(mask, buff));
  lua_pushinteger(L, lua_gethookcount(L1));
  return 3;
}


static int db_debug (lua_State *L) {
  for (;;) {
    char buffer[250];
    fputs("lua_debug> ", stderr);
    if (fgets(buffer, sizeof(buffer), stdin) == 0 ||
        strcmp(buffer, "cont\n") == 0)
      return 0;
    if (luaL_loadbuffer(L, buffer, strlen(buffer), "=(debug command)") ||
        lua_pcall(L, 0, 0, 0)) {
      fputs(lua_tostring(L, -1), stderr);
      fputs("\n", stderr);
    }
    lua_settop(L, 0);  /* remove eventual returns */
  }
}


#define LEVELS1	12	/* size of the first part of the stack */
#define LEVELS2	10	/* size of the second part of the stack */

static int db_errorfb (lua_State *L) {
  int level;
  int firstpart = 1;  /* still before eventual `...' */
  int arg;
  lua_State *L1 = getthread(L, &arg);
  lua_Debug ar;
  if (lua_isnumber(L, arg+2)) {
    level = (int)lua_tointeger(L, arg+2);
    lua_pop(L, 1);
  }
  else
    level = (L == L1) ? 1 : 0;  /* level 0 may be this own function */
  if (lua_gettop(L) == arg)
    lua_pushliteral(L, "");
  else if (!lua_isstring(L, arg+1)) return 1;  /* message is not a string */
  else lua_pushliteral(L, "\n");
  lua_pushliteral(L, "stack traceback:");
  while (lua_getstack(L1, level++, &ar)) {
    if (level > LEVELS1 && firstpart) {
      /* no more than `LEVELS2' more levels? */
      if (!lua_getstack(L1, level+LEVELS2, &ar))
        level--;  /* keep going */
      else {
        lua_pushliteral(L, "\n\t...");  /* too many levels */
        while (lua_getstack(L1, level+LEVELS2, &ar))  /* find last levels */
          level++;
      }
      firstpart = 0;
      continue;
    }
    lua_pushliteral(L, "\n\t");
    lua_getinfo(L1, "Snl", &ar);
    lua_pushfstring(L, "%s:", ar.short_src);
    if (ar.currentline > 0)
      lua_pushfstring(L, "%d:", ar.currentline);
    if (*ar.namewhat != '\0')  /* is there a name? */
        lua_pushfstring(L, " in function " LUA_QS, ar.name);
    else {
      if (*ar.what == 'm')  /* main? */
        lua_pushfstring(L, " in main chunk");
      else if (*ar.what == 'C' || *ar.what == 't')
        lua_pushliteral(L, " ?");  /* C function or tail call */
      else
        lua_pushfstring(L, " in function <%s:%d>",
                           ar.short_src, ar.linedefined);
    }
    lua_concat(L, lua_gettop(L) - arg);
  }
  lua_concat(L, lua_gettop(L) - arg);
  return 1;
}


static const luaL_Reg dblib[] = {
  {"debug", db_debug},
  {"getfenv", db_getfenv},
  {"gethook", db_gethook},
  {"getinfo", db_getinfo},
  {"getlocal", db_getlocal},
  {"getregistry", db_getregistry},
  {"getmetatable", db_getmetatable},
  {"getupvalue", db_getupvalue},
  {"setfenv", db_setfenv},
  {"sethook", db_sethook},
  {"setlocal", db_setlocal},
  {"setmetatable", db_setmetatable},
  {"setupvalue", db_setupvalue},
  {"traceback", db_errorfb},
  {NULL, NULL}
};


LUALIB_API int luaopen_debug (lua_State *L) {
  luaL_register(L, LUA_DBLIBNAME, dblib);
  return 1;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ldo.h ===
/*
** $Id: ldo.h,v 2.7 2005/08/24 16:15:49 roberto Exp $
** Stack and Call structure of Lua
** See Copyright Notice in lua.h
*/

#ifndef ldo_h
#define ldo_h


#include "lobject.h"
#include "lstate.h"
#include "lzio.h"


#define luaD_checkstack(L,n)	\
  if ((char *)L->stack_last - (char *)L->top <= (n)*(int)sizeof(TValue)) \
    luaD_growstack(L, n); \
  else condhardstacktests(luaD_reallocstack(L, L->stacksize - EXTRA_STACK - 1));


#define incr_top(L) {luaD_checkstack(L,1); L->top++;}

#define savestack(L,p)		((char *)(p) - (char *)L->stack)
#define restorestack(L,n)	((TValue *)((char *)L->stack + (n)))

#define saveci(L,p)		((char *)(p) - (char *)L->base_ci)
#define restoreci(L,n)		((CallInfo *)((char *)L->base_ci + (n)))


/* results from luaD_precall */
#define PCRLUA		0	/* initiated a call to a Lua function */
#define PCRC		1	/* did a call to a C function */
#define PCRYIELD	2	/* C funtion yielded */


/* type of protected functions, to be ran by `runprotected' */
typedef void (*Pfunc) (lua_State *L, void *ud);

LUAI_FUNC int luaD_protectedparser (lua_State *L, ZIO *z, const char *name);
LUAI_FUNC void luaD_callhook (lua_State *L, int event, int line);
LUAI_FUNC int luaD_precall (lua_State *L, StkId func, int nresults);
LUAI_FUNC void luaD_call (lua_State *L, StkId func, int nResults);
LUAI_FUNC int luaD_pcall (lua_State *L, Pfunc func, void *u,
                                        ptrdiff_t oldtop, ptrdiff_t ef);
LUAI_FUNC int luaD_poscall (lua_State *L, StkId firstResult);
LUAI_FUNC void luaD_reallocCI (lua_State *L, int newsize);
LUAI_FUNC void luaD_reallocstack (lua_State *L, int newsize);
LUAI_FUNC void luaD_growstack (lua_State *L, int n);

LUAI_FUNC void luaD_throw (lua_State *L, int errcode);
LUAI_FUNC int luaD_rawrunprotected (lua_State *L, Pfunc f, void *ud);

LUAI_FUNC void luaD_seterrorobj (lua_State *L, int errcode, StkId oldtop);

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lfunc.h ===
/*
** $Id: lfunc.h,v 2.4 2005/04/25 19:24:10 roberto Exp $
** Auxiliary functions to manipulate prototypes and closures
** See Copyright Notice in lua.h
*/

#ifndef lfunc_h
#define lfunc_h


#include "lobject.h"


#define sizeCclosure(n)	(cast(int, sizeof(CClosure)) + \
                         cast(int, sizeof(TValue)*((n)-1)))

#define sizeLclosure(n)	(cast(int, sizeof(LClosure)) + \
                         cast(int, sizeof(TValue *)*((n)-1)))


LUAI_FUNC Proto *luaF_newproto (lua_State *L);
LUAI_FUNC Closure *luaF_newCclosure (lua_State *L, int nelems, Table *e);
LUAI_FUNC Closure *luaF_newLclosure (lua_State *L, int nelems, Table *e);
LUAI_FUNC UpVal *luaF_newupval (lua_State *L);
LUAI_FUNC UpVal *luaF_findupval (lua_State *L, StkId level);
LUAI_FUNC void luaF_close (lua_State *L, StkId level);
LUAI_FUNC void luaF_freeproto (lua_State *L, Proto *f);
LUAI_FUNC void luaF_freeclosure (lua_State *L, Closure *c);
LUAI_FUNC void luaF_freeupval (lua_State *L, UpVal *uv);
LUAI_FUNC const char *luaF_getlocalname (const Proto *func, int local_number,
                                         int pc);


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lfunc.c ===
/*
** $Id: lfunc.c,v 2.12 2005/12/22 16:19:56 roberto Exp $
** Auxiliary functions to manipulate prototypes and closures
** See Copyright Notice in lua.h
*/


#include <stddef.h>

#define lfunc_c
#define LUA_CORE

#include "lua.h"

#include "lfunc.h"
#include "lgc.h"
#include "lmem.h"
#include "lobject.h"
#include "lstate.h"



Closure *luaF_newCclosure (lua_State *L, int nelems, Table *e) {
  Closure *c = cast(Closure *, luaM_malloc(L, sizeCclosure(nelems)));
  luaC_link(L, obj2gco(c), LUA_TFUNCTION);
  c->c.isC = 1;
  c->c.env = e;
  c->c.nupvalues = cast_byte(nelems);
  return c;
}


Closure *luaF_newLclosure (lua_State *L, int nelems, Table *e) {
  Closure *c = cast(Closure *, luaM_malloc(L, sizeLclosure(nelems)));
  luaC_link(L, obj2gco(c), LUA_TFUNCTION);
  c->l.isC = 0;
  c->l.env = e;
  c->l.nupvalues = cast_byte(nelems);
  while (nelems--) c->l.upvals[nelems] = NULL;
  return c;
}


UpVal *luaF_newupval (lua_State *L) {
  UpVal *uv = luaM_new(L, UpVal);
  luaC_link(L, obj2gco(uv), LUA_TUPVAL);
  uv->v = &uv->u.value;
  setnilvalue(uv->v);
  return uv;
}


UpVal *luaF_findupval (lua_State *L, StkId level) {
  global_State *g = G(L);
  GCObject **pp = &L->openupval;
  UpVal *p;
  UpVal *uv;
  while ((p = ngcotouv(*pp)) != NULL && p->v >= level) {
    lua_assert(p->v != &p->u.value);
    if (p->v == level) {  /* found a corresponding upvalue? */
      if (isdead(g, obj2gco(p)))  /* is it dead? */
        changewhite(obj2gco(p));  /* ressurect it */
      return p;
    }
    pp = &p->next;
  }
  uv = luaM_new(L, UpVal);  /* not found: create a new one */
  uv->tt = LUA_TUPVAL;
  uv->marked = luaC_white(g);
  uv->v = level;  /* current value lives in the stack */
  uv->next = *pp;  /* chain it in the proper position */
  *pp = obj2gco(uv);
  uv->u.l.prev = &g->uvhead;  /* double link it in `uvhead' list */
  uv->u.l.next = g->uvhead.u.l.next;
  uv->u.l.next->u.l.prev = uv;
  g->uvhead.u.l.next = uv;
  lua_assert(uv->u.l.next->u.l.prev == uv && uv->u.l.prev->u.l.next == uv);
  return uv;
}


static void unlinkupval (UpVal *uv) {
  lua_assert(uv->u.l.next->u.l.prev == uv && uv->u.l.prev->u.l.next == uv);
  uv->u.l.next->u.l.prev = uv->u.l.prev;  /* remove from `uvhead' list */
  uv->u.l.prev->u.l.next = uv->u.l.next;
}


void luaF_freeupval (lua_State *L, UpVal *uv) {
  if (uv->v != &uv->u.value)  /* is it open? */
    unlinkupval(uv);  /* remove from open list */
  luaM_free(L, uv);  /* free upvalue */
}


void luaF_close (lua_State *L, StkId level) {
  UpVal *uv;
  global_State *g = G(L);
  while ((uv = ngcotouv(L->openupval)) != NULL && uv->v >= level) {
    GCObject *o = obj2gco(uv);
    lua_assert(!isblack(o) && uv->v != &uv->u.value);
    L->openupval = uv->next;  /* remove from `open' list */
    if (isdead(g, o))
      luaF_freeupval(L, uv);  /* free upvalue */
    else {
      unlinkupval(uv);
      setobj(L, &uv->u.value, uv->v);
      uv->v = &uv->u.value;  /* now current value lives here */
      luaC_linkupval(L, uv);  /* link upvalue into `gcroot' list */
    }
  }
}


Proto *luaF_newproto (lua_State *L) {
  Proto *f = luaM_new(L, Proto);
  luaC_link(L, obj2gco(f), LUA_TPROTO);
  f->k = NULL;
  f->sizek = 0;
  f->p = NULL;
  f->sizep = 0;
  f->code = NULL;
  f->sizecode = 0;
  f->sizelineinfo = 0;
  f->sizeupvalues = 0;
  f->nups = 0;
  f->upvalues = NULL;
  f->numparams = 0;
  f->is_vararg = 0;
  f->maxstacksize = 0;
  f->lineinfo = NULL;
  f->sizelocvars = 0;
  f->locvars = NULL;
  f->linedefined = 0;
  f->lastlinedefined = 0;
  f->source = NULL;
  return f;
}


void luaF_freeproto (lua_State *L, Proto *f) {
  luaM_freearray(L, f->code, f->sizecode, Instruction);
  luaM_freearray(L, f->p, f->sizep, Proto *);
  luaM_freearray(L, f->k, f->sizek, TValue);
  luaM_freearray(L, f->lineinfo, f->sizelineinfo, int);
  luaM_freearray(L, f->locvars, f->sizelocvars, struct LocVar);
  luaM_freearray(L, f->upvalues, f->sizeupvalues, TString *);
  luaM_free(L, f);
}


void luaF_freeclosure (lua_State *L, Closure *c) {
  int size = (c->c.isC) ? sizeCclosure(c->c.nupvalues) :
                          sizeLclosure(c->l.nupvalues);
  luaM_freemem(L, c, size);
}


/*
** Look for n-th local variable at line `line' in function `func'.
** Returns NULL if not found.
*/
const char *luaF_getlocalname (const Proto *f, int local_number, int pc) {
  int i;
  for (i = 0; i<f->sizelocvars && f->locvars[i].startpc <= pc; i++) {
    if (pc < f->locvars[i].endpc) {  /* is variable active? */
      local_number--;
      if (local_number == 0)
        return getstr(f->locvars[i].varname);
    }
  }
  return NULL;  /* not found */
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\linit.c ===
/*
** $Id: linit.c,v 1.14 2005/12/29 15:32:11 roberto Exp $
** Initialization of libraries for lua.c
** See Copyright Notice in lua.h
*/


#define linit_c
#define LUA_LIB

#include "lua.h"

#include "lualib.h"
#include "lauxlib.h"


static const luaL_Reg lualibs[] = {
  {"", luaopen_base},
  {LUA_LOADLIBNAME, luaopen_package},
  {LUA_TABLIBNAME, luaopen_table},
  {LUA_IOLIBNAME, luaopen_io},
  {LUA_OSLIBNAME, luaopen_os},
  {LUA_STRLIBNAME, luaopen_string},
  {LUA_MATHLIBNAME, luaopen_math},
  {LUA_DBLIBNAME, luaopen_debug},
  {NULL, NULL}
};


LUALIB_API void luaL_openlibs (lua_State *L) {
  const luaL_Reg *lib = lualibs;
  for (; lib->func; lib++) {
    lua_pushcfunction(L, lib->func);
    lua_pushstring(L, lib->name);
    lua_call(L, 1, 0);
  }
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lgc.h ===
/*
** $Id: lgc.h,v 2.15 2005/08/24 16:15:49 roberto Exp $
** Garbage Collector
** See Copyright Notice in lua.h
*/

#ifndef lgc_h
#define lgc_h


#include "lobject.h"


/*
** Possible states of the Garbage Collector
*/
#define GCSpause	0
#define GCSpropagate	1
#define GCSsweepstring	2
#define GCSsweep	3
#define GCSfinalize	4


/*
** some userful bit tricks
*/
#define resetbits(x,m)	((x) &= cast(lu_byte, ~(m)))
#define setbits(x,m)	((x) |= (m))
#define testbits(x,m)	((x) & (m))
#define bitmask(b)	(1<<(b))
#define bit2mask(b1,b2)	(bitmask(b1) | bitmask(b2))
#define l_setbit(x,b)	setbits(x, bitmask(b))
#define resetbit(x,b)	resetbits(x, bitmask(b))
#define testbit(x,b)	testbits(x, bitmask(b))
#define set2bits(x,b1,b2)	setbits(x, (bit2mask(b1, b2)))
#define reset2bits(x,b1,b2)	resetbits(x, (bit2mask(b1, b2)))
#define test2bits(x,b1,b2)	testbits(x, (bit2mask(b1, b2)))



/*
** Layout for bit use in `marked' field:
** bit 0 - object is white (type 0)
** bit 1 - object is white (type 1)
** bit 2 - object is black
** bit 3 - for userdata: has been finalized
** bit 3 - for tables: has weak keys
** bit 4 - for tables: has weak values
** bit 5 - object is fixed (should not be collected)
** bit 6 - object is "super" fixed (only the main thread)
*/


#define WHITE0BIT	0
#define WHITE1BIT	1
#define BLACKBIT	2
#define FINALIZEDBIT	3
#define KEYWEAKBIT	3
#define VALUEWEAKBIT	4
#define FIXEDBIT	5
#define SFIXEDBIT	6
#define WHITEBITS	bit2mask(WHITE0BIT, WHITE1BIT)


#define iswhite(x)      test2bits((x)->gch.marked, WHITE0BIT, WHITE1BIT)
#define isblack(x)      testbit((x)->gch.marked, BLACKBIT)
#define isgray(x)	(!isblack(x) && !iswhite(x))

#define otherwhite(g)	(g->currentwhite ^ WHITEBITS)
#define isdead(g,v)	((v)->gch.marked & otherwhite(g) & WHITEBITS)

#define changewhite(x)	((x)->gch.marked ^= WHITEBITS)
#define gray2black(x)	l_setbit((x)->gch.marked, BLACKBIT)

#define valiswhite(x)	(iscollectable(x) && iswhite(gcvalue(x)))

#define luaC_white(g)	cast(lu_byte, (g)->currentwhite & WHITEBITS)


#define luaC_checkGC(L) { \
  condhardstacktests(luaD_reallocstack(L, L->stacksize - EXTRA_STACK - 1)); \
  if (G(L)->totalbytes >= G(L)->GCthreshold) \
	luaC_step(L); }


#define luaC_barrier(L,p,v) { if (valiswhite(v) && isblack(obj2gco(p)))  \
	luaC_barrierf(L,obj2gco(p),gcvalue(v)); }

#define luaC_barriert(L,t,v) { if (valiswhite(v) && isblack(obj2gco(t)))  \
	luaC_barrierback(L,t); }

#define luaC_objbarrier(L,p,o)  \
	{ if (iswhite(obj2gco(o)) && isblack(obj2gco(p))) \
		luaC_barrierf(L,obj2gco(p),obj2gco(o)); }

#define luaC_objbarriert(L,t,o)  \
   { if (iswhite(obj2gco(o)) && isblack(obj2gco(t))) luaC_barrierback(L,t); }

LUAI_FUNC size_t luaC_separateudata (lua_State *L, int all);
LUAI_FUNC void luaC_callGCTM (lua_State *L);
LUAI_FUNC void luaC_freeall (lua_State *L);
LUAI_FUNC void luaC_step (lua_State *L);
LUAI_FUNC void luaC_fullgc (lua_State *L);
LUAI_FUNC void luaC_link (lua_State *L, GCObject *o, lu_byte tt);
LUAI_FUNC void luaC_linkupval (lua_State *L, UpVal *uv);
LUAI_FUNC void luaC_barrierf (lua_State *L, GCObject *o, GCObject *v);
LUAI_FUNC void luaC_barrierback (lua_State *L, Table *t);


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ldump.c ===
/*
** $Id: ldump.c,v 1.15 2006/02/16 15:53:49 lhf Exp $
** save precompiled Lua chunks
** See Copyright Notice in lua.h
*/

#include <stddef.h>

#define ldump_c
#define LUA_CORE

#include "lua.h"

#include "lobject.h"
#include "lstate.h"
#include "lundump.h"

typedef struct {
 lua_State* L;
 lua_Writer writer;
 void* data;
 int strip;
 int status;
} DumpState;

#define DumpMem(b,n,size,D)	DumpBlock(b,(n)*(size),D)
#define DumpVar(x,D)	 	DumpMem(&x,1,sizeof(x),D)

static void DumpBlock(const void* b, size_t size, DumpState* D)
{
 if (D->status==0)
 {
  lua_unlock(D->L);
  D->status=(*D->writer)(D->L,b,size,D->data);
  lua_lock(D->L);
 }
}

static void DumpChar(int y, DumpState* D)
{
 char x=(char)y;
 DumpVar(x,D);
}

static void DumpInt(int x, DumpState* D)
{
 DumpVar(x,D);
}

static void DumpNumber(lua_Number x, DumpState* D)
{
 DumpVar(x,D);
}

static void DumpVector(const void* b, int n, size_t size, DumpState* D)
{
 DumpInt(n,D);
 DumpMem(b,n,size,D);
}

static void DumpString(const TString* s, DumpState* D)
{
 if (s==NULL || getstr(s)==NULL)
 {
  size_t size=0;
  DumpVar(size,D);
 }
 else
 {
  size_t size=s->tsv.len+1;		/* include trailing '\0' */
  DumpVar(size,D);
  DumpBlock(getstr(s),size,D);
 }
}

#define DumpCode(f,D)	 DumpVector(f->code,f->sizecode,sizeof(Instruction),D)

static void DumpFunction(const Proto* f, const TString* p, DumpState* D);

static void DumpConstants(const Proto* f, DumpState* D)
{
 int i,n=f->sizek;
 DumpInt(n,D);
 for (i=0; i<n; i++)
 {
  const TValue* o=&f->k[i];
  DumpChar(ttype(o),D);
  switch (ttype(o))
  {
   case LUA_TNIL:
	break;
   case LUA_TBOOLEAN:
	DumpChar(bvalue(o),D);
	break;
   case LUA_TNUMBER:
	DumpNumber(nvalue(o),D);
	break;
   case LUA_TSTRING:
	DumpString(rawtsvalue(o),D);
	break;
   default:
	lua_assert(0);			/* cannot happen */
	break;
  }
 }
 n=f->sizep;
 DumpInt(n,D);
 for (i=0; i<n; i++) DumpFunction(f->p[i],f->source,D);
}

static void DumpDebug(const Proto* f, DumpState* D)
{
 int i,n;
 n= (D->strip) ? 0 : f->sizelineinfo;
 DumpVector(f->lineinfo,n,sizeof(int),D);
 n= (D->strip) ? 0 : f->sizelocvars;
 DumpInt(n,D);
 for (i=0; i<n; i++)
 {
  DumpString(f->locvars[i].varname,D);
  DumpInt(f->locvars[i].startpc,D);
  DumpInt(f->locvars[i].endpc,D);
 }
 n= (D->strip) ? 0 : f->sizeupvalues;
 DumpInt(n,D);
 for (i=0; i<n; i++) DumpString(f->upvalues[i],D);
}

static void DumpFunction(const Proto* f, const TString* p, DumpState* D)
{
 DumpString((f->source==p || D->strip) ? NULL : f->source,D);
 DumpInt(f->linedefined,D);
 DumpInt(f->lastlinedefined,D);
 DumpChar(f->nups,D);
 DumpChar(f->numparams,D);
 DumpChar(f->is_vararg,D);
 DumpChar(f->maxstacksize,D);
 DumpCode(f,D);
 DumpConstants(f,D);
 DumpDebug(f,D);
}

static void DumpHeader(DumpState* D)
{
 char h[LUAC_HEADERSIZE];
 luaU_header(h);
 DumpBlock(h,LUAC_HEADERSIZE,D);
}

/*
** dump Lua function as precompiled chunk
*/
int luaU_dump (lua_State* L, const Proto* f, lua_Writer w, void* data, int strip)
{
 DumpState D;
 D.L=L;
 D.writer=w;
 D.data=data;
 D.strip=strip;
 D.status=0;
 DumpHeader(&D);
 DumpFunction(f,NULL,&D);
 return D.status;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\llex.c ===
/*
** $Id: llex.c,v 2.20 2006/03/09 18:14:31 roberto Exp $
** Lexical Analyzer
** See Copyright Notice in lua.h
*/


#include <ctype.h>
#include <locale.h>
#include <string.h>

#define llex_c
#define LUA_CORE

#include "lua.h"

#include "ldo.h"
#include "llex.h"
#include "lobject.h"
#include "lparser.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"
#include "lzio.h"



#define next(ls) (ls->current = zgetc(ls->z))




#define currIsNewline(ls)	(ls->current == '\n' || ls->current == '\r')


/* ORDER RESERVED */
const char *const luaX_tokens [] = {
    "and", "break", "do", "else", "elseif",
    "end", "false", "for", "function", "if",
    "in", "local", "nil", "not", "or", "repeat",
    "return", "then", "true", "until", "while",
    "..", "...", "==", ">=", "<=", "~=",
    "<number>", "<name>", "<string>", "<eof>",
    NULL
};


#define save_and_next(ls) (save(ls, ls->current), next(ls))


static void save (LexState *ls, int c) {
  Mbuffer *b = ls->buff;
  if (b->n + 1 > b->buffsize) {
    size_t newsize;
    if (b->buffsize >= MAX_SIZET/2)
      luaX_lexerror(ls, "lexical element too long", 0);
    newsize = b->buffsize * 2;
    luaZ_resizebuffer(ls->L, b, newsize);
  }
  b->buffer[b->n++] = cast(char, c);
}


void luaX_init (lua_State *L) {
  int i;
  for (i=0; i<NUM_RESERVED; i++) {
    TString *ts = luaS_new(L, luaX_tokens[i]);
    luaS_fix(ts);  /* reserved words are never collected */
    lua_assert(strlen(luaX_tokens[i])+1 <= TOKEN_LEN);
    ts->tsv.reserved = cast_byte(i+1);  /* reserved word */
  }
}


#define MAXSRC          80


const char *luaX_token2str (LexState *ls, int token) {
  if (token < FIRST_RESERVED) {
    lua_assert(token == cast(unsigned char, token));
    return (iscntrl(token)) ? luaO_pushfstring(ls->L, "char(%d)", token) :
                              luaO_pushfstring(ls->L, "%c", token);
  }
  else
    return luaX_tokens[token-FIRST_RESERVED];
}


static const char *txtToken (LexState *ls, int token) {
  switch (token) {
    case TK_NAME:
    case TK_STRING:
    case TK_NUMBER:
      save(ls, '\0');
      return luaZ_buffer(ls->buff);
    default:
      return luaX_token2str(ls, token);
  }
}


void luaX_lexerror (LexState *ls, const char *msg, int token) {
  char buff[MAXSRC];
  luaO_chunkid(buff, getstr(ls->source), MAXSRC);
  msg = luaO_pushfstring(ls->L, "%s:%d: %s", buff, ls->linenumber, msg);
  if (token)
    luaO_pushfstring(ls->L, "%s near " LUA_QS, msg, txtToken(ls, token));
  luaD_throw(ls->L, LUA_ERRSYNTAX);
}


void luaX_syntaxerror (LexState *ls, const char *msg) {
  luaX_lexerror(ls, msg, ls->t.token);
}


TString *luaX_newstring (LexState *ls, const char *str, size_t l) {
  lua_State *L = ls->L;
  TString *ts = luaS_newlstr(L, str, l);
  TValue *o = luaH_setstr(L, ls->fs->h, ts);  /* entry for `str' */
  if (ttisnil(o))
    setbvalue(o, 1);  /* make sure `str' will not be collected */
  return ts;
}


static void inclinenumber (LexState *ls) {
  int old = ls->current;
  lua_assert(currIsNewline(ls));
  next(ls);  /* skip `\n' or `\r' */
  if (currIsNewline(ls) && ls->current != old)
    next(ls);  /* skip `\n\r' or `\r\n' */
  if (++ls->linenumber >= MAX_INT)
    luaX_syntaxerror(ls, "chunk has too many lines");
}


void luaX_setinput (lua_State *L, LexState *ls, ZIO *z, TString *source) {
  ls->decpoint = '.';
  ls->L = L;
  ls->lookahead.token = TK_EOS;  /* no look-ahead token */
  ls->z = z;
  ls->fs = NULL;
  ls->linenumber = 1;
  ls->lastline = 1;
  ls->source = source;
  luaZ_resizebuffer(ls->L, ls->buff, LUA_MINBUFFER);  /* initialize buffer */
  next(ls);  /* read first char */
}



/*
** =======================================================
** LEXICAL ANALYZER
** =======================================================
*/



static int check_next (LexState *ls, const char *set) {
  if (!strchr(set, ls->current))
    return 0;
  save_and_next(ls);
  return 1;
}


static void buffreplace (LexState *ls, char from, char to) {
  size_t n = luaZ_bufflen(ls->buff);
  char *p = luaZ_buffer(ls->buff);
  while (n--)
    if (p[n] == from) p[n] = to;
}


static void trydecpoint (LexState *ls, SemInfo *seminfo) {
  /* format error: try to update decimal point separator */
  struct lconv *cv = localeconv();
  char old = ls->decpoint;
  ls->decpoint = (cv ? cv->decimal_point[0] : '.');
  buffreplace(ls, old, ls->decpoint);  /* try updated decimal separator */
  if (!luaO_str2d(luaZ_buffer(ls->buff), &seminfo->r)) {
    /* format error with correct decimal point: no more options */
    buffreplace(ls, ls->decpoint, '.');  /* undo change (for error message) */
    luaX_lexerror(ls, "malformed number", TK_NUMBER);
  }
}


/* LUA_NUMBER */
static void read_numeral (LexState *ls, SemInfo *seminfo) {
  lua_assert(isdigit(ls->current));
  do {
    save_and_next(ls);
  } while (isdigit(ls->current) || ls->current == '.');
  if (check_next(ls, "Ee"))  /* `E'? */
    check_next(ls, "+-");  /* optional exponent sign */
  while (isalnum(ls->current) || ls->current == '_')
    save_and_next(ls);
  save(ls, '\0');
  buffreplace(ls, '.', ls->decpoint);  /* follow locale for decimal point */
  if (!luaO_str2d(luaZ_buffer(ls->buff), &seminfo->r))  /* format error? */
    trydecpoint(ls, seminfo); /* try to update decimal point separator */
}


static int skip_sep (LexState *ls) {
  int count = 0;
  int s = ls->current;
  lua_assert(s == '[' || s == ']');
  save_and_next(ls);
  while (ls->current == '=') {
    save_and_next(ls);
    count++;
  }
  return (ls->current == s) ? count : (-count) - 1;
}


static void read_long_string (LexState *ls, SemInfo *seminfo, int sep) {
  int cont = 0;
  (void)(cont);  /* avoid warnings when `cont' is not used */
  save_and_next(ls);  /* skip 2nd `[' */
  if (currIsNewline(ls))  /* string starts with a newline? */
    inclinenumber(ls);  /* skip it */
  for (;;) {
    switch (ls->current) {
      case EOZ:
        luaX_lexerror(ls, (seminfo) ? "unfinished long string" :
                                   "unfinished long comment", TK_EOS);
        break;  /* to avoid warnings */
#if defined(LUA_COMPAT_LSTR)
      case '[': {
        if (skip_sep(ls) == sep) {
          save_and_next(ls);  /* skip 2nd `[' */
          cont++;
#if LUA_COMPAT_LSTR == 1
          if (sep == 0)
            luaX_lexerror(ls, "nesting of [[...]] is deprecated", '[');
#endif
        }
        break;
      }
#endif
      case ']': {
        if (skip_sep(ls) == sep) {
          save_and_next(ls);  /* skip 2nd `]' */
#if defined(LUA_COMPAT_LSTR) && LUA_COMPAT_LSTR == 2
          cont--;
          if (sep == 0 && cont >= 0) break;
#endif
          goto endloop;
        }
        break;
      }
      case '\n':
      case '\r': {
        save(ls, '\n');
        inclinenumber(ls);
        if (!seminfo) luaZ_resetbuffer(ls->buff);  /* avoid wasting space */
        break;
      }
      default: {
        if (seminfo) save_and_next(ls);
        else next(ls);
      }
    }
  } endloop:
  if (seminfo)
    seminfo->ts = luaX_newstring(ls, luaZ_buffer(ls->buff) + (2 + sep),
                                     luaZ_bufflen(ls->buff) - 2*(2 + sep));
}


static void read_string (LexState *ls, int del, SemInfo *seminfo) {
  save_and_next(ls);
  while (ls->current != del) {
    switch (ls->current) {
      case EOZ:
        luaX_lexerror(ls, "unfinished string", TK_EOS);
        continue;  /* to avoid warnings */
      case '\n':
      case '\r':
        luaX_lexerror(ls, "unfinished string", TK_STRING);
        continue;  /* to avoid warnings */
      case '\\': {
        int c;
        next(ls);  /* do not save the `\' */
        switch (ls->current) {
          case 'a': c = '\a'; break;
          case 'b': c = '\b'; break;
          case 'f': c = '\f'; break;
          case 'n': c = '\n'; break;
          case 'r': c = '\r'; break;
          case 't': c = '\t'; break;
          case 'v': c = '\v'; break;
          case '\n':  /* go through */
          case '\r': save(ls, '\n'); inclinenumber(ls); continue;
          case EOZ: continue;  /* will raise an error next loop */
          default: {
            if (!isdigit(ls->current))
              save_and_next(ls);  /* handles \\, \", \', and \? */
            else {  /* \xxx */
              int i = 0;
              c = 0;
              do {
                c = 10*c + (ls->current-'0');
                next(ls);
              } while (++i<3 && isdigit(ls->current));
              if (c > UCHAR_MAX)
                luaX_lexerror(ls, "escape sequence too large", TK_STRING);
              save(ls, c);
            }
            continue;
          }
        }
        save(ls, c);
        next(ls);
        continue;
      }
      default:
        save_and_next(ls);
    }
  }
  save_and_next(ls);  /* skip delimiter */
  seminfo->ts = luaX_newstring(ls, luaZ_buffer(ls->buff) + 1,
                                   luaZ_bufflen(ls->buff) - 2);
}


static int llex (LexState *ls, SemInfo *seminfo) {
  luaZ_resetbuffer(ls->buff);
  for (;;) {
    switch (ls->current) {
      case '\n':
      case '\r': {
        inclinenumber(ls);
        continue;
      }
      case '-': {
        next(ls);
        if (ls->current != '-') return '-';
        /* else is a comment */
        next(ls);
        if (ls->current == '[') {
          int sep = skip_sep(ls);
          luaZ_resetbuffer(ls->buff);  /* `skip_sep' may dirty the buffer */
          if (sep >= 0) {
            read_long_string(ls, NULL, sep);  /* long comment */
            luaZ_resetbuffer(ls->buff);
            continue;
          }
        }
        /* else short comment */
        while (!currIsNewline(ls) && ls->current != EOZ)
          next(ls);
        continue;
      }
      case '[': {
        int sep = skip_sep(ls);
        if (sep >= 0) {
          read_long_string(ls, seminfo, sep);
          return TK_STRING;
        }
        else if (sep == -1) return '[';
        else luaX_lexerror(ls, "invalid long string delimiter", TK_STRING);
      }
      case '=': {
        next(ls);
        if (ls->current != '=') return '=';
        else { next(ls); return TK_EQ; }
      }
      case '<': {
        next(ls);
        if (ls->current != '=') return '<';
        else { next(ls); return TK_LE; }
      }
      case '>': {
        next(ls);
        if (ls->current != '=') return '>';
        else { next(ls); return TK_GE; }
      }
      case '~': {
        next(ls);
        if (ls->current != '=') return '~';
        else { next(ls); return TK_NE; }
      }
      case '"':
      case '\'': {
        read_string(ls, ls->current, seminfo);
        return TK_STRING;
      }
      case '.': {
        save_and_next(ls);
        if (check_next(ls, ".")) {
          if (check_next(ls, "."))
            return TK_DOTS;   /* ... */
          else return TK_CONCAT;   /* .. */
        }
        else if (!isdigit(ls->current)) return '.';
        else {
          read_numeral(ls, seminfo);
          return TK_NUMBER;
        }
      }
      case EOZ: {
        return TK_EOS;
      }
      default: {
        if (isspace(ls->current)) {
          lua_assert(!currIsNewline(ls));
          next(ls);
          continue;
        }
        else if (isdigit(ls->current)) {
          read_numeral(ls, seminfo);
          return TK_NUMBER;
        }
        else if (isalpha(ls->current) || ls->current == '_') {
          /* identifier or reserved word */
          TString *ts;
          do {
            save_and_next(ls);
          } while (isalnum(ls->current) || ls->current == '_');
          ts = luaX_newstring(ls, luaZ_buffer(ls->buff),
                                  luaZ_bufflen(ls->buff));
          if (ts->tsv.reserved > 0)  /* reserved word? */
            return ts->tsv.reserved - 1 + FIRST_RESERVED;
          else {
            seminfo->ts = ts;
            return TK_NAME;
          }
        }
        else {
          int c = ls->current;
          next(ls);
          return c;  /* single-char tokens (+ - / ...) */
        }
      }
    }
  }
}


void luaX_next (LexState *ls) {
  ls->lastline = ls->linenumber;
  if (ls->lookahead.token != TK_EOS) {  /* is there a look-ahead token? */
    ls->t = ls->lookahead;  /* use this one */
    ls->lookahead.token = TK_EOS;  /* and discharge it */
  }
  else
    ls->t.token = llex(ls, &ls->t.seminfo);  /* read next token */
}


void luaX_lookahead (LexState *ls) {
  lua_assert(ls->lookahead.token == TK_EOS);
  ls->lookahead.token = llex(ls, &ls->lookahead.seminfo);
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\liolib.c ===
/*
** $Id: liolib.c,v 2.73 2006/05/08 20:14:16 roberto Exp $
** Standard I/O (and system) library
** See Copyright Notice in lua.h
*/


#include <errno.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define liolib_c
#define LUA_LIB

#include "lua.h"

#include "lauxlib.h"
#include "lualib.h"



#define IO_INPUT	1
#define IO_OUTPUT	2


static const char *const fnames[] = {"input", "output"};


static int pushresult (lua_State *L, int i, const char *filename) {
  int en = errno;  /* calls to Lua API may change this value */
  if (i) {
    lua_pushboolean(L, 1);
    return 1;
  }
  else {
    lua_pushnil(L);
    if (filename)
      lua_pushfstring(L, "%s: %s", filename, strerror(en));
    else
      lua_pushfstring(L, "%s", strerror(en));
    lua_pushinteger(L, en);
    return 3;
  }
}


static void fileerror (lua_State *L, int arg, const char *filename) {
  lua_pushfstring(L, "%s: %s", filename, strerror(errno));
  luaL_argerror(L, arg, lua_tostring(L, -1));
}


#define topfile(L)	((FILE **)luaL_checkudata(L, 1, LUA_FILEHANDLE))


static int io_type (lua_State *L) {
  void *ud;
  luaL_checkany(L, 1);
  ud = lua_touserdata(L, 1);
  lua_getfield(L, LUA_REGISTRYINDEX, LUA_FILEHANDLE);
  if (ud == NULL || !lua_getmetatable(L, 1) || !lua_rawequal(L, -2, -1))
    lua_pushnil(L);  /* not a file */
  else if (*((FILE **)ud) == NULL)
    lua_pushliteral(L, "closed file");
  else
    lua_pushliteral(L, "file");
  return 1;
}


static FILE *tofile (lua_State *L) {
  FILE **f = topfile(L);
  if (*f == NULL)
    luaL_error(L, "attempt to use a closed file");
  return *f;
}



/*
** When creating file handles, always creates a `closed' file handle
** before opening the actual file; so, if there is a memory error, the
** file is not left opened.
*/
static FILE **newfile (lua_State *L) {
  FILE **pf = (FILE **)lua_newuserdata(L, sizeof(FILE *));
  *pf = NULL;  /* file handle is currently `closed' */
  luaL_getmetatable(L, LUA_FILEHANDLE);
  lua_setmetatable(L, -2);
  return pf;
}


/*
** this function has a separated environment, which defines the
** correct __close for 'popen' files
*/
static int io_pclose (lua_State *L) {
  FILE **p = topfile(L);
  int ok = lua_pclose(L, *p);
  *p = NULL;
  return pushresult(L, ok, NULL);
}


static int io_fclose (lua_State *L) {
  FILE **p = topfile(L);
  int ok = (fclose(*p) == 0);
  *p = NULL;
  return pushresult(L, ok, NULL);
}


static int aux_close (lua_State *L) {
  lua_getfenv(L, 1);
  lua_getfield(L, -1, "__close");
  return (lua_tocfunction(L, -1))(L);
}


static int io_close (lua_State *L) {
  if (lua_isnone(L, 1))
    lua_rawgeti(L, LUA_ENVIRONINDEX, IO_OUTPUT);
  tofile(L);  /* make sure argument is a file */
  return aux_close(L);
}


static int io_gc (lua_State *L) {
  FILE *f = *topfile(L);
  /* ignore closed files and standard files */
  if (f != NULL && f != stdin && f != stdout && f != stderr)
    aux_close(L);
  return 0;
}


static int io_tostring (lua_State *L) {
  FILE *f = *topfile(L);
  if (f == NULL)
    lua_pushstring(L, "file (closed)");
  else
    lua_pushfstring(L, "file (%p)", f);
  return 1;
}


static int io_open (lua_State *L) {
  const char *filename = luaL_checkstring(L, 1);
  const char *mode = luaL_optstring(L, 2, "r");
  FILE **pf = newfile(L);
  *pf = fopen(filename, mode);
  return (*pf == NULL) ? pushresult(L, 0, filename) : 1;
}


static int io_popen (lua_State *L) {
  const char *filename = luaL_checkstring(L, 1);
  const char *mode = luaL_optstring(L, 2, "r");
  FILE **pf = newfile(L);
  *pf = lua_popen(L, filename, mode);
  return (*pf == NULL) ? pushresult(L, 0, filename) : 1;
}


static int io_tmpfile (lua_State *L) {
  FILE **pf = newfile(L);
  *pf = tmpfile();
  return (*pf == NULL) ? pushresult(L, 0, NULL) : 1;
}


static FILE *getiofile (lua_State *L, int findex) {
  FILE *f;
  lua_rawgeti(L, LUA_ENVIRONINDEX, findex);
  f = *(FILE **)lua_touserdata(L, -1);
  if (f == NULL)
    luaL_error(L, "standard %s file is closed", fnames[findex - 1]);
  return f;
}


static int g_iofile (lua_State *L, int f, const char *mode) {
  if (!lua_isnoneornil(L, 1)) {
    const char *filename = lua_tostring(L, 1);
    if (filename) {
      FILE **pf = newfile(L);
      *pf = fopen(filename, mode);
      if (*pf == NULL)
        fileerror(L, 1, filename);
    }
    else {
      tofile(L);  /* check that it's a valid file handle */
      lua_pushvalue(L, 1);
    }
    lua_rawseti(L, LUA_ENVIRONINDEX, f);
  }
  /* return current value */
  lua_rawgeti(L, LUA_ENVIRONINDEX, f);
  return 1;
}


static int io_input (lua_State *L) {
  return g_iofile(L, IO_INPUT, "r");
}


static int io_output (lua_State *L) {
  return g_iofile(L, IO_OUTPUT, "w");
}


static int io_readline (lua_State *L);


static void aux_lines (lua_State *L, int idx, int toclose) {
  lua_pushvalue(L, idx);
  lua_pushboolean(L, toclose);  /* close/not close file when finished */
  lua_pushcclosure(L, io_readline, 2);
}


static int f_lines (lua_State *L) {
  tofile(L);  /* check that it's a valid file handle */
  aux_lines(L, 1, 0);
  return 1;
}


static int io_lines (lua_State *L) {
  if (lua_isnoneornil(L, 1)) {  /* no arguments? */
    /* will iterate over default input */
    lua_rawgeti(L, LUA_ENVIRONINDEX, IO_INPUT);
    return f_lines(L);
  }
  else {
    const char *filename = luaL_checkstring(L, 1);
    FILE **pf = newfile(L);
    *pf = fopen(filename, "r");
    if (*pf == NULL)
      fileerror(L, 1, filename);
    aux_lines(L, lua_gettop(L), 1);
    return 1;
  }
}


/*
** {======================================================
** READ
** =======================================================
*/


static int read_number (lua_State *L, FILE *f) {
  lua_Number d;
  if (fscanf(f, LUA_NUMBER_SCAN, &d) == 1) {
    lua_pushnumber(L, d);
    return 1;
  }
  else return 0;  /* read fails */
}


static int test_eof (lua_State *L, FILE *f) {
  int c = getc(f);
  ungetc(c, f);
  lua_pushlstring(L, NULL, 0);
  return (c != EOF);
}


static int read_line (lua_State *L, FILE *f) {
  luaL_Buffer b;
  luaL_buffinit(L, &b);
  for (;;) {
    size_t l;
    char *p = luaL_prepbuffer(&b);
    if (fgets(p, LUAL_BUFFERSIZE, f) == NULL) {  /* eof? */
      luaL_pushresult(&b);  /* close buffer */
      return (lua_strlen(L, -1) > 0);  /* check whether read something */
    }
    l = strlen(p);
    if (l == 0 || p[l-1] != '\n')
      luaL_addsize(&b, l);
    else {
      luaL_addsize(&b, l - 1);  /* do not include `eol' */
      luaL_pushresult(&b);  /* close buffer */
      return 1;  /* read at least an `eol' */
    }
  }
}


static int read_chars (lua_State *L, FILE *f, size_t n) {
  size_t rlen;  /* how much to read */
  size_t nr;  /* number of chars actually read */
  luaL_Buffer b;
  luaL_buffinit(L, &b);
  rlen = LUAL_BUFFERSIZE;  /* try to read that much each time */
  do {
    char *p = luaL_prepbuffer(&b);
    if (rlen > n) rlen = n;  /* cannot read more than asked */
    nr = fread(p, sizeof(char), rlen, f);
    luaL_addsize(&b, nr);
    n -= nr;  /* still have to read `n' chars */
  } while (n > 0 && nr == rlen);  /* until end of count or eof */
  luaL_pushresult(&b);  /* close buffer */
  return (n == 0 || lua_strlen(L, -1) > 0);
}


static int g_read (lua_State *L, FILE *f, int first) {
  int nargs = lua_gettop(L) - 1;
  int success;
  int n;
  clearerr(f);
  if (nargs == 0) {  /* no arguments? */
    success = read_line(L, f);
    n = first+1;  /* to return 1 result */
  }
  else {  /* ensure stack space for all results and for auxlib's buffer */
    luaL_checkstack(L, nargs+LUA_MINSTACK, "too many arguments");
    success = 1;
    for (n = first; nargs-- && success; n++) {
      if (lua_type(L, n) == LUA_TNUMBER) {
        size_t l = (size_t)lua_tointeger(L, n);
        success = (l == 0) ? test_eof(L, f) : read_chars(L, f, l);
      }
      else {
        const char *p = lua_tostring(L, n);
        luaL_argcheck(L, p && p[0] == '*', n, "invalid option");
        switch (p[1]) {
          case 'n':  /* number */
            success = read_number(L, f);
            break;
          case 'l':  /* line */
            success = read_line(L, f);
            break;
          case 'a':  /* file */
            read_chars(L, f, ~((size_t)0));  /* read MAX_SIZE_T chars */
            success = 1; /* always success */
            break;
          default:
            return luaL_argerror(L, n, "invalid format");
        }
      }
    }
  }
  if (ferror(f))
    return pushresult(L, 0, NULL);
  if (!success) {
    lua_pop(L, 1);  /* remove last result */
    lua_pushnil(L);  /* push nil instead */
  }
  return n - first;
}


static int io_read (lua_State *L) {
  return g_read(L, getiofile(L, IO_INPUT), 1);
}


static int f_read (lua_State *L) {
  return g_read(L, tofile(L), 2);
}


static int io_readline (lua_State *L) {
  FILE *f = *(FILE **)lua_touserdata(L, lua_upvalueindex(1));
  int sucess;
  if (f == NULL)  /* file is already closed? */
    luaL_error(L, "file is already closed");
  sucess = read_line(L, f);
  if (ferror(f))
    return luaL_error(L, "%s", strerror(errno));
  if (sucess) return 1;
  else {  /* EOF */
    if (lua_toboolean(L, lua_upvalueindex(2))) {  /* generator created file? */
      lua_settop(L, 0);
      lua_pushvalue(L, lua_upvalueindex(1));
      aux_close(L);  /* close it */
    }
    return 0;
  }
}

/* }====================================================== */


static int g_write (lua_State *L, FILE *f, int arg) {
  int nargs = lua_gettop(L) - 1;
  int status = 1;
  for (; nargs--; arg++) {
    if (lua_type(L, arg) == LUA_TNUMBER) {
      /* optimization: could be done exactly as for strings */
      status = status &&
          fprintf(f, LUA_NUMBER_FMT, lua_tonumber(L, arg)) > 0;
    }
    else {
      size_t l;
      const char *s = luaL_checklstring(L, arg, &l);
      status = status && (fwrite(s, sizeof(char), l, f) == l);
    }
  }
  return pushresult(L, status, NULL);
}


static int io_write (lua_State *L) {
  return g_write(L, getiofile(L, IO_OUTPUT), 1);
}


static int f_write (lua_State *L) {
  return g_write(L, tofile(L), 2);
}


static int f_seek (lua_State *L) {
  static const int mode[] = {SEEK_SET, SEEK_CUR, SEEK_END};
  static const char *const modenames[] = {"set", "cur", "end", NULL};
  FILE *f = tofile(L);
  int op = luaL_checkoption(L, 2, "cur", modenames);
  long offset = luaL_optlong(L, 3, 0);
  op = fseek(f, offset, mode[op]);
  if (op)
    return pushresult(L, 0, NULL);  /* error */
  else {
    lua_pushinteger(L, ftell(f));
    return 1;
  }
}


static int f_setvbuf (lua_State *L) {
  static const int mode[] = {_IONBF, _IOFBF, _IOLBF};
  static const char *const modenames[] = {"no", "full", "line", NULL};
  FILE *f = tofile(L);
  int op = luaL_checkoption(L, 2, NULL, modenames);
  lua_Integer sz = luaL_optinteger(L, 3, LUAL_BUFFERSIZE);
  int res = setvbuf(f, NULL, mode[op], sz);
  return pushresult(L, res == 0, NULL);
}



static int io_flush (lua_State *L) {
  return pushresult(L, fflush(getiofile(L, IO_OUTPUT)) == 0, NULL);
}


static int f_flush (lua_State *L) {
  return pushresult(L, fflush(tofile(L)) == 0, NULL);
}


static const luaL_Reg iolib[] = {
  {"close", io_close},
  {"flush", io_flush},
  {"input", io_input},
  {"lines", io_lines},
  {"open", io_open},
  {"output", io_output},
  {"popen", io_popen},
  {"read", io_read},
  {"tmpfile", io_tmpfile},
  {"type", io_type},
  {"write", io_write},
  {NULL, NULL}
};


static const luaL_Reg flib[] = {
  {"close", io_close},
  {"flush", f_flush},
  {"lines", f_lines},
  {"read", f_read},
  {"seek", f_seek},
  {"setvbuf", f_setvbuf},
  {"write", f_write},
  {"__gc", io_gc},
  {"__tostring", io_tostring},
  {NULL, NULL}
};


static void createmeta (lua_State *L) {
  luaL_newmetatable(L, LUA_FILEHANDLE);  /* create metatable for file handles */
  lua_pushvalue(L, -1);  /* push metatable */
  lua_setfield(L, -2, "__index");  /* metatable.__index = metatable */
  luaL_register(L, NULL, flib);  /* file methods */
}


static void createstdfile (lua_State *L, FILE *f, int k, const char *fname) {
  *newfile(L) = f;
  if (k > 0) {
    lua_pushvalue(L, -1);
    lua_rawseti(L, LUA_ENVIRONINDEX, k);
  }
  lua_setfield(L, -2, fname);
}


LUALIB_API int luaopen_io (lua_State *L) {
  createmeta(L);
  /* create (private) environment (with fields IO_INPUT, IO_OUTPUT, __close) */
  lua_createtable(L, 2, 1);
  lua_replace(L, LUA_ENVIRONINDEX);
  /* open library */
  luaL_register(L, LUA_IOLIBNAME, iolib);
  /* create (and set) default files */
  createstdfile(L, stdin, IO_INPUT, "stdin");
  createstdfile(L, stdout, IO_OUTPUT, "stdout");
  createstdfile(L, stderr, 0, "stderr");
  /* create environment for 'popen' */
  lua_getfield(L, -1, "popen");
  lua_createtable(L, 0, 1);
  lua_pushcfunction(L, io_pclose);
  lua_setfield(L, -2, "__close");
  lua_setfenv(L, -2);
  lua_pop(L, 1);  /* pop 'popen' */
  /* set default close function */
  lua_pushcfunction(L, io_fclose);
  lua_setfield(L, LUA_ENVIRONINDEX, "__close");
  return 1;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lgc.c ===
/*
** $Id: lgc.c,v 2.38 2006/05/24 14:34:06 roberto Exp $
** Garbage Collector
** See Copyright Notice in lua.h
*/

#include <string.h>

#define lgc_c
#define LUA_CORE

#include "lua.h"

#include "ldebug.h"
#include "ldo.h"
#include "lfunc.h"
#include "lgc.h"
#include "lmem.h"
#include "lobject.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"
#include "ltm.h"


#define GCSTEPSIZE	1024u
#define GCSWEEPMAX	40
#define GCSWEEPCOST	10
#define GCFINALIZECOST	100


#define maskmarks	cast_byte(~(bitmask(BLACKBIT)|WHITEBITS))

#define makewhite(g,x)	\
   ((x)->gch.marked = cast_byte(((x)->gch.marked & maskmarks) | luaC_white(g)))

#define white2gray(x)	reset2bits((x)->gch.marked, WHITE0BIT, WHITE1BIT)
#define black2gray(x)	resetbit((x)->gch.marked, BLACKBIT)

#define stringmark(s)	reset2bits((s)->tsv.marked, WHITE0BIT, WHITE1BIT)


#define isfinalized(u)		testbit((u)->marked, FINALIZEDBIT)
#define markfinalized(u)	l_setbit((u)->marked, FINALIZEDBIT)


#define KEYWEAK         bitmask(KEYWEAKBIT)
#define VALUEWEAK       bitmask(VALUEWEAKBIT)



#define markvalue(g,o) { checkconsistency(o); \
  if (iscollectable(o) && iswhite(gcvalue(o))) reallymarkobject(g,gcvalue(o)); }

#define markobject(g,t) { if (iswhite(obj2gco(t))) \
		reallymarkobject(g, obj2gco(t)); }


#define setthreshold(g)  (g->GCthreshold = (g->estimate/100) * g->gcpause)


static void removeentry (Node *n) {
  lua_assert(ttisnil(gval(n)));
  if (iscollectable(gkey(n)))
    setttype(gkey(n), LUA_TDEADKEY);  /* dead key; remove it */
}


static void reallymarkobject (global_State *g, GCObject *o) {
  lua_assert(iswhite(o) && !isdead(g, o));
  white2gray(o);
  switch (o->gch.tt) {
    case LUA_TSTRING: {
      return;
    }
    case LUA_TUSERDATA: {
      Table *mt = gco2u(o)->metatable;
      gray2black(o);  /* udata are never gray */
      if (mt) markobject(g, mt);
      markobject(g, gco2u(o)->env);
      return;
    }
    case LUA_TUPVAL: {
      UpVal *uv = gco2uv(o);
      markvalue(g, uv->v);
      if (uv->v == &uv->u.value)  /* closed? */
        gray2black(o);  /* open upvalues are never black */
      return;
    }
    case LUA_TFUNCTION: {
      gco2cl(o)->c.gclist = g->gray;
      g->gray = o;
      break;
    }
    case LUA_TTABLE: {
      gco2h(o)->gclist = g->gray;
      g->gray = o;
      break;
    }
    case LUA_TTHREAD: {
      gco2th(o)->gclist = g->gray;
      g->gray = o;
      break;
    }
    case LUA_TPROTO: {
      gco2p(o)->gclist = g->gray;
      g->gray = o;
      break;
    }
    default: lua_assert(0);
  }
}


static void marktmu (global_State *g) {
  GCObject *u = g->tmudata;
  if (u) {
    do {
      u = u->gch.next;
      makewhite(g, u);  /* may be marked, if left from previous GC */
      reallymarkobject(g, u);
    } while (u != g->tmudata);
  }
}


/* move `dead' udata that need finalization to list `tmudata' */
size_t luaC_separateudata (lua_State *L, int all) {
  global_State *g = G(L);
  size_t deadmem = 0;
  GCObject **p = &g->mainthread->next;
  GCObject *curr;
  while ((curr = *p) != NULL) {
    if (!(iswhite(curr) || all) || isfinalized(gco2u(curr)))
      p = &curr->gch.next;  /* don't bother with them */
    else if (fasttm(L, gco2u(curr)->metatable, TM_GC) == NULL) {
      markfinalized(gco2u(curr));  /* don't need finalization */
      p = &curr->gch.next;
    }
    else {  /* must call its gc method */
      deadmem += sizeudata(gco2u(curr));
      markfinalized(gco2u(curr));
      *p = curr->gch.next;
      /* link `curr' at the end of `tmudata' list */
      if (g->tmudata == NULL)  /* list is empty? */
        g->tmudata = curr->gch.next = curr;  /* creates a circular list */
      else {
        curr->gch.next = g->tmudata->gch.next;
        g->tmudata->gch.next = curr;
        g->tmudata = curr;
      }
    }
  }
  return deadmem;
}


static int traversetable (global_State *g, Table *h) {
  int i;
  int weakkey = 0;
  int weakvalue = 0;
  const TValue *mode;
  if (h->metatable)
    markobject(g, h->metatable);
  mode = gfasttm(g, h->metatable, TM_MODE);
  if (mode && ttisstring(mode)) {  /* is there a weak mode? */
    weakkey = (strchr(svalue(mode), 'k') != NULL);
    weakvalue = (strchr(svalue(mode), 'v') != NULL);
    if (weakkey || weakvalue) {  /* is really weak? */
      h->marked &= ~(KEYWEAK | VALUEWEAK);  /* clear bits */
      h->marked |= cast_byte((weakkey << KEYWEAKBIT) |
                             (weakvalue << VALUEWEAKBIT));
      h->gclist = g->weak;  /* must be cleared after GC, ... */
      g->weak = obj2gco(h);  /* ... so put in the appropriate list */
    }
  }
  if (weakkey && weakvalue) return 1;
  if (!weakvalue) {
    i = h->sizearray;
    while (i--)
      markvalue(g, &h->array[i]);
  }
  i = sizenode(h);
  while (i--) {
    Node *n = gnode(h, i);
    lua_assert(ttype(gkey(n)) != LUA_TDEADKEY || ttisnil(gval(n)));
    if (ttisnil(gval(n)))
      removeentry(n);  /* remove empty entries */
    else {
      lua_assert(!ttisnil(gkey(n)));
      if (!weakkey) markvalue(g, gkey(n));
      if (!weakvalue) markvalue(g, gval(n));
    }
  }
  return weakkey || weakvalue;
}


/*
** All marks are conditional because a GC may happen while the
** prototype is still being created
*/
static void traverseproto (global_State *g, Proto *f) {
  int i;
  if (f->source) stringmark(f->source);
  for (i=0; i<f->sizek; i++)  /* mark literals */
    markvalue(g, &f->k[i]);
  for (i=0; i<f->sizeupvalues; i++) {  /* mark upvalue names */
    if (f->upvalues[i])
      stringmark(f->upvalues[i]);
  }
  for (i=0; i<f->sizep; i++) {  /* mark nested protos */
    if (f->p[i])
      markobject(g, f->p[i]);
  }
  for (i=0; i<f->sizelocvars; i++) {  /* mark local-variable names */
    if (f->locvars[i].varname)
      stringmark(f->locvars[i].varname);
  }
}



static void traverseclosure (global_State *g, Closure *cl) {
  markobject(g, cl->c.env);
  if (cl->c.isC) {
    int i;
    for (i=0; i<cl->c.nupvalues; i++)  /* mark its upvalues */
      markvalue(g, &cl->c.upvalue[i]);
  }
  else {
    int i;
    lua_assert(cl->l.nupvalues == cl->l.p->nups);
    markobject(g, cl->l.p);
    for (i=0; i<cl->l.nupvalues; i++)  /* mark its upvalues */
      markobject(g, cl->l.upvals[i]);
  }
}


static void checkstacksizes (lua_State *L, StkId max) {
  int ci_used = cast_int(L->ci - L->base_ci);  /* number of `ci' in use */
  int s_used = cast_int(max - L->stack);  /* part of stack in use */
  if (L->size_ci > LUAI_MAXCALLS)  /* handling overflow? */
    return;  /* do not touch the stacks */
  if (4*ci_used < L->size_ci && 2*BASIC_CI_SIZE < L->size_ci)
    luaD_reallocCI(L, L->size_ci/2);  /* still big enough... */
  condhardstacktests(luaD_reallocCI(L, ci_used + 1));
  if (4*s_used < L->stacksize &&
      2*(BASIC_STACK_SIZE+EXTRA_STACK) < L->stacksize)
    luaD_reallocstack(L, L->stacksize/2);  /* still big enough... */
  condhardstacktests(luaD_reallocstack(L, s_used));
}


static void traversestack (global_State *g, lua_State *l) {
  StkId o, lim;
  CallInfo *ci;
  markvalue(g, gt(l));
  lim = l->top;
  for (ci = l->base_ci; ci <= l->ci; ci++) {
    lua_assert(ci->top <= l->stack_last);
    if (lim < ci->top) lim = ci->top;
  }
  for (o = l->stack; o < l->top; o++)
    markvalue(g, o);
  for (; o <= lim; o++)
    setnilvalue(o);
  checkstacksizes(l, lim);
}


/*
** traverse one gray object, turning it to black.
** Returns `quantity' traversed.
*/
static l_mem propagatemark (global_State *g) {
  GCObject *o = g->gray;
  lua_assert(isgray(o));
  gray2black(o);
  switch (o->gch.tt) {
    case LUA_TTABLE: {
      Table *h = gco2h(o);
      g->gray = h->gclist;
      if (traversetable(g, h))  /* table is weak? */
        black2gray(o);  /* keep it gray */
      return sizeof(Table) + sizeof(TValue) * h->sizearray +
                             sizeof(Node) * sizenode(h);
    }
    case LUA_TFUNCTION: {
      Closure *cl = gco2cl(o);
      g->gray = cl->c.gclist;
      traverseclosure(g, cl);
      return (cl->c.isC) ? sizeCclosure(cl->c.nupvalues) :
                           sizeLclosure(cl->l.nupvalues);
    }
    case LUA_TTHREAD: {
      lua_State *th = gco2th(o);
      g->gray = th->gclist;
      th->gclist = g->grayagain;
      g->grayagain = o;
      black2gray(o);
      traversestack(g, th);
      return sizeof(lua_State) + sizeof(TValue) * th->stacksize +
                                 sizeof(CallInfo) * th->size_ci;
    }
    case LUA_TPROTO: {
      Proto *p = gco2p(o);
      g->gray = p->gclist;
      traverseproto(g, p);
      return sizeof(Proto) + sizeof(Instruction) * p->sizecode +
                             sizeof(Proto *) * p->sizep +
                             sizeof(TValue) * p->sizek + 
                             sizeof(int) * p->sizelineinfo +
                             sizeof(LocVar) * p->sizelocvars +
                             sizeof(TString *) * p->sizeupvalues;
    }
    default: lua_assert(0); return 0;
  }
}


static size_t propagateall (global_State *g) {
  size_t m = 0;
  while (g->gray) m += propagatemark(g);
  return m;
}


/*
** The next function tells whether a key or value can be cleared from
** a weak table. Non-collectable objects are never removed from weak
** tables. Strings behave as `values', so are never removed too. for
** other objects: if really collected, cannot keep them; for userdata
** being finalized, keep them in keys, but not in values
*/
static int iscleared (const TValue *o, int iskey) {
  if (!iscollectable(o)) return 0;
  if (ttisstring(o)) {
    stringmark(rawtsvalue(o));  /* strings are `values', so are never weak */
    return 0;
  }
  return iswhite(gcvalue(o)) ||
    (ttisuserdata(o) && (!iskey && isfinalized(uvalue(o))));
}


/*
** clear collected entries from weaktables
*/
static void cleartable (GCObject *l) {
  while (l) {
    Table *h = gco2h(l);
    int i = h->sizearray;
    lua_assert(testbit(h->marked, VALUEWEAKBIT) ||
               testbit(h->marked, KEYWEAKBIT));
    if (testbit(h->marked, VALUEWEAKBIT)) {
      while (i--) {
        TValue *o = &h->array[i];
        if (iscleared(o, 0))  /* value was collected? */
          setnilvalue(o);  /* remove value */
      }
    }
    i = sizenode(h);
    while (i--) {
      Node *n = gnode(h, i);
      if (!ttisnil(gval(n)) &&  /* non-empty entry? */
          (iscleared(key2tval(n), 1) || iscleared(gval(n), 0))) {
        setnilvalue(gval(n));  /* remove value ... */
        removeentry(n);  /* remove entry from table */
      }
    }
    l = h->gclist;
  }
}


static void freeobj (lua_State *L, GCObject *o) {
  switch (o->gch.tt) {
    case LUA_TPROTO: luaF_freeproto(L, gco2p(o)); break;
    case LUA_TFUNCTION: luaF_freeclosure(L, gco2cl(o)); break;
    case LUA_TUPVAL: luaF_freeupval(L, gco2uv(o)); break;
    case LUA_TTABLE: luaH_free(L, gco2h(o)); break;
    case LUA_TTHREAD: {
      lua_assert(gco2th(o) != L && gco2th(o) != G(L)->mainthread);
      luaE_freethread(L, gco2th(o));
      break;
    }
    case LUA_TSTRING: {
      G(L)->strt.nuse--;
      luaM_freemem(L, o, sizestring(gco2ts(o)));
      break;
    }
    case LUA_TUSERDATA: {
      luaM_freemem(L, o, sizeudata(gco2u(o)));
      break;
    }
    default: lua_assert(0);
  }
}



#define sweepwholelist(L,p)	sweeplist(L,p,MAX_LUMEM)


static GCObject **sweeplist (lua_State *L, GCObject **p, lu_mem count) {
  GCObject *curr;
  global_State *g = G(L);
  int deadmask = otherwhite(g);
  while ((curr = *p) != NULL && count-- > 0) {
    if (curr->gch.tt == LUA_TTHREAD)  /* sweep open upvalues of each thread */
      sweepwholelist(L, &gco2th(curr)->openupval);
    if ((curr->gch.marked ^ WHITEBITS) & deadmask) {  /* not dead? */
      lua_assert(!isdead(g, curr) || testbit(curr->gch.marked, FIXEDBIT));
      makewhite(g, curr);  /* make it white (for next cycle) */
      p = &curr->gch.next;
    }
    else {  /* must erase `curr' */
      lua_assert(isdead(g, curr) || deadmask == bitmask(SFIXEDBIT));
      *p = curr->gch.next;
      if (curr == g->rootgc)  /* is the first element of the list? */
        g->rootgc = curr->gch.next;  /* adjust first */
      freeobj(L, curr);
    }
  }
  return p;
}


static void checkSizes (lua_State *L) {
  global_State *g = G(L);
  /* check size of string hash */
  if (g->strt.nuse < cast(lu_int32, g->strt.size/4) &&
      g->strt.size > MINSTRTABSIZE*2)
    luaS_resize(L, g->strt.size/2);  /* table is too big */
  /* check size of buffer */
  if (luaZ_sizebuffer(&g->buff) > LUA_MINBUFFER*2) {  /* buffer too big? */
    size_t newsize = luaZ_sizebuffer(&g->buff) / 2;
    luaZ_resizebuffer(L, &g->buff, newsize);
  }
}


static void GCTM (lua_State *L) {
  global_State *g = G(L);
  GCObject *o = g->tmudata->gch.next;  /* get first element */
  Udata *udata = rawgco2u(o);
  const TValue *tm;
  /* remove udata from `tmudata' */
  if (o == g->tmudata)  /* last element? */
    g->tmudata = NULL;
  else
    g->tmudata->gch.next = udata->uv.next;
  udata->uv.next = g->mainthread->next;  /* return it to `root' list */
  g->mainthread->next = o;
  makewhite(g, o);
  tm = fasttm(L, udata->uv.metatable, TM_GC);
  if (tm != NULL) {
    lu_byte oldah = L->allowhook;
    lu_mem oldt = g->GCthreshold;
    L->allowhook = 0;  /* stop debug hooks during GC tag method */
    g->GCthreshold = 2*g->totalbytes;  /* avoid GC steps */
    setobj2s(L, L->top, tm);
    setuvalue(L, L->top+1, udata);
    L->top += 2;
    luaD_call(L, L->top - 2, 0);
    L->allowhook = oldah;  /* restore hooks */
    g->GCthreshold = oldt;  /* restore threshold */
  }
}


/*
** Call all GC tag methods
*/
void luaC_callGCTM (lua_State *L) {
  while (G(L)->tmudata)
    GCTM(L);
}


void luaC_freeall (lua_State *L) {
  global_State *g = G(L);
  int i;
  g->currentwhite = WHITEBITS | bitmask(SFIXEDBIT);  /* mask to collect all elements */
  sweepwholelist(L, &g->rootgc);
  for (i = 0; i < g->strt.size; i++)  /* free all string lists */
    sweepwholelist(L, &g->strt.hash[i]);
}


static void markmt (global_State *g) {
  int i;
  for (i=0; i<NUM_TAGS; i++)
    if (g->mt[i]) markobject(g, g->mt[i]);
}


/* mark root set */
static void markroot (lua_State *L) {
  global_State *g = G(L);
  g->gray = NULL;
  g->grayagain = NULL;
  g->weak = NULL;
  markobject(g, g->mainthread);
  /* make global table be traversed before main stack */
  markvalue(g, gt(g->mainthread));
  markvalue(g, registry(L));
  markmt(g);
  g->gcstate = GCSpropagate;
}


static void remarkupvals (global_State *g) {
  UpVal *uv;
  for (uv = g->uvhead.u.l.next; uv != &g->uvhead; uv = uv->u.l.next) {
    lua_assert(uv->u.l.next->u.l.prev == uv && uv->u.l.prev->u.l.next == uv);
    if (isgray(obj2gco(uv)))
      markvalue(g, uv->v);
  }
}


static void atomic (lua_State *L) {
  global_State *g = G(L);
  size_t udsize;  /* total size of userdata to be finalized */
  /* remark occasional upvalues of (maybe) dead threads */
  remarkupvals(g);
  /* traverse objects cautch by write barrier and by 'remarkupvals' */
  propagateall(g);
  /* remark weak tables */
  g->gray = g->weak;
  g->weak = NULL;
  lua_assert(!iswhite(obj2gco(g->mainthread)));
  markobject(g, L);  /* mark running thread */
  markmt(g);  /* mark basic metatables (again) */
  propagateall(g);
  /* remark gray again */
  g->gray = g->grayagain;
  g->grayagain = NULL;
  propagateall(g);
  udsize = luaC_separateudata(L, 0);  /* separate userdata to be finalized */
  marktmu(g);  /* mark `preserved' userdata */
  udsize += propagateall(g);  /* remark, to propagate `preserveness' */
  cleartable(g->weak);  /* remove collected objects from weak tables */
  /* flip current white */
  g->currentwhite = cast_byte(otherwhite(g));
  g->sweepstrgc = 0;
  g->sweepgc = &g->rootgc;
  g->gcstate = GCSsweepstring;
  g->estimate = g->totalbytes - udsize;  /* first estimate */
}


static l_mem singlestep (lua_State *L) {
  global_State *g = G(L);
  /*lua_checkmemory(L);*/
  switch (g->gcstate) {
    case GCSpause: {
      markroot(L);  /* start a new collection */
      return 0;
    }
    case GCSpropagate: {
      if (g->gray)
        return propagatemark(g);
      else {  /* no more `gray' objects */
        atomic(L);  /* finish mark phase */
        return 0;
      }
    }
    case GCSsweepstring: {
      lu_mem old = g->totalbytes;
      sweepwholelist(L, &g->strt.hash[g->sweepstrgc++]);
      if (g->sweepstrgc >= g->strt.size)  /* nothing more to sweep? */
        g->gcstate = GCSsweep;  /* end sweep-string phase */
      lua_assert(old >= g->totalbytes);
      g->estimate -= old - g->totalbytes;
      return GCSWEEPCOST;
    }
    case GCSsweep: {
      lu_mem old = g->totalbytes;
      g->sweepgc = sweeplist(L, g->sweepgc, GCSWEEPMAX);
      if (*g->sweepgc == NULL) {  /* nothing more to sweep? */
        checkSizes(L);
        g->gcstate = GCSfinalize;  /* end sweep phase */
      }
      lua_assert(old >= g->totalbytes);
      g->estimate -= old - g->totalbytes;
      return GCSWEEPMAX*GCSWEEPCOST;
    }
    case GCSfinalize: {
      if (g->tmudata) {
        GCTM(L);
        if (g->estimate > GCFINALIZECOST)
          g->estimate -= GCFINALIZECOST;
        return GCFINALIZECOST;
      }
      else {
        g->gcstate = GCSpause;  /* end collection */
        g->gcdept = 0;
        return 0;
      }
    }
    default: lua_assert(0); return 0;
  }
}


void luaC_step (lua_State *L) {
  global_State *g = G(L);
  l_mem lim = (GCSTEPSIZE/100) * g->gcstepmul;
  if (lim == 0)
    lim = (MAX_LUMEM-1)/2;  /* no limit */
  g->gcdept += g->totalbytes - g->GCthreshold;
  do {
    lim -= singlestep(L);
    if (g->gcstate == GCSpause)
      break;
  } while (lim > 0);
  if (g->gcstate != GCSpause) {
    if (g->gcdept < GCSTEPSIZE)
      g->GCthreshold = g->totalbytes + GCSTEPSIZE;  /* - lim/g->gcstepmul;*/
    else {
      g->gcdept -= GCSTEPSIZE;
      g->GCthreshold = g->totalbytes;
    }
  }
  else {
    lua_assert(g->totalbytes >= g->estimate);
    setthreshold(g);
  }
}


void luaC_fullgc (lua_State *L) {
  global_State *g = G(L);
  if (g->gcstate <= GCSpropagate) {
    /* reset sweep marks to sweep all elements (returning them to white) */
    g->sweepstrgc = 0;
    g->sweepgc = &g->rootgc;
    /* reset other collector lists */
    g->gray = NULL;
    g->grayagain = NULL;
    g->weak = NULL;
    g->gcstate = GCSsweepstring;
  }
  lua_assert(g->gcstate != GCSpause && g->gcstate != GCSpropagate);
  /* finish any pending sweep phase */
  while (g->gcstate != GCSfinalize) {
    lua_assert(g->gcstate == GCSsweepstring || g->gcstate == GCSsweep);
    singlestep(L);
  }
  markroot(L);
  while (g->gcstate != GCSpause) {
    singlestep(L);
  }
  setthreshold(g);
}


void luaC_barrierf (lua_State *L, GCObject *o, GCObject *v) {
  global_State *g = G(L);
  lua_assert(isblack(o) && iswhite(v) && !isdead(g, v) && !isdead(g, o));
  lua_assert(g->gcstate != GCSfinalize && g->gcstate != GCSpause);
  lua_assert(ttype(&o->gch) != LUA_TTABLE);
  /* must keep invariant? */
  if (g->gcstate == GCSpropagate)
    reallymarkobject(g, v);  /* restore invariant */
  else  /* don't mind */
    makewhite(g, o);  /* mark as white just to avoid other barriers */
}


void luaC_barrierback (lua_State *L, Table *t) {
  global_State *g = G(L);
  GCObject *o = obj2gco(t);
  lua_assert(isblack(o) && !isdead(g, o));
  lua_assert(g->gcstate != GCSfinalize && g->gcstate != GCSpause);
  black2gray(o);  /* make table gray (again) */
  t->gclist = g->grayagain;
  g->grayagain = o;
}


void luaC_link (lua_State *L, GCObject *o, lu_byte tt) {
  global_State *g = G(L);
  o->gch.next = g->rootgc;
  g->rootgc = o;
  o->gch.marked = luaC_white(g);
  o->gch.tt = tt;
}


void luaC_linkupval (lua_State *L, UpVal *uv) {
  global_State *g = G(L);
  GCObject *o = obj2gco(uv);
  o->gch.next = g->rootgc;  /* link upvalue into `rootgc' list */
  g->rootgc = o;
  if (isgray(o)) { 
    if (g->gcstate == GCSpropagate) {
      gray2black(o);  /* closed upvalues need barrier */
      luaC_barrier(L, uv, uv->v);
    }
    else {  /* sweep phase: sweep it (turning it into white) */
      makewhite(g, o);
      lua_assert(g->gcstate != GCSfinalize && g->gcstate != GCSpause);
    }
  }
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\llimits.h ===
/*
** $Id: llimits.h,v 1.69 2005/12/27 17:12:00 roberto Exp $
** Limits, basic types, and some other `installation-dependent' definitions
** See Copyright Notice in lua.h
*/

#ifndef llimits_h
#define llimits_h


#include <limits.h>
#include <stddef.h>


#include "lua.h"


typedef LUAI_UINT32 lu_int32;

typedef LUAI_UMEM lu_mem;

typedef LUAI_MEM l_mem;



/* chars used as small naturals (so that `char' is reserved for characters) */
typedef unsigned char lu_byte;


#define MAX_SIZET	((size_t)(~(size_t)0)-2)

#define MAX_LUMEM	((lu_mem)(~(lu_mem)0)-2)


#define MAX_INT (INT_MAX-2)  /* maximum value of an int (-2 for safety) */

/*
** conversion of pointer to integer
** this is for hashing only; there is no problem if the integer
** cannot hold the whole pointer value
*/
#define IntPoint(p)  ((unsigned int)(lu_mem)(p))



/* type to ensure maximum alignment */
typedef LUAI_USER_ALIGNMENT_T L_Umaxalign;


/* result of a `usual argument conversion' over lua_Number */
typedef LUAI_UACNUMBER l_uacNumber;


/* internal assertions for in-house debugging */
#ifdef lua_assert

#define check_exp(c,e)		(lua_assert(c), (e))
#define api_check(l,e)		lua_assert(e)

#else

#define lua_assert(c)		((void)0)
#define check_exp(c,e)		(e)
#define api_check		luai_apicheck

#endif


#ifndef UNUSED
#define UNUSED(x)	((void)(x))	/* to avoid warnings */
#endif


#ifndef cast
#define cast(t, exp)	((t)(exp))
#endif

#define cast_byte(i)	cast(lu_byte, (i))
#define cast_num(i)	cast(lua_Number, (i))
#define cast_int(i)	cast(int, (i))



/*
** type for virtual-machine instructions
** must be an unsigned with (at least) 4 bytes (see details in lopcodes.h)
*/
typedef lu_int32 Instruction;



/* maximum stack for a Lua function */
#define MAXSTACK	250



/* minimum size for the string table (must be power of 2) */
#ifndef MINSTRTABSIZE
#define MINSTRTABSIZE	32
#endif


/* minimum size for string buffer */
#ifndef LUA_MINBUFFER
#define LUA_MINBUFFER	32
#endif


#ifndef lua_lock
#define lua_lock(L)     ((void) 0) 
#define lua_unlock(L)   ((void) 0)
#endif

#ifndef luai_threadyield
#define luai_threadyield(L)     {lua_unlock(L); lua_lock(L);}
#endif


/*
** macro to control inclusion of some hard tests on stack reallocation
*/ 
#ifndef HARDSTACKTESTS
#define condhardstacktests(x)	((void)0)
#else
#define condhardstacktests(x)	x
#endif

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lmathlib.c ===
/*
** $Id: lmathlib.c,v 1.67 2005/08/26 17:36:32 roberto Exp $
** Standard mathematical library
** See Copyright Notice in lua.h
*/


#include <stdlib.h>
#include <math.h>

#define lmathlib_c
#define LUA_LIB

#include "lua.h"

#include "lauxlib.h"
#include "lualib.h"


#undef PI
#define PI (3.14159265358979323846)
#define RADIANS_PER_DEGREE (PI/180.0)



static int math_abs (lua_State *L) {
  lua_pushnumber(L, fabs(luaL_checknumber(L, 1)));
  return 1;
}

static int math_sin (lua_State *L) {
  lua_pushnumber(L, sin(luaL_checknumber(L, 1)));
  return 1;
}

static int math_sinh (lua_State *L) {
  lua_pushnumber(L, sinh(luaL_checknumber(L, 1)));
  return 1;
}

static int math_cos (lua_State *L) {
  lua_pushnumber(L, cos(luaL_checknumber(L, 1)));
  return 1;
}

static int math_cosh (lua_State *L) {
  lua_pushnumber(L, cosh(luaL_checknumber(L, 1)));
  return 1;
}

static int math_tan (lua_State *L) {
  lua_pushnumber(L, tan(luaL_checknumber(L, 1)));
  return 1;
}

static int math_tanh (lua_State *L) {
  lua_pushnumber(L, tanh(luaL_checknumber(L, 1)));
  return 1;
}

static int math_asin (lua_State *L) {
  lua_pushnumber(L, asin(luaL_checknumber(L, 1)));
  return 1;
}

static int math_acos (lua_State *L) {
  lua_pushnumber(L, acos(luaL_checknumber(L, 1)));
  return 1;
}

static int math_atan (lua_State *L) {
  lua_pushnumber(L, atan(luaL_checknumber(L, 1)));
  return 1;
}

static int math_atan2 (lua_State *L) {
  lua_pushnumber(L, atan2(luaL_checknumber(L, 1), luaL_checknumber(L, 2)));
  return 1;
}

static int math_ceil (lua_State *L) {
  lua_pushnumber(L, ceil(luaL_checknumber(L, 1)));
  return 1;
}

static int math_floor (lua_State *L) {
  lua_pushnumber(L, floor(luaL_checknumber(L, 1)));
  return 1;
}

static int math_fmod (lua_State *L) {
  lua_pushnumber(L, fmod(luaL_checknumber(L, 1), luaL_checknumber(L, 2)));
  return 1;
}

static int math_modf (lua_State *L) {
  double ip;
  double fp = modf(luaL_checknumber(L, 1), &ip);
  lua_pushnumber(L, ip);
  lua_pushnumber(L, fp);
  return 2;
}

static int math_sqrt (lua_State *L) {
  lua_pushnumber(L, sqrt(luaL_checknumber(L, 1)));
  return 1;
}

static int math_pow (lua_State *L) {
  lua_pushnumber(L, pow(luaL_checknumber(L, 1), luaL_checknumber(L, 2)));
  return 1;
}

static int math_log (lua_State *L) {
  lua_pushnumber(L, log(luaL_checknumber(L, 1)));
  return 1;
}

static int math_log10 (lua_State *L) {
  lua_pushnumber(L, log10(luaL_checknumber(L, 1)));
  return 1;
}

static int math_exp (lua_State *L) {
  lua_pushnumber(L, exp(luaL_checknumber(L, 1)));
  return 1;
}

static int math_deg (lua_State *L) {
  lua_pushnumber(L, luaL_checknumber(L, 1)/RADIANS_PER_DEGREE);
  return 1;
}

static int math_rad (lua_State *L) {
  lua_pushnumber(L, luaL_checknumber(L, 1)*RADIANS_PER_DEGREE);
  return 1;
}

static int math_frexp (lua_State *L) {
  int e;
  lua_pushnumber(L, frexp(luaL_checknumber(L, 1), &e));
  lua_pushinteger(L, e);
  return 2;
}

static int math_ldexp (lua_State *L) {
  lua_pushnumber(L, ldexp(luaL_checknumber(L, 1), luaL_checkint(L, 2)));
  return 1;
}



static int math_min (lua_State *L) {
  int n = lua_gettop(L);  /* number of arguments */
  lua_Number dmin = luaL_checknumber(L, 1);
  int i;
  for (i=2; i<=n; i++) {
    lua_Number d = luaL_checknumber(L, i);
    if (d < dmin)
      dmin = d;
  }
  lua_pushnumber(L, dmin);
  return 1;
}


static int math_max (lua_State *L) {
  int n = lua_gettop(L);  /* number of arguments */
  lua_Number dmax = luaL_checknumber(L, 1);
  int i;
  for (i=2; i<=n; i++) {
    lua_Number d = luaL_checknumber(L, i);
    if (d > dmax)
      dmax = d;
  }
  lua_pushnumber(L, dmax);
  return 1;
}


static int math_random (lua_State *L) {
  /* the `%' avoids the (rare) case of r==1, and is needed also because on
     some systems (SunOS!) `rand()' may return a value larger than RAND_MAX */
  lua_Number r = (lua_Number)(rand()%RAND_MAX) / (lua_Number)RAND_MAX;
  switch (lua_gettop(L)) {  /* check number of arguments */
    case 0: {  /* no arguments */
      lua_pushnumber(L, r);  /* Number between 0 and 1 */
      break;
    }
    case 1: {  /* only upper limit */
      int u = luaL_checkint(L, 1);
      luaL_argcheck(L, 1<=u, 1, "interval is empty");
      lua_pushnumber(L, floor(r*u)+1);  /* int between 1 and `u' */
      break;
    }
    case 2: {  /* lower and upper limits */
      int l = luaL_checkint(L, 1);
      int u = luaL_checkint(L, 2);
      luaL_argcheck(L, l<=u, 2, "interval is empty");
      lua_pushnumber(L, floor(r*(u-l+1))+l);  /* int between `l' and `u' */
      break;
    }
    default: return luaL_error(L, "wrong number of arguments");
  }
  return 1;
}


static int math_randomseed (lua_State *L) {
  srand(luaL_checkint(L, 1));
  return 0;
}


static const luaL_Reg mathlib[] = {
  {"abs",   math_abs},
  {"acos",  math_acos},
  {"asin",  math_asin},
  {"atan2", math_atan2},
  {"atan",  math_atan},
  {"ceil",  math_ceil},
  {"cosh",   math_cosh},
  {"cos",   math_cos},
  {"deg",   math_deg},
  {"exp",   math_exp},
  {"floor", math_floor},
  {"fmod",   math_fmod},
  {"frexp", math_frexp},
  {"ldexp", math_ldexp},
  {"log10", math_log10},
  {"log",   math_log},
  {"max",   math_max},
  {"min",   math_min},
  {"modf",   math_modf},
  {"pow",   math_pow},
  {"rad",   math_rad},
  {"random",     math_random},
  {"randomseed", math_randomseed},
  {"sinh",   math_sinh},
  {"sin",   math_sin},
  {"sqrt",  math_sqrt},
  {"tanh",   math_tanh},
  {"tan",   math_tan},
  {NULL, NULL}
};


/*
** Open math library
*/
LUALIB_API int luaopen_math (lua_State *L) {
  luaL_register(L, LUA_MATHLIBNAME, mathlib);
  lua_pushnumber(L, PI);
  lua_setfield(L, -2, "pi");
  lua_pushnumber(L, HUGE_VAL);
  lua_setfield(L, -2, "huge");
#if defined(LUA_COMPAT_MOD)
  lua_getfield(L, -1, "fmod");
  lua_setfield(L, -2, "mod");
#endif
  return 1;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\llex.h ===
/*
** $Id: llex.h,v 1.58 2006/03/23 18:23:32 roberto Exp $
** Lexical Analyzer
** See Copyright Notice in lua.h
*/

#ifndef llex_h
#define llex_h

#include "lobject.h"
#include "lzio.h"


#define FIRST_RESERVED	257

/* maximum length of a reserved word */
#define TOKEN_LEN	(sizeof("function")/sizeof(char))


/*
* WARNING: if you change the order of this enumeration,
* grep "ORDER RESERVED"
*/
enum RESERVED {
  /* terminal symbols denoted by reserved words */
  TK_AND = FIRST_RESERVED, TK_BREAK,
  TK_DO, TK_ELSE, TK_ELSEIF, TK_END, TK_FALSE, TK_FOR, TK_FUNCTION,
  TK_IF, TK_IN, TK_LOCAL, TK_NIL, TK_NOT, TK_OR, TK_REPEAT,
  TK_RETURN, TK_THEN, TK_TRUE, TK_UNTIL, TK_WHILE,
  /* other terminal symbols */
  TK_CONCAT, TK_DOTS, TK_EQ, TK_GE, TK_LE, TK_NE, TK_NUMBER,
  TK_NAME, TK_STRING, TK_EOS
};

/* number of reserved words */
#define NUM_RESERVED	(cast(int, TK_WHILE-FIRST_RESERVED+1))


/* array with token `names' */
LUAI_DATA const char *const luaX_tokens [];


typedef union {
  lua_Number r;
  TString *ts;
} SemInfo;  /* semantics information */


typedef struct Token {
  int token;
  SemInfo seminfo;
} Token;


typedef struct LexState {
  int current;  /* current character (charint) */
  int linenumber;  /* input line counter */
  int lastline;  /* line of last token `consumed' */
  Token t;  /* current token */
  Token lookahead;  /* look ahead token */
  struct FuncState *fs;  /* `FuncState' is private to the parser */
  struct lua_State *L;
  ZIO *z;  /* input stream */
  Mbuffer *buff;  /* buffer for tokens */
  TString *source;  /* current source name */
  char decpoint;  /* locale decimal point */
} LexState;


LUAI_FUNC void luaX_init (lua_State *L);
LUAI_FUNC void luaX_setinput (lua_State *L, LexState *ls, ZIO *z,
                              TString *source);
LUAI_FUNC TString *luaX_newstring (LexState *ls, const char *str, size_t l);
LUAI_FUNC void luaX_next (LexState *ls);
LUAI_FUNC void luaX_lookahead (LexState *ls);
LUAI_FUNC void luaX_lexerror (LexState *ls, const char *msg, int token);
LUAI_FUNC void luaX_syntaxerror (LexState *ls, const char *s);
LUAI_FUNC const char *luaX_token2str (LexState *ls, int token);


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lmem.h ===
/*
** $Id: lmem.h,v 1.31 2005/04/25 19:24:10 roberto Exp $
** Interface to Memory Manager
** See Copyright Notice in lua.h
*/

#ifndef lmem_h
#define lmem_h


#include <stddef.h>

#include "llimits.h"
#include "lua.h"

#define MEMERRMSG	"not enough memory"


#define luaM_reallocv(L,b,on,n,e) \
	((cast(size_t, (n)+1) <= MAX_SIZET/(e)) ?  /* +1 to avoid warnings */ \
		luaM_realloc_(L, (b), (on)*(e), (n)*(e)) : \
		luaM_toobig(L))

#define luaM_freemem(L, b, s)	luaM_realloc_(L, (b), (s), 0)
#define luaM_free(L, b)		luaM_realloc_(L, (b), sizeof(*(b)), 0)
#define luaM_freearray(L, b, n, t)   luaM_reallocv(L, (b), n, 0, sizeof(t))

#define luaM_malloc(L,t)	luaM_realloc_(L, NULL, 0, (t))
#define luaM_new(L,t)		cast(t *, luaM_malloc(L, sizeof(t)))
#define luaM_newvector(L,n,t) \
		cast(t *, luaM_reallocv(L, NULL, 0, n, sizeof(t)))

#define luaM_growvector(L,v,nelems,size,t,limit,e) \
          if ((nelems)+1 > (size)) \
            ((v)=cast(t *, luaM_growaux_(L,v,&(size),sizeof(t),limit,e)))

#define luaM_reallocvector(L, v,oldn,n,t) \
   ((v)=cast(t *, luaM_reallocv(L, v, oldn, n, sizeof(t))))


LUAI_FUNC void *luaM_realloc_ (lua_State *L, void *block, size_t oldsize,
                                                          size_t size);
LUAI_FUNC void *luaM_toobig (lua_State *L);
LUAI_FUNC void *luaM_growaux_ (lua_State *L, void *block, int *size,
                               size_t size_elem, int limit,
                               const char *errormsg);

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lmem.c ===
/*
** $Id: lmem.c,v 1.70 2005/12/26 13:35:47 roberto Exp $
** Interface to Memory Manager
** See Copyright Notice in lua.h
*/


#include <stddef.h>

#define lmem_c
#define LUA_CORE

#include "lua.h"

#include "ldebug.h"
#include "ldo.h"
#include "lmem.h"
#include "lobject.h"
#include "lstate.h"



/*
** About the realloc function:
** void * frealloc (void *ud, void *ptr, size_t osize, size_t nsize);
** (`osize' is the old size, `nsize' is the new size)
**
** Lua ensures that (ptr == NULL) iff (osize == 0).
**
** * frealloc(ud, NULL, 0, x) creates a new block of size `x'
**
** * frealloc(ud, p, x, 0) frees the block `p'
** (in this specific case, frealloc must return NULL).
** particularly, frealloc(ud, NULL, 0, 0) does nothing
** (which is equivalent to free(NULL) in ANSI C)
**
** frealloc returns NULL if it cannot create or reallocate the area
** (any reallocation to an equal or smaller size cannot fail!)
*/



#define MINSIZEARRAY	4


void *luaM_growaux_ (lua_State *L, void *block, int *size, size_t size_elems,
                     int limit, const char *errormsg) {
  void *newblock;
  int newsize;
  if (*size >= limit/2) {  /* cannot double it? */
    if (*size >= limit)  /* cannot grow even a little? */
      luaG_runerror(L, errormsg);
    newsize = limit;  /* still have at least one free place */
  }
  else {
    newsize = (*size)*2;
    if (newsize < MINSIZEARRAY)
      newsize = MINSIZEARRAY;  /* minimum size */
  }
  newblock = luaM_reallocv(L, block, *size, newsize, size_elems);
  *size = newsize;  /* update only when everything else is OK */
  return newblock;
}


void *luaM_toobig (lua_State *L) {
  luaG_runerror(L, "memory allocation error: block too big");
  return NULL;  /* to avoid warnings */
}



/*
** generic allocation routine.
*/
void *luaM_realloc_ (lua_State *L, void *block, size_t osize, size_t nsize) {
  global_State *g = G(L);
  lua_assert((osize == 0) == (block == NULL));
  block = (*g->frealloc)(g->ud, block, osize, nsize);
  if (block == NULL && nsize > 0)
    luaD_throw(L, LUA_ERRMEM);
  lua_assert((nsize == 0) == (block == NULL));
  g->totalbytes = (g->totalbytes - osize) + nsize;
  return block;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lobject.h ===
/*
** $Id: lobject.h,v 2.20 2006/01/18 11:37:34 roberto Exp $
** Type definitions for Lua objects
** See Copyright Notice in lua.h
*/


#ifndef lobject_h
#define lobject_h


#include <stdarg.h>


#include "llimits.h"
#include "lua.h"


/* tags for values visible from Lua */
#define LAST_TAG	LUA_TTHREAD

#define NUM_TAGS	(LAST_TAG+1)


/*
** Extra tags for non-values
*/
#define LUA_TPROTO	(LAST_TAG+1)
#define LUA_TUPVAL	(LAST_TAG+2)
#define LUA_TDEADKEY	(LAST_TAG+3)


/*
** Union of all collectable objects
*/
typedef union GCObject GCObject;


/*
** Common Header for all collectable objects (in macro form, to be
** included in other objects)
*/
#define CommonHeader	GCObject *next; lu_byte tt; lu_byte marked


/*
** Common header in struct form
*/
typedef struct GCheader {
  CommonHeader;
} GCheader;




/*
** Union of all Lua values
*/
typedef union {
  GCObject *gc;
  void *p;
  lua_Number n;
  int b;
} Value;


/*
** Tagged Values
*/

#define TValuefields	Value value; int tt

typedef struct lua_TValue {
  TValuefields;
} TValue;


/* Macros to test type */
#define ttisnil(o)	(ttype(o) == LUA_TNIL)
#define ttisnumber(o)	(ttype(o) == LUA_TNUMBER)
#define ttisstring(o)	(ttype(o) == LUA_TSTRING)
#define ttistable(o)	(ttype(o) == LUA_TTABLE)
#define ttisfunction(o)	(ttype(o) == LUA_TFUNCTION)
#define ttisboolean(o)	(ttype(o) == LUA_TBOOLEAN)
#define ttisuserdata(o)	(ttype(o) == LUA_TUSERDATA)
#define ttisthread(o)	(ttype(o) == LUA_TTHREAD)
#define ttislightuserdata(o)	(ttype(o) == LUA_TLIGHTUSERDATA)

/* Macros to access values */
#define ttype(o)	((o)->tt)
#define gcvalue(o)	check_exp(iscollectable(o), (o)->value.gc)
#define pvalue(o)	check_exp(ttislightuserdata(o), (o)->value.p)
#define nvalue(o)	check_exp(ttisnumber(o), (o)->value.n)
#define rawtsvalue(o)	check_exp(ttisstring(o), &(o)->value.gc->ts)
#define tsvalue(o)	(&rawtsvalue(o)->tsv)
#define rawuvalue(o)	check_exp(ttisuserdata(o), &(o)->value.gc->u)
#define uvalue(o)	(&rawuvalue(o)->uv)
#define clvalue(o)	check_exp(ttisfunction(o), &(o)->value.gc->cl)
#define hvalue(o)	check_exp(ttistable(o), &(o)->value.gc->h)
#define bvalue(o)	check_exp(ttisboolean(o), (o)->value.b)
#define thvalue(o)	check_exp(ttisthread(o), &(o)->value.gc->th)

#define l_isfalse(o)	(ttisnil(o) || (ttisboolean(o) && bvalue(o) == 0))

/*
** for internal debug only
*/
#define checkconsistency(obj) \
  lua_assert(!iscollectable(obj) || (ttype(obj) == (obj)->value.gc->gch.tt))

#define checkliveness(g,obj) \
  lua_assert(!iscollectable(obj) || \
  ((ttype(obj) == (obj)->value.gc->gch.tt) && !isdead(g, (obj)->value.gc)))


/* Macros to set values */
#define setnilvalue(obj) ((obj)->tt=LUA_TNIL)

#define setnvalue(obj,x) \
  { TValue *i_o=(obj); i_o->value.n=(x); i_o->tt=LUA_TNUMBER; }

#define setpvalue(obj,x) \
  { TValue *i_o=(obj); i_o->value.p=(x); i_o->tt=LUA_TLIGHTUSERDATA; }

#define setbvalue(obj,x) \
  { TValue *i_o=(obj); i_o->value.b=(x); i_o->tt=LUA_TBOOLEAN; }

#define setsvalue(L,obj,x) \
  { TValue *i_o=(obj); \
    i_o->value.gc=cast(GCObject *, (x)); i_o->tt=LUA_TSTRING; \
    checkliveness(G(L),i_o); }

#define setuvalue(L,obj,x) \
  { TValue *i_o=(obj); \
    i_o->value.gc=cast(GCObject *, (x)); i_o->tt=LUA_TUSERDATA; \
    checkliveness(G(L),i_o); }

#define setthvalue(L,obj,x) \
  { TValue *i_o=(obj); \
    i_o->value.gc=cast(GCObject *, (x)); i_o->tt=LUA_TTHREAD; \
    checkliveness(G(L),i_o); }

#define setclvalue(L,obj,x) \
  { TValue *i_o=(obj); \
    i_o->value.gc=cast(GCObject *, (x)); i_o->tt=LUA_TFUNCTION; \
    checkliveness(G(L),i_o); }

#define sethvalue(L,obj,x) \
  { TValue *i_o=(obj); \
    i_o->value.gc=cast(GCObject *, (x)); i_o->tt=LUA_TTABLE; \
    checkliveness(G(L),i_o); }

#define setptvalue(L,obj,x) \
  { TValue *i_o=(obj); \
    i_o->value.gc=cast(GCObject *, (x)); i_o->tt=LUA_TPROTO; \
    checkliveness(G(L),i_o); }




#define setobj(L,obj1,obj2) \
  { const TValue *o2=(obj2); TValue *o1=(obj1); \
    o1->value = o2->value; o1->tt=o2->tt; \
    checkliveness(G(L),o1); }


/*
** different types of sets, according to destination
*/

/* from stack to (same) stack */
#define setobjs2s	setobj
/* to stack (not from same stack) */
#define setobj2s	setobj
#define setsvalue2s	setsvalue
#define sethvalue2s	sethvalue
#define setptvalue2s	setptvalue
/* from table to same table */
#define setobjt2t	setobj
/* to table */
#define setobj2t	setobj
/* to new object */
#define setobj2n	setobj
#define setsvalue2n	setsvalue

#define setttype(obj, tt) (ttype(obj) = (tt))


#define iscollectable(o)	(ttype(o) >= LUA_TSTRING)



typedef TValue *StkId;  /* index to stack elements */


/*
** String headers for string table
*/
typedef union TString {
  L_Umaxalign dummy;  /* ensures maximum alignment for strings */
  struct {
    CommonHeader;
    lu_byte reserved;
    unsigned int hash;
    size_t len;
  } tsv;
} TString;


#define getstr(ts)	cast(const char *, (ts) + 1)
#define svalue(o)       getstr(tsvalue(o))



typedef union Udata {
  L_Umaxalign dummy;  /* ensures maximum alignment for `local' udata */
  struct {
    CommonHeader;
    struct Table *metatable;
    struct Table *env;
    size_t len;
  } uv;
} Udata;




/*
** Function Prototypes
*/
typedef struct Proto {
  CommonHeader;
  TValue *k;  /* constants used by the function */
  Instruction *code;
  struct Proto **p;  /* functions defined inside the function */
  int *lineinfo;  /* map from opcodes to source lines */
  struct LocVar *locvars;  /* information about local variables */
  TString **upvalues;  /* upvalue names */
  TString  *source;
  int sizeupvalues;
  int sizek;  /* size of `k' */
  int sizecode;
  int sizelineinfo;
  int sizep;  /* size of `p' */
  int sizelocvars;
  int linedefined;
  int lastlinedefined;
  GCObject *gclist;
  lu_byte nups;  /* number of upvalues */
  lu_byte numparams;
  lu_byte is_vararg;
  lu_byte maxstacksize;
} Proto;


/* masks for new-style vararg */
#define VARARG_HASARG		1
#define VARARG_ISVARARG		2
#define VARARG_NEEDSARG		4


typedef struct LocVar {
  TString *varname;
  int startpc;  /* first point where variable is active */
  int endpc;    /* first point where variable is dead */
} LocVar;



/*
** Upvalues
*/

typedef struct UpVal {
  CommonHeader;
  TValue *v;  /* points to stack or to its own value */
  union {
    TValue value;  /* the value (when closed) */
    struct {  /* double linked list (when open) */
      struct UpVal *prev;
      struct UpVal *next;
    } l;
  } u;
} UpVal;


/*
** Closures
*/

#define ClosureHeader \
	CommonHeader; lu_byte isC; lu_byte nupvalues; GCObject *gclist; \
	struct Table *env

typedef struct CClosure {
  ClosureHeader;
  lua_CFunction f;
  TValue upvalue[1];
} CClosure;


typedef struct LClosure {
  ClosureHeader;
  struct Proto *p;
  UpVal *upvals[1];
} LClosure;


typedef union Closure {
  CClosure c;
  LClosure l;
} Closure;


#define iscfunction(o)	(ttype(o) == LUA_TFUNCTION && clvalue(o)->c.isC)
#define isLfunction(o)	(ttype(o) == LUA_TFUNCTION && !clvalue(o)->c.isC)


/*
** Tables
*/

typedef union TKey {
  struct {
    TValuefields;
    struct Node *next;  /* for chaining */
  } nk;
  TValue tvk;
} TKey;


typedef struct Node {
  TValue i_val;
  TKey i_key;
} Node;


typedef struct Table {
  CommonHeader;
  lu_byte flags;  /* 1<<p means tagmethod(p) is not present */ 
  lu_byte lsizenode;  /* log2 of size of `node' array */
  struct Table *metatable;
  TValue *array;  /* array part */
  Node *node;
  Node *lastfree;  /* any free position is before this position */
  GCObject *gclist;
  int sizearray;  /* size of `array' array */
} Table;



/*
** `module' operation for hashing (size is always a power of 2)
*/
#define lmod(s,size) \
	(check_exp((size&(size-1))==0, (cast(int, (s) & ((size)-1)))))


#define twoto(x)	(1<<(x))
#define sizenode(t)	(twoto((t)->lsizenode))


#define luaO_nilobject		(&luaO_nilobject_)

LUAI_DATA const TValue luaO_nilobject_;

#define ceillog2(x)	(luaO_log2((x)-1) + 1)

LUAI_FUNC int luaO_log2 (unsigned int x);
LUAI_FUNC int luaO_int2fb (unsigned int x);
LUAI_FUNC int luaO_fb2int (int x);
LUAI_FUNC int luaO_rawequalObj (const TValue *t1, const TValue *t2);
LUAI_FUNC int luaO_str2d (const char *s, lua_Number *result);
LUAI_FUNC const char *luaO_pushvfstring (lua_State *L, const char *fmt,
                                                       va_list argp);
LUAI_FUNC const char *luaO_pushfstring (lua_State *L, const char *fmt, ...);
LUAI_FUNC void luaO_chunkid (char *out, const char *source, size_t len);


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lopcodes.c ===
/*
** $Id: lopcodes.c,v 1.37 2005/11/08 19:45:36 roberto Exp $
** See Copyright Notice in lua.h
*/


#define lopcodes_c
#define LUA_CORE


#include "lopcodes.h"


/* ORDER OP */

const char *const luaP_opnames[NUM_OPCODES+1] = {
  "MOVE",
  "LOADK",
  "LOADBOOL",
  "LOADNIL",
  "GETUPVAL",
  "GETGLOBAL",
  "GETTABLE",
  "SETGLOBAL",
  "SETUPVAL",
  "SETTABLE",
  "NEWTABLE",
  "SELF",
  "ADD",
  "SUB",
  "MUL",
  "DIV",
  "MOD",
  "POW",
  "UNM",
  "NOT",
  "LEN",
  "CONCAT",
  "JMP",
  "EQ",
  "LT",
  "LE",
  "TEST",
  "TESTSET",
  "CALL",
  "TAILCALL",
  "RETURN",
  "FORLOOP",
  "FORPREP",
  "TFORLOOP",
  "SETLIST",
  "CLOSE",
  "CLOSURE",
  "VARARG",
  NULL
};


#define opmode(t,a,b,c,m) (((t)<<7) | ((a)<<6) | ((b)<<4) | ((c)<<2) | (m))

const lu_byte luaP_opmodes[NUM_OPCODES] = {
/*       T  A    B       C     mode		   opcode	*/
  opmode(0, 1, OpArgR, OpArgN, iABC) 		/* OP_MOVE */
 ,opmode(0, 1, OpArgK, OpArgN, iABx)		/* OP_LOADK */
 ,opmode(0, 1, OpArgU, OpArgU, iABC)		/* OP_LOADBOOL */
 ,opmode(0, 1, OpArgR, OpArgN, iABC)		/* OP_LOADNIL */
 ,opmode(0, 1, OpArgU, OpArgN, iABC)		/* OP_GETUPVAL */
 ,opmode(0, 1, OpArgK, OpArgN, iABx)		/* OP_GETGLOBAL */
 ,opmode(0, 1, OpArgR, OpArgK, iABC)		/* OP_GETTABLE */
 ,opmode(0, 0, OpArgK, OpArgN, iABx)		/* OP_SETGLOBAL */
 ,opmode(0, 0, OpArgU, OpArgN, iABC)		/* OP_SETUPVAL */
 ,opmode(0, 0, OpArgK, OpArgK, iABC)		/* OP_SETTABLE */
 ,opmode(0, 1, OpArgU, OpArgU, iABC)		/* OP_NEWTABLE */
 ,opmode(0, 1, OpArgR, OpArgK, iABC)		/* OP_SELF */
 ,opmode(0, 1, OpArgK, OpArgK, iABC)		/* OP_ADD */
 ,opmode(0, 1, OpArgK, OpArgK, iABC)		/* OP_SUB */
 ,opmode(0, 1, OpArgK, OpArgK, iABC)		/* OP_MUL */
 ,opmode(0, 1, OpArgK, OpArgK, iABC)		/* OP_DIV */
 ,opmode(0, 1, OpArgK, OpArgK, iABC)		/* OP_MOD */
 ,opmode(0, 1, OpArgK, OpArgK, iABC)		/* OP_POW */
 ,opmode(0, 1, OpArgR, OpArgN, iABC)		/* OP_UNM */
 ,opmode(0, 1, OpArgR, OpArgN, iABC)		/* OP_NOT */
 ,opmode(0, 1, OpArgR, OpArgN, iABC)		/* OP_LEN */
 ,opmode(0, 1, OpArgR, OpArgR, iABC)		/* OP_CONCAT */
 ,opmode(0, 0, OpArgR, OpArgN, iAsBx)		/* OP_JMP */
 ,opmode(1, 0, OpArgK, OpArgK, iABC)		/* OP_EQ */
 ,opmode(1, 0, OpArgK, OpArgK, iABC)		/* OP_LT */
 ,opmode(1, 0, OpArgK, OpArgK, iABC)		/* OP_LE */
 ,opmode(1, 1, OpArgR, OpArgU, iABC)		/* OP_TEST */
 ,opmode(1, 1, OpArgR, OpArgU, iABC)		/* OP_TESTSET */
 ,opmode(0, 1, OpArgU, OpArgU, iABC)		/* OP_CALL */
 ,opmode(0, 1, OpArgU, OpArgU, iABC)		/* OP_TAILCALL */
 ,opmode(0, 0, OpArgU, OpArgN, iABC)		/* OP_RETURN */
 ,opmode(0, 1, OpArgR, OpArgN, iAsBx)		/* OP_FORLOOP */
 ,opmode(0, 1, OpArgR, OpArgN, iAsBx)		/* OP_FORPREP */
 ,opmode(1, 0, OpArgN, OpArgU, iABC)		/* OP_TFORLOOP */
 ,opmode(0, 0, OpArgU, OpArgU, iABC)		/* OP_SETLIST */
 ,opmode(0, 0, OpArgN, OpArgN, iABC)		/* OP_CLOSE */
 ,opmode(0, 1, OpArgU, OpArgN, iABx)		/* OP_CLOSURE */
 ,opmode(0, 1, OpArgU, OpArgN, iABC)		/* OP_VARARG */
};
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lobject.c ===
/*
** $Id: lobject.c,v 2.22 2006/02/10 17:43:52 roberto Exp $
** Some generic functions over Lua objects
** See Copyright Notice in lua.h
*/

#include <ctype.h>
#include <stdarg.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define lobject_c
#define LUA_CORE

#include "lua.h"

#include "ldo.h"
#include "lmem.h"
#include "lobject.h"
#include "lstate.h"
#include "lstring.h"
#include "lvm.h"



const TValue luaO_nilobject_ = {{NULL}, LUA_TNIL};


/*
** converts an integer to a "floating point byte", represented as
** (eeeeexxx), where the real value is (1xxx) * 2^(eeeee - 1) if
** eeeee != 0 and (xxx) otherwise.
*/
int luaO_int2fb (unsigned int x) {
  int e = 0;  /* expoent */
  while (x >= 16) {
    x = (x+1) >> 1;
    e++;
  }
  if (x < 8) return x;
  else return ((e+1) << 3) | (cast_int(x) - 8);
}


/* converts back */
int luaO_fb2int (int x) {
  int e = (x >> 3) & 31;
  if (e == 0) return x;
  else return ((x & 7)+8) << (e - 1);
}


int luaO_log2 (unsigned int x) {
  static const lu_byte log_2[256] = {
    0,1,2,2,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,
    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
    8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,
    8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,
    8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,
    8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8
  };
  int l = -1;
  while (x >= 256) { l += 8; x >>= 8; }
  return l + log_2[x];

}


int luaO_rawequalObj (const TValue *t1, const TValue *t2) {
  if (ttype(t1) != ttype(t2)) return 0;
  else switch (ttype(t1)) {
    case LUA_TNIL:
      return 1;
    case LUA_TNUMBER:
      return luai_numeq(nvalue(t1), nvalue(t2));
    case LUA_TBOOLEAN:
      return bvalue(t1) == bvalue(t2);  /* boolean true must be 1 !! */
    case LUA_TLIGHTUSERDATA:
      return pvalue(t1) == pvalue(t2);
    default:
      lua_assert(iscollectable(t1));
      return gcvalue(t1) == gcvalue(t2);
  }
}


int luaO_str2d (const char *s, lua_Number *result) {
  char *endptr;
  *result = lua_str2number(s, &endptr);
  if (endptr == s) return 0;  /* conversion failed */
  if (*endptr == 'x' || *endptr == 'X')  /* maybe an hexadecimal constant? */
    *result = cast_num(strtoul(s, &endptr, 16));
  if (*endptr == '\0') return 1;  /* most common case */
  while (isspace(cast(unsigned char, *endptr))) endptr++;
  if (*endptr != '\0') return 0;  /* invalid trailing characters? */
  return 1;
}



static void pushstr (lua_State *L, const char *str) {
  setsvalue2s(L, L->top, luaS_new(L, str));
  incr_top(L);
}


/* this function handles only `%d', `%c', %f, %p, and `%s' formats */
const char *luaO_pushvfstring (lua_State *L, const char *fmt, va_list argp) {
  int n = 1;
  pushstr(L, "");
  for (;;) {
    const char *e = strchr(fmt, '%');
    if (e == NULL) break;
    setsvalue2s(L, L->top, luaS_newlstr(L, fmt, e-fmt));
    incr_top(L);
    switch (*(e+1)) {
      case 's': {
        const char *s = va_arg(argp, char *);
        if (s == NULL) s = "(null)";
        pushstr(L, s);
        break;
      }
      case 'c': {
        char buff[2];
        buff[0] = cast(char, va_arg(argp, int));
        buff[1] = '\0';
        pushstr(L, buff);
        break;
      }
      case 'd': {
        setnvalue(L->top, cast_num(va_arg(argp, int)));
        incr_top(L);
        break;
      }
      case 'f': {
        setnvalue(L->top, cast_num(va_arg(argp, l_uacNumber)));
        incr_top(L);
        break;
      }
      case 'p': {
        char buff[4*sizeof(void *) + 8]; /* should be enough space for a `%p' */
        sprintf(buff, "%p", va_arg(argp, void *));
        pushstr(L, buff);
        break;
      }
      case '%': {
        pushstr(L, "%");
        break;
      }
      default: {
        char buff[3];
        buff[0] = '%';
        buff[1] = *(e+1);
        buff[2] = '\0';
        pushstr(L, buff);
        break;
      }
    }
    n += 2;
    fmt = e+2;
  }
  pushstr(L, fmt);
  luaV_concat(L, n+1, cast_int(L->top - L->base) - 1);
  L->top -= n;
  return svalue(L->top - 1);
}


const char *luaO_pushfstring (lua_State *L, const char *fmt, ...) {
  const char *msg;
  va_list argp;
  va_start(argp, fmt);
  msg = luaO_pushvfstring(L, fmt, argp);
  va_end(argp);
  return msg;
}


void luaO_chunkid (char *out, const char *source, size_t bufflen) {
  if (*source == '=') {
    strncpy(out, source+1, bufflen);  /* remove first char */
    out[bufflen-1] = '\0';  /* ensures null termination */
  }
  else {  /* out = "source", or "...source" */
    if (*source == '@') {
      size_t l;
      source++;  /* skip the `@' */
      bufflen -= sizeof(" '...' ");
      l = strlen(source);
      strcpy(out, "");
      if (l > bufflen) {
        source += (l-bufflen);  /* get last part of file name */
        strcat(out, "...");
      }
      strcat(out, source);
    }
    else {  /* out = [string "string"] */
      size_t len = strcspn(source, "\n\r");  /* stop at first newline */
      bufflen -= sizeof(" [string \"...\"] ");
      if (len > bufflen) len = bufflen;
      strcpy(out, "[string \"");
      if (source[len] != '\0') {  /* must truncate? */
        strncat(out, source, len);
        strcat(out, "...");
      }
      else
        strcat(out, source);
      strcat(out, "\"]");
    }
  }
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\loadlib.c ===
/*
** $Id: loadlib.c,v 1.52 2006/04/10 18:27:23 roberto Exp $
** Dynamic library loader for Lua
** See Copyright Notice in lua.h
**
** This module contains an implementation of loadlib for Unix systems
** that have dlfcn, an implementation for Darwin (Mac OS X), an
** implementation for Windows, and a stub for other systems.
*/


#include <stdlib.h>
#include <string.h>


#define loadlib_c
#define LUA_LIB

#include "lauxlib.h"
#include "lobject.h"
#include "lua.h"
#include "lualib.h"


/* prefix for open functions in C libraries */
#define LUA_POF		"luaopen_"

/* separator for open functions in C libraries */
#define LUA_OFSEP	"_"


#define LIBPREFIX	"LOADLIB: "

#define POF		LUA_POF
#define LIB_FAIL	"open"


/* error codes for ll_loadfunc */
#define ERRLIB		1
#define ERRFUNC		2

#define setprogdir(L)		((void)0)


static void ll_unloadlib (void *lib);
static void *ll_load (lua_State *L, const char *path);
static lua_CFunction ll_sym (lua_State *L, void *lib, const char *sym);



#if defined(LUA_DL_DLOPEN)
/*
** {========================================================================
** This is an implementation of loadlib based on the dlfcn interface.
** The dlfcn interface is available in Linux, SunOS, Solaris, IRIX, FreeBSD,
** NetBSD, AIX 4.2, HPUX 11, and  probably most other Unix flavors, at least
** as an emulation layer on top of native functions.
** =========================================================================
*/

#include <dlfcn.h>

static void ll_unloadlib (void *lib) {
  dlclose(lib);
}


static void *ll_load (lua_State *L, const char *path) {
  void *lib = dlopen(path, RTLD_NOW);
  if (lib == NULL) lua_pushstring(L, dlerror());
  return lib;
}


static lua_CFunction ll_sym (lua_State *L, void *lib, const char *sym) {
  lua_CFunction f = (lua_CFunction)dlsym(lib, sym);
  if (f == NULL) lua_pushstring(L, dlerror());
  return f;
}

/* }====================================================== */



#elif defined(LUA_DL_DLL)
/*
** {======================================================================
** This is an implementation of loadlib for Windows using native functions.
** =======================================================================
*/

#include <windows.h>


#undef setprogdir

static void setprogdir (lua_State *L) {
  char buff[MAX_PATH + 1];
  char *lb;
  DWORD nsize = sizeof(buff)/sizeof(char);
  DWORD n = GetModuleFileName(NULL, buff, nsize);
  if (n == 0 || n == nsize || (lb = strrchr(buff, '\\')) == NULL)
    luaL_error(L, "unable to get ModuleFileName");
  else {
    *lb = '\0';
    luaL_gsub(L, lua_tostring(L, -1), LUA_EXECDIR, buff);
    lua_remove(L, -2);  /* remove original string */
  }
}


static void pusherror (lua_State *L) {
  int error = GetLastError();
  char buffer[128];
  if (FormatMessage(FORMAT_MESSAGE_IGNORE_INSERTS | FORMAT_MESSAGE_FROM_SYSTEM,
      NULL, error, 0, buffer, sizeof(buffer), NULL))
    lua_pushstring(L, buffer);
  else
    lua_pushfstring(L, "system error %d\n", error);
}

static void ll_unloadlib (void *lib) {
  FreeLibrary((HINSTANCE)lib);
}


static void *ll_load (lua_State *L, const char *path) {
  HINSTANCE lib = LoadLibrary(path);
  if (lib == NULL) pusherror(L);
  return lib;
}


static lua_CFunction ll_sym (lua_State *L, void *lib, const char *sym) {
  lua_CFunction f = (lua_CFunction)GetProcAddress((HINSTANCE)lib, sym);
  if (f == NULL) pusherror(L);
  return f;
}

/* }====================================================== */



#elif defined(LUA_DL_DYLD)
/*
** {======================================================================
** Native Mac OS X / Darwin Implementation
** =======================================================================
*/

#include <mach-o/dyld.h>


/* Mac appends a `_' before C function names */
#undef POF
#define POF	"_" LUA_POF


static void pusherror (lua_State *L) {
  const char *err_str;
  const char *err_file;
  NSLinkEditErrors err;
  int err_num;
  NSLinkEditError(&err, &err_num, &err_file, &err_str);
  lua_pushstring(L, err_str);
}


static const char *errorfromcode (NSObjectFileImageReturnCode ret) {
  switch (ret) {
    case NSObjectFileImageInappropriateFile:
      return "file is not a bundle";
    case NSObjectFileImageArch:
      return "library is for wrong CPU type";
    case NSObjectFileImageFormat:
      return "bad format";
    case NSObjectFileImageAccess:
      return "cannot access file";
    case NSObjectFileImageFailure:
    default:
      return "unable to load library";
  }
}


static void ll_unloadlib (void *lib) {
  NSUnLinkModule((NSModule)lib, NSUNLINKMODULE_OPTION_RESET_LAZY_REFERENCES);
}


static void *ll_load (lua_State *L, const char *path) {
  NSObjectFileImage img;
  NSObjectFileImageReturnCode ret;
  /* this would be a rare case, but prevents crashing if it happens */
  if(!_dyld_present()) {
    lua_pushliteral(L, "dyld not present");
    return NULL;
  }
  ret = NSCreateObjectFileImageFromFile(path, &img);
  if (ret == NSObjectFileImageSuccess) {
    NSModule mod = NSLinkModule(img, path, NSLINKMODULE_OPTION_PRIVATE |
                       NSLINKMODULE_OPTION_RETURN_ON_ERROR);
    NSDestroyObjectFileImage(img);
    if (mod == NULL) pusherror(L);
    return mod;
  }
  lua_pushstring(L, errorfromcode(ret));
  return NULL;
}


static lua_CFunction ll_sym (lua_State *L, void *lib, const char *sym) {
  NSSymbol nss = NSLookupSymbolInModule((NSModule)lib, sym);
  if (nss == NULL) {
    lua_pushfstring(L, "symbol " LUA_QS " not found", sym);
    return NULL;
  }
  return (lua_CFunction)NSAddressOfSymbol(nss);
}

/* }====================================================== */



#else
/*
** {======================================================
** Fallback for other systems
** =======================================================
*/

#undef LIB_FAIL
#define LIB_FAIL	"absent"


#define DLMSG	"dynamic libraries not enabled; check your Lua installation"


static void ll_unloadlib (void *lib) {
  (void)lib;  /* to avoid warnings */
}


static void *ll_load (lua_State *L, const char *path) {
  (void)path;  /* to avoid warnings */
  lua_pushliteral(L, DLMSG);
  return NULL;
}


static lua_CFunction ll_sym (lua_State *L, void *lib, const char *sym) {
  (void)lib; (void)sym;  /* to avoid warnings */
  lua_pushliteral(L, DLMSG);
  return NULL;
}

/* }====================================================== */
#endif



static void **ll_register (lua_State *L, const char *path) {
  void **plib;
  lua_pushfstring(L, "%s%s", LIBPREFIX, path);
  lua_gettable(L, LUA_REGISTRYINDEX);  /* check library in registry? */
  if (!lua_isnil(L, -1))  /* is there an entry? */
    plib = (void **)lua_touserdata(L, -1);
  else {  /* no entry yet; create one */
    lua_pop(L, 1);
    plib = (void **)lua_newuserdata(L, sizeof(const void *));
    *plib = NULL;
    luaL_getmetatable(L, "_LOADLIB");
    lua_setmetatable(L, -2);
    lua_pushfstring(L, "%s%s", LIBPREFIX, path);
    lua_pushvalue(L, -2);
    lua_settable(L, LUA_REGISTRYINDEX);
  }
  return plib;
}


/*
** __gc tag method: calls library's `ll_unloadlib' function with the lib
** handle
*/
static int gctm (lua_State *L) {
  void **lib = (void **)luaL_checkudata(L, 1, "_LOADLIB");
  if (*lib) ll_unloadlib(*lib);
  *lib = NULL;  /* mark library as closed */
  return 0;
}


static int ll_loadfunc (lua_State *L, const char *path, const char *sym) {
  void **reg = ll_register(L, path);
  if (*reg == NULL) *reg = ll_load(L, path);
  if (*reg == NULL)
    return ERRLIB;  /* unable to load library */
  else {
    lua_CFunction f = ll_sym(L, *reg, sym);
    if (f == NULL)
      return ERRFUNC;  /* unable to find function */
    lua_pushcfunction(L, f);
    return 0;  /* return function */
  }
}


static int ll_loadlib (lua_State *L) {
  const char *path = luaL_checkstring(L, 1);
  const char *init = luaL_checkstring(L, 2);
  int stat = ll_loadfunc(L, path, init);
  if (stat == 0)  /* no errors? */
    return 1;  /* return the loaded function */
  else {  /* error; error message is on stack top */
    lua_pushnil(L);
    lua_insert(L, -2);
    lua_pushstring(L, (stat == ERRLIB) ?  LIB_FAIL : "init");
    return 3;  /* return nil, error message, and where */
  }
}



/*
** {======================================================
** 'require' function
** =======================================================
*/


static int readable (const char *filename) {
  FILE *f = fopen(filename, "r");  /* try to open file */
  if (f == NULL) return 0;  /* open failed */
  fclose(f);
  return 1;
}


static const char *pushnexttemplate (lua_State *L, const char *path) {
  const char *l;
  while (*path == *LUA_PATHSEP) path++;  /* skip separators */
  if (*path == '\0') return NULL;  /* no more templates */
  l = strchr(path, *LUA_PATHSEP);  /* find next separator */
  if (l == NULL) l = path + strlen(path);
  lua_pushlstring(L, path, l - path);  /* template */
  return l;
}


static const char *findfile (lua_State *L, const char *name,
                                           const char *pname) {
  const char *path;
  name = luaL_gsub(L, name, ".", LUA_DIRSEP);
  lua_getfield(L, LUA_ENVIRONINDEX, pname);
  path = lua_tostring(L, -1);
  if (path == NULL)
    luaL_error(L, LUA_QL("package.%s") " must be a string", pname);
  lua_pushstring(L, "");  /* error accumulator */
  while ((path = pushnexttemplate(L, path)) != NULL) {
    const char *filename;
    filename = luaL_gsub(L, lua_tostring(L, -1), LUA_PATH_MARK, name);
    if (readable(filename))  /* does file exist and is readable? */
      return filename;  /* return that file name */
    lua_pop(L, 2);  /* remove path template and file name */ 
    luaO_pushfstring(L, "\n\tno file " LUA_QS, filename);
    lua_concat(L, 2);
  }
  return NULL;  /* not found */
}


static void loaderror (lua_State *L, const char *filename) {
  luaL_error(L, "error loading module " LUA_QS " from file " LUA_QS ":\n\t%s",
                lua_tostring(L, 1), filename, lua_tostring(L, -1));
}


static int loader_Lua (lua_State *L) {
  const char *filename;
  const char *name = luaL_checkstring(L, 1);
  filename = findfile(L, name, "path");
  if (filename == NULL) return 1;  /* library not found in this path */
  if (luaL_loadfile(L, filename) != 0)
    loaderror(L, filename);
  return 1;  /* library loaded successfully */
}


static const char *mkfuncname (lua_State *L, const char *modname) {
  const char *funcname;
  const char *mark = strchr(modname, *LUA_IGMARK);
  if (mark) modname = mark + 1;
  funcname = luaL_gsub(L, modname, ".", LUA_OFSEP);
  funcname = lua_pushfstring(L, POF"%s", funcname);
  lua_remove(L, -2);  /* remove 'gsub' result */
  return funcname;
}


static int loader_C (lua_State *L) {
  const char *funcname;
  const char *name = luaL_checkstring(L, 1);
  const char *filename = findfile(L, name, "cpath");
  if (filename == NULL) return 1;  /* library not found in this path */
  funcname = mkfuncname(L, name);
  if (ll_loadfunc(L, filename, funcname) != 0)
    loaderror(L, filename);
  return 1;  /* library loaded successfully */
}


static int loader_Croot (lua_State *L) {
  const char *funcname;
  const char *filename;
  const char *name = luaL_checkstring(L, 1);
  const char *p = strchr(name, '.');
  int stat;
  if (p == NULL) return 0;  /* is root */
  lua_pushlstring(L, name, p - name);
  filename = findfile(L, lua_tostring(L, -1), "cpath");
  if (filename == NULL) return 1;  /* root not found */
  funcname = mkfuncname(L, name);
  if ((stat = ll_loadfunc(L, filename, funcname)) != 0) {
    if (stat != ERRFUNC) loaderror(L, filename);  /* real error */
    luaO_pushfstring(L, "\n\tno module " LUA_QS " in file " LUA_QS,
                        name, filename);
    return 1;  /* function not found */
  }
  return 1;
}


static int loader_preload (lua_State *L) {
  const char *name = luaL_checkstring(L, 1);
  lua_getfield(L, LUA_ENVIRONINDEX, "preload");
  if (!lua_istable(L, -1))
    luaL_error(L, LUA_QL("package.preload") " must be a table");
  lua_getfield(L, -1, name);
  if (lua_isnil(L, -1))  /* not found? */
    luaO_pushfstring(L, "\n\tno field package.preload['%s']", name);
  return 1;
}


static const int sentinel_ = 0;
#define sentinel	((void *)&sentinel_)


static int ll_require (lua_State *L) {
  const char *name = luaL_checkstring(L, 1);
  int i;
  lua_settop(L, 1);  /* _LOADED table will be at index 2 */
  lua_getfield(L, LUA_REGISTRYINDEX, "_LOADED");
  lua_getfield(L, 2, name);
  if (lua_toboolean(L, -1)) {  /* is it there? */
    if (lua_touserdata(L, -1) == sentinel)  /* check loops */
      luaL_error(L, "loop or previous error loading module " LUA_QS, name);
    return 1;  /* package is already loaded */
  }
  /* else must load it; iterate over available loaders */
  lua_getfield(L, LUA_ENVIRONINDEX, "loaders");
  if (!lua_istable(L, -1))
    luaL_error(L, LUA_QL("package.loaders") " must be a table");
  lua_pushstring(L, "");  /* error message accumulator */
  for (i=1; ; i++) {
    lua_rawgeti(L, -2, i);  /* get a loader */
    if (lua_isnil(L, -1))
      luaL_error(L, "module " LUA_QS " not found:%s",
                    name, lua_tostring(L, -2));
    lua_pushstring(L, name);
    lua_call(L, 1, 1);  /* call it */
    if (lua_isfunction(L, -1))  /* did it find module? */
      break;  /* module loaded successfully */
    else if (lua_isstring(L, -1))  /* loader returned error message? */
      lua_concat(L, 2);  /* accumulate it */
    else
      lua_pop(L, 1);
  }
  lua_pushlightuserdata(L, sentinel);
  lua_setfield(L, 2, name);  /* _LOADED[name] = sentinel */
  lua_pushstring(L, name);  /* pass name as argument to module */
  lua_call(L, 1, 1);  /* run loaded module */
  if (!lua_isnil(L, -1))  /* non-nil return? */
    lua_setfield(L, 2, name);  /* _LOADED[name] = returned value */
  lua_getfield(L, 2, name);
  if (lua_touserdata(L, -1) == sentinel) {   /* module did not set a value? */
    lua_pushboolean(L, 1);  /* use true as result */
    lua_pushvalue(L, -1);  /* extra copy to be returned */
    lua_setfield(L, 2, name);  /* _LOADED[name] = true */
  }
  return 1;
}

/* }====================================================== */



/*
** {======================================================
** 'module' function
** =======================================================
*/
  

static void setfenv (lua_State *L) {
  lua_Debug ar;
  lua_getstack(L, 1, &ar);
  lua_getinfo(L, "f", &ar);
  lua_pushvalue(L, -2);
  lua_setfenv(L, -2);
  lua_pop(L, 1);
}


static void dooptions (lua_State *L, int n) {
  int i;
  for (i = 2; i <= n; i++) {
    lua_pushvalue(L, i);  /* get option (a function) */
    lua_pushvalue(L, -2);  /* module */
    lua_call(L, 1, 0);
  }
}


static void modinit (lua_State *L, const char *modname) {
  const char *dot;
  lua_pushvalue(L, -1);
  lua_setfield(L, -2, "_M");  /* module._M = module */
  lua_pushstring(L, modname);
  lua_setfield(L, -2, "_NAME");
  dot = strrchr(modname, '.');  /* look for last dot in module name */
  if (dot == NULL) dot = modname;
  else dot++;
  /* set _PACKAGE as package name (full module name minus last part) */
  lua_pushlstring(L, modname, dot - modname);
  lua_setfield(L, -2, "_PACKAGE");
}


static int ll_module (lua_State *L) {
  const char *modname = luaL_checkstring(L, 1);
  int loaded = lua_gettop(L) + 1;  /* index of _LOADED table */
  lua_getfield(L, LUA_REGISTRYINDEX, "_LOADED");
  lua_getfield(L, loaded, modname);  /* get _LOADED[modname] */
  if (!lua_istable(L, -1)) {  /* not found? */
    lua_pop(L, 1);  /* remove previous result */
    /* try global variable (and create one if it does not exist) */
    if (luaL_findtable(L, LUA_GLOBALSINDEX, modname, 1) != NULL)
      return luaL_error(L, "name conflict for module " LUA_QS, modname);
    lua_pushvalue(L, -1);
    lua_setfield(L, loaded, modname);  /* _LOADED[modname] = new table */
  }
  /* check whether table already has a _NAME field */
  lua_getfield(L, -1, "_NAME");
  if (!lua_isnil(L, -1))  /* is table an initialized module? */
    lua_pop(L, 1);
  else {  /* no; initialize it */
    lua_pop(L, 1);
    modinit(L, modname);
  }
  lua_pushvalue(L, -1);
  setfenv(L);
  dooptions(L, loaded - 1);
  return 0;
}


static int ll_seeall (lua_State *L) {
  luaL_checktype(L, 1, LUA_TTABLE);
  if (!lua_getmetatable(L, 1)) {
    lua_createtable(L, 0, 1); /* create new metatable */
    lua_pushvalue(L, -1);
    lua_setmetatable(L, 1);
  }
  lua_pushvalue(L, LUA_GLOBALSINDEX);
  lua_setfield(L, -2, "__index");  /* mt.__index = _G */
  return 0;
}


/* }====================================================== */



/* auxiliary mark (for internal use) */
#define AUXMARK		"\1"

static void setpath (lua_State *L, const char *fieldname, const char *envname,
                                   const char *def) {
  const char *path = getenv(envname);
  if (path == NULL)  /* no environment variable? */
    lua_pushstring(L, def);  /* use default */
  else {
    /* replace ";;" by ";AUXMARK;" and then AUXMARK by default path */
    path = luaL_gsub(L, path, LUA_PATHSEP LUA_PATHSEP,
                              LUA_PATHSEP AUXMARK LUA_PATHSEP);
    luaL_gsub(L, path, AUXMARK, def);
    lua_remove(L, -2);
  }
  setprogdir(L);
  lua_setfield(L, -2, fieldname);
}


static const luaL_Reg pk_funcs[] = {
  {"loadlib", ll_loadlib},
  {"seeall", ll_seeall},
  {NULL, NULL}
};


static const luaL_Reg ll_funcs[] = {
  {"module", ll_module},
  {"require", ll_require},
  {NULL, NULL}
};


static const lua_CFunction loaders[] =
  {loader_preload, loader_Lua, loader_C, loader_Croot, NULL};


LUALIB_API int luaopen_package (lua_State *L) {
  int i;
  /* create new type _LOADLIB */
  luaL_newmetatable(L, "_LOADLIB");
  lua_pushcfunction(L, gctm);
  lua_setfield(L, -2, "__gc");
  /* create `package' table */
  luaL_register(L, LUA_LOADLIBNAME, pk_funcs);
#if defined(LUA_COMPAT_LOADLIB) 
  lua_getfield(L, -1, "loadlib");
  lua_setfield(L, LUA_GLOBALSINDEX, "loadlib");
#endif
  lua_pushvalue(L, -1);
  lua_replace(L, LUA_ENVIRONINDEX);
  /* create `loaders' table */
  lua_createtable(L, 0, sizeof(loaders)/sizeof(loaders[0]) - 1);
  /* fill it with pre-defined loaders */
  for (i=0; loaders[i] != NULL; i++) {
    lua_pushcfunction(L, loaders[i]);
    lua_rawseti(L, -2, i+1);
  }
  lua_setfield(L, -2, "loaders");  /* put it in field `loaders' */
  setpath(L, "path", LUA_PATH, LUA_PATH_DEFAULT);  /* set field `path' */
  setpath(L, "cpath", LUA_CPATH, LUA_CPATH_DEFAULT); /* set field `cpath' */
  /* store config information */
  lua_pushstring(L, LUA_DIRSEP "\n" LUA_PATHSEP "\n" LUA_PATH_MARK "\n"
                    LUA_EXECDIR "\n" LUA_IGMARK);
  lua_setfield(L, -2, "config");
  /* set field `loaded' */
  luaL_findtable(L, LUA_REGISTRYINDEX, "_LOADED", 2);
  lua_setfield(L, -2, "loaded");
  /* set field `preload' */
  lua_newtable(L);
  lua_setfield(L, -2, "preload");
  lua_pushvalue(L, LUA_GLOBALSINDEX);
  luaL_register(L, NULL, ll_funcs);  /* open lib into global table */
  lua_pop(L, 1);
  return 1;  /* return 'package' table */
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lopcodes.h ===
/*
** $Id: lopcodes.h,v 1.125 2006/03/14 19:04:44 roberto Exp $
** Opcodes for Lua virtual machine
** See Copyright Notice in lua.h
*/

#ifndef lopcodes_h
#define lopcodes_h

#include "llimits.h"


/*===========================================================================
  We assume that instructions are unsigned numbers.
  All instructions have an opcode in the first 6 bits.
  Instructions can have the following fields:
	`A' : 8 bits
	`B' : 9 bits
	`C' : 9 bits
	`Bx' : 18 bits (`B' and `C' together)
	`sBx' : signed Bx

  A signed argument is represented in excess K; that is, the number
  value is the unsigned value minus K. K is exactly the maximum value
  for that argument (so that -max is represented by 0, and +max is
  represented by 2*max), which is half the maximum for the corresponding
  unsigned argument.
===========================================================================*/


enum OpMode {iABC, iABx, iAsBx};  /* basic instruction format */


/*
** size and position of opcode arguments.
*/
#define SIZE_C		9
#define SIZE_B		9
#define SIZE_Bx		(SIZE_C + SIZE_B)
#define SIZE_A		8

#define SIZE_OP		6

#define POS_OP		0
#define POS_A		(POS_OP + SIZE_OP)
#define POS_C		(POS_A + SIZE_A)
#define POS_B		(POS_C + SIZE_C)
#define POS_Bx		POS_C


/*
** limits for opcode arguments.
** we use (signed) int to manipulate most arguments,
** so they must fit in LUAI_BITSINT-1 bits (-1 for sign)
*/
#if SIZE_Bx < LUAI_BITSINT-1
#define MAXARG_Bx        ((1<<SIZE_Bx)-1)
#define MAXARG_sBx        (MAXARG_Bx>>1)         /* `sBx' is signed */
#else
#define MAXARG_Bx        MAX_INT
#define MAXARG_sBx        MAX_INT
#endif


#define MAXARG_A        ((1<<SIZE_A)-1)
#define MAXARG_B        ((1<<SIZE_B)-1)
#define MAXARG_C        ((1<<SIZE_C)-1)


/* creates a mask with `n' 1 bits at position `p' */
#define MASK1(n,p)	((~((~(Instruction)0)<<n))<<p)

/* creates a mask with `n' 0 bits at position `p' */
#define MASK0(n,p)	(~MASK1(n,p))

/*
** the following macros help to manipulate instructions
*/

#define GET_OPCODE(i)	(cast(OpCode, ((i)>>POS_OP) & MASK1(SIZE_OP,0)))
#define SET_OPCODE(i,o)	((i) = (((i)&MASK0(SIZE_OP,POS_OP)) | \
		((cast(Instruction, o)<<POS_OP)&MASK1(SIZE_OP,POS_OP))))

#define GETARG_A(i)	(cast(int, ((i)>>POS_A) & MASK1(SIZE_A,0)))
#define SETARG_A(i,u)	((i) = (((i)&MASK0(SIZE_A,POS_A)) | \
		((cast(Instruction, u)<<POS_A)&MASK1(SIZE_A,POS_A))))

#define GETARG_B(i)	(cast(int, ((i)>>POS_B) & MASK1(SIZE_B,0)))
#define SETARG_B(i,b)	((i) = (((i)&MASK0(SIZE_B,POS_B)) | \
		((cast(Instruction, b)<<POS_B)&MASK1(SIZE_B,POS_B))))

#define GETARG_C(i)	(cast(int, ((i)>>POS_C) & MASK1(SIZE_C,0)))
#define SETARG_C(i,b)	((i) = (((i)&MASK0(SIZE_C,POS_C)) | \
		((cast(Instruction, b)<<POS_C)&MASK1(SIZE_C,POS_C))))

#define GETARG_Bx(i)	(cast(int, ((i)>>POS_Bx) & MASK1(SIZE_Bx,0)))
#define SETARG_Bx(i,b)	((i) = (((i)&MASK0(SIZE_Bx,POS_Bx)) | \
		((cast(Instruction, b)<<POS_Bx)&MASK1(SIZE_Bx,POS_Bx))))

#define GETARG_sBx(i)	(GETARG_Bx(i)-MAXARG_sBx)
#define SETARG_sBx(i,b)	SETARG_Bx((i),cast(unsigned int, (b)+MAXARG_sBx))


#define CREATE_ABC(o,a,b,c)	((cast(Instruction, o)<<POS_OP) \
			| (cast(Instruction, a)<<POS_A) \
			| (cast(Instruction, b)<<POS_B) \
			| (cast(Instruction, c)<<POS_C))

#define CREATE_ABx(o,a,bc)	((cast(Instruction, o)<<POS_OP) \
			| (cast(Instruction, a)<<POS_A) \
			| (cast(Instruction, bc)<<POS_Bx))


/*
** Macros to operate RK indices
*/

/* this bit 1 means constant (0 means register) */
#define BITRK		(1 << (SIZE_B - 1))

/* test whether value is a constant */
#define ISK(x)		((x) & BITRK)

/* gets the index of the constant */
#define INDEXK(r)	((int)(r) & ~BITRK)

#define MAXINDEXRK	(BITRK - 1)

/* code a constant index as a RK value */
#define RKASK(x)	((x) | BITRK)


/*
** invalid register that fits in 8 bits
*/
#define NO_REG		MAXARG_A


/*
** R(x) - register
** Kst(x) - constant (in constant table)
** RK(x) == if ISK(x) then Kst(INDEXK(x)) else R(x)
*/


/*
** grep "ORDER OP" if you change these enums
*/

typedef enum {
/*----------------------------------------------------------------------
name		args	description
------------------------------------------------------------------------*/
OP_MOVE,/*	A B	R(A) := R(B)					*/
OP_LOADK,/*	A Bx	R(A) := Kst(Bx)					*/
OP_LOADBOOL,/*	A B C	R(A) := (Bool)B; if (C) pc++			*/
OP_LOADNIL,/*	A B	R(A) := ... := R(B) := nil			*/
OP_GETUPVAL,/*	A B	R(A) := UpValue[B]				*/

OP_GETGLOBAL,/*	A Bx	R(A) := Gbl[Kst(Bx)]				*/
OP_GETTABLE,/*	A B C	R(A) := R(B)[RK(C)]				*/

OP_SETGLOBAL,/*	A Bx	Gbl[Kst(Bx)] := R(A)				*/
OP_SETUPVAL,/*	A B	UpValue[B] := R(A)				*/
OP_SETTABLE,/*	A B C	R(A)[RK(B)] := RK(C)				*/

OP_NEWTABLE,/*	A B C	R(A) := {} (size = B,C)				*/

OP_SELF,/*	A B C	R(A+1) := R(B); R(A) := R(B)[RK(C)]		*/

OP_ADD,/*	A B C	R(A) := RK(B) + RK(C)				*/
OP_SUB,/*	A B C	R(A) := RK(B) - RK(C)				*/
OP_MUL,/*	A B C	R(A) := RK(B) * RK(C)				*/
OP_DIV,/*	A B C	R(A) := RK(B) / RK(C)				*/
OP_MOD,/*	A B C	R(A) := RK(B) % RK(C)				*/
OP_POW,/*	A B C	R(A) := RK(B) ^ RK(C)				*/
OP_UNM,/*	A B	R(A) := -R(B)					*/
OP_NOT,/*	A B	R(A) := not R(B)				*/
OP_LEN,/*	A B	R(A) := length of R(B)				*/

OP_CONCAT,/*	A B C	R(A) := R(B).. ... ..R(C)			*/

OP_JMP,/*	sBx	pc+=sBx					*/

OP_EQ,/*	A B C	if ((RK(B) == RK(C)) ~= A) then pc++		*/
OP_LT,/*	A B C	if ((RK(B) <  RK(C)) ~= A) then pc++  		*/
OP_LE,/*	A B C	if ((RK(B) <= RK(C)) ~= A) then pc++  		*/

OP_TEST,/*	A C	if not (R(A) <=> C) then pc++			*/ 
OP_TESTSET,/*	A B C	if (R(B) <=> C) then R(A) := R(B) else pc++	*/ 

OP_CALL,/*	A B C	R(A), ... ,R(A+C-2) := R(A)(R(A+1), ... ,R(A+B-1)) */
OP_TAILCALL,/*	A B C	return R(A)(R(A+1), ... ,R(A+B-1))		*/
OP_RETURN,/*	A B	return R(A), ... ,R(A+B-2)	(see note)	*/

OP_FORLOOP,/*	A sBx	R(A)+=R(A+2);
			if R(A) <?= R(A+1) then { pc+=sBx; R(A+3)=R(A) }*/
OP_FORPREP,/*	A sBx	R(A)-=R(A+2); pc+=sBx				*/

OP_TFORLOOP,/*	A C	R(A+3), ... ,R(A+2+C) := R(A)(R(A+1), R(A+2)); 
                        if R(A+3) ~= nil then R(A+2)=R(A+3) else pc++	*/ 
OP_SETLIST,/*	A B C	R(A)[(C-1)*FPF+i] := R(A+i), 1 <= i <= B	*/

OP_CLOSE,/*	A 	close all variables in the stack up to (>=) R(A)*/
OP_CLOSURE,/*	A Bx	R(A) := closure(KPROTO[Bx], R(A), ... ,R(A+n))	*/

OP_VARARG/*	A B	R(A), R(A+1), ..., R(A+B-1) = vararg		*/
} OpCode;


#define NUM_OPCODES	(cast(int, OP_VARARG) + 1)



/*===========================================================================
  Notes:
  (*) In OP_CALL, if (B == 0) then B = top. C is the number of returns - 1,
      and can be 0: OP_CALL then sets `top' to last_result+1, so
      next open instruction (OP_CALL, OP_RETURN, OP_SETLIST) may use `top'.

  (*) In OP_VARARG, if (B == 0) then use actual number of varargs and
      set top (like in OP_CALL with C == 0).

  (*) In OP_RETURN, if (B == 0) then return up to `top'

  (*) In OP_SETLIST, if (B == 0) then B = `top';
      if (C == 0) then next `instruction' is real C

  (*) For comparisons, A specifies what condition the test should accept
      (true or false).

  (*) All `skips' (pc++) assume that next instruction is a jump
===========================================================================*/


/*
** masks for instruction properties. The format is:
** bits 0-1: op mode
** bits 2-3: C arg mode
** bits 4-5: B arg mode
** bit 6: instruction set register A
** bit 7: operator is a test
*/  

enum OpArgMask {
  OpArgN,  /* argument is not used */
  OpArgU,  /* argument is used */
  OpArgR,  /* argument is a register or a jump offset */
  OpArgK   /* argument is a constant or register/constant */
};

LUAI_DATA const lu_byte luaP_opmodes[NUM_OPCODES];

#define getOpMode(m)	(cast(enum OpMode, luaP_opmodes[m] & 3))
#define getBMode(m)	(cast(enum OpArgMask, (luaP_opmodes[m] >> 4) & 3))
#define getCMode(m)	(cast(enum OpArgMask, (luaP_opmodes[m] >> 2) & 3))
#define testAMode(m)	(luaP_opmodes[m] & (1 << 6))
#define testTMode(m)	(luaP_opmodes[m] & (1 << 7))


LUAI_DATA const char *const luaP_opnames[NUM_OPCODES+1];  /* opcode names */


/* number of list items to accumulate before a SETLIST instruction */
#define LFIELDS_PER_FLUSH	50


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\loslib.c ===
/*
** $Id: loslib.c,v 1.19 2006/04/26 18:19:49 roberto Exp $
** Standard Operating System library
** See Copyright Notice in lua.h
*/


#include <errno.h>
#include <locale.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>

#define loslib_c
#define LUA_LIB

#include "lua.h"

#include "lauxlib.h"
#include "lualib.h"


static int os_pushresult (lua_State *L, int i, const char *filename) {
  int en = errno;  /* calls to Lua API may change this value */
  if (i) {
    lua_pushboolean(L, 1);
    return 1;
  }
  else {
    lua_pushnil(L);
    lua_pushfstring(L, "%s: %s", filename, strerror(en));
    lua_pushinteger(L, en);
    return 3;
  }
}


static int os_execute (lua_State *L) {
  lua_pushinteger(L, system(luaL_optstring(L, 1, NULL)));
  return 1;
}


static int os_remove (lua_State *L) {
  const char *filename = luaL_checkstring(L, 1);
  return os_pushresult(L, remove(filename) == 0, filename);
}


static int os_rename (lua_State *L) {
  const char *fromname = luaL_checkstring(L, 1);
  const char *toname = luaL_checkstring(L, 2);
  return os_pushresult(L, rename(fromname, toname) == 0, fromname);
}


static int os_tmpname (lua_State *L) {
  char buff[LUA_TMPNAMBUFSIZE];
  int err;
  lua_tmpnam(buff, err);
  if (err)
    return luaL_error(L, "unable to generate a unique filename");
  lua_pushstring(L, buff);
  return 1;
}


static int os_getenv (lua_State *L) {
  lua_pushstring(L, getenv(luaL_checkstring(L, 1)));  /* if NULL push nil */
  return 1;
}


static int os_clock (lua_State *L) {
  lua_pushnumber(L, ((lua_Number)clock())/(lua_Number)CLOCKS_PER_SEC);
  return 1;
}


/*
** {======================================================
** Time/Date operations
** { year=%Y, month=%m, day=%d, hour=%H, min=%M, sec=%S,
**   wday=%w+1, yday=%j, isdst=? }
** =======================================================
*/

static void setfield (lua_State *L, const char *key, int value) {
  lua_pushinteger(L, value);
  lua_setfield(L, -2, key);
}

static void setboolfield (lua_State *L, const char *key, int value) {
  if (value < 0)  /* undefined? */
    return;  /* does not set field */
  lua_pushboolean(L, value);
  lua_setfield(L, -2, key);
}

static int getboolfield (lua_State *L, const char *key) {
  int res;
  lua_getfield(L, -1, key);
  res = lua_isnil(L, -1) ? -1 : lua_toboolean(L, -1);
  lua_pop(L, 1);
  return res;
}


static int getfield (lua_State *L, const char *key, int d) {
  int res;
  lua_getfield(L, -1, key);
  if (lua_isnumber(L, -1))
    res = (int)lua_tointeger(L, -1);
  else {
    if (d < 0)
      return luaL_error(L, "field " LUA_QS " missing in date table", key);
    res = d;
  }
  lua_pop(L, 1);
  return res;
}


static int os_date (lua_State *L) {
  const char *s = luaL_optstring(L, 1, "%c");
  time_t t = luaL_opt(L, (time_t)luaL_checknumber, 2, time(NULL));
  struct tm *stm;
  if (*s == '!') {  /* UTC? */
    stm = gmtime(&t);
    s++;  /* skip `!' */
  }
  else
    stm = localtime(&t);
  if (stm == NULL)  /* invalid date? */
    lua_pushnil(L);
  else if (strcmp(s, "*t") == 0) {
    lua_createtable(L, 0, 9);  /* 9 = number of fields */
    setfield(L, "sec", stm->tm_sec);
    setfield(L, "min", stm->tm_min);
    setfield(L, "hour", stm->tm_hour);
    setfield(L, "day", stm->tm_mday);
    setfield(L, "month", stm->tm_mon+1);
    setfield(L, "year", stm->tm_year+1900);
    setfield(L, "wday", stm->tm_wday+1);
    setfield(L, "yday", stm->tm_yday+1);
    setboolfield(L, "isdst", stm->tm_isdst);
  }
  else {
    char b[256];
    if (strftime(b, sizeof(b), s, stm))
      lua_pushstring(L, b);
    else
      return luaL_error(L, LUA_QL("date") " format too long");
  }
  return 1;
}


static int os_time (lua_State *L) {
  time_t t;
  if (lua_isnoneornil(L, 1))  /* called without args? */
    t = time(NULL);  /* get current time */
  else {
    struct tm ts;
    luaL_checktype(L, 1, LUA_TTABLE);
    lua_settop(L, 1);  /* make sure table is at the top */
    ts.tm_sec = getfield(L, "sec", 0);
    ts.tm_min = getfield(L, "min", 0);
    ts.tm_hour = getfield(L, "hour", 12);
    ts.tm_mday = getfield(L, "day", -1);
    ts.tm_mon = getfield(L, "month", -1) - 1;
    ts.tm_year = getfield(L, "year", -1) - 1900;
    ts.tm_isdst = getboolfield(L, "isdst");
    t = mktime(&ts);
  }
  if (t == (time_t)(-1))
    lua_pushnil(L);
  else
    lua_pushnumber(L, (lua_Number)t);
  return 1;
}


static int os_difftime (lua_State *L) {
  lua_pushnumber(L, difftime((time_t)(luaL_checknumber(L, 1)),
                             (time_t)(luaL_optnumber(L, 2, 0))));
  return 1;
}

/* }====================================================== */


static int os_setlocale (lua_State *L) {
  static const int cat[] = {LC_ALL, LC_COLLATE, LC_CTYPE, LC_MONETARY,
                      LC_NUMERIC, LC_TIME};
  static const char *const catnames[] = {"all", "collate", "ctype", "monetary",
     "numeric", "time", NULL};
  const char *l = luaL_optstring(L, 1, NULL);
  int op = luaL_checkoption(L, 2, "all", catnames);
  lua_pushstring(L, setlocale(cat[op], l));
  return 1;
}


static int os_exit (lua_State *L) {
  exit(luaL_optint(L, 1, EXIT_SUCCESS));
  return 0;  /* to avoid warnings */
}

static const luaL_Reg syslib[] = {
  {"clock",     os_clock},
  {"date",      os_date},
  {"difftime",  os_difftime},
  {"execute",   os_execute},
  {"exit",      os_exit},
  {"getenv",    os_getenv},
  {"remove",    os_remove},
  {"rename",    os_rename},
  {"setlocale", os_setlocale},
  {"time",      os_time},
  {"tmpname",   os_tmpname},
  {NULL, NULL}
};

/* }====================================================== */



LUALIB_API int luaopen_os (lua_State *L) {
  luaL_register(L, LUA_OSLIBNAME, syslib);
  return 1;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lparser.h ===
/*
** $Id: lparser.h,v 1.57 2006/03/09 18:14:31 roberto Exp $
** Lua Parser
** See Copyright Notice in lua.h
*/

#ifndef lparser_h
#define lparser_h

#include "llimits.h"
#include "lobject.h"
#include "lzio.h"


/*
** Expression descriptor
*/

typedef enum {
  VVOID,	/* no value */
  VNIL,
  VTRUE,
  VFALSE,
  VK,		/* info = index of constant in `k' */
  VKNUM,	/* nval = numerical value */
  VLOCAL,	/* info = local register */
  VUPVAL,       /* info = index of upvalue in `upvalues' */
  VGLOBAL,	/* info = index of table; aux = index of global name in `k' */
  VINDEXED,	/* info = table register; aux = index register (or `k') */
  VJMP,		/* info = instruction pc */
  VRELOCABLE,	/* info = instruction pc */
  VNONRELOC,	/* info = result register */
  VCALL,	/* info = instruction pc */
  VVARARG	/* info = instruction pc */
} expkind;

typedef struct expdesc {
  expkind k;
  union {
    struct { int info, aux; } s;
    lua_Number nval;
  } u;
  int t;  /* patch list of `exit when true' */
  int f;  /* patch list of `exit when false' */
} expdesc;


typedef struct upvaldesc {
  lu_byte k;
  lu_byte info;
} upvaldesc;


struct BlockCnt;  /* defined in lparser.c */


/* state needed to generate code for a given function */
typedef struct FuncState {
  Proto *f;  /* current function header */
  Table *h;  /* table to find (and reuse) elements in `k' */
  struct FuncState *prev;  /* enclosing function */
  struct LexState *ls;  /* lexical state */
  struct lua_State *L;  /* copy of the Lua state */
  struct BlockCnt *bl;  /* chain of current blocks */
  int pc;  /* next position to code (equivalent to `ncode') */
  int lasttarget;   /* `pc' of last `jump target' */
  int jpc;  /* list of pending jumps to `pc' */
  int freereg;  /* first free register */
  int nk;  /* number of elements in `k' */
  int np;  /* number of elements in `p' */
  short nlocvars;  /* number of elements in `locvars' */
  lu_byte nactvar;  /* number of active local variables */
  upvaldesc upvalues[LUAI_MAXUPVALUES];  /* upvalues */
  unsigned short actvar[LUAI_MAXVARS];  /* declared-variable stack */
} FuncState;


LUAI_FUNC Proto *luaY_parser (lua_State *L, ZIO *z, Mbuffer *buff,
                                            const char *name);


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lparser.c ===
/*
** $Id: lparser.c,v 2.42 2006/06/05 15:57:59 roberto Exp $
** Lua Parser
** See Copyright Notice in lua.h
*/


#include <string.h>

#define lparser_c
#define LUA_CORE

#include "lua.h"

#include "lcode.h"
#include "ldebug.h"
#include "ldo.h"
#include "lfunc.h"
#include "llex.h"
#include "lmem.h"
#include "lobject.h"
#include "lopcodes.h"
#include "lparser.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"



#define hasmultret(k)       ((k) == VCALL || (k) == VVARARG)

#define getlocvar(fs, i)    ((fs)->f->locvars[(fs)->actvar[i]])

#define luaY_checklimit(fs,v,l,m)   if ((v)>(l)) errorlimit(fs,l,m)


/*
** nodes for block list (list of active blocks)
*/
typedef struct BlockCnt {
  struct BlockCnt *previous;  /* chain */
  int breaklist;  /* list of jumps out of this loop */
  lu_byte nactvar;  /* # active locals outside the breakable structure */
  lu_byte upval;  /* true if some variable in the block is an upvalue */
  lu_byte isbreakable;  /* true if `block' is a loop */
} BlockCnt;



/*
** prototypes for recursive non-terminal functions
*/
static void chunk (LexState *ls);
static void expr (LexState *ls, expdesc *v);


static void anchor_token (LexState *ls) {
  if (ls->t.token == TK_NAME || ls->t.token == TK_STRING) {
    TString *ts = ls->t.seminfo.ts;
    luaX_newstring(ls, getstr(ts), ts->tsv.len);
  }
}


static void error_expected (LexState *ls, int token) {
  luaX_syntaxerror(ls,
      luaO_pushfstring(ls->L, LUA_QS " expected", luaX_token2str(ls, token)));
}


static void errorlimit (FuncState *fs, int limit, const char *what) {
  const char *msg = (fs->f->linedefined == 0) ?
    luaO_pushfstring(fs->L, "main function has more than %d %s", limit, what) :
    luaO_pushfstring(fs->L, "function at line %d has more than %d %s",
                            fs->f->linedefined, limit, what);
  luaX_lexerror(fs->ls, msg, 0);
}


static int testnext (LexState *ls, int c) {
  if (ls->t.token == c) {
    luaX_next(ls);
    return 1;
  }
  else return 0;
}


static void check (LexState *ls, int c) {
  if (ls->t.token != c)
    error_expected(ls, c);
}

static void checknext (LexState *ls, int c) {
  check(ls, c);
  luaX_next(ls);
}


#define check_condition(ls,c,msg)   { if (!(c)) luaX_syntaxerror(ls, msg); }



static void check_match (LexState *ls, int what, int who, int where) {
  if (!testnext(ls, what)) {
    if (where == ls->linenumber)
      error_expected(ls, what);
    else {
      luaX_syntaxerror(ls, luaO_pushfstring(ls->L,
             LUA_QS " expected (to close " LUA_QS " at line %d)",
              luaX_token2str(ls, what), luaX_token2str(ls, who), where));
    }
  }
}


static TString *str_checkname (LexState *ls) {
  TString *ts;
  check(ls, TK_NAME);
  ts = ls->t.seminfo.ts;
  luaX_next(ls);
  return ts;
}


static void init_exp (expdesc *e, expkind k, int i) {
  e->f = e->t = NO_JUMP;
  e->k = k;
  e->u.s.info = i;
}


static void codestring (LexState *ls, expdesc *e, TString *s) {
  init_exp(e, VK, luaK_stringK(ls->fs, s));
}


static void checkname(LexState *ls, expdesc *e) {
  codestring(ls, e, str_checkname(ls));
}


static int registerlocalvar (LexState *ls, TString *varname) {
  FuncState *fs = ls->fs;
  Proto *f = fs->f;
  int oldsize = f->sizelocvars;
  luaM_growvector(ls->L, f->locvars, fs->nlocvars, f->sizelocvars,
                  LocVar, SHRT_MAX, "too many local variables");
  while (oldsize < f->sizelocvars) f->locvars[oldsize++].varname = NULL;
  f->locvars[fs->nlocvars].varname = varname;
  luaC_objbarrier(ls->L, f, varname);
  return fs->nlocvars++;
}


#define new_localvarliteral(ls,v,n) \
  new_localvar(ls, luaX_newstring(ls, "" v, (sizeof(v)/sizeof(char))-1), n)


static void new_localvar (LexState *ls, TString *name, int n) {
  FuncState *fs = ls->fs;
  luaY_checklimit(fs, fs->nactvar+n+1, LUAI_MAXVARS, "local variables");
  fs->actvar[fs->nactvar+n] = cast(unsigned short, registerlocalvar(ls, name));
}


static void adjustlocalvars (LexState *ls, int nvars) {
  FuncState *fs = ls->fs;
  fs->nactvar = cast_byte(fs->nactvar + nvars);
  for (; nvars; nvars--) {
    getlocvar(fs, fs->nactvar - nvars).startpc = fs->pc;
  }
}


static void removevars (LexState *ls, int tolevel) {
  FuncState *fs = ls->fs;
  while (fs->nactvar > tolevel)
    getlocvar(fs, --fs->nactvar).endpc = fs->pc;
}


static int indexupvalue (FuncState *fs, TString *name, expdesc *v) {
  int i;
  Proto *f = fs->f;
  int oldsize = f->sizeupvalues;
  for (i=0; i<f->nups; i++) {
    if (fs->upvalues[i].k == v->k && fs->upvalues[i].info == v->u.s.info) {
      lua_assert(f->upvalues[i] == name);
      return i;
    }
  }
  /* new one */
  luaY_checklimit(fs, f->nups + 1, LUAI_MAXUPVALUES, "upvalues");
  luaM_growvector(fs->L, f->upvalues, f->nups, f->sizeupvalues,
                  TString *, MAX_INT, "");
  while (oldsize < f->sizeupvalues) f->upvalues[oldsize++] = NULL;
  f->upvalues[f->nups] = name;
  luaC_objbarrier(fs->L, f, name);
  lua_assert(v->k == VLOCAL || v->k == VUPVAL);
  fs->upvalues[f->nups].k = cast_byte(v->k);
  fs->upvalues[f->nups].info = cast_byte(v->u.s.info);
  return f->nups++;
}


static int searchvar (FuncState *fs, TString *n) {
  int i;
  for (i=fs->nactvar-1; i >= 0; i--) {
    if (n == getlocvar(fs, i).varname)
      return i;
  }
  return -1;  /* not found */
}


static void markupval (FuncState *fs, int level) {
  BlockCnt *bl = fs->bl;
  while (bl && bl->nactvar > level) bl = bl->previous;
  if (bl) bl->upval = 1;
}


static int singlevaraux (FuncState *fs, TString *n, expdesc *var, int base) {
  if (fs == NULL) {  /* no more levels? */
    init_exp(var, VGLOBAL, NO_REG);  /* default is global variable */
    return VGLOBAL;
  }
  else {
    int v = searchvar(fs, n);  /* look up at current level */
    if (v >= 0) {
      init_exp(var, VLOCAL, v);
      if (!base)
        markupval(fs, v);  /* local will be used as an upval */
      return VLOCAL;
    }
    else {  /* not found at current level; try upper one */
      if (singlevaraux(fs->prev, n, var, 0) == VGLOBAL)
        return VGLOBAL;
      var->u.s.info = indexupvalue(fs, n, var);  /* else was LOCAL or UPVAL */
      var->k = VUPVAL;  /* upvalue in this level */
      return VUPVAL;
    }
  }
}


static void singlevar (LexState *ls, expdesc *var) {
  TString *varname = str_checkname(ls);
  FuncState *fs = ls->fs;
  if (singlevaraux(fs, varname, var, 1) == VGLOBAL)
    var->u.s.info = luaK_stringK(fs, varname);  /* info points to global name */
}


static void adjust_assign (LexState *ls, int nvars, int nexps, expdesc *e) {
  FuncState *fs = ls->fs;
  int extra = nvars - nexps;
  if (hasmultret(e->k)) {
    extra++;  /* includes call itself */
    if (extra < 0) extra = 0;
    luaK_setreturns(fs, e, extra);  /* last exp. provides the difference */
    if (extra > 1) luaK_reserveregs(fs, extra-1);
  }
  else {
    if (e->k != VVOID) luaK_exp2nextreg(fs, e);  /* close last expression */
    if (extra > 0) {
      int reg = fs->freereg;
      luaK_reserveregs(fs, extra);
      luaK_nil(fs, reg, extra);
    }
  }
}


static void enterlevel (LexState *ls) {
  if (++ls->L->nCcalls > LUAI_MAXCCALLS)
    luaX_lexerror(ls, "chunk has too many syntax levels", 0);
}


#define leavelevel(ls)  ((ls)->L->nCcalls--)


static void enterblock (FuncState *fs, BlockCnt *bl, lu_byte isbreakable) {
  bl->breaklist = NO_JUMP;
  bl->isbreakable = isbreakable;
  bl->nactvar = fs->nactvar;
  bl->upval = 0;
  bl->previous = fs->bl;
  fs->bl = bl;
  lua_assert(fs->freereg == fs->nactvar);
}


static void leaveblock (FuncState *fs) {
  BlockCnt *bl = fs->bl;
  fs->bl = bl->previous;
  removevars(fs->ls, bl->nactvar);
  if (bl->upval)
    luaK_codeABC(fs, OP_CLOSE, bl->nactvar, 0, 0);
  /* a block either controls scope or breaks (never both) */
  lua_assert(!bl->isbreakable || !bl->upval);
  lua_assert(bl->nactvar == fs->nactvar);
  fs->freereg = fs->nactvar;  /* free registers */
  luaK_patchtohere(fs, bl->breaklist);
}


static void pushclosure (LexState *ls, FuncState *func, expdesc *v) {
  FuncState *fs = ls->fs;
  Proto *f = fs->f;
  int oldsize = f->sizep;
  int i;
  luaM_growvector(ls->L, f->p, fs->np, f->sizep, Proto *,
                  MAXARG_Bx, "constant table overflow");
  while (oldsize < f->sizep) f->p[oldsize++] = NULL;
  f->p[fs->np++] = func->f;
  luaC_objbarrier(ls->L, f, func->f);
  init_exp(v, VRELOCABLE, luaK_codeABx(fs, OP_CLOSURE, 0, fs->np-1));
  for (i=0; i<func->f->nups; i++) {
    OpCode o = (func->upvalues[i].k == VLOCAL) ? OP_MOVE : OP_GETUPVAL;
    luaK_codeABC(fs, o, 0, func->upvalues[i].info, 0);
  }
}


static void open_func (LexState *ls, FuncState *fs) {
  lua_State *L = ls->L;
  Proto *f = luaF_newproto(L);
  fs->f = f;
  fs->prev = ls->fs;  /* linked list of funcstates */
  fs->ls = ls;
  fs->L = L;
  ls->fs = fs;
  fs->pc = 0;
  fs->lasttarget = -1;
  fs->jpc = NO_JUMP;
  fs->freereg = 0;
  fs->nk = 0;
  fs->np = 0;
  fs->nlocvars = 0;
  fs->nactvar = 0;
  fs->bl = NULL;
  f->source = ls->source;
  f->maxstacksize = 2;  /* registers 0/1 are always valid */
  fs->h = luaH_new(L, 0, 0);
  /* anchor table of constants and prototype (to avoid being collected) */
  sethvalue2s(L, L->top, fs->h);
  incr_top(L);
  setptvalue2s(L, L->top, f);
  incr_top(L);
}


static void close_func (LexState *ls) {
  lua_State *L = ls->L;
  FuncState *fs = ls->fs;
  Proto *f = fs->f;
  removevars(ls, 0);
  luaK_ret(fs, 0, 0);  /* final return */
  luaM_reallocvector(L, f->code, f->sizecode, fs->pc, Instruction);
  f->sizecode = fs->pc;
  luaM_reallocvector(L, f->lineinfo, f->sizelineinfo, fs->pc, int);
  f->sizelineinfo = fs->pc;
  luaM_reallocvector(L, f->k, f->sizek, fs->nk, TValue);
  f->sizek = fs->nk;
  luaM_reallocvector(L, f->p, f->sizep, fs->np, Proto *);
  f->sizep = fs->np;
  luaM_reallocvector(L, f->locvars, f->sizelocvars, fs->nlocvars, LocVar);
  f->sizelocvars = fs->nlocvars;
  luaM_reallocvector(L, f->upvalues, f->sizeupvalues, f->nups, TString *);
  f->sizeupvalues = f->nups;
  lua_assert(luaG_checkcode(f));
  lua_assert(fs->bl == NULL);
  ls->fs = fs->prev;
  L->top -= 2;  /* remove table and prototype from the stack */
  /* last token read was anchored in defunct function; must reanchor it */
  if (fs) anchor_token(ls);
}


Proto *luaY_parser (lua_State *L, ZIO *z, Mbuffer *buff, const char *name) {
  struct LexState lexstate;
  struct FuncState funcstate;
  lexstate.buff = buff;
  luaX_setinput(L, &lexstate, z, luaS_new(L, name));
  open_func(&lexstate, &funcstate);
  funcstate.f->is_vararg = VARARG_ISVARARG;  /* main func. is always vararg */
  luaX_next(&lexstate);  /* read first token */
  chunk(&lexstate);
  check(&lexstate, TK_EOS);
  close_func(&lexstate);
  lua_assert(funcstate.prev == NULL);
  lua_assert(funcstate.f->nups == 0);
  lua_assert(lexstate.fs == NULL);
  return funcstate.f;
}



/*============================================================*/
/* GRAMMAR RULES */
/*============================================================*/


static void field (LexState *ls, expdesc *v) {
  /* field -> ['.' | ':'] NAME */
  FuncState *fs = ls->fs;
  expdesc key;
  luaK_exp2anyreg(fs, v);
  luaX_next(ls);  /* skip the dot or colon */
  checkname(ls, &key);
  luaK_indexed(fs, v, &key);
}


static void yindex (LexState *ls, expdesc *v) {
  /* index -> '[' expr ']' */
  luaX_next(ls);  /* skip the '[' */
  expr(ls, v);
  luaK_exp2val(ls->fs, v);
  checknext(ls, ']');
}


/*
** {======================================================================
** Rules for Constructors
** =======================================================================
*/


struct ConsControl {
  expdesc v;  /* last list item read */
  expdesc *t;  /* table descriptor */
  int nh;  /* total number of `record' elements */
  int na;  /* total number of array elements */
  int tostore;  /* number of array elements pending to be stored */
};


static void recfield (LexState *ls, struct ConsControl *cc) {
  /* recfield -> (NAME | `['exp1`]') = exp1 */
  FuncState *fs = ls->fs;
  int reg = ls->fs->freereg;
  expdesc key, val;
  int rkkey;
  if (ls->t.token == TK_NAME) {
    luaY_checklimit(fs, cc->nh, MAX_INT, "items in a constructor");
    checkname(ls, &key);
  }
  else  /* ls->t.token == '[' */
    yindex(ls, &key);
  cc->nh++;
  checknext(ls, '=');
  rkkey = luaK_exp2RK(fs, &key);
  expr(ls, &val);
  luaK_codeABC(fs, OP_SETTABLE, cc->t->u.s.info, rkkey, luaK_exp2RK(fs, &val));
  fs->freereg = reg;  /* free registers */
}


static void closelistfield (FuncState *fs, struct ConsControl *cc) {
  if (cc->v.k == VVOID) return;  /* there is no list item */
  luaK_exp2nextreg(fs, &cc->v);
  cc->v.k = VVOID;
  if (cc->tostore == LFIELDS_PER_FLUSH) {
    luaK_setlist(fs, cc->t->u.s.info, cc->na, cc->tostore);  /* flush */
    cc->tostore = 0;  /* no more items pending */
  }
}


static void lastlistfield (FuncState *fs, struct ConsControl *cc) {
  if (cc->tostore == 0) return;
  if (hasmultret(cc->v.k)) {
    luaK_setmultret(fs, &cc->v);
    luaK_setlist(fs, cc->t->u.s.info, cc->na, LUA_MULTRET);
    cc->na--;  /* do not count last expression (unknown number of elements) */
  }
  else {
    if (cc->v.k != VVOID)
      luaK_exp2nextreg(fs, &cc->v);
    luaK_setlist(fs, cc->t->u.s.info, cc->na, cc->tostore);
  }
}


static void listfield (LexState *ls, struct ConsControl *cc) {
  expr(ls, &cc->v);
  luaY_checklimit(ls->fs, cc->na, MAX_INT, "items in a constructor");
  cc->na++;
  cc->tostore++;
}


static void constructor (LexState *ls, expdesc *t) {
  /* constructor -> ?? */
  FuncState *fs = ls->fs;
  int line = ls->linenumber;
  int pc = luaK_codeABC(fs, OP_NEWTABLE, 0, 0, 0);
  struct ConsControl cc;
  cc.na = cc.nh = cc.tostore = 0;
  cc.t = t;
  init_exp(t, VRELOCABLE, pc);
  init_exp(&cc.v, VVOID, 0);  /* no value (yet) */
  luaK_exp2nextreg(ls->fs, t);  /* fix it at stack top (for gc) */
  checknext(ls, '{');
  do {
    lua_assert(cc.v.k == VVOID || cc.tostore > 0);
    if (ls->t.token == '}') break;
    closelistfield(fs, &cc);
    switch(ls->t.token) {
      case TK_NAME: {  /* may be listfields or recfields */
        luaX_lookahead(ls);
        if (ls->lookahead.token != '=')  /* expression? */
          listfield(ls, &cc);
        else
          recfield(ls, &cc);
        break;
      }
      case '[': {  /* constructor_item -> recfield */
        recfield(ls, &cc);
        break;
      }
      default: {  /* constructor_part -> listfield */
        listfield(ls, &cc);
        break;
      }
    }
  } while (testnext(ls, ',') || testnext(ls, ';'));
  check_match(ls, '}', '{', line);
  lastlistfield(fs, &cc);
  SETARG_B(fs->f->code[pc], luaO_int2fb(cc.na)); /* set initial array size */
  SETARG_C(fs->f->code[pc], luaO_int2fb(cc.nh));  /* set initial table size */
}

/* }====================================================================== */



static void parlist (LexState *ls) {
  /* parlist -> [ param { `,' param } ] */
  FuncState *fs = ls->fs;
  Proto *f = fs->f;
  int nparams = 0;
  f->is_vararg = 0;
  if (ls->t.token != ')') {  /* is `parlist' not empty? */
    do {
      switch (ls->t.token) {
        case TK_NAME: {  /* param -> NAME */
          new_localvar(ls, str_checkname(ls), nparams++);
          break;
        }
        case TK_DOTS: {  /* param -> `...' */
          luaX_next(ls);
#if defined(LUA_COMPAT_VARARG)
          /* use `arg' as default name */
          new_localvarliteral(ls, "arg", nparams++);
          f->is_vararg = VARARG_HASARG | VARARG_NEEDSARG;
#endif
          f->is_vararg |= VARARG_ISVARARG;
          break;
        }
        default: luaX_syntaxerror(ls, "<name> or " LUA_QL("...") " expected");
      }
    } while (!f->is_vararg && testnext(ls, ','));
  }
  adjustlocalvars(ls, nparams);
  f->numparams = cast_byte(fs->nactvar - (f->is_vararg & VARARG_HASARG));
  luaK_reserveregs(fs, fs->nactvar);  /* reserve register for parameters */
}


static void body (LexState *ls, expdesc *e, int needself, int line) {
  /* body ->  `(' parlist `)' chunk END */
  FuncState new_fs;
  open_func(ls, &new_fs);
  new_fs.f->linedefined = line;
  checknext(ls, '(');
  if (needself) {
    new_localvarliteral(ls, "self", 0);
    adjustlocalvars(ls, 1);
  }
  parlist(ls);
  checknext(ls, ')');
  chunk(ls);
  new_fs.f->lastlinedefined = ls->linenumber;
  check_match(ls, TK_END, TK_FUNCTION, line);
  close_func(ls);
  pushclosure(ls, &new_fs, e);
}


static int explist1 (LexState *ls, expdesc *v) {
  /* explist1 -> expr { `,' expr } */
  int n = 1;  /* at least one expression */
  expr(ls, v);
  while (testnext(ls, ',')) {
    luaK_exp2nextreg(ls->fs, v);
    expr(ls, v);
    n++;
  }
  return n;
}


static void funcargs (LexState *ls, expdesc *f) {
  FuncState *fs = ls->fs;
  expdesc args;
  int base, nparams;
  int line = ls->linenumber;
  switch (ls->t.token) {
    case '(': {  /* funcargs -> `(' [ explist1 ] `)' */
      if (line != ls->lastline)
        luaX_syntaxerror(ls,"ambiguous syntax (function call x new statement)");
      luaX_next(ls);
      if (ls->t.token == ')')  /* arg list is empty? */
        args.k = VVOID;
      else {
        explist1(ls, &args);
        luaK_setmultret(fs, &args);
      }
      check_match(ls, ')', '(', line);
      break;
    }
    case '{': {  /* funcargs -> constructor */
      constructor(ls, &args);
      break;
    }
    case TK_STRING: {  /* funcargs -> STRING */
      codestring(ls, &args, ls->t.seminfo.ts);
      luaX_next(ls);  /* must use `seminfo' before `next' */
      break;
    }
    default: {
      luaX_syntaxerror(ls, "function arguments expected");
      return;
    }
  }
  lua_assert(f->k == VNONRELOC);
  base = f->u.s.info;  /* base register for call */
  if (hasmultret(args.k))
    nparams = LUA_MULTRET;  /* open call */
  else {
    if (args.k != VVOID)
      luaK_exp2nextreg(fs, &args);  /* close last argument */
    nparams = fs->freereg - (base+1);
  }
  init_exp(f, VCALL, luaK_codeABC(fs, OP_CALL, base, nparams+1, 2));
  luaK_fixline(fs, line);
  fs->freereg = base+1;  /* call remove function and arguments and leaves
                            (unless changed) one result */
}




/*
** {======================================================================
** Expression parsing
** =======================================================================
*/


static void prefixexp (LexState *ls, expdesc *v) {
  /* prefixexp -> NAME | '(' expr ')' */
  switch (ls->t.token) {
    case '(': {
      int line = ls->linenumber;
      luaX_next(ls);
      expr(ls, v);
      check_match(ls, ')', '(', line);
      luaK_dischargevars(ls->fs, v);
      return;
    }
    case TK_NAME: {
      singlevar(ls, v);
      return;
    }
    default: {
      luaX_syntaxerror(ls, "unexpected symbol");
      return;
    }
  }
}


static void primaryexp (LexState *ls, expdesc *v) {
  /* primaryexp ->
        prefixexp { `.' NAME | `[' exp `]' | `:' NAME funcargs | funcargs } */
  FuncState *fs = ls->fs;
  prefixexp(ls, v);
  for (;;) {
    switch (ls->t.token) {
      case '.': {  /* field */
        field(ls, v);
        break;
      }
      case '[': {  /* `[' exp1 `]' */
        expdesc key;
        luaK_exp2anyreg(fs, v);
        yindex(ls, &key);
        luaK_indexed(fs, v, &key);
        break;
      }
      case ':': {  /* `:' NAME funcargs */
        expdesc key;
        luaX_next(ls);
        checkname(ls, &key);
        luaK_self(fs, v, &key);
        funcargs(ls, v);
        break;
      }
      case '(': case TK_STRING: case '{': {  /* funcargs */
        luaK_exp2nextreg(fs, v);
        funcargs(ls, v);
        break;
      }
      default: return;
    }
  }
}


static void simpleexp (LexState *ls, expdesc *v) {
  /* simpleexp -> NUMBER | STRING | NIL | true | false | ... |
                  constructor | FUNCTION body | primaryexp */
  switch (ls->t.token) {
    case TK_NUMBER: {
      init_exp(v, VKNUM, 0);
      v->u.nval = ls->t.seminfo.r;
      break;
    }
    case TK_STRING: {
      codestring(ls, v, ls->t.seminfo.ts);
      break;
    }
    case TK_NIL: {
      init_exp(v, VNIL, 0);
      break;
    }
    case TK_TRUE: {
      init_exp(v, VTRUE, 0);
      break;
    }
    case TK_FALSE: {
      init_exp(v, VFALSE, 0);
      break;
    }
    case TK_DOTS: {  /* vararg */
      FuncState *fs = ls->fs;
      check_condition(ls, fs->f->is_vararg,
                      "cannot use " LUA_QL("...") " outside a vararg function");
      fs->f->is_vararg &= ~VARARG_NEEDSARG;  /* don't need 'arg' */
      init_exp(v, VVARARG, luaK_codeABC(fs, OP_VARARG, 0, 1, 0));
      break;
    }
    case '{': {  /* constructor */
      constructor(ls, v);
      return;
    }
    case TK_FUNCTION: {
      luaX_next(ls);
      body(ls, v, 0, ls->linenumber);
      return;
    }
    default: {
      primaryexp(ls, v);
      return;
    }
  }
  luaX_next(ls);
}


static UnOpr getunopr (int op) {
  switch (op) {
    case TK_NOT: return OPR_NOT;
    case '-': return OPR_MINUS;
    case '#': return OPR_LEN;
    default: return OPR_NOUNOPR;
  }
}


static BinOpr getbinopr (int op) {
  switch (op) {
    case '+': return OPR_ADD;
    case '-': return OPR_SUB;
    case '*': return OPR_MUL;
    case '/': return OPR_DIV;
    case '%': return OPR_MOD;
    case '^': return OPR_POW;
    case TK_CONCAT: return OPR_CONCAT;
    case TK_NE: return OPR_NE;
    case TK_EQ: return OPR_EQ;
    case '<': return OPR_LT;
    case TK_LE: return OPR_LE;
    case '>': return OPR_GT;
    case TK_GE: return OPR_GE;
    case TK_AND: return OPR_AND;
    case TK_OR: return OPR_OR;
    default: return OPR_NOBINOPR;
  }
}


static const struct {
  lu_byte left;  /* left priority for each binary operator */
  lu_byte right; /* right priority */
} priority[] = {  /* ORDER OPR */
   {6, 6}, {6, 6}, {7, 7}, {7, 7}, {7, 7},  /* `+' `-' `/' `%' */
   {10, 9}, {5, 4},                 /* power and concat (right associative) */
   {3, 3}, {3, 3},                  /* equality and inequality */
   {3, 3}, {3, 3}, {3, 3}, {3, 3},  /* order */
   {2, 2}, {1, 1}                   /* logical (and/or) */
};

#define UNARY_PRIORITY  8  /* priority for unary operators */


/*
** subexpr -> (simpleexp | unop subexpr) { binop subexpr }
** where `binop' is any binary operator with a priority higher than `limit'
*/
static BinOpr subexpr (LexState *ls, expdesc *v, unsigned int limit) {
  BinOpr op;
  UnOpr uop;
  enterlevel(ls);
  uop = getunopr(ls->t.token);
  if (uop != OPR_NOUNOPR) {
    luaX_next(ls);
    subexpr(ls, v, UNARY_PRIORITY);
    luaK_prefix(ls->fs, uop, v);
  }
  else simpleexp(ls, v);
  /* expand while operators have priorities higher than `limit' */
  op = getbinopr(ls->t.token);
  while (op != OPR_NOBINOPR && priority[op].left > limit) {
    expdesc v2;
    BinOpr nextop;
    luaX_next(ls);
    luaK_infix(ls->fs, op, v);
    /* read sub-expression with higher priority */
    nextop = subexpr(ls, &v2, priority[op].right);
    luaK_posfix(ls->fs, op, v, &v2);
    op = nextop;
  }
  leavelevel(ls);
  return op;  /* return first untreated operator */
}


static void expr (LexState *ls, expdesc *v) {
  subexpr(ls, v, 0);
}

/* }==================================================================== */



/*
** {======================================================================
** Rules for Statements
** =======================================================================
*/


static int block_follow (int token) {
  switch (token) {
    case TK_ELSE: case TK_ELSEIF: case TK_END:
    case TK_UNTIL: case TK_EOS:
      return 1;
    default: return 0;
  }
}


static void block (LexState *ls) {
  /* block -> chunk */
  FuncState *fs = ls->fs;
  BlockCnt bl;
  enterblock(fs, &bl, 0);
  chunk(ls);
  lua_assert(bl.breaklist == NO_JUMP);
  leaveblock(fs);
}


/*
** structure to chain all variables in the left-hand side of an
** assignment
*/
struct LHS_assign {
  struct LHS_assign *prev;
  expdesc v;  /* variable (global, local, upvalue, or indexed) */
};


/*
** check whether, in an assignment to a local variable, the local variable
** is needed in a previous assignment (to a table). If so, save original
** local value in a safe place and use this safe copy in the previous
** assignment.
*/
static void check_conflict (LexState *ls, struct LHS_assign *lh, expdesc *v) {
  FuncState *fs = ls->fs;
  int extra = fs->freereg;  /* eventual position to save local variable */
  int conflict = 0;
  for (; lh; lh = lh->prev) {
    if (lh->v.k == VINDEXED) {
      if (lh->v.u.s.info == v->u.s.info) {  /* conflict? */
        conflict = 1;
        lh->v.u.s.info = extra;  /* previous assignment will use safe copy */
      }
      if (lh->v.u.s.aux == v->u.s.info) {  /* conflict? */
        conflict = 1;
        lh->v.u.s.aux = extra;  /* previous assignment will use safe copy */
      }
    }
  }
  if (conflict) {
    luaK_codeABC(fs, OP_MOVE, fs->freereg, v->u.s.info, 0);  /* make copy */
    luaK_reserveregs(fs, 1);
  }
}


static void assignment (LexState *ls, struct LHS_assign *lh, int nvars) {
  expdesc e;
  check_condition(ls, VLOCAL <= lh->v.k && lh->v.k <= VINDEXED,
                      "syntax error");
  if (testnext(ls, ',')) {  /* assignment -> `,' primaryexp assignment */
    struct LHS_assign nv;
    nv.prev = lh;
    primaryexp(ls, &nv.v);
    if (nv.v.k == VLOCAL)
      check_conflict(ls, lh, &nv.v);
    assignment(ls, &nv, nvars+1);
  }
  else {  /* assignment -> `=' explist1 */
    int nexps;
    checknext(ls, '=');
    nexps = explist1(ls, &e);
    if (nexps != nvars) {
      adjust_assign(ls, nvars, nexps, &e);
      if (nexps > nvars)
        ls->fs->freereg -= nexps - nvars;  /* remove extra values */
    }
    else {
      luaK_setoneret(ls->fs, &e);  /* close last expression */
      luaK_storevar(ls->fs, &lh->v, &e);
      return;  /* avoid default */
    }
  }
  init_exp(&e, VNONRELOC, ls->fs->freereg-1);  /* default assignment */
  luaK_storevar(ls->fs, &lh->v, &e);
}


static int cond (LexState *ls) {
  /* cond -> exp */
  expdesc v;
  expr(ls, &v);  /* read condition */
  if (v.k == VNIL) v.k = VFALSE;  /* `falses' are all equal here */
  luaK_goiftrue(ls->fs, &v);
  return v.f;
}


static void breakstat (LexState *ls) {
  FuncState *fs = ls->fs;
  BlockCnt *bl = fs->bl;
  int upval = 0;
  while (bl && !bl->isbreakable) {
    upval |= bl->upval;
    bl = bl->previous;
  }
  if (!bl)
    luaX_syntaxerror(ls, "no loop to break");
  if (upval)
    luaK_codeABC(fs, OP_CLOSE, bl->nactvar, 0, 0);
  luaK_concat(fs, &bl->breaklist, luaK_jump(fs));
}


static void whilestat (LexState *ls, int line) {
  /* whilestat -> WHILE cond DO block END */
  FuncState *fs = ls->fs;
  int whileinit;
  int condexit;
  BlockCnt bl;
  luaX_next(ls);  /* skip WHILE */
  whileinit = luaK_getlabel(fs);
  condexit = cond(ls);
  enterblock(fs, &bl, 1);
  checknext(ls, TK_DO);
  block(ls);
  luaK_patchlist(fs, luaK_jump(fs), whileinit);
  check_match(ls, TK_END, TK_WHILE, line);
  leaveblock(fs);
  luaK_patchtohere(fs, condexit);  /* false conditions finish the loop */
}


static void repeatstat (LexState *ls, int line) {
  /* repeatstat -> REPEAT block UNTIL cond */
  int condexit;
  FuncState *fs = ls->fs;
  int repeat_init = luaK_getlabel(fs);
  BlockCnt bl1, bl2;
  enterblock(fs, &bl1, 1);  /* loop block */
  enterblock(fs, &bl2, 0);  /* scope block */
  luaX_next(ls);  /* skip REPEAT */
  chunk(ls);
  check_match(ls, TK_UNTIL, TK_REPEAT, line);
  condexit = cond(ls);  /* read condition (inside scope block) */
  if (!bl2.upval) {  /* no upvalues? */
    leaveblock(fs);  /* finish scope */
    luaK_patchlist(ls->fs, condexit, repeat_init);  /* close the loop */
  }
  else {  /* complete semantics when there are upvalues */
    breakstat(ls);  /* if condition then break */
    luaK_patchtohere(ls->fs, condexit);  /* else... */
    leaveblock(fs);  /* finish scope... */
    luaK_patchlist(ls->fs, luaK_jump(fs), repeat_init);  /* and repeat */
  }
  leaveblock(fs);  /* finish loop */
}


static int exp1 (LexState *ls) {
  expdesc e;
  int k;
  expr(ls, &e);
  k = e.k;
  luaK_exp2nextreg(ls->fs, &e);
  return k;
}


static void forbody (LexState *ls, int base, int line, int nvars, int isnum) {
  /* forbody -> DO block */
  BlockCnt bl;
  FuncState *fs = ls->fs;
  int prep, endfor;
  adjustlocalvars(ls, 3);  /* control variables */
  checknext(ls, TK_DO);
  prep = isnum ? luaK_codeAsBx(fs, OP_FORPREP, base, NO_JUMP) : luaK_jump(fs);
  enterblock(fs, &bl, 0);  /* scope for declared variables */
  adjustlocalvars(ls, nvars);
  luaK_reserveregs(fs, nvars);
  block(ls);
  leaveblock(fs);  /* end of scope for declared variables */
  luaK_patchtohere(fs, prep);
  endfor = (isnum) ? luaK_codeAsBx(fs, OP_FORLOOP, base, NO_JUMP) :
                     luaK_codeABC(fs, OP_TFORLOOP, base, 0, nvars);
  luaK_fixline(fs, line);  /* pretend that `OP_FOR' starts the loop */
  luaK_patchlist(fs, (isnum ? endfor : luaK_jump(fs)), prep + 1);
}


static void fornum (LexState *ls, TString *varname, int line) {
  /* fornum -> NAME = exp1,exp1[,exp1] forbody */
  FuncState *fs = ls->fs;
  int base = fs->freereg;
  new_localvarliteral(ls, "(for index)", 0);
  new_localvarliteral(ls, "(for limit)", 1);
  new_localvarliteral(ls, "(for step)", 2);
  new_localvar(ls, varname, 3);
  checknext(ls, '=');
  exp1(ls);  /* initial value */
  checknext(ls, ',');
  exp1(ls);  /* limit */
  if (testnext(ls, ','))
    exp1(ls);  /* optional step */
  else {  /* default step = 1 */
    luaK_codeABx(fs, OP_LOADK, fs->freereg, luaK_numberK(fs, 1));
    luaK_reserveregs(fs, 1);
  }
  forbody(ls, base, line, 1, 1);
}


static void forlist (LexState *ls, TString *indexname) {
  /* forlist -> NAME {,NAME} IN explist1 forbody */
  FuncState *fs = ls->fs;
  expdesc e;
  int nvars = 0;
  int line;
  int base = fs->freereg;
  /* create control variables */
  new_localvarliteral(ls, "(for generator)", nvars++);
  new_localvarliteral(ls, "(for state)", nvars++);
  new_localvarliteral(ls, "(for control)", nvars++);
  /* create declared variables */
  new_localvar(ls, indexname, nvars++);
  while (testnext(ls, ','))
    new_localvar(ls, str_checkname(ls), nvars++);
  checknext(ls, TK_IN);
  line = ls->linenumber;
  adjust_assign(ls, 3, explist1(ls, &e), &e);
  luaK_checkstack(fs, 3);  /* extra space to call generator */
  forbody(ls, base, line, nvars - 3, 0);
}


static void forstat (LexState *ls, int line) {
  /* forstat -> FOR (fornum | forlist) END */
  FuncState *fs = ls->fs;
  TString *varname;
  BlockCnt bl;
  enterblock(fs, &bl, 1);  /* scope for loop and control variables */
  luaX_next(ls);  /* skip `for' */
  varname = str_checkname(ls);  /* first variable name */
  switch (ls->t.token) {
    case '=': fornum(ls, varname, line); break;
    case ',': case TK_IN: forlist(ls, varname); break;
    default: luaX_syntaxerror(ls, LUA_QL("=") " or " LUA_QL("in") " expected");
  }
  check_match(ls, TK_END, TK_FOR, line);
  leaveblock(fs);  /* loop scope (`break' jumps to this point) */
}


static int test_then_block (LexState *ls) {
  /* test_then_block -> [IF | ELSEIF] cond THEN block */
  int condexit;
  luaX_next(ls);  /* skip IF or ELSEIF */
  condexit = cond(ls);
  checknext(ls, TK_THEN);
  block(ls);  /* `then' part */
  return condexit;
}


static void ifstat (LexState *ls, int line) {
  /* ifstat -> IF cond THEN block {ELSEIF cond THEN block} [ELSE block] END */
  FuncState *fs = ls->fs;
  int flist;
  int escapelist = NO_JUMP;
  flist = test_then_block(ls);  /* IF cond THEN block */
  while (ls->t.token == TK_ELSEIF) {
    luaK_concat(fs, &escapelist, luaK_jump(fs));
    luaK_patchtohere(fs, flist);
    flist = test_then_block(ls);  /* ELSEIF cond THEN block */
  }
  if (ls->t.token == TK_ELSE) {
    luaK_concat(fs, &escapelist, luaK_jump(fs));
    luaK_patchtohere(fs, flist);
    luaX_next(ls);  /* skip ELSE (after patch, for correct line info) */
    block(ls);  /* `else' part */
  }
  else
    luaK_concat(fs, &escapelist, flist);
  luaK_patchtohere(fs, escapelist);
  check_match(ls, TK_END, TK_IF, line);
}


static void localfunc (LexState *ls) {
  expdesc v, b;
  FuncState *fs = ls->fs;
  new_localvar(ls, str_checkname(ls), 0);
  init_exp(&v, VLOCAL, fs->freereg);
  luaK_reserveregs(fs, 1);
  adjustlocalvars(ls, 1);
  body(ls, &b, 0, ls->linenumber);
  luaK_storevar(fs, &v, &b);
  /* debug information will only see the variable after this point! */
  getlocvar(fs, fs->nactvar - 1).startpc = fs->pc;
}


static void localstat (LexState *ls) {
  /* stat -> LOCAL NAME {`,' NAME} [`=' explist1] */
  int nvars = 0;
  int nexps;
  expdesc e;
  do {
    new_localvar(ls, str_checkname(ls), nvars++);
  } while (testnext(ls, ','));
  if (testnext(ls, '='))
    nexps = explist1(ls, &e);
  else {
    e.k = VVOID;
    nexps = 0;
  }
  adjust_assign(ls, nvars, nexps, &e);
  adjustlocalvars(ls, nvars);
}


static int funcname (LexState *ls, expdesc *v) {
  /* funcname -> NAME {field} [`:' NAME] */
  int needself = 0;
  singlevar(ls, v);
  while (ls->t.token == '.')
    field(ls, v);
  if (ls->t.token == ':') {
    needself = 1;
    field(ls, v);
  }
  return needself;
}


static void funcstat (LexState *ls, int line) {
  /* funcstat -> FUNCTION funcname body */
  int needself;
  expdesc v, b;
  luaX_next(ls);  /* skip FUNCTION */
  needself = funcname(ls, &v);
  body(ls, &b, needself, line);
  luaK_storevar(ls->fs, &v, &b);
  luaK_fixline(ls->fs, line);  /* definition `happens' in the first line */
}


static void exprstat (LexState *ls) {
  /* stat -> func | assignment */
  FuncState *fs = ls->fs;
  struct LHS_assign v;
  primaryexp(ls, &v.v);
  if (v.v.k == VCALL)  /* stat -> func */
    SETARG_C(getcode(fs, &v.v), 1);  /* call statement uses no results */
  else {  /* stat -> assignment */
    v.prev = NULL;
    assignment(ls, &v, 1);
  }
}


static void retstat (LexState *ls) {
  /* stat -> RETURN explist */
  FuncState *fs = ls->fs;
  expdesc e;
  int first, nret;  /* registers with returned values */
  luaX_next(ls);  /* skip RETURN */
  if (block_follow(ls->t.token) || ls->t.token == ';')
    first = nret = 0;  /* return no values */
  else {
    nret = explist1(ls, &e);  /* optional return values */
    if (hasmultret(e.k)) {
      luaK_setmultret(fs, &e);
      if (e.k == VCALL && nret == 1) {  /* tail call? */
        SET_OPCODE(getcode(fs,&e), OP_TAILCALL);
        lua_assert(GETARG_A(getcode(fs,&e)) == fs->nactvar);
      }
      first = fs->nactvar;
      nret = LUA_MULTRET;  /* return all values */
    }
    else {
      if (nret == 1)  /* only one single value? */
        first = luaK_exp2anyreg(fs, &e);
      else {
        luaK_exp2nextreg(fs, &e);  /* values must go to the `stack' */
        first = fs->nactvar;  /* return all `active' values */
        lua_assert(nret == fs->freereg - first);
      }
    }
  }
  luaK_ret(fs, first, nret);
}


static int statement (LexState *ls) {
  int line = ls->linenumber;  /* may be needed for error messages */
  switch (ls->t.token) {
    case TK_IF: {  /* stat -> ifstat */
      ifstat(ls, line);
      return 0;
    }
    case TK_WHILE: {  /* stat -> whilestat */
      whilestat(ls, line);
      return 0;
    }
    case TK_DO: {  /* stat -> DO block END */
      luaX_next(ls);  /* skip DO */
      block(ls);
      check_match(ls, TK_END, TK_DO, line);
      return 0;
    }
    case TK_FOR: {  /* stat -> forstat */
      forstat(ls, line);
      return 0;
    }
    case TK_REPEAT: {  /* stat -> repeatstat */
      repeatstat(ls, line);
      return 0;
    }
    case TK_FUNCTION: {
      funcstat(ls, line);  /* stat -> funcstat */
      return 0;
    }
    case TK_LOCAL: {  /* stat -> localstat */
      luaX_next(ls);  /* skip LOCAL */
      if (testnext(ls, TK_FUNCTION))  /* local function? */
        localfunc(ls);
      else
        localstat(ls);
      return 0;
    }
    case TK_RETURN: {  /* stat -> retstat */
      retstat(ls);
      return 1;  /* must be last statement */
    }
    case TK_BREAK: {  /* stat -> breakstat */
      luaX_next(ls);  /* skip BREAK */
      breakstat(ls);
      return 1;  /* must be last statement */
    }
    default: {
      exprstat(ls);
      return 0;  /* to avoid warnings */
    }
  }
}


static void chunk (LexState *ls) {
  /* chunk -> { stat [`;'] } */
  int islast = 0;
  enterlevel(ls);
  while (!islast && !block_follow(ls->t.token)) {
    islast = statement(ls);
    testnext(ls, ';');
    lua_assert(ls->fs->f->maxstacksize >= ls->fs->freereg &&
               ls->fs->freereg >= ls->fs->nactvar);
    ls->fs->freereg = ls->fs->nactvar;  /* free registers */
  }
  leavelevel(ls);
}

/* }====================================================================== */
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lstate.c ===
/*
** $Id: lstate.c,v 2.36 2006/05/24 14:15:50 roberto Exp $
** Global State
** See Copyright Notice in lua.h
*/


#include <stddef.h>

#define lstate_c
#define LUA_CORE

#include "lua.h"

#include "ldebug.h"
#include "ldo.h"
#include "lfunc.h"
#include "lgc.h"
#include "llex.h"
#include "lmem.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"
#include "ltm.h"


#define state_size(x)	(sizeof(x) + LUAI_EXTRASPACE)
#define fromstate(l)	(cast(lu_byte *, (l)) - LUAI_EXTRASPACE)
#define tostate(l)   (cast(lua_State *, cast(lu_byte *, l) + LUAI_EXTRASPACE))


/*
** Main thread combines a thread state and the global state
*/
typedef struct LG {
  lua_State l;
  global_State g;
} LG;
  


static void stack_init (lua_State *L1, lua_State *L) {
  /* initialize CallInfo array */
  L1->base_ci = luaM_newvector(L, BASIC_CI_SIZE, CallInfo);
  L1->ci = L1->base_ci;
  L1->size_ci = BASIC_CI_SIZE;
  L1->end_ci = L1->base_ci + L1->size_ci - 1;
  /* initialize stack array */
  L1->stack = luaM_newvector(L, BASIC_STACK_SIZE + EXTRA_STACK, TValue);
  L1->stacksize = BASIC_STACK_SIZE + EXTRA_STACK;
  L1->top = L1->stack;
  L1->stack_last = L1->stack+(L1->stacksize - EXTRA_STACK)-1;
  /* initialize first ci */
  L1->ci->func = L1->top;
  setnilvalue(L1->top++);  /* `function' entry for this `ci' */
  L1->base = L1->ci->base = L1->top;
  L1->ci->top = L1->top + LUA_MINSTACK;
}


static void freestack (lua_State *L, lua_State *L1) {
  luaM_freearray(L, L1->base_ci, L1->size_ci, CallInfo);
  luaM_freearray(L, L1->stack, L1->stacksize, TValue);
}


/*
** open parts that may cause memory-allocation errors
*/
static void f_luaopen (lua_State *L, void *ud) {
  global_State *g = G(L);
  UNUSED(ud);
  stack_init(L, L);  /* init stack */
  sethvalue(L, gt(L), luaH_new(L, 0, 2));  /* table of globals */
  sethvalue(L, registry(L), luaH_new(L, 0, 2));  /* registry */
  luaS_resize(L, MINSTRTABSIZE);  /* initial size of string table */
  luaT_init(L);
  luaX_init(L);
  luaS_fix(luaS_newliteral(L, MEMERRMSG));
  g->GCthreshold = 4*g->totalbytes;
}


static void preinit_state (lua_State *L, global_State *g) {
  G(L) = g;
  L->stack = NULL;
  L->stacksize = 0;
  L->errorJmp = NULL;
  L->hook = NULL;
  L->hookmask = 0;
  L->basehookcount = 0;
  L->allowhook = 1;
  resethookcount(L);
  L->openupval = NULL;
  L->size_ci = 0;
  L->nCcalls = 0;
  L->status = 0;
  L->base_ci = L->ci = NULL;
  L->savedpc = NULL;
  L->errfunc = 0;
  setnilvalue(gt(L));
}


static void close_state (lua_State *L) {
  global_State *g = G(L);
  luaF_close(L, L->stack);  /* close all upvalues for this thread */
  luaC_freeall(L);  /* collect all objects */
  lua_assert(g->rootgc == obj2gco(L));
  lua_assert(g->strt.nuse == 0);
  luaM_freearray(L, G(L)->strt.hash, G(L)->strt.size, TString *);
  luaZ_freebuffer(L, &g->buff);
  freestack(L, L);
  lua_assert(g->totalbytes == sizeof(LG));
  (*g->frealloc)(g->ud, fromstate(L), state_size(LG), 0);
}


lua_State *luaE_newthread (lua_State *L) {
  lua_State *L1 = tostate(luaM_malloc(L, state_size(lua_State)));
  luaC_link(L, obj2gco(L1), LUA_TTHREAD);
  preinit_state(L1, G(L));
  stack_init(L1, L);  /* init stack */
  setobj2n(L, gt(L1), gt(L));  /* share table of globals */
  L1->hookmask = L->hookmask;
  L1->basehookcount = L->basehookcount;
  L1->hook = L->hook;
  resethookcount(L1);
  lua_assert(iswhite(obj2gco(L1)));
  return L1;
}


void luaE_freethread (lua_State *L, lua_State *L1) {
  luaF_close(L1, L1->stack);  /* close all upvalues for this thread */
  lua_assert(L1->openupval == NULL);
  luai_userstatefree(L1);
  freestack(L, L1);
  luaM_freemem(L, fromstate(L1), state_size(lua_State));
}


LUA_API lua_State *lua_newstate (lua_Alloc f, void *ud) {
  int i;
  lua_State *L;
  global_State *g;
  void *l = (*f)(ud, NULL, 0, state_size(LG));
  if (l == NULL) return NULL;
  L = tostate(l);
  g = &((LG *)L)->g;
  L->next = NULL;
  L->tt = LUA_TTHREAD;
  g->currentwhite = bit2mask(WHITE0BIT, FIXEDBIT);
  L->marked = luaC_white(g);
  set2bits(L->marked, FIXEDBIT, SFIXEDBIT);
  preinit_state(L, g);
  g->frealloc = f;
  g->ud = ud;
  g->mainthread = L;
  g->uvhead.u.l.prev = &g->uvhead;
  g->uvhead.u.l.next = &g->uvhead;
  g->GCthreshold = 0;  /* mark it as unfinished state */
  g->strt.size = 0;
  g->strt.nuse = 0;
  g->strt.hash = NULL;
  setnilvalue(registry(L));
  luaZ_initbuffer(L, &g->buff);
  g->panic = NULL;
  g->gcstate = GCSpause;
  g->rootgc = obj2gco(L);
  g->sweepstrgc = 0;
  g->sweepgc = &g->rootgc;
  g->gray = NULL;
  g->grayagain = NULL;
  g->weak = NULL;
  g->tmudata = NULL;
  g->totalbytes = sizeof(LG);
  g->gcpause = LUAI_GCPAUSE;
  g->gcstepmul = LUAI_GCMUL;
  g->gcdept = 0;
  for (i=0; i<NUM_TAGS; i++) g->mt[i] = NULL;
  if (luaD_rawrunprotected(L, f_luaopen, NULL) != 0) {
    /* memory allocation error: free partial state */
    close_state(L);
    L = NULL;
  }
  else
    luai_userstateopen(L);
  return L;
}


static void callallgcTM (lua_State *L, void *ud) {
  UNUSED(ud);
  luaC_callGCTM(L);  /* call GC metamethods for all udata */
}


LUA_API void lua_close (lua_State *L) {
  L = G(L)->mainthread;  /* only the main thread can be closed */
  lua_lock(L);
  luaF_close(L, L->stack);  /* close all upvalues for this thread */
  luaC_separateudata(L, 1);  /* separate udata that have GC metamethods */
  L->errfunc = 0;  /* no error function during GC metamethods */
  do {  /* repeat until no more errors */
    L->ci = L->base_ci;
    L->base = L->top = L->ci->base;
    L->nCcalls = 0;
  } while (luaD_rawrunprotected(L, callallgcTM, NULL) != 0);
  lua_assert(G(L)->tmudata == NULL);
  luai_userstateclose(L);
  close_state(L);
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lstring.c ===
/*
** $Id: lstring.c,v 2.8 2005/12/22 16:19:56 roberto Exp $
** String table (keeps all strings handled by Lua)
** See Copyright Notice in lua.h
*/


#include <string.h>

#define lstring_c
#define LUA_CORE

#include "lua.h"

#include "lmem.h"
#include "lobject.h"
#include "lstate.h"
#include "lstring.h"



void luaS_resize (lua_State *L, int newsize) {
  GCObject **newhash;
  stringtable *tb;
  int i;
  if (G(L)->gcstate == GCSsweepstring)
    return;  /* cannot resize during GC traverse */
  newhash = luaM_newvector(L, newsize, GCObject *);
  tb = &G(L)->strt;
  for (i=0; i<newsize; i++) newhash[i] = NULL;
  /* rehash */
  for (i=0; i<tb->size; i++) {
    GCObject *p = tb->hash[i];
    while (p) {  /* for each node in the list */
      GCObject *next = p->gch.next;  /* save next */
      unsigned int h = gco2ts(p)->hash;
      int h1 = lmod(h, newsize);  /* new position */
      lua_assert(cast_int(h%newsize) == lmod(h, newsize));
      p->gch.next = newhash[h1];  /* chain it */
      newhash[h1] = p;
      p = next;
    }
  }
  luaM_freearray(L, tb->hash, tb->size, TString *);
  tb->size = newsize;
  tb->hash = newhash;
}


static TString *newlstr (lua_State *L, const char *str, size_t l,
                                       unsigned int h) {
  TString *ts;
  stringtable *tb;
  if (l+1 > (MAX_SIZET - sizeof(TString))/sizeof(char))
    luaM_toobig(L);
  ts = cast(TString *, luaM_malloc(L, (l+1)*sizeof(char)+sizeof(TString)));
  ts->tsv.len = l;
  ts->tsv.hash = h;
  ts->tsv.marked = luaC_white(G(L));
  ts->tsv.tt = LUA_TSTRING;
  ts->tsv.reserved = 0;
  memcpy(ts+1, str, l*sizeof(char));
  ((char *)(ts+1))[l] = '\0';  /* ending 0 */
  tb = &G(L)->strt;
  h = lmod(h, tb->size);
  ts->tsv.next = tb->hash[h];  /* chain new entry */
  tb->hash[h] = obj2gco(ts);
  tb->nuse++;
  if (tb->nuse > cast(lu_int32, tb->size) && tb->size <= MAX_INT/2)
    luaS_resize(L, tb->size*2);  /* too crowded */
  return ts;
}


TString *luaS_newlstr (lua_State *L, const char *str, size_t l) {
  GCObject *o;
  unsigned int h = cast(unsigned int, l);  /* seed */
  size_t step = (l>>5)+1;  /* if string is too long, don't hash all its chars */
  size_t l1;
  for (l1=l; l1>=step; l1-=step)  /* compute hash */
    h = h ^ ((h<<5)+(h>>2)+cast(unsigned char, str[l1-1]));
  for (o = G(L)->strt.hash[lmod(h, G(L)->strt.size)];
       o != NULL;
       o = o->gch.next) {
    TString *ts = rawgco2ts(o);
    if (ts->tsv.len == l && (memcmp(str, getstr(ts), l) == 0)) {
      /* string may be dead */
      if (isdead(G(L), o)) changewhite(o);
      return ts;
    }
  }
  return newlstr(L, str, l, h);  /* not found */
}


Udata *luaS_newudata (lua_State *L, size_t s, Table *e) {
  Udata *u;
  if (s > MAX_SIZET - sizeof(Udata))
    luaM_toobig(L);
  u = cast(Udata *, luaM_malloc(L, s + sizeof(Udata)));
  u->uv.marked = luaC_white(G(L));  /* is not finalized */
  u->uv.tt = LUA_TUSERDATA;
  u->uv.len = s;
  u->uv.metatable = NULL;
  u->uv.env = e;
  /* chain it on udata list (after main thread) */
  u->uv.next = G(L)->mainthread->next;
  G(L)->mainthread->next = obj2gco(u);
  return u;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ltable.h ===
/*
** $Id: ltable.h,v 2.10 2006/01/10 13:13:06 roberto Exp $
** Lua tables (hash)
** See Copyright Notice in lua.h
*/

#ifndef ltable_h
#define ltable_h

#include "lobject.h"


#define gnode(t,i)	(&(t)->node[i])
#define gkey(n)		(&(n)->i_key.nk)
#define gval(n)		(&(n)->i_val)
#define gnext(n)	((n)->i_key.nk.next)

#define key2tval(n)	(&(n)->i_key.tvk)


LUAI_FUNC const TValue *luaH_getnum (Table *t, int key);
LUAI_FUNC TValue *luaH_setnum (lua_State *L, Table *t, int key);
LUAI_FUNC const TValue *luaH_getstr (Table *t, TString *key);
LUAI_FUNC TValue *luaH_setstr (lua_State *L, Table *t, TString *key);
LUAI_FUNC const TValue *luaH_get (Table *t, const TValue *key);
LUAI_FUNC TValue *luaH_set (lua_State *L, Table *t, const TValue *key);
LUAI_FUNC Table *luaH_new (lua_State *L, int narray, int lnhash);
LUAI_FUNC void luaH_resizearray (lua_State *L, Table *t, int nasize);
LUAI_FUNC void luaH_free (lua_State *L, Table *t);
LUAI_FUNC int luaH_next (lua_State *L, Table *t, StkId key);
LUAI_FUNC int luaH_getn (Table *t);


#if defined(LUA_DEBUG)
LUAI_FUNC Node *luaH_mainposition (const Table *t, const TValue *key);
LUAI_FUNC int luaH_isdummy (Node *n);
#endif


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lstring.h ===
/*
** $Id: lstring.h,v 1.43 2005/04/25 19:24:10 roberto Exp $
** String table (keep all strings handled by Lua)
** See Copyright Notice in lua.h
*/

#ifndef lstring_h
#define lstring_h


#include "lgc.h"
#include "lobject.h"
#include "lstate.h"


#define sizestring(s)	(sizeof(union TString)+((s)->len+1)*sizeof(char))

#define sizeudata(u)	(sizeof(union Udata)+(u)->len)

#define luaS_new(L, s)	(luaS_newlstr(L, s, strlen(s)))
#define luaS_newliteral(L, s)	(luaS_newlstr(L, "" s, \
                                 (sizeof(s)/sizeof(char))-1))

#define luaS_fix(s)	l_setbit((s)->tsv.marked, FIXEDBIT)

LUAI_FUNC void luaS_resize (lua_State *L, int newsize);
LUAI_FUNC Udata *luaS_newudata (lua_State *L, size_t s, Table *e);
LUAI_FUNC TString *luaS_newlstr (lua_State *L, const char *str, size_t l);


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ltablib.c ===
/*
** $Id: ltablib.c,v 1.38 2005/10/23 17:38:15 roberto Exp $
** Library for Table Manipulation
** See Copyright Notice in lua.h
*/


#include <stddef.h>

#define ltablib_c
#define LUA_LIB

#include "lua.h"

#include "lauxlib.h"
#include "lualib.h"


#define aux_getn(L,n)	(luaL_checktype(L, n, LUA_TTABLE), luaL_getn(L, n))


static int foreachi (lua_State *L) {
  int i;
  int n = aux_getn(L, 1);
  luaL_checktype(L, 2, LUA_TFUNCTION);
  for (i=1; i <= n; i++) {
    lua_pushvalue(L, 2);  /* function */
    lua_pushinteger(L, i);  /* 1st argument */
    lua_rawgeti(L, 1, i);  /* 2nd argument */
    lua_call(L, 2, 1);
    if (!lua_isnil(L, -1))
      return 1;
    lua_pop(L, 1);  /* remove nil result */
  }
  return 0;
}


static int foreach (lua_State *L) {
  luaL_checktype(L, 1, LUA_TTABLE);
  luaL_checktype(L, 2, LUA_TFUNCTION);
  lua_pushnil(L);  /* first key */
  while (lua_next(L, 1)) {
    lua_pushvalue(L, 2);  /* function */
    lua_pushvalue(L, -3);  /* key */
    lua_pushvalue(L, -3);  /* value */
    lua_call(L, 2, 1);
    if (!lua_isnil(L, -1))
      return 1;
    lua_pop(L, 2);  /* remove value and result */
  }
  return 0;
}


static int maxn (lua_State *L) {
  lua_Number max = 0;
  luaL_checktype(L, 1, LUA_TTABLE);
  lua_pushnil(L);  /* first key */
  while (lua_next(L, 1)) {
    lua_pop(L, 1);  /* remove value */
    if (lua_type(L, -1) == LUA_TNUMBER) {
      lua_Number v = lua_tonumber(L, -1);
      if (v > max) max = v;
    }
  }
  lua_pushnumber(L, max);
  return 1;
}


static int getn (lua_State *L) {
  lua_pushinteger(L, aux_getn(L, 1));
  return 1;
}


static int setn (lua_State *L) {
  luaL_checktype(L, 1, LUA_TTABLE);
#ifndef luaL_setn
  luaL_setn(L, 1, luaL_checkint(L, 2));
#else
  luaL_error(L, LUA_QL("setn") " is obsolete");
#endif
  lua_pushvalue(L, 1);
  return 1;
}


static int tinsert (lua_State *L) {
  int e = aux_getn(L, 1) + 1;  /* first empty element */
  int pos;  /* where to insert new element */
  switch (lua_gettop(L)) {
    case 2: {  /* called with only 2 arguments */
      pos = e;  /* insert new element at the end */
      break;
    }
    case 3: {
      int i;
      pos = luaL_checkint(L, 2);  /* 2nd argument is the position */
      if (pos > e) e = pos;  /* `grow' array if necessary */
      for (i = e; i > pos; i--) {  /* move up elements */
        lua_rawgeti(L, 1, i-1);
        lua_rawseti(L, 1, i);  /* t[i] = t[i-1] */
      }
      break;
    }
    default: {
      return luaL_error(L, "wrong number of arguments to " LUA_QL("insert"));
    }
  }
  luaL_setn(L, 1, e);  /* new size */
  lua_rawseti(L, 1, pos);  /* t[pos] = v */
  return 0;
}


static int tremove (lua_State *L) {
  int e = aux_getn(L, 1);
  int pos = luaL_optint(L, 2, e);
  if (e == 0) return 0;  /* table is `empty' */
  luaL_setn(L, 1, e - 1);  /* t.n = n-1 */
  lua_rawgeti(L, 1, pos);  /* result = t[pos] */
  for ( ;pos<e; pos++) {
    lua_rawgeti(L, 1, pos+1);
    lua_rawseti(L, 1, pos);  /* t[pos] = t[pos+1] */
  }
  lua_pushnil(L);
  lua_rawseti(L, 1, e);  /* t[e] = nil */
  return 1;
}


static int tconcat (lua_State *L) {
  luaL_Buffer b;
  size_t lsep;
  int i, last;
  const char *sep = luaL_optlstring(L, 2, "", &lsep);
  luaL_checktype(L, 1, LUA_TTABLE);
  i = luaL_optint(L, 3, 1);
  last = luaL_opt(L, luaL_checkint, 4, luaL_getn(L, 1));
  luaL_buffinit(L, &b);
  for (; i <= last; i++) {
    lua_rawgeti(L, 1, i);
    luaL_argcheck(L, lua_isstring(L, -1), 1, "table contains non-strings");
    luaL_addvalue(&b);
    if (i != last)
      luaL_addlstring(&b, sep, lsep);
  }
  luaL_pushresult(&b);
  return 1;
}



/*
** {======================================================
** Quicksort
** (based on `Algorithms in MODULA-3', Robert Sedgewick;
**  Addison-Wesley, 1993.)
*/


static void set2 (lua_State *L, int i, int j) {
  lua_rawseti(L, 1, i);
  lua_rawseti(L, 1, j);
}

static int sort_comp (lua_State *L, int a, int b) {
  if (!lua_isnil(L, 2)) {  /* function? */
    int res;
    lua_pushvalue(L, 2);
    lua_pushvalue(L, a-1);  /* -1 to compensate function */
    lua_pushvalue(L, b-2);  /* -2 to compensate function and `a' */
    lua_call(L, 2, 1);
    res = lua_toboolean(L, -1);
    lua_pop(L, 1);
    return res;
  }
  else  /* a < b? */
    return lua_lessthan(L, a, b);
}

static void auxsort (lua_State *L, int l, int u) {
  while (l < u) {  /* for tail recursion */
    int i, j;
    /* sort elements a[l], a[(l+u)/2] and a[u] */
    lua_rawgeti(L, 1, l);
    lua_rawgeti(L, 1, u);
    if (sort_comp(L, -1, -2))  /* a[u] < a[l]? */
      set2(L, l, u);  /* swap a[l] - a[u] */
    else
      lua_pop(L, 2);
    if (u-l == 1) break;  /* only 2 elements */
    i = (l+u)/2;
    lua_rawgeti(L, 1, i);
    lua_rawgeti(L, 1, l);
    if (sort_comp(L, -2, -1))  /* a[i]<a[l]? */
      set2(L, i, l);
    else {
      lua_pop(L, 1);  /* remove a[l] */
      lua_rawgeti(L, 1, u);
      if (sort_comp(L, -1, -2))  /* a[u]<a[i]? */
        set2(L, i, u);
      else
        lua_pop(L, 2);
    }
    if (u-l == 2) break;  /* only 3 elements */
    lua_rawgeti(L, 1, i);  /* Pivot */
    lua_pushvalue(L, -1);
    lua_rawgeti(L, 1, u-1);
    set2(L, i, u-1);
    /* a[l] <= P == a[u-1] <= a[u], only need to sort from l+1 to u-2 */
    i = l; j = u-1;
    for (;;) {  /* invariant: a[l..i] <= P <= a[j..u] */
      /* repeat ++i until a[i] >= P */
      while (lua_rawgeti(L, 1, ++i), sort_comp(L, -1, -2)) {
        if (i>u) luaL_error(L, "invalid order function for sorting");
        lua_pop(L, 1);  /* remove a[i] */
      }
      /* repeat --j until a[j] <= P */
      while (lua_rawgeti(L, 1, --j), sort_comp(L, -3, -1)) {
        if (j<l) luaL_error(L, "invalid order function for sorting");
        lua_pop(L, 1);  /* remove a[j] */
      }
      if (j<i) {
        lua_pop(L, 3);  /* pop pivot, a[i], a[j] */
        break;
      }
      set2(L, i, j);
    }
    lua_rawgeti(L, 1, u-1);
    lua_rawgeti(L, 1, i);
    set2(L, u-1, i);  /* swap pivot (a[u-1]) with a[i] */
    /* a[l..i-1] <= a[i] == P <= a[i+1..u] */
    /* adjust so that smaller half is in [j..i] and larger one in [l..u] */
    if (i-l < u-i) {
      j=l; i=i-1; l=i+2;
    }
    else {
      j=i+1; i=u; u=j-2;
    }
    auxsort(L, j, i);  /* call recursively the smaller one */
  }  /* repeat the routine for the larger one */
}

static int sort (lua_State *L) {
  int n = aux_getn(L, 1);
  luaL_checkstack(L, 40, "");  /* assume array is smaller than 2^40 */
  if (!lua_isnoneornil(L, 2))  /* is there a 2nd argument? */
    luaL_checktype(L, 2, LUA_TFUNCTION);
  lua_settop(L, 2);  /* make sure there is two arguments */
  auxsort(L, 1, n);
  return 0;
}

/* }====================================================== */


static const luaL_Reg tab_funcs[] = {
  {"concat", tconcat},
  {"foreach", foreach},
  {"foreachi", foreachi},
  {"getn", getn},
  {"maxn", maxn},
  {"insert", tinsert},
  {"remove", tremove},
  {"setn", setn},
  {"sort", sort},
  {NULL, NULL}
};


LUALIB_API int luaopen_table (lua_State *L) {
  luaL_register(L, LUA_TABLIBNAME, tab_funcs);
  return 1;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lstate.h ===
/*
** $Id: lstate.h,v 2.24 2006/02/06 18:27:59 roberto Exp $
** Global State
** See Copyright Notice in lua.h
*/

#ifndef lstate_h
#define lstate_h

#include "lua.h"

#include "lobject.h"
#include "ltm.h"
#include "lzio.h"



struct lua_longjmp;  /* defined in ldo.c */


/* table of globals */
#define gt(L)	(&L->l_gt)

/* registry */
#define registry(L)	(&G(L)->l_registry)


/* extra stack space to handle TM calls and some other extras */
#define EXTRA_STACK   5


#define BASIC_CI_SIZE           8

#define BASIC_STACK_SIZE        (2*LUA_MINSTACK)



typedef struct stringtable {
  GCObject **hash;
  lu_int32 nuse;  /* number of elements */
  int size;
} stringtable;


/*
** informations about a call
*/
typedef struct CallInfo {
  StkId base;  /* base for this function */
  StkId func;  /* function index in the stack */
  StkId	top;  /* top for this function */
  const Instruction *savedpc;
  int nresults;  /* expected number of results from this function */
  int tailcalls;  /* number of tail calls lost under this entry */
} CallInfo;



#define curr_func(L)	(clvalue(L->ci->func))
#define ci_func(ci)	(clvalue((ci)->func))
#define f_isLua(ci)	(!ci_func(ci)->c.isC)
#define isLua(ci)	(ttisfunction((ci)->func) && f_isLua(ci))


/*
** `global state', shared by all threads of this state
*/
typedef struct global_State {
  stringtable strt;  /* hash table for strings */
  lua_Alloc frealloc;  /* function to reallocate memory */
  void *ud;         /* auxiliary data to `frealloc' */
  lu_byte currentwhite;
  lu_byte gcstate;  /* state of garbage collector */
  int sweepstrgc;  /* position of sweep in `strt' */
  GCObject *rootgc;  /* list of all collectable objects */
  GCObject **sweepgc;  /* position of sweep in `rootgc' */
  GCObject *gray;  /* list of gray objects */
  GCObject *grayagain;  /* list of objects to be traversed atomically */
  GCObject *weak;  /* list of weak tables (to be cleared) */
  GCObject *tmudata;  /* last element of list of userdata to be GC */
  Mbuffer buff;  /* temporary buffer for string concatentation */
  lu_mem GCthreshold;
  lu_mem totalbytes;  /* number of bytes currently allocated */
  lu_mem estimate;  /* an estimate of number of bytes actually in use */
  lu_mem gcdept;  /* how much GC is `behind schedule' */
  int gcpause;  /* size of pause between successive GCs */
  int gcstepmul;  /* GC `granularity' */
  lua_CFunction panic;  /* to be called in unprotected errors */
  TValue l_registry;
  struct lua_State *mainthread;
  UpVal uvhead;  /* head of double-linked list of all open upvalues */
  struct Table *mt[NUM_TAGS];  /* metatables for basic types */
  TString *tmname[TM_N];  /* array with tag-method names */
} global_State;


/*
** `per thread' state
*/
struct lua_State {
  CommonHeader;
  lu_byte status;
  StkId top;  /* first free slot in the stack */
  StkId base;  /* base of current function */
  global_State *l_G;
  CallInfo *ci;  /* call info for current function */
  const Instruction *savedpc;  /* `savedpc' of current function */
  StkId stack_last;  /* last free slot in the stack */
  StkId stack;  /* stack base */
  CallInfo *end_ci;  /* points after end of ci array*/
  CallInfo *base_ci;  /* array of CallInfo's */
  int stacksize;
  int size_ci;  /* size of array `base_ci' */
  unsigned short nCcalls;  /* number of nested C calls */
  lu_byte hookmask;
  lu_byte allowhook;
  int basehookcount;
  int hookcount;
  lua_Hook hook;
  TValue l_gt;  /* table of globals */
  TValue env;  /* temporary place for environments */
  GCObject *openupval;  /* list of open upvalues in this stack */
  GCObject *gclist;
  struct lua_longjmp *errorJmp;  /* current error recover point */
  ptrdiff_t errfunc;  /* current error handling function (stack index) */
};


#define G(L)	(L->l_G)


/*
** Union of all collectable objects
*/
union GCObject {
  GCheader gch;
  union TString ts;
  union Udata u;
  union Closure cl;
  struct Table h;
  struct Proto p;
  struct UpVal uv;
  struct lua_State th;  /* thread */
};


/* macros to convert a GCObject into a specific value */
#define rawgco2ts(o)	check_exp((o)->gch.tt == LUA_TSTRING, &((o)->ts))
#define gco2ts(o)	(&rawgco2ts(o)->tsv)
#define rawgco2u(o)	check_exp((o)->gch.tt == LUA_TUSERDATA, &((o)->u))
#define gco2u(o)	(&rawgco2u(o)->uv)
#define gco2cl(o)	check_exp((o)->gch.tt == LUA_TFUNCTION, &((o)->cl))
#define gco2h(o)	check_exp((o)->gch.tt == LUA_TTABLE, &((o)->h))
#define gco2p(o)	check_exp((o)->gch.tt == LUA_TPROTO, &((o)->p))
#define gco2uv(o)	check_exp((o)->gch.tt == LUA_TUPVAL, &((o)->uv))
#define ngcotouv(o) \
	check_exp((o) == NULL || (o)->gch.tt == LUA_TUPVAL, &((o)->uv))
#define gco2th(o)	check_exp((o)->gch.tt == LUA_TTHREAD, &((o)->th))

/* macro to convert any Lua object into a GCObject */
#define obj2gco(v)	(cast(GCObject *, (v)))


LUAI_FUNC lua_State *luaE_newthread (lua_State *L);
LUAI_FUNC void luaE_freethread (lua_State *L, lua_State *L1);

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lstrlib.c ===
/*
** $Id: lstrlib.c,v 1.132 2006/04/26 20:41:19 roberto Exp $
** Standard library for string operations and pattern-matching
** See Copyright Notice in lua.h
*/


#include <ctype.h>
#include <stddef.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define lstrlib_c
#define LUA_LIB

#include "lua.h"

#include "lauxlib.h"
#include "lualib.h"


/* macro to `unsign' a character */
#define uchar(c)        ((unsigned char)(c))



static int str_len (lua_State *L) {
  size_t l;
  luaL_checklstring(L, 1, &l);
  lua_pushinteger(L, l);
  return 1;
}


static ptrdiff_t posrelat (ptrdiff_t pos, size_t len) {
  /* relative string position: negative means back from end */
  return (pos>=0) ? pos : (ptrdiff_t)len+pos+1;
}


static int str_sub (lua_State *L) {
  size_t l;
  const char *s = luaL_checklstring(L, 1, &l);
  ptrdiff_t start = posrelat(luaL_checkinteger(L, 2), l);
  ptrdiff_t end = posrelat(luaL_optinteger(L, 3, -1), l);
  if (start < 1) start = 1;
  if (end > (ptrdiff_t)l) end = (ptrdiff_t)l;
  if (start <= end)
    lua_pushlstring(L, s+start-1, end-start+1);
  else lua_pushliteral(L, "");
  return 1;
}


static int str_reverse (lua_State *L) {
  size_t l;
  luaL_Buffer b;
  const char *s = luaL_checklstring(L, 1, &l);
  luaL_buffinit(L, &b);
  while (l--) luaL_addchar(&b, s[l]);
  luaL_pushresult(&b);
  return 1;
}


static int str_lower (lua_State *L) {
  size_t l;
  size_t i;
  luaL_Buffer b;
  const char *s = luaL_checklstring(L, 1, &l);
  luaL_buffinit(L, &b);
  for (i=0; i<l; i++)
    luaL_addchar(&b, tolower(uchar(s[i])));
  luaL_pushresult(&b);
  return 1;
}


static int str_upper (lua_State *L) {
  size_t l;
  size_t i;
  luaL_Buffer b;
  const char *s = luaL_checklstring(L, 1, &l);
  luaL_buffinit(L, &b);
  for (i=0; i<l; i++)
    luaL_addchar(&b, toupper(uchar(s[i])));
  luaL_pushresult(&b);
  return 1;
}

static int str_rep (lua_State *L) {
  size_t l;
  luaL_Buffer b;
  const char *s = luaL_checklstring(L, 1, &l);
  int n = luaL_checkint(L, 2);
  luaL_buffinit(L, &b);
  while (n-- > 0)
    luaL_addlstring(&b, s, l);
  luaL_pushresult(&b);
  return 1;
}


static int str_byte (lua_State *L) {
  size_t l;
  const char *s = luaL_checklstring(L, 1, &l);
  ptrdiff_t posi = posrelat(luaL_optinteger(L, 2, 1), l);
  ptrdiff_t pose = posrelat(luaL_optinteger(L, 3, posi), l);
  int n, i;
  if (posi <= 0) posi = 1;
  if ((size_t)pose > l) pose = l;
  if (posi > pose) return 0;  /* empty interval; return no values */
  n = (int)(pose -  posi + 1);
  if (posi + n <= pose)  /* overflow? */
    luaL_error(L, "string slice too long");
  luaL_checkstack(L, n, "string slice too long");
  for (i=0; i<n; i++)
    lua_pushinteger(L, uchar(s[posi+i-1]));
  return n;
}


static int str_char (lua_State *L) {
  int n = lua_gettop(L);  /* number of arguments */
  int i;
  luaL_Buffer b;
  luaL_buffinit(L, &b);
  for (i=1; i<=n; i++) {
    int c = luaL_checkint(L, i);
    luaL_argcheck(L, uchar(c) == c, i, "invalid value");
    luaL_addchar(&b, uchar(c));
  }
  luaL_pushresult(&b);
  return 1;
}


static int writer (lua_State *L, const void* b, size_t size, void* B) {
  (void)L;
  luaL_addlstring((luaL_Buffer*) B, (const char *)b, size);
  return 0;
}


static int str_dump (lua_State *L) {
  luaL_Buffer b;
  luaL_checktype(L, 1, LUA_TFUNCTION);
  lua_settop(L, 1);
  luaL_buffinit(L,&b);
  if (lua_dump(L, writer, &b) != 0)
    luaL_error(L, "unable to dump given function");
  luaL_pushresult(&b);
  return 1;
}



/*
** {======================================================
** PATTERN MATCHING
** =======================================================
*/


#define CAP_UNFINISHED  (-1)
#define CAP_POSITION    (-2)

typedef struct MatchState {
  const char *src_init;  /* init of source string */
  const char *src_end;  /* end (`\0') of source string */
  lua_State *L;
  int level;  /* total number of captures (finished or unfinished) */
  struct {
    const char *init;
    ptrdiff_t len;
  } capture[LUA_MAXCAPTURES];
} MatchState;


#define L_ESC       '%'
#define SPECIALS    "^$*+?.([%-"


static int check_capture (MatchState *ms, int l) {
  l -= '1';
  if (l < 0 || l >= ms->level || ms->capture[l].len == CAP_UNFINISHED)
    return luaL_error(ms->L, "invalid capture index");
  return l;
}


static int capture_to_close (MatchState *ms) {
  int level = ms->level;
  for (level--; level>=0; level--)
    if (ms->capture[level].len == CAP_UNFINISHED) return level;
  return luaL_error(ms->L, "invalid pattern capture");
}


static const char *classend (MatchState *ms, const char *p) {
  switch (*p++) {
    case L_ESC: {
      if (*p == '\0')
        luaL_error(ms->L, "malformed pattern (ends with " LUA_QL("%%") ")");
      return p+1;
    }
    case '[': {
      if (*p == '^') p++;
      do {  /* look for a `]' */
        if (*p == '\0')
          luaL_error(ms->L, "malformed pattern (missing " LUA_QL("]") ")");
        if (*(p++) == L_ESC && *p != '\0')
          p++;  /* skip escapes (e.g. `%]') */
      } while (*p != ']');
      return p+1;
    }
    default: {
      return p;
    }
  }
}


static int match_class (int c, int cl) {
  int res;
  switch (tolower(cl)) {
    case 'a' : res = isalpha(c); break;
    case 'c' : res = iscntrl(c); break;
    case 'd' : res = isdigit(c); break;
    case 'l' : res = islower(c); break;
    case 'p' : res = ispunct(c); break;
    case 's' : res = isspace(c); break;
    case 'u' : res = isupper(c); break;
    case 'w' : res = isalnum(c); break;
    case 'x' : res = isxdigit(c); break;
    case 'z' : res = (c == 0); break;
    default: return (cl == c);
  }
  return (islower(cl) ? res : !res);
}


static int matchbracketclass (int c, const char *p, const char *ec) {
  int sig = 1;
  if (*(p+1) == '^') {
    sig = 0;
    p++;  /* skip the `^' */
  }
  while (++p < ec) {
    if (*p == L_ESC) {
      p++;
      if (match_class(c, uchar(*p)))
        return sig;
    }
    else if ((*(p+1) == '-') && (p+2 < ec)) {
      p+=2;
      if (uchar(*(p-2)) <= c && c <= uchar(*p))
        return sig;
    }
    else if (uchar(*p) == c) return sig;
  }
  return !sig;
}


static int singlematch (int c, const char *p, const char *ep) {
  switch (*p) {
    case '.': return 1;  /* matches any char */
    case L_ESC: return match_class(c, uchar(*(p+1)));
    case '[': return matchbracketclass(c, p, ep-1);
    default:  return (uchar(*p) == c);
  }
}


static const char *match (MatchState *ms, const char *s, const char *p);


static const char *matchbalance (MatchState *ms, const char *s,
                                   const char *p) {
  if (*p == 0 || *(p+1) == 0)
    luaL_error(ms->L, "unbalanced pattern");
  if (*s != *p) return NULL;
  else {
    int b = *p;
    int e = *(p+1);
    int cont = 1;
    while (++s < ms->src_end) {
      if (*s == e) {
        if (--cont == 0) return s+1;
      }
      else if (*s == b) cont++;
    }
  }
  return NULL;  /* string ends out of balance */
}


static const char *max_expand (MatchState *ms, const char *s,
                                 const char *p, const char *ep) {
  ptrdiff_t i = 0;  /* counts maximum expand for item */
  while ((s+i)<ms->src_end && singlematch(uchar(*(s+i)), p, ep))
    i++;
  /* keeps trying to match with the maximum repetitions */
  while (i>=0) {
    const char *res = match(ms, (s+i), ep+1);
    if (res) return res;
    i--;  /* else didn't match; reduce 1 repetition to try again */
  }
  return NULL;
}


static const char *min_expand (MatchState *ms, const char *s,
                                 const char *p, const char *ep) {
  for (;;) {
    const char *res = match(ms, s, ep+1);
    if (res != NULL)
      return res;
    else if (s<ms->src_end && singlematch(uchar(*s), p, ep))
      s++;  /* try with one more repetition */
    else return NULL;
  }
}


static const char *start_capture (MatchState *ms, const char *s,
                                    const char *p, int what) {
  const char *res;
  int level = ms->level;
  if (level >= LUA_MAXCAPTURES) luaL_error(ms->L, "too many captures");
  ms->capture[level].init = s;
  ms->capture[level].len = what;
  ms->level = level+1;
  if ((res=match(ms, s, p)) == NULL)  /* match failed? */
    ms->level--;  /* undo capture */
  return res;
}


static const char *end_capture (MatchState *ms, const char *s,
                                  const char *p) {
  int l = capture_to_close(ms);
  const char *res;
  ms->capture[l].len = s - ms->capture[l].init;  /* close capture */
  if ((res = match(ms, s, p)) == NULL)  /* match failed? */
    ms->capture[l].len = CAP_UNFINISHED;  /* undo capture */
  return res;
}


static const char *match_capture (MatchState *ms, const char *s, int l) {
  size_t len;
  l = check_capture(ms, l);
  len = ms->capture[l].len;
  if ((size_t)(ms->src_end-s) >= len &&
      memcmp(ms->capture[l].init, s, len) == 0)
    return s+len;
  else return NULL;
}


static const char *match (MatchState *ms, const char *s, const char *p) {
  init: /* using goto's to optimize tail recursion */
  switch (*p) {
    case '(': {  /* start capture */
      if (*(p+1) == ')')  /* position capture? */
        return start_capture(ms, s, p+2, CAP_POSITION);
      else
        return start_capture(ms, s, p+1, CAP_UNFINISHED);
    }
    case ')': {  /* end capture */
      return end_capture(ms, s, p+1);
    }
    case L_ESC: {
      switch (*(p+1)) {
        case 'b': {  /* balanced string? */
          s = matchbalance(ms, s, p+2);
          if (s == NULL) return NULL;
          p+=4; goto init;  /* else return match(ms, s, p+4); */
        }
        case 'f': {  /* frontier? */
          const char *ep; char previous;
          p += 2;
          if (*p != '[')
            luaL_error(ms->L, "missing " LUA_QL("[") " after "
                               LUA_QL("%%f") " in pattern");
          ep = classend(ms, p);  /* points to what is next */
          previous = (s == ms->src_init) ? '\0' : *(s-1);
          if (matchbracketclass(uchar(previous), p, ep-1) ||
             !matchbracketclass(uchar(*s), p, ep-1)) return NULL;
          p=ep; goto init;  /* else return match(ms, s, ep); */
        }
        default: {
          if (isdigit(uchar(*(p+1)))) {  /* capture results (%0-%9)? */
            s = match_capture(ms, s, uchar(*(p+1)));
            if (s == NULL) return NULL;
            p+=2; goto init;  /* else return match(ms, s, p+2) */
          }
          goto dflt;  /* case default */
        }
      }
    }
    case '\0': {  /* end of pattern */
      return s;  /* match succeeded */
    }
    case '$': {
      if (*(p+1) == '\0')  /* is the `$' the last char in pattern? */
        return (s == ms->src_end) ? s : NULL;  /* check end of string */
      else goto dflt;
    }
    default: dflt: {  /* it is a pattern item */
      const char *ep = classend(ms, p);  /* points to what is next */
      int m = s<ms->src_end && singlematch(uchar(*s), p, ep);
      switch (*ep) {
        case '?': {  /* optional */
          const char *res;
          if (m && ((res=match(ms, s+1, ep+1)) != NULL))
            return res;
          p=ep+1; goto init;  /* else return match(ms, s, ep+1); */
        }
        case '*': {  /* 0 or more repetitions */
          return max_expand(ms, s, p, ep);
        }
        case '+': {  /* 1 or more repetitions */
          return (m ? max_expand(ms, s+1, p, ep) : NULL);
        }
        case '-': {  /* 0 or more repetitions (minimum) */
          return min_expand(ms, s, p, ep);
        }
        default: {
          if (!m) return NULL;
          s++; p=ep; goto init;  /* else return match(ms, s+1, ep); */
        }
      }
    }
  }
}



static const char *lmemfind (const char *s1, size_t l1,
                               const char *s2, size_t l2) {
  if (l2 == 0) return s1;  /* empty strings are everywhere */
  else if (l2 > l1) return NULL;  /* avoids a negative `l1' */
  else {
    const char *init;  /* to search for a `*s2' inside `s1' */
    l2--;  /* 1st char will be checked by `memchr' */
    l1 = l1-l2;  /* `s2' cannot be found after that */
    while (l1 > 0 && (init = (const char *)memchr(s1, *s2, l1)) != NULL) {
      init++;   /* 1st char is already checked */
      if (memcmp(init, s2+1, l2) == 0)
        return init-1;
      else {  /* correct `l1' and `s1' to try again */
        l1 -= init-s1;
        s1 = init;
      }
    }
    return NULL;  /* not found */
  }
}


static void push_onecapture (MatchState *ms, int i, const char *s,
                                                    const char *e) {
  if (i >= ms->level) {
    if (i == 0)  /* ms->level == 0, too */
      lua_pushlstring(ms->L, s, e - s);  /* add whole match */
    else
      luaL_error(ms->L, "invalid capture index");
  }
  else {
    ptrdiff_t l = ms->capture[i].len;
    if (l == CAP_UNFINISHED) luaL_error(ms->L, "unfinished capture");
    if (l == CAP_POSITION)
      lua_pushinteger(ms->L, ms->capture[i].init - ms->src_init + 1);
    else
      lua_pushlstring(ms->L, ms->capture[i].init, l);
  }
}


static int push_captures (MatchState *ms, const char *s, const char *e) {
  int i;
  int nlevels = (ms->level == 0 && s) ? 1 : ms->level;
  luaL_checkstack(ms->L, nlevels, "too many captures");
  for (i = 0; i < nlevels; i++)
    push_onecapture(ms, i, s, e);
  return nlevels;  /* number of strings pushed */
}


static int str_find_aux (lua_State *L, int find) {
  size_t l1, l2;
  const char *s = luaL_checklstring(L, 1, &l1);
  const char *p = luaL_checklstring(L, 2, &l2);
  ptrdiff_t init = posrelat(luaL_optinteger(L, 3, 1), l1) - 1;
  if (init < 0) init = 0;
  else if ((size_t)(init) > l1) init = (ptrdiff_t)l1;
  if (find && (lua_toboolean(L, 4) ||  /* explicit request? */
      strpbrk(p, SPECIALS) == NULL)) {  /* or no special characters? */
    /* do a plain search */
    const char *s2 = lmemfind(s+init, l1-init, p, l2);
    if (s2) {
      lua_pushinteger(L, s2-s+1);
      lua_pushinteger(L, s2-s+l2);
      return 2;
    }
  }
  else {
    MatchState ms;
    int anchor = (*p == '^') ? (p++, 1) : 0;
    const char *s1=s+init;
    ms.L = L;
    ms.src_init = s;
    ms.src_end = s+l1;
    do {
      const char *res;
      ms.level = 0;
      if ((res=match(&ms, s1, p)) != NULL) {
        if (find) {
          lua_pushinteger(L, s1-s+1);  /* start */
          lua_pushinteger(L, res-s);   /* end */
          return push_captures(&ms, NULL, 0) + 2;
        }
        else
          return push_captures(&ms, s1, res);
      }
    } while (s1++ < ms.src_end && !anchor);
  }
  lua_pushnil(L);  /* not found */
  return 1;
}


static int str_find (lua_State *L) {
  return str_find_aux(L, 1);
}


static int str_match (lua_State *L) {
  return str_find_aux(L, 0);
}


static int gmatch_aux (lua_State *L) {
  MatchState ms;
  size_t ls;
  const char *s = lua_tolstring(L, lua_upvalueindex(1), &ls);
  const char *p = lua_tostring(L, lua_upvalueindex(2));
  const char *src;
  ms.L = L;
  ms.src_init = s;
  ms.src_end = s+ls;
  for (src = s + (size_t)lua_tointeger(L, lua_upvalueindex(3));
       src <= ms.src_end;
       src++) {
    const char *e;
    ms.level = 0;
    if ((e = match(&ms, src, p)) != NULL) {
      lua_Integer newstart = e-s;
      if (e == src) newstart++;  /* empty match? go at least one position */
      lua_pushinteger(L, newstart);
      lua_replace(L, lua_upvalueindex(3));
      return push_captures(&ms, src, e);
    }
  }
  return 0;  /* not found */
}


static int gmatch (lua_State *L) {
  luaL_checkstring(L, 1);
  luaL_checkstring(L, 2);
  lua_settop(L, 2);
  lua_pushinteger(L, 0);
  lua_pushcclosure(L, gmatch_aux, 3);
  return 1;
}


static int gfind_nodef (lua_State *L) {
  return luaL_error(L, LUA_QL("string.gfind") " was renamed to "
                       LUA_QL("string.gmatch"));
}


static void add_s (MatchState *ms, luaL_Buffer *b, const char *s,
                                                   const char *e) {
  size_t l, i;
  const char *news = lua_tolstring(ms->L, 3, &l);
  for (i = 0; i < l; i++) {
    if (news[i] != L_ESC)
      luaL_addchar(b, news[i]);
    else {
      i++;  /* skip ESC */
      if (!isdigit(uchar(news[i])))
        luaL_addchar(b, news[i]);
      else if (news[i] == '0')
          luaL_addlstring(b, s, e - s);
      else {
        push_onecapture(ms, news[i] - '1', s, e);
        luaL_addvalue(b);  /* add capture to accumulated result */
      }
    }
  }
}


static void add_value (MatchState *ms, luaL_Buffer *b, const char *s,
                                                       const char *e) {
  lua_State *L = ms->L;
  switch (lua_type(L, 3)) {
    case LUA_TNUMBER:
    case LUA_TSTRING: {
      add_s(ms, b, s, e);
      return;
    }
    case LUA_TFUNCTION: {
      int n;
      lua_pushvalue(L, 3);
      n = push_captures(ms, s, e);
      lua_call(L, n, 1);
      break;
    }
    case LUA_TTABLE: {
      push_onecapture(ms, 0, s, e);
      lua_gettable(L, 3);
      break;
    }
    default: {
      luaL_argerror(L, 3, "string/function/table expected");
      return;
    }
  }
  if (!lua_toboolean(L, -1)) {  /* nil or false? */
    lua_pop(L, 1);
    lua_pushlstring(L, s, e - s);  /* keep original text */
  }
  else if (!lua_isstring(L, -1))
    luaL_error(L, "invalid replacement value (a %s)", luaL_typename(L, -1));
  luaL_addvalue(b);  /* add result to accumulator */
}


static int str_gsub (lua_State *L) {
  size_t srcl;
  const char *src = luaL_checklstring(L, 1, &srcl);
  const char *p = luaL_checkstring(L, 2);
  int max_s = luaL_optint(L, 4, srcl+1);
  int anchor = (*p == '^') ? (p++, 1) : 0;
  int n = 0;
  MatchState ms;
  luaL_Buffer b;
  luaL_buffinit(L, &b);
  ms.L = L;
  ms.src_init = src;
  ms.src_end = src+srcl;
  while (n < max_s) {
    const char *e;
    ms.level = 0;
    e = match(&ms, src, p);
    if (e) {
      n++;
      add_value(&ms, &b, src, e);
    }
    if (e && e>src) /* non empty match? */
      src = e;  /* skip it */
    else if (src < ms.src_end)
      luaL_addchar(&b, *src++);
    else break;
    if (anchor) break;
  }
  luaL_addlstring(&b, src, ms.src_end-src);
  luaL_pushresult(&b);
  lua_pushinteger(L, n);  /* number of substitutions */
  return 2;
}

/* }====================================================== */


/* maximum size of each formatted item (> len(format('%99.99f', -1e308))) */
#define MAX_ITEM    512
/* valid flags in a format specification */
#define FLAGS   "-+ #0"
/*
** maximum size of each format specification (such as '%-099.99d')
** (+10 accounts for %99.99x plus margin of error)
*/
#define MAX_FORMAT  (sizeof(FLAGS) + sizeof(LUA_INTFRMLEN) + 10)


static void addquoted (lua_State *L, luaL_Buffer *b, int arg) {
  size_t l;
  const char *s = luaL_checklstring(L, arg, &l);
  luaL_addchar(b, '"');
  while (l--) {
    switch (*s) {
      case '"': case '\\': case '\n': {
        luaL_addchar(b, '\\');
        luaL_addchar(b, *s);
        break;
      }
      case '\r': {
        luaL_addlstring(b, "\\r", 2);
        break;
      }
      case '\0': {
        luaL_addlstring(b, "\\000", 4);
        break;
      }
      default: {
        luaL_addchar(b, *s);
        break;
      }
    }
    s++;
  }
  luaL_addchar(b, '"');
}

static const char *scanformat (lua_State *L, const char *strfrmt, char *form) {
  const char *p = strfrmt;
  while (*p != '\0' && strchr(FLAGS, *p) != NULL) p++;  /* skip flags */
  if ((size_t)(p - strfrmt) >= sizeof(FLAGS))
    luaL_error(L, "invalid format (repeated flags)");
  if (isdigit(uchar(*p))) p++;  /* skip width */
  if (isdigit(uchar(*p))) p++;  /* (2 digits at most) */
  if (*p == '.') {
    p++;
    if (isdigit(uchar(*p))) p++;  /* skip precision */
    if (isdigit(uchar(*p))) p++;  /* (2 digits at most) */
  }
  if (isdigit(uchar(*p)))
    luaL_error(L, "invalid format (width or precision too long)");
  *(form++) = '%';
  strncpy(form, strfrmt, p - strfrmt + 1);
  form += p - strfrmt + 1;
  *form = '\0';
  return p;
}


static void addintlen (char *form) {
  size_t l = strlen(form);
  char spec = form[l - 1];
  strcpy(form + l - 1, LUA_INTFRMLEN);
  form[l + sizeof(LUA_INTFRMLEN) - 2] = spec;
  form[l + sizeof(LUA_INTFRMLEN) - 1] = '\0';
}


static int str_format (lua_State *L) {
  int arg = 1;
  size_t sfl;
  const char *strfrmt = luaL_checklstring(L, arg, &sfl);
  const char *strfrmt_end = strfrmt+sfl;
  luaL_Buffer b;
  luaL_buffinit(L, &b);
  while (strfrmt < strfrmt_end) {
    if (*strfrmt != L_ESC)
      luaL_addchar(&b, *strfrmt++);
    else if (*++strfrmt == L_ESC)
      luaL_addchar(&b, *strfrmt++);  /* %% */
    else { /* format item */
      char form[MAX_FORMAT];  /* to store the format (`%...') */
      char buff[MAX_ITEM];  /* to store the formatted item */
      arg++;
      strfrmt = scanformat(L, strfrmt, form);
      switch (*strfrmt++) {
        case 'c': {
          sprintf(buff, form, (int)luaL_checknumber(L, arg));
          break;
        }
        case 'd':  case 'i': {
          addintlen(form);
          sprintf(buff, form, (LUA_INTFRM_T)luaL_checknumber(L, arg));
          break;
        }
        case 'o':  case 'u':  case 'x':  case 'X': {
          addintlen(form);
          sprintf(buff, form, (unsigned LUA_INTFRM_T)luaL_checknumber(L, arg));
          break;
        }
        case 'e':  case 'E': case 'f':
        case 'g': case 'G': {
          sprintf(buff, form, (double)luaL_checknumber(L, arg));
          break;
        }
        case 'q': {
          addquoted(L, &b, arg);
          continue;  /* skip the 'addsize' at the end */
        }
        case 's': {
          size_t l;
          const char *s = luaL_checklstring(L, arg, &l);
          if (!strchr(form, '.') && l >= 100) {
            /* no precision and string is too long to be formatted;
               keep original string */
            lua_pushvalue(L, arg);
            luaL_addvalue(&b);
            continue;  /* skip the `addsize' at the end */
          }
          else {
            sprintf(buff, form, s);
            break;
          }
        }
        default: {  /* also treat cases `pnLlh' */
          return luaL_error(L, "invalid option " LUA_QL("%%%c") " to "
                               LUA_QL("format"), *(strfrmt - 1));
        }
      }
      luaL_addlstring(&b, buff, strlen(buff));
    }
  }
  luaL_pushresult(&b);
  return 1;
}


static const luaL_Reg strlib[] = {
  {"byte", str_byte},
  {"char", str_char},
  {"dump", str_dump},
  {"find", str_find},
  {"format", str_format},
  {"gfind", gfind_nodef},
  {"gmatch", gmatch},
  {"gsub", str_gsub},
  {"len", str_len},
  {"lower", str_lower},
  {"match", str_match},
  {"rep", str_rep},
  {"reverse", str_reverse},
  {"sub", str_sub},
  {"upper", str_upper},
  {NULL, NULL}
};


static void createmetatable (lua_State *L) {
  lua_createtable(L, 0, 1);  /* create metatable for strings */
  lua_pushliteral(L, "");  /* dummy string */
  lua_pushvalue(L, -2);
  lua_setmetatable(L, -2);  /* set string metatable */
  lua_pop(L, 1);  /* pop dummy string */
  lua_pushvalue(L, -2);  /* string library... */
  lua_setfield(L, -2, "__index");  /* ...is the __index metamethod */
  lua_pop(L, 1);  /* pop metatable */
}


/*
** Open string library
*/
LUALIB_API int luaopen_string (lua_State *L) {
  luaL_register(L, LUA_STRLIBNAME, strlib);
#if defined(LUA_COMPAT_GFIND)
  lua_getfield(L, -1, "gmatch");
  lua_setfield(L, -2, "gfind");
#endif
  createmetatable(L);
  return 1;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ltable.c ===
/*
** $Id: ltable.c,v 2.32 2006/01/18 11:49:02 roberto Exp $
** Lua tables (hash)
** See Copyright Notice in lua.h
*/


/*
** Implementation of tables (aka arrays, objects, or hash tables).
** Tables keep its elements in two parts: an array part and a hash part.
** Non-negative integer keys are all candidates to be kept in the array
** part. The actual size of the array is the largest `n' such that at
** least half the slots between 0 and n are in use.
** Hash uses a mix of chained scatter table with Brent's variation.
** A main invariant of these tables is that, if an element is not
** in its main position (i.e. the `original' position that its hash gives
** to it), then the colliding element is in its own main position.
** Hence even when the load factor reaches 100%, performance remains good.
*/

#include <math.h>
#include <string.h>

#define ltable_c
#define LUA_CORE

#include "lua.h"

#include "ldebug.h"
#include "ldo.h"
#include "lgc.h"
#include "lmem.h"
#include "lobject.h"
#include "lstate.h"
#include "ltable.h"


/*
** max size of array part is 2^MAXBITS
*/
#if LUAI_BITSINT > 26
#define MAXBITS		26
#else
#define MAXBITS		(LUAI_BITSINT-2)
#endif

#define MAXASIZE	(1 << MAXBITS)


#define hashpow2(t,n)      (gnode(t, lmod((n), sizenode(t))))
  
#define hashstr(t,str)  hashpow2(t, (str)->tsv.hash)
#define hashboolean(t,p)        hashpow2(t, p)


/*
** for some types, it is better to avoid modulus by power of 2, as
** they tend to have many 2 factors.
*/
#define hashmod(t,n)	(gnode(t, ((n) % ((sizenode(t)-1)|1))))


#define hashpointer(t,p)	hashmod(t, IntPoint(p))


/*
** number of ints inside a lua_Number
*/
#define numints		cast_int(sizeof(lua_Number)/sizeof(int))



#define dummynode		(&dummynode_)

static const Node dummynode_ = {
  {{NULL}, LUA_TNIL},  /* value */
  {{{NULL}, LUA_TNIL, NULL}}  /* key */
};


/*
** hash for lua_Numbers
*/
static Node *hashnum (const Table *t, lua_Number n) {
  unsigned int a[numints];
  int i;
  n += 1;  /* normalize number (avoid -0) */
  lua_assert(sizeof(a) <= sizeof(n));
  memcpy(a, &n, sizeof(a));
  for (i = 1; i < numints; i++) a[0] += a[i];
  return hashmod(t, a[0]);
}



/*
** returns the `main' position of an element in a table (that is, the index
** of its hash value)
*/
static Node *mainposition (const Table *t, const TValue *key) {
  switch (ttype(key)) {
    case LUA_TNUMBER:
      return hashnum(t, nvalue(key));
    case LUA_TSTRING:
      return hashstr(t, rawtsvalue(key));
    case LUA_TBOOLEAN:
      return hashboolean(t, bvalue(key));
    case LUA_TLIGHTUSERDATA:
      return hashpointer(t, pvalue(key));
    default:
      return hashpointer(t, gcvalue(key));
  }
}


/*
** returns the index for `key' if `key' is an appropriate key to live in
** the array part of the table, -1 otherwise.
*/
static int arrayindex (const TValue *key) {
  if (ttisnumber(key)) {
    lua_Number n = nvalue(key);
    int k;
    lua_number2int(k, n);
    if (luai_numeq(cast_num(k), n))
      return k;
  }
  return -1;  /* `key' did not match some condition */
}


/*
** returns the index of a `key' for table traversals. First goes all
** elements in the array part, then elements in the hash part. The
** beginning of a traversal is signalled by -1.
*/
static int findindex (lua_State *L, Table *t, StkId key) {
  int i;
  if (ttisnil(key)) return -1;  /* first iteration */
  i = arrayindex(key);
  if (0 < i && i <= t->sizearray)  /* is `key' inside array part? */
    return i-1;  /* yes; that's the index (corrected to C) */
  else {
    Node *n = mainposition(t, key);
    do {  /* check whether `key' is somewhere in the chain */
      /* key may be dead already, but it is ok to use it in `next' */
      if (luaO_rawequalObj(key2tval(n), key) ||
            (ttype(gkey(n)) == LUA_TDEADKEY && iscollectable(key) &&
             gcvalue(gkey(n)) == gcvalue(key))) {
        i = cast_int(n - gnode(t, 0));  /* key index in hash table */
        /* hash elements are numbered after array ones */
        return i + t->sizearray;
      }
      else n = gnext(n);
    } while (n);
    luaG_runerror(L, "invalid key to " LUA_QL("next"));  /* key not found */
    return 0;  /* to avoid warnings */
  }
}


int luaH_next (lua_State *L, Table *t, StkId key) {
  int i = findindex(L, t, key);  /* find original element */
  for (i++; i < t->sizearray; i++) {  /* try first array part */
    if (!ttisnil(&t->array[i])) {  /* a non-nil value? */
      setnvalue(key, cast_num(i+1));
      setobj2s(L, key+1, &t->array[i]);
      return 1;
    }
  }
  for (i -= t->sizearray; i < sizenode(t); i++) {  /* then hash part */
    if (!ttisnil(gval(gnode(t, i)))) {  /* a non-nil value? */
      setobj2s(L, key, key2tval(gnode(t, i)));
      setobj2s(L, key+1, gval(gnode(t, i)));
      return 1;
    }
  }
  return 0;  /* no more elements */
}


/*
** {=============================================================
** Rehash
** ==============================================================
*/


static int computesizes (int nums[], int *narray) {
  int i;
  int twotoi;  /* 2^i */
  int a = 0;  /* number of elements smaller than 2^i */
  int na = 0;  /* number of elements to go to array part */
  int n = 0;  /* optimal size for array part */
  for (i = 0, twotoi = 1; twotoi/2 < *narray; i++, twotoi *= 2) {
    if (nums[i] > 0) {
      a += nums[i];
      if (a > twotoi/2) {  /* more than half elements present? */
        n = twotoi;  /* optimal size (till now) */
        na = a;  /* all elements smaller than n will go to array part */
      }
    }
    if (a == *narray) break;  /* all elements already counted */
  }
  *narray = n;
  lua_assert(*narray/2 <= na && na <= *narray);
  return na;
}


static int countint (const TValue *key, int *nums) {
  int k = arrayindex(key);
  if (0 < k && k <= MAXASIZE) {  /* is `key' an appropriate array index? */
    nums[ceillog2(k)]++;  /* count as such */
    return 1;
  }
  else
    return 0;
}


static int numusearray (const Table *t, int *nums) {
  int lg;
  int ttlg;  /* 2^lg */
  int ause = 0;  /* summation of `nums' */
  int i = 1;  /* count to traverse all array keys */
  for (lg=0, ttlg=1; lg<=MAXBITS; lg++, ttlg*=2) {  /* for each slice */
    int lc = 0;  /* counter */
    int lim = ttlg;
    if (lim > t->sizearray) {
      lim = t->sizearray;  /* adjust upper limit */
      if (i > lim)
        break;  /* no more elements to count */
    }
    /* count elements in range (2^(lg-1), 2^lg] */
    for (; i <= lim; i++) {
      if (!ttisnil(&t->array[i-1]))
        lc++;
    }
    nums[lg] += lc;
    ause += lc;
  }
  return ause;
}


static int numusehash (const Table *t, int *nums, int *pnasize) {
  int totaluse = 0;  /* total number of elements */
  int ause = 0;  /* summation of `nums' */
  int i = sizenode(t);
  while (i--) {
    Node *n = &t->node[i];
    if (!ttisnil(gval(n))) {
      ause += countint(key2tval(n), nums);
      totaluse++;
    }
  }
  *pnasize += ause;
  return totaluse;
}


static void setarrayvector (lua_State *L, Table *t, int size) {
  int i;
  luaM_reallocvector(L, t->array, t->sizearray, size, TValue);
  for (i=t->sizearray; i<size; i++)
     setnilvalue(&t->array[i]);
  t->sizearray = size;
}


static void setnodevector (lua_State *L, Table *t, int size) {
  int lsize;
  if (size == 0) {  /* no elements to hash part? */
    t->node = cast(Node *, dummynode);  /* use common `dummynode' */
    lsize = 0;
  }
  else {
    int i;
    lsize = ceillog2(size);
    if (lsize > MAXBITS)
      luaG_runerror(L, "table overflow");
    size = twoto(lsize);
    t->node = luaM_newvector(L, size, Node);
    for (i=0; i<size; i++) {
      Node *n = gnode(t, i);
      gnext(n) = NULL;
      setnilvalue(gkey(n));
      setnilvalue(gval(n));
    }
  }
  t->lsizenode = cast_byte(lsize);
  t->lastfree = gnode(t, size);  /* all positions are free */
}


static void resize (lua_State *L, Table *t, int nasize, int nhsize) {
  int i;
  int oldasize = t->sizearray;
  int oldhsize = t->lsizenode;
  Node *nold = t->node;  /* save old hash ... */
  if (nasize > oldasize)  /* array part must grow? */
    setarrayvector(L, t, nasize);
  /* create new hash part with appropriate size */
  setnodevector(L, t, nhsize);  
  if (nasize < oldasize) {  /* array part must shrink? */
    t->sizearray = nasize;
    /* re-insert elements from vanishing slice */
    for (i=nasize; i<oldasize; i++) {
      if (!ttisnil(&t->array[i]))
        setobjt2t(L, luaH_setnum(L, t, i+1), &t->array[i]);
    }
    /* shrink array */
    luaM_reallocvector(L, t->array, oldasize, nasize, TValue);
  }
  /* re-insert elements from hash part */
  for (i = twoto(oldhsize) - 1; i >= 0; i--) {
    Node *old = nold+i;
    if (!ttisnil(gval(old)))
      setobjt2t(L, luaH_set(L, t, key2tval(old)), gval(old));
  }
  if (nold != dummynode)
    luaM_freearray(L, nold, twoto(oldhsize), Node);  /* free old array */
}


void luaH_resizearray (lua_State *L, Table *t, int nasize) {
  int nsize = (t->node == dummynode) ? 0 : sizenode(t);
  resize(L, t, nasize, nsize);
}


static void rehash (lua_State *L, Table *t, const TValue *ek) {
  int nasize, na;
  int nums[MAXBITS+1];  /* nums[i] = number of keys between 2^(i-1) and 2^i */
  int i;
  int totaluse;
  for (i=0; i<=MAXBITS; i++) nums[i] = 0;  /* reset counts */
  nasize = numusearray(t, nums);  /* count keys in array part */
  totaluse = nasize;  /* all those keys are integer keys */
  totaluse += numusehash(t, nums, &nasize);  /* count keys in hash part */
  /* count extra key */
  nasize += countint(ek, nums);
  totaluse++;
  /* compute new size for array part */
  na = computesizes(nums, &nasize);
  /* resize the table to new computed sizes */
  resize(L, t, nasize, totaluse - na);
}



/*
** }=============================================================
*/


Table *luaH_new (lua_State *L, int narray, int nhash) {
  Table *t = luaM_new(L, Table);
  luaC_link(L, obj2gco(t), LUA_TTABLE);
  t->metatable = NULL;
  t->flags = cast_byte(~0);
  /* temporary values (kept only if some malloc fails) */
  t->array = NULL;
  t->sizearray = 0;
  t->lsizenode = 0;
  t->node = cast(Node *, dummynode);
  setarrayvector(L, t, narray);
  setnodevector(L, t, nhash);
  return t;
}


void luaH_free (lua_State *L, Table *t) {
  if (t->node != dummynode)
    luaM_freearray(L, t->node, sizenode(t), Node);
  luaM_freearray(L, t->array, t->sizearray, TValue);
  luaM_free(L, t);
}


static Node *getfreepos (Table *t) {
  while (t->lastfree-- > t->node) {
    if (ttisnil(gkey(t->lastfree)))
      return t->lastfree;
  }
  return NULL;  /* could not find a free place */
}



/*
** inserts a new key into a hash table; first, check whether key's main 
** position is free. If not, check whether colliding node is in its main 
** position or not: if it is not, move colliding node to an empty place and 
** put new key in its main position; otherwise (colliding node is in its main 
** position), new key goes to an empty position. 
*/
static TValue *newkey (lua_State *L, Table *t, const TValue *key) {
  Node *mp = mainposition(t, key);
  if (!ttisnil(gval(mp)) || mp == dummynode) {
    Node *othern;
    Node *n = getfreepos(t);  /* get a free place */
    if (n == NULL) {  /* cannot find a free place? */
      rehash(L, t, key);  /* grow table */
      return luaH_set(L, t, key);  /* re-insert key into grown table */
    }
    lua_assert(n != dummynode);
    othern = mainposition(t, key2tval(mp));
    if (othern != mp) {  /* is colliding node out of its main position? */
      /* yes; move colliding node into free position */
      while (gnext(othern) != mp) othern = gnext(othern);  /* find previous */
      gnext(othern) = n;  /* redo the chain with `n' in place of `mp' */
      *n = *mp;  /* copy colliding node into free pos. (mp->next also goes) */
      gnext(mp) = NULL;  /* now `mp' is free */
      setnilvalue(gval(mp));
    }
    else {  /* colliding node is in its own main position */
      /* new node will go into free position */
      gnext(n) = gnext(mp);  /* chain new position */
      gnext(mp) = n;
      mp = n;
    }
  }
  gkey(mp)->value = key->value; gkey(mp)->tt = key->tt;
  luaC_barriert(L, t, key);
  lua_assert(ttisnil(gval(mp)));
  return gval(mp);
}


/*
** search function for integers
*/
const TValue *luaH_getnum (Table *t, int key) {
  /* (1 <= key && key <= t->sizearray) */
  if (cast(unsigned int, key-1) < cast(unsigned int, t->sizearray))
    return &t->array[key-1];
  else {
    lua_Number nk = cast_num(key);
    Node *n = hashnum(t, nk);
    do {  /* check whether `key' is somewhere in the chain */
      if (ttisnumber(gkey(n)) && luai_numeq(nvalue(gkey(n)), nk))
        return gval(n);  /* that's it */
      else n = gnext(n);
    } while (n);
    return luaO_nilobject;
  }
}


/*
** search function for strings
*/
const TValue *luaH_getstr (Table *t, TString *key) {
  Node *n = hashstr(t, key);
  do {  /* check whether `key' is somewhere in the chain */
    if (ttisstring(gkey(n)) && rawtsvalue(gkey(n)) == key)
      return gval(n);  /* that's it */
    else n = gnext(n);
  } while (n);
  return luaO_nilobject;
}


/*
** main search function
*/
const TValue *luaH_get (Table *t, const TValue *key) {
  switch (ttype(key)) {
    case LUA_TNIL: return luaO_nilobject;
    case LUA_TSTRING: return luaH_getstr(t, rawtsvalue(key));
    case LUA_TNUMBER: {
      int k;
      lua_Number n = nvalue(key);
      lua_number2int(k, n);
      if (luai_numeq(cast_num(k), nvalue(key))) /* index is int? */
        return luaH_getnum(t, k);  /* use specialized version */
      /* else go through */
    }
    default: {
      Node *n = mainposition(t, key);
      do {  /* check whether `key' is somewhere in the chain */
        if (luaO_rawequalObj(key2tval(n), key))
          return gval(n);  /* that's it */
        else n = gnext(n);
      } while (n);
      return luaO_nilobject;
    }
  }
}


TValue *luaH_set (lua_State *L, Table *t, const TValue *key) {
  const TValue *p = luaH_get(t, key);
  t->flags = 0;
  if (p != luaO_nilobject)
    return cast(TValue *, p);
  else {
    if (ttisnil(key)) luaG_runerror(L, "table index is nil");
    else if (ttisnumber(key) && luai_numisnan(nvalue(key)))
      luaG_runerror(L, "table index is NaN");
    return newkey(L, t, key);
  }
}


TValue *luaH_setnum (lua_State *L, Table *t, int key) {
  const TValue *p = luaH_getnum(t, key);
  if (p != luaO_nilobject)
    return cast(TValue *, p);
  else {
    TValue k;
    setnvalue(&k, cast_num(key));
    return newkey(L, t, &k);
  }
}


TValue *luaH_setstr (lua_State *L, Table *t, TString *key) {
  const TValue *p = luaH_getstr(t, key);
  if (p != luaO_nilobject)
    return cast(TValue *, p);
  else {
    TValue k;
    setsvalue(L, &k, key);
    return newkey(L, t, &k);
  }
}


static int unbound_search (Table *t, unsigned int j) {
  unsigned int i = j;  /* i is zero or a present index */
  j++;
  /* find `i' and `j' such that i is present and j is not */
  while (!ttisnil(luaH_getnum(t, j))) {
    i = j;
    j *= 2;
    if (j > cast(unsigned int, MAX_INT)) {  /* overflow? */
      /* table was built with bad purposes: resort to linear search */
      i = 1;
      while (!ttisnil(luaH_getnum(t, i))) i++;
      return i - 1;
    }
  }
  /* now do a binary search between them */
  while (j - i > 1) {
    unsigned int m = (i+j)/2;
    if (ttisnil(luaH_getnum(t, m))) j = m;
    else i = m;
  }
  return i;
}


/*
** Try to find a boundary in table `t'. A `boundary' is an integer index
** such that t[i] is non-nil and t[i+1] is nil (and 0 if t[1] is nil).
*/
int luaH_getn (Table *t) {
  unsigned int j = t->sizearray;
  if (j > 0 && ttisnil(&t->array[j - 1])) {
    /* there is a boundary in the array part: (binary) search for it */
    unsigned int i = 0;
    while (j - i > 1) {
      unsigned int m = (i+j)/2;
      if (ttisnil(&t->array[m - 1])) j = m;
      else i = m;
    }
    return i;
  }
  /* else must find a boundary in hash part */
  else if (t->node == dummynode)  /* hash part is empty? */
    return j;  /* that is easy... */
  else return unbound_search(t, j);
}



#if defined(LUA_DEBUG)

Node *luaH_mainposition (const Table *t, const TValue *key) {
  return mainposition(t, key);
}

int luaH_isdummy (Node *n) { return n == dummynode; }

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ltm.h ===
/*
** $Id: ltm.h,v 2.6 2005/06/06 13:30:25 roberto Exp $
** Tag methods
** See Copyright Notice in lua.h
*/

#ifndef ltm_h
#define ltm_h


#include "lobject.h"


/*
* WARNING: if you change the order of this enumeration,
* grep "ORDER TM"
*/
typedef enum {
  TM_INDEX,
  TM_NEWINDEX,
  TM_GC,
  TM_MODE,
  TM_EQ,  /* last tag method with `fast' access */
  TM_ADD,
  TM_SUB,
  TM_MUL,
  TM_DIV,
  TM_MOD,
  TM_POW,
  TM_UNM,
  TM_LEN,
  TM_LT,
  TM_LE,
  TM_CONCAT,
  TM_CALL,
  TM_N		/* number of elements in the enum */
} TMS;



#define gfasttm(g,et,e) ((et) == NULL ? NULL : \
  ((et)->flags & (1u<<(e))) ? NULL : luaT_gettm(et, e, (g)->tmname[e]))

#define fasttm(l,et,e)	gfasttm(G(l), et, e)

LUAI_DATA const char *const luaT_typenames[];


LUAI_FUNC const TValue *luaT_gettm (Table *events, TMS event, TString *ename);
LUAI_FUNC const TValue *luaT_gettmbyobj (lua_State *L, const TValue *o,
                                                       TMS event);
LUAI_FUNC void luaT_init (lua_State *L);

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\ltm.c ===
/*
** $Id: ltm.c,v 2.8 2006/01/10 12:50:00 roberto Exp $
** Tag methods
** See Copyright Notice in lua.h
*/


#include <string.h>

#define ltm_c
#define LUA_CORE

#include "lua.h"

#include "lobject.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"
#include "ltm.h"



const char *const luaT_typenames[] = {
  "nil", "boolean", "userdata", "number",
  "string", "table", "function", "userdata", "thread",
  "proto", "upval"
};


void luaT_init (lua_State *L) {
  static const char *const luaT_eventname[] = {  /* ORDER TM */
    "__index", "__newindex",
    "__gc", "__mode", "__eq",
    "__add", "__sub", "__mul", "__div", "__mod",
    "__pow", "__unm", "__len", "__lt", "__le",
    "__concat", "__call"
  };
  int i;
  for (i=0; i<TM_N; i++) {
    G(L)->tmname[i] = luaS_new(L, luaT_eventname[i]);
    luaS_fix(G(L)->tmname[i]);  /* never collect these names */
  }
}


/*
** function to be used with macro "fasttm": optimized for absence of
** tag methods
*/
const TValue *luaT_gettm (Table *events, TMS event, TString *ename) {
  const TValue *tm = luaH_getstr(events, ename);
  lua_assert(event <= TM_EQ);
  if (ttisnil(tm)) {  /* no tag method? */
    events->flags |= cast_byte(1u<<event);  /* cache this fact */
    return NULL;
  }
  else return tm;
}


const TValue *luaT_gettmbyobj (lua_State *L, const TValue *o, TMS event) {
  Table *mt;
  switch (ttype(o)) {
    case LUA_TTABLE:
      mt = hvalue(o)->metatable;
      break;
    case LUA_TUSERDATA:
      mt = uvalue(o)->metatable;
      break;
    default:
      mt = G(L)->mt[ttype(o)];
  }
  return (mt ? luaH_getstr(mt, G(L)->tmname[event]) : luaO_nilobject);
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\luac.c ===
/*
** $Id: luac.c,v 1.54 2006/06/02 17:37:11 lhf Exp $
** Lua compiler (saves bytecodes to files; also list bytecodes)
** See Copyright Notice in lua.h
*/

#include <errno.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define luac_c
#define LUA_CORE

#include "lua.h"
#include "lauxlib.h"

#include "ldo.h"
#include "lfunc.h"
#include "lmem.h"
#include "lobject.h"
#include "lopcodes.h"
#include "lstring.h"
#include "lundump.h"

#define PROGNAME	"luac"		/* default program name */
#define	OUTPUT		PROGNAME ".out"	/* default output file */

static int listing=0;			/* list bytecodes? */
static int dumping=1;			/* dump bytecodes? */
static int stripping=0;			/* strip debug information? */
static char Output[]={ OUTPUT };	/* default output file name */
static const char* output=Output;	/* actual output file name */
static const char* progname=PROGNAME;	/* actual program name */

static void fatal(const char* message)
{
 fprintf(stderr,"%s: %s\n",progname,message);
 exit(EXIT_FAILURE);
}

static void cannot(const char* what)
{
 fprintf(stderr,"%s: cannot %s %s: %s\n",progname,what,output,strerror(errno));
 exit(EXIT_FAILURE);
}

static void usage(const char* message)
{
 if (*message=='-')
  fprintf(stderr,"%s: unrecognized option " LUA_QS "\n",progname,message);
 else
  fprintf(stderr,"%s: %s\n",progname,message);
 fprintf(stderr,
 "usage: %s [options] [filenames].\n"
 "Available options are:\n"
 "  -        process stdin\n"
 "  -l       list\n"
 "  -o name  output to file " LUA_QL("name") " (default is \"%s\")\n"
 "  -p       parse only\n"
 "  -s       strip debug information\n"
 "  -v       show version information\n"
 "  --       stop handling options\n",
 progname,Output);
 exit(EXIT_FAILURE);
}

#define	IS(s)	(strcmp(argv[i],s)==0)

static int doargs(int argc, char* argv[])
{
 int i;
 int version=0;
 if (argv[0]!=NULL && *argv[0]!=0) progname=argv[0];
 for (i=1; i<argc; i++)
 {
  if (*argv[i]!='-')			/* end of options; keep it */
   break;
  else if (IS("--"))			/* end of options; skip it */
  {
   ++i;
   if (version) ++version;
   break;
  }
  else if (IS("-"))			/* end of options; use stdin */
   break;
  else if (IS("-l"))			/* list */
   ++listing;
  else if (IS("-o"))			/* output file */
  {
   output=argv[++i];
   if (output==NULL || *output==0) usage(LUA_QL("-o") " needs argument");
   if (IS("-")) output=NULL;
  }
  else if (IS("-p"))			/* parse only */
   dumping=0;
  else if (IS("-s"))			/* strip debug information */
   stripping=1;
  else if (IS("-v"))			/* show version */
   ++version;
  else					/* unknown option */
   usage(argv[i]);
 }
 if (i==argc && (listing || !dumping))
 {
  dumping=0;
  argv[--i]=Output;
 }
 if (version)
 {
  printf("%s  %s\n",LUA_RELEASE,LUA_COPYRIGHT);
  if (version==argc-1) exit(EXIT_SUCCESS);
 }
 return i;
}

#define toproto(L,i) (clvalue(L->top+(i))->l.p)

static const Proto* combine(lua_State* L, int n)
{
 if (n==1)
  return toproto(L,-1);
 else
 {
  int i,pc;
  Proto* f=luaF_newproto(L);
  setptvalue2s(L,L->top,f); incr_top(L);
  f->source=luaS_newliteral(L,"=(" PROGNAME ")");
  f->maxstacksize=1;
  pc=2*n+1;
  f->code=luaM_newvector(L,pc,Instruction);
  f->sizecode=pc;
  f->p=luaM_newvector(L,n,Proto*);
  f->sizep=n;
  pc=0;
  for (i=0; i<n; i++)
  {
   f->p[i]=toproto(L,i-n-1);
   f->code[pc++]=CREATE_ABx(OP_CLOSURE,0,i);
   f->code[pc++]=CREATE_ABC(OP_CALL,0,1,1);
  }
  f->code[pc++]=CREATE_ABC(OP_RETURN,0,1,0);
  return f;
 }
}

static int writer(lua_State* L, const void* p, size_t size, void* u)
{
 UNUSED(L);
 return (fwrite(p,size,1,(FILE*)u)!=1) && (size!=0);
}

struct Smain {
 int argc;
 char** argv;
};

static int pmain(lua_State* L)
{
 struct Smain* s = (struct Smain*)lua_touserdata(L, 1);
 int argc=s->argc;
 char** argv=s->argv;
 const Proto* f;
 int i;
 if (!lua_checkstack(L,argc)) fatal("too many input files");
 for (i=0; i<argc; i++)
 {
  const char* filename=IS("-") ? NULL : argv[i];
  if (luaL_loadfile(L,filename)!=0) fatal(lua_tostring(L,-1));
 }
 f=combine(L,argc);
 if (listing) luaU_print(f,listing>1);
 if (dumping)
 {
  FILE* D= (output==NULL) ? stdout : fopen(output,"wb");
  if (D==NULL) cannot("open");
  lua_lock(L);
  luaU_dump(L,f,writer,D,stripping);
  lua_unlock(L);
  if (ferror(D)) cannot("write");
  if (fclose(D)) cannot("close");
 }
 return 0;
}

int main(int argc, char* argv[])
{
 lua_State* L;
 struct Smain s;
 int i=doargs(argc,argv);
 argc-=i; argv+=i;
 if (argc<=0) usage("no input files given");
 L=lua_open();
 if (L==NULL) fatal("not enough memory for state");
 s.argc=argc;
 s.argv=argv;
 if (lua_cpcall(L,pmain,&s)!=0) fatal(lua_tostring(L,-1));
 lua_close(L);
 return EXIT_SUCCESS;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\luaconf.h ===
/*
** $Id: luaconf.h,v 1.82 2006/04/10 18:27:23 roberto Exp $
** Configuration file for Lua
** See Copyright Notice in lua.h
*/


#ifndef lconfig_h
#define lconfig_h

#include <limits.h>
#include <stddef.h>


/*
** ==================================================================
** Search for "@@" to find all configurable definitions.
** ===================================================================
*/


/*
@@ LUA_ANSI controls the use of non-ansi features.
** CHANGE it (define it) if you want Lua to avoid the use of any
** non-ansi feature or library.
*/
#if defined(__STRICT_ANSI__)
#define LUA_ANSI
#endif


#if !defined(LUA_ANSI) && defined(_WIN32)
#define LUA_WIN
#endif

#if defined(LUA_USE_LINUX)
#define LUA_USE_POSIX
#define LUA_USE_DLOPEN		/* needs an extra library: -ldl */
#define LUA_USE_READLINE	/* needs some extra libraries */
#endif

#if defined(LUA_USE_MACOSX)
#define LUA_USE_POSIX
#define LUA_DL_DYLD		/* does not need extra library */
#endif



/*
@@ LUA_USE_POSIX includes all functionallity listed as X/Open System
@* Interfaces Extension (XSI).
** CHANGE it (define it) if your system is XSI compatible.
*/
#if defined(LUA_USE_POSIX)
#define LUA_USE_MKSTEMP
#define LUA_USE_ISATTY
#define LUA_USE_POPEN
#define LUA_USE_ULONGJMP
#endif


/*
@@ LUA_PATH and LUA_CPATH are the names of the environment variables that
@* Lua check to set its paths.
@@ LUA_INIT is the name of the environment variable that Lua
@* checks for initialization code.
** CHANGE them if you want different names.
*/
#define LUA_PATH        "LUA_PATH"
#define LUA_CPATH       "LUA_CPATH"
#define LUA_INIT	"LUA_INIT"


/*
@@ LUA_PATH_DEFAULT is the default path that Lua uses to look for
@* Lua libraries.
@@ LUA_CPATH_DEFAULT is the default path that Lua uses to look for
@* C libraries.
** CHANGE them if your machine has a non-conventional directory
** hierarchy or if you want to install your libraries in
** non-conventional directories.
*/
#if defined(_WIN32)
/*
** In Windows, any exclamation mark ('!') in the path is replaced by the
** path of the directory of the executable file of the current process.
*/
#define LUA_LDIR	"!\\lua\\"
#define LUA_CDIR	"!\\"
#define LUA_PATH_DEFAULT  \
		".\\?.lua;"  LUA_LDIR"?.lua;"  LUA_LDIR"?\\init.lua;" \
		             LUA_CDIR"?.lua;"  LUA_CDIR"?\\init.lua"
#define LUA_CPATH_DEFAULT \
	".\\?.dll;"  LUA_CDIR"?.dll;" LUA_CDIR"loadall.dll"

#else
#define LUA_ROOT	"/usr/local/"
#define LUA_LDIR	LUA_ROOT "share/lua/5.1/"
#define LUA_CDIR	LUA_ROOT "lib/lua/5.1/"
#define LUA_PATH_DEFAULT  \
		"./?.lua;"  LUA_LDIR"?.lua;"  LUA_LDIR"?/init.lua;" \
		            LUA_CDIR"?.lua;"  LUA_CDIR"?/init.lua"
#define LUA_CPATH_DEFAULT \
	"./?.so;"  LUA_CDIR"?.so;" LUA_CDIR"loadall.so"
#endif


/*
@@ LUA_DIRSEP is the directory separator (for submodules).
** CHANGE it if your machine does not use "/" as the directory separator
** and is not Windows. (On Windows Lua automatically uses "\".)
*/
#if defined(_WIN32)
#define LUA_DIRSEP	"\\"
#else
#define LUA_DIRSEP	"/"
#endif


/*
@@ LUA_PATHSEP is the character that separates templates in a path.
@@ LUA_PATH_MARK is the string that marks the substitution points in a
@* template.
@@ LUA_EXECDIR in a Windows path is replaced by the executable's
@* directory.
@@ LUA_IGMARK is a mark to ignore all before it when bulding the
@* luaopen_ function name.
** CHANGE them if for some reason your system cannot use those
** characters. (E.g., if one of those characters is a common character
** in file/directory names.) Probably you do not need to change them.
*/
#define LUA_PATHSEP	";"
#define LUA_PATH_MARK	"?"
#define LUA_EXECDIR	"!"
#define LUA_IGMARK	"-"


/*
@@ LUA_INTEGER is the integral type used by lua_pushinteger/lua_tointeger.
** CHANGE that if ptrdiff_t is not adequate on your machine. (On most
** machines, ptrdiff_t gives a good choice between int or long.)
*/
#define LUA_INTEGER	ptrdiff_t


/*
@@ LUA_API is a mark for all core API functions.
@@ LUALIB_API is a mark for all standard library functions.
** CHANGE them if you need to define those functions in some special way.
** For instance, if you want to create one Windows DLL with the core and
** the libraries, you may want to use the following definition (define
** LUA_BUILD_AS_DLL to get it).
*/
#if defined(LUA_BUILD_AS_DLL)

#if defined(LUA_CORE) || defined(LUA_LIB)
#define LUA_API __declspec(dllexport)
#else
#define LUA_API __declspec(dllimport)
#endif

#else

#define LUA_API		extern

#endif

/* more often than not the libs go together with the core */
#define LUALIB_API	LUA_API


/*
@@ LUAI_FUNC is a mark for all extern functions that are not to be
@* exported to outside modules.
@@ LUAI_DATA is a mark for all extern (const) variables that are not to
@* be exported to outside modules.
** CHANGE them if you need to mark them in some special way. Elf/gcc
** (versions 3.2 and later) mark them as "hidden" to optimize access
** when Lua is compiled as a shared library.
*/
#if defined(luaall_c)
#define LUAI_FUNC	static
#define LUAI_DATA	/* empty */

#elif defined(__GNUC__) && ((__GNUC__*100 + __GNUC_MINOR__) >= 302) && \
      defined(__ELF__)
#define LUAI_FUNC	__attribute__((visibility("hidden"))) extern
#define LUAI_DATA	LUAI_FUNC

#else
#define LUAI_FUNC	extern
#define LUAI_DATA	extern
#endif



/*
@@ LUA_QL describes how error messages quote program elements.
** CHANGE it if you want a different appearance.
*/
#define LUA_QL(x)	"'" x "'"
#define LUA_QS		LUA_QL("%s")


/*
@@ LUA_IDSIZE gives the maximum size for the description of the source
@* of a function in debug information.
** CHANGE it if you want a different size.
*/
#define LUA_IDSIZE	60


/*
** {==================================================================
** Stand-alone configuration
** ===================================================================
*/

#if defined(lua_c) || defined(luaall_c)

/*
@@ lua_stdin_is_tty detects whether the standard input is a 'tty' (that
@* is, whether we're running lua interactively).
** CHANGE it if you have a better definition for non-POSIX/non-Windows
** systems.
*/
#if defined(LUA_USE_ISATTY)
#include <unistd.h>
#define lua_stdin_is_tty()	isatty(0)
#elif defined(LUA_WIN)
#include <io.h>
#include <stdio.h>
#define lua_stdin_is_tty()	_isatty(_fileno(stdin))
#else
#define lua_stdin_is_tty()	1  /* assume stdin is a tty */
#endif


/*
@@ LUA_PROMPT is the default prompt used by stand-alone Lua.
@@ LUA_PROMPT2 is the default continuation prompt used by stand-alone Lua.
** CHANGE them if you want different prompts. (You can also change the
** prompts dynamically, assigning to globals _PROMPT/_PROMPT2.)
*/
#define LUA_PROMPT		"> "
#define LUA_PROMPT2		">> "


/*
@@ LUA_PROGNAME is the default name for the stand-alone Lua program.
** CHANGE it if your stand-alone interpreter has a different name and
** your system is not able to detect that name automatically.
*/
#define LUA_PROGNAME		"lua"


/*
@@ LUA_MAXINPUT is the maximum length for an input line in the
@* stand-alone interpreter.
** CHANGE it if you need longer lines.
*/
#define LUA_MAXINPUT	512


/*
@@ lua_readline defines how to show a prompt and then read a line from
@* the standard input.
@@ lua_saveline defines how to "save" a read line in a "history".
@@ lua_freeline defines how to free a line read by lua_readline.
** CHANGE them if you want to improve this functionality (e.g., by using
** GNU readline and history facilities).
*/
#if defined(LUA_USE_READLINE)
#include <stdio.h>
#include <readline/readline.h>
#include <readline/history.h>
#define lua_readline(L,b,p)	((void)L, ((b)=readline(p)) != NULL)
#define lua_saveline(L,idx) \
	if (lua_strlen(L,idx) > 0)  /* non-empty line? */ \
	  add_history(lua_tostring(L, idx));  /* add it to history */
#define lua_freeline(L,b)	((void)L, free(b))
#else
#define lua_readline(L,b,p)	\
	((void)L, fputs(p, stdout), fflush(stdout),  /* show prompt */ \
	fgets(b, LUA_MAXINPUT, stdin) != NULL)  /* get line */
#define lua_saveline(L,idx)	{ (void)L; (void)idx; }
#define lua_freeline(L,b)	{ (void)L; (void)b; }
#endif

#endif

/* }================================================================== */


/*
@@ LUAI_GCPAUSE defines the default pause between garbage-collector cycles
@* as a percentage.
** CHANGE it if you want the GC to run faster or slower (higher values
** mean larger pauses which mean slower collection.) You can also change
** this value dynamically.
*/
#define LUAI_GCPAUSE	200  /* 200% (wait memory to double before next GC) */


/*
@@ LUAI_GCMUL defines the default speed of garbage collection relative to
@* memory allocation as a percentage.
** CHANGE it if you want to change the granularity of the garbage
** collection. (Higher values mean coarser collections. 0 represents
** infinity, where each step performs a full collection.) You can also
** change this value dynamically.
*/
#define LUAI_GCMUL	200 /* GC runs 'twice the speed' of memory allocation */



/*
@@ LUA_COMPAT_GETN controls compatibility with old getn behavior.
** CHANGE it (define it) if you want exact compatibility with the
** behavior of setn/getn in Lua 5.0.
*/
#undef LUA_COMPAT_GETN

/*
@@ LUA_COMPAT_LOADLIB controls compatibility about global loadlib.
** CHANGE it to undefined as soon as you do not need a global 'loadlib'
** function (the function is still available as 'package.loadlib').
*/
#undef LUA_COMPAT_LOADLIB

/*
@@ LUA_COMPAT_VARARG controls compatibility with old vararg feature.
** CHANGE it to undefined as soon as your programs use only '...' to
** access vararg parameters (instead of the old 'arg' table).
*/
#define LUA_COMPAT_VARARG

/*
@@ LUA_COMPAT_MOD controls compatibility with old math.mod function.
** CHANGE it to undefined as soon as your programs use 'math.fmod' or
** the new '%' operator instead of 'math.mod'.
*/
#define LUA_COMPAT_MOD

/*
@@ LUA_COMPAT_LSTR controls compatibility with old long string nesting
@* facility.
** CHANGE it to 2 if you want the old behaviour, or undefine it to turn
** off the advisory error when nesting [[...]].
*/
#define LUA_COMPAT_LSTR		1

/*
@@ LUA_COMPAT_GFIND controls compatibility with old 'string.gfind' name.
** CHANGE it to undefined as soon as you rename 'string.gfind' to
** 'string.gmatch'.
*/
#define LUA_COMPAT_GFIND

/*
@@ LUA_COMPAT_OPENLIB controls compatibility with old 'luaL_openlib'
@* behavior.
** CHANGE it to undefined as soon as you replace to 'luaL_registry'
** your uses of 'luaL_openlib'
*/
#define LUA_COMPAT_OPENLIB



/*
@@ luai_apicheck is the assert macro used by the Lua-C API.
** CHANGE luai_apicheck if you want Lua to perform some checks in the
** parameters it gets from API calls. This may slow down the interpreter
** a bit, but may be quite useful when debugging C code that interfaces
** with Lua. A useful redefinition is to use assert.h.
*/
#if defined(LUA_USE_APICHECK)
#include <assert.h>
#define luai_apicheck(L,o)	{ (void)L; assert(o); }
#else
#define luai_apicheck(L,o)	{ (void)L; }
#endif


/*
@@ LUAI_BITSINT defines the number of bits in an int.
** CHANGE here if Lua cannot automatically detect the number of bits of
** your machine. Probably you do not need to change this.
*/
/* avoid overflows in comparison */
#if INT_MAX-20 < 32760
#define LUAI_BITSINT	16
#elif INT_MAX > 2147483640L
/* int has at least 32 bits */
#define LUAI_BITSINT	32
#else
#error "you must define LUA_BITSINT with number of bits in an integer"
#endif


/*
@@ LUAI_UINT32 is an unsigned integer with at least 32 bits.
@@ LUAI_INT32 is an signed integer with at least 32 bits.
@@ LUAI_UMEM is an unsigned integer big enough to count the total
@* memory used by Lua.
@@ LUAI_MEM is a signed integer big enough to count the total memory
@* used by Lua.
** CHANGE here if for some weird reason the default definitions are not
** good enough for your machine. (The definitions in the 'else'
** part always works, but may waste space on machines with 64-bit
** longs.) Probably you do not need to change this.
*/
#if LUAI_BITSINT >= 32
#define LUAI_UINT32	unsigned int
#define LUAI_INT32	int
#define LUAI_MAXINT32	INT_MAX
#define LUAI_UMEM	size_t
#define LUAI_MEM	ptrdiff_t
#else
/* 16-bit ints */
#define LUAI_UINT32	unsigned long
#define LUAI_INT32	long
#define LUAI_MAXINT32	LONG_MAX
#define LUAI_UMEM	unsigned long
#define LUAI_MEM	long
#endif


/*
@@ LUAI_MAXCALLS limits the number of nested calls.
** CHANGE it if you need really deep recursive calls. This limit is
** arbitrary; its only purpose is to stop infinite recursion before
** exhausting memory.
*/
#define LUAI_MAXCALLS	20000


/*
@@ LUAI_MAXCSTACK limits the number of Lua stack slots that a C function
@* can use.
** CHANGE it if you need lots of (Lua) stack space for your C
** functions. This limit is arbitrary; its only purpose is to stop C
** functions to consume unlimited stack space.
*/
#define LUAI_MAXCSTACK	2048



/*
** {==================================================================
** CHANGE (to smaller values) the following definitions if your system
** has a small C stack. (Or you may want to change them to larger
** values if your system has a large C stack and these limits are
** too rigid for you.) Some of these constants control the size of
** stack-allocated arrays used by the compiler or the interpreter, while
** others limit the maximum number of recursive calls that the compiler
** or the interpreter can perform. Values too large may cause a C stack
** overflow for some forms of deep constructs.
** ===================================================================
*/


/*
@@ LUAI_MAXCCALLS is the maximum depth for nested C calls (short) and
@* syntactical nested non-terminals in a program.
*/
#define LUAI_MAXCCALLS		200


/*
@@ LUAI_MAXVARS is the maximum number of local variables per function
@* (must be smaller than 250).
*/
#define LUAI_MAXVARS		200


/*
@@ LUAI_MAXUPVALUES is the maximum number of upvalues per function
@* (must be smaller than 250).
*/
#define LUAI_MAXUPVALUES	60


/*
@@ LUAL_BUFFERSIZE is the buffer size used by the lauxlib buffer system.
*/
#define LUAL_BUFFERSIZE		BUFSIZ

/* }================================================================== */




/*
** {==================================================================
@@ LUA_NUMBER is the type of numbers in Lua.
** CHANGE the following definitions only if you want to build Lua
** with a number type different from double. You may also need to
** change lua_number2int & lua_number2integer.
** ===================================================================
*/

#define LUA_NUMBER_DOUBLE
#define LUA_NUMBER	double

/*
@@ LUAI_UACNUMBER is the result of an 'usual argument conversion'
@* over a number.
*/
#define LUAI_UACNUMBER	double


/*
@@ LUA_NUMBER_SCAN is the format for reading numbers.
@@ LUA_NUMBER_FMT is the format for writing numbers.
@@ lua_number2str converts a number to a string.
@@ LUAI_MAXNUMBER2STR is maximum size of previous conversion.
@@ lua_str2number converts a string to a number.
*/
#define LUA_NUMBER_SCAN		"%lf"
#define LUA_NUMBER_FMT		"%.14g"
#define lua_number2str(s,n)	sprintf((s), LUA_NUMBER_FMT, (n))
#define LUAI_MAXNUMBER2STR	32 /* 16 digits, sign, point, and \0 */
#define lua_str2number(s,p)	strtod((s), (p))


/*
@@ The luai_num* macros define the primitive operations over numbers.
*/
#if defined(LUA_CORE)
#include <math.h>
#define luai_numadd(a,b)	((a)+(b))
#define luai_numsub(a,b)	((a)-(b))
#define luai_nummul(a,b)	((a)*(b))
#define luai_numdiv(a,b)	((a)/(b))
#define luai_nummod(a,b)	((a) - floor((a)/(b))*(b))
#define luai_numpow(a,b)	(pow(a,b))
#define luai_numunm(a)		(-(a))
#define luai_numeq(a,b)		((a)==(b))
#define luai_numlt(a,b)		((a)<(b))
#define luai_numle(a,b)		((a)<=(b))
#define luai_numisnan(a)	(!luai_numeq((a), (a)))
#endif


/*
@@ lua_number2int is a macro to convert lua_Number to int.
@@ lua_number2integer is a macro to convert lua_Number to lua_Integer.
** CHANGE them if you know a faster way to convert a lua_Number to
** int (with any rounding method and without throwing errors) in your
** system. In Pentium machines, a naive typecast from double to int
** in C is extremely slow, so any alternative is worth trying.
*/

/* On a Pentium, resort to a trick */
#if defined(LUA_NUMBER_DOUBLE) && !defined(LUA_ANSI) && !defined(__SSE2__) && \
    (defined(__i386) || defined (_M_IX86) || defined(__i386__))

/* On a Microsoft compiler, use assembler */
#if defined(_MSC_VER)

#define lua_number2int(i,d)   __asm fld d   __asm fistp i
#define lua_number2integer(i,n)		lua_number2int(i, n)

/* the next trick should work on any Pentium, but sometimes clashes
   with a DirectX idiosyncrasy */
#else

union luai_Cast { double l_d; long l_l; };
#define lua_number2int(i,d) \
  { volatile union luai_Cast u; u.l_d = (d) + 6755399441055744.0; (i) = u.l_l; }
#define lua_number2integer(i,n)		lua_number2int(i, n)

#endif


/* this option always works, but may be slow */
#else
#define lua_number2int(i,d)	((i)=(int)(d))
#define lua_number2integer(i,d)	((i)=(lua_Integer)(d))

#endif

/* }================================================================== */


/*
@@ LUAI_USER_ALIGNMENT_T is a type that requires maximum alignment.
** CHANGE it if your system requires alignments larger than double. (For
** instance, if your system supports long doubles and they must be
** aligned in 16-byte boundaries, then you should add long double in the
** union.) Probably you do not need to change this.
*/
#define LUAI_USER_ALIGNMENT_T	union { double u; void *s; long l; }


/*
@@ LUAI_THROW/LUAI_TRY define how Lua does exception handling.
** CHANGE them if you prefer to use longjmp/setjmp even with C++
** or if want/don't to use _longjmp/_setjmp instead of regular
** longjmp/setjmp. By default, Lua handles errors with exceptions when
** compiling as C++ code, with _longjmp/_setjmp when asked to use them,
** and with longjmp/setjmp otherwise.
*/
#if defined(__cplusplus)
/* C++ exceptions */
#define LUAI_THROW(L,c)	throw(c)
#define LUAI_TRY(L,c,a)	try { a } catch(...) \
	{ if ((c)->status == 0) (c)->status = -1; }
#define luai_jmpbuf	int  /* dummy variable */

#elif defined(LUA_USE_ULONGJMP)
/* in Unix, try _longjmp/_setjmp (more efficient) */
#define LUAI_THROW(L,c)	_longjmp((c)->b, 1)
#define LUAI_TRY(L,c,a)	if (_setjmp((c)->b) == 0) { a }
#define luai_jmpbuf	jmp_buf

#else
/* default handling with long jumps */
#define LUAI_THROW(L,c)	longjmp((c)->b, 1)
#define LUAI_TRY(L,c,a)	if (setjmp((c)->b) == 0) { a }
#define luai_jmpbuf	jmp_buf

#endif


/*
@@ LUA_MAXCAPTURES is the maximum number of captures that a pattern
@* can do during pattern-matching.
** CHANGE it if you need more captures. This limit is arbitrary.
*/
#define LUA_MAXCAPTURES		32


/*
@@ lua_tmpnam is the function that the OS library uses to create a
@* temporary name.
@@ LUA_TMPNAMBUFSIZE is the maximum size of a name created by lua_tmpnam.
** CHANGE them if you have an alternative to tmpnam (which is considered
** insecure) or if you want the original tmpnam anyway.  By default, Lua
** uses tmpnam except when POSIX is available, where it uses mkstemp.
*/
#if defined(loslib_c) || defined(luaall_c)

#if defined(LUA_USE_MKSTEMP)
#include <unistd.h>
#define LUA_TMPNAMBUFSIZE	32
#define lua_tmpnam(b,e)	{ \
	strcpy(b, "/tmp/lua_XXXXXX"); \
	e = mkstemp(b); \
	if (e != -1) close(e); \
	e = (e == -1); }

#else
#define LUA_TMPNAMBUFSIZE	L_tmpnam
#define lua_tmpnam(b,e)		{ e = (tmpnam(b) == NULL); }
#endif

#endif


/*
@@ lua_popen spawns a new process connected to the current one through
@* the file streams.
** CHANGE it if you have a way to implement it in your system.
*/
#if defined(LUA_USE_POPEN)

#define lua_popen(L,c,m)	((void)L, popen(c,m))
#define lua_pclose(L,file)	((void)L, (pclose(file) != -1))

#elif defined(LUA_WIN)

#define lua_popen(L,c,m)	((void)L, _popen(c,m))
#define lua_pclose(L,file)	((void)L, (_pclose(file) != -1))

#else

#define lua_popen(L,c,m)	((void)((void)c, m),  \
		luaL_error(L, LUA_QL("popen") " not supported"), (FILE*)0)
#define lua_pclose(L,file)		((void)((void)L, file), 0)

#endif

/*
@@ LUA_DL_* define which dynamic-library system Lua should use.
** CHANGE here if Lua has problems choosing the appropriate
** dynamic-library system for your platform (either Windows' DLL, Mac's
** dyld, or Unix's dlopen). If your system is some kind of Unix, there
** is a good chance that it has dlopen, so LUA_DL_DLOPEN will work for
** it.  To use dlopen you also need to adapt the src/Makefile (probably
** adding -ldl to the linker options), so Lua does not select it
** automatically.  (When you change the makefile to add -ldl, you must
** also add -DLUA_USE_DLOPEN.)
** If you do not want any kind of dynamic library, undefine all these
** options.
** By default, _WIN32 gets LUA_DL_DLL and MAC OS X gets LUA_DL_DYLD.
*/
#if defined(LUA_USE_DLOPEN)
#define LUA_DL_DLOPEN
#endif

#if defined(LUA_WIN)
#define LUA_DL_DLL
#endif


/*
@@ LUAI_EXTRASPACE allows you to add user-specific data in a lua_State
@* (the data goes just *before* the lua_State pointer).
** CHANGE (define) this if you really need that. This value must be
** a multiple of the maximum alignment required for your machine.
*/
#define LUAI_EXTRASPACE		0


/*
@@ luai_userstate* allow user-specific actions on threads.
** CHANGE them if you defined LUAI_EXTRASPACE and need to do something
** extra when a thread is created/deleted/resumed/yielded.
*/
#define luai_userstateopen(L)		((void)L)
#define luai_userstateclose(L)		((void)L)
#define luai_userstatethread(L,L1)	((void)L)
#define luai_userstatefree(L)		((void)L)
#define luai_userstateresume(L,n)	((void)L)
#define luai_userstateyield(L,n)	((void)L)


/*
@@ LUA_INTFRMLEN is the length modifier for integer conversions
@* in 'string.format'.
@@ LUA_INTFRM_T is the integer type correspoding to the previous length
@* modifier.
** CHANGE them if your system supports long long or does not support long.
*/

#if defined(LUA_USELONGLONG)

#define LUA_INTFRMLEN		"ll"
#define LUA_INTFRM_T		long long

#else

#define LUA_INTFRMLEN		"l"
#define LUA_INTFRM_T		long

#endif



/* =================================================================== */

/*
** Local configuration. You can use this space to add your redefinitions
** without modifying the main part of the file.
*/



#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lua.h ===
/*
** $Id: lua.h,v 1.218 2006/06/02 15:34:00 roberto Exp $
** Lua - An Extensible Extension Language
** Lua.org, PUC-Rio, Brazil (http://www.lua.org)
** See Copyright Notice at the end of this file
*/


#ifndef lua_h
#define lua_h

#include <stdarg.h>
#include <stddef.h>


#include "luaconf.h"


#define LUA_VERSION	"Lua 5.1"
#define LUA_RELEASE	"Lua 5.1.1"
#define LUA_VERSION_NUM	501
#define LUA_COPYRIGHT	"Copyright (C) 1994-2006 Lua.org, PUC-Rio"
#define LUA_AUTHORS 	"R. Ierusalimschy, L. H. de Figueiredo & W. Celes"


/* mark for precompiled code (`<esc>Lua') */
#define	LUA_SIGNATURE	"\033Lua"

/* option for multiple returns in `lua_pcall' and `lua_call' */
#define LUA_MULTRET	(-1)


/*
** pseudo-indices
*/
#define LUA_REGISTRYINDEX	(-10000)
#define LUA_ENVIRONINDEX	(-10001)
#define LUA_GLOBALSINDEX	(-10002)
#define lua_upvalueindex(i)	(LUA_GLOBALSINDEX-(i))


/* thread status; 0 is OK */
#define LUA_YIELD	1
#define LUA_ERRRUN	2
#define LUA_ERRSYNTAX	3
#define LUA_ERRMEM	4
#define LUA_ERRERR	5


typedef struct lua_State lua_State;

typedef int (*lua_CFunction) (lua_State *L);


/*
** functions that read/write blocks when loading/dumping Lua chunks
*/
typedef const char * (*lua_Reader) (lua_State *L, void *ud, size_t *sz);

typedef int (*lua_Writer) (lua_State *L, const void* p, size_t sz, void* ud);


/*
** prototype for memory-allocation functions
*/
typedef void * (*lua_Alloc) (void *ud, void *ptr, size_t osize, size_t nsize);


/*
** basic types
*/
#define LUA_TNONE		(-1)

#define LUA_TNIL		0
#define LUA_TBOOLEAN		1
#define LUA_TLIGHTUSERDATA	2
#define LUA_TNUMBER		3
#define LUA_TSTRING		4
#define LUA_TTABLE		5
#define LUA_TFUNCTION		6
#define LUA_TUSERDATA		7
#define LUA_TTHREAD		8



/* minimum Lua stack available to a C function */
#define LUA_MINSTACK	20


/*
** generic extra include file
*/
#if defined(LUA_USER_H)
#include LUA_USER_H
#endif


/* type of numbers in Lua */
typedef LUA_NUMBER lua_Number;


/* type for integer functions */
typedef LUA_INTEGER lua_Integer;



/*
** state manipulation
*/
LUA_API lua_State *(lua_newstate) (lua_Alloc f, void *ud);
LUA_API void       (lua_close) (lua_State *L);
LUA_API lua_State *(lua_newthread) (lua_State *L);

LUA_API lua_CFunction (lua_atpanic) (lua_State *L, lua_CFunction panicf);


/*
** basic stack manipulation
*/
LUA_API int   (lua_gettop) (lua_State *L);
LUA_API void  (lua_settop) (lua_State *L, int idx);
LUA_API void  (lua_pushvalue) (lua_State *L, int idx);
LUA_API void  (lua_remove) (lua_State *L, int idx);
LUA_API void  (lua_insert) (lua_State *L, int idx);
LUA_API void  (lua_replace) (lua_State *L, int idx);
LUA_API int   (lua_checkstack) (lua_State *L, int sz);

LUA_API void  (lua_xmove) (lua_State *from, lua_State *to, int n);


/*
** access functions (stack -> C)
*/

LUA_API int             (lua_isnumber) (lua_State *L, int idx);
LUA_API int             (lua_isstring) (lua_State *L, int idx);
LUA_API int             (lua_iscfunction) (lua_State *L, int idx);
LUA_API int             (lua_isuserdata) (lua_State *L, int idx);
LUA_API int             (lua_type) (lua_State *L, int idx);
LUA_API const char     *(lua_typename) (lua_State *L, int tp);

LUA_API int            (lua_equal) (lua_State *L, int idx1, int idx2);
LUA_API int            (lua_rawequal) (lua_State *L, int idx1, int idx2);
LUA_API int            (lua_lessthan) (lua_State *L, int idx1, int idx2);

LUA_API lua_Number      (lua_tonumber) (lua_State *L, int idx);
LUA_API lua_Integer     (lua_tointeger) (lua_State *L, int idx);
LUA_API int             (lua_toboolean) (lua_State *L, int idx);
LUA_API const char     *(lua_tolstring) (lua_State *L, int idx, size_t *len);
LUA_API size_t          (lua_objlen) (lua_State *L, int idx);
LUA_API lua_CFunction   (lua_tocfunction) (lua_State *L, int idx);
LUA_API void	       *(lua_touserdata) (lua_State *L, int idx);
LUA_API lua_State      *(lua_tothread) (lua_State *L, int idx);
LUA_API const void     *(lua_topointer) (lua_State *L, int idx);


/*
** push functions (C -> stack)
*/
LUA_API void  (lua_pushnil) (lua_State *L);
LUA_API void  (lua_pushnumber) (lua_State *L, lua_Number n);
LUA_API void  (lua_pushinteger) (lua_State *L, lua_Integer n);
LUA_API void  (lua_pushlstring) (lua_State *L, const char *s, size_t l);
LUA_API void  (lua_pushstring) (lua_State *L, const char *s);
LUA_API const char *(lua_pushvfstring) (lua_State *L, const char *fmt,
                                                      va_list argp);
LUA_API const char *(lua_pushfstring) (lua_State *L, const char *fmt, ...);
LUA_API void  (lua_pushcclosure) (lua_State *L, lua_CFunction fn, int n);
LUA_API void  (lua_pushboolean) (lua_State *L, int b);
LUA_API void  (lua_pushlightuserdata) (lua_State *L, void *p);
LUA_API int   (lua_pushthread) (lua_State *L);


/*
** get functions (Lua -> stack)
*/
LUA_API void  (lua_gettable) (lua_State *L, int idx);
LUA_API void  (lua_getfield) (lua_State *L, int idx, const char *k);
LUA_API void  (lua_rawget) (lua_State *L, int idx);
LUA_API void  (lua_rawgeti) (lua_State *L, int idx, int n);
LUA_API void  (lua_createtable) (lua_State *L, int narr, int nrec);
LUA_API void *(lua_newuserdata) (lua_State *L, size_t sz);
LUA_API int   (lua_getmetatable) (lua_State *L, int objindex);
LUA_API void  (lua_getfenv) (lua_State *L, int idx);


/*
** set functions (stack -> Lua)
*/
LUA_API void  (lua_settable) (lua_State *L, int idx);
LUA_API void  (lua_setfield) (lua_State *L, int idx, const char *k);
LUA_API void  (lua_rawset) (lua_State *L, int idx);
LUA_API void  (lua_rawseti) (lua_State *L, int idx, int n);
LUA_API int   (lua_setmetatable) (lua_State *L, int objindex);
LUA_API int   (lua_setfenv) (lua_State *L, int idx);


/*
** `load' and `call' functions (load and run Lua code)
*/
LUA_API void  (lua_call) (lua_State *L, int nargs, int nresults);
LUA_API int   (lua_pcall) (lua_State *L, int nargs, int nresults, int errfunc);
LUA_API int   (lua_cpcall) (lua_State *L, lua_CFunction func, void *ud);
LUA_API int   (lua_load) (lua_State *L, lua_Reader reader, void *dt,
                                        const char *chunkname);

LUA_API int (lua_dump) (lua_State *L, lua_Writer writer, void *data);


/*
** coroutine functions
*/
LUA_API int  (lua_yield) (lua_State *L, int nresults);
LUA_API int  (lua_resume) (lua_State *L, int narg);
LUA_API int  (lua_status) (lua_State *L);

/*
** garbage-collection function and options
*/

#define LUA_GCSTOP		0
#define LUA_GCRESTART		1
#define LUA_GCCOLLECT		2
#define LUA_GCCOUNT		3
#define LUA_GCCOUNTB		4
#define LUA_GCSTEP		5
#define LUA_GCSETPAUSE		6
#define LUA_GCSETSTEPMUL	7

LUA_API int (lua_gc) (lua_State *L, int what, int data);


/*
** miscellaneous functions
*/

LUA_API int   (lua_error) (lua_State *L);

LUA_API int   (lua_next) (lua_State *L, int idx);

LUA_API void  (lua_concat) (lua_State *L, int n);

LUA_API lua_Alloc (lua_getallocf) (lua_State *L, void **ud);
LUA_API void lua_setallocf (lua_State *L, lua_Alloc f, void *ud);



/* 
** ===============================================================
** some useful macros
** ===============================================================
*/

#define lua_pop(L,n)		lua_settop(L, -(n)-1)

#define lua_newtable(L)		lua_createtable(L, 0, 0)

#define lua_register(L,n,f) (lua_pushcfunction(L, (f)), lua_setglobal(L, (n)))

#define lua_pushcfunction(L,f)	lua_pushcclosure(L, (f), 0)

#define lua_strlen(L,i)		lua_objlen(L, (i))

#define lua_isfunction(L,n)	(lua_type(L, (n)) == LUA_TFUNCTION)
#define lua_istable(L,n)	(lua_type(L, (n)) == LUA_TTABLE)
#define lua_islightuserdata(L,n)	(lua_type(L, (n)) == LUA_TLIGHTUSERDATA)
#define lua_isnil(L,n)		(lua_type(L, (n)) == LUA_TNIL)
#define lua_isboolean(L,n)	(lua_type(L, (n)) == LUA_TBOOLEAN)
#define lua_isthread(L,n)	(lua_type(L, (n)) == LUA_TTHREAD)
#define lua_isnone(L,n)		(lua_type(L, (n)) == LUA_TNONE)
#define lua_isnoneornil(L, n)	(lua_type(L, (n)) <= 0)

#define lua_pushliteral(L, s)	\
	lua_pushlstring(L, "" s, (sizeof(s)/sizeof(char))-1)

#define lua_setglobal(L,s)	lua_setfield(L, LUA_GLOBALSINDEX, (s))
#define lua_getglobal(L,s)	lua_getfield(L, LUA_GLOBALSINDEX, (s))

#define lua_tostring(L,i)	lua_tolstring(L, (i), NULL)



/*
** compatibility macros and functions
*/

#define lua_open()	luaL_newstate()

#define lua_getregistry(L)	lua_pushvalue(L, LUA_REGISTRYINDEX)

#define lua_getgccount(L)	lua_gc(L, LUA_GCCOUNT, 0)

#define lua_Chunkreader		lua_Reader
#define lua_Chunkwriter		lua_Writer



/*
** {======================================================================
** Debug API
** =======================================================================
*/


/*
** Event codes
*/
#define LUA_HOOKCALL	0
#define LUA_HOOKRET	1
#define LUA_HOOKLINE	2
#define LUA_HOOKCOUNT	3
#define LUA_HOOKTAILRET 4


/*
** Event masks
*/
#define LUA_MASKCALL	(1 << LUA_HOOKCALL)
#define LUA_MASKRET	(1 << LUA_HOOKRET)
#define LUA_MASKLINE	(1 << LUA_HOOKLINE)
#define LUA_MASKCOUNT	(1 << LUA_HOOKCOUNT)

typedef struct lua_Debug lua_Debug;  /* activation record */


/* Functions to be called by the debuger in specific events */
typedef void (*lua_Hook) (lua_State *L, lua_Debug *ar);


LUA_API int lua_getstack (lua_State *L, int level, lua_Debug *ar);
LUA_API int lua_getinfo (lua_State *L, const char *what, lua_Debug *ar);
LUA_API const char *lua_getlocal (lua_State *L, const lua_Debug *ar, int n);
LUA_API const char *lua_setlocal (lua_State *L, const lua_Debug *ar, int n);
LUA_API const char *lua_getupvalue (lua_State *L, int funcindex, int n);
LUA_API const char *lua_setupvalue (lua_State *L, int funcindex, int n);

LUA_API int lua_sethook (lua_State *L, lua_Hook func, int mask, int count);
LUA_API lua_Hook lua_gethook (lua_State *L);
LUA_API int lua_gethookmask (lua_State *L);
LUA_API int lua_gethookcount (lua_State *L);


struct lua_Debug {
  int event;
  const char *name;	/* (n) */
  const char *namewhat;	/* (n) `global', `local', `field', `method' */
  const char *what;	/* (S) `Lua', `C', `main', `tail' */
  const char *source;	/* (S) */
  int currentline;	/* (l) */
  int nups;		/* (u) number of upvalues */
  int linedefined;	/* (S) */
  int lastlinedefined;	/* (S) */
  char short_src[LUA_IDSIZE]; /* (S) */
  /* private part */
  int i_ci;  /* active function */
};

/* }====================================================================== */


/******************************************************************************
* Copyright (C) 1994-2006 Lua.org, PUC-Rio.  All rights reserved.
*
* Permission is hereby granted, free of charge, to any person obtaining
* a copy of this software and associated documentation files (the
* "Software"), to deal in the Software without restriction, including
* without limitation the rights to use, copy, modify, merge, publish,
* distribute, sublicense, and/or sell copies of the Software, and to
* permit persons to whom the Software is furnished to do so, subject to
* the following conditions:
*
* The above copyright notice and this permission notice shall be
* included in all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
* EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
* IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
* CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
* TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
* SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
******************************************************************************/


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lua.c ===
/*
** $Id: lua.c,v 1.160 2006/06/02 15:34:00 roberto Exp $
** Lua stand-alone interpreter
** See Copyright Notice in lua.h
*/


#include <signal.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define lua_c

#include "lua.h"

#include "lauxlib.h"
#include "lualib.h"



static lua_State *globalL = NULL;

static const char *progname = LUA_PROGNAME;



static void lstop (lua_State *L, lua_Debug *ar) {
  (void)ar;  /* unused arg. */
  lua_sethook(L, NULL, 0, 0);
  luaL_error(L, "interrupted!");
}


static void __cdecl laction (int i) {
  signal(i, SIG_DFL); /* if another SIGINT happens before lstop,
                              terminate process (default action) */
  lua_sethook(globalL, lstop, LUA_MASKCALL | LUA_MASKRET | LUA_MASKCOUNT, 1);
}


static void print_usage (void) {
  fprintf(stderr,
  "usage: %s [options] [script [args]].\n"
  "Available options are:\n"
  "  -e stat  execute string " LUA_QL("stat") "\n"
  "  -l name  require library " LUA_QL("name") "\n"
  "  -i       enter interactive mode after executing " LUA_QL("script") "\n"
  "  -v       show version information\n"
  "  --       stop handling options\n"
  "  -        execute stdin and stop handling options\n"
  ,
  progname);
  fflush(stderr);
}


static void l_message (const char *pname, const char *msg) {
  if (pname) fprintf(stderr, "%s: ", pname);
  fprintf(stderr, "%s\n", msg);
  fflush(stderr);
}


static int report (lua_State *L, int status) {
  if (status && !lua_isnil(L, -1)) {
    const char *msg = lua_tostring(L, -1);
    if (msg == NULL) msg = "(error object is not a string)";
    l_message(progname, msg);
    lua_pop(L, 1);
  }
  return status;
}


static int traceback (lua_State *L) {
  lua_getfield(L, LUA_GLOBALSINDEX, "debug");
  if (!lua_istable(L, -1)) {
    lua_pop(L, 1);
    return 1;
  }
  lua_getfield(L, -1, "traceback");
  if (!lua_isfunction(L, -1)) {
    lua_pop(L, 2);
    return 1;
  }
  lua_pushvalue(L, 1);  /* pass error message */
  lua_pushinteger(L, 2);  /* skip this function and traceback */
  lua_call(L, 2, 1);  /* call debug.traceback */
  return 1;
}


static int docall (lua_State *L, int narg, int clear) {
  int status;
  int base = lua_gettop(L) - narg;  /* function index */
  lua_pushcfunction(L, traceback);  /* push traceback function */
  lua_insert(L, base);  /* put it under chunk and args */
  signal(SIGINT, laction);
  status = lua_pcall(L, narg, (clear ? 0 : LUA_MULTRET), base);
  signal(SIGINT, SIG_DFL);
  lua_remove(L, base);  /* remove traceback function */
  /* force a complete garbage collection in case of errors */
  if (status != 0) lua_gc(L, LUA_GCCOLLECT, 0);
  return status;
}


static void print_version (void) {
  l_message(NULL, LUA_RELEASE "  " LUA_COPYRIGHT);
}


static int getargs (lua_State *L, char **argv, int n) {
  int narg;
  int i;
  int argc = 0;
  while (argv[argc]) argc++;  /* count total number of arguments */
  narg = argc - (n + 1);  /* number of arguments to the script */
  luaL_checkstack(L, narg + 3, "too many arguments to script");
  for (i=n+1; i < argc; i++)
    lua_pushstring(L, argv[i]);
  lua_createtable(L, narg, n + 1);
  for (i=0; i < argc; i++) {
    lua_pushstring(L, argv[i]);
    lua_rawseti(L, -2, i - n);
  }
  return narg;
}


static int dofile (lua_State *L, const char *name) {
  int status = luaL_loadfile(L, name) || docall(L, 0, 1);
  return report(L, status);
}


static int dostring (lua_State *L, const char *s, const char *name) {
  int status = luaL_loadbuffer(L, s, strlen(s), name) || docall(L, 0, 1);
  return report(L, status);
}


static int dolibrary (lua_State *L, const char *name) {
  lua_getglobal(L, "require");
  lua_pushstring(L, name);
  return report(L, lua_pcall(L, 1, 0, 0));
}


static const char *get_prompt (lua_State *L, int firstline) {
  const char *p;
  lua_getfield(L, LUA_GLOBALSINDEX, firstline ? "_PROMPT" : "_PROMPT2");
  p = lua_tostring(L, -1);
  if (p == NULL) p = (firstline ? LUA_PROMPT : LUA_PROMPT2);
  lua_pop(L, 1);  /* remove global */
  return p;
}


static int incomplete (lua_State *L, int status) {
  if (status == LUA_ERRSYNTAX) {
    size_t lmsg;
    const char *msg = lua_tolstring(L, -1, &lmsg);
    const char *tp = msg + lmsg - (sizeof(LUA_QL("<eof>")) - 1);
    if (strstr(msg, LUA_QL("<eof>")) == tp) {
      lua_pop(L, 1);
      return 1;
    }
  }
  return 0;  /* else... */
}


static int pushline (lua_State *L, int firstline) {
  char buffer[LUA_MAXINPUT];
  char *b = buffer;
  size_t l;
  const char *prmt = get_prompt(L, firstline);
  if (lua_readline(L, b, prmt) == 0)
    return 0;  /* no input */
  l = strlen(b);
  if (l > 0 && b[l-1] == '\n')  /* line ends with newline? */
    b[l-1] = '\0';  /* remove it */
  if (firstline && b[0] == '=')  /* first line starts with `=' ? */
    lua_pushfstring(L, "return %s", b+1);  /* change it to `return' */
  else
    lua_pushstring(L, b);
  lua_freeline(L, b);
  return 1;
}


static int loadline (lua_State *L) {
  int status;
  lua_settop(L, 0);
  if (!pushline(L, 1))
    return -1;  /* no input */
  for (;;) {  /* repeat until gets a complete line */
    status = luaL_loadbuffer(L, lua_tostring(L, 1), lua_strlen(L, 1), "=stdin");
    if (!incomplete(L, status)) break;  /* cannot try to add lines? */
    if (!pushline(L, 0))  /* no more input? */
      return -1;
    lua_pushliteral(L, "\n");  /* add a new line... */
    lua_insert(L, -2);  /* ...between the two lines */
    lua_concat(L, 3);  /* join them */
  }
  lua_saveline(L, 1);
  lua_remove(L, 1);  /* remove line */
  return status;
}


static void dotty (lua_State *L) {
  int status;
  const char *oldprogname = progname;
  progname = NULL;
  while ((status = loadline(L)) != -1) {
    if (status == 0) status = docall(L, 0, 0);
    report(L, status);
    if (status == 0 && lua_gettop(L) > 0) {  /* any result to print? */
      lua_getglobal(L, "print");
      lua_insert(L, 1);
      if (lua_pcall(L, lua_gettop(L)-1, 0, 0) != 0)
        l_message(progname, lua_pushfstring(L,
                               "error calling " LUA_QL("print") " (%s)",
                               lua_tostring(L, -1)));
    }
  }
  lua_settop(L, 0);  /* clear stack */
  fputs("\n", stdout);
  fflush(stdout);
  progname = oldprogname;
}


static int handle_script (lua_State *L, char **argv, int n) {
  int status;
  const char *fname;
  int narg = getargs(L, argv, n);  /* collect arguments */
  lua_setglobal(L, "arg");
  fname = argv[n];
  if (strcmp(fname, "-") == 0 && strcmp(argv[n-1], "--") != 0) 
    fname = NULL;  /* stdin */
  status = luaL_loadfile(L, fname);
  lua_insert(L, -(narg+1));
  if (status == 0)
    status = docall(L, narg, 0);
  else
    lua_pop(L, narg);      
  return report(L, status);
}


/* check that argument has no extra characters at the end */
#define notail(x)	{if ((x)[2] != '\0') return -1;}


static int collectargs (char **argv, int *pi, int *pv, int *pe) {
  int i;
  for (i = 1; argv[i] != NULL; i++) {
    if (argv[i][0] != '-')  /* not an option? */
        return i;
    switch (argv[i][1]) {  /* option */
      case '-':
        notail(argv[i]);
        return (argv[i+1] != NULL ? i+1 : 0);
      case '\0':
        return i;
      case 'i':
        notail(argv[i]);
        *pi = 1;  /* go through */
      case 'v':
        notail(argv[i]);
        *pv = 1;
        break;
      case 'e':
        *pe = 1;  /* go through */
      case 'l':
        if (argv[i][2] == '\0') {
          i++;
          if (argv[i] == NULL) return -1;
        }
        break;
      default: return -1;  /* invalid option */
    }
  }
  return 0;
}


static int runargs (lua_State *L, char **argv, int n) {
  int i;
  for (i = 1; i < n; i++) {
    if (argv[i] == NULL) continue;
    lua_assert(argv[i][0] == '-');
    switch (argv[i][1]) {  /* option */
      case 'e': {
        const char *chunk = argv[i] + 2;
        if (*chunk == '\0') chunk = argv[++i];
        lua_assert(chunk != NULL);
        if (dostring(L, chunk, "=(command line)") != 0)
          return 1;
        break;
      }
      case 'l': {
        const char *filename = argv[i] + 2;
        if (*filename == '\0') filename = argv[++i];
        lua_assert(filename != NULL);
        if (dolibrary(L, filename))
          return 1;  /* stop if file fails */
        break;
      }
      default: break;
    }
  }
  return 0;
}


static int handle_luainit (lua_State *L) {
  const char *init = getenv(LUA_INIT);
  if (init == NULL) return 0;  /* status OK */
  else if (init[0] == '@')
    return dofile(L, init+1);
  else
    return dostring(L, init, "=" LUA_INIT);
}


struct Smain {
  int argc;
  char **argv;
  int status;
};


static int pmain (lua_State *L) {
  struct Smain *s = (struct Smain *)lua_touserdata(L, 1);
  char **argv = s->argv;
  int script;
  int has_i = 0, has_v = 0, has_e = 0;
  globalL = L;
  if (argv[0] && argv[0][0]) progname = argv[0];
  lua_gc(L, LUA_GCSTOP, 0);  /* stop collector during initialization */
  luaL_openlibs(L);  /* open libraries */
  lua_gc(L, LUA_GCRESTART, 0);
  s->status = handle_luainit(L);
  if (s->status != 0) return 0;
  script = collectargs(argv, &has_i, &has_v, &has_e);
  if (script < 0) {  /* invalid args? */
    print_usage();
    s->status = 1;
    return 0;
  }
  if (has_v) print_version();
  s->status = runargs(L, argv, (script > 0) ? script : s->argc);
  if (s->status != 0) return 0;
  if (script)
    s->status = handle_script(L, argv, script);
  if (s->status != 0) return 0;
  if (has_i)
    dotty(L);
  else if (script == 0 && !has_e && !has_v) {
    if (lua_stdin_is_tty()) {
      print_version();
      dotty(L);
    }
    else dofile(L, NULL);  /* executes stdin as a file */
  }
  return 0;
}


int __cdecl main (int argc, char **argv) {
  int status;
  struct Smain s;
  lua_State *L = lua_open();  /* create state */
  if (L == NULL) {
    l_message(argv[0], "cannot create state: not enough memory");
    return EXIT_FAILURE;
  }
  s.argc = argc;
  s.argv = argv;
  status = lua_cpcall(L, &pmain, &s);
  report(L, status);
  lua_close(L);
  return (status || s.status) ? EXIT_FAILURE : EXIT_SUCCESS;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lualib.h ===
/*
** $Id: lualib.h,v 1.36 2005/12/27 17:12:00 roberto Exp $
** Lua standard libraries
** See Copyright Notice in lua.h
*/


#ifndef lualib_h
#define lualib_h

#include "lua.h"


/* Key to file-handle type */
#define LUA_FILEHANDLE		"FILE*"


#define LUA_COLIBNAME	"coroutine"
LUALIB_API int (luaopen_base) (lua_State *L);

#define LUA_TABLIBNAME	"table"
LUALIB_API int (luaopen_table) (lua_State *L);

#define LUA_IOLIBNAME	"io"
LUALIB_API int (luaopen_io) (lua_State *L);

#define LUA_OSLIBNAME	"os"
LUALIB_API int (luaopen_os) (lua_State *L);

#define LUA_STRLIBNAME	"string"
LUALIB_API int (luaopen_string) (lua_State *L);

#define LUA_MATHLIBNAME	"math"
LUALIB_API int (luaopen_math) (lua_State *L);

#define LUA_DBLIBNAME	"debug"
LUALIB_API int (luaopen_debug) (lua_State *L);

#define LUA_LOADLIBNAME	"package"
LUALIB_API int (luaopen_package) (lua_State *L);


/* open all previous libraries */
LUALIB_API void (luaL_openlibs) (lua_State *L); 



#ifndef lua_assert
#define lua_assert(x)	((void)0)
#endif


#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lundump.h ===
/*
** $Id: lundump.h,v 1.40 2005/11/11 14:03:13 lhf Exp $
** load precompiled Lua chunks
** See Copyright Notice in lua.h
*/

#ifndef lundump_h
#define lundump_h

#include "lobject.h"
#include "lzio.h"

/* load one chunk; from lundump.c */
LUAI_FUNC Proto* luaU_undump (lua_State* L, ZIO* Z, Mbuffer* buff, const char* name);

/* make header; from lundump.c */
LUAI_FUNC void luaU_header (char* h);

/* dump one chunk; from ldump.c */
LUAI_FUNC int luaU_dump (lua_State* L, const Proto* f, lua_Writer w, void* data, int strip);

#ifdef luac_c
/* print one chunk; from print.c */
LUAI_FUNC void luaU_print (const Proto* f, int full);
#endif

/* for header of binary files -- this is Lua 5.1 */
#define LUAC_VERSION		0x51

/* for header of binary files -- this is the official format */
#define LUAC_FORMAT		0

/* size of header of binary files */
#define LUAC_HEADERSIZE		12

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lundump.c ===
/*
** $Id: lundump.c,v 1.60 2006/02/16 15:53:49 lhf Exp $
** load precompiled Lua chunks
** See Copyright Notice in lua.h
*/

#include <string.h>

#define lundump_c
#define LUA_CORE

#include "lua.h"

#include "ldebug.h"
#include "ldo.h"
#include "lfunc.h"
#include "lmem.h"
#include "lobject.h"
#include "lstring.h"
#include "lundump.h"
#include "lzio.h"

typedef struct {
 lua_State* L;
 ZIO* Z;
 Mbuffer* b;
 const char* name;
} LoadState;

#ifdef LUAC_TRUST_BINARIES
#define IF(c,s)
#else
#define IF(c,s)		if (c) error(S,s)

static void error(LoadState* S, const char* why)
{
 luaO_pushfstring(S->L,"%s: %s in precompiled chunk",S->name,why);
 luaD_throw(S->L,LUA_ERRSYNTAX);
}
#endif

#define LoadMem(S,b,n,size)	LoadBlock(S,b,(n)*(size))
#define	LoadByte(S)		(lu_byte)LoadChar(S)
#define LoadVar(S,x)		LoadMem(S,&x,1,sizeof(x))
#define LoadVector(S,b,n,size)	LoadMem(S,b,n,size)

static void LoadBlock(LoadState* S, void* b, size_t size)
{
 size_t r=luaZ_read(S->Z,b,size);
 IF (r!=0, "unexpected end");
}

static int LoadChar(LoadState* S)
{
 char x;
 LoadVar(S,x);
 return x;
}

static int LoadInt(LoadState* S)
{
 int x;
 LoadVar(S,x);
 IF (x<0, "bad integer");
 return x;
}

static lua_Number LoadNumber(LoadState* S)
{
 lua_Number x;
 LoadVar(S,x);
 return x;
}

static TString* LoadString(LoadState* S)
{
 size_t size;
 LoadVar(S,size);
 if (size==0)
  return NULL;
 else
 {
  char* s=luaZ_openspace(S->L,S->b,size);
  LoadBlock(S,s,size);
  return luaS_newlstr(S->L,s,size-1);		/* remove trailing '\0' */
 }
}

static void LoadCode(LoadState* S, Proto* f)
{
 int n=LoadInt(S);
 f->code=luaM_newvector(S->L,n,Instruction);
 f->sizecode=n;
 LoadVector(S,f->code,n,sizeof(Instruction));
}

static Proto* LoadFunction(LoadState* S, TString* p);

static void LoadConstants(LoadState* S, Proto* f)
{
 int i,n;
 n=LoadInt(S);
 f->k=luaM_newvector(S->L,n,TValue);
 f->sizek=n;
 for (i=0; i<n; i++) setnilvalue(&f->k[i]);
 for (i=0; i<n; i++)
 {
  TValue* o=&f->k[i];
  int t=LoadChar(S);
  switch (t)
  {
   case LUA_TNIL:
   	setnilvalue(o);
	break;
   case LUA_TBOOLEAN:
   	setbvalue(o,LoadChar(S));
	break;
   case LUA_TNUMBER:
	setnvalue(o,LoadNumber(S));
	break;
   case LUA_TSTRING:
	setsvalue2n(S->L,o,LoadString(S));
	break;
   default:
	IF (1, "bad constant");
	break;
  }
 }
 n=LoadInt(S);
 f->p=luaM_newvector(S->L,n,Proto*);
 f->sizep=n;
 for (i=0; i<n; i++) f->p[i]=NULL;
 for (i=0; i<n; i++) f->p[i]=LoadFunction(S,f->source);
}

static void LoadDebug(LoadState* S, Proto* f)
{
 int i,n;
 n=LoadInt(S);
 f->lineinfo=luaM_newvector(S->L,n,int);
 f->sizelineinfo=n;
 LoadVector(S,f->lineinfo,n,sizeof(int));
 n=LoadInt(S);
 f->locvars=luaM_newvector(S->L,n,LocVar);
 f->sizelocvars=n;
 for (i=0; i<n; i++) f->locvars[i].varname=NULL;
 for (i=0; i<n; i++)
 {
  f->locvars[i].varname=LoadString(S);
  f->locvars[i].startpc=LoadInt(S);
  f->locvars[i].endpc=LoadInt(S);
 }
 n=LoadInt(S);
 f->upvalues=luaM_newvector(S->L,n,TString*);
 f->sizeupvalues=n;
 for (i=0; i<n; i++) f->upvalues[i]=NULL;
 for (i=0; i<n; i++) f->upvalues[i]=LoadString(S);
}

static Proto* LoadFunction(LoadState* S, TString* p)
{
 Proto* f=luaF_newproto(S->L);
 setptvalue2s(S->L,S->L->top,f); incr_top(S->L);
 f->source=LoadString(S); if (f->source==NULL) f->source=p;
 f->linedefined=LoadInt(S);
 f->lastlinedefined=LoadInt(S);
 f->nups=LoadByte(S);
 f->numparams=LoadByte(S);
 f->is_vararg=LoadByte(S);
 f->maxstacksize=LoadByte(S);
 LoadCode(S,f);
 LoadConstants(S,f);
 LoadDebug(S,f);
 IF (!luaG_checkcode(f), "bad code");
 S->L->top--;
 return f;
}

static void LoadHeader(LoadState* S)
{
 char h[LUAC_HEADERSIZE];
 char s[LUAC_HEADERSIZE];
 luaU_header(h);
 LoadBlock(S,s,LUAC_HEADERSIZE);
 IF (memcmp(h,s,LUAC_HEADERSIZE)!=0, "bad header");
}

/*
** load precompiled chunk
*/
Proto* luaU_undump (lua_State* L, ZIO* Z, Mbuffer* buff, const char* name)
{
 LoadState S;
 if (*name=='@' || *name=='=')
  S.name=name+1;
 else if (*name==LUA_SIGNATURE[0])
  S.name="binary string";
 else
  S.name=name;
 S.L=L;
 S.Z=Z;
 S.b=buff;
 LoadHeader(&S);
 return LoadFunction(&S,luaS_newliteral(L,"=?"));
}

/*
* make header
*/
void luaU_header (char* h)
{
 int x=1;
 memcpy(h,LUA_SIGNATURE,sizeof(LUA_SIGNATURE)-1);
 h+=sizeof(LUA_SIGNATURE)-1;
 *h++=(char)LUAC_VERSION;
 *h++=(char)LUAC_FORMAT;
 *h++=(char)*(char*)&x;				/* endianness */
 *h++=(char)sizeof(int);
 *h++=(char)sizeof(size_t);
 *h++=(char)sizeof(Instruction);
 *h++=(char)sizeof(lua_Number);
 *h++=(char)(((lua_Number)0.5)==0);		/* is lua_Number integral? */
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lvm.c ===
/*
** $Id: lvm.c,v 2.63 2006/06/05 15:58:59 roberto Exp $
** Lua virtual machine
** See Copyright Notice in lua.h
*/


#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define lvm_c
#define LUA_CORE

#include "lua.h"

#include "ldebug.h"
#include "ldo.h"
#include "lfunc.h"
#include "lgc.h"
#include "lobject.h"
#include "lopcodes.h"
#include "lstate.h"
#include "lstring.h"
#include "ltable.h"
#include "ltm.h"
#include "lvm.h"



/* limit for table tag-method chains (to avoid loops) */
#define MAXTAGLOOP  100


const TValue *luaV_tonumber (const TValue *obj, TValue *n) {
  lua_Number num;
  if (ttisnumber(obj)) return obj;
  if (ttisstring(obj) && luaO_str2d(svalue(obj), &num)) {
    setnvalue(n, num);
    return n;
  }
  if (ttisboolean(obj)) {
    setnvalue(n, bvalue(obj));
    return n;
  }
  return NULL;
}


int luaV_tostring (lua_State *L, StkId obj) {
  if (!ttisnumber(obj))
    return 0;
  else {
    char s[LUAI_MAXNUMBER2STR];
    lua_Number n = nvalue(obj);
    lua_number2str(s, n);
    setsvalue2s(L, obj, luaS_new(L, s));
    return 1;
  }
}


static void traceexec (lua_State *L, const Instruction *pc) {
  lu_byte mask = L->hookmask;
  const Instruction *oldpc = L->savedpc;
  L->savedpc = pc;
  if ((mask & LUA_MASKLINE) && L->hookcount == 0) {
    resethookcount(L);
    luaD_callhook(L, LUA_HOOKCOUNT, -1);
  }
  if (mask & LUA_MASKLINE) {
    Proto *p = ci_func(L->ci)->l.p;
    int npc = pcRel(pc, p);
    int newline = getline(p, npc);
    /* call linehook when enter a new function, when jump back (loop),
       or when enter a new line */
    if (npc == 0 || pc <= oldpc || newline != getline(p, pcRel(oldpc, p)))
      luaD_callhook(L, LUA_HOOKLINE, newline);
  }
}


static void callTMres (lua_State *L, StkId res, const TValue *f,
                        const TValue *p1, const TValue *p2) {
  ptrdiff_t result = savestack(L, res);
  setobj2s(L, L->top, f);  /* push function */
  setobj2s(L, L->top+1, p1);  /* 1st argument */
  setobj2s(L, L->top+2, p2);  /* 2nd argument */
  luaD_checkstack(L, 3);
  L->top += 3;
  luaD_call(L, L->top - 3, 1);
  res = restorestack(L, result);
  L->top--;
  setobjs2s(L, res, L->top);
}



static void callTM (lua_State *L, const TValue *f, const TValue *p1,
                    const TValue *p2, const TValue *p3) {
  setobj2s(L, L->top, f);  /* push function */
  setobj2s(L, L->top+1, p1);  /* 1st argument */
  setobj2s(L, L->top+2, p2);  /* 2nd argument */
  setobj2s(L, L->top+3, p3);  /* 3th argument */
  luaD_checkstack(L, 4);
  L->top += 4;
  luaD_call(L, L->top - 4, 0);
}


void luaV_gettable (lua_State *L, const TValue *t, TValue *key, StkId val) {
  int loop;
  for (loop = 0; loop < MAXTAGLOOP; loop++) {
    const TValue *tm;
    if (ttistable(t)) {  /* `t' is a table? */
      Table *h = hvalue(t);
      const TValue *res = luaH_get(h, key); /* do a primitive get */
      if (!ttisnil(res) ||  /* result is no nil? */
          (tm = fasttm(L, h->metatable, TM_INDEX)) == NULL) { /* or no TM? */
        setobj2s(L, val, res);
        return;
      }
      /* else will try the tag method */
    }
    else if (ttisnil(tm = luaT_gettmbyobj(L, t, TM_INDEX)))
      luaG_typeerror(L, t, "index");
    if (ttisfunction(tm)) {
      callTMres(L, val, tm, t, key);
      return;
    }
    t = tm;  /* else repeat with `tm' */
  }
  luaG_runerror(L, "loop in gettable");
}


void luaV_settable (lua_State *L, const TValue *t, TValue *key, StkId val) {
  int loop;
  for (loop = 0; loop < MAXTAGLOOP; loop++) {
    const TValue *tm;
    if (ttistable(t)) {  /* `t' is a table? */
      Table *h = hvalue(t);
      TValue *oldval = luaH_set(L, h, key); /* do a primitive set */
      if (!ttisnil(oldval) ||  /* result is no nil? */
          (tm = fasttm(L, h->metatable, TM_NEWINDEX)) == NULL) { /* or no TM? */
        setobj2t(L, oldval, val);
        luaC_barriert(L, h, val);
        return;
      }
      /* else will try the tag method */
    }
    else if (ttisnil(tm = luaT_gettmbyobj(L, t, TM_NEWINDEX)))
      luaG_typeerror(L, t, "index");
    if (ttisfunction(tm)) {
      callTM(L, tm, t, key, val);
      return;
    }
    t = tm;  /* else repeat with `tm' */
  }
  luaG_runerror(L, "loop in settable");
}


static int call_binTM (lua_State *L, const TValue *p1, const TValue *p2,
                       StkId res, TMS event) {
  const TValue *tm = luaT_gettmbyobj(L, p1, event);  /* try first operand */
  if (ttisnil(tm))
    tm = luaT_gettmbyobj(L, p2, event);  /* try second operand */
  if (!ttisfunction(tm)) return 0;
  callTMres(L, res, tm, p1, p2);
  return 1;
}


static const TValue *get_compTM (lua_State *L, Table *mt1, Table *mt2,
                                  TMS event) {
  const TValue *tm1 = fasttm(L, mt1, event);
  const TValue *tm2;
  if (tm1 == NULL) return NULL;  /* no metamethod */
  if (mt1 == mt2) return tm1;  /* same metatables => same metamethods */
  tm2 = fasttm(L, mt2, event);
  if (tm2 == NULL) return NULL;  /* no metamethod */
  if (luaO_rawequalObj(tm1, tm2))  /* same metamethods? */
    return tm1;
  return NULL;
}


static int call_orderTM (lua_State *L, const TValue *p1, const TValue *p2,
                         TMS event) {
  const TValue *tm1 = luaT_gettmbyobj(L, p1, event);
  const TValue *tm2;
  if (ttisnil(tm1)) return -1;  /* no metamethod? */
  tm2 = luaT_gettmbyobj(L, p2, event);
  if (!luaO_rawequalObj(tm1, tm2))  /* different metamethods? */
    return -1;
  callTMres(L, L->top, tm1, p1, p2);
  return !l_isfalse(L->top);
}


static int l_strcmp (const TString *ls, const TString *rs) {
  const char *l = getstr(ls);
  size_t ll = ls->tsv.len;
  const char *r = getstr(rs);
  size_t lr = rs->tsv.len;
  for (;;) {
    int temp = strcoll(l, r);
    if (temp != 0) return temp;
    else {  /* strings are equal up to a `\0' */
      size_t len = strlen(l);  /* index of first `\0' in both strings */
      if (len == lr)  /* r is finished? */
        return (len == ll) ? 0 : 1;
      else if (len == ll)  /* l is finished? */
        return -1;  /* l is smaller than r (because r is not finished) */
      /* both strings longer than `len'; go on comparing (after the `\0') */
      len++;
      l += len; ll -= len; r += len; lr -= len;
    }
  }
}


int luaV_lessthan (lua_State *L, const TValue *l, const TValue *r) {
  int res;
  if (ttype(l) != ttype(r))
    return luaG_ordererror(L, l, r);
  else if (ttisnumber(l))
    return luai_numlt(nvalue(l), nvalue(r));
  else if (ttisstring(l))
    return l_strcmp(rawtsvalue(l), rawtsvalue(r)) < 0;
  else if ((res = call_orderTM(L, l, r, TM_LT)) != -1)
    return res;
  return luaG_ordererror(L, l, r);
}


static int lessequal (lua_State *L, const TValue *l, const TValue *r) {
  int res;
  if (ttype(l) != ttype(r))
    return luaG_ordererror(L, l, r);
  else if (ttisnumber(l))
    return luai_numle(nvalue(l), nvalue(r));
  else if (ttisstring(l))
    return l_strcmp(rawtsvalue(l), rawtsvalue(r)) <= 0;
  else if ((res = call_orderTM(L, l, r, TM_LE)) != -1)  /* first try `le' */
    return res;
  else if ((res = call_orderTM(L, r, l, TM_LT)) != -1)  /* else try `lt' */
    return !res;
  return luaG_ordererror(L, l, r);
}


int luaV_equalval (lua_State *L, const TValue *t1, const TValue *t2) {
  const TValue *tm;
  lua_assert(ttype(t1) == ttype(t2));
  switch (ttype(t1)) {
    case LUA_TNIL: return 1;
    case LUA_TNUMBER: return luai_numeq(nvalue(t1), nvalue(t2));
    case LUA_TBOOLEAN: return bvalue(t1) == bvalue(t2);  /* true must be 1 !! */
    case LUA_TLIGHTUSERDATA: return pvalue(t1) == pvalue(t2);
    case LUA_TUSERDATA: {
      if (uvalue(t1) == uvalue(t2)) return 1;
      tm = get_compTM(L, uvalue(t1)->metatable, uvalue(t2)->metatable,
                         TM_EQ);
      break;  /* will try TM */
    }
    case LUA_TTABLE: {
      if (hvalue(t1) == hvalue(t2)) return 1;
      tm = get_compTM(L, hvalue(t1)->metatable, hvalue(t2)->metatable, TM_EQ);
      break;  /* will try TM */
    }
    default: return gcvalue(t1) == gcvalue(t2);
  }
  if (tm == NULL) return 0;  /* no TM? */
  callTMres(L, L->top, tm, t1, t2);  /* call TM */
  return !l_isfalse(L->top);
}


void luaV_concat (lua_State *L, int total, int last) {
  do {
    StkId top = L->base + last + 1;
    int n = 2;  /* number of elements handled in this pass (at least 2) */
    if (!tostring(L, top-2) || !tostring(L, top-1)) {
      if (!call_binTM(L, top-2, top-1, top-2, TM_CONCAT))
        luaG_concaterror(L, top-2, top-1);
    } else if (tsvalue(top-1)->len > 0) {  /* if len=0, do nothing */
      /* at least two string values; get as many as possible */
      size_t tl = tsvalue(top-1)->len;
      char *buffer;
      int i;
      /* collect total length */
      for (n = 1; n < total && tostring(L, top-n-1); n++) {
        size_t l = tsvalue(top-n-1)->len;
        if (l >= MAX_SIZET - tl) luaG_runerror(L, "string length overflow");
        tl += l;
      }
      buffer = luaZ_openspace(L, &G(L)->buff, tl);
      tl = 0;
      for (i=n; i>0; i--) {  /* concat all strings */
        size_t l = tsvalue(top-i)->len;
        memcpy(buffer+tl, svalue(top-i), l);
        tl += l;
      }
      setsvalue2s(L, top-n, luaS_newlstr(L, buffer, tl));
    }
    total -= n-1;  /* got `n' strings to create 1 new */
    last -= n-1;
  } while (total > 1);  /* repeat until only 1 result left */
}


static void Arith (lua_State *L, StkId ra, const TValue *rb,
                   const TValue *rc, TMS op) {
  TValue tempb, tempc;
  const TValue *b, *c;
  if ((b = luaV_tonumber(rb, &tempb)) != NULL &&
      (c = luaV_tonumber(rc, &tempc)) != NULL) {
    lua_Number nb = nvalue(b), nc = nvalue(c);
    switch (op) {
      case TM_ADD: setnvalue(ra, luai_numadd(nb, nc)); break;
      case TM_SUB: setnvalue(ra, luai_numsub(nb, nc)); break;
      case TM_MUL: setnvalue(ra, luai_nummul(nb, nc)); break;
      case TM_DIV: setnvalue(ra, luai_numdiv(nb, nc)); break;
      case TM_MOD: setnvalue(ra, luai_nummod(nb, nc)); break;
      case TM_POW: setnvalue(ra, luai_numpow(nb, nc)); break;
      case TM_UNM: setnvalue(ra, luai_numunm(nb)); break;
      default: lua_assert(0); break;
    }
  }
  else if (!call_binTM(L, rb, rc, ra, op))
    luaG_aritherror(L, rb, rc);
}



/*
** some macros for common tasks in `luaV_execute'
*/

#define runtime_check(L, c) { if (!(c)) break; }

#define RA(i)   (base+GETARG_A(i))
/* to be used after possible stack reallocation */
#define RB(i)   check_exp(getBMode(GET_OPCODE(i)) == OpArgR, base+GETARG_B(i))
#define RC(i)   check_exp(getCMode(GET_OPCODE(i)) == OpArgR, base+GETARG_C(i))
#define RKB(i)  check_exp(getBMode(GET_OPCODE(i)) == OpArgK, \
    ISK(GETARG_B(i)) ? k+INDEXK(GETARG_B(i)) : base+GETARG_B(i))
#define RKC(i)  check_exp(getCMode(GET_OPCODE(i)) == OpArgK, \
    ISK(GETARG_C(i)) ? k+INDEXK(GETARG_C(i)) : base+GETARG_C(i))
#define KBx(i)  check_exp(getBMode(GET_OPCODE(i)) == OpArgK, k+GETARG_Bx(i))


#define dojump(L,pc,i)  {(pc) += (i); luai_threadyield(L);}


#define Protect(x)  { L->savedpc = pc; {x;}; base = L->base; }


#define arith_op(op,tm) { \
        TValue *rb = RKB(i); \
        TValue *rc = RKC(i); \
        if (ttisnumber(rb) && ttisnumber(rc)) { \
          lua_Number nb = nvalue(rb), nc = nvalue(rc); \
          setnvalue(ra, op(nb, nc)); \
        } \
        else \
          Protect(Arith(L, ra, rb, rc, tm)); \
      }



void luaV_execute (lua_State *L, int nexeccalls) {
  LClosure *cl;
  StkId base;
  TValue *k;
  const Instruction *pc;
 reentry:  /* entry point */
  lua_assert(isLua(L->ci));
  pc = L->savedpc;
  cl = &clvalue(L->ci->func)->l;
  base = L->base;
  k = cl->p->k;
  /* main loop of interpreter */
  for (;;) {
    const Instruction i = *pc++;
    StkId ra;
    if ((L->hookmask & (LUA_MASKLINE | LUA_MASKCOUNT)) &&
        (--L->hookcount == 0 || L->hookmask & LUA_MASKLINE)) {
      traceexec(L, pc);
      if (L->status == LUA_YIELD) {  /* did hook yield? */
        L->savedpc = pc - 1;
        return;
      }
      base = L->base;
    }
    /* warning!! several calls may realloc the stack and invalidate `ra' */
    ra = RA(i);
    lua_assert(base == L->base && L->base == L->ci->base);
    lua_assert(base <= L->top && L->top <= L->stack + L->stacksize);
    lua_assert(L->top == L->ci->top || luaG_checkopenop(i));
    switch (GET_OPCODE(i)) {
      case OP_MOVE: {
        setobjs2s(L, ra, RB(i));
        continue;
      }
      case OP_LOADK: {
        setobj2s(L, ra, KBx(i));
        continue;
      }
      case OP_LOADBOOL: {
        setbvalue(ra, GETARG_B(i));
        if (GETARG_C(i)) pc++;  /* skip next instruction (if C) */
        continue;
      }
      case OP_LOADNIL: {
        TValue *rb = RB(i);
        do {
          setnilvalue(rb--);
        } while (rb >= ra);
        continue;
      }
      case OP_GETUPVAL: {
        int b = GETARG_B(i);
        setobj2s(L, ra, cl->upvals[b]->v);
        continue;
      }
      case OP_GETGLOBAL: {
        TValue g;
        TValue *rb = KBx(i);
        sethvalue(L, &g, cl->env);
        lua_assert(ttisstring(rb));
        Protect(luaV_gettable(L, &g, rb, ra));
        continue;
      }
      case OP_GETTABLE: {
        Protect(luaV_gettable(L, RB(i), RKC(i), ra));
        continue;
      }
      case OP_SETGLOBAL: {
        TValue g;
        sethvalue(L, &g, cl->env);
        lua_assert(ttisstring(KBx(i)));
        Protect(luaV_settable(L, &g, KBx(i), ra));
        continue;
      }
      case OP_SETUPVAL: {
        UpVal *uv = cl->upvals[GETARG_B(i)];
        setobj(L, uv->v, ra);
        luaC_barrier(L, uv, ra);
        continue;
      }
      case OP_SETTABLE: {
        Protect(luaV_settable(L, ra, RKB(i), RKC(i)));
        continue;
      }
      case OP_NEWTABLE: {
        int b = GETARG_B(i);
        int c = GETARG_C(i);
        sethvalue(L, ra, luaH_new(L, luaO_fb2int(b), luaO_fb2int(c)));
        Protect(luaC_checkGC(L));
        continue;
      }
      case OP_SELF: {
        StkId rb = RB(i);
        setobjs2s(L, ra+1, rb);
        Protect(luaV_gettable(L, rb, RKC(i), ra));
        continue;
      }
      case OP_ADD: {
        arith_op(luai_numadd, TM_ADD);
        continue;
      }
      case OP_SUB: {
        arith_op(luai_numsub, TM_SUB);
        continue;
      }
      case OP_MUL: {
        arith_op(luai_nummul, TM_MUL);
        continue;
      }
      case OP_DIV: {
        arith_op(luai_numdiv, TM_DIV);
        continue;
      }
      case OP_MOD: {
        arith_op(luai_nummod, TM_MOD);
        continue;
      }
      case OP_POW: {
        arith_op(luai_numpow, TM_POW);
        continue;
      }
      case OP_UNM: {
        TValue *rb = RB(i);
        if (ttisnumber(rb)) {
          lua_Number nb = nvalue(rb);
          setnvalue(ra, luai_numunm(nb));
        }
        else {
          Protect(Arith(L, ra, rb, rb, TM_UNM));
        }
        continue;
      }
      case OP_NOT: {
        int res = l_isfalse(RB(i));  /* next assignment may change this value */
        setbvalue(ra, res);
        continue;
      }
      case OP_LEN: {
        const TValue *rb = RB(i);
        switch (ttype(rb)) {
          case LUA_TTABLE: {
            setnvalue(ra, cast_num(luaH_getn(hvalue(rb))));
            break;
          }
          case LUA_TSTRING: {
            setnvalue(ra, cast_num(tsvalue(rb)->len));
            break;
          }
          default: {  /* try metamethod */
            Protect(
              if (!call_binTM(L, rb, luaO_nilobject, ra, TM_LEN))
                luaG_typeerror(L, rb, "get length of");
            )
          }
        }
        continue;
      }
      case OP_CONCAT: {
        int b = GETARG_B(i);
        int c = GETARG_C(i);
        Protect(luaV_concat(L, c-b+1, c); luaC_checkGC(L));
        setobjs2s(L, RA(i), base+b);
        continue;
      }
      case OP_JMP: {
        dojump(L, pc, GETARG_sBx(i));
        continue;
      }
      case OP_EQ: {
        TValue *rb = RKB(i);
        TValue *rc = RKC(i);
        Protect(
          if (equalobj(L, rb, rc) == GETARG_A(i))
            dojump(L, pc, GETARG_sBx(*pc));
        )
        pc++;
        continue;
      }
      case OP_LT: {
        Protect(
          if (luaV_lessthan(L, RKB(i), RKC(i)) == GETARG_A(i))
            dojump(L, pc, GETARG_sBx(*pc));
        )
        pc++;
        continue;
      }
      case OP_LE: {
        Protect(
          if (lessequal(L, RKB(i), RKC(i)) == GETARG_A(i))
            dojump(L, pc, GETARG_sBx(*pc));
        )
        pc++;
        continue;
      }
      case OP_TEST: {
        if (l_isfalse(ra) != GETARG_C(i))
          dojump(L, pc, GETARG_sBx(*pc));
        pc++;
        continue;
      }
      case OP_TESTSET: {
        TValue *rb = RB(i);
        if (l_isfalse(rb) != GETARG_C(i)) {
          setobjs2s(L, ra, rb);
          dojump(L, pc, GETARG_sBx(*pc));
        }
        pc++;
        continue;
      }
      case OP_CALL: {
        int b = GETARG_B(i);
        int nresults = GETARG_C(i) - 1;
        if (b != 0) L->top = ra+b;  /* else previous instruction set top */
        L->savedpc = pc;
        switch (luaD_precall(L, ra, nresults)) {
          case PCRLUA: {
            nexeccalls++;
            goto reentry;  /* restart luaV_execute over new Lua function */
          }
          case PCRC: {
            /* it was a C function (`precall' called it); adjust results */
            if (nresults >= 0) L->top = L->ci->top;
            base = L->base;
            continue;
          }
          default: {
            return;  /* yield */
          }
        }
      }
      case OP_TAILCALL: {
        int b = GETARG_B(i);
        if (b != 0) L->top = ra+b;  /* else previous instruction set top */
        L->savedpc = pc;
        lua_assert(GETARG_C(i) - 1 == LUA_MULTRET);
        switch (luaD_precall(L, ra, LUA_MULTRET)) {
          case PCRLUA: {
            /* tail call: put new frame in place of previous one */
            CallInfo *ci = L->ci - 1;  /* previous frame */
            int aux;
            StkId func = ci->func;
            StkId pfunc = (ci+1)->func;  /* previous function index */
            if (L->openupval) luaF_close(L, ci->base);
            L->base = ci->base = ci->func + ((ci+1)->base - pfunc);
            for (aux = 0; pfunc+aux < L->top; aux++)  /* move frame down */
              setobjs2s(L, func+aux, pfunc+aux);
            ci->top = L->top = func+aux;  /* correct top */
            lua_assert(L->top == L->base + clvalue(func)->l.p->maxstacksize);
            ci->savedpc = L->savedpc;
            ci->tailcalls++;  /* one more call lost */
            L->ci--;  /* remove new frame */
            goto reentry;
          }
          case PCRC: {  /* it was a C function (`precall' called it) */
            base = L->base;
            continue;
          }
          default: {
            return;  /* yield */
          }
        }
      }
      case OP_RETURN: {
        int b = GETARG_B(i);
        if (b != 0) L->top = ra+b-1;
        if (L->openupval) luaF_close(L, base);
        L->savedpc = pc;
        b = luaD_poscall(L, ra);
        if (--nexeccalls == 0)  /* was previous function running `here'? */
          return;  /* no: return */
        else {  /* yes: continue its execution */
          if (b) L->top = L->ci->top;
          lua_assert(isLua(L->ci));
          lua_assert(GET_OPCODE(*((L->ci)->savedpc - 1)) == OP_CALL);
          goto reentry;
        }
      }
      case OP_FORLOOP: {
        lua_Number step = nvalue(ra+2);
        lua_Number idx = luai_numadd(nvalue(ra), step); /* increment index */
        lua_Number limit = nvalue(ra+1);
        if (luai_numlt(0, step) ? luai_numle(idx, limit)
                                : luai_numle(limit, idx)) {
          dojump(L, pc, GETARG_sBx(i));  /* jump back */
          setnvalue(ra, idx);  /* update internal index... */
          setnvalue(ra+3, idx);  /* ...and external index */
        }
        continue;
      }
      case OP_FORPREP: {
        const TValue *init = ra;
        const TValue *plimit = ra+1;
        const TValue *pstep = ra+2;
        L->savedpc = pc;  /* next steps may throw errors */
        if (!tonumber(init, ra))
          luaG_runerror(L, LUA_QL("for") " initial value must be a number");
        else if (!tonumber(plimit, ra+1))
          luaG_runerror(L, LUA_QL("for") " limit must be a number");
        else if (!tonumber(pstep, ra+2))
          luaG_runerror(L, LUA_QL("for") " step must be a number");
        setnvalue(ra, luai_numsub(nvalue(ra), nvalue(pstep)));
        dojump(L, pc, GETARG_sBx(i));
        continue;
      }
      case OP_TFORLOOP: {
        StkId cb = ra + 3;  /* call base */
        setobjs2s(L, cb+2, ra+2);
        setobjs2s(L, cb+1, ra+1);
        setobjs2s(L, cb, ra);
        L->top = cb+3;  /* func. + 2 args (state and index) */
        Protect(luaD_call(L, cb, GETARG_C(i)));
        L->top = L->ci->top;
        cb = RA(i) + 3;  /* previous call may change the stack */
        if (!ttisnil(cb)) {  /* continue loop? */
          setobjs2s(L, cb-1, cb);  /* save control variable */
          dojump(L, pc, GETARG_sBx(*pc));  /* jump back */
        }
        pc++;
        continue;
      }
      case OP_SETLIST: {
        int n = GETARG_B(i);
        int c = GETARG_C(i);
        int last;
        Table *h;
        if (n == 0) {
          n = cast_int(L->top - ra) - 1;
          L->top = L->ci->top;
        }
        if (c == 0) c = cast_int(*pc++);
        runtime_check(L, ttistable(ra));
        h = hvalue(ra);
        last = ((c-1)*LFIELDS_PER_FLUSH) + n;
        if (last > h->sizearray)  /* needs more space? */
          luaH_resizearray(L, h, last);  /* pre-alloc it at once */
        for (; n > 0; n--) {
          TValue *val = ra+n;
          setobj2t(L, luaH_setnum(L, h, last--), val);
          luaC_barriert(L, h, val);
        }
        continue;
      }
      case OP_CLOSE: {
        luaF_close(L, ra);
        continue;
      }
      case OP_CLOSURE: {
        Proto *p;
        Closure *ncl;
        int nup, j;
        p = cl->p->p[GETARG_Bx(i)];
        nup = p->nups;
        ncl = luaF_newLclosure(L, nup, cl->env);
        ncl->l.p = p;
        for (j=0; j<nup; j++, pc++) {
          if (GET_OPCODE(*pc) == OP_GETUPVAL)
            ncl->l.upvals[j] = cl->upvals[GETARG_B(*pc)];
          else {
            lua_assert(GET_OPCODE(*pc) == OP_MOVE);
            ncl->l.upvals[j] = luaF_findupval(L, base + GETARG_B(*pc));
          }
        }
        setclvalue(L, ra, ncl);
        Protect(luaC_checkGC(L));
        continue;
      }
      case OP_VARARG: {
        int b = GETARG_B(i) - 1;
        int j;
        CallInfo *ci = L->ci;
        int n = cast_int(ci->base - ci->func) - cl->p->numparams - 1;
        if (b == LUA_MULTRET) {
          Protect(luaD_checkstack(L, n));
          ra = RA(i);  /* previous call may change the stack */
          b = n;
          L->top = ra + n;
        }
        for (j = 0; j < b; j++) {
          if (j < n) {
            setobjs2s(L, ra + j, ci->base - n + j);
          }
          else {
            setnilvalue(ra + j);
          }
        }
        continue;
      }
    }
  }
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lzio.h ===
/*
** $Id: lzio.h,v 1.21 2005/05/17 19:49:15 roberto Exp $
** Buffered streams
** See Copyright Notice in lua.h
*/


#ifndef lzio_h
#define lzio_h

#include "lua.h"

#include "lmem.h"


#define EOZ	(-1)			/* end of stream */

typedef struct Zio ZIO;

#define char2int(c)	cast(int, cast(unsigned char, (c)))

#define zgetc(z)  (((z)->n--)>0 ?  char2int(*(z)->p++) : luaZ_fill(z))

typedef struct Mbuffer {
  char *buffer;
  size_t n;
  size_t buffsize;
} Mbuffer;

#define luaZ_initbuffer(L, buff) ((buff)->buffer = NULL, (buff)->buffsize = 0)

#define luaZ_buffer(buff)	((buff)->buffer)
#define luaZ_sizebuffer(buff)	((buff)->buffsize)
#define luaZ_bufflen(buff)	((buff)->n)

#define luaZ_resetbuffer(buff) ((buff)->n = 0)


#define luaZ_resizebuffer(L, buff, size) \
	(luaM_reallocvector(L, (buff)->buffer, (buff)->buffsize, size, char), \
	(buff)->buffsize = size)

#define luaZ_freebuffer(L, buff)	luaZ_resizebuffer(L, buff, 0)


LUAI_FUNC char *luaZ_openspace (lua_State *L, Mbuffer *buff, size_t n);
LUAI_FUNC void luaZ_init (lua_State *L, ZIO *z, lua_Reader reader,
                                        void *data);
LUAI_FUNC size_t luaZ_read (ZIO* z, void* b, size_t n);	/* read next n bytes */
LUAI_FUNC int luaZ_lookahead (ZIO *z);



/* --------- Private Part ------------------ */

struct Zio {
  size_t n;			/* bytes still unread */
  const char *p;		/* current position in buffer */
  lua_Reader reader;
  void* data;			/* additional data */
  lua_State *L;			/* Lua state (for reader) */
};


LUAI_FUNC int luaZ_fill (ZIO *z);

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lib\obj\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_liblua_none_12.4.56.0_none_9464548c378e5803
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=liblua
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9.manifest
XP_MANIFEST_PATH=manifests\x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9.cat
XP_CATALOG_PATH=manifests\x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9.cat
XP_PAYLOAD_PATH=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=liblua,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lzio.c ===
/*
** $Id: lzio.c,v 1.31 2005/06/03 20:15:29 roberto Exp $
** a generic input stream interface
** See Copyright Notice in lua.h
*/


#include <string.h>

#define lzio_c
#define LUA_CORE

#include "lua.h"

#include "llimits.h"
#include "lmem.h"
#include "lstate.h"
#include "lzio.h"


int luaZ_fill (ZIO *z) {
  size_t size;
  lua_State *L = z->L;
  const char *buff;
  lua_unlock(L);
  buff = z->reader(L, z->data, &size);
  lua_lock(L);
  if (buff == NULL || size == 0) return EOZ;
  z->n = size - 1;
  z->p = buff;
  return char2int(*(z->p++));
}


int luaZ_lookahead (ZIO *z) {
  if (z->n == 0) {
    if (luaZ_fill(z) == EOZ)
      return EOZ;
    else {
      z->n++;  /* luaZ_fill removed first byte; put back it */
      z->p--;
    }
  }
  return char2int(*z->p);
}


void luaZ_init (lua_State *L, ZIO *z, lua_Reader reader, void *data) {
  z->L = L;
  z->reader = reader;
  z->data = data;
  z->n = 0;
  z->p = NULL;
}


/* --------------------------------------------------------------- read --- */
size_t luaZ_read (ZIO *z, void *b, size_t n) {
  while (n) {
    size_t m;
    if (luaZ_lookahead(z) == EOZ)
      return n;  /* return number of missing bytes */
    m = (n <= z->n) ? n : z->n;  /* min. between n and z->n */
    memcpy(b, z->p, m);
    z->n -= m;
    z->p += m;
    b = (char *)b + m;
    n -= m;
  }
  return 0;
}

/* ------------------------------------------------------------------------ */
char *luaZ_openspace (lua_State *L, Mbuffer *buff, size_t n) {
  if (n > buff->buffsize) {
    if (n < LUA_MINBUFFER) n = LUA_MINBUFFER;
    luaZ_resizebuffer(L, buff, n);
  }
  return buff->buffer;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lvm.h ===
/*
** $Id: lvm.h,v 2.5 2005/08/22 18:54:49 roberto Exp $
** Lua virtual machine
** See Copyright Notice in lua.h
*/

#ifndef lvm_h
#define lvm_h


#include "ldo.h"
#include "lobject.h"
#include "ltm.h"


#define tostring(L,o) ((ttype(o) == LUA_TSTRING) || (luaV_tostring(L, o)))

#define tonumber(o,n)	(ttype(o) == LUA_TNUMBER || \
                         (((o) = luaV_tonumber(o,n)) != NULL))

#define equalobj(L,o1,o2) \
	(ttype(o1) == ttype(o2) && luaV_equalval(L, o1, o2))


LUAI_FUNC int luaV_lessthan (lua_State *L, const TValue *l, const TValue *r);
LUAI_FUNC int luaV_equalval (lua_State *L, const TValue *t1, const TValue *t2);
LUAI_FUNC const TValue *luaV_tonumber (const TValue *obj, TValue *n);
LUAI_FUNC int luaV_tostring (lua_State *L, StkId obj);
LUAI_FUNC void luaV_gettable (lua_State *L, const TValue *t, TValue *key,
                                            StkId val);
LUAI_FUNC void luaV_settable (lua_State *L, const TValue *t, TValue *key,
                                            StkId val);
LUAI_FUNC void luaV_execute (lua_State *L, int nexeccalls);
LUAI_FUNC void luaV_concat (lua_State *L, int total, int last);

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\print.c ===
/*
** $Id: print.c,v 1.55 2006/05/31 13:30:05 lhf Exp $
** print bytecodes
** See Copyright Notice in lua.h
*/

#include <ctype.h>
#include <stdio.h>

#define luac_c
#define LUA_CORE

#include "ldebug.h"
#include "lobject.h"
#include "lopcodes.h"
#include "lundump.h"

#define PrintFunction	luaU_print

#define Sizeof(x)	((int)sizeof(x))
#define VOID(p)		((const void*)(p))

static void PrintString(const TString* ts)
{
 const char* s=getstr(ts);
 int n=ts->tsv.len;
 int i;
 putchar('"');
 for (i=0; i<n; i++)
 {
  int c=s[i];
  switch (c)
  {
   case '"': printf("\\\""); break;
   case '\a': printf("\\a"); break;
   case '\b': printf("\\b"); break;
   case '\f': printf("\\f"); break;
   case '\n': printf("\\n"); break;
   case '\r': printf("\\r"); break;
   case '\t': printf("\\t"); break;
   case '\v': printf("\\v"); break;
   default:	if (isprint((unsigned char)c))
   			putchar(c);
		else
			printf("\\%03u",(unsigned char)c);
  }
 }
 putchar('"');
}

static void PrintConstant(const Proto* f, int i)
{
 const TValue* o=&f->k[i];
 switch (ttype(o))
 {
  case LUA_TNIL:
	printf("nil");
	break;
  case LUA_TBOOLEAN:
	printf(bvalue(o) ? "true" : "false");
	break;
  case LUA_TNUMBER:
	printf(LUA_NUMBER_FMT,nvalue(o));
	break;
  case LUA_TSTRING:
	PrintString(rawtsvalue(o));
	break;
  default:				/* cannot happen */
	printf("? type=%d",ttype(o));
	break;
 }
}

static void PrintCode(const Proto* f)
{
 const Instruction* code=f->code;
 int pc,n=f->sizecode;
 for (pc=0; pc<n; pc++)
 {
  Instruction i=code[pc];
  OpCode o=GET_OPCODE(i);
  int a=GETARG_A(i);
  int b=GETARG_B(i);
  int c=GETARG_C(i);
  int bx=GETARG_Bx(i);
  int sbx=GETARG_sBx(i);
  int line=getline(f,pc);
  printf("\t%d\t",pc+1);
  if (line>0) printf("[%d]\t",line); else printf("[-]\t");
  printf("%-9s\t",luaP_opnames[o]);
  switch (getOpMode(o))
  {
   case iABC:
    printf("%d",a);
    if (getBMode(o)!=OpArgN) printf(" %d",ISK(b) ? (-1-INDEXK(b)) : b);
    if (getCMode(o)!=OpArgN) printf(" %d",ISK(c) ? (-1-INDEXK(c)) : c);
    break;
   case iABx:
    if (getBMode(o)==OpArgK) printf("%d %d",a,-1-bx); else printf("%d %d",a,bx);
    break;
   case iAsBx:
    if (o==OP_JMP) printf("%d",sbx); else printf("%d %d",a,sbx);
    break;
  }
  switch (o)
  {
   case OP_LOADK:
    printf("\t; "); PrintConstant(f,bx);
    break;
   case OP_GETUPVAL:
   case OP_SETUPVAL:
    printf("\t; %s", (f->sizeupvalues>0) ? getstr(f->upvalues[b]) : "-");
    break;
   case OP_GETGLOBAL:
   case OP_SETGLOBAL:
    printf("\t; %s",svalue(&f->k[bx]));
    break;
   case OP_GETTABLE:
   case OP_SELF:
    if (ISK(c)) { printf("\t; "); PrintConstant(f,INDEXK(c)); }
    break;
   case OP_SETTABLE:
   case OP_ADD:
   case OP_SUB:
   case OP_MUL:
   case OP_DIV:
   case OP_POW:
   case OP_EQ:
   case OP_LT:
   case OP_LE:
    if (ISK(b) || ISK(c))
    {
     printf("\t; ");
     if (ISK(b)) PrintConstant(f,INDEXK(b)); else printf("-");
     printf(" ");
     if (ISK(c)) PrintConstant(f,INDEXK(c)); else printf("-");
    }
    break;
   case OP_JMP:
   case OP_FORLOOP:
   case OP_FORPREP:
    printf("\t; to %d",sbx+pc+2);
    break;
   case OP_CLOSURE:
    printf("\t; %p",VOID(f->p[bx]));
    break;
   case OP_SETLIST:
    if (c==0) printf("\t; %d",(int)code[++pc]);
    else printf("\t; %d",c);
    break;
   default:
    break;
  }
  printf("\n");
 }
}

#define SS(x)	(x==1)?"":"s"
#define S(x)	x,SS(x)

static void PrintHeader(const Proto* f)
{
 const char* s=getstr(f->source);
 if (*s=='@' || *s=='=')
  s++;
 else if (*s==LUA_SIGNATURE[0])
  s="(bstring)";
 else
  s="(string)";
 printf("\n%s <%s:%d,%d> (%d instruction%s, %d bytes at %p)\n",
 	(f->linedefined==0)?"main":"function",s,
	f->linedefined,f->lastlinedefined,
	S(f->sizecode),f->sizecode*Sizeof(Instruction),VOID(f));
 printf("%d%s param%s, %d slot%s, %d upvalue%s, ",
	f->numparams,f->is_vararg?"+":"",SS(f->numparams),
	S(f->maxstacksize),S(f->nups));
 printf("%d local%s, %d constant%s, %d function%s\n",
	S(f->sizelocvars),S(f->sizek),S(f->sizep));
}

static void PrintConstants(const Proto* f)
{
 int i,n=f->sizek;
 printf("constants (%d) for %p:\n",n,VOID(f));
 for (i=0; i<n; i++)
 {
  printf("\t%d\t",i+1);
  PrintConstant(f,i);
  printf("\n");
 }
}

static void PrintLocals(const Proto* f)
{
 int i,n=f->sizelocvars;
 printf("locals (%d) for %p:\n",n,VOID(f));
 for (i=0; i<n; i++)
 {
  printf("\t%d\t%s\t%d\t%d\n",
  i,getstr(f->locvars[i].varname),f->locvars[i].startpc+1,f->locvars[i].endpc+1);
 }
}

static void PrintUpvalues(const Proto* f)
{
 int i,n=f->sizeupvalues;
 printf("upvalues (%d) for %p:\n",n,VOID(f));
 if (f->upvalues==NULL) return;
 for (i=0; i<n; i++)
 {
  printf("\t%d\t%s\n",i,getstr(f->upvalues[i]));
 }
}

void PrintFunction(const Proto* f, int full)
{
 int i,n=f->sizep;
 PrintHeader(f);
 PrintCode(f);
 if (full)
 {
  PrintConstants(f);
  PrintLocals(f);
  PrintUpvalues(f);
 }
 for (i=0; i<n; i++) PrintFunction(f->p[i],full);
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lib\objd\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_liblua_none_12.4.56.0_none_9464548c378e5803
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=liblua
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9.manifest
XP_MANIFEST_PATH=manifests\x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9.cat
XP_CATALOG_PATH=manifests\x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9.cat
XP_PAYLOAD_PATH=x86_liblua_no-public-key_12.4.56.0_x-ww_d43976e9
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=liblua,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lua\obj\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_lua_none_12.4.56.0_none_b4da9323193799b2
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=lua
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e.manifest
XP_MANIFEST_PATH=manifests\x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e.cat
XP_CATALOG_PATH=manifests\x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e.cat
XP_PAYLOAD_PATH=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=lua,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\lua\objd\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_lua_none_12.4.56.0_none_b4da9323193799b2
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=lua
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e.manifest
XP_MANIFEST_PATH=manifests\x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e.cat
XP_CATALOG_PATH=manifests\x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e.cat
XP_PAYLOAD_PATH=x86_lua_no-public-key_12.4.56.0_x-ww_a1499d2e
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=lua,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\lua\src\sg\sg.c ===
/*
** $Id: lua.c,v 1.160 2006/06/02 15:34:00 roberto Exp $
** Lua stand-alone interpreter
** See Copyright Notice in lua.h
*/


#include <signal.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define lua_c

#ifdef __cplusplus
extern "C" {
#endif

#include "lua.h"
#include "lauxlib.h"
#include "lualib.h"

#ifdef __cplusplus
}
#endif

//
// Debug Routines
//
static void stack_dump(lua_State *L, char *msg)
{
    int i;
    int top = lua_gettop(L);

    if (msg != NULL)
    {
        printf("%s: ",msg);
    }

    for (i = 1; i <= top; i++)
    {
        int t = lua_type(L, i);
        switch (t)
        {
        case LUA_TSTRING:
            printf("%d:'%s' ", i, lua_tostring(L,i));
            break;
        case LUA_TBOOLEAN:
            printf("%d:%s ", i, lua_toboolean(L, i) ? "true" : "false" );
            break;
        case LUA_TNUMBER:
            printf("%d:%g ", i, lua_tonumber(L, i) );
            break;
        default:
            printf("%d:<%s> ", i, lua_typename(L, t));
            break;
        }
    }

    printf("\n");
}

//
// Thunks
//
#define INLINE __inline
typedef unsigned char   UCHAR;
typedef unsigned short  USHORT;
typedef unsigned long   ULONG;
typedef unsigned _int64 ULONGLONG;
typedef UCHAR     BYTE;
typedef USHORT    WORD;
typedef ULONG     DWORD;
typedef ULONGLONG QWORD;
typedef BYTE      BOOLEAN;
#define FALSE     0
#define TRUE      1

//
// Endian Routines
//
#define HTONL_(ul) \
    ((ULONG)((((ul) >> 24) & 0x000000FFL) | (((ul) >>  8) & 0x0000FF00L) | \
             (((ul) <<  8) & 0x00FF0000L) | (((ul) << 24))))

#define NTOHL_(ul) HTONL_(ul)

#define HTONS_(us) \
    ((USHORT)((((us) >> 8) & 0x00FF) | (((us) << 8) & 0xFF00)))

#define NTOHS_(us) HTONS_(us)


INLINE ULONG HTONL(ULONG ul) { return (HTONL_(ul)); }
INLINE ULONG NTOHL(ULONG ul) { return (NTOHL_(ul)); }
INLINE USHORT HTONS(USHORT us) { return (HTONS_(us)); }
INLINE USHORT NTOHS(USHORT us) { return (NTOHS_(us)); }

//
// SG LUA Buffer Implementation
//
typedef struct {
    DWORD    _cbBuffer;
    BYTE    *_pbBuffer;
    BOOLEAN  _bReadOnly;
} SgLuaBuffer;

SgLuaBuffer *SgLuaBufferToPointer(lua_State *L, int narg );
static int SgLuaBufferLogicElement(lua_State *L,DWORD elemSize, BOOLEAN bNetwork, BOOLEAN bAnd);
static int SgLuaBufferAnd(lua_State *L);
static int SgLuaBufferAndWord(lua_State *L);
static int SgLuaBufferAndWordN(lua_State *L);
static int SgLuaBufferAndDWord(lua_State *L);
static int SgLuaBufferAndDWordN(lua_State *L);
static int SgLuaBufferAndQWord(lua_State *L);
static int SgLuaBufferAndQWordN(lua_State *L);
static int SgLuaBufferCopy(lua_State *L);
static int SgLuaBufferGet(lua_State *L);
static int SgLuaBufferGetElement(lua_State *L, DWORD elemSize, BOOLEAN bNetwork);
static int SgLuaBufferGetWord(lua_State *L);
static int SgLuaBufferGetDWord(lua_State *L);
static int SgLuaBufferGetQWord(lua_State *L);
static int SgLuaBufferGetWordN(lua_State *L);
static int SgLuaBufferGetDWordN(lua_State *L);
static int SgLuaBufferGetQWordN(lua_State *L);
static int SgLuaBufferNew(lua_State *L);
static int SgLuaBufferOr(lua_State *L);
static int SgLuaBufferOrWord(lua_State *L);
static int SgLuaBufferOrWordN(lua_State *L);
static int SgLuaBufferOrDWord(lua_State *L);
static int SgLuaBufferOrWordN(lua_State *L);
static int SgLuaBufferOrQWord(lua_State *L);
static int SgLuaBufferOrQWordN(lua_State *L);
static int SgLuaBufferReadOnly(lua_State *L, BYTE *pbBuffer,DWORD cbBuffer);
static int SgLuaBufferSet(lua_State *L);
static int SgLuaBufferSetElement(lua_State *L, DWORD elemSize, BOOLEAN bNetwork);
static int SgLuaBufferSetWord(lua_State *L);
static int SgLuaBufferSetDWord(lua_State *L);
static int SgLuaBufferSetQWord(lua_State *L);
static int SgLuaBufferSetWordN(lua_State *L);
static int SgLuaBufferSetDWordN(lua_State *L);
static int SgLuaBufferSetQWordN(lua_State *L);
static int SgLuaBufferSize(lua_State *L);
static int SgLuaBufferToString(lua_State *L);

// ----------------------------------------------------------------------------------------
// SG Binary Class
// ----------------------------------------------------------------------------------------

static int SgLuaBinaryAnd(lua_State *L)
{
    ULONGLONG num1;
    ULONGLONG num2;

    //
    // Argument check
    //
    if (lua_gettop(L) < 2)
    {
        return luaL_error(L,"bAnd(<num1>,<num2>) - too few arguments");
    }

    //
    // Read the parameters
    //
    num1 = (ULONGLONG) luaL_checknumber(L,1);
    num2 = (ULONGLONG) luaL_checknumber(L,2);
    printf("%I64x & %I64x = %I64x\n", num1, num2, (num1 & num2) );

    //
    // Operation
    //
    num1 &= num2;

    //
    // return value
    //
    lua_pushinteger(L, (lua_Integer) num1);
    return 1;
}

static int SgLuaBinaryOr(lua_State *L)
{
    ULONGLONG num1;
    ULONGLONG num2;

    //
    // Argument check
    //
    if (lua_gettop(L) < 2)
    {
        return luaL_error(L,"bOr(<num1>,<num2>) - too few arguments");
    }

    //
    // Read the parameters
    //
    num1 = (ULONGLONG) luaL_checknumber(L,1);
    num2 = (ULONGLONG) luaL_checknumber(L,2);
    printf("%I64x | %I64x = %I64x\n", num1, num2, (num1 | num2) );

    //
    // Operation
    //
    num1 |= num2;

    //
    // return value
    //
    lua_pushinteger(L, (lua_Integer) num1);
    return 1;
}

static int SgLuaBinaryXor(lua_State *L)
{
    ULONGLONG num1;
    ULONGLONG num2;

    //
    // Argument check
    //
    if (lua_gettop(L) < 2)
    {
        return luaL_error(L,"bXor(<num1>,<num2>) - too few arguments");
    }

    //
    // Read the parameters
    //
    num1 = (ULONGLONG) luaL_checknumber(L,1);
    num2 = (ULONGLONG) luaL_checknumber(L,2);
    printf("%I64x ^ %I64x = %I64x\n", num1, num2, (num1 ^ num2) );

    //
    // Operation
    //
    num1 ^= num2;

    //
    // return value
    //
    lua_pushinteger(L, (lua_Integer) num1);
    return 1;
}

static int SgLuaBinaryNot(lua_State *L)
{
    ULONGLONG num;

    //
    // Argument check
    //
    if (lua_gettop(L) < 1)
    {
        return luaL_error(L,"bNot(<num1>) - too few arguments");
    }

    //
    // Read the parameters
    //
    num = (ULONGLONG) luaL_checknumber(L,1);
    printf("~%I64x = %I64x\n", num, ~num );

    //
    // Operation
    //
    num = ~num;

    //
    // return value
    //
    lua_pushinteger(L, (lua_Integer) num);
    return 1;
}

// ----------------------------------------------------------------------------------------
// SG Buffer Class
// ----------------------------------------------------------------------------------------

static SgLuaBuffer *SgLuaBufferToPointer(lua_State *L, int narg)
//
// Worker routine to find the userdata from the stack
//
{
    void *b = luaL_checkudata( L, narg, "SG.Buffer" );
    luaL_argcheck(L, b != NULL, narg, "'SG.Buffer' expected");
    return (SgLuaBuffer *)b;
}

static int SgLuaBufferNew(lua_State *L)
//
// Sample Usage: a = SgBuffer.new(1024);
// Sample Usage: a = SgBUffer.new('0x123456789abcdef')
// Sample Usage: a = SbBuffer.new('0x123456789abcdef',true)
//
{
    const char  *luaString = NULL;
    int          luaBoolean = FALSE;
    int          luaType;
    size_t       cbBytes;
    size_t       cbBuffer;
    SgLuaBuffer *b;

    stack_dump(L,"New - Enter");

    //
    // Make sure that the lua stack has at least one element
    //
    if (lua_gettop(L) == 0)
    {
        return luaL_error(L,"New: called with 0 arguments");
    }

    //
    // The argument we want is at stack location (1). This can be either
    // a LUA_TSTRING or a LUA_TNUMBER
    //
    luaType = lua_type(L,1);
    if (luaType != LUA_TNUMBER && luaType != LUA_TSTRING)
    {
        return luaL_error(L,"New: argument 0 is type %s", lua_typename(L,luaType));
    }

    //
    // Look at the argument to see how big of a buffer is required
    //
    if (luaType == LUA_TNUMBER)
    {
        //
        // Make sure that we have integer at the top of the stack
        //
        cbBuffer = luaL_checkint(L, 1);
    }
    else
    {
        //
        // Get a pointer to the string. This string is in hex format and null
        // terminated. So the real amount of space required by the buffer
        // is (cbBuffer / 2)
        //
        luaString = lua_tolstring( L, 1, &cbBuffer );
        
        //
        // Make sure that the string is correctly sized
        //
        luaL_argcheck(
            L,
            (cbBuffer % 2 == 0),
            1,
            "New: string is not a multiple of 2"
            );
        luaL_argcheck(
            L,
            cbBuffer >= 2,
            1,
            "New: string must contain at least 1 byte"
            );

        cbBuffer = (cbBuffer / 2);
    }

    //
    // See if we have anything at index 2
    //
    if (lua_gettop(L) >= 2)
    {
        //
        // Yes. This will control wether or not we are readonly
        //
        luaBoolean = lua_toboolean( L, 2 );
    }

    //
    // Calculate the number of bytes we need for the array
    //
    cbBytes = sizeof(SgLuaBuffer) + cbBuffer * sizeof(char);

    //
    // Allocate the userdata and set the metable for it
    //
    b = (SgLuaBuffer *) lua_newuserdata(L, cbBytes );
    luaL_getmetatable(L, "SG.Buffer" );
    lua_setmetatable(L, -2);

    //
    // Set the user buffer to empty bytes and setup the pointer to the
    // buffer array
    //
    memset( b, 0, sizeof(SgLuaBuffer) );
    b->_cbBuffer = cbBuffer;
    b->_pbBuffer = (char *) (b + 1);
    b->_bReadOnly = (BOOLEAN) (luaBoolean ? TRUE : FALSE);

    //
    // Initialize the buffer properly
    //
    if (luaType == LUA_TNUMBER)
    {
        //
        // Zero the buffer
        //
        memset( b->_pbBuffer, 0, cbBuffer );
    }
    else
    {
        BYTE *pb = b->_pbBuffer;

        //
        // Convert the string to hexidecimal
        //
        for (; cbBuffer > 0; --cbBuffer, ++pb )
        {
            BYTE bValue = 0;
            int i;

            for (i = 0; i < 2; i++)
            {
                bValue <<= 4;
                if (*luaString >= '0' && *luaString <= '9')
                {
                    bValue |= (*luaString - '0');
                }
                else if (*luaString >= 'a' && *luaString <= 'f')
                {
                    bValue |= (*luaString - 'a') + 10;
                }
                else if (*luaString >= 'A' && *luaString <= 'F')
                {
                    bValue |= (*luaString - 'A') + 10;
                }
                else
                {
                    return luaL_error(L, "New: string contains non-hex character");
                }
                luaString++;
            }
            *pb = bValue;
        }
    }

    stack_dump(L, "New - Exit");

    //
    // new userdata on the stack
    //
    return 1;
}

static int SgLuaBufferCompare(lua_State *L)
//
// Sample Usage: SgBuffer.compare(ToBuffer, ToOffset, FromBuffer, FromOffset, Length )
//
{
    int         result;
    ULONG       toIndex;
    ULONG       fromIndex;
    ULONG       length;
    SgLuaBuffer *to;
    SgLuaBuffer *from;

    //
    // Argument check
    //
    if (lua_gettop(L) < 5)
    {
        return luaL_error(L,"compare(to,tooffset,from,fromoffset,length) - too few arguments");
    }

    //
    // 5 Length of the buffer to copy
    //
    length = luaL_checkint(L, 5 );

    //
    // 4 FromOffset
    //
    fromIndex = luaL_checkint(L, 4 );

    //
    // 3 From Buffer
    //
    from = SgLuaBufferToPointer(L, 3 );

    //
    // 2 ToOffset
    //
    toIndex = luaL_checkint(L, 2 );

    //
    // 1 To
    //
    to = SgLuaBufferToPointer(L, 1 );

    //
    // Argument checks
    //
    luaL_argcheck(
        L,
        toIndex + length <= to->_cbBuffer,
        2,
        "index out of bounds for to buffer"
        );
    luaL_argcheck(
        L,
        fromIndex + length <= from->_cbBuffer,
        4,
        "index out of bounds for from buffer"
        );

    //
    // Compare the memory
    //
    result = memcmp( 
        to->_pbBuffer + toIndex,
        from->_pbBuffer + fromIndex,
        length
        );

    //
    // Answer pushed onto the stack
    //
    lua_pushinteger( L, result );
    return 1;
}

static int SgLuaBufferCopy(lua_State *L)
//
// Sample Usage: SgBuffer.copy(ToBuffer, ToOffset, FromBuffer, FromOffset, Length )
//
{
    int         stackTop = -1;
    ULONG       toIndex;
    ULONG       fromIndex;
    ULONG       length;
    SgLuaBuffer *to;
    SgLuaBuffer *from;

    //
    // Argument check
    //
    if (lua_gettop(L) < 5)
    {
        return luaL_error(L,"copy(to,tooffset,from,fromoffset,length) - too few arguments");
    }

    //
    // 5 Length of the buffer to copy
    //
    length = luaL_checkint(L, 5 );

    //
    // 4 FromOffset
    //
    fromIndex = luaL_checkint(L, 4 );

    //
    // 3 From Buffer
    //
    from = SgLuaBufferToPointer(L, 3 );

    //
    // 2 ToOffset
    //
    toIndex = luaL_checkint(L, 2 );

    //
    // 1 To
    //
    to = SgLuaBufferToPointer(L, 1 );

    //
    // Argument checks
    //
    luaL_argcheck(
        L,
        to->_bReadOnly == FALSE,
        1,
        "destination buffer is read-only"
        );
    luaL_argcheck(
        L,
        toIndex + length <= to->_cbBuffer,
        2,
        "destination buffer too small"
        );
    luaL_argcheck(
        L,
        fromIndex + length <= from->_cbBuffer,
        4,
        "index out of bounds for from buffer"
        );

    //
    // Copy the memory
    //
    memcpy( 
        to->_pbBuffer + toIndex,
        from->_pbBuffer + fromIndex,
        length
        );

    //
    // Nothing pushed onto the stack
    //
    return 0;
}

static int SgLuaBufferInitialize( lua_State *L, BYTE *pbBuffer, DWORD cbBuffer )
{
    size_t       cbBytes;
    SgLuaBuffer *b; 

    //
    // Calculate the number of bytes we need for the record pointer
    //
    cbBytes = sizeof(SgLuaBuffer);

    //
    // Allocate the user data and set the metatable for it
    //
    b = (SgLuaBuffer *) lua_newuserdata(L, cbBytes );
    luaL_getmetatable(L, "SG.Buffer" );
    lua_setmetatable(L, -2);

    //
    // Setup the user buffer to point to the supplied pointer and set it to
    // read only mode
    //
    b->_pbBuffer = pbBuffer;
    b->_cbBuffer = cbBuffer;
    b->_bReadOnly = TRUE;

    //
    // new user data on the stack
    //
    return 1;
}

static int SgLuaBufferLogicElement(lua_State *L, DWORD elemSize, BOOLEAN bNetwork, BOOLEAN bAnd)
//
// Worker routine for :and()
//
{
    int         retNum = 1;
    QWORD       mask1;
    QWORD       mask2;
    DWORD       value1;
    DWORD       value2;
    DWORD       index;
    SgLuaBuffer *b;

    stack_dump(L, "AndElement - Enter");

    //
    // Param -> Optional Value for size 8 sets
    //
    if (elemSize == 8)
    {
        if (lua_gettop(L) < 4)
        {
            return luaL_error(L,"logic(offset,lowdword,highdword) - too few arguments");
        }
        mask2 = (QWORD) luaL_checknumber(L, 4 );
    }
    else
    {
        if (lua_gettop(L) < 3)
        {
            return luaL_error(L,"logic(offset,number) - too few arguments");
        }
    }

    //
    // Param -> Value to set
    //
    mask1 = (QWORD) luaL_checknumber(L, 3 );

    //
    // 2 Param -> Index to read from
    //
    index = luaL_checkint(L, 2 );

    //
    // 1 Param -> Buffer to read from
    //
    b = SgLuaBufferToPointer(L, 1 );

    //
    // Range Check
    //
    luaL_argcheck(
        L,
        b->_cbBuffer >= elemSize && index < (b->_cbBuffer - (elemSize - 1)),
        2,
        "index out of range"
        );

    //
    // Answer depends on element size
    //
    switch (elemSize)
    {
    case 2:
        value1 =  * ( (USHORT *) (b->_pbBuffer + index)   );
        if (bNetwork)
        {
            value1 = HTONS( (USHORT) value1 );
        }
        if (bAnd)
        {
            value1 &= (USHORT) mask1;
        }
        else
        {
            value1 |= (USHORT) mask1;
        }
        break;
    case 4:
        value1 = * ( (ULONG *)   (b->_pbBuffer + index)   );
        if (bNetwork)
        {
            value1 = HTONL( value1 );
        }
        if (bAnd)
        {
            value1 &= (ULONG) mask1;
        }
        else
        {
            value1 |= (ULONG) mask1;
        }
        break;
    case 8:
        value1 = * ( (ULONG *)  (b->_pbBuffer + index)    );
        value2 = * ( (ULONG *)  (b->_pbBuffer + index) + 1);
        if (bNetwork)
        {
            DWORD temp = value2;

            value2 = HTONL( value1 );
            value1 = HTONL( temp );
        }
        if (bAnd)
        {
            value1 &= (ULONG) mask1;
            value2 &= (ULONG) mask2;
        }
        else
        {
            value1 |= (ULONG) mask1;
            value2 |= (ULONG) mask2;
        }
        break;
    default:
        value1 = * ( (UCHAR *)  (b->_pbBuffer + index)    );
        if (bAnd)
        {
            value1 &= (UCHAR) mask1;
        }
        else
        {
            value1 |= (UCHAR) mask1;
        }
        break;
    }

    //
    // Push the answers onto the stack
    //
    lua_pushinteger(L, value1 );
    if (elemSize == 8)
    {
        lua_pushinteger(L, value2);
        retNum = 2;
    }

    stack_dump(L, "LogicElement - Exit");

    //
    // 1 or 2 Numbers pushed onto the stack
    //
    return retNum;
}

static int SgLuaBufferAnd(lua_State *L)
//
// Sample Usage: a = SgBuffer:and(1,0x70);
//
{
    return SgLuaBufferLogicElement(L, 1, FALSE, TRUE);
}

static int SgLuaBufferAndWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:andword(1,0x7070);
//
{
    return SgLuaBufferLogicElement(L, 2, FALSE, TRUE);
}

static int SgLuaBufferAndWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:andwordn(1,0x7070);
//
{
    return SgLuaBufferLogicElement(L, 2, TRUE, TRUE);
}

static int SgLuaBufferAndDWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:anddword(1,0x70707070);
//
{
    return SgLuaBufferLogicElement(L, 4, FALSE, TRUE);
}

static int SgLuaBufferAndDWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:anddwordn(1,0x70707070);
//
{
    return SgLuaBufferLogicElement(L, 4, TRUE, TRUE);
}

static int SgLuaBufferAndQWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:andqword(1,0x70707070,0x70707070);
//
{
    return SgLuaBufferLogicElement(L, 8, FALSE, TRUE);
}

static int SgLuaBufferAndQWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:andqword(1,0x70707070,0x70707070);
//
{
    return SgLuaBufferLogicElement(L, 8, TRUE, TRUE);
}

static int SgLuaBufferOr(lua_State *L)
//
// Sample Usage: a = SgBuffer:or(1,0x70);
//
{
    return SgLuaBufferLogicElement(L, 1, FALSE, FALSE);
}

static int SgLuaBufferOrWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:orword(1,0x7070);
//
{
    return SgLuaBufferLogicElement(L, 2, FALSE, FALSE);
}

static int SgLuaBufferOrWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:orwordn(1,0x7070);
//
{
    return SgLuaBufferLogicElement(L, 2, TRUE, FALSE);
}

static int SgLuaBufferOrDWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:ordword(1,0x70707070);
//
{
    return SgLuaBufferLogicElement(L, 4, FALSE, FALSE);
}

static int SgLuaBufferOrDWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:ordwordn(1,0x70707070);
//
{
    return SgLuaBufferLogicElement(L, 4, TRUE, FALSE);
}

static int SgLuaBufferOrQWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:orqword(1,0x70707070,0x70707070);
//
{
    return SgLuaBufferLogicElement(L, 8, FALSE, FALSE);
}

static int SgLuaBufferOrQWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:orqword(1,0x70707070,0x70707070);
//
{
    return SgLuaBufferLogicElement(L, 8, TRUE, FALSE);
}

static int SgLuaBufferGetElement(lua_State *L, DWORD elemSize, BOOLEAN bNetwork)
//
// Worker routine for :get()
//
{
    int         retNum = 1;
    DWORD       index;
    DWORD       value1;
    DWORD       value2;
    SgLuaBuffer *b;

    stack_dump(L, "GetElement - Enter");

    if (lua_gettop(L) < 2)
    {
        return luaL_error(L,"getelement(offset) - too few arguments");
    }

    //
    // 2 Param -> Index to read from
    //
    index = (DWORD) luaL_checkint(L, 2 );

    //
    // 1 Param -> Buffer to read from
    //
    b = SgLuaBufferToPointer(L, 1 );

    //
    // Range Check
    //
    luaL_argcheck(
        L,
        b->_cbBuffer >= elemSize && index < (b->_cbBuffer - (elemSize - 1)),
        2,
        "index out of range"
        );

    //
    // Answer depends on element size
    //
    switch (elemSize)
    {
    case 2:
        value1 =  * ( (USHORT *) (b->_pbBuffer + index)   );
        if (bNetwork)
        {
            value1 = HTONS( (USHORT) value1 );
        }
        break;
    case 4:
        value1 = * ( (ULONG *)   (b->_pbBuffer + index)   );
        if (bNetwork)
        {
            value1 = HTONL( value1 );
        }
        break;
    case 8:
        value1 = * ( (ULONG *)  (b->_pbBuffer + index)    );
        value2 = * ( (ULONG *)  (b->_pbBuffer + index) + 1);
        if (bNetwork)
        {
            DWORD temp = value2;

            value2 = HTONL( value1 );
            value1 = HTONL( temp );
        }
        break;
    default:
        value1 = * ( (UCHAR *)  (b->_pbBuffer + index)    );
        break;
    }

    //
    // Push the answers onto the stack
    //
    lua_pushinteger(L, value1 );
    if (elemSize == 8)
    {
        lua_pushinteger(L, value2);
        retNum = 2;
    }

    stack_dump(L, "GetElement - Exit");

    //
    // 1 or 2 Numbers pushed onto the stack
    //
    return retNum;
}

static int SgLuaBufferGet(lua_State *L)
//
// Sample Usage: a = SgBuffer:get(1);
//
{
    return SgLuaBufferGetElement(L, 1, FALSE);
}

static int SgLuaBufferGetWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:getword(1);
//
{
    return SgLuaBufferGetElement(L, 2, FALSE);
}

static int SgLuaBufferGetWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:getwordn(1);
//
{
    return SgLuaBufferGetElement(L, 2, TRUE);
}

static int SgLuaBufferGetDWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:getdword(1);
//
{
    return SgLuaBufferGetElement(L, 4, FALSE);
}

static int SgLuaBufferGetDWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:getdwordn(1);
//
{
    return SgLuaBufferGetElement(L, 4, TRUE);
}

static int SgLuaBufferGetQWord(lua_State *L)
//
// Sample Usage: a = SgBuffer:getqword(1);
//
{
    return SgLuaBufferGetElement(L, 8, FALSE);
}

static int SgLuaBufferGetQWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer:getqword(1);
//
{
    return SgLuaBufferGetElement(L, 8, TRUE);
}

static int SgLuaBufferLastElement(lua_State *L, ULONG elemSize)
//
// Worker routine for :get()
//
{
    BYTE        *pb;
    SgLuaBuffer *b;
    ULONG        i;
    USHORT      *pw;
    ULONG       *pl;
    ULONGLONG   *pll;

    if (lua_gettop(L) < 1)
    {
        return luaL_error(L,"lastelement() - too few arguments");
    }

    //
    // 1 Param -> Buffer to read from
    //
    b = SgLuaBufferToPointer(L, 1 );

    //
    // Answer depends on element size
    //
    switch (elemSize)
    {
    case 2:
        pw = (USHORT *) (b->_pbBuffer);
        for (i = (b->_cbBuffer / sizeof(USHORT) ); i > 0; i--)
        {
            if (pw[i-1] != 0)
            {
                break;
            }
        }
        break;

    case 4:
        pl = (ULONG *) (b->_pbBuffer);
        for (i = (b->_cbBuffer / sizeof(ULONG) ); i > 0; i--)
        {
            if (pl[i-1] != 0)
            {
                break;
            }
        }
        break;

    case 8:
        pll = (ULONGLONG *) (b->_pbBuffer);
        for (i = (b->_cbBuffer / sizeof(ULONGLONG) ); i > 0; i--)
        {
            if (pll[i-1] != 0)
            {
                break;
            }
        }
        break;

    default:
        pb = (b->_pbBuffer);
        for (i = (b->_cbBuffer / sizeof(BYTE) ); i > 0; i--)
        {
            if (pb[i-1] != 0)
            {
                break;
            }
        }
        break;
    }

    //
    // If we went through the entire array without finding a non-zero value
    // then return -1
    //
    if (i == 0)
    {
        lua_pushinteger(L, -1);
    }
    else
    {
        lua_pushinteger(L, ( (i - 1) * elemSize) );
    }

    //
    // 1 pushed onto the stack
    //
    return 1;
}

static int SgLuaBufferLast(lua_State *L)
// 
// Sample Usage: a = SgBuffer:last()
//
{
    return SgLuaBufferLastElement(L, 1);
}

static int SgLuaBufferLastWord(lua_State *L)
// 
// Sample Usage: a = SgBuffer:lastword()
//
{
    return SgLuaBufferLastElement(L, 2);
}

static int SgLuaBufferLastDWord(lua_State *L)
// 
// Sample Usage: a = SgBuffer:lastdword()
//
{
    return SgLuaBufferLastElement(L, 4);
}

static int SgLuaBufferLastQWord(lua_State *L)
// 
// Sample Usage: a = SgBuffer:lastqword()
//
{
    return SgLuaBufferLastElement(L, 8);
}

static int SgLuaBufferSetElement(lua_State *L, DWORD elemSize, BOOLEAN bNetwork)
//
// Worker routine for :set()
//
{
    QWORD       value1;
    QWORD       value2;
    DWORD       index;
    SgLuaBuffer *b;

    stack_dump(L, "SetElement - Enter");

    if (elemSize == 8)
    {
        if (lua_gettop(L) < 4)
        {
            return luaL_error(L,"setelement(offset,lowdword,highdword) - too few arguments");
        }
        value2 = (QWORD) luaL_checknumber(L, 4 );
    }
    else
    {
        if (lua_gettop(L) < 3)
        {
            return luaL_error(L,"setelement(offset,number) - too few arguments");
        }
    }
    //
    // 3 Param -> Value to set
    //
    value1 = (QWORD) luaL_checknumber(L, 3 );

    //
    // 2 Param -> Index to read from
    //
    index = luaL_checkint(L, 2 );

    //
    // 1 Param -> Buffer to read from
    //
    b = SgLuaBufferToPointer(L, 1 );

    //
    // Range Check
    //
    luaL_argcheck(
        L,
        b->_cbBuffer >= elemSize && index <= (b->_cbBuffer - (elemSize - 1)),
        2,
        "index out of range"
        );

    //
    // Read only Check
    //
    luaL_argcheck(
        L,
        b->_bReadOnly == FALSE,
        1,
        "'SG.Buffer' is read-only"
        );

    //
    // Action depends on element size
    //
    switch (elemSize)
    {
    case 2:
        if (bNetwork)
        {
            value1 = HTONS( (USHORT) value1);
        }
        * ( ( (USHORT *) (b->_pbBuffer + index)     ) ) = (USHORT) (value1 & 0xFFFF);
        break;
    case 4:
        if (bNetwork)
        {
            value1 = HTONL( (ULONG) value1);
        }
        * ( ( (ULONG *)  (b->_pbBuffer + index)     ) ) = (ULONG) value1;
        break;
    case 8:
        if (bNetwork)
        {
            QWORD temp = value2;

            value2 = HTONL( (ULONG) value1);
            value1 = HTONL( (ULONG) temp);
        }
        * ( ( (ULONG *)  (b->_pbBuffer + index)     ) ) = (ULONG) value1;
        * ( ( (ULONG *)  (b->_pbBuffer + index) + 1 ) ) = (ULONG) value2;
        break;
    default:
        * ( ( (UCHAR *)  (b->_pbBuffer + index)     ) ) = (UCHAR) (value1 & 0xFF);
        break;
    }

    stack_dump(L, "SetElement - Exit");

    //
    // Nothing pushed onto the stack
    //
    return 0;
}

static int SgLuaBufferSet(lua_State *L)
//
// Sample Usage: a = SgBuffer.set(1,1);
//
{
    return SgLuaBufferSetElement(L, 1, FALSE);
}

static int SgLuaBufferSetWord(lua_State *L)
//
// Sample Usage: a = SgBuffer.setword(1,1);
//
{
    return SgLuaBufferSetElement(L, 2, FALSE);
}

static int SgLuaBufferSetWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer.setwordn(1,1);
//
{
    return SgLuaBufferSetElement(L, 2, TRUE);
}

static int SgLuaBufferSetDWord(lua_State *L)
//
// Sample Usage: a = SgBuffer.setdword(1,1);
//
{
    return SgLuaBufferSetElement(L, 4, FALSE);
}

static int SgLuaBufferSetDWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer.setdwordn(1,1);
//
{
    return SgLuaBufferSetElement(L, 4, TRUE);
}

static int SgLuaBufferSetQWord(lua_State *L)
//
// Sample Usage: a = SgBuffer.setqword(1,1);
//
{
    return SgLuaBufferSetElement(L, 8, FALSE);
}

static int SgLuaBufferSetQWordN(lua_State *L)
//
// Sample Usage: a = SgBuffer.setqwordn(1,1);
//
{
    return SgLuaBufferSetElement(L, 8, TRUE);
}

static int SgLuaBufferSize(lua_State *L)
{
    SgLuaBuffer *b;

    stack_dump(L, "Size - Enter");

    //
    // 1 Param -> Buffer we need the size for
    //
    b = SgLuaBufferToPointer(L, 1 );

    //
    // Answer
    //
    lua_pushinteger(L, b->_cbBuffer );
    stack_dump(L, "Size - Exit");

    //
    // 1 Number pushed onto the stack
    //
    return 1;
}

static int SgLuaBufferToString(lua_State *L)
{
    char *buffer;
    char *temp;
    DWORD i;
    SgLuaBuffer *b;

    // stack_dump(L, "ToString - Enter");

    //
    // 1 Param -> Buffer we need the size for
    //
    b = SgLuaBufferToPointer(L, 1 );
    
    //
    // Allocate storage and setup pointers for the string we will dynamically
    // build
    //
    buffer = (char *) malloc((b->_cbBuffer * 2) + 1);
    temp = buffer;

    //
    // Iterate over all of the bytes in the array
    //
    for (i = 0; i < b->_cbBuffer; i++)
    {
        temp += sprintf(temp,"%02x",b->_pbBuffer[i]);
    }

    //
    // Answer
    //
    lua_pushstring( L, buffer );
    // stack_dump(L, "ToString - Exit");

    //
    // Free the allocated memory
    //
    free(buffer);

    //
    // 1 string pushed onto the stack
    //
    return 1;
}

static const struct luaL_reg SgLuaBufferLibF[] = {
    { "new", SgLuaBufferNew },
    { "copy", SgLuaBufferCopy },
    { "compare", SgLuaBufferCompare },
    { NULL, NULL },
};

static const struct luaL_reg SgLuaBufferLibM[] = {
    
    //
    // Meta functions
    //
    { "__tostring", SgLuaBufferToString },
    { "__len", SgLuaBufferSize },

    //
    // And functions
    //
    { "andbyte",   SgLuaBufferAnd },
    { "andword",   SgLuaBufferAndWord },
    { "andwordn",  SgLuaBufferAndWordN },
    { "anddword",  SgLuaBufferAndDWord },
    { "anddwordn", SgLuaBufferAndDWordN },
    { "andqword",  SgLuaBufferAndQWord },
    { "andqwordn", SgLuaBufferAndQWordN },

    //
    // Get Functions
    //
    { "getbyte",   SgLuaBufferGet },
    { "getword",   SgLuaBufferGetWord },
    { "getdword",  SgLuaBufferGetDWord },
    { "getqword",  SgLuaBufferGetQWord },
    { "getwordn",  SgLuaBufferGetWordN },
    { "getdwordn", SgLuaBufferGetDWordN },
    { "getqwordn", SgLuaBufferGetQWordN },

    //
    // Last Functions
    //
    { "lastbyte",  SgLuaBufferLast },
    { "lastword",  SgLuaBufferLastWord },
    { "lastdword", SgLuaBufferLastDWord },
    { "lastqword", SgLuaBufferLastQWord },

    //
    // Or Functions
    //
    { "orbyte",   SgLuaBufferOr },
    { "orword",   SgLuaBufferOrWord },
    { "orwordn",  SgLuaBufferOrWordN },
    { "ordword",  SgLuaBufferOrDWord },
    { "ordwordn", SgLuaBufferOrDWordN },
    { "orqword",  SgLuaBufferOrQWord },
    { "orqwordn", SgLuaBufferOrQWordN },

    //
    // SET functions
    //
    { "setbyte",   SgLuaBufferSet },
    { "setword",   SgLuaBufferSetWord },
    { "setdword",  SgLuaBufferSetDWord },
    { "setqword",  SgLuaBufferSetQWord },
    { "setwordn",  SgLuaBufferSetWordN },
    { "setdwordn", SgLuaBufferSetDWordN },
    { "setqwordn", SgLuaBufferSetQWordN },

    //
    // Size function
    //
    { "size", SgLuaBufferSize },

    //
    // Terminator
    //
    { NULL, NULL },
};

// This is the table of extensions. The left column is the name of the API as it's 
// registered in lua. The right column is the corresponding C api.
static const luaL_Reg g_SgLuaExtension[] = {
    {"bAnd",               SgLuaBinaryAnd },
    {"bOr",                SgLuaBinaryOr },
    {"bXor",               SgLuaBinaryXor },
    {"bNot",               SgLuaBinaryNot },
    {NULL,                 NULL}
};

//
// Main
//
int 
__cdecl
main (
    int argc,
    char **argv
    ) 
{
    char test[256];
    char buff[256];
    int error;

    lua_State *L = lua_open();

    //
    // Turn off the GC
    //
    lua_gc(L,LUA_GCSTOP, 0);

    //
    // Open the libraries
    //
    luaL_openlibs(L);

    //
    // Register the top level extensions
    //
    luaL_register(L, "Sgext", g_SgLuaExtension);

    //
    // Register the buffer class
    //
    luaL_newmetatable(L, "SG.Buffer");
    lua_pushstring(L,"__index");
    lua_pushvalue(L, -2);
    stack_dump(L,"0: ");
    
    lua_settable(L, -3);
    stack_dump(L,"1: ");

    luaL_register(L, NULL, SgLuaBufferLibM );
    luaL_register(L, "Buffer", SgLuaBufferLibF );
    lua_pop(L, 2);
    stack_dump(L,"2: ");

    lua_gc(L,LUA_GCRESTART, 0);

    //
    // Dummy test buffer
    //
    for (error = 0; error < sizeof(test); error++)
    {
        test[error] = (char ) error;
    }
    SgLuaBufferInitialize( L, (BYTE *) &test, sizeof(test) );
    lua_setglobal( L, "test" );

    //
    // Loop on input
    //
    while (fgets(buff,sizeof(buff), stdin) != NULL)
    {
        error = luaL_loadbuffer(L,buff,strlen(buff),"line") ||
                lua_pcall(L,0,0,0);
        if (error) 
        {
            fprintf(stderr,"%s\n",lua_tostring(L,-1));
            lua_pop(L,1);
        }
    }
    lua_close(L);
    return (0);
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\compport.cpp ===
// Copyright (c) Microsoft Corporation.  All rights reserved

#include "servhlpp.h"


XomDefineArea(ServHlpDebug);


/////////////////////////////////////////////////////////////////////////////
#define CP_SHUTDOWN_KEY     ((ULONG_PTR) ~0)


/////////////////////////////////////////////////////////////////////////////
void* CCompletionContext::operator new(size_t len) 
{ 
    return XAlloc(len); 
}

void CCompletionContext::operator delete(void *pv) 
{ 
    XFree(pv); 
}

/////////////////////////////////////////////////////////////////////////////
void* CCompletionPort::operator new(size_t len) 
{ 
    return XAlloc(len); 
}

void CCompletionPort::operator delete(void *pv) 
{ 
    XFree(pv); 
}

/////////////////////////////////////////////////////////////////////////////
STDMETHODIMP CCompletionPort::CreateInstance( 
                                        DWORD dwConcurrancy, 
                                        DWORD dwThreadPoolSize, 
                                        DWORD dwThreadPriority,
                                        CCompletionPort **ppPort,
                                        ICompletionPortThreadInit* pThreadInit )
{
    HRESULT hr = S_OK;

    *ppPort = new CCompletionPort( 
                    dwConcurrancy, 
                    dwThreadPoolSize, 
                    dwThreadPriority, 
                    pThreadInit,
                    &hr);

    if( NULL == *ppPort )
    {
        return( E_OUTOFMEMORY );
    }

    if( FAILED( hr ) )
    {
        (*ppPort)->Release();
        *ppPort = NULL;
        return( hr );
    }

    return( S_OK );
}


/////////////////////////////////////////////////////////////////////////////
CCompletionPort::CCompletionPort( 
                    DWORD dwConcurrancy, 
                    DWORD dwThreadPoolSize, 
                    DWORD dwThreadPriority, 
                    ICompletionPortThreadInit* pThreadInit,
                    HRESULT *phr )
{
    InitializeCriticalSection( &m_cs );

    m_hPort = NULL;
    m_cThreads = 0;
    m_hThreads = NULL;
    m_cRef = 1;

    m_dwConcurrancy = dwConcurrancy;
    m_dwThreadPriority = dwThreadPriority;
    m_pThreadInit = pThreadInit;
    SAFE_ADDREF(m_pThreadInit);
        
    m_hPort = CreateIoCompletionPort( INVALID_HANDLE_VALUE, NULL, 0, dwConcurrancy );

    if( NULL == m_hPort )
    {
        *phr = E_UNEXPECTED;
        return;
    }

    m_cThreads = dwThreadPoolSize;
    
    if( 0 == m_cThreads )
    {
        SYSTEM_INFO si;
        GetSystemInfo( &si );
        m_cThreads = 1 + si.dwNumberOfProcessors;
    }

    m_hThreads = new HANDLE[m_cThreads];

    if( NULL == m_hThreads )
    {
        *phr = E_OUTOFMEMORY;
        return;
    }

    ZeroMemory( m_hThreads, sizeof(m_hThreads) );

    DWORD tid;

    for( int i = 0; i < (int)m_cThreads; i++ )
    {
        XomTrace(
            ServHlpDebug,
            L_LOW,
            "CCompletionPort::CCompletionPort(), creating new thread");

        m_hThreads[i] = CreateThread( NULL, 0, ThreadBase, (LPVOID)this, 0, &tid );
       
        if( NULL == m_hThreads[i] )
        {
            *phr = E_UNEXPECTED;
            return;
        }
    }
}


/////////////////////////////////////////////////////////////////////////////
CCompletionPort::~CCompletionPort()
{
    Shutdown();

    DeleteCriticalSection( &m_cs );
    SAFE_RELEASE(m_pThreadInit);
}


/////////////////////////////////////////////////////////////////////////////
void CCompletionPort::Shutdown()
{
    EnterCriticalSection( &m_cs );

    if( NULL != m_hPort )
    {
		int i;

        for( i = 0; i < (int)m_cThreads; i++ )
        {
            PostQueuedCompletionStatus( m_hPort, 0, CP_SHUTDOWN_KEY, NULL );
        }

        if( NULL != m_hThreads )
        {
            for( i = 0; ( i < (int)m_cThreads ) && m_hThreads[i]; i++ );

            while (i > MAXIMUM_WAIT_OBJECTS)
            {
                WaitForMultipleObjects( MAXIMUM_WAIT_OBJECTS, &(m_hThreads[i - MAXIMUM_WAIT_OBJECTS]), TRUE, INFINITE );
                i -= MAXIMUM_WAIT_OBJECTS;
            }

            if( i )
            {
                WaitForMultipleObjects( i, m_hThreads, TRUE, INFINITE );
            }

            SAFE_CLOSEHANDLE( m_hPort );

            for( i = 0; i < (int)m_cThreads; i++ )
            {
                SAFE_CLOSEHANDLE( m_hThreads[i] );
            }

            SAFE_ARRAYDELETE( m_hThreads );
        }
    }

    LeaveCriticalSection( &m_cs );
}


/////////////////////////////////////////////////////////////////////////////
void CCompletionPort::ThreadProc()
{
    CCompletionContext *pContext;
    OVERLAPPED *po;
    DWORD cbTransferred;
    ULONG_PTR upKey;
    BOOL fSuccess;

    SetThreadPriority( GetCurrentThread(), m_dwThreadPriority );

    CoInitializeEx( NULL, COINIT_MULTITHREADED );

#if defined(ICECAP) && !defined(USE_DLP)
    ( void ) NameProfile( "CCompletionPort::ThreadProc", PROFILE_THREADLEVEL, PROFILE_CURRENTID );
#endif

    if(m_pThreadInit != NULL)
    {
        m_pThreadInit->OnThreadInit();
    }

    //SetThreadDebugName( "CCompletionPort::ThreadProc" );

    for(;;)
    {
        fSuccess = GetQueuedCompletionStatus( m_hPort, &cbTransferred, &upKey, &po, INFINITE );

        if( !fSuccess && ( NULL == po ) )
        {
            break;
        }
    
        if( NULL != po )
        {
            pContext = (CCompletionContext*) po;

            XOMASSERT( NULL != pContext->GetHandler() );

            pContext->GetHandler()->OnIoCompletion(
                        ( fSuccess ? NO_ERROR : GetLastError() ), 
                        cbTransferred, 
                        upKey,
                        pContext );
        }
        else if( CP_SHUTDOWN_KEY == upKey )
        {
            break;
        }
    }

    if(m_pThreadInit != NULL)
    {
        m_pThreadInit->OnThreadTerm();
    }
    
    CoUninitialize();
}

/////////////////////////////////////////////////////////////////////////////
DWORD WINAPI CCompletionPort::ThreadBase( LPVOID pvThis )
{
    ((CCompletionPort*)pvThis)->ThreadProc();

    return( 0xDEAD );
} 


/////////////////////////////////////////////////////////////////////////////
HRESULT CCompletionPort::Attach( HANDLE hParam, ULONG_PTR upKey )
{
    HRESULT hr = S_OK;
    EnterCriticalSection( &m_cs );
    
    HANDLE hPort = CreateIoCompletionPort( hParam, m_hPort, upKey, m_dwConcurrancy );

    if( NULL == hPort )
    {
        hr = E_FAIL;
    }

    LeaveCriticalSection( &m_cs );

    return( hr );
}


/////////////////////////////////////////////////////////////////////////////
HRESULT CCompletionPort::Leave( HANDLE hParam )
{
    //
    // You can't unjoin a completion port on NT!!!
    //
    return( S_OK );
}


/////////////////////////////////////////////////////////////////////////////
HRESULT CCompletionPort::PostCompletion( 
                            CCompletionContext *pCtx, 
                            DWORD cbTransferred, 
                            ULONG_PTR upKey )
{
    HRESULT hr = S_OK;
    EnterCriticalSection( &m_cs );

    if( !PostQueuedCompletionStatus( m_hPort, cbTransferred, upKey, (LPOVERLAPPED)pCtx ) )
    {
        hr = E_FAIL;
    }

    LeaveCriticalSection( &m_cs );

    return( hr );
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\compport.h ===
// Copyright (c) Microsoft Corporation.  All rights reserved

#pragma once

#include <wmsstd.h>
    
class CCompletionContext;
class CCompletionHandler;
class CCompletionPort;


/////////////////////////////////////////////////////////////////////////////
class CCompletionHandler
{
public:
    virtual ULONG AddRef() = 0;

    virtual ULONG Release() = 0;

    virtual void OnIoCompletion( 
                    DWORD dwError, 
                    DWORD cbTransferred, 
                    ULONG_PTR ulpKey,
                    CCompletionContext *pCtx ) = 0;
};
    
/////////////////////////////////////////////////////////////////////////////
class CCompletionContext : public OVERLAPPED
{
public:
    CCompletionContext() 
    {
        ZeroMemory( (OVERLAPPED*)this, sizeof(OVERLAPPED) );
    }

    void *operator new(size_t len);
    void operator delete(void *pv);
    
    virtual CCompletionHandler* GetHandler() = 0;
};

/////////////////////////////////////////////////////////////////////////////
class __declspec(novtable) ICompletionPortThreadInit
{
public:
    virtual ULONG AddRef() = 0;
    virtual ULONG Release() = 0;
    virtual void OnThreadInit() = 0;
    virtual void OnThreadTerm() = 0;
};
    
/////////////////////////////////////////////////////////////////////////////
class CCompletionPort
{
public:
    static STDMETHODIMP CreateInstance( 
                                DWORD dwConcurrancy, 
                                DWORD dwThreadPoolSize, 
                                DWORD dwThreadPriority,
                                CCompletionPort **ppPort,
                                ICompletionPortThreadInit* pThreadInit = NULL);

    void *operator new(size_t len);
    void operator delete(void *pv);

    STDMETHODIMP_(ULONG) AddRef()
    {
        return( INC_REF( m_cRef ) );
    }

    STDMETHODIMP_(ULONG) Release()
    {
        if( 0 == DEC_REF( m_cRef ) )
        {
            delete this;
            return( 0 );
        }
        
        return( 0xbad );
    }

    HRESULT Attach( HANDLE hParam, ULONG_PTR upKey = 0 );

    HRESULT Leave( HANDLE hParam );

    HRESULT PostCompletion(
                    CCompletionContext *pCtx,
                    DWORD cbTransferred = 0,
                    ULONG_PTR upKey = 0 );

    void Shutdown();

private:

    CCompletionPort( DWORD dwConcurrancy, 
                     DWORD dwThreadPoolSize, 
                     DWORD dwThreadPriority, 
                     ICompletionPortThreadInit* pThreadInit,
                     HRESULT *phr );

    ~CCompletionPort();

    static DWORD WINAPI ThreadBase( LPVOID pvThis );
    void ThreadProc();

    HANDLE m_hPort;
    HANDLE *m_hThreads;
    DWORD m_cThreads;
    DWORD m_dwThreadPriority;
    DWORD m_dwConcurrancy;
    DWORD m_cRef;
    CRITICAL_SECTION m_cs;
    ICompletionPortThreadInit* m_pThreadInit;
};
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\servhlpp.h ===
// Copyright (c) Microsoft Corporation.  All rights reserved

#pragma once

#define INCL_WINSOCK_API_TYPEDEFS 1
#include <winsock2.h>
#include <objbase.h>
#include <wsockntp.h>
#include "mswsock.h"
#include "ws2tcpip.h"
#include "mstcpip.h"
#include <Aclapi.h>
#include <stdio.h>
#include <stdlib.h>
#include <icecap.h>
#include <atlbase.h>
#include <atlcom.h>
#include "wmsstd.h"

#if defined(_XALLOC_CRT_)
#define XAlloc(nSize) _aligned_malloc(nSize, MEMORY_ALLOCATION_ALIGNMENT)
#define XFree(pv) if (pv != NULL) _aligned_free(pv)
#define XDumpLeaks()
#endif
#if defined(_XALLOC_ROCKALL_)
#include "xalloc.h"
#endif

#include "xmgmt.h"
#include "xeventids.h"
#include "vptrlist.h"

#include "compport.h"
#include "ntservice.h"
#include "loadperf.h"
#include "servsock.h"
#include "servpipe.h"
#include "tcpcnt.h"

#import "CommonConfig.tlb" raw_interfaces_only, no_smart_pointers


XomImportArea(ServHlpDebug);

#ifndef ARRAY_ELEMENTS
#define ARRAY_ELEMENTS(x) (sizeof(x) / sizeof(x[0]))
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\servpipe.cpp ===
/*++

Copyright (c) Microsoft Corporation.  All rights reserved

Module Name:

    servpipe.cpp

Abstract:


--*/

#include "servhlpp.h"


XomImportArea(ServHlpDebug);

CPipeIoContext::CPipeIoContext(
    IoType eType,
    CCompletionHandler* pHandler,
    CServerPipeServerCallback* pServerCallback,
    CServerPipeCallback* pCallback,
    HANDLE hPipe,
    BYTE* pBuffer,
    DWORD cbBuffer,
    ULONGLONG qwArgument
)
{
    m_eIoType = eType;
    
    
    m_pHandler = pHandler;
    m_pHandler->AddRef();

    if(pServerCallback)
    {
        m_pServerCallback = pServerCallback;
        m_pServerCallback->AddRef();
    }
    else
    {
        m_pServerCallback = NULL;
    }

    if(pCallback)
    {
        m_pPipeCallback = pCallback;
        m_pPipeCallback->AddRef();
    }
    else
    {
        m_pPipeCallback = NULL;
    }
    
    m_hPipe = hPipe;
    m_fOwnsPipe = true;

    m_pBuffer = pBuffer;
    m_cbBuffer = cbBuffer;

    m_qwArgument = qwArgument;
}

CPipeIoContext::~CPipeIoContext()
{
    SAFE_RELEASE(m_pHandler);
    SAFE_RELEASE(m_pServerCallback);
    SAFE_RELEASE(m_pPipeCallback);

    if (m_fOwnsPipe && m_hPipe != INVALID_HANDLE_VALUE)
    {
        CloseHandle(m_hPipe);
    }
}

CServerPipe::CServerPipe()
{
    m_pIOCP = NULL;
    m_hPipe = INVALID_HANDLE_VALUE;
}

CServerPipe::~CServerPipe()
{
    Close();

    SAFE_RELEASE(m_pIOCP);
}

HRESULT CServerPipe::Init(
    CCompletionPort* pIOCP )
{
    m_pIOCP = pIOCP;
    m_pIOCP->AddRef();

    return S_OK;
}

HRESULT CServerPipe::Attach(
    HANDLE hPipe)
{
    m_hPipe = hPipe;

    return S_OK;
}

HRESULT CServerPipe::Close()
{
    // Close can be called along multiple threads due to the async callback nature of the requests
    // so make sure that Close will operate only once.
    HANDLE pipe = InterlockedExchangePointer(&m_hPipe, INVALID_HANDLE_VALUE);
    if(pipe != INVALID_HANDLE_VALUE)
    {
        DisconnectNamedPipe(pipe);
        CloseHandle(pipe);
    }

    return S_OK;
}


HRESULT CServerPipe::Connect(
    LPCWSTR pwszPipeName 
)
{
    HRESULT hr = S_OK;
    HANDLE hPipe = INVALID_HANDLE_VALUE;
    DWORD dwNewMode;
    BOOL fRes;

    hPipe = CreateFileW(
        pwszPipeName, 
        GENERIC_READ | GENERIC_WRITE, 
        0,
        NULL,
        OPEN_EXISTING,
        FILE_FLAG_OVERLAPPED,
        NULL);

    if(INVALID_HANDLE_VALUE == hPipe)
    {
        hr = HRESULT_FROM_WIN32(GetLastError());
        goto lDone;
    }

    dwNewMode = PIPE_READMODE_MESSAGE;

    fRes = SetNamedPipeHandleState(hPipe, &dwNewMode, NULL, NULL);

    if(!fRes)
    {
        hr = HRESULT_FROM_WIN32(GetLastError());
        goto lDone;
    }
    
    hr = m_pIOCP->Attach(hPipe);

    if(FAILED(hr))
    {
        goto lDone;
    }

    m_hPipe = hPipe;
    
    hPipe = INVALID_HANDLE_VALUE;

lDone:

    if(INVALID_HANDLE_VALUE != hPipe)
    {
        CloseHandle(hPipe);
        hPipe = INVALID_HANDLE_VALUE;
    }

    return hr;
}


HRESULT CServerPipe::Write(
    BYTE* pBuffer,
    DWORD cbBuffer,
    CServerPipeCallback* pCallback,
    ULONGLONG qwCallbackArg )
{
    HRESULT hr = S_OK;
    BOOL fRes;
    CPipeIoContext* pIoContext = NULL;

    pIoContext = new CPipeIoContext(
        CPipeIoContext::IoWrite, this, NULL, pCallback, 
        INVALID_HANDLE_VALUE, pBuffer, cbBuffer, qwCallbackArg);
    
    if(NULL == pIoContext)
    {
        hr = E_OUTOFMEMORY;
        goto lDone;
    }

    fRes = WriteFile(m_hPipe, pBuffer, cbBuffer, NULL, pIoContext);

    if( !fRes && GetLastError() != ERROR_IO_PENDING)
    {
        hr = HRESULT_FROM_WIN32(GetLastError());
        goto lDone;
    }
    
    pIoContext = NULL;

lDone:

    SAFE_DELETE(pIoContext);

    return hr;
}

HRESULT CServerPipe::Read(
    BYTE* pBuffer,
    DWORD cbBuffer,
    CServerPipeCallback* pCallback,
    ULONGLONG qwCallbackArg 
)
{
    HRESULT hr = S_OK;
    BOOL fRes;
    CPipeIoContext* pIoContext = NULL;

    pIoContext = new CPipeIoContext(
        CPipeIoContext::IoRead, this, NULL, pCallback,
        INVALID_HANDLE_VALUE, pBuffer, cbBuffer, qwCallbackArg);

    if(NULL == pIoContext)
    {
        hr = E_OUTOFMEMORY;
        goto lDone;
    }

    fRes = ReadFile(m_hPipe, pBuffer, cbBuffer, NULL, pIoContext);

    if(!fRes)
    {
        DWORD dwErr = GetLastError();

        switch(dwErr)
        {
        case ERROR_IO_PENDING:
            // Not really an error. Our completion handler will get called
            // later on.
            break;

        case ERROR_MORE_DATA:
            // What? That damn service is sending more stuff that it was 
            // supposed to. However the completion handler will still be 
            // called and it will be notified of the error. Let it handle it.
            break;

        default:
            // Other errors. pIoContext (hopefully) wasn't queued, delete it.
            hr = HRESULT_FROM_WIN32(GetLastError());
            goto lDone;
        }
    }

    pIoContext = NULL;

lDone:
    
    SAFE_DELETE(pIoContext);

    return hr;
}

void CServerPipe::OnIoCompletion( 
                DWORD dwError, 
                DWORD cbTransferred, 
                ULONG_PTR ulpKey,
                CCompletionContext *pUncastCtx )
{
    CPipeIoContext* pCtx = (CPipeIoContext*) pUncastCtx;

    if(NULL == pCtx)
    {
        goto lDone;
    }

    switch(pCtx->GetIoType())
    {
    case CPipeIoContext::IoWrite:
        {
            HRESULT hr = S_OK;

            if(dwError != NO_ERROR)
            {
                hr = HRESULT_FROM_WIN32(dwError);
                goto lDoneIoWrite;
            }
            
        lDoneIoWrite:
            
            pCtx->GetPipeCallback()->OnPipeWrite(
                pCtx->GetBuffer(),
                pCtx->GetBufferSize(),
                cbTransferred,
                hr,
                pCtx->GetArgument());
        
            break;
        }

    case CPipeIoContext::IoRead:
        {
            HRESULT hr = S_OK;

            if(dwError != NO_ERROR)
            {
                hr = HRESULT_FROM_WIN32(dwError);
                goto lDoneIoRead;
            }
            
        lDoneIoRead:

            pCtx->GetPipeCallback()->OnPipeRead(
                pCtx->GetBuffer(),
                cbTransferred,
                hr,
                pCtx->GetArgument());
            break;
        }
    }
    
lDone:

    SAFE_DELETE(pCtx);
}


CServerPipeServer::CServerPipeServer()
{
    m_pIOCP = NULL;
    m_wszPipeName[0] = L'\0';
    m_pSD = NULL;
}

CServerPipeServer::~CServerPipeServer()
{
    SAFE_RELEASE(m_pIOCP);

    if(m_pSD != NULL)
    {
        LocalFree(m_pSD);
        m_pSD = NULL;
    }
}

HRESULT CServerPipeServer::Init(
    CCompletionPort* pIOCP,
    LPCWSTR pwszNamedPipe,
    PSECURITY_DESCRIPTOR pSD )
{
    DWORD dwSDLength;
    HRESULT hr = S_OK;

    pIOCP->AddRef();
    m_pIOCP = pIOCP;

    lstrcpynW(m_wszPipeName, pwszNamedPipe, ARRAY_ELEMENTS(m_wszPipeName));

    if(pSD != NULL)
    {
        dwSDLength = GetSecurityDescriptorLength(pSD);

        m_pSD = (PSECURITY_DESCRIPTOR*) LocalAlloc(0, dwSDLength);

        if(NULL == m_pSD)
        {
            hr = E_OUTOFMEMORY;
            goto lDone;
        }

        memcpy(m_pSD, pSD, dwSDLength);
    }

lDone:

    return hr;
}


HRESULT CServerPipeServer::Connect(
    CServerPipeServerCallback* pCallback,
    ULONGLONG qwArgument )
{
    HRESULT hr = S_OK;
    BOOL fRet;
    CPipeIoContext* pIoContext = NULL;
    HANDLE hPipeInstance = INVALID_HANDLE_VALUE;
    SECURITY_ATTRIBUTES SecAttr;
    PSECURITY_ATTRIBUTES pSecAttr = NULL;
    
    if(m_pSD != NULL)
    {
        //
        // Security descriptor is available. Let's use it
        //
        
        SecAttr.nLength = sizeof(SecAttr);
        SecAttr.lpSecurityDescriptor = m_pSD;
        SecAttr.bInheritHandle = FALSE;

        pSecAttr = &SecAttr;
    }

    hPipeInstance = CreateNamedPipeW(
        m_wszPipeName, 
        PIPE_ACCESS_DUPLEX | FILE_FLAG_OVERLAPPED,
        PIPE_TYPE_MESSAGE | PIPE_READMODE_MESSAGE | PIPE_WAIT,
        PIPE_UNLIMITED_INSTANCES,
        1024,
        1024,
        10000,
        pSecAttr);

    // NOTE: WinXP and Win2k did not return ERROR_ALREADY_EXISTS when the pipe had already been created
    // even though they were supposed to according to the MSDN.  Win2k3 Server fixes this 
    // (see http://liveraid/?id=585277).  Previously there was a check here against ERROR_ALREADY_EXISTS
    // causing this to incorrectly fail on Win2k3 Server.  This function is called multiple times to 
    // submit new listen jobs, so pre-existence of the pipe is an expected condition.
    if( INVALID_HANDLE_VALUE == hPipeInstance )
    {
        hr = HRESULT_FROM_WIN32(GetLastError());
        XomNtEvent( XEVENT_PIPE_FAILURE, "CServerPipeServer::Connect - Failed in CreateNamedPipeW, hr = 0x%x", hr );
        goto lDone;
    }

    hr = m_pIOCP->Attach(hPipeInstance);
    if(FAILED(hr))
    {
        XomNtEvent( XEVENT_PIPE_FAILURE_1, "CServerPipeServer::Connect - Failed in Attach the pipe to IO completion port, hr = 0x%x", hr );
        goto lDone;
    }

    // The pipe handle will be closed by the receiver of this context.
    pIoContext = new CPipeIoContext(CPipeIoContext::IoConnect, this, pCallback, 
        NULL, hPipeInstance, NULL, 0, qwArgument);

    if(NULL == pIoContext)
    {
        hr = E_OUTOFMEMORY;
        goto lDone;
    }

    // pIoContext owns the handle now.
    hPipeInstance = INVALID_HANDLE_VALUE;


    fRet = ConnectNamedPipe(pIoContext->GetPipe(), pIoContext);

    if( !fRet && GetLastError()!= ERROR_IO_PENDING )
    {
        DWORD dwErr = GetLastError();
        if ( dwErr == ERROR_PIPE_CONNECTED )
        {
            // If a client connects before the function is called, the function returns zero and GetLastError returns ERROR_PIPE_CONNECTED. 
            // This can happen if a client connects in the interval between the call to CreateNamedPipe and the call to ConnectNamedPipe. 
            // In this situation, there is a good connection between client and server, even though the function returns zero.
            //
            // Since the client is already connected, post a completion to execute the callback.
            hr = m_pIOCP->PostCompletion(pIoContext);
            if (FAILED(hr))
            {
                goto lDone;
            }
        }
        else
        {
            hr = HRESULT_FROM_WIN32(GetLastError());
            XomNtEvent( XEVENT_PIPE_FAILURE_2, "CServerPipeServer::Connect - Failed in ConnectNamedPipe, hr = 0x%x", hr );
            goto lDone;
        }
    }

    // Successful call to Connect means that it owns the final reference.
    pIoContext = NULL;

lDone:

    if(INVALID_HANDLE_VALUE != hPipeInstance)
    {
        CloseHandle(hPipeInstance);
        hPipeInstance = INVALID_HANDLE_VALUE;
    }

    SAFE_DELETE(pIoContext);

    return hr;
}

void CServerPipeServer::OnIoCompletion( 
                DWORD dwError, 
                DWORD cbTransferred, 
                ULONG_PTR ulpKey,
                CCompletionContext *pUncastCtx )
{
    CPipeIoContext* pCtx = (CPipeIoContext*) pUncastCtx;

    if(NULL == pCtx)
    {
        goto lDone;
    }

    switch(pCtx->GetIoType())
    {
    case CPipeIoContext::IoConnect:
        
        {
            HRESULT hr = S_OK;
            CServerPipe* pNewPipe = NULL;
            
            if( dwError != NO_ERROR &&
                dwError != ERROR_PIPE_CONNECTED )
            {
                hr = HRESULT_FROM_WIN32(dwError);
                goto lDoneIoConnect;
            }
            
            pNewPipe = new CServerPipe;

            if(NULL == pNewPipe)
            {
                hr = E_OUTOFMEMORY;
                goto lDoneIoConnect;
            }

            hr = pNewPipe->Init(m_pIOCP);

            if(FAILED(hr))
            {
                goto lDoneIoConnect;
            }

            hr = pNewPipe->Attach(pCtx->GetPipe());

            if(FAILED(hr))
            {
                goto lDoneIoConnect;
            }

            pCtx->SetOwnsPipe(FALSE);
        lDoneIoConnect:

            pCtx->GetServerCallback()->OnPipeConnect(
                this,
                SUCCEEDED(hr) ? pNewPipe : NULL,
                hr,
                pCtx->GetArgument() );

            // Prefast likes to say that we are leaking pNewPipe even though
            // it's not true. Come on prefast, go find leaks somewhere else!
            
            SAFE_RELEASE(pNewPipe);
        
            break;
        }
    }

lDone:
    
    SAFE_DELETE(pCtx);

    return;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\servpipe.h ===
/*++

Copyright (c) Microsoft Corporation.  All rights reserved

Module Name:

    servpipe.h

Abstract:


--*/

#ifndef _SERVPIPE_H_
#define _SERVPIPE_H_

#include <compport.h>
#include <addref.h>

class CServerPipeServer;
class CServerPipe;

class CServerPipeServerCallback
{
public:

    virtual ULONG AddRef() = 0;
    
    virtual ULONG Release() = 0;

    virtual HRESULT OnPipeConnect(
        CServerPipeServer* pServerPipe,
        CServerPipe* pAcceptedPipe,
        HRESULT hrResult,
        ULONGLONG qwCallbackArg ) = 0;
};

class CServerPipeCallback
{
public:

    virtual ULONG AddRef() = 0;
    
    virtual ULONG Release() = 0;

    virtual HRESULT OnPipeWrite(
        BYTE* pBufferSent,
        DWORD cbToSend,
        DWORD cbSent,
        HRESULT hr,
        ULONGLONG qwCallbackArg) = 0;

    virtual HRESULT OnPipeRead(
        BYTE* pbFilledInBuffer,
        DWORD cbRead,
        HRESULT hr,
        ULONGLONG qwCallbackArg) = 0;
};

class CPipeIoContext : 
    public CCompletionContext
{
public:

    enum IoType
    {
        IoInvalidType,
        IoConnect,
        IoWrite,
        IoRead
    };

    CPipeIoContext(
        IoType eType,
        CCompletionHandler* pHandler,
        CServerPipeServerCallback* pServerCallback,
        CServerPipeCallback* pCallback,
        HANDLE hPipe,
        BYTE* pBuffer,
        DWORD cbBuffer,
        ULONGLONG qwArgument);
    

    ~CPipeIoContext();
    
    IoType GetIoType()                                { return m_eIoType; }
    CCompletionHandler* GetHandler()                { return m_pHandler; }
    CServerPipeServerCallback* GetServerCallback()    { return m_pServerCallback; }
    CServerPipeCallback* GetPipeCallback()            { return m_pPipeCallback; }
    HANDLE GetPipe()                                { return m_hPipe; }
    BYTE* GetBuffer()                                { return m_pBuffer; }
    DWORD GetBufferSize()                            { return m_cbBuffer; }
    ULONGLONG GetArgument()                            { return m_qwArgument; }
    void SetOwnsPipe(bool flag)                        { m_fOwnsPipe = flag; }

protected:

    bool m_fOwnsPipe;
    IoType m_eIoType;
    CCompletionHandler* m_pHandler;
    CServerPipeServerCallback* m_pServerCallback;
    CServerPipeCallback* m_pPipeCallback;
    HANDLE m_hPipe;
    BYTE* m_pBuffer;
    DWORD m_cbBuffer;
    ULONGLONG m_qwArgument;
};


class CServerPipe : 
    public CCompletionHandler
{
public:
    
    IMPLEMENT_REFCOUNT;
        
    CServerPipe();
    
    ~CServerPipe();
    
    HRESULT Init(
        CCompletionPort* pIOCP );
        
    HRESULT Attach(
        HANDLE hPipe);

    HRESULT Connect(
        LPCWSTR pwszPipeName);
    
    HRESULT Close();

    HRESULT Write(
        BYTE* pBuffer,
        DWORD cbBuffer,
        CServerPipeCallback* pCallback,
        ULONGLONG qwCallbackArg );

    HRESULT Read(
        BYTE* pBuffer,
        DWORD cbBuffer,
        CServerPipeCallback* pCallback,
        ULONGLONG qwCallbackArg );
    

protected:

    virtual void OnIoCompletion( 
                    DWORD dwError, 
                    DWORD cbTransferred, 
                    ULONG_PTR ulpKey,
                    CCompletionContext *pUncastCtx );

    CCompletionPort* m_pIOCP;
    HANDLE m_hPipe;
};

class CServerPipeServer :
    public CCompletionHandler
{
public:
    
    IMPLEMENT_REFCOUNT;
    
    CServerPipeServer();
    
    ~CServerPipeServer();
    
    HRESULT Init(
        CCompletionPort* pIOCP,
        LPCWSTR pwszNamedPipe,
        PSECURITY_DESCRIPTOR pSD );
    
    HRESULT Connect(
        CServerPipeServerCallback* pCallback,
        ULONGLONG qwArgument );

protected:

    virtual void OnIoCompletion( 
                    DWORD dwError, 
                    DWORD cbTransferred, 
                    ULONG_PTR ulpKey,
                    CCompletionContext *pUncastCtx );

    CCompletionPort* m_pIOCP;

    WCHAR m_wszPipeName[256];

    PSECURITY_DESCRIPTOR m_pSD;
};

#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\ntservice.h ===
// Copyright (c) Microsoft Corporation.  All rights reserved

#pragma once

#include <commonconfig.h>

#define MAX_SERVICE_NAME        128
#define MAX_SERVICE_ACCT_PWD    128

// Forward declarations

//////////////////////////////////////////////////////////////////////////////
//
// Base class for an NT service that runs in its own process.
//
class CNTService
{
public:
    CNTService(
            LPCWSTR pszServiceName,
            LPCWSTR pszServiceDisplayName,
            LPCWSTR pszServiceDescription,
            LPCWSTR pszPerfBaseName,
            CComBSTR componentKey = Component_unknown );
    virtual ~CNTService();

    //
    // Call this function as the body of the service's main() routine.
    // It handles command line arguments as follows:
    //     -Install     ==  install the service and perf counters
    //     -Uninstall   ==  uninstall perf counters and service
    //     -Console     ==  run as a console app instead of a service
    //
    DWORD ProcessMain( DWORD dwArgc, LPWSTR *pszArgv );

protected:
    //
    // Utility function that determines if the service has been registered
    // with the SCM
    //
    BOOL IsServiceInstalled();

    //
    // Derived classes must implement this initialization method
    //
    virtual HRESULT InitService( DWORD dwArgc, LPWSTR *pszArgv ) = 0;

    //
    // Derived classes must do run their service in this routine
    //
    virtual HRESULT RunService( BOOL *pfServiceRan ) = 0;

    //
    // Derived classes can override this termination method
    //
    virtual void TermService();

    //
    // Handle all aspects of service installation
    //
    virtual DWORD Install();

    //
    // Handle all aspects of service uninstallation
    //
    virtual DWORD Uninstall();

    //
    // Register perfmon counters using perf DLL with same base name as the EXE by default
    //
    virtual DWORD InstallCounters();

    //
    // Unregister any previously registered perfmon counters. Use m_pszServiceName by 
    // default, but allow overrides.
    //
    virtual DWORD UninstallCounters(LPCWSTR pszServiceName = NULL);


    //
    // Get the path to the executable for this service.  overridable so that derived classes can add custom command line args.
    //
    virtual WCHAR *GetExePathAndArgs();

    //
    // Register the service with the SCM
    //
    DWORD InstallService();

    //
    // Unregister the service with the SCM
    //
    DWORD UninstallService();

    //
    // Grant the service account rights to logon as a service
    //
    virtual DWORD GrantLogonRights(LPCWSTR szAccount);

    //
    // Retrieve secret (service account password)
    //
    DWORD ResolveSecret(LPCWSTR szPath, LPCWSTR szSecret);


    
    //
    // Various service status reporting methods
    //
    DWORD ChangeState( DWORD dwState );

    DWORD Checkpoint( DWORD dwWaitHint = 0 );

    DWORD ReportError( DWORD dwErr );

    //
    // Runs the main thread of the service/console app
    //
    virtual void ServiceMain( DWORD dwArgc, LPWSTR *pszArgv );

    //
    // Called by the service control handler routine to process notifications
    // and commands from the SCM.
    //
    virtual void ServiceControlHandler( DWORD dwOpcode );

    //
    // Gives derived classes access to our shutdown notification event
    //
    HANDLE ShutdownEvent()
    {
        return( m_hevtShutdown );
    }

    //
    // Report installation progress/error
    //
    void InstallError( char* pszFmt, ... );
    void InstallInfo( char* pszFmt = NULL, ... );

private:
    static void WINAPI StaticServiceMain( DWORD dwArgc, LPWSTR *pszArgv );

    static void WINAPI StaticServiceControlHandler( DWORD dwOpcode );

    static BOOL WINAPI StaticConsoleCtrlHandler( DWORD dwCtrlType );

protected:
    WCHAR m_szServiceName       [ MAX_SERVICE_NAME ];
    WCHAR m_szServiceDisplayName[ MAX_SERVICE_NAME ];

    LPCWSTR m_pszServiceName;
    LPCWSTR m_pszServiceDisplayName;
    LPCWSTR m_pszServiceDescription;
    LPCWSTR m_pszPerfBaseName;

    BOOL m_fRunningAsService;
    BOOL m_fStartOnInstall;

    HANDLE m_hevtShutdown;

    SERVICE_STATUS_HANDLE m_hServiceStatus;

    SERVICE_STATUS m_Status;
    CComBSTR m_eComponent;

    WCHAR m_szSvcAcctPwd[ MAX_SERVICE_ACCT_PWD + 1 ];
    BOOL  m_fResolvedPwd;
};





class CSIDLookup
{
public:
    CSIDLookup();
    ~CSIDLookup();

    HRESULT Lookup(LPCWSTR szAccount);
    PSID    GetPSID(void);

private:
    DWORD           m_cbSID;
    DWORD           m_cchRefDomainName;
    PSID            m_pSID;
    LPWSTR          m_szRefDomainName;
    SID_NAME_USE    m_SIDNameUse;
};






//////////////////////////////////////////////////////////////////////////////
//
// There must always be only one global service object; it is pointed to
// by the following global pointer;  the actual object can be a derived class.
//
extern CNTService *g_pService;
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\servsock.h ===
// Copyright (c) Microsoft Corporation.  All rights reserved

#pragma once

#include "compport.h"

// Forward declarations
class CVPtrList;
class CServerSocket;
class CServerSocketConnectWatchdog;
typedef UINT_PTR SOCKET;


//////////////////////////////////////////////////////////////////////////////
char *GetIPDisplayString( DWORD dwIP );


//////////////////////////////////////////////////////////////////////////////
class CServerSocketCallback
{
public:
    virtual ULONG AddRef() = 0;

    virtual ULONG Release() = 0;

    virtual void OnSocketConnect(
                        HRESULT hr,
                        QWORD qwCallbackArg ) {}

    virtual void OnSocketAccept(
                        CServerSocket *pListenSocket,
                        CServerSocket *pAcceptedSocket,
                        sockaddr_in *pLocalAddr,
                        sockaddr_in *pRemoteAddr,
                        HRESULT hr,
                        QWORD qwCallbackArg ) {}

    virtual void OnSocketSend(
                        BYTE *pbBufferSent,
                        DWORD cbToSend,
                        DWORD cbSent,
                        HRESULT hr,
                        QWORD qwCallbackArg ) {}

    virtual void OnSocketSendTo(
                        BYTE *pbBufferSent,
                        DWORD cbToSend,
                        DWORD cbSent,
                        HRESULT hr,
                        QWORD qwCallbackArg ) {}

    virtual void OnSocketReceive(
                        BYTE *pbFilledInBuffer,
                        DWORD cbRead,
                        HRESULT hr,
                        QWORD qwCallbackArg ) {}

    virtual void OnSocketReceiveFrom(
                        BYTE *pbFilledInBuffer,
                        DWORD cbRead,
                        sockaddr_in *pFilledInFrom,
                        HRESULT hr,
                        QWORD qwCallbackArg ) {}

    virtual void OnSocketClose(
                        HRESULT hr,
                        QWORD qwCallbackArg ) {}
};


//////////////////////////////////////////////////////////////////////////////
//
// I/O completion context for sockets
//
class CSocketIoContext : public CCompletionContext
{
public:
    enum IoType
    { 
        IoInvalidType = 0,
        IoConnect,
        IoAccept,
        IoSend,
        IoSendTo,
        IoReceive,
        IoReceiveFrom
    };

    CSocketIoContext()
    {
        m_cRef = 1;
    }

    ~CSocketIoContext()  
    { 
        Destroy();
    }

    void *operator new(size_t len);
    void operator delete(void *pv);


    ULONG AddRef()
    {
        LONG lResult = InterlockedIncrement( &m_cRef );

        return( lResult );
    }

    ULONG Release()
    {
        LONG lResult = InterlockedDecrement( &m_cRef );

        if( 0 == lResult )
        {
            delete this;
            return( 0 );
        }

        return( 0xbad );
    }

    void Init(
            CCompletionHandler *pHandler,
            IoType ioType,
            BYTE *pbBuffer,
            DWORD cbBuffer,
            SOCKET socket,
            CServerSocketCallback *pCallback,
            QWORD qwCallbackArg )
    {
        m_pHandler = pHandler;
        m_ioType = ioType;        
        m_pbBuffer = pbBuffer;
        m_cbBuffer = cbBuffer;
        m_Socket = socket;
        m_pCallback = pCallback;
        m_qwCallbackArg = qwCallbackArg;
        m_addrlen = sizeof(sockaddr);
        m_hr = S_OK;

        SAFE_ADDREF( pHandler );
        SAFE_ADDREF( pCallback );
    }

    void Destroy()
    {
        SAFE_RELEASE( m_pCallback );
        SAFE_RELEASE( m_pHandler );
        m_ioType = IoInvalidType;
        m_pbBuffer = NULL;
        m_cbBuffer = 0;
        m_Socket = INVALID_SOCKET;
        m_qwCallbackArg = 0;
    }
    

    CCompletionHandler *GetHandler()        { return( m_pHandler ); }
    IoType GetIoType()                      { return( m_ioType ); }
    BYTE *GetBuffer()                       { return( m_pbBuffer ); }
    DWORD GetBufferSize()                   { return( m_cbBuffer ); }
    SOCKET GetSocket()                      { return( m_Socket ); }
    CServerSocketCallback *GetCallback()    { return( m_pCallback ); }
    QWORD GetCallbackArg()                  { return( m_qwCallbackArg ); }
    sockaddr_in *GetAddr()                  { return( &m_addr ); }
    int* GetAddrLen()                       { return( &m_addrlen ); }
    HRESULT GetHRESULT()                    { return( m_hr ); }

    void SetAddr( const sockaddr_in *pAddr )
    {
        if( NULL != pAddr )
        {
            memcpy( &m_addr, pAddr, sizeof(sockaddr_in) );
        }
    }

    void SetHRESULT( HRESULT hr )
    {
        m_hr = hr;
    }

private:
    LONG m_cRef;
    CCompletionHandler *m_pHandler;
    IoType m_ioType;
    BYTE *m_pbBuffer;
    DWORD m_cbBuffer;
    SOCKET m_Socket;
    CServerSocketCallback *m_pCallback;
    QWORD m_qwCallbackArg;
    sockaddr_in m_addr;
    int m_addrlen;
    HRESULT m_hr;
};

//////////////////////////////////////////////////////////////////////////////
class CServerSocket : public CCompletionHandler
{
public:

    static HRESULT __stdcall CreateInstance( 
                                CServerSocket **ppSocket, 
                                CCompletionPort *pIOCP, 
                                CCompletionPort *pAcceptIOCP, 
                                SOCKET s = INVALID_SOCKET );

    void *operator new(size_t len);
    void operator delete(void *pv);

    ULONG AddRef()
    {
        LONG lResult = InterlockedIncrement( &m_cRef );

        return( lResult );
    }

    ULONG Release()
    {
        LONG lResult = InterlockedDecrement( &m_cRef );

        if( 0 == lResult )
        {
            delete this;
            return( 0 );
        }

        return( 0xbad );
    }

    //
    // Synchronous. Must be called before any other function.
    // SO_REUSEADDR is set by default before the implicit call to Bind()
    //
    HRESULT Init( 
                int protocol,                   // IPPROTO_TCP, IPPROTO_UDP 
                const sockaddr_in *pAddress,    // IP address to bind to
                BOOL fReuseAddr,
                sockaddr_in *pAddressUsed = NULL );

    //
    // Synchronous.
    //
    HRESULT GetLocalAddress( sockaddr_in *pLocalAddress );

    HRESULT GetPeerAddress( sockaddr_in *pPeerAddress );

    //
    // TCP: Asynchronous
    // UDP: Synchronous
    //
    HRESULT Connect( 
                const sockaddr_in *pAddr,
                CServerSocketCallback *pCallback,
                QWORD qwCallbackArg );

    //
    // Synchronous.
    //
    HRESULT Listen( DWORD dwConnectionBacklog );

    //
    // Always asynchronous.
    //
    HRESULT Accept(
                CServerSocketCallback *pCallback,
                QWORD qwCallbackArg );

    //
    // TCP: Asynchronous. OnSocketSend is called on completion
    // UDP: Synchronous. If success, cbToSend is guaranteed to be the
    //      number of bytes sent.
    //
    HRESULT Send(
                BYTE *pbBuffer,
                DWORD cbToSend, 
                CServerSocketCallback *pCallback,
                QWORD qwCallbackArg );

    //
    // TCP: Asynchronous. OnSocketSend is called on completion
    // UDP: Synchronous. If success, cbToSend is guaranteed to be the
    //      number of bytes sent.
    //
    HRESULT SendEx(
                WSABUF *rgBuffers,
                DWORD cBuffers, 
                CServerSocketCallback *pCallback,
                QWORD qwCallbackArg );


    //
    // TCP: Not supported.
    // UDP: Synchronous. If success, cbToSend is guaranteed to be the
    //      number of bytes sent.
    //
    HRESULT SendTo( 
                BYTE *pbBuffer,
                DWORD cbToSend, 
                const sockaddr_in *pSendToAddr,
                CServerSocketCallback *pCallback,
                QWORD qwCallbackArg );

    //
    // Asynchronous. OnSocketReceive is called on completion
    //
    HRESULT Receive( 
                BYTE *pbBuffer,
                DWORD cbBuffer,
                CServerSocketCallback *pCallback,
                QWORD qwCallbackArg );

    //
    // Asynchronous. OnSocketReceiveFrom is called on completion
    //
    HRESULT ReceiveFrom( 
                BYTE *pbBuffer,
                DWORD cbBuffer,
                CServerSocketCallback *pCallback,
                QWORD qwCallbackArg );

    //
    // Synchronous.
    //
    HRESULT Close();

    //
    // Synchronous.
    //
    HRESULT GetSocket( SOCKET *pSocket );

    //
    // Synchronous. Sets I/O type.
    //
    HRESULT SetBlockingIO( BOOL fBlockingIO );

    //
    // Synchronous. TRUE disables TCP Nagle. FALSE enables.
    //
    HRESULT SetDisableNagle( BOOL fDisable );

    //
    // Synchronous. Sets the socket receive buffer size.
    //
    HRESULT SetReceiveBufferSize( DWORD dwBufferSize );

    //
    // Synchronous. Sets the socket send buffer size.
    //
    HRESULT SetSendBufferSize( DWORD dwBufferSize );

    //
    // Synchronous. TRUE causes broadcasts to be received (default).  FALSE ignores broadcasts.
    //
    HRESULT SetReceiveBroadcast( BOOL fReceive );

    //
    // TCP: Not supported.
    // UDP: Synchronous. Gets the maximum message size that is allowed on
    // the socket.
    //
    HRESULT GetMaxMessageSize( DWORD *pdwMaxMessageSize );

    //
    // CCompletionHandler impl
    //
    virtual void OnIoCompletion( 
                    DWORD dwError, 
                    DWORD cbTransferred, 
                    ULONG_PTR ulpKey,
                    CCompletionContext *pCtx );

    
    CCompletionPort* GetIOCP() { return ( m_pIOCP ); }

protected:
    CServerSocket();

    virtual ~CServerSocket();

    HRESULT InternalInit( CCompletionPort *pIOCP, CCompletionPort *pAcceptIOCP, SOCKET s );

    //
    // Common init code between Init() and sockets created with Accept()
    // 
    HRESULT FinishInit( int protocol );

    //
    // Helper function to call OnAccept()
    //
    void CallOnAccept( DWORD dwError, DWORD cbTransferred, CSocketIoContext *pCtx );

    //
    // Winsock error processing helper
    //
    static HRESULT HandleWSAReturnValue(
                            CSocketIoContext::IoType Operation, 
                            int iRet );

private:
    LONG m_cRef;

    SOCKET m_Socket;
    int m_protocol;

    BOOL m_fBlockingIO;
    BOOL m_fHavePeerAddr;

    sockaddr_in m_saddrLocal;
    sockaddr_in m_saddrPeer;

    CCompletionPort *m_pIOCP;
    CCompletionPort *m_pAcceptIOCP;
};


//////////////////////////////////////////////////////////////////////////////
class CServerSocketConnectWatchdog
{
public:

    enum
    {
        CONNECT_TIMEOUT = 20000,
        CONNECT_LIST_COUNT = 3,
        INITIAL_LIST_ALLOC = 64
    };
    
    CServerSocketConnectWatchdog();

    ~CServerSocketConnectWatchdog();

    HRESULT Init();

    void Shutdown();

    HRESULT AddConnectingSocket(
        CSocketIoContext* pContext );

    void Remove(
        CSocketIoContext* pContext );
    
protected:

    void Lock()
    {
        EnterCriticalSection(&m_cs);
    }

    void Unlock()
    {
        LeaveCriticalSection(&m_cs);
    }

    static DWORD WINAPI ConnectionWatchdogThreadProc(
        LPVOID pThisRaw );

    void ConnectionWatchdog();

    HRESULT EnsureInit()
    {
        HRESULT hr = S_OK;
        
        if(! m_bLazyInit)
        {
            Lock();

            if(! m_bLazyInit)
            {
                hr = Init();
            }

            Unlock();
        }
    
        return hr;
    }

    CRITICAL_SECTION m_cs;

    HANDLE m_hWatchdogThread;

    DWORD m_dwWatchdogThreadId;

    BOOL m_bLazyInit;

    HANDLE m_hChangeEvent;
    
    CVPtrList* m_pSocketList;

    HANDLE m_rghChangeEvent[CONNECT_LIST_COUNT + 1];

    DWORD m_dwNextList;
};
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\ntservice.cpp ===
// Copyright (c) Microsoft Corporation.  All rights reserved

#include "servhlpp.h"

#include "ntsecapi.h"
#include "msxml2.h"

#ifndef STATUS_SUCCESS
#define STATUS_SUCCESS  ((NTSTATUS)0x00000000L)
#endif

// Globals
extern CServerSocketConnectWatchdog g_SocketConnectWatchdog;



//////////////////////////////////////////////////////////////////////////////
CNTService::CNTService(
                LPCWSTR pszServiceName,
                LPCWSTR pszServiceDisplayName,
                LPCWSTR pszServiceDescription,
                LPCWSTR pszPerfBaseName,
                CComBSTR componentKey ) :
    m_pszServiceName( pszServiceName ),
    m_pszServiceDisplayName( pszServiceDisplayName ),
    m_pszServiceDescription( pszServiceDescription ),
    m_pszPerfBaseName( pszPerfBaseName ),
    m_fRunningAsService( TRUE ),
    m_hServiceStatus( NULL ),
    m_eComponent( componentKey )
{
    XOMASSERT( NULL != m_pszServiceName );
    ZeroMemory( &m_Status, sizeof(m_Status) );
    ZeroMemory( &m_szSvcAcctPwd, sizeof(m_szSvcAcctPwd) );

    m_fStartOnInstall = true;
    m_fResolvedPwd = false;

    m_Status.dwServiceType = SERVICE_WIN32_OWN_PROCESS;
    m_Status.dwCurrentState = SERVICE_STOPPED;
    m_Status.dwControlsAccepted = SERVICE_ACCEPT_STOP;

    m_hevtShutdown = CreateEvent( NULL, FALSE, FALSE, NULL );
}


//////////////////////////////////////////////////////////////////////////////
CNTService::~CNTService()
{
    SAFE_CLOSEHANDLE( m_hevtShutdown );
}

BOOL
AmIAService(
    PBOOL IsAService
    )
{

    PSID Service = NULL;
    PSID LocalSystem = NULL;
    SID_IDENTIFIER_AUTHORITY NtAuthority = SECURITY_NT_AUTHORITY ;
    BOOL IsService = FALSE ;
    BOOL IsLocalSystem = FALSE ;
    BOOL Success = FALSE ;

    if ( !AllocateAndInitializeSid(&NtAuthority, 1, SECURITY_LOCAL_SYSTEM_RID, 
            0, 0, 0, 0, 0, 0, 0, &LocalSystem ) )
    {
        return FALSE ;
    }

    if ( !AllocateAndInitializeSid( &NtAuthority, 1, SECURITY_SERVICE_RID, 
            0, 0, 0, 0, 0, 0, 0, &Service ) )
    {
        FreeSid( LocalSystem );
        return FALSE ;
        
    }

    *IsAService = FALSE ;

    if ( CheckTokenMembership(NULL, Service, &IsService ) )
    {
        if ( !IsService )
        {
            if ( CheckTokenMembership(NULL, LocalSystem, &IsLocalSystem ) )
            {
                Success = TRUE ;

                if ( IsLocalSystem )
                {
                    *IsAService = TRUE ;
                }
            }
            
        }
        else 
        {
            Success = TRUE ;

            *IsAService = TRUE ;
        }

    }

    FreeSid ( LocalSystem );
    FreeSid ( Service );
    return Success ;
}

//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::ProcessMain( DWORD dwArgc, LPWSTR *pszArgv )
{
    CoInitializeEx( NULL, COINIT_MULTITHREADED );

    //
    // Handle a few common command-line options
    //
    for( DWORD i = 1; i < dwArgc; i++ )
    {
        if( ( L'/' == pszArgv[ i ][ 0 ] ) || ( L'-' == pszArgv[ i ][ 0 ] ) )
        {
            if( 0 == _wcsicmp( pszArgv[ i ] + 1, L"Install" ) ||
                0 == _wcsicmp( pszArgv[ i ] + 1, L"Uninstall" ) )
            {
                InstallInfo();

                // Allow multiple instance of the same service to be installed by appending a number to the
                // end of the service name.
                if( i + 1 < dwArgc )
                {
                    // Be strict about what we allow here as it should have limited use
                    if( L'\0' == pszArgv[ i + 1 ][ 1 ] &&
                        L'0' <= pszArgv[ i + 1 ][ 0 ] &&
                        L'9' >= pszArgv[ i + 1 ][ 0 ] )
                    {
                        wcsncpy( m_szServiceName, m_pszServiceName, MAX_SERVICE_NAME - 2 );
                        wcscat_s( m_szServiceName, _countof(m_szServiceName), pszArgv[ i + 1 ] );
                        m_szServiceName[ MAX_SERVICE_NAME - 1 ] = L'\0';
                        m_pszServiceName = m_szServiceName;

                        wcsncpy( m_szServiceDisplayName, m_pszServiceDisplayName, MAX_SERVICE_NAME - 2 );
                        wcscat_s( m_szServiceDisplayName, _countof(m_szServiceDisplayName), pszArgv[ i + 1 ] );
                        m_szServiceDisplayName[ MAX_SERVICE_NAME - 1 ] = L'\0';
                        m_pszServiceDisplayName = m_szServiceDisplayName;
                    }
                }


                if( 0 == _wcsicmp( pszArgv[ i ] + 1, L"Install" ) )
                {
                    return( Install() );
                }
                else
                {
                    return( Uninstall() ) ;
                }
            }
        }
    }

    AmIAService( &m_fRunningAsService );

    //
    // Run the service main routine either on this thread (if running as
    // a console app) or on a new thread (if running as a service).
    //
    if( m_fRunningAsService )
    {
        SERVICE_TABLE_ENTRY DispatchTable[] =
        {
            { (WCHAR *) m_pszServiceName, StaticServiceMain },
            { NULL, NULL }
        };

        if( !StartServiceCtrlDispatcher( DispatchTable ) )
        {
            return( GetLastError() );
        }
    }
    else
    {
        // Allow Ctrl+C to exit the console app
        SetConsoleCtrlHandler( StaticConsoleCtrlHandler, TRUE );
        ServiceMain( dwArgc, pszArgv );
    }


    CoUninitialize();


    //
    // The service has been stopped (or the console has been shut down).
    //
    return( m_Status.dwWin32ExitCode );
}


//////////////////////////////////////////////////////////////////////////////
BOOL CNTService::IsServiceInstalled()
{
    BOOL fResult = FALSE;

    SC_HANDLE hSCM = OpenSCManager( NULL, NULL, SC_MANAGER_ALL_ACCESS );

    if( NULL != hSCM )
    {
        SC_HANDLE hService = ::OpenService( hSCM, m_pszServiceName, SERVICE_QUERY_CONFIG );

        if( NULL != hService )
        {
            fResult = TRUE;
            CloseServiceHandle( hService );
        }

        CloseServiceHandle( hSCM );
    }

    return( fResult );
}


//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::Install()
{
    DWORD dwRes = ERROR_SUCCESS;
    
    InstallInfo( "Configurator performing Install");

    do
    {
        //
        // Optionally uninstall the service - is this necessary?
        //
        if( IsServiceInstalled() )
        {
            InstallInfo( "Removing pre-existing service");

            dwRes = UninstallService();

            if( ERROR_SUCCESS != dwRes )
            {
                break;
            }
        }

        //
        // Optionally install into the SCM
        //
        dwRes = InstallService();

        if( ERROR_SUCCESS != dwRes )
        {
            break;
        }

    }
    while( FALSE );

    return( dwRes );
}

WCHAR *CNTService::GetExePathAndArgs()
{
    static WCHAR szFileName[MAX_PATH + 1];
    GetModuleFileName(NULL, szFileName, MAX_PATH);
    szFileName[MAX_PATH] = L'\0';
    return szFileName;
}

//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::Uninstall()
{
    DWORD dwRes = ERROR_SUCCESS;

    InstallInfo( "Configurator performing Uninstall");

    do
    {
        //
        // Remove the perfmon counters
        //
        dwRes = UninstallCounters();

        if( ERROR_FILE_NOT_FOUND == dwRes )
        {
            InstallInfo("Perf counters not found, continuing uninstall");
            dwRes = ERROR_SUCCESS;
        }
        else if( ERROR_SUCCESS != dwRes )
        {
            break;
        }

        //
        // Remove the service from the SCM
        //
        if( IsServiceInstalled() )
        {
            dwRes = UninstallService();

            if( ERROR_SUCCESS != dwRes )
            {
                break;
            }
        }
        else
        {
            InstallInfo( "Service was not present and did not have to be removed");
        }
    }
    while( FALSE );

    return( dwRes );
}


//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::InstallCounters()
{
    DWORD dwRes = ERROR_SUCCESS;


    do
    {
        // Skip this step if the service doesn't have a counter dll
        if(NULL == m_pszPerfBaseName)
            break;
        
        if(0 == wcslen(m_pszPerfBaseName))
            break;
        
        InstallInfo( "Installing performance counters specified in %S", m_pszPerfBaseName);

        //
        // Construct name of perf DLL from this EXE's base name
        //
        WCHAR szPerfDLL[ MAX_PATH ];
        wcscpy(szPerfDLL, m_pszPerfBaseName);
        wcscat(szPerfDLL, L".dll");

        //
        // Get the perf DLL to register its entry points
        //
        HMODULE hmodPerf = LoadLibrary( szPerfDLL );

        if( NULL == hmodPerf )
        {
            dwRes = GetLastError();
            break;
        }

        FARPROC DllRegServ = (FARPROC) GetProcAddress( hmodPerf, "DllRegisterServer" );

        if( NULL != DllRegServ )
        {
            DllRegServ();
        }

        FreeLibrary( hmodPerf );

    }
    while( FALSE );

    return( dwRes );
}


//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::UninstallCounters(LPCWSTR pszServiceName)
{
    DWORD dwRes = ERROR_SUCCESS;

    if (pszServiceName == NULL)
    {
        pszServiceName = m_pszServiceName;
    }

    do
    {
        // Skip this step if the service doesn't have a counter dll
        if(NULL == m_pszPerfBaseName)
            break;
        
        InstallInfo( "Removing performance counters specified in %S for service %S", 
                     m_pszPerfBaseName, pszServiceName);

        //
        // Use the same routine as unlodctr.exe to do the proper registry
        // grovelling necessary to remove our counters
        //
        WCHAR szCmdLine[ MAX_PATH ];
        wcscpy(szCmdLine, L"unlodctr.exe ");
        wcscat(szCmdLine, pszServiceName);

        dwRes = UnloadPerfCounterTextStrings( szCmdLine, TRUE );

        if( ERROR_SUCCESS != dwRes )
        {
            InstallError( "Failed to unload performance counters strings \"%S\" (0x%08x)\n", szCmdLine, dwRes );
            break;
        }
    }
    while( FALSE );

    return( dwRes );
}





//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::InstallService()
{
    DWORD dwRes = ERROR_SUCCESS;
    SC_HANDLE hSCM      = NULL;
    SC_HANDLE hService  = NULL;
    HANDLE    hToken    = NULL;
    CComBSTR bsEnvironment;
    CComBSTR bsServer;
    CComBSTR bsSvcUser;
    CComBSTR bsSvcPassword;
    CComBSTR bsSvcDependencies;
    CComBSTR bsSecurePath;

    do
    {
        InstallInfo( "Installing NT service");

        //
        // Anything to do?
        //
        if( IsServiceInstalled() )
        {
            InstallInfo( "WARNING: Service is already installed!  Pre-existance check didn't work?");
        }

        if( Component_unknown != m_eComponent )
        {
            CComPtr<XblConfig::IConfig>        pIConfig = NULL;
            CComPtr<XblConfig::IComponentInfo> pIComponentInfo = NULL;
        

            dwRes = pIConfig.CoCreateInstance( __uuidof( XblConfig::ConfigInterop ) );
            if( FAILED( dwRes ) )
            {
                InstallError( "Unable to CoCreateInstance configuration object (0x%08x)\n", dwRes );
                break;
            }

            dwRes = pIConfig->get_Server(&bsServer);
            if( FAILED( dwRes ) )
            {
                InstallError( "Failed to call get_Server (0x%08x)\n", dwRes );
            }

            dwRes = pIConfig->get_Environment(&bsEnvironment);
            if( FAILED( dwRes ) )
            {
                InstallError( "Failed to call get_Environment (0x%08x)\n", dwRes );
                //  This is not a fatal error, just means that xblobs might be setup with
                //  production recovery settings.  If this failed though, good money says
                //  that the next call will fail as well...
            }

            dwRes = pIConfig->GetComponent( m_eComponent, &pIComponentInfo );
            if( FAILED( dwRes ) )
            {
                InstallError( "Failed to call GetComponent for component %ws (0x%08x)\n", static_cast<wchar_t *> (m_eComponent), dwRes );
                break;
            }


            dwRes = pIConfig->GetSetting( Setting_setup_secureUNC, &bsSecurePath );
            if( FAILED( dwRes ) )
            {
                InstallError( "Failed to call GetSetting for secure path (0x%08x)\n", dwRes );
                break;
            }

            if (bsSecurePath.Length() > 0)
                bsSecurePath.Append("\\site.xml");



            InstallInfo( "Installing component %ws (%S) on %S in %S", static_cast<wchar_t *> (m_eComponent), m_pszServiceName, bsServer, bsEnvironment);

            //-------------------------------------------------------------------------
            // For NT services:
            // Username is used to specify the service account to run the service under
            // Password is used to _indirectly_ (see below) specify the password for 
            //          the service account in indicated in Username
            // Info1 is used to specify the list of service dependencies for this service
            //
            dwRes = pIComponentInfo->get_Username( &bsSvcUser );
            if( FAILED( dwRes ) )
            {
                InstallError( "Failed calling pIComponentInfo->get_Username (0x%08x)\n", dwRes );
                break;
            }


            dwRes = pIComponentInfo->get_Password( &bsSvcPassword );
            if( FAILED( dwRes ) )
            {
                InstallError( "Failed calling pIComponentInfo->get_Password (0x%08x)\n", dwRes );
                break;
            }
    

            if (bsSvcUser.m_str == NULL || bsSvcUser.Length() == 0 || bsSvcPassword.m_str == NULL || bsSvcPassword.Length() == 0)
            {
                InstallError( "Failed to find a user or password in config for component %ws\n", static_cast<wchar_t *> (m_eComponent));
                dwRes = ERROR_NOT_FOUND;
                break;
            }
            //-------------------------------------------------------------------------
            // In order to secure service account passwords, the password info in the 
            // configDB is used to identify entries in a secured site.xml file that 
            // will (in production) only be exposed via UNC during setup operations
            // 
            // We use this method to dereference the account identifier in the DB 
            // to an actual PW stored in the site.xml file (basically a simple
            // lookup operation in an XML file)
            // 
            // The path stored in the configDB will not include the filespec itself,
            // so it ("\\site.xml") will be added by the ResolveSecret()
            //
            dwRes = ResolveSecret(bsSecurePath, bsSvcPassword);




            //-------------------------------------------------------------------------
            // For NT Services, we use the Info1 column to store a comma delimited 
            // list of services that this service depends upon.  However, in order to
            // feed it to SCM, it needs to be a double null terminated, null delimited
            // list of strings.
            // 
            dwRes = pIComponentInfo->get_Info1( &bsSvcDependencies );
            if( FAILED( dwRes ) )
            {
                InstallError( "Failed calling pIComponentInfo->get_Info1 (0x%08x)\n", dwRes );
                break;
            }


            // Split multiple dependancies on delimiters (',', ';', and '/')
            for (size_t i = 0; i < bsSvcDependencies.Length(); ++i)
            {
                if (bsSvcDependencies[i] == L',' || bsSvcDependencies[i] == L';' || bsSvcDependencies[i] == L'/')
                {
                    bsSvcDependencies[i] = L'\0';
                }
            }
#if defined(_M_IX86)
            // If we are doing a 32bit service, then add a dependency on PerfHost so 32bit counters show up on startup.
            if (bsSvcDependencies.Length() > 0)
            {
                // Add NULL separator for no-empty string.
                bsSvcDependencies.Append( L"\0", 1);
            }
            bsSvcDependencies.Append( L"PerfHost", 8 );
#endif
            bsSvcDependencies.Append( L"\0", 1);      // Depedencies are supposed to be a double null terminated list of null terminated strings
        }
        else
        {
            bsSvcDependencies.Append( L"RPCSS\0", 6 );
            bsEnvironment = L"";
        }


        //
        // It is very unfortunate that at this point dwRes holds a HRESULT
        // while this function returns a Win32 error by contract. The best
        // compromise is to have the function return a value that honors the
        // win32 success/failure semantics (0 -> success, failure otherwise),
        // but could potentially return hresults/ntstatus's as failure. This
        // ensures that returns such as S_FALSE are sanitized, but that doesn't
        // fix callers that use FAILED(dwRes). Those need to be fixed case by
        // case
        //
        dwRes = ERROR_SUCCESS;

        //
        // Figure out where this .EXE lives
        //
        WCHAR *szFileName = GetExePathAndArgs();

        // If there was a service account specified, make sure that account is granted
        // rights to logon as a service
        if (bsSvcUser != NULL)
        {
            dwRes = GrantLogonRights(bsSvcUser);
            if ( ERROR_SUCCESS != dwRes )
            {
                if (dwRes == 0x80070534)
                    InstallError( "Failed granting SeLogonServiceRight to %S because account could not be resolved (0x%08x)\n", bsSvcUser, dwRes );
                else
                    InstallError( "Failed granting SeLogonServiceRight to %S (0x%08x)\n", bsSvcUser, dwRes );
                break;
            }
        }

        //
        // Contact the SCM and attempt to add a new service
        //
        hSCM = OpenSCManager( NULL, NULL, SC_MANAGER_ALL_ACCESS );

        if( NULL == hSCM )
        {
            dwRes = GetLastError();
            InstallError( "Failed opening Service Control Manager (0x%08x)\n", dwRes );
            break;
        }

        DWORD dwFlags = SERVICE_WIN32_OWN_PROCESS;

#if DBG
        // $REVIEW (michion):  Can't specify a service account and interactive process
        //                     at the same time
        if (bsSvcUser == NULL)
        {
            dwFlags |= SERVICE_INTERACTIVE_PROCESS;
        }

#endif

        hService = CreateService(
                            hSCM,
                            m_pszServiceName,
                            m_pszServiceDisplayName,
                            SERVICE_ALL_ACCESS,
                            dwFlags,
                            SERVICE_AUTO_START,
                            SERVICE_ERROR_NORMAL,
                            szFileName,
                            NULL,
                            NULL,
                            bsSvcDependencies,
                            bsSvcUser,
                            m_szSvcAcctPwd );

        if( NULL == hService )
        {
            // common errors:  1057 = ERROR_INVALID_SERVICE_ACCOUNT
            dwRes = GetLastError();
            InstallError( "Failed to create service %S (0x%08x)\n", m_pszServiceName, dwRes );
            break;
        }

        InstallInfo( "Service '%S' (%S) successfully created", m_pszServiceDisplayName, m_pszServiceName);

        //
        // Associate our descriptive string with the newly installed service
        //
        SERVICE_DESCRIPTION scDescription;
        scDescription.lpDescription = (LPWSTR) m_pszServiceDescription;

        if( !ChangeServiceConfig2(
                        hService,
                        SERVICE_CONFIG_DESCRIPTION,
                        (void *) &scDescription ) )
        {
            dwRes = GetLastError();
            InstallError( "Failed to change service description (0x%08x)\n", dwRes );
            break;
        }

        //---------------------------------------------------------------------
        // Now, reconfigure the service retry configuration.  This turns out to
        // be a bit of a PITA because it requires the process token to have
        // the SE_SHUTDOWN_NAME privilege enabled which isn't (apparently)
        // present by default, even for machine/domain admins.
        //
        InstallInfo( "Setting service retry configuration");

        TOKEN_PRIVILEGES        tkPrivileges;
        SERVICE_FAILURE_ACTIONS scFailureActions;
        SC_ACTION               rgActions[4];
    
        if( !OpenProcessToken(GetCurrentProcess(), TOKEN_ADJUST_PRIVILEGES | TOKEN_QUERY, &hToken ) )
        {
            dwRes = GetLastError();
            InstallError( "Failed calling OpenProcessToken (0x%08x)\n", dwRes );
            break;
        }
     
        LookupPrivilegeValue(NULL, SE_SHUTDOWN_NAME, &tkPrivileges.Privileges[0].Luid); 

        tkPrivileges.PrivilegeCount           = 1;
        tkPrivileges.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED; 
     
        if( !AdjustTokenPrivileges(hToken, FALSE, &tkPrivileges, 0, (PTOKEN_PRIVILEGES)NULL, 0) ||
            ERROR_SUCCESS != GetLastError() ) // Not all privileges were adjusted
        {
            dwRes = GetLastError();
            InstallError( "Failed calling AdjustTokenPrivileges (0x%08x)\n", dwRes );
            break;
        }

        //---------------------------------------------------------------------
        // With that out of the way, we can set the restart configuration
        // (the privilege switch above is needed in order to set an
        // SC_ACTION_REBOOT Type entry)
        //
        if(_wcsicmp(bsEnvironment.m_str, L"xblob") == 0)
        {
            rgActions[0].Type  = SC_ACTION_NONE;     // $REVIEW (michion): parameterize these into member vars
            rgActions[0].Delay = 5000;
            rgActions[1].Type  = SC_ACTION_NONE;
            rgActions[1].Delay = 5000;
            rgActions[2].Type  = SC_ACTION_NONE;
            rgActions[2].Delay = 5000;
            rgActions[3].Type  = SC_ACTION_NONE;
            rgActions[3].Delay = 5000;
        }
        else
        {
            rgActions[0].Type  = SC_ACTION_RESTART;     // $REVIEW (michion): parameterize these into member vars
            rgActions[0].Delay = 5000;
            rgActions[1].Type  = SC_ACTION_RESTART;
            rgActions[1].Delay = 15000;
            rgActions[2].Type  = SC_ACTION_RESTART;
            rgActions[2].Delay = 30000;
            rgActions[3].Type  = SC_ACTION_NONE;
            rgActions[3].Delay = 1000;
        }

        scFailureActions.dwResetPeriod = 1800;
        scFailureActions.lpRebootMsg   = L"";
        scFailureActions.lpCommand     = L"";
        scFailureActions.cActions      = sizeof(rgActions)/sizeof(rgActions[0]);
        scFailureActions.lpsaActions   = rgActions;

        if( !ChangeServiceConfig2(
                        hService,
                        SERVICE_CONFIG_FAILURE_ACTIONS,
                        (void *) &scFailureActions ) )
        {
            dwRes = GetLastError();
            InstallError( "Failed calling ChangeServiceConfig2 (0x%08x)\n", dwRes );
            break;
        }



        dwRes = InstallCounters();

        if( ERROR_SUCCESS != dwRes )
        {
            InstallError( "Failed calling InstallCounters (0x%08x)\n", dwRes );
            break;
        }
        




        if (m_fStartOnInstall)
        {
            InstallInfo( "Starting service %S", m_pszServiceName);

            if( !StartService(
                            hService,
                            0,
                            NULL ) )
            {
                dwRes = GetLastError();
                InstallError( "Failed calling StartService (0x%08x)\n", dwRes );
                break;
            }
        }


    }
    while( FALSE );

    //
    // Clean up
    //
    if( NULL != hToken )
    {
        CloseHandle( hToken );
    }

    if( NULL != hService )
    {
        CloseServiceHandle( hService );
    }

    if( NULL != hSCM )
    {
        CloseServiceHandle( hSCM );
    }
    
    return( dwRes );
}







//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::UninstallService()
{
    DWORD dwRes = ERROR_SUCCESS;
    SC_HANDLE hSCM = NULL;
    SC_HANDLE hService = NULL;
    BOOL      fOK = FALSE;

    do
    {
        InstallInfo( "Uninstalling NT service");

        //
        // Anything to do?
        //
        if( !IsServiceInstalled() )
        {
            InstallInfo( "WARNING: Service is not installed!  Pre-existance check didn't work?");
            break;
        }

        //
        // Contact the SCM and attempt to open the existing service
        //
        hSCM = OpenSCManager( NULL, NULL, SC_MANAGER_ALL_ACCESS );

        if( NULL == hSCM )
        {
            dwRes = GetLastError();
            InstallError( "Failed opening Service Control Manager (0x%08x)\n", dwRes );
            break;
        }

        hService = OpenService( hSCM, m_pszServiceName, SERVICE_STOP | DELETE );

        if( NULL == hService )
        {
            dwRes = GetLastError();
            InstallError( "Failed retrieving service handle for %S (0x%08x)\n", m_pszServiceName, dwRes );
            break;
        }

        //
        // Stop and delete the service
        //
        SERVICE_STATUS status;

        fOK = ControlService( hService, SERVICE_CONTROL_STOP, &status );
        if (!fOK)
        {
            dwRes = GetLastError();

            if (dwRes != 0x00000426)   // if the service isn't running, we should get back 0x0426 (ERROR_SERVICE_NOT_ACTIVE)
            {
                InstallError( "Failed to stop service %S.  Service delete will probably fail as well (0x%08x)\n", m_pszServiceName, dwRes );
            }
            else
            {
                dwRes = 0;  // reset the exit code so that XMGMT doesn't think this was an actual error
            }
        }


        if( !DeleteService( hService ) )
        {
            dwRes = GetLastError();
            InstallError( "Failed deleting service %S (0x%08x)\n", m_pszServiceName, dwRes );
            break;
        }

        InstallInfo( "Service '%S' (%S) successfully stopped and deleted", m_pszServiceDisplayName, m_pszServiceName);

    }
    while( FALSE );

    //
    // Clean up
    //
    if( NULL != hService )
    {
        CloseServiceHandle( hService );
    }

    if( NULL != hSCM )
    {
        CloseServiceHandle( hSCM );
    }
 
    if ( ERROR_SUCCESS == dwRes)
    {
        // It sometimes takes a while for the service to "disappear". Doing the install 
        // too soon may results in a 1072, ERROR_SERVICE_MARKED_FOR_DELETE, error code.  
        // We'll wait "a bit" before returning to make sure the service really goes away, 
        // then just give up.
        for (DWORD secondsToWait = 30; secondsToWait > 0; secondsToWait--)
        {
            if (!IsServiceInstalled())
            {
                break;
            }
            InstallInfo("Waiting %d more seconds for the service to actually get deleted...", secondsToWait);
            Sleep(1000);
        }
    }

    return( dwRes );
}

////////////////////////////////////////////////////////////////////////////
void CNTService::InstallError( char* pszFmt, ... )
{
    char szFmt[ 1024 ];
    va_list marker;

    va_start( marker, pszFmt );
    _vsnprintf(szFmt, ARRAY_ELEMENTS(szFmt), pszFmt, marker );
    printf("InstallError: %s\n", szFmt);
    va_end( marker );

    return;
}


////////////////////////////////////////////////////////////////////////////
void CNTService::InstallInfo( char* pszFmt, ... )
{
    if (pszFmt == NULL)
    {
        printf("CNTService configurator intializing\n");
    }
    else
    {
        char szFmt[ 1024 ];
        va_list marker;

        va_start( marker, pszFmt );
        _vsnprintf(szFmt, ARRAY_ELEMENTS(szFmt), pszFmt, marker );
        printf("   %s\n", szFmt);
        va_end( marker );
    }

    return;
}




////////////////////////////////////////////////////////////////////////////
DWORD CNTService::ChangeState( DWORD dwState )
{
    m_Status.dwCheckPoint = (DWORD) -1; // will be inc. in Checkpoint()
    m_Status.dwCurrentState = dwState;

    return( Checkpoint() );
}


///////////////////////////////////////////////////////////////////////////////////////
DWORD CNTService::Checkpoint( DWORD dwWaitHint /* = 0 */ )
{
    if( m_fRunningAsService )
    {
        m_Status.dwWaitHint = dwWaitHint;
        m_Status.dwCheckPoint++;
        
        if( !SetServiceStatus( m_hServiceStatus, &m_Status ) )
        {
            return( GetLastError() );
        }
    }

    return( ERROR_SUCCESS );
}


////////////////////////////////////////////////////////////////////////////
DWORD CNTService::ReportError( DWORD dwErr )
{
    m_Status.dwWin32ExitCode = ERROR_SERVICE_SPECIFIC_ERROR;
    m_Status.dwServiceSpecificExitCode = dwErr;

    return( Checkpoint() );
}


//////////////////////////////////////////////////////////////////////////////
void CNTService::ServiceMain( DWORD dwArgc, LPWSTR *pszArgv )
{
    // CONSIDER: Move mgmt initialization here

    if( m_fRunningAsService )
    {
        m_hServiceStatus = RegisterServiceCtrlHandler(
                                            m_pszServiceName,
                                            StaticServiceControlHandler );

        if( NULL == m_hServiceStatus )
        {
            m_Status.dwWin32ExitCode = GetLastError();
            return;
        }
    }

    ChangeState( SERVICE_START_PENDING );

    m_Status.dwWin32ExitCode = S_OK;
    m_Status.dwCheckPoint = 0;
    m_Status.dwWaitHint = 0;

    HRESULT hr = S_OK;
    BOOL fServiceRan = FALSE;

    do
    {
        Checkpoint();

        hr = InitService( dwArgc, pszArgv );

        if( FAILED( hr ) )
        {
            break;
        }

        Checkpoint();

        ChangeState( SERVICE_RUNNING );

        hr = RunService( &fServiceRan );

        if( FAILED( hr ) )
        {
            break;
        }
    }
    while( FALSE );

    if ( FAILED( hr ) && !fServiceRan )
    {
        ChangeState( SERVICE_STOP_PENDING );
        ReportError( hr );
    }

    ChangeState( SERVICE_STOPPED );
}

//////////////////////////////////////////////////////////////////////////////
void CNTService::TermService()
{
    // wake up the RunService thread
    SetEvent( m_hevtShutdown );
}

//////////////////////////////////////////////////////////////////////////////
void CNTService::ServiceControlHandler( DWORD dwOpcode )
{
    switch (dwOpcode )
    {
    case SERVICE_CONTROL_STOP:
        // tell scm we're stopping
        ChangeState( SERVICE_STOP_PENDING );

        // wake up any sockets that are waiting to connect
        g_SocketConnectWatchdog.Shutdown();

        TermService();
        break;

    case SERVICE_CONTROL_PAUSE:
    case SERVICE_CONTROL_CONTINUE:
    case SERVICE_CONTROL_INTERROGATE:
    case SERVICE_CONTROL_SHUTDOWN:
    case SERVICE_CONTROL_PARAMCHANGE:
    case SERVICE_CONTROL_NETBINDADD:
    case SERVICE_CONTROL_NETBINDREMOVE:
    case SERVICE_CONTROL_NETBINDENABLE:
    case SERVICE_CONTROL_NETBINDDISABLE:
    case SERVICE_CONTROL_DEVICEEVENT:
    case SERVICE_CONTROL_HARDWAREPROFILECHANGE:
    case SERVICE_CONTROL_POWEREVENT:
    case SERVICE_CONTROL_SESSIONCHANGE:
        //
        // ignored
        //
        break;

    default:
        //
        // Unknown service control opcode?
        //
        XomTrace(
            ServHlpDebug,
            L_NORMAL,
            "ServiceControlHandler: unknown opcode %d", 
            dwOpcode);
    }
}


//////////////////////////////////////////////////////////////////////////////
void WINAPI CNTService::StaticServiceMain( DWORD dwArgc, LPWSTR *pszArgv )
{
    XOMASSERT( NULL != g_pService );
    g_pService->ServiceMain( dwArgc, pszArgv );
}


//////////////////////////////////////////////////////////////////////////////
void WINAPI CNTService::StaticServiceControlHandler( DWORD dwOpcode )
{
    XOMASSERT( NULL != g_pService );
    g_pService->ServiceControlHandler( dwOpcode );
}

//////////////////////////////////////////////////////////////////////////////
BOOL WINAPI CNTService::StaticConsoleCtrlHandler( DWORD dwCtrlType )
{
    XOMASSERT( NULL != g_pService );
    g_pService->ServiceControlHandler( SERVICE_CONTROL_STOP );
    return TRUE;
}

//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::GrantLogonRights(LPCWSTR szAccount)
{
    DWORD       dwRes       = ERROR_SUCCESS;
    NTSTATUS    ntStatus    = 0;

    LSA_OBJECT_ATTRIBUTES   ObjectAttributes;
    LSA_UNICODE_STRING      PrivilegeString;
    LSA_HANDLE              PolicyHandle = NULL;

    CSIDLookup              sidLookup;

    dwRes = sidLookup.Lookup(szAccount);
    if (FAILED(dwRes))
    {
        goto lCleanup;
    }

    //
    // It is very unfortunate that at this point dwRes holds a HRESULT
    // while this function returns a Win32 error by contract. The best
    // compromise is to have the function return a value that honors the
    // win32 success/failure semantics (0 -> success, failure otherwise),
    // but could potentially return hresults/ntstatus's as failure. This
    // ensures that returns such as S_FALSE are sanitized, but that doesn't
    // fix callers that use FAILED(dwRes). Those need to be fixed case by
    // case
    //
    dwRes = ERROR_SUCCESS;

    ZeroMemory(&ObjectAttributes, sizeof(ObjectAttributes));

    ntStatus = ::LsaOpenPolicy(
                    NULL,
                    &ObjectAttributes,
                    POLICY_CREATE_ACCOUNT | POLICY_LOOKUP_NAMES,
                    &PolicyHandle
                    );

    if (ntStatus != STATUS_SUCCESS)
    {
        dwRes = ::LsaNtStatusToWinError(ntStatus);
        goto lCleanup;
    }

    

    PrivilegeString.Buffer        = L"SeServiceLogonRight";
    PrivilegeString.Length        = (USHORT) wcslen(PrivilegeString.Buffer) * sizeof(WCHAR);
    PrivilegeString.MaximumLength = (USHORT)(wcslen(PrivilegeString.Buffer)+1) * sizeof(WCHAR);


    ntStatus = ::LsaAddAccountRights(
                    PolicyHandle,
                    sidLookup.GetPSID(),
                    &PrivilegeString,
                    1
                    );

    if (ntStatus != STATUS_SUCCESS)
    {
        dwRes = LsaNtStatusToWinError(ntStatus);
        goto lCleanup;
    }


lCleanup:
    if (PolicyHandle)
    {
        LsaClose(PolicyHandle);
        PolicyHandle = NULL;
    }

    return( dwRes );
}







//////////////////////////////////////////////////////////////////////////////
DWORD CNTService::ResolveSecret(LPCWSTR szPath, LPCWSTR szSecret)
{
    HRESULT             hr = E_UNEXPECTED;

    IXMLDOMDocument     *pXmlDoc    = NULL;
    IXMLDOMNode         *pNode      = NULL;

    VARIANT_BOOL        varStatus;

    CComBSTR            bstrText;
    CComBSTR            bstrFilter;

    VARIANT             varPath;


    // We will allow the database to contain an unencrypted password for use
    // in non-critical environments (test).  The resolution logic here will
    // bail out if the secret .xml file isn't found or can't resolve the
    // szSecret string which allows us to use real passwords in the configDB
    // in test environments OR lookup identifiers in real environments
    //
    // We also carry the m_fResolvedPwd flag to record whether we did a 
    // successful lookup so we can generate event logs if we are not 
    // performing succesful lookups in environments that we expect to
    //
    // $REVIEW (michion): of course we have to implement that...
    //
    m_fResolvedPwd = true;
    wcsncpy(m_szSvcAcctPwd, szSecret, MAX_SERVICE_ACCT_PWD);

    do
    {
        // We will typically bypass the lookup mechanism by specifying an empty
        // setup_secureUNC value so we will bypass all this code and allow the
        // the initialization to supply the password directly from the configDB
        // and also avoid any spurious error messages that would otherwise be
        // generated below
        //
        if (wcslen(szPath) == 0)
        {
            InstallInfo("Bypassing secure account information lookup -- only acceptable in non production environments");
            hr = S_OK;
            break;
        }


        // in non-critical environments (test).  The resolution logic here will
        VariantInit(&varPath);
        V_BSTR(&varPath) = SysAllocString(szPath);
        V_VT(&varPath)   = VT_BSTR;
    
        hr = CoCreateInstance(__uuidof(DOMDocument30),
                                NULL,
                                CLSCTX_INPROC_SERVER,
                                __uuidof(IXMLDOMDocument),
                                (void**)&pXmlDoc);

        if( FAILED( hr ) )
        {
            InstallError( "Failed to CoCreateInstance DOMDocument30 object (0x%08x)\n", hr );
            break;
        }


        hr = pXmlDoc->put_async(VARIANT_FALSE);

        hr = pXmlDoc->put_validateOnParse(VARIANT_FALSE);

        hr = pXmlDoc->put_resolveExternals(VARIANT_FALSE);



        hr = pXmlDoc->load(varPath, &varStatus);
        if( FAILED( hr ) )
        {
            InstallError( "Failed calling load for XML doc  %S (0x%08x)\n", szPath, hr );
            break;
        }


        if (varStatus != VARIANT_TRUE || pXmlDoc == NULL)
        {
            InstallError( "Failed to load XML doc %S (0x%08x)\n", szPath, hr );
            break;
        }




        bstrFilter = L"//Site/Domain/Account[@Identifier = \"";
        bstrFilter.Append(szSecret);
        bstrFilter.Append(L"\"]/Password");




        hr = pXmlDoc->selectSingleNode(bstrFilter, &pNode);
        if( FAILED( hr ) )
        {
            InstallError( "Failed calling selectSingleNode for %S (0x%08x)\n", bstrFilter, hr );
            break;
        }


        if( pNode == NULL)
        {
            InstallError( "Failed to retrieve node %S (0x%08x)\n", bstrFilter, hr );
            break;
        }


        hr = pNode->get_text(&bstrText);
        if( FAILED( hr ) )
        {
            InstallError( "Failed to node text %S (0x%08x)\n", bstrFilter, hr );
            break;
        }


        // WOOT got it all resolved!  Squirrel away the lookup result into our member var
        // for later consumption by the code responsible for setting up the NT service
        //
        m_fResolvedPwd = true;
        wcsncpy(m_szSvcAcctPwd, bstrText, MAX_SERVICE_ACCT_PWD);
    }
    while( FALSE );


    //
    // Clean up
    //
    if( NULL != pNode )
    {
        pNode->Release();
        pNode = NULL;
    }

    if( NULL != pXmlDoc )
    {
        pXmlDoc->Release();
        pXmlDoc = NULL;
    }
    
    return( hr );
}













CSIDLookup::CSIDLookup()
{
    m_cbSID            = 0;
    m_cchRefDomainName = 0;
    m_pSID             = NULL;
    m_szRefDomainName  = NULL;
}


CSIDLookup::~CSIDLookup()
{
    if (m_pSID)
    {
        ::LocalFree(m_pSID);
        m_pSID = NULL;
    }

    if (m_szRefDomainName)
    {
        ::LocalFree(m_szRefDomainName);
        m_szRefDomainName = NULL;
    }
}


HRESULT CSIDLookup::Lookup(LPCWSTR szAccount)
{
    BOOL    fRet    = false;
    HRESULT hr      = S_OK;
    DWORD   dwRes   = ERROR_SUCCESS;
    SID     sidDummy;
    WCHAR   wstrDummy[2];

    // Get the required buffer sizes

    // N.B.: This is royally F*(&@#D up!  The MSDN docs claim that passing
    //       NULL for the PSID and ReferenceDomainName parameters will,
    //       in conjunction with passing pointers to zero'd out DWORDs for
    //       cbSid and cchReferenceDomainName, return the amount of
    //       space needed for these two buffers.  Total BS!  Unless the
    //       pointers are non-NULL, the function won't return anything in
    //       the cb/cch DWORDS except zero


    fRet = LookupAccountName(
            NULL,
            szAccount,
            &sidDummy,
            &m_cbSID,
            wstrDummy,
            &m_cchRefDomainName,
            &m_SIDNameUse
            );

    if (!fRet)
    {
        dwRes = ::GetLastError();
        if (dwRes == ERROR_INSUFFICIENT_BUFFER)
        {
            //-----------------------------------------------------------------
            // this is ok, we expected the function to complain about buffer
            // sizes being too small.  Just keep going now that we have the
            // actual buffer sizes we need in m_cbSID and m_cchRefDomainName
            //
            dwRes = ERROR_SUCCESS;
        }
        else
        {
            //-----------------------------------------------------------------
            // Gotta convert errors into HRESULTS (caller is checking FAILED()
            // which doesn't pick up on regular win32 errors
            //
            hr = HRESULT_FROM_WIN32(dwRes);
            goto lCleanup;
        }
    }
    
    
    m_szRefDomainName = (LPWSTR)::LocalAlloc(LPTR, m_cchRefDomainName * sizeof(TCHAR));
    if (m_szRefDomainName == NULL)
    {
        hr = E_OUTOFMEMORY;
        goto lCleanup;
    }
    
    
    m_pSID = (PSID)::LocalAlloc(LPTR, m_cbSID);
    if (m_pSID == NULL)
    {
        hr = E_OUTOFMEMORY;
        goto lCleanup;
    }
    
    
    // Do the lookup for real now
    fRet = LookupAccountName(
             NULL,
             szAccount,
             m_pSID,
             &m_cbSID,
             m_szRefDomainName,
             &m_cchRefDomainName,
             &m_SIDNameUse
             );
    
    if (!fRet)
    {
        dwRes = ::GetLastError();
        hr = HRESULT_FROM_WIN32(dwRes);
        goto lCleanup;
    }
    

lCleanup:
    if (FAILED(hr))
    {
        if (m_pSID)
        {
            ::LocalFree(m_pSID);
            m_pSID = NULL;
        }
        
        if (m_szRefDomainName)
        {
            ::LocalFree(m_szRefDomainName);
            m_szRefDomainName = NULL;
        }
    }

    return hr;
}


PSID    CSIDLookup::GetPSID(void)
{
    return m_pSID;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\servsock.cpp ===
// Copyright (c) Microsoft Corporation.  All rights reserved

#include "servhlpp.h"


CServerSocketConnectWatchdog g_SocketConnectWatchdog;

//////////////////////////////////////////////////////////////////////////////
#define ACCEPT_ADDRESS_LEN          ( 16 + sizeof(sockaddr_in) )
#define ACCEPT_ADDRESS_BUFFER_SIZE  ( 2 * ACCEPT_ADDRESS_LEN )

//////////////////////////////////////////////////////////////////////////////
void* CSocketIoContext::operator new(size_t len) 
{ 
    return XAlloc(len); 
}

void CSocketIoContext::operator delete(void *pv) 
{ 
    XFree(pv); 
}

//////////////////////////////////////////////////////////////////////////////
void* CServerSocket::operator new(size_t len) 
{ 
    return XAlloc(len); 
}

void CServerSocket::operator delete(void *pv) 
{ 
    XFree(pv); 
}

//////////////////////////////////////////////////////////////////////////////
char *GetIPDisplayString( DWORD dwIP )
{
    in_addr a;

    a.S_un.S_addr = htonl( dwIP );

    return( inet_ntoa( a ) );
}

//////////////////////////////////////////////////////////////////////////////
HRESULT __stdcall CServerSocket::CreateInstance( 
                            CServerSocket **ppSocket, 
                            CCompletionPort *pIOCP, 
                            CCompletionPort *pAcceptIOCP, 
                            SOCKET s )
{
    //
    // Validate arguments
    //
    if( NULL == ppSocket )
    {
        return( E_INVALIDARG );
    }

    HRESULT hr;
    
    do
    {
        *ppSocket = new CServerSocket;

        if( NULL == *ppSocket )
        {
            hr = E_OUTOFMEMORY;
            break;
        }

        hr = (*ppSocket)->InternalInit( pIOCP, pAcceptIOCP, s );

        if( FAILED( hr ) )
        {
            break;
        }
    
        hr = S_OK;
    }
    while( FALSE );

    if( FAILED( hr ) )
    {
        SAFE_RELEASE( *ppSocket );
    }
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
CServerSocket::CServerSocket() :
    m_cRef( 1 ),
    m_Socket( INVALID_SOCKET ),
    m_protocol( IPPROTO_MAX ),
    m_fBlockingIO( FALSE ),
    m_fHavePeerAddr( FALSE ),
    m_pIOCP( NULL ),
    m_pAcceptIOCP( NULL )
{
}


//////////////////////////////////////////////////////////////////////////////
CServerSocket::~CServerSocket()
{
    Close();

    SAFE_RELEASE( m_pIOCP );
    SAFE_RELEASE( m_pAcceptIOCP );
}


/////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::InternalInit(
                        CCompletionPort *pIOCP, 
                        CCompletionPort *pAcceptIOCP, 
                        SOCKET s )
{
    m_pIOCP = pIOCP;
    
    if( NULL == m_pIOCP )
    {
        XOMASSERT( !"Need an IOCP here" );
        return( E_INVALIDARG );
    }

    SAFE_ADDREF( m_pIOCP );

    m_pAcceptIOCP = pAcceptIOCP;
    SAFE_ADDREF( m_pAcceptIOCP );

    m_Socket = s;

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::Init( 
                int protocol,
                const sockaddr_in *pAddress,
                BOOL fReuseAddr,
                sockaddr_in *pAddressUsed )
{
    //
    // Validate arguments
    //
    if( NULL == pAddress )
    {
        return( E_INVALIDARG );
    }

    if( pAddress->sin_family != AF_INET )
    {
        XOMASSERT( !"Bad address family (not AF_INET)" );
        return( E_INVALIDARG );
    }

    HRESULT hr;
    
    do
    {
        //
        // If we had already been inited before, close the socket first
        //
        if( INVALID_SOCKET != m_Socket )
        {
            hr = Close();

            if( FAILED( hr ) )
            {
                XOMASSERT( !"How come we are failing here?" );
                break;
            }
        }

        //
        // Decide on the socket type based on the requested protocol
        //
        int socketType;
        switch( protocol )
        {
        case IPPROTO_IP:
            socketType = SOCK_RAW;
            break;
        case IPPROTO_TCP:
            socketType = SOCK_STREAM;
            break;
        case IPPROTO_UDP:
            socketType = SOCK_DGRAM;
            break;
        default:
            XOMASSERT( !"Unsupported protocol" );
            return( E_INVALIDARG );
        }

        //
        // Allocate a new overlapped IO socket
        //
        m_Socket = WSASocket(
                        pAddress->sin_family,
                        socketType,
                        protocol,
                        NULL,
                        0,
                        WSA_FLAG_OVERLAPPED );

        if( INVALID_SOCKET == m_Socket )
        {
            hr = HRESULT_FROM_WIN32( WSAGetLastError( ) );
            break;
        }

        //
        // Configure the socket for proper address reuse
        //
        int rc = setsockopt(
                    m_Socket,
                    SOL_SOCKET,
                    SO_REUSEADDR,
                    (const char *) &fReuseAddr,
                    sizeof(fReuseAddr) );

        if( SOCKET_ERROR == rc )
        {
            hr = HRESULT_FROM_WIN32( WSAGetLastError( ) );        
            break;
        }

        //
        // Bind the socket to a local address
        //
        rc = bind( m_Socket, (sockaddr *) pAddress, sizeof(sockaddr_in) );
        if( SOCKET_ERROR == rc )
        {
            hr = HRESULT_FROM_WIN32( WSAGetLastError( ) );        
            break;
        }

        //
        // Get the address that we are bound to and optionally return to
        // the caller.
        //
        int addrLen = sizeof(sockaddr_in);

        rc = getsockname( m_Socket, (sockaddr *) &m_saddrLocal, &addrLen );
        if( SOCKET_ERROR == rc )
        {
            hr = HRESULT_FROM_WIN32( WSAGetLastError( ) );        
            break;
        }

        if( NULL != pAddressUsed )
        {
            memcpy( pAddressUsed, &m_saddrLocal, sizeof(sockaddr_in) );
        }

        //
        // For raw sockets, specify that the sender will supply the IP header when Send/SendTo is called
        //
        if( SOCK_RAW == socketType )
        {
            DWORD dwOptionOn = 1;
            rc = setsockopt(
                        m_Socket,
                        IPPROTO_IP,
                        IP_HDRINCL,
                        (char *) &dwOptionOn,
                        sizeof( dwOptionOn ) );
            if( SOCKET_ERROR == rc )
            {
                hr = HRESULT_FROM_WIN32( WSAGetLastError( ) );        
                break;
            }

            // NOTE: We must bind before we do this
            DWORD dwBytesRet;
	    rc = WSAIoctl(
                     m_Socket,
                     SIO_RCVALL, 
                     &dwOptionOn,
                     sizeof( dwOptionOn ),
                     NULL,
                     0,
                     &dwBytesRet,
                     NULL,
                     NULL );
            if( SOCKET_ERROR == rc )
            {
                hr = HRESULT_FROM_WIN32( WSAGetLastError( ) );        
                break;
            }
        }

        //
        // Handle common init code for regular and accepted sockets.
        //
        hr = FinishInit( protocol );

        if( FAILED( hr ) )
        {
            break;
        }

        hr = S_OK;
    }
    while( FALSE );

    //
    // Clean up
    //
    if( FAILED( hr ) )
    {
        closesocket( m_Socket );
        m_Socket = INVALID_SOCKET;
    }
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::FinishInit( int protocol )
{
    XOMASSERT( IPPROTO_MAX != protocol );
    XOMASSERT( INVALID_SOCKET != m_Socket );
    XOMASSERT( NULL != m_pIOCP );
    
    HRESULT hr;
    
    do
    {
        m_protocol = protocol;

        //
        // Set the proper blocking status for this socket (non-blocking
        // is the default)
        //
        u_long arg = m_fBlockingIO ? 0 : 1;

        int rc = ioctlsocket( m_Socket, FIONBIO, &arg );

        if( SOCKET_ERROR == rc )
        {
            hr = HRESULT_FROM_WIN32( WSAGetLastError( ) );        
            break;
        }

        //
        // Attach this socket to the designated I/O completion port
        //
        hr = m_pIOCP->Attach( (HANDLE) m_Socket );

        if( FAILED( hr ) )
        {
            break;
        }

        hr = S_OK;
    }
    while( FALSE );
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::GetLocalAddress( sockaddr_in *pLocalAddress )
{
    //
    // Validate arguments
    //
    if( NULL == pLocalAddress )
    {
        return( E_INVALIDARG );
    }

    if( INVALID_SOCKET == m_Socket )
    {
        return( E_HANDLE );
    }

    memcpy( pLocalAddress, &m_saddrLocal, sizeof(sockaddr_in) );

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::GetPeerAddress( sockaddr_in *pPeerAddress )
{
    if( INVALID_SOCKET == m_Socket )
    {
        return( E_HANDLE );
    }

    if( !m_fHavePeerAddr )
    {
        int addrLen = sizeof(sockaddr_in);

        int rc = getpeername( m_Socket, (sockaddr *) &m_saddrPeer, &addrLen );

        if( SOCKET_ERROR == rc )
        {
            return( HRESULT_FROM_WIN32( WSAGetLastError() ) );
        }

        m_fHavePeerAddr = TRUE;
    }

    memcpy( pPeerAddress, &m_saddrPeer, sizeof(sockaddr_in) );

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::Connect( 
                            const sockaddr_in *pAddr,
                            CServerSocketCallback *pCallback,
                            QWORD qwCallbackArg )
{
    HRESULT hr = S_OK;
    
    CSocketIoContext* pContext = NULL;

    int iErr;

    //
    // Validate arguments
    //
    
    if(NULL == pAddr)
    {
        return E_INVALIDARG;
    }

    if(NULL == pCallback)
    {
        return E_INVALIDARG;
    }

    if( IPPROTO_TCP != m_protocol )
    {
        XOMASSERT( !"Can't connect on a UDP socket" );

        //
        // Actually we can, but it's not supported right now
        //

        return( E_INVALIDARG );
    }
    
    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    //
    // Register this socket in the connect watchdog list. 
    //

    pContext = new CSocketIoContext;

    if(NULL == pContext)
    {
        hr = E_OUTOFMEMORY;
        goto lDone;
    }
    
    pContext->Init(this, CSocketIoContext::IoConnect, NULL, 0, m_Socket, pCallback, qwCallbackArg);
    
    hr = g_SocketConnectWatchdog.AddConnectingSocket(pContext);

    if(FAILED(hr))
    {
        goto lDone;
    }

    //
    // Start connect operation
    //

    iErr = connect(m_Socket, (sockaddr*) pAddr, sizeof(sockaddr_in));

    if(SOCKET_ERROR != iErr)
    {
        XOMASSERT( !"Socket in blocking mode?");
        hr = E_FAIL;
        goto lDone;
    }

    iErr = WSAGetLastError();

    if(WSAEWOULDBLOCK != iErr)
    {   
        hr = HRESULT_FROM_WIN32(iErr);

        XomTrace(
            ServHlpDebug,
            L_NORMAL,
            "CServSocket::Connect: Error - connecting socket. hr = 0x%x",
            hr);

        goto lDone;
    }

lDone:

    if(FAILED(hr))
    {
        if(pContext)
        {
            //
            // We failed. No notifications are required. Remove context object
            // from the watchdog list.
            //

            g_SocketConnectWatchdog.Remove(pContext);
        }
    }

    SAFE_RELEASE(pContext);
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::Listen( DWORD dwConnectionBacklog )
{
    //
    // Don't need to check incoming parameters, listen() will do it for us
    // 
    if( SOCKET_ERROR == listen( m_Socket, dwConnectionBacklog ) )
    {
        return( HRESULT_FROM_WIN32( WSAGetLastError() ) );
    }

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::Accept(
                            CServerSocketCallback *pCallback,
                            QWORD qwCallbackArg )
{
    //
    // Validate arguments
    //
    if( NULL == pCallback )
    {
        return( E_INVALIDARG );
    }

    if( IPPROTO_TCP != m_protocol )
    {
        XOMASSERT( !"Can't accept on a UDP socket" );
        return( E_INVALIDARG );
    }

    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    HRESULT hr;
    SOCKET sockAccept = INVALID_SOCKET;
    BYTE *pbAcceptBuffer = NULL;
    CSocketIoContext *pCtx = NULL;
    
    do
    {
        //
        // Allocate an accept buffer
        //
        pbAcceptBuffer = (BYTE *) XAlloc(ACCEPT_ADDRESS_BUFFER_SIZE);
        if( pbAcceptBuffer == NULL )
        {
            hr = E_OUTOFMEMORY;
            break;
        }
        
        //
        // Create a new overlapped I/O TCP socket
        //
        sockAccept = WSASocket(
                            AF_INET,
                            SOCK_STREAM,
                            IPPROTO_TCP,
                            NULL,
                            0,
                            WSA_FLAG_OVERLAPPED );

        if( INVALID_SOCKET == sockAccept ) 
        {
            hr = HRESULT_FROM_WIN32( WSAGetLastError() );
            break;
        }

        //
        // Initialize a new I/O context struct
        //
        pCtx = new CSocketIoContext;

        if( NULL == pCtx )
        {
            hr = E_OUTOFMEMORY;
            break;
        }

        pCtx->Init(
                this,
                CSocketIoContext::IoAccept,
                pbAcceptBuffer,
                0,
                sockAccept,
                pCallback,
                qwCallbackArg );
    
        //
        // Attempt to queue an async accept
        //
        DWORD cbReceived;

        /*
            PS Xenon - Bug 58256

            It is possible that the IOCompletion call back gets called before WSASend completes.
            Ensure pCtx is alive for the entire lifetime of WSASend by calling AddRef

            Same concept with AcceptEx
        */
        XOMASSERT(NULL!=pCtx);
        pCtx->AddRef();

        BOOL fSync = AcceptEx(
                        m_Socket,
                        sockAccept,
                        pbAcceptBuffer,
                        0,
                        ACCEPT_ADDRESS_LEN,
                        ACCEPT_ADDRESS_LEN,
                        &cbReceived,
                        pCtx );

        pCtx->Release();
        
        pbAcceptBuffer = NULL; // AcceptEx callback will free

        if( fSync )
        {
            XOMASSERT( !"Oh, oh, synchronous AcceptEx" );
            hr = E_FAIL;
            break;
        }

        DWORD dwError = WSAGetLastError();

        if( ERROR_IO_PENDING != dwError )
        {
            hr = HRESULT_FROM_WIN32( dwError );
            break;
        }

        hr = S_OK;
    }
    while( FALSE );

    //
    // Clean up on failure
    //
    if( FAILED( hr ) )
    {
        XomTrace(
            ServHlpDebug,
            L_NORMAL,
            "CServSocket::Accept: Error - closing accept socket %d hr = 0x%x", 
            sockAccept,
            hr);

        closesocket( sockAccept );

        SAFE_RELEASE( pCtx );
    }

    if (pbAcceptBuffer != NULL)
    {
        XFree(pbAcceptBuffer);
    }
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::Send(
                            BYTE *pbBuffer,
                            DWORD cbToSend, 
                            CServerSocketCallback *pCallback,
                            QWORD qwCallbackArg )
{
    //
    // Validate arguments
    //
    if( ( NULL == pbBuffer ) || ( NULL == pCallback ) )
    {
        return( E_INVALIDARG );
    }

    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    HRESULT hr;
    CSocketIoContext *pCtx = NULL;
    
    do
    {
        //
        // Initialize a new I/O context struct
        //
        pCtx = new CSocketIoContext;

        if( NULL == pCtx )
        {
            hr = E_OUTOFMEMORY;
            break;
        }

        pCtx->Init(
                this,
                CSocketIoContext::IoSend,
                pbBuffer,
                cbToSend,
                m_Socket,
                pCallback,
                qwCallbackArg );

   

        //
        // Send the data asynchronously
        //
        WSABUF wsa;

        wsa.len = cbToSend;
        wsa.buf = (char *) pbBuffer;

        DWORD cbSent = 0;

        /*
            PS Xenon - Bug 58256

            It is possible that the IOCompletion call back gets called before WSASend completes.
            Ensure pCtx is alive for the entire lifetime of WSASend by calling AddRef
        */
        XOMASSERT(NULL!=pCtx);
        pCtx->AddRef();
        
        int rc = WSASend( m_Socket, &wsa, 1, &cbSent, 0, pCtx, NULL );

        pCtx->Release();
        
        hr = HandleWSAReturnValue( CSocketIoContext::IoSend, rc );

        if( FAILED( hr ) )
        {
            break;
        }
    
        hr = S_OK;
    }
    while( FALSE );

    //
    // Clean up on failure
    //
    if( FAILED( hr ) )
    {
        SAFE_RELEASE( pCtx );
    }
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::SendEx(
                            WSABUF *rgBuffers,
                            DWORD cBuffers, 
                            CServerSocketCallback *pCallback,
                            QWORD qwCallbackArg )
{
    //
    // Validate arguments
    //
    if( ( NULL == rgBuffers ) || ( NULL == pCallback ) || (cBuffers == 0) )
    {
        return( E_INVALIDARG );
    }

    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    HRESULT hr;
    CSocketIoContext *pCtx = NULL;
    
    do
    {
        //
        // Initialize a new I/O context struct
        //
        pCtx = new CSocketIoContext;

        if( NULL == pCtx )
        {
            hr = E_OUTOFMEMORY;
            break;
        }

        pCtx->Init(
                this,
                CSocketIoContext::IoSend,
                (BYTE *) rgBuffers,
                cBuffers,
                m_Socket,
                pCallback,
                qwCallbackArg );

        //
        // Send the data asynchronously
        //
        DWORD cbSent = 0;

        /*
            PS Xenon - Bug 58256

            It is possible that the IOCompletion call back gets called before WSASend completes.
            Ensure pCtx is alive for the entire lifetime of WSASend by calling AddRef
        */
        XOMASSERT(NULL!=pCtx);
        pCtx->AddRef();
        
        int rc = WSASend( m_Socket, rgBuffers, cBuffers, &cbSent, 0, pCtx, NULL );

        pCtx->Release();

        hr = HandleWSAReturnValue( CSocketIoContext::IoSend, rc );

        if( FAILED( hr ) )
        {
            break;
        }
    
        hr = S_OK;
    }
    while( FALSE );

    //
    // Clean up on failure
    //
    if( FAILED( hr ) )
    {
        SAFE_RELEASE( pCtx );
    }
    
    return( hr );
}

//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::SendTo( 
                            BYTE *pbBuffer,
                            DWORD cbToSend, 
                            const sockaddr_in *pSendToAddr,
                            CServerSocketCallback *pCallback,
                            QWORD qwCallbackArg )
{
    //
    // Validate arguments
    //
    if( ( NULL == pbBuffer ) || ( NULL == pCallback ) )
    {
        return( E_INVALIDARG );
    }

    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    if( IPPROTO_UDP != m_protocol &&
        IPPROTO_IP != m_protocol )
    {
        XOMASSERT( !"Protocol must be UDP or IP" );
        return( E_NOTIMPL );
    }

    HRESULT hr;
    CSocketIoContext *pCtx = NULL;
    
    do
    {
        //
        // Initialize a new I/O context struct
        //
        pCtx = new CSocketIoContext;

        if( NULL == pCtx )
        {
            hr = E_OUTOFMEMORY;
            break;
        }

        pCtx->Init(
                this,
                CSocketIoContext::IoSendTo,
                pbBuffer,
                cbToSend,
                m_Socket,
                pCallback,
                qwCallbackArg );

        //
        // Send the data asynchronously
        //
        WSABUF wsa;

        wsa.len = cbToSend;
        wsa.buf = (char *) pbBuffer;

        DWORD cbSent = 0;

        /*
            PS Xenon - Bug 58256

            It is possible that the IOCompletion call back gets called before WSASend completes.
            Ensure pCtx is alive for the entire lifetime of WSASend by calling AddRef

            Similar concept with WSASendTo
        */
        XOMASSERT(NULL!=pCtx);
        pCtx->AddRef();

        int rc = WSASendTo(
                        m_Socket,
                        &wsa,
                        1,
                        &cbSent,
                        0,
                        (sockaddr *) pSendToAddr,
                        sizeof(sockaddr_in),
                        pCtx,
                        NULL );

        pCtx->Release();

        hr = HandleWSAReturnValue( CSocketIoContext::IoSend, rc );

        if( FAILED( hr ) )
        {
            break;
        }
    
        hr = S_OK;
    }
    while( FALSE );

    //
    // Clean up on failure
    //
    if( FAILED( hr ) )
    {
        SAFE_RELEASE( pCtx );
    }
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::Receive( 
                            BYTE *pbBuffer,
                            DWORD cbBuffer,
                            CServerSocketCallback *pCallback,
                            QWORD qwCallbackArg )
{
    //
    // Validate arguments
    //
    if( ( NULL == pbBuffer ) || ( NULL == pCallback ) )
    {
        return( E_INVALIDARG );
    }

    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    HRESULT hr;
    CSocketIoContext *pCtx = NULL;
    
    do
    {
        //
        // Initialize a new I/O context struct
        //
        pCtx = new CSocketIoContext;

        if( NULL == pCtx )
        {
            hr = E_OUTOFMEMORY;
            break;
        }

        pCtx->Init(
                this,
                CSocketIoContext::IoReceive,
                pbBuffer,
                cbBuffer,
                m_Socket,
                pCallback,
                qwCallbackArg );

        //
        // Receive the data asynchronously
        //
        WSABUF wsa;

        wsa.len = cbBuffer;
        wsa.buf = (char *) pbBuffer;

        DWORD dwFlags = 0;
        DWORD cbReceived = 0;

         /*
            PS Xenon - Bug 58256

            It is possible that the IOCompletion call back gets called before WSASend completes.
            Ensure pCtx is alive for the entire lifetime of WSASend by calling AddRef

            Similar concept with WSARecv
        */
        XOMASSERT(NULL!=pCtx);
        pCtx->AddRef();

        int rc = WSARecv(
                        m_Socket,
                        &wsa,
                        1,
                        &cbReceived,
                        &dwFlags,
                        pCtx,
                        NULL );

        pCtx->Release();                

        hr = HandleWSAReturnValue( CSocketIoContext::IoReceive, rc );

        if( FAILED( hr ) )
        {
            break;
        }
    
        hr = S_OK;
    }
    while( FALSE );

    //
    // Clean up on failure
    //
    if( FAILED( hr ) )
    {
        SAFE_RELEASE( pCtx );
    }
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::ReceiveFrom( 
                            BYTE *pbBuffer,
                            DWORD cbBuffer,
                            CServerSocketCallback *pCallback,
                            QWORD qwCallbackArg )
{
    //
    // Validate arguments
    //
    if( ( NULL == pbBuffer ) || ( NULL == pCallback ) )
    {
        return( E_INVALIDARG );
    }

    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    HRESULT hr;
    CSocketIoContext *pCtx = NULL;
    
    do
    {
        //
        // Initialize a new I/O context struct
        //
        pCtx = new CSocketIoContext;

        if( NULL == pCtx )
        {
            hr = E_OUTOFMEMORY;
            break;
        }

        pCtx->Init(
                this,
                CSocketIoContext::IoReceiveFrom,
                pbBuffer,
                cbBuffer,
                m_Socket,
                pCallback,
                qwCallbackArg );

        //
        // Receive the data asynchronously
        //
        WSABUF wsa;

        wsa.len = cbBuffer;
        wsa.buf = (char *) pbBuffer;

        DWORD dwFlags = 0;
        DWORD cbReceived = 0;

         /*
            PS Xenon - Bug 58256

            It is possible that the IOCompletion call back gets called before WSASend completes.
            Ensure pCtx is alive for the entire lifetime of WSASend by calling AddRef

            Similar concept with WSARecvFrom
        */
        XOMASSERT(NULL!=pCtx);
        pCtx->AddRef();

        int rc = WSARecvFrom(
                        m_Socket,
                        &wsa,
                        1,
                        &cbReceived,
                        &dwFlags,
                        (sockaddr*) pCtx->GetAddr(),
                        (int*) pCtx->GetAddrLen(),
                        pCtx,
                        NULL );

        pCtx->Release();

        hr = HandleWSAReturnValue( CSocketIoContext::IoReceiveFrom, rc );

        if( FAILED( hr ) )
        {
            break;
        }
    
        hr = S_OK;
    }
    while( FALSE );

    //
    // Clean up on failure
    //
    if( FAILED( hr ) )
    {
        SAFE_RELEASE( pCtx );
    }
    
    return( hr );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::Close()
{
    //
    // Check if we are already closed
    //
    if( INVALID_SOCKET == m_Socket ) 
    {
        return( S_OK );
    }

    shutdown( m_Socket, SD_SEND );

    closesocket( m_Socket );

    XOMASSERT( NULL != m_pIOCP );
    m_pIOCP-> Leave( (HANDLE) m_Socket );

    m_Socket = INVALID_SOCKET;

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::GetSocket( SOCKET *pSocket )
{
    //
    // Validate arguments
    //
    if( NULL == pSocket )
    {
        return( E_INVALIDARG );
    }

    *pSocket = m_Socket;

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::SetBlockingIO( BOOL fBlockingIO )
{
    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }
    
    u_long arg = fBlockingIO ? 0L : 1L;

    int rc = ioctlsocket( m_Socket, FIONBIO, &arg );

    if( SOCKET_ERROR == rc )
    {
        return( E_FAIL );
    }

    m_fBlockingIO = fBlockingIO;

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::SetDisableNagle( BOOL fDisable )
{
    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    int rc = setsockopt(
                    m_Socket,
                    IPPROTO_TCP,
                    TCP_NODELAY,
                    (char *) &fDisable,
                    sizeof(BOOL) );

    if ( SOCKET_ERROR == rc )    
    {
       return( HRESULT_FROM_WIN32( WSAGetLastError() ) );
    }

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::SetReceiveBufferSize( DWORD dwBufferSize )
{
    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    int iBufSize = (int) dwBufferSize;

    int rc = setsockopt(
                    m_Socket,
                    SOL_SOCKET,
                    SO_RCVBUF,
                    (char *) &iBufSize,
                    sizeof(int) );

    if ( SOCKET_ERROR == rc )    
    {
       return( HRESULT_FROM_WIN32( WSAGetLastError() ) );
    }

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::SetSendBufferSize( DWORD dwBufferSize )
{
    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    int iBufSize = (int) dwBufferSize;

    int rc = setsockopt(
                    m_Socket,
                    SOL_SOCKET,
                    SO_SNDBUF,
                    (char *) &iBufSize,
                    sizeof(int) );

    if ( SOCKET_ERROR == rc )    
    {
       return( HRESULT_FROM_WIN32( WSAGetLastError() ) );
    }

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::SetReceiveBroadcast( BOOL fReceive )
{
    if( INVALID_SOCKET == m_Socket ) 
    {
        return( E_HANDLE );
    }

    int rc = setsockopt(
                    m_Socket,
                    IPPROTO_IP,
                    IP_RECEIVE_BROADCAST,
                    (char *) &fReceive,
                    sizeof(BOOL) );

    if ( SOCKET_ERROR == rc )    
    {
       return( HRESULT_FROM_WIN32( WSAGetLastError() ) );
    }

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::GetMaxMessageSize( DWORD *pdwMaxMessageSize )
{
    //
    // Validate arguments
    //
    if( NULL == pdwMaxMessageSize )
    {
        return( E_INVALIDARG );
    }

    *pdwMaxMessageSize = 0;

    unsigned int uiMsgSize;
    int iParamSize = sizeof(uiMsgSize);

    int rc = getsockopt(
                    m_Socket,
                    SOL_SOCKET,
                    SO_MAX_MSG_SIZE,
                    (char *) &uiMsgSize,
                    &iParamSize );

    if( SOCKET_ERROR == rc )
    {
        return( HRESULT_FROM_WIN32( WSAGetLastError() ) );
    }

    *pdwMaxMessageSize = uiMsgSize;

    return( S_OK );
}


//////////////////////////////////////////////////////////////////////////////
void CServerSocket::OnIoCompletion( 
                        DWORD dwError, 
                        DWORD cbTransferred, 
                        ULONG_PTR ulpKey,
                        CCompletionContext *pCompCtx )
{
    //
    // Check everything is ok
    //
    if( NULL == pCompCtx )
    {
        XOMASSERT( !"Unexpected IO completion w/ NULL context" );
        return;
    }

    CSocketIoContext *pCtx = (CSocketIoContext *) pCompCtx;

#if DBG
    if( dwError )
    {
        XomTrace(
            ServHlpDebug,
            L_NORMAL,
            "CServSocket::OnIoCompletion: type %u err %u encountered, wsa error %d", 
            pCtx->GetIoType(),
            dwError,
            WSAGetLastError());
    }
#endif

    //
    //  Get the callback
    //
    CServerSocketCallback *pCallback = pCtx->GetCallback();

    if( NULL == pCallback )
    {
        XOMASSERT( !"What's going on?" );
        return;
    }

#ifdef ICECAP_BUILD
    StartProfile(PROFILE_THREADLEVEL, PROFILE_CURRENTID);
#endif

    //
    // Call the corresponding callback. 
    // pCtx keeps a reference to us, so we won't get deleted if the 
    // callback calls Release()
    //

    switch( pCtx->GetIoType() )
    {
    case CSocketIoContext::IoConnect:

        pCallback->OnSocketConnect(
            pCtx->GetHRESULT(),
            pCtx->GetCallbackArg() );
        break;
    
    case CSocketIoContext::IoAccept:

        CallOnAccept( dwError, cbTransferred, pCtx );
        break;
    
    case CSocketIoContext::IoSend:
      
        pCallback->OnSocketSend(
                            pCtx->GetBuffer(),
                            pCtx->GetBufferSize(),
                            cbTransferred,
                            HRESULT_FROM_WIN32( dwError ),
                            pCtx->GetCallbackArg() );
        break;

    case CSocketIoContext::IoSendTo:

        pCallback->OnSocketSendTo(
                            pCtx->GetBuffer(),
                            pCtx->GetBufferSize(),
                            cbTransferred,
                            HRESULT_FROM_WIN32( dwError ),
                            pCtx->GetCallbackArg() );
        break;

    case CSocketIoContext::IoReceive:

        pCallback->OnSocketReceive(
                            pCtx->GetBuffer(),
                            cbTransferred,
                            HRESULT_FROM_WIN32( dwError ),
                            pCtx->GetCallbackArg() );
        break;

    case CSocketIoContext::IoReceiveFrom:

        pCallback->OnSocketReceiveFrom(
                            pCtx->GetBuffer(),
                            cbTransferred,
                            pCtx->GetAddr(),
                            HRESULT_FROM_WIN32( dwError ),
                            pCtx->GetCallbackArg() );
        break;
    
    default:

        XOMASSERT( !"Bogus IoCompletion type" );
        break;
    }

    SAFE_RELEASE( pCtx );

#ifdef ICECAP_BUILD
    StopProfile(PROFILE_THREADLEVEL, PROFILE_CURRENTID);
#endif

}


/////////////////////////////////////////////////////////////////////////////
void CServerSocket::CallOnAccept(
                            DWORD dwError,
                            DWORD cbTransferred,
                            CSocketIoContext *pCtx )
{
    HRESULT hr;
    CServerSocket *pSocket = NULL;
    sockaddr *psaddrLocal = NULL;
    sockaddr *psaddrRemote = NULL;
    int iLocalAddrLen;
    int iRemoteAddrLen;

    XOMASSERT( 0 == cbTransferred );
    
    do
    {
        //
        // Get out quick on obvious failures
        //
        if( INVALID_SOCKET == pCtx->GetSocket() )
        {
            hr = E_INVALIDARG;
            break;
        }

        if( 0 != dwError )
        {
            hr = HRESULT_FROM_WIN32( dwError );
            break;
        }
        
        //
        // Parse the accept buffer for addresses
        //
        XOMASSERT( 0 == pCtx->GetBufferSize() );

        GetAcceptExSockaddrs(
                pCtx->GetBuffer(),
                pCtx->GetBufferSize(),
                ACCEPT_ADDRESS_LEN,
                ACCEPT_ADDRESS_LEN,
                &psaddrLocal,
                &iLocalAddrLen,
                &psaddrRemote,
                &iRemoteAddrLen );
 
        XOMASSERT( sizeof(sockaddr_in) == iLocalAddrLen );
        XOMASSERT( sizeof(sockaddr_in) == iRemoteAddrLen );

        //
        // Be sure to inherit the attributes from the listen socket
        //
        int rc = setsockopt( 
                        pCtx->GetSocket(),     
                        SOL_SOCKET,     
                        SO_UPDATE_ACCEPT_CONTEXT, 
                        (char *) &m_Socket,     
                        sizeof(m_Socket) );

        if( SOCKET_ERROR == rc )
        {
            hr = HRESULT_FROM_WIN32( WSAGetLastError() );
            break;
        }

        //
        // Allocate and initialize a new socket class to represent the
        // new connection
        //
        pSocket = new CServerSocket;
    
        if( NULL == pSocket )
        {
            hr = E_OUTOFMEMORY;
            break;
        }

        hr = pSocket->InternalInit( m_pAcceptIOCP, m_pAcceptIOCP, pCtx->GetSocket() );
        
        if( FAILED( hr ) )
        {
            break;
        }

        //
        // Store local and remote address in the newly created socket (since getpeername
        // wouldn't work because it was created with AcceptEx)
        //
        if( NULL != psaddrLocal )
        {
            memcpy( &pSocket->m_saddrLocal, psaddrLocal, sizeof(sockaddr_in) );
        }

        if( NULL != psaddrRemote )
        {
            memcpy( &pSocket->m_saddrPeer, psaddrRemote, sizeof(sockaddr_in) );
            pSocket->m_fHavePeerAddr = TRUE;
        }

        //
        // Hook the socket up to the appropriate completion port, etc.
        //
        hr = pSocket->FinishInit( m_protocol );

        if( FAILED( hr ) )
        {
            break;
        }

        hr = S_OK;
    }
    while( FALSE );

    //
    // we receive this error in case the listen socket is being closed,
    // so we need to close the accept socket as well.
    //
    if( hr == HRESULT_FROM_WIN32( WSA_OPERATION_ABORTED ) )
    {
        shutdown( pCtx->GetSocket(), SD_SEND );
        closesocket( pCtx->GetSocket() );
    }

    //
    // Call the callback in all cases to prevent memory leaks
    // The caller should addref the socket if they want to keep it
    //
    CServerSocketCallback *pCallback = pCtx->GetCallback();

    pCallback->OnSocketAccept(
                            this,
                            pSocket,
                            (sockaddr_in *) psaddrLocal,
                            (sockaddr_in *) psaddrRemote,
                            hr,
                            pCtx->GetCallbackArg() );
    
    if( NULL != pCtx->GetBuffer() )
    {
        XFree(pCtx->GetBuffer());
    }

    SAFE_RELEASE( pSocket );
}


/////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocket::HandleWSAReturnValue(
                            CSocketIoContext::IoType Operation, 
                            int iRet )
{
    if( SOCKET_ERROR == iRet )
    {
        int iWSAError = WSAGetLastError();
    
        //
        // WSA_IO_PENDING is not an error, it just means that the I/O operation
        // will complete later.  But the same is also true for WSAEMSGSIZE, if
        // we were calling WSARecv or WSAReceiveFrom.  Don't believe what the NT documentation
        // for WSARecv says.  The IO completion port will be signalled if we get an WSAEMSGSIZE.
        //
        if( ( WSA_IO_PENDING != iWSAError ) && 
            ( ( WSAEMSGSIZE != iWSAError ) || 
              ( CSocketIoContext::IoReceive != Operation && 
                CSocketIoContext::IoReceiveFrom != Operation ) ) )
        {
            HRESULT hr = HRESULT_FROM_WIN32( iWSAError );

            XomTrace(
                ServHlpDebug,
                L_NORMAL,
                "WSA error: %d, hr = 0x%x", 
                iWSAError, 
                hr);

            return( hr );
        }

        return( S_OK );
    }    
    else if( 0 == iRet )
    {
        //
        // Synchronous operation, completion already scheduled by the system
        //
        return( S_OK );
    }
    else 
    {
        XOMASSERT( !"Bizarre undocumented Winsock behavior" );

        return( E_FAIL );
    }
}


/////////////////////////////////////////////////////////////////////////////
CServerSocketConnectWatchdog::CServerSocketConnectWatchdog()
{
    InitializeCriticalSection(&m_cs);
    m_hWatchdogThread = NULL;
    m_dwWatchdogThreadId = 0;
    m_bLazyInit = FALSE;
    ZeroMemory(m_rghChangeEvent, sizeof(m_rghChangeEvent));
    m_dwNextList = 0;
    m_pSocketList = NULL;
}

/////////////////////////////////////////////////////////////////////////////
CServerSocketConnectWatchdog::~CServerSocketConnectWatchdog()
{
    Shutdown();
    DeleteCriticalSection(&m_cs);
}

/////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocketConnectWatchdog::Init()
{
    HRESULT hr = S_OK;

    // Initialize list
    m_pSocketList = new CVPtrList[ CONNECT_LIST_COUNT ];
    if( NULL == m_pSocketList )
    {
        hr = E_OUTOFMEMORY;
        XomTrace(
            ServHlpDebug,
            L_HIGH,
            "[CServerSocketConnectWatchdog::Init] out of memory allocating m_pSocketList, hr=0x%08x",
            hr);
        goto lDone;
    }
    
    //
    // Initialize notification events and socket lists
    //
    
    for(int nList=0; nList < CONNECT_LIST_COUNT; nList++)
    {
        m_rghChangeEvent[nList] = CreateEvent(NULL, FALSE, FALSE, NULL);

        if(NULL == m_rghChangeEvent[nList])
        {
            hr = HRESULT_FROM_WIN32(GetLastError());

            XomTrace(
                ServHlpDebug,
                L_HIGH,
                "[CServerSocketConnectWatchdog::Init] m_rghChangeEvent[nList] = CreateEvent failed, hr=0x%08x",
                hr);
    
            goto lDone;
        }

        hr = m_pSocketList[nList].Initialize(INITIAL_LIST_ALLOC);

        if(FAILED(hr))
        {

            XomTrace(
                ServHlpDebug,
                L_HIGH,
                "[CServerSocketConnectWatchdog::Init] m_rgSocketList[nList].Initialize failed, hr=0x%08x",
                hr);

            goto lDone;
        }
    }

    //
    // This last event will be the shutdown event
    //

    m_rghChangeEvent[CONNECT_LIST_COUNT] = CreateEvent(NULL, TRUE, FALSE, NULL);

    if(NULL == m_rghChangeEvent[CONNECT_LIST_COUNT])
    {
        hr = HRESULT_FROM_WIN32(GetLastError());

        XomTrace(
                ServHlpDebug,
                L_HIGH,
                "[CServerSocketConnectWatchdog::Init] m_rghChangeEvent[CONNECT_LIST_COUNT] = CreateEvent failed, hr=0x%08x",
                hr);

        goto lDone;
    }

    //
    // Create the watchdog thread
    //

    m_hWatchdogThread = CreateThread(NULL, 0, ConnectionWatchdogThreadProc, (LPVOID) this, 0, &m_dwWatchdogThreadId);

    if(NULL == m_hWatchdogThread)
    {
        hr = HRESULT_FROM_WIN32(GetLastError());

        XomTrace(
                ServHlpDebug,
                L_HIGH,
                "[CServerSocketConnectWatchdog::Init] m_hWatchDogThread = CreateThread failed, hr=0x%08x",
                hr);

        goto lDone;
    }

    m_bLazyInit = TRUE;

lDone:

    return hr;
}

/////////////////////////////////////////////////////////////////////////////
void CServerSocketConnectWatchdog::Shutdown()
{
    // Shutdown watchdog thread
    if(m_hWatchdogThread)
    {
        SetEvent(m_rghChangeEvent[CONNECT_LIST_COUNT]);

        int iRes = WaitForSingleObject(m_hWatchdogThread, 5000);

        if(iRes != WAIT_OBJECT_0)
        {
            XomTrace(
                ServHlpDebug,
                L_NORMAL,
                "Failed to shutdown watchdog thread gracefully");
        }

        CloseHandle(m_hWatchdogThread);
        m_hWatchdogThread = NULL;
    }

    // Clean up the shutdown event    
    if(m_rghChangeEvent[CONNECT_LIST_COUNT] != NULL)
    {
        CloseHandle(m_rghChangeEvent[CONNECT_LIST_COUNT]);
        m_rghChangeEvent[CONNECT_LIST_COUNT] = NULL;
    }

    if( NULL != m_pSocketList )
    {
        // Clean up connecting socket list
        for(int nList=0; nList < CONNECT_LIST_COUNT; nList++)
        {
            CSocketIoContext* pSC = NULL;

            while(m_pSocketList[nList].RemoveTail((void**) &pSC))
            {
                ((CServerSocket*)pSC->GetHandler())->GetIOCP()->PostCompletion(pSC);
            }

            if(m_rghChangeEvent[nList] != NULL)
            {
                CloseHandle(m_rghChangeEvent[nList]);
                m_rghChangeEvent[nList] = NULL;
            }
        }

        delete[] m_pSocketList;
        m_pSocketList = NULL;
    }

    m_bLazyInit = FALSE;
}

/////////////////////////////////////////////////////////////////////////////
DWORD WINAPI CServerSocketConnectWatchdog::ConnectionWatchdogThreadProc(
    LPVOID pThisRaw
)
{
    ((CServerSocketConnectWatchdog*) pThisRaw)->ConnectionWatchdog();

    return 0;
}

/////////////////////////////////////////////////////////////////////////////
void CServerSocketConnectWatchdog::ConnectionWatchdog()
{

    for(;;)
    {
        
        //
        // Wait until we get connect notifications or until we shutdown
        //
        
        DWORD dwRes = WaitForMultipleObjects(sizeof(m_rghChangeEvent)/sizeof(m_rghChangeEvent[0]), 
            m_rghChangeEvent, FALSE, INFINITE);

        if(dwRes >= WAIT_OBJECT_0 + CONNECT_LIST_COUNT)
        {
            //
            // Shutdown
            //
          
            break;
        }

        Lock();

        //
        // Each event has a corresponding list.
        //
        
        DWORD nList = dwRes - WAIT_OBJECT_0;

        if(m_pSocketList[nList].IsEmpty())
        {
            Unlock();
            continue;
        }

        CSocketIoContext* pSC = NULL;
        LISTPOS pos = m_pSocketList[nList].GetHeadPosition();
        LISTPOS posN = pos;
        
        for(;;)
        {
            pos = posN;

            if(! m_pSocketList[nList].GetNext(posN, (void**) &pSC))
            {
                break;
            }
            
            //
            // Check if it connected or failed
            //
            
            fd_set writefds;
            FD_ZERO(&writefds);
            FD_SET(pSC->GetSocket(), &writefds);

            fd_set exceptfds;
            FD_ZERO(&exceptfds);
            FD_SET(pSC->GetSocket(), &exceptfds);

            TIMEVAL sTimeout = {0, 0}; 

            // A return value of zero indicates that we hit the timeout (ie no information
            // yet), a return value less than zero indicates an error, and a return value
            // greater than zero means the connect operation is done, and still may have
            // failed.
            int iRes = select(0, NULL, &writefds, &exceptfds, &sTimeout);

            if(iRes > 0 && FD_ISSET(pSC->GetSocket(), &writefds))
            {
                //
                // This socket connected successfully
                //

                m_pSocketList[nList].RemoveAt(pos);


                ((CServerSocket*)pSC->GetHandler())->GetIOCP()->PostCompletion(pSC);
            }
            else if( iRes != 0 )
            {
//                XOMASSERT(FD_ISSET(pSC->GetSocket(), &exceptfds));
                
                //
                // This socket failed to connect
                //

                pSC->SetHRESULT(E_FAIL);
                m_pSocketList[nList].RemoveAt(pos);

                ((CServerSocket*)pSC->GetHandler())->GetIOCP()->PostCompletion(pSC);
            }
            else
            {
                Sleep(0);
            }
        }

        Unlock();
    }
}

/////////////////////////////////////////////////////////////////////////////
HRESULT CServerSocketConnectWatchdog::AddConnectingSocket(
    CSocketIoContext* pContext
)
{
    XOMASSERT(pContext);

    HRESULT hr = S_OK;

    hr = EnsureInit();

    if(FAILED(hr))
    {
        goto lDone;
    }

    Lock();

    //
    // We want to be notified when this socket finishes connecting.
    //

    int iErr = WSAEventSelect(pContext->GetSocket(), m_rghChangeEvent[m_dwNextList], FD_CONNECT);

    if(SOCKET_ERROR == iErr)
    {    
        hr = HRESULT_FROM_WIN32(iErr);

        XomTrace(
            ServHlpDebug,
            L_NORMAL,
            "[CServerSocketConnectWatchdog::AddConnectingSocket] WSAEventSelect failed, hr = 0x%x", 
            hr);

        Unlock();

        goto lDone;
    }

    //
    // Add context object to one of our lists.
    //

    LISTPOS pos = m_pSocketList[m_dwNextList].AddTail((void*) pContext);
    pContext->AddRef();


    //
    // Next list is determined by round robin.
    //
    
    m_dwNextList = (m_dwNextList + 1) % CONNECT_LIST_COUNT;


    Unlock();

lDone:

    return hr;
}

/////////////////////////////////////////////////////////////////////////////
void CServerSocketConnectWatchdog::Remove(
    CSocketIoContext* pContext
)
{
    for(DWORD nList=0; nList < CONNECT_LIST_COUNT; nList++)
    {
        CSocketIoContext* pSC = NULL;
        LISTPOS pos = m_pSocketList[nList].GetHeadPosition();
        LISTPOS posN = pos;
        
        while((pos = posN, m_pSocketList[nList].GetNext(posN, (void**) &pSC)))
        {
            if(pSC == pContext)
            {
                m_pSocketList[nList].RemoveAt(pos);
                pSC->Release();

                return;
            }
        }
    }
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\tcpcnt.cpp ===
/*++

Copyright (c) Microsoft Corporation.  All rights reserved

Module Name:

    tcpcnt.cpp

Abstract:


--*/

#include "servhlpp.h"


// Uncomment this to start throttling reads. WARNING: not tested.
// #define THROTTLE_READS

XomDefineArea(TCPCnt);
    // Debug area

/////////////////////////////////////////////////////////////////////////////    
CTCPCnt::CTCPCnt(DWORD dwCTCPCntMaxOutboundBuffers)
{
    CTCPCnt_MAX_OUTBOUND_BUFFERS = dwCTCPCntMaxOutboundBuffers;
    m_rgOutboundBuffers = new CTCPCntBuffer *[CTCPCnt_MAX_OUTBOUND_BUFFERS];
    m_rgWSABuffers = new WSABUF[CTCPCnt_MAX_OUTBOUND_BUFFERS];
    m_pSocket = NULL;
    m_eState = S_NOT_CONNECTED;
    m_dwOutboundBuffersStart = 0;
    m_dwOutboundBuffersEnd = 0;
    m_dwBufferConsumed = 0;
    m_fSending = FALSE;
    m_fReceiving = FALSE;
    ZeroMemory(&m_sinOut, sizeof(m_sinOut));
    m_szDebugName[0] = '\0';
}

/////////////////////////////////////////////////////////////////////////////
CTCPCnt::~CTCPCnt()
{
    Disconnect(S_OK);

    ResetBufferList();

    SAFE_RELEASE(m_pSocket);
    SAFE_ARRAYDELETE(m_rgOutboundBuffers);
    SAFE_ARRAYDELETE(m_rgWSABuffers);
}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::OnConnect() {}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::OnDisconnect( HRESULT hrReason ) {}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::OnDone() {}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::ParseReceiveBuffer(
    BYTE* pBuffer,
    DWORD* pcbBuffer
)
{
    //
    // The default implementation doesn't do anything with the buffer
    //

    *pcbBuffer = 0;
    
    return;
}


/////////////////////////////////////////////////////////////////////////////
HRESULT CTCPCnt::Attach(
    CServerSocket* pSocket
)
{
    return AttachAndConnect(pSocket, NULL);
}

/////////////////////////////////////////////////////////////////////////////
HRESULT CTCPCnt::AttachAndConnect(
    CServerSocket* pSocket,
    sockaddr_in* pAddr
)
{
    HRESULT hr = S_OK;
    
    hr = InternalInit(pSocket, pAddr);
    
    if(FAILED(hr))
    {
        XomTrace(
            TCPCnt,
            L_NORMAL,
            "[CTCPCnt::AttachAndConnect] (%s) InternalInit failed, hr = 0x%08x", 
            m_szDebugName, hr);

        //
        // We failed so we're not keeping the socket connection object.
        //    
        
        goto lDone;
    }

lDone:

    return hr;
}

/////////////////////////////////////////////////////////////////////////////
HRESULT CTCPCnt::InternalInit(
    CServerSocket* pSocket,
    sockaddr_in* psin
)
{
    HRESULT hr = S_OK;

    if(m_pSocket != NULL)
    {
        XomTrace(
            TCPCnt,
            L_ERROR,
            "[CTCPCnt::InternalInit] (%s) Object cannot be reused", 
            m_szDebugName);

        XOMASSERT(!"[CTCPCnt::InternalInit] Object cannot be reused");

        hr = E_UNEXPECTED;

        goto lDone;
    }
    
    m_pSocket = pSocket;
    m_pSocket->AddRef();

    if(psin)
    {
        memcpy(&m_sinOut, psin, sizeof(m_sinOut));
        
        //
        // Socket needs to be connected before we can start using it.
        //
        
        AddRef();
        
        m_eState = S_CONNECTING;

        hr = m_pSocket->Connect(psin, this, 0);

        if(FAILED(hr))
        {
            Release();

            XomTrace(
                TCPCnt,
                L_ERROR,
                "[CTCPCnt::Init] (%s) m_pSocket->Connect failed, hr=0x%08x",
                m_szDebugName, hr);
            
            goto lDone;
        }
    }
    else
    {
        //
        // Socket is connected and ready for use.
        //

        hr = m_pSocket->GetPeerAddress(&m_sinOut);

        if(FAILED(hr))
        {
            XomTrace(TCPCnt, L_ERROR,
                "[CTCPCnt::InternalInit] (%s) m_pSocket->GetPeerAddress failed, hr = 0x%08x", 
                m_szDebugName, hr);
            goto lDone;
        }

        m_eState = S_CONNECTED;

        hr = StartReceiving();

        if(FAILED(hr))
        {
            XomTrace(
                TCPCnt,
                L_ERROR,
                "[CTCPCnt::Init] (%s) StartReceiving failed, hr=0x%08x",
                m_szDebugName, hr);
            goto lDone;
        }            
    }

lDone:

    if(FAILED(hr))
    {
        Disconnect(hr);
    }

    if(SUCCEEDED(hr))
    {
        XomTrace(TCPCnt, L_NORMAL,
            "[CTCPCnt::InternalInit] (%s) Attaching socket, addr = "DBGSINFMT", hr = 0x%08x",
            m_szDebugName, DBGSINPRM(&m_sinOut), hr);
    }
    else
    {
        XomTrace(TCPCnt, L_ERROR,
            "[CTCPCnt::InternalInit] (%s) Attaching socket, addr = "DBGSINFMT", hr = 0x%08x",
            m_szDebugName, DBGSINPRM(&m_sinOut), hr);
    }

    return hr;
}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::Disconnect(
    HRESULT hr
)
{
    //
    // Make sure that only one thread will make through.
    //
    
    if(InterlockedExchange((LONG*) &m_eState, S_NOT_CONNECTED) != S_NOT_CONNECTED)
    {
        XomTrace(TCPCnt, L_NORMAL, 
            "[CTCPCnt::Disconnect] (%s) Disconnecting from "DBGSINFMT" with hr = 0x%08x", 
            m_szDebugName,
            DBGSINPRM(&m_sinOut), hr);

        //
        // Cancel pending operations
        //
        
        if(m_pSocket)
        {
            m_pSocket->Close();
        }

        // Release the outstanding buffers, since they are not going to be
        // sent anymore.
        ResetBufferList();

        // Send Notification of disconnect
        OnDisconnect(hr);
    }

    return;
}

/////////////////////////////////////////////////////////////////////////////
HRESULT CTCPCnt::Send(
    CTCPCntBuffer* pBuffer
)
{
    HRESULT hr = S_OK;
    DWORD dwOldEnd;
    DWORD dwNewEnd;
    
    if(S_NOT_CONNECTED == m_eState)
    {
        //
        // Not connected (nor connecting)
        //

        hr = E_FAIL;

        XomTrace(TCPCnt, L_ERROR, 
            "[CTCPCnt::Send] (%s) Cannot start sending without connecting first",
            m_szDebugName);
        
        goto lDone;
    }

    if(pBuffer != CTCPCnt_DONE_ENTRY)
    {
        pBuffer->AddRef();
    }
    else
    {
        XomTrace(TCPCnt, L_LOW, 
            "[CTCPCnt::Send] (%s) Queueing 'Done' mark ",
            m_szDebugName);
    }
    
    //
    // Add it to outbound queue
    //

    m_lockBufferList.WriteLock();

    dwOldEnd = m_dwOutboundBuffersEnd;
    dwNewEnd = (dwOldEnd + 1) % CTCPCnt_MAX_OUTBOUND_BUFFERS;

    if(dwNewEnd == m_dwOutboundBuffersStart)
    {
        //
        // Outbound queue is full
        //
        
        XomTrace(TCPCnt, L_ERROR,
            "[CTCPCnt::Send] (%s) Outbound queue is full.",
            m_szDebugName);
    
        hr = HRESULT_FROM_WIN32(WSAENOBUFS);

        if(pBuffer != CTCPCnt_DONE_ENTRY)
        {
            pBuffer->Release();
        }
        
        m_lockBufferList.WriteUnlock();

        goto lDone;
    }

    m_rgOutboundBuffers[dwOldEnd] = pBuffer;
    m_dwOutboundBuffersEnd = dwNewEnd;

    m_lockBufferList.WriteUnlock();

    //
    // Keep things going
    //

    hr = StartSending();

    if(FAILED(hr))
    {
        XomTrace(
            TCPCnt,
            L_ERROR,
            "[CTCPCnt::Send] (%s) StartSending failed, hr=0x%08x", 
            m_szDebugName, hr);

        goto lDone;
    }                

lDone:

    if(FAILED(hr))
    {
        Disconnect(hr);
    }

    if(SUCCEEDED(hr))
    {
        XomTrace(TCPCnt, L_LOW,
            "[CTCPCnt::Send] (%s) Sending, addr = "DBGSINFMT", hr = 0x%08x",
            m_szDebugName,
            DBGSINPRM(&m_sinOut), hr);
    }
    else
    {
        XomTrace(TCPCnt, L_ERROR,
            "[CTCPCnt::Send] (%s) Sending, addr = "DBGSINFMT", hr = 0x%08x",
            m_szDebugName,
            DBGSINPRM(&m_sinOut), hr);
    }

    return hr;
}

/////////////////////////////////////////////////////////////////////////////
HRESULT CTCPCnt::Done()
{

    return Send((CTCPCntBuffer*) CTCPCnt_DONE_ENTRY);
}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::OnSocketConnect(
    HRESULT hr,
    QWORD qwCallbackArg 
)
{
    if(FAILED(hr))
    {
        goto lDone;
    }

    InterlockedExchange((LONG*) &m_eState, (LONG)S_CONNECTED);

    hr = StartReceiving();

    if(FAILED(hr))
    {
        XomTrace(
            TCPCnt,
            L_ERROR,
            "[CTCPCnt::Init] (%s) StartReceiving failed, hr=0x%08x",
            m_szDebugName,
            hr);

        goto lDone;
    }            

    hr = StartSending();

    if(FAILED(hr))
    {
        XomTrace(
            TCPCnt,
            L_ERROR,
            "[CTCPCnt::Init] (%s) StartSending failed, hr=0x%08x",
            m_szDebugName,
            hr);

        goto lDone;
    }            

    OnConnect();
    
lDone:
    
    if(FAILED(hr))
    {
        Disconnect(hr);
    }

    if(SUCCEEDED(hr))
    {
        XomTrace(TCPCnt, L_NORMAL,
            "[CTCPCnt::OnSocketConnect] (%s) OnConnect, addr = "DBGSINFMT", hr = 0x%08x",
            m_szDebugName,
            DBGSINPRM(&m_sinOut), hr);
    }
    else
    {
        XomTrace(TCPCnt, L_ERROR,
            "[CTCPCnt::OnSocketConnect] (%s) OnConnect, addr = "DBGSINFMT", hr = 0x%08x",
            m_szDebugName,
            DBGSINPRM(&m_sinOut), hr);
    }

    Release();
}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::OnSocketSend(
    BYTE *pbBufferSent,
    DWORD cbToSend,
    DWORD cbSent,
    HRESULT hrSend,
    QWORD qwCallbackArg 
)
{
    HRESULT hr = S_OK;
    DWORD dwCount = (DWORD) qwCallbackArg;
        
    //
    // Release the buffers and adjust the outgoing buffer list start
    //

    m_lockBufferList.WriteLock();

    if (m_eState == S_CONNECTED)
    {
        while(dwCount > 0)
        {
            XOMASSERT(m_dwOutboundBuffersStart != m_dwOutboundBuffersEnd);

            m_rgOutboundBuffers[m_dwOutboundBuffersStart]->Release();

            m_dwOutboundBuffersStart = (m_dwOutboundBuffersStart + 1) % 
                CTCPCnt_MAX_OUTBOUND_BUFFERS;

            dwCount--;
        }
    }
    else
    {
        hr = S_FALSE;
    }

    m_lockBufferList.WriteUnlock();

    //
    // We're not sending anymore
    //

    m_fSending = FALSE;
    
    if((hr == S_OK) && SUCCEEDED(hrSend) && cbSent != 0)
    {
        //
        // We're doing OK. Keep going.
        //
        
        hr = StartSending();

        if(FAILED(hr))
        {

            XomTrace(
                TCPCnt,
                L_ERROR,
                "[CTCPCnt::OnSocketSend] (%s) StartSending failed, hr=0x%08x",
                m_szDebugName,
                hr);
            goto lDone;
        }    

#ifdef THROTTLE_READS

        //
        // Call StartReceiving to start receiving again if we stopped receiving
        // because the outbound queue was too big.
        //

        hr = StartReceiving();

        if(FAILED(hr))
        {
            XomTrace(TCPCnt, L_ERROR,
                "[CTCPCnt::OnSocketSend] (%s) StartSending failed, hr=0x%08x",
                m_szDebugName,
                hr);
            goto lDone;
        }    

#endif

    }
    else
    {
        //
        // Probably disconnecting or shutting down.
        //

        hr = FAILED(hrSend) ? hrSend : E_FAIL;
    }

lDone:

    if(FAILED(hr))
    {
        Disconnect(hrSend);
    }

    if(SUCCEEDED(hr))
    {
        XomTrace(TCPCnt, L_LOW,
            "[CTCPCnt::OnSocketSend] (%s) OnSend, addr = "DBGSINFMT", %d bytes, hr = 0x%08x",
            m_szDebugName,
            DBGSINPRM(&m_sinOut), cbSent, hrSend);
    }
    else
    {
        XomTrace(TCPCnt, L_ERROR,
            "[CTCPCnt::OnSocketSend] (%s) OnSend, addr = "DBGSINFMT", %d bytes, hr = 0x%08x",
            m_szDebugName,
            DBGSINPRM(&m_sinOut), cbSent, hrSend);
    }

    Release();
}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::OnSocketReceive(
    BYTE *pbFilledInBuffer,
    DWORD cbRead,
    HRESULT hrReceive,
    QWORD qwCallbackArg 
) 
{
    HRESULT hr = S_OK;

    InterlockedExchange(&m_fReceiving, FALSE);

    if(SUCCEEDED(hrReceive) && (cbRead != 0))
    {
        //
        // Compute received data in our "to be processed" total.
        //
        
        m_dwBufferConsumed += cbRead;

        if(m_dwBufferConsumed > CTCPCnt_RECEIVE_BUFFER_LENGTH)
        {
            hr = E_UNEXPECTED;

            XomTrace(
                TCPCnt,
                L_ERROR,
                "[CTCPCnt::OnSocketReceive] (%s) m_dwBufferConsumed > CTCPCnt_RECEIVE_BUFFER_LENGTH",
                m_szDebugName);

            XOMASSERT(!"[CTCPCnt::OnSocketReceive] m_dwBufferConsumed > CTCPCnt_RECEIVE_BUFFER_LENGTH");

            goto lDone;
        }

        //
        // Ask daddy to parse it
        //
        
        ParseReceiveBuffer(m_rgbBuffer, &m_dwBufferConsumed);

        if((int) (CTCPCnt_RECEIVE_BUFFER_LENGTH - m_dwBufferConsumed) <= 0)
        {
            hr = E_FAIL;

            XomTrace(
                TCPCnt,
                L_ERROR,
                "[CTCPCnt::OnSocketReceive] (%s) Receive buffer is completely full after ParseReceiveBuffer. Disconnecting.",
                m_szDebugName);
            
            goto lDone;
        }

        //
        // And keep going
        //
        
        hr = StartReceiving();

        if(FAILED(hr))
        {
            XomTrace(
                TCPCnt,
                L_ERROR,
                "[CTCPCnt::OnSocketReceive] (%s) StartReceiving failed, hr=0x%08x",
                m_szDebugName,
                hr);

            goto lDone;
        }            
    }

lDone:
    
    if(FAILED(hr) || (cbRead == 0))
    {
        Disconnect(hr);
    }

    if(SUCCEEDED(hr))
    {
        XomTrace(TCPCnt, L_LOW,
            "[CTCPCnt::OnSocketReceive] (%s) OnReceive, addr = "DBGSINFMT", %d bytes, hr = 0x%08x",
            m_szDebugName,
            DBGSINPRM(&m_sinOut), cbRead, hrReceive);
    }
    else
    {
        XomTrace(TCPCnt, L_ERROR,
            "[CTCPCnt::OnSocketReceive] (%s) OnReceive, addr = "DBGSINFMT", %d bytes, hr = 0x%08x",
            m_szDebugName,
            DBGSINPRM(&m_sinOut), cbRead, hrReceive);
    }

    Release();
}

/////////////////////////////////////////////////////////////////////////////
void CTCPCnt::ResetBufferList()
{
    m_lockBufferList.WriteLock();

    while(m_dwOutboundBuffersStart != m_dwOutboundBuffersEnd)
    {
        if(m_rgOutboundBuffers[m_dwOutboundBuffersStart] != CTCPCnt_DONE_ENTRY)
        {
            m_rgOutboundBuffers[m_dwOutboundBuffersStart]->Release();
        }

        m_dwOutboundBuffersStart = (m_dwOutboundBuffersStart + 1) % 
            CTCPCnt_MAX_OUTBOUND_BUFFERS;
    }

    m_lockBufferList.WriteUnlock();
}

/////////////////////////////////////////////////////////////////////////////
HRESULT CTCPCnt::StartSending()
{
    HRESULT hr = S_OK;
    DWORD dwCount;
    DWORD dwPointer;
    DWORD dwBatchStart;

    while (TRUE)
    {
        // First, claim the send token to make sure that no one else is sending.
        if(InterlockedExchange(&m_fSending, TRUE) != FALSE)
        {
            //
            // Already sending
            //
            
            break;
        }

        //
        // Calculate count and the start / end stuff
        //

        m_lockBufferList.WriteLock();

        // If the socket is disconnected, then there is no reason to attempt to send.
        if( m_eState != S_CONNECTED )
        {
            //
            // Socket disconnected or connecting. Can't start sending.
            //
            
            m_fSending = FALSE;
            m_lockBufferList.WriteUnlock();
            hr = E_FAIL;
            break;
        }

        if(m_dwOutboundBuffersStart == m_dwOutboundBuffersEnd)
        {
            //
            // Outgoing queue is empty
            //
            
            m_fSending = FALSE;
            m_lockBufferList.WriteUnlock();
            break;
        }
        
        dwBatchStart = m_dwOutboundBuffersStart;
        dwPointer = m_dwOutboundBuffersStart;
        dwCount = 0;

        while(dwPointer != m_dwOutboundBuffersEnd)
        {
            if(m_rgOutboundBuffers[dwPointer] != CTCPCnt_DONE_ENTRY)
            {
                m_rgWSABuffers[dwPointer].buf = (char*) m_rgOutboundBuffers[dwPointer]->GetBuffer();
                m_rgWSABuffers[dwPointer].len = m_rgOutboundBuffers[dwPointer]->GetBufferLength();

                dwCount++;
                XOMASSERT(dwCount <= CTCPCnt_MAX_OUTBOUND_BUFFERS);

                dwPointer = (dwPointer + 1) % CTCPCnt_MAX_OUTBOUND_BUFFERS;

                // need to send contiguous blocks.  if we hit the end, stop this batch and wait for the next one.
                if (dwPointer == 0)
                {
                    break;
                }
            }
            else
            {
                if(dwCount > 0)
                {
                    //
                    // We can only batch buffers until the DONE_ENTRY. 
                    //
                    
                    break;
                }
                else
                {
                    //
                    // The done entry. Call the callback, and check for more 
                    // buffers.
                    //

                    m_dwOutboundBuffersStart = (m_dwOutboundBuffersStart + 1) % 
                        CTCPCnt_MAX_OUTBOUND_BUFFERS;

                    dwPointer = m_dwOutboundBuffersStart;
                    dwBatchStart = m_dwOutboundBuffersStart;

                    OnDone();

                    continue;                    
                }
            }
        }

        m_lockBufferList.WriteUnlock();

        if(dwCount > 0)
        {
            AddRef();
        
            hr = m_pSocket->SendEx(
                &(m_rgWSABuffers[dwBatchStart]),
                dwCount,
                this,
                (QWORD) dwCount);

            if(FAILED(hr))
            {
                m_fSending = FALSE;
                Release();

                XomTrace(
                   TCPCnt,
                   L_ERROR,
                   "[CTCPCnt::SendNextBuffer] (%s) m_pSocket->Send failed, hr = 0x%08x",
                   m_szDebugName,
                   hr);         
            }            
        }
        break;
    }

    return hr;
}

/////////////////////////////////////////////////////////////////////////////
HRESULT CTCPCnt::StartReceiving()
{
    HRESULT hr = S_OK;
    
    if(    m_eState != S_CONNECTED )
    {
        //
        // Socket disconnected or connecting. Can't start receiving.
        //
        
        goto lDone;
    }

#ifdef THROTTLE_READS
    //
    // If the outbound send queue is close to full we should stop receiving
    //

    m_lockBufferList.WriteLock();

    if(m_dwOutboundBuffersStart <= m_dwOutboundBuffersEnd)
    {
        dwCount = m_dwOutboundBuffersEnd - m_dwOutboundBuffersStart;
    }
    else
    {
        dwCount = CTCPCnt_MAX_OUTBOUND_BUFFERS - m_dwOutboundBuffersStart + 
            m_dwOutboundBuffersEnd;
    }

    m_lockBufferList.WriteUnlock();

    if(dwCount >= CTCPCnt_THROTTLE_THRESHOLD)
    {
        // Outbound queue is too full. Stop receiving until it catches up.

        goto lDone;
    }
#endif

    if(InterlockedCompareExchange(&m_fReceiving, TRUE, FALSE) != FALSE)
    {
        // Already receiving

        goto lDone;
    }

    AddRef();
    
    hr = m_pSocket->Receive(m_rgbBuffer + m_dwBufferConsumed, 
        CTCPCnt_RECEIVE_BUFFER_LENGTH - m_dwBufferConsumed, this, 0);

    if(FAILED(hr))
    {
        InterlockedExchange(&m_fReceiving, FALSE);
        Release();

        XomTrace(
                TCPCnt,
                L_ERROR,
                "[CTCPCnt::StartReceiving] (%s) m_pSocket->Receive failed, hr = 0x%08x",
                m_szDebugName,
                hr);
        
        goto lDone;
    }

lDone:

    return hr;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\tcpcnt.h ===
/*++

Copyright (c) Microsoft Corporation.  All rights reserved

Module Name:

  tcpcnt.h

Abstract:

  This file contains classes to help dealing with TCP connections. All classes
  use CServerSocket (servsock.h) and CCompletionPort (compport.h).

  CTCPCnt provides basic connect, send and receive functionality.

  CTCPCntMessageBased inherits from CTCPCnt and provides message parsing and
  processing.

  CTCPCntBuffer is a pure virtual class (interface) that buffers passed to 
  CTCPCnt and its other derived classes must implement.

  CTCPCntTemplateBuffer is a template for fixed size buffers that inherit from
  CTCPCntBuffer and it's usually enough for most cases.

--*/

#ifndef _TCPCNT_H_
#define _TCPCNT_H_

#include "servsock.h"
#include "addref.h"
#include <vptrlist.h>
#include <xlocks.h>

class CTCPCnt;
class CTCPSocketConnection;
class CTCPCntBuffer;

#define CTCPCnt_DONE_ENTRY ((VOID*)-1)
    // This constant is used when Done is called. It is posted in the 
    // outgoing queue and when it's found, OnDone gets called. 

#define CTCPCnt_RECEIVE_BUFFER_LENGTH 0x4000
    // Maximum receive buffer length

#define CTCPCnt_DEFAULT_MAX_OUTBOUND_BUFFERS 1024
#define CTCPCnt_MAX_OUTBOUND_BUFFERS (this->m_dwCTCPCntMaxOutboundBuffers)
    // Maximum outbound buffers

#define CTCPCnt_THROTTLE_THRESHOLD ((CTCPCnt_MAX_OUTBOUND_BUFFERS / 4) * 3)
    // Number of buffers in outbound queue before we stop receiving

#define CTCPCnt_MAX_BUFFERS_ON_SINGLE_SEND 256
    // Maximum number of buffers sent in a single "WSASend"

/******************************************************************************

  CTCPCnt

  Provides basic TCP connection services.

  You can create and initialize a CServerSocket object and call AttachAndConnect 
  to start the connection process. Or if you have a CServerSocket that is 
  already connected, for example from a successfull Accept, you can simply
  call Attach.

  Use Send to queue buffers to be sent to the destination. The buffers must be
  objects from classes that implement the interface CTCPCntBuffer. 

  Override any of the virtual methods if you want to process incoming data, 
  perform some custom task on Connect or Disconnect, etc..

******************************************************************************/

class CTCPCnt :
    public CServerSocketCallback,
    public CAddRefable

{
public:

    IMPLEMENT_REFCOUNT;

    // Constructor
    
    CTCPCnt(DWORD dwCTCPCntMaxOutboundBuffers = CTCPCnt_DEFAULT_MAX_OUTBOUND_BUFFERS);

    // Using rockall as allocator

    void *operator new(size_t len) { return XAlloc((int)len); }
    void operator delete(void *pv) { XFree(pv); }
    
    // Public methods. Check out implementation for details.
    
    HRESULT Attach(
        CServerSocket* pSocket );

    HRESULT AttachAndConnect(
        CServerSocket* pSocket,
        sockaddr_in* pAddr );

    virtual HRESULT Send(
        CTCPCntBuffer* pBuffer );

    HRESULT Done();

    void Disconnect(
        HRESULT hr );

    bool IsConnected()
    {
        return m_eState != S_NOT_CONNECTED;
    }

    void SetDebugName(LPCSTR pszName)
    {
        strncpy(m_szDebugName, pszName, sizeof(m_szDebugName)/sizeof(m_szDebugName[0]));
    }

    const sockaddr_in* GetSockAddr() { return &m_sinOut; }

protected:

    virtual HRESULT InternalInit(
        CServerSocket* pSocket,
        sockaddr_in* psin );

    // Destructor
    
    virtual ~CTCPCnt();
        // Destructor is protected. The only way to release this object is by
        // calling Release.

    // CTCPCnt virtuals. Override these and be cool. For more info, check the 
    // implementation.
    
    virtual void OnConnect();

    virtual void OnDisconnect(
        HRESULT hrReason );

    virtual void OnDone();
    
    virtual void ParseReceiveBuffer(
        BYTE* pBuffer,
        DWORD* pcbBuffer );

    // Protected methods. Check out implementation for details.
    
    void ResetBufferList();

    HRESULT StartSending();

    HRESULT StartReceiving();

    // CServerSocketCallback virtuals. 

    virtual void OnSocketConnect(
        HRESULT hr,
        QWORD qwCallbackArg );

    virtual void OnSocketAccept(
        CServerSocket *pListenSocket,
        CServerSocket *pAcceptedSocket,
        sockaddr_in *pLocalAddr,
        sockaddr_in *pRemoteAddr,
        HRESULT hr,
        QWORD qwCallbackArg ) {}

    virtual void OnSocketSend(
        BYTE *pbBufferSent,
        DWORD cbToSend,
        DWORD cbSent,
        HRESULT hrSend,
        QWORD qwCallbackArg );

    virtual void OnSocketSendTo(
        BYTE *pbBufferSent,
        DWORD cbToSend,
        DWORD cbSent,
        HRESULT hr,
        QWORD qwCallbackArg ) {}

    virtual void OnSocketReceive(
        BYTE *pbFilledInBuffer,
        DWORD cbRead,
        HRESULT hrReceive,
        QWORD qwCallbackArg );

    virtual void OnSocketReceiveFrom(
        BYTE *pbFilledInBuffer,
        DWORD cbRead,
        sockaddr_in *pFilledInFrom,
        HRESULT hr,
        QWORD qwCallbackArg ) {}

    virtual void OnSocketClose(
        HRESULT hr,
        QWORD qwCallbackArg ) {}

    // Connection enumerated states
    
    enum STATE {
    
        S_NOT_CONNECTED,
            // Not connected. 

        S_CONNECTING,
            // In the process of connecting. 

        S_CONNECTED
            // Connected
    };
    
    CServerSocket* m_pSocket;
        // The socket this object is encapsulating.

    STATE m_eState;
        // Current state of this object.

    DWORD m_dwCTCPCntMaxOutboundBuffers;
    CTCPCntBuffer** m_rgOutboundBuffers;
    volatile DWORD m_dwOutboundBuffersStart;
    volatile DWORD m_dwOutboundBuffersEnd;
    WSABUF *m_rgWSABuffers;
        // Queue of outbound buffers.

    xlocks::CSpinLock m_lockBufferList;
        // To synch access to m_BufferList.

    BYTE m_rgbBuffer[CTCPCnt_RECEIVE_BUFFER_LENGTH];
        // Used to receive data.

    DWORD m_dwBufferConsumed;
        // Amount of m_rgbBuffer used. In bytes.

    volatile LONG m_fSending;
        // Send pending?

    volatile LONG m_fReceiving;
        // Receiving?

    sockaddr_in m_sinOut;
        // Address of destination

    char m_szDebugName[32];
        // A debug name that will be used in trace statements.
};

/******************************************************************************

  CTCPCntMessageBased

  Provides CTCPCnt functionality plus incoming message parsing.

  CTCPCntMessageBased was designed to work with almost any kind of message
  oriented protocol. It allows the developer to specify it's own way to 
  define the message size. Just pass one of the CTCPCntMessageBasedPlugin_*
  classes in the GetMessageSize template parameter or write your own.
  
  E.g. CTCPCntMessageBased<CTCPCntMessageBasedPlugin_VerySimple> will handle
  messages where the first DWORD contains the total size of the message.

  Then override ProcessMessage to process your own messages.

  The maximum message size is limited to the receive buffer size of CTCPCnt
  which is defined by the constant CTCPCnt_RECEIVE_BUFFER_LENGTH.

******************************************************************************/

template <class GetMessageSize>
class CTCPCntMessageBased
    : public CTCPCnt
{
public:

    CTCPCntMessageBased<GetMessageSize>(DWORD dwCTCPCntMaxOutboundBuffers = CTCPCnt_DEFAULT_MAX_OUTBOUND_BUFFERS) :
        CTCPCnt(dwCTCPCntMaxOutboundBuffers)
    {
    }
    
    virtual void ProcessMessage(
        BYTE* pMsg,
        DWORD cbMsg ) = 0;
        // Override me to process the incoming messages. 
        // pMsg points to the message buffer.
        // cbMsg contains the size of the message pointed by pMsg.
        // You're allowed to change the buffer's content up to cbMsg bytes.

    // CTCPCnt virtuals

    virtual void ParseReceiveBuffer(
        BYTE* pBuffer,
        DWORD* pcbBuffer )
        // Parses the incoming data into messages. Each message will
        // generate one call to ProcessMessage.
    {
        HRESULT hr = S_OK;
        
        int cbParsed = 0;
        int cbAvailable = 0;

        for(;;)
        {
            cbAvailable = (int) (*pcbBuffer - cbParsed);
            
            // I'm using ints here instead of DWORDs because cbAvailable
            // could become negative if ProcessMessage ended up calling 
            // Disconnect
            
            int cbMessageSize = GetMessageSize()(pBuffer + cbParsed, cbAvailable);

            if(0 == cbMessageSize)
            {
                // We haven't read enough to parse a message. Come back later.

                break;
            }

            if( cbMessageSize > CTCPCnt_RECEIVE_BUFFER_LENGTH ||
                cbMessageSize < 0 )
            {
                //
                // Message is bigger than we could ever parse.
                //
                
                hr = E_FAIL;

                //XomTrace(
                //    ServHlpDebug,
                //    L_NORMAL,
                //    "[CTCPCnt::ParseReceiveBuffer] message is bigger than parsing buffer");
                
                goto lDone;
            }

            if(cbMessageSize > cbAvailable)
            {
                //
                // We haven't read the entire message yet.
                //

                break;
            }

            ProcessMessage(pBuffer + cbParsed, (DWORD) cbMessageSize);

            cbParsed += cbMessageSize;
        }
        
        //
        // Move the remainder of the receive buffer to the beginning. This 
        // shouldn't happen very often and shouldn't suck if the messages 
        // sizes are relatively small.
        //
        
        if(cbAvailable > 0)
        {
            XOMASSERT(cbAvailable + cbParsed <= CTCPCnt_RECEIVE_BUFFER_LENGTH);
            memmove(pBuffer, pBuffer + cbParsed, cbAvailable);
        }

        *pcbBuffer = cbAvailable;
        
    lDone:

        if(FAILED(hr))
        {
            Disconnect(hr);
        }
    }
};

/******************************************************************************

  CTCPCntMessageBased plugins

  Use these plugins to adjust CTCPCntMessageBased to your protocol... or write
  your own

******************************************************************************/

// CTCPCntMessageBasedPlugin_VerySimple
// Use this one if the length of the messages of your protocol are the first
// thing in the message and has the size of a DWORD in host byte order (as
// opposed to network byte order).
  
struct CTCPCntMessageBasedPlugin_VerySimple
{
    int operator ()(
        const BYTE* pBuffer,
        DWORD cbBuffer
    ) const
    {
        if(cbBuffer < sizeof(DWORD))
            return 0;

        return (int) *((DWORD*)pBuffer);
    }
};


/******************************************************************************

  CTCPCntBuffer

  Buffers passed to CTCPCnt::Send must inherit from this class. This class 
  is pure virtual (interface like) and is not good by itself. Try using its
  derived classes or write your own.

******************************************************************************/

class CTCPCntBuffer :
    public CAddRefable
{
public:

    virtual BYTE* GetBuffer() = 0;

    virtual DWORD GetBufferLength() = 0;

    // CONSIDER: Stash off the send list node in here
};

/******************************************************************************

  CTCPCntTemplateBuffer

  Use this if you use fixed buffer sizes. Pass the size in SIZE and you're
  all set.

******************************************************************************/

template <int SIZE>
class CTCPCntTemplateBuffer :
    public CTCPCntBuffer
{
public:

    IMPLEMENT_REFCOUNT;
    
    CTCPCntTemplateBuffer()
    {
        m_cbMsgBuffer = 0;
    }
    
    void *operator new(size_t len) { return XAlloc(len); }
    void operator delete(void *pv) { XFree(pv); }

    void SetSize(DWORD cbSize)
    {
        XOMASSERT(cbSize <= SIZE);
        m_cbMsgBuffer = cbSize;
    }

    DWORD GetMaxSize()
    {
        return SIZE;
    }
    
    // CTCPPumpBuffer virtuals
    
    virtual BYTE* GetBuffer()
    {
        return m_rgbMsgBuffer;
    }

    virtual DWORD GetBufferLength()
    {
        return m_cbMsgBuffer;
    }

protected:    

    ~CTCPCntTemplateBuffer()
        // Destructor is protected. The only way to release this object is by
        // calling Release.
    {
    }

    BYTE m_rgbMsgBuffer[SIZE];
    DWORD m_cbMsgBuffer;
};


/******************************************************************************

  CTCPCntVarBuffer

  Use this if you use variable buffer sizes. Constuct with static member
  CreateInstance.

******************************************************************************/
class CTCPCntVarBuffer :
    public CTCPCntBuffer
{
public:

    IMPLEMENT_REFCOUNT;

    static CTCPCntVarBuffer * __stdcall CreateInstance(DWORD cbBuffer)
    {
        CTCPCntVarBuffer *pCRet;

        pCRet = (CTCPCntVarBuffer *) XAlloc(cbBuffer + sizeof(CTCPCntVarBuffer));
        if (pCRet == NULL)
        {
            return NULL;
        }
        else
        {
            pCRet->CTCPCntVarBuffer::CTCPCntVarBuffer();
            pCRet->m_cbBuffer = cbBuffer;
            return pCRet;
        }
    }

    CTCPCntVarBuffer *Resize(DWORD cbBuffer)
    {
        if (cbBuffer <= m_cbBuffer)
        {
            m_cbBuffer = cbBuffer;
            return this;
        }
        else
        {
            return NULL;
        }
    }    
    
    void operator delete(void *pv) { XFree(pv); }
    
    // CTCPPumpBuffer virtuals

    virtual BYTE* GetBuffer()
    {
        return (BYTE *)(this + 1);
    }

    virtual DWORD GetBufferLength()
    {
        return m_cbBuffer;
    }

protected:
    
    void *operator new(size_t len) { return NULL; }

    DWORD m_cbBuffer;
};


#endif // #ifndef _TCPCNT_H_
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\crt\objd\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_servhlp_none_12.4.56.0_none_cbed9e443bdf8c54
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=servhlp
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.manifest
XP_MANIFEST_PATH=manifests\x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.cat
XP_CATALOG_PATH=manifests\x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.cat
XP_PAYLOAD_PATH=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=servhlp,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\rockall\obj\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_servhlp_none_12.4.56.0_none_cbed9e443bdf8c54
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=servhlp
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.manifest
XP_MANIFEST_PATH=manifests\x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.cat
XP_CATALOG_PATH=manifests\x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.cat
XP_PAYLOAD_PATH=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=servhlp,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\crt\obj\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_servhlp_none_12.4.56.0_none_cbed9e443bdf8c54
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=servhlp
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.manifest
XP_MANIFEST_PATH=manifests\x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.cat
XP_CATALOG_PATH=manifests\x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.cat
XP_PAYLOAD_PATH=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=servhlp,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\ntsvc\rockall\objd\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_servhlp_none_12.4.56.0_none_cbed9e443bdf8c54
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=servhlp
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.manifest
XP_MANIFEST_PATH=manifests\x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.cat
XP_CATALOG_PATH=manifests\x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c.cat
XP_PAYLOAD_PATH=x86_servhlp_no-public-key_12.4.56.0_x-ww_6804464c
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=servhlp,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\irtldbg.cpp ===
// Implementation of debug support functions

#include "precomp.hxx"

#include <tchar.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdarg.h>
#include <malloc.h>

#define DLL_IMPLEMENTATION
#define IMPLEMENTATION_EXPORT
#include <irtldbg.h>


IRTL_DLLEXP
void __cdecl
IrtlTrace(
    LPCTSTR ptszFormat,
    ...)
{
    TCHAR tszBuff[2048];
    va_list args;
    
    va_start(args, ptszFormat);
    _vsntprintf(tszBuff, sizeof(tszBuff) / sizeof(TCHAR), ptszFormat, args);
    tszBuff[ (sizeof(tszBuff)/sizeof(tszBuff[0])) - 1 ] = _T('\0');
    va_end(args);

    OutputDebugString(tszBuff);
}



#ifdef IRTLDEBUG

# if defined(USE_DEBUG_CRTS)  &&  defined(_MSC_VER)  &&  (_MSC_VER >= 1000)


#  ifdef IRTLDBG_RUNNING_AS_SERVICE

// The default assertion mechanism set up by Visual C++ 4 will not
// work with Active Server Pages because it's running inside a service
// and there is no desktop to interact with.

// Note: for this to work properly, #define _WIN32_WINNT 0x400 before
// including <winuser.h> or MB_SERVICE_NOTIFICATION won't be #define'd.

int __cdecl
AspAssertHandler(
    int   nReportType,
    char* pszErrorText,
    int*  pnReturn)
{
    const char szInfo[] = " (Press ABORT to terminate LKRhash,"
                          " RETRY to debug this failure,"
                          " or IGNORE to continue.)";
    char* pszMessageTitle = NULL;
    int nResult = FALSE;
    
    *pnReturn = 0;       // nothing for _CrtDbgReport to do
    
    // These flags enable message boxes to show up on the user's console
    switch (nReportType)
    {
    case _CRT_WARN:
        // If using MFC's TRACE macro (AfxTrace), the report hook
        // (AspAssertHandler) will get called with _CRT_WARN.  Ignore.
        pszMessageTitle = "Warning";
        *pnReturn = 0;
        return FALSE;

    case _CRT_ERROR:
        pszMessageTitle = "Fatal Error";
        break;

    case _CRT_ASSERT:
        pszMessageTitle = "Assertion Failed";
        break;
    }   
    
    char* pszMessageText =
        static_cast<char*>(malloc(strlen(pszErrorText) + strlen(szInfo) + 1));

    if (NULL == pszMessageText)
        return FALSE;

    strcpy(pszMessageText, pszErrorText);
    strcat(pszMessageText, szInfo);
    
    const int n = MessageBoxA(NULL, pszMessageText, pszMessageTitle,
                              (MB_SERVICE_NOTIFICATION | MB_TOPMOST
                               | MB_ABORTRETRYIGNORE | MB_ICONEXCLAMATION));

    if (n == IDABORT)
    {
        exit(1);
    }
    else if (n == IDRETRY)
    {
        *pnReturn = 1;   // tell _CrtDbgReport to start the debugger
        nResult = TRUE;  // tell _CrtDbgReport to run
    }

    free(pszMessageText);
    
    return nResult;
}

#  endif // IRTLDBG_RUNNING_AS_SERVICE
# endif // _MSC_VER >= 1000



void
IrtlDebugInit()
{
# if defined(USE_DEBUG_CRTS)  &&  defined(_MSC_VER)  &&  (_MSC_VER >= 1000)
#  ifdef IRTLDBG_RUNNING_AS_SERVICE
    // If we end up in _CrtDbgReport, don't put up a message box
    // _CrtSetReportMode(_CRT_WARN,   _CRTDBG_MODE_DEBUG);
    _CrtSetReportMode(_CRT_ASSERT, _CRTDBG_MODE_DEBUG);
    _CrtSetReportMode(_CRT_ERROR,  _CRTDBG_MODE_DEBUG);

    // Use AspAssertHandler to put up a message box instead
    _CrtSetReportHook(AspAssertHandler);
#  endif // IRTLDBG_RUNNING_AS_SERVICE

    
    // Enable debug heap allocations & check for memory leaks at program exit
    // The memory leak check will not be performed if inetinfo.exe is
    // run directly under a debugger, only if it is run as a service.
    _CrtSetDbgFlag(_CRTDBG_ALLOC_MEM_DF | _CRTDBG_LEAK_CHECK_DF
                   | _CrtSetDbgFlag(_CRTDBG_REPORT_FLAG));
# endif // _MSC_VER >= 1000
}



void
IrtlDebugTerm()
{
# if defined(USE_DEBUG_CRTS)  &&  defined(_MSC_VER)  &&  (_MSC_VER >= 1000)
#  ifdef IRTLDBG_RUNNING_AS_SERVICE
    // Turn off AspAssertHandler, so that we don't get numerous message boxes
    // if there are memory leaks on shutdown
    _CrtSetReportHook(NULL);
#  endif // IRTLDBG_RUNNING_AS_SERVICE
# endif // _MSC_VER >= 1000
}

#endif //IRTLDEBUG



BOOL
IsValidString(
    LPCTSTR ptsz,
    int nLength /* =-1 */)
{
    if (ptsz == NULL)
        return FALSE;

    return !IsBadStringPtr(ptsz, nLength);
}



BOOL
IsValidAddress(
    LPCVOID pv,
    UINT nBytes,
    BOOL fReadWrite /* =TRUE */)
{
    return (pv != NULL
            &&  !IsBadReadPtr(pv, nBytes)
            &&  (!fReadWrite  ||  !IsBadWritePtr((LPVOID) pv, nBytes)));
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\dllmain.cpp ===
// DllMain

#include <precomp.hxx>

#define DLL_IMPLEMENTATION
#define IMPLEMENTATION_EXPORT
#include <irtldbg.h>
#include <lkrhash.h>
#include "_locks.h"


/////////////////////////////////////////////////////////////////////////////
// DLL Entry Point

extern "C"
BOOL WINAPI
DllMain(
    HINSTANCE hInstance,
    DWORD dwReason,
    LPVOID /*lpReserved*/)
{
    BOOL  fReturn = TRUE;  // ok
    
    if (dwReason == DLL_PROCESS_ATTACH)
    {
        DisableThreadLibraryCalls(hInstance);
        Locks_Initialize();
        IRTL_DEBUG_INIT();
        IRTLTRACE0("LKRhash::DllMain::DLL_PROCESS_ATTACH\n");
        fReturn = LKRHashTableInit();
    }
    else if (dwReason == DLL_PROCESS_DETACH)
    {
        IRTLTRACE0("LKRhash::DllMain::DLL_PROCESS_DETACH\n");
        LKRHashTableUninit();
        IRTL_DEBUG_TERM();
        Locks_Cleanup();
    }

    return fReturn;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\locks.cpp ===
/*++

   Copyright    (c)    1998-2000    Microsoft Corporation

   Module  Name :
       locks.cpp

   Abstract:
       A collection of locks for multithreaded access to data structures

   Author:
       George V. Reilly      (GeorgeRe)     06-Jan-1998

   Environment:
       Win32 - User Mode

   Project:
       Internet Information Server RunTime Library

   Revision History:

--*/


#include "precomp.hxx"

#define DLL_IMPLEMENTATION
#define IMPLEMENTATION_EXPORT
#include <locks.h>
#include "_locks.h"


//------------------------------------------------------------------------
// Not all Win32 platforms support all the functions we want. Set up dummy
// thunks and use GetProcAddress to find their addresses at runtime.

typedef
BOOL
(WINAPI * PFN_SWITCH_TO_THREAD)(
    VOID
    );

static BOOL WINAPI
FakeSwitchToThread(
    VOID)
{
    return FALSE;
}

PFN_SWITCH_TO_THREAD  g_pfnSwitchToThread = NULL;


typedef
BOOL
(WINAPI * PFN_TRY_ENTER_CRITICAL_SECTION)(
    IN OUT LPCRITICAL_SECTION lpCriticalSection
    );

static BOOL WINAPI
FakeTryEnterCriticalSection(
    LPCRITICAL_SECTION /*lpCriticalSection*/)
{
    return FALSE;
}

PFN_TRY_ENTER_CRITICAL_SECTION g_pfnTryEnterCritSec = NULL;


typedef
DWORD
(WINAPI * PFN_SET_CRITICAL_SECTION_SPIN_COUNT)(
    LPCRITICAL_SECTION lpCriticalSection,
    DWORD dwSpinCount
   );

static DWORD WINAPI
FakeSetCriticalSectionSpinCount(
    LPCRITICAL_SECTION /*lpCriticalSection*/,
    DWORD              /*dwSpinCount*/)
{
    // For faked critical sections, the previous spin count is just ZERO!
    return 0;
}

PFN_SET_CRITICAL_SECTION_SPIN_COUNT  g_pfnSetCSSpinCount = NULL;

DWORD g_cProcessors = 0;


BOOL g_fLocksInitialized = FALSE;
CSimpleLock g_lckInit;

BOOL
Locks_Initialize()
{
    if (!g_fLocksInitialized)
    {
        g_lckInit.Enter();
    
        if (!g_fLocksInitialized)
        {
            // load kernel32 and get NT-specific entry points
            HMODULE hKernel32 = GetModuleHandle(TEXT("kernel32.dll"));

            if (hKernel32 != NULL)
            {
                g_pfnSwitchToThread = (PFN_SWITCH_TO_THREAD)
                    GetProcAddress(hKernel32, "SwitchToThread");
                
                g_pfnTryEnterCritSec = (PFN_TRY_ENTER_CRITICAL_SECTION)
                    GetProcAddress(hKernel32, "TryEnterCriticalSection");
                
                g_pfnSetCSSpinCount = (PFN_SET_CRITICAL_SECTION_SPIN_COUNT)
                    GetProcAddress(hKernel32, "SetCriticalSectionSpinCount");
            }
            
            if (g_pfnSwitchToThread == NULL)
                g_pfnSwitchToThread = FakeSwitchToThread;
            
            if (g_pfnTryEnterCritSec == NULL)
                g_pfnTryEnterCritSec = FakeTryEnterCriticalSection;
            
            if (g_pfnSetCSSpinCount == NULL)
                g_pfnSetCSSpinCount = FakeSetCriticalSectionSpinCount;
            
            g_cProcessors = NumProcessors();

            Lock_AtomicExchange((LONG*) &g_fLocksInitialized, TRUE);
        }
        
        g_lckInit.Leave();
    }

    return TRUE;
}


BOOL
Locks_Cleanup()
{
    return TRUE;
}



#ifdef __LOCKS_NAMESPACE__
namespace Locks {
#endif // __LOCKS_NAMESPACE__


#define LOCK_DEFAULT_SPIN_DATA(CLASS)                       \
  WORD   CLASS::sm_wDefaultSpinCount  = LOCK_DEFAULT_SPINS; \
  double CLASS::sm_dblDfltSpinAdjFctr = 0.5


#ifdef LOCK_INSTRUMENTATION

# define LOCK_STATISTICS_DATA(CLASS)            \
LONG        CLASS::sm_cTotalLocks       = 0;    \
LONG        CLASS::sm_cContendedLocks   = 0;    \
LONG        CLASS::sm_nSleeps           = 0;    \
LONGLONG    CLASS::sm_cTotalSpins       = 0;    \
LONG        CLASS::sm_nReadLocks        = 0;    \
LONG        CLASS::sm_nWriteLocks       = 0


# define LOCK_STATISTICS_DUMMY_IMPLEMENTATION(CLASS)            \
CLockStatistics                 CLASS::Statistics() const       \
{return CLockStatistics();}                                     \
CGlobalLockStatistics           CLASS::GlobalStatistics()       \
{return CGlobalLockStatistics();}                               \
void                            CLASS::ResetGlobalStatistics()  \
{}


# define LOCK_STATISTICS_REAL_IMPLEMENTATION(CLASS)             \
                                                                \
/* Per-lock statistics */                                       \
CLockStatistics                                                 \
CLASS::Statistics() const                                       \
{                                                               \
    CLockStatistics ls;                                         \
                                                                \
    ls.m_nContentions     = m_nContentions;                     \
    ls.m_nSleeps          = m_nSleeps;                          \
    ls.m_nContentionSpins = m_nContentionSpins;                 \
    if (m_nContentions > 0)                                     \
        ls.m_nAverageSpins = m_nContentionSpins / m_nContentions;\
    else                                                        \
        ls.m_nAverageSpins = 0;                                 \
    ls.m_nReadLocks       = m_nReadLocks;                       \
    ls.m_nWriteLocks      = m_nWriteLocks;                      \
    _tcscpy(ls.m_tszName, m_tszName);                           \
                                                                \
    return ls;                                                  \
}                                                               \
                                                                \
                                                                \
/* Global statistics for CLASS */                               \
CGlobalLockStatistics                                           \
CLASS::GlobalStatistics()                                       \
{                                                               \
    CGlobalLockStatistics gls;                                  \
                                                                \
    gls.m_cTotalLocks      = sm_cTotalLocks;                    \
    gls.m_cContendedLocks  = sm_cContendedLocks;                \
    gls.m_nSleeps          = sm_nSleeps;                        \
    gls.m_cTotalSpins      = sm_cTotalSpins;                    \
    if (sm_cContendedLocks > 0)                                 \
        gls.m_nAverageSpins = static_cast<LONG>(sm_cTotalSpins / \
                                                sm_cContendedLocks);\
    else                                                        \
        gls.m_nAverageSpins = 0;                                \
    gls.m_nReadLocks       = sm_nReadLocks;                     \
    gls.m_nWriteLocks      = sm_nWriteLocks;                    \
                                                                \
    return gls;                                                 \
}                                                               \
                                                                \
                                                                \
/* Reset global statistics for CLASS */                         \
void                                                            \
CLASS::ResetGlobalStatistics()                                  \
{                                                               \
    sm_cTotalLocks       = 0;                                   \
    sm_cContendedLocks   = 0;                                   \
    sm_nSleeps           = 0;                                   \
    sm_cTotalSpins       = 0;                                   \
    sm_nReadLocks        = 0;                                   \
    sm_nWriteLocks       = 0;                                   \
}


// Note: we are not using Interlocked operations for the shared
// statistical counters.  We'll lose perfect accuracy, but we'll
// gain by reduced bus synchronization traffic.
# define LOCK_INSTRUMENTATION_PROLOG()  \
    ++sm_cContendedLocks;               \
    LONG cTotalSpins = 0;               \
    WORD cSleeps = 0

// Don't need InterlockedIncrement or InterlockedExchangeAdd for 
// member variables, as the lock is now locked by this thread.
# define LOCK_INSTRUMENTATION_EPILOG()  \
    ++m_nContentions;                   \
    m_nSleeps += cSleeps;               \
    m_nContentionSpins += cTotalSpins;  \
    sm_nSleeps += cSleeps;              \
    sm_cTotalSpins += cTotalSpins

#else // !LOCK_INSTRUMENTATION
# define LOCK_STATISTICS_DATA(CLASS)
# define LOCK_STATISTICS_DUMMY_IMPLEMENTATION(CLASS)
# define LOCK_STATISTICS_REAL_IMPLEMENTATION(CLASS)
# define LOCK_INSTRUMENTATION_PROLOG()
# define LOCK_INSTRUMENTATION_EPILOG()
#endif // !LOCK_INSTRUMENTATION



//------------------------------------------------------------------------
// Function: RandomBackoffFactor
// Synopsis: A fudge factor to help avoid synchronization problems
//------------------------------------------------------------------------

double
RandomBackoffFactor()
{
    static const double s_aFactors[] = {
        1.020, 0.965,  0.890, 1.065,
        1.025, 1.115,  0.940, 0.995,
        1.050, 1.080,  0.915, 0.980,
        1.010,
    };
    const int nFactors = sizeof(s_aFactors) / sizeof(s_aFactors[0]);

    // Alternatives for nRand include a static counter
    // or the low DWORD of QueryPerformanceCounter().
    DWORD nRand = ::GetCurrentThreadId();

    return s_aFactors[nRand % nFactors];
}


//------------------------------------------------------------------------
// Function: SwitchOrSleep
// Synopsis: If possible, yields the thread with SwitchToThread. If that
//           doesn't work, calls Sleep.
//------------------------------------------------------------------------

void
SwitchOrSleep(
    DWORD dwSleepMSec)
{
#ifdef LOCKS_SWITCH_TO_THREAD
    if (!g_pfnSwitchToThread())
#endif
        Sleep(dwSleepMSec);
}
    



// CSmallSpinLock static member variables

LOCK_DEFAULT_SPIN_DATA(CSmallSpinLock);

#ifdef LOCK_SMALL_SPIN_INSTRUMENTATION

LOCK_STATISTICS_DATA(CSmallSpinLock);
LOCK_STATISTICS_REAL_IMPLEMENTATION(CSmallSpinLock);

#endif // LOCK_SMALL_SPIN_INSTRUMENTATION


//------------------------------------------------------------------------
// Function: CSmallSpinLock::_LockSpin
// Synopsis: Acquire an exclusive lock.  Blocks until acquired.
//------------------------------------------------------------------------

void
CSmallSpinLock::_LockSpin()
{
#ifdef LOCK_SMALL_SPIN_INSTRUMENTATION
    LOCK_INSTRUMENTATION_PROLOG();
#endif // LOCK_SMALL_SPIN_INSTRUMENTATION
    
    DWORD dwSleepTime = 0;
    LONG  cBaseSpins  = sm_wDefaultSpinCount;
    LONG  cBaseSpins2 = static_cast<LONG>(cBaseSpins * RandomBackoffFactor());

    // This lock cannot be acquired recursively. Attempting to do so will
    // deadlock this thread forever. Use CSpinLock instead if you need that
    // kind of lock.
    if (m_lTid == _CurrentThreadId())
    {
        IRTLASSERT(
           !"CSmallSpinLock: Illegally attempted to acquire lock recursively");
        DebugBreak();
    }

    while (!_TryLock())
    {
        // Only spin on a multiprocessor machine and then only if
        // spinning is enabled
        if (g_cProcessors > 1  &&  cBaseSpins != LOCK_DONT_SPIN)
        {
            LONG cSpins = cBaseSpins2;
        
            // Check no more than cBaseSpins2 times then yield.
            // It is important not to use the InterlockedExchange in the
            // inner loop in order to minimize system memory bus traffic.
            while (m_lTid != 0)
            { 
                if (--cSpins < 0)
                { 
#ifdef LOCK_SMALL_SPIN_INSTRUMENTATION
                    cTotalSpins += cBaseSpins2;
                    ++cSleeps;
#endif // LOCK_SMALL_SPIN_INSTRUMENTATION
                    SwitchOrSleep(dwSleepTime) ;

                    // Backoff algorithm: reduce (or increase) busy wait time
                    cBaseSpins2 = (int) (cBaseSpins2 * sm_dblDfltSpinAdjFctr);
                    // LOCK_MINIMUM_SPINS <= cBaseSpins2 <= LOCK_MAXIMUM_SPINS
                    cBaseSpins2 = min(LOCK_MAXIMUM_SPINS, cBaseSpins2);
                    cBaseSpins2 = max(cBaseSpins2, LOCK_MINIMUM_SPINS);
                    cSpins = cBaseSpins2;

                    // Using Sleep(0) leads to the possibility of priority
                    // inversion.  Sleep(0) only yields the processor if
                    // there's another thread of the same priority that's
                    // ready to run.  If a high-priority thread is trying to
                    // acquire the lock, which is held by a low-priority
                    // thread, then the low-priority thread may never get
                    // scheduled and hence never free the lock.  NT attempts
                    // to avoid priority inversions by temporarily boosting
                    // the priority of low-priority runnable threads, but the
                    // problem can still occur if there's a medium-priority
                    // thread that's always runnable.  If Sleep(1) is used,
                    // then the thread unconditionally yields the CPU.  We
                    // only do this for the second and subsequent even
                    // iterations, since a millisecond is a long time to wait
                    // if the thread can be scheduled in again sooner
                    // (~100,000 instructions).
                    // Avoid priority inversion: 0, 1, 0, 1,...
                    dwSleepTime = !dwSleepTime;
                }
                else
                {
                    Lock_Yield();
                }
            }

            // Lock is now available, but we still need to do the
            // InterlockedExchange to atomically grab it for ourselves.
#ifdef LOCK_SMALL_SPIN_INSTRUMENTATION
            cTotalSpins += cBaseSpins2 - cSpins;
#endif // LOCK_SMALL_SPIN_INSTRUMENTATION
        }

        // On a 1P machine, busy waiting is a waste of time
        else
        {
#ifdef LOCK_SMALL_SPIN_INSTRUMENTATION
            ++cSleeps;
#endif // LOCK_SMALL_SPIN_INSTRUMENTATION
            SwitchOrSleep(dwSleepTime);

            // Avoid priority inversion: 0, 1, 0, 1,...
            dwSleepTime = !dwSleepTime;
        }

    }

#ifdef LOCK_SMALL_SPIN_INSTRUMENTATION
    LOCK_INSTRUMENTATION_EPILOG();
#endif // LOCK_SMALL_SPIN_INSTRUMENTATION
}



// CSpinLock static member variables

LOCK_DEFAULT_SPIN_DATA(CSpinLock);
LOCK_STATISTICS_DATA(CSpinLock);
LOCK_STATISTICS_REAL_IMPLEMENTATION(CSpinLock);


//------------------------------------------------------------------------
// Function: CSpinLock::_LockSpin
// Synopsis: Acquire an exclusive lock.  Blocks until acquired.
//------------------------------------------------------------------------

void
CSpinLock::_LockSpin()
{
    LOCK_INSTRUMENTATION_PROLOG();
    
    DWORD dwSleepTime   = 0;
    bool  fAcquiredLock = false;
    LONG  cBaseSpins    = sm_wDefaultSpinCount;

    cBaseSpins = static_cast<LONG>(cBaseSpins * RandomBackoffFactor());

    while (!fAcquiredLock)
    {
        // Only spin on a multiprocessor machine and then only if
        // spinning is enabled
        if (g_cProcessors > 1  &&  sm_wDefaultSpinCount != LOCK_DONT_SPIN)
        {
            LONG cSpins = cBaseSpins;
        
            // Check no more than cBaseSpins times then yield
            while (m_lTid != 0)
            { 
                if (--cSpins < 0)
                { 
#ifdef LOCK_INSTRUMENTATION
                    cTotalSpins += cBaseSpins;
                    ++cSleeps;
#endif // LOCK_INSTRUMENTATION

                    SwitchOrSleep(dwSleepTime) ;

                    // Backoff algorithm: reduce (or increase) busy wait time
                    cBaseSpins = (int) (cBaseSpins * sm_dblDfltSpinAdjFctr);
                    // LOCK_MINIMUM_SPINS <= cBaseSpins <= LOCK_MAXIMUM_SPINS
                    cBaseSpins = min(LOCK_MAXIMUM_SPINS, cBaseSpins);
                    cBaseSpins = max(cBaseSpins, LOCK_MINIMUM_SPINS);
                    cSpins = cBaseSpins;
            
                    // Avoid priority inversion: 0, 1, 0, 1,...
                    dwSleepTime = !dwSleepTime;
                }
                else
                {
                    Lock_Yield();
                }
            }

            // Lock is now available, but we still need to atomically
            // update m_cOwners and m_nThreadId to grab it for ourselves.
#ifdef LOCK_INSTRUMENTATION
            cTotalSpins += cBaseSpins - cSpins;
#endif // LOCK_INSTRUMENTATION
        }

        // on a 1P machine, busy waiting is a waste of time
        else
        {
#ifdef LOCK_INSTRUMENTATION
            ++cSleeps;
#endif // LOCK_INSTRUMENTATION
            SwitchOrSleep(dwSleepTime);
            
            // Avoid priority inversion: 0, 1, 0, 1,...
            dwSleepTime = !dwSleepTime;
        }

        // Is the lock unowned?
        if (_TryLock())
            fAcquiredLock = true; // got the lock
    }

    IRTLASSERT((m_lTid & OWNER_MASK) > 0
               &&  (m_lTid & THREAD_MASK) == _CurrentThreadId());

    LOCK_INSTRUMENTATION_EPILOG();
}



// CCritSec static member variables

LOCK_DEFAULT_SPIN_DATA(CCritSec);
LOCK_STATISTICS_DATA(CCritSec);
LOCK_STATISTICS_DUMMY_IMPLEMENTATION(CCritSec);

bool
CCritSec::TryWriteLock()
{
    IRTLASSERT(g_pfnTryEnterCritSec != NULL);
    return g_pfnTryEnterCritSec(&m_cs) ? true : false;
}

//------------------------------------------------------------------------
// Function: CCritSec::SetSpinCount
// Synopsis: This function is used to call the appropriate underlying
//           functions to set the spin count for the supplied critical
//           section. The original function is supposed to be exported out
//           of kernel32.dll from NT 4.0 SP3. If the func is not available
//           from the dll, we will use a fake function.
//
// Arguments:
//   lpCriticalSection
//      Points to the critical section object.
//
//   dwSpinCount
//      Supplies the spin count for the critical section object. For UP
//      systems, the spin count is ignored and the critical section spin
//      count is set to 0. For MP systems, if contention occurs, instead of
//      waiting on a semaphore associated with the critical section, the
//      calling thread will spin for spin count iterations before doing the
//      hard wait. If the critical section becomes free during the spin, a
//      wait is avoided.
//
// Returns:
//      The previous spin count for the critical section is returned.
//------------------------------------------------------------------------

DWORD
CCritSec::SetSpinCount(
    LPCRITICAL_SECTION pcs,
    DWORD dwSpinCount)
{
    IRTLASSERT(g_pfnSetCSSpinCount != NULL);
    return g_pfnSetCSSpinCount(pcs, dwSpinCount);
}


// CFakeLock static member variables

LOCK_DEFAULT_SPIN_DATA(CFakeLock);
LOCK_STATISTICS_DATA(CFakeLock);
LOCK_STATISTICS_DUMMY_IMPLEMENTATION(CFakeLock);



// CReaderWriterLock static member variables

LOCK_DEFAULT_SPIN_DATA(CReaderWriterLock);
LOCK_STATISTICS_DATA(CReaderWriterLock);
LOCK_STATISTICS_REAL_IMPLEMENTATION(CReaderWriterLock);


void
CReaderWriterLock::_LockSpin(
    bool fWrite)
{
    LOCK_INSTRUMENTATION_PROLOG();
    
    DWORD dwSleepTime  = 0;
    LONG  cBaseSpins   = static_cast<LONG>(sm_wDefaultSpinCount
                                           * RandomBackoffFactor());
    LONG  cSpins       = cBaseSpins;
    
    for (;;)
    {
        if (g_cProcessors < 2  ||  sm_wDefaultSpinCount == LOCK_DONT_SPIN)
            cSpins = 1; // must loop once to call _TryRWLock

        for (int i = cSpins;  --i >= 0;  )
        {
            bool fLock = fWrite  ?  _TryWriteLock()  :  _TryReadLock();
            if (fLock)
            {
#ifdef LOCK_INSTRUMENTATION
                cTotalSpins += (cSpins - i - 1);
#endif // LOCK_INSTRUMENTATION
                goto locked;
            }
            Lock_Yield();
        }

#ifdef LOCK_INSTRUMENTATION
        cTotalSpins += cBaseSpins;
        ++cSleeps;
#endif // LOCK_INSTRUMENTATION

        SwitchOrSleep(dwSleepTime) ;
        dwSleepTime = !dwSleepTime; // Avoid priority inversion: 0, 1, 0, 1,...
        
        // Backoff algorithm: reduce (or increase) busy wait time
        cBaseSpins = (int) (cBaseSpins * sm_dblDfltSpinAdjFctr);
        // LOCK_MINIMUM_SPINS <= cBaseSpins <= LOCK_MAXIMUM_SPINS
        cBaseSpins = min(LOCK_MAXIMUM_SPINS, cBaseSpins);
        cBaseSpins = max(cBaseSpins, LOCK_MINIMUM_SPINS);
        cSpins = cBaseSpins;
    }

  locked:
    IRTLASSERT(fWrite ? IsWriteLocked() : IsReadLocked());

    LOCK_INSTRUMENTATION_EPILOG();
}



// CReaderWriterLock2 static member variables

LOCK_DEFAULT_SPIN_DATA(CReaderWriterLock2);
LOCK_STATISTICS_DATA(CReaderWriterLock2);
LOCK_STATISTICS_REAL_IMPLEMENTATION(CReaderWriterLock2);


void
CReaderWriterLock2::_WriteLockSpin()
{
    // Add ourselves to the queue of waiting writers
    for (LONG l = m_lRW;  !_CmpExch(l + SL_WRITER_INCR, l);  l = m_lRW)
    {
        Lock_Yield();
    }
    
    _LockSpin(true);
}


void
CReaderWriterLock2::_LockSpin(
    bool fWrite)
{
    LOCK_INSTRUMENTATION_PROLOG();
    
    DWORD dwSleepTime  = 0;
    LONG  cBaseSpins   = static_cast<LONG>(sm_wDefaultSpinCount
                                           * RandomBackoffFactor());
    LONG  cSpins       = cBaseSpins;
    
    for (;;)
    {
        if (g_cProcessors < 2  ||  sm_wDefaultSpinCount == LOCK_DONT_SPIN)
            cSpins = 1; // must loop once to call _TryRWLock

        for (int i = cSpins;  --i >= 0;  )
        {
            bool fLock = fWrite  ?  _TryWriteLock(0)  :  _TryReadLock();

            if (fLock)
            {
#ifdef LOCK_INSTRUMENTATION
                cTotalSpins += (cSpins - i - 1);
#endif // LOCK_INSTRUMENTATION
                goto locked;
            }
            Lock_Yield();
        }

#ifdef LOCK_INSTRUMENTATION
        cTotalSpins += cBaseSpins;
        ++cSleeps;
#endif // LOCK_INSTRUMENTATION

        SwitchOrSleep(dwSleepTime) ;
        dwSleepTime = !dwSleepTime; // Avoid priority inversion: 0, 1, 0, 1,...
        
        // Backoff algorithm: reduce (or increase) busy wait time
        cBaseSpins = (int) (cBaseSpins * sm_dblDfltSpinAdjFctr);
        // LOCK_MINIMUM_SPINS <= cBaseSpins <= LOCK_MAXIMUM_SPINS
        cBaseSpins = min(LOCK_MAXIMUM_SPINS, cBaseSpins);
        cBaseSpins = max(cBaseSpins, LOCK_MINIMUM_SPINS);
        cSpins = cBaseSpins;
    }

  locked:
    IRTLASSERT(fWrite ? IsWriteLocked() : IsReadLocked());

    LOCK_INSTRUMENTATION_EPILOG();
}



// CReaderWriterLock3 static member variables

LOCK_DEFAULT_SPIN_DATA(CReaderWriterLock3);
LOCK_STATISTICS_DATA(CReaderWriterLock3);
LOCK_STATISTICS_REAL_IMPLEMENTATION(CReaderWriterLock3);


void
CReaderWriterLock3::_WriteLockSpin()
{
    // Add ourselves to the queue of waiting writers
    for (LONG l = m_lRW;  !_CmpExch(l + SL_WRITER_INCR, l);  l = m_lRW)
    {
        Lock_Yield();
    }
    
    _LockSpin(SPIN_WRITE);
}


void
CReaderWriterLock3::_LockSpin(
    SPIN_TYPE st)
{
    LOCK_INSTRUMENTATION_PROLOG();
    
    DWORD dwSleepTime  = 0;
    LONG  cBaseSpins   = static_cast<LONG>(sm_wDefaultSpinCount
                                           * RandomBackoffFactor());
    LONG  cSpins       = cBaseSpins;
    
    for (;;)
    {
        if (g_cProcessors < 2  ||  sm_wDefaultSpinCount == LOCK_DONT_SPIN)
            cSpins = 1; // must loop once to call _TryRWLock

        for (int i = cSpins;  --i >= 0;  )
        {
            bool fLock;

            if (st == SPIN_WRITE)
                fLock = _TryWriteLock(0);
            else if (st == SPIN_READ)
                fLock = _TryReadLock();
            else
            {
                IRTLASSERT(st == SPIN_READ_RECURSIVE);
                fLock = _TryReadLockRecursive();
            }

            if (fLock)
            {
#ifdef LOCK_INSTRUMENTATION
                cTotalSpins += (cSpins - i - 1);
#endif // LOCK_INSTRUMENTATION
                goto locked;
            }
            Lock_Yield();
        }

#ifdef LOCK_INSTRUMENTATION
        cTotalSpins += cBaseSpins;
        ++cSleeps;
#endif // LOCK_INSTRUMENTATION

        SwitchOrSleep(dwSleepTime) ;
        dwSleepTime = !dwSleepTime; // Avoid priority inversion: 0, 1, 0, 1,...
        
        // Backoff algorithm: reduce (or increase) busy wait time
        cBaseSpins = (int) (cBaseSpins * sm_dblDfltSpinAdjFctr);
        // LOCK_MINIMUM_SPINS <= cBaseSpins <= LOCK_MAXIMUM_SPINS
        cBaseSpins = min(LOCK_MAXIMUM_SPINS, cBaseSpins);
        cBaseSpins = max(cBaseSpins, LOCK_MINIMUM_SPINS);
        cSpins = cBaseSpins;
    }

  locked:
    IRTLASSERT((st == SPIN_WRITE)  ?  IsWriteLocked()  :  IsReadLocked());

    LOCK_INSTRUMENTATION_EPILOG();
}



#ifdef __LOCKS_NAMESPACE__
}
#endif // __LOCKS_NAMESPACE__
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\lkrhash.cpp ===
/*++

   Copyright    (c) 1998-2001    Microsoft Corporation

   Module  Name :
       LKRhash.cpp

   Abstract:
       Implements LKRhash: a fast, scalable, cache- and MP-friendly hash table

   Author:
       Paul (Per-Ake) Larson, palarson@microsoft.com, July 1997
       Murali R. Krishnan    (MuraliK)
       George V. Reilly      (GeorgeRe)     06-Jan-1998

   Environment:
       Win32 - User Mode

   Project:
       Internet Information Server RunTime Library

   Revision History:
       Jan 1998   - Massive cleanup and rewrite.  Templatized.
       10/01/1998 - Change name from LKhash to LKRhash

--*/

#include "precomp.hxx"


#define DLL_IMPLEMENTATION
#define IMPLEMENTATION_EXPORT
#include <lkrhash.h>

#ifndef __LKRHASH_NO_NAMESPACE__
 #define LKRHASH_NS LKRhash
#else  // __LKRHASH_NO_NAMESPACE__
 #define LKRHASH_NS
#endif // __LKRHASH_NO_NAMESPACE__

#include "_locks.h"


#ifdef LKRHASH_ALLOCATOR_NEW

# define DECLARE_ALLOCATOR(CLASS)                        \
  CLKRhashAllocator* LKRHASH_NS::CLASS::sm_palloc = NULL

# define DECLARE_ALLOCATOR_LHTSUBCLASS(CLASS)            \
  CLKRhashAllocator* LKRHASH_NS::CLKRLinearHashTable::CLASS::sm_palloc = NULL


  // DECLARE_ALLOCATOR(CLKRLinearHashTable);
  // DECLARE_ALLOCATOR(CLKRHashTable);
  DECLARE_ALLOCATOR(CNodeClump);
  DECLARE_ALLOCATOR(CSmallSegment);
  DECLARE_ALLOCATOR(CMediumSegment);
  DECLARE_ALLOCATOR(CLargeSegment);

#endif // LKRHASH_ALLOCATOR_NEW


static bool s_fInitialized = false;
static LONG g_nLkrInitCount = 0;
CSimpleLock g_lckLkrInit;


// -------------------------------------------------------------------------
// Initialize per-class allocators
// -------------------------------------------------------------------------

bool
LKRHashTableInit()
{
    bool f = true;

#define INIT_ALLOCATOR(CLASS, N)                                \
    LKRHASH_ALLOCATOR_INIT(LKRHASH_NS::CLASS, N, f)

#define INIT_ALLOCATOR_LHTSUBCLASS(CLASS, N)                    \
    LKRHASH_ALLOCATOR_INIT(LKRHASH_NS::CLKRLinearHashTable::CLASS, N, f)


    g_lckLkrInit.Enter();

    LONG nCount = g_nLkrInitCount;

    UNREFERENCED_PARAMETER(nCount);
    IRTLTRACE1("LKRHashTableInit, %ld\n", nCount);

    if (++g_nLkrInitCount == 1)
    {
        // INIT_ALLOCATOR(CLKRLinearHashTable,        20);
        // INIT_ALLOCATOR(CLKRHashTable,               4);
        INIT_ALLOCATOR(CNodeClump,    200);
        INIT_ALLOCATOR(CSmallSegment,   5);
        INIT_ALLOCATOR(CMediumSegment,  5);
        INIT_ALLOCATOR(CLargeSegment,   5);
        
        s_fInitialized = f;
    }

    g_lckLkrInit.Leave();

    return f;
} // LKRHashTableInit



// -------------------------------------------------------------------------
// Destroy per-class allocators
// -------------------------------------------------------------------------

void
LKRHashTableUninit()
{
#define UNINIT_ALLOCATOR(CLASS)                        \
    LKRHASH_ALLOCATOR_UNINIT(LKRHASH_NS::CLASS)

#define UNINIT_ALLOCATOR_LHTSUBCLASS(CLASS)            \
    LKRHASH_ALLOCATOR_UNINIT(LKRHASH_NS::CLKRLinearHashTable::CLASS)

    g_lckLkrInit.Enter();

    LONG nCount = g_nLkrInitCount;

    UNREFERENCED_PARAMETER(nCount);

    if (--g_nLkrInitCount == 0)
    {
        // UNINIT_ALLOCATOR(CLKRLinearHashTable);
        // UNINIT_ALLOCATOR(CLKRHashTable);
        UNINIT_ALLOCATOR(CNodeClump);
        UNINIT_ALLOCATOR(CSmallSegment);
        UNINIT_ALLOCATOR(CMediumSegment);
        UNINIT_ALLOCATOR(CLargeSegment);
        
        s_fInitialized = false;
    }

    g_lckLkrInit.Leave();

    IRTLTRACE1("LKRHashTableUninit done, %ld\n", nCount);

} // LKRHashTableUninit



#ifndef __LKRHASH_NO_NAMESPACE__
namespace LKRhash {
#endif // !__LKRHASH_NO_NAMESPACE__

// See if countdown loops are faster than countup loops for traversing
// a CNodeClump
#ifdef LKR_COUNTDOWN
 #define  FOR_EACH_NODE(x)    for (x = NODES_PER_CLUMP;  --x >= 0;  )
#else // !LKR_COUNTDOWN
 #define  FOR_EACH_NODE(x)    for (x = 0;  x < NODES_PER_CLUMP;  ++x)
#endif // !LKR_COUNTDOWN


// -------------------------------------------------------------------------
// class static member variables
// -------------------------------------------------------------------------

#ifdef LOCK_INSTRUMENTATION
LONG CBucket::sm_cBuckets    = 0;

LONG CLKRLinearHashTable::sm_cTables              = 0;
#endif // LOCK_INSTRUMENTATION


#ifndef LKR_NO_GLOBAL_LIST
CLockedDoubleList CLKRLinearHashTable::sm_llGlobalList;
CLockedDoubleList CLKRHashTable::sm_llGlobalList;
#endif // LKR_NO_GLOBAL_LIST



// CLKRLinearHashTable --------------------------------------------------------
// Public Constructor for class CLKRLinearHashTable.
// -------------------------------------------------------------------------

CLKRLinearHashTable::CLKRLinearHashTable(
    LPCSTR          pszName,        // An identifier for debugging
    PFnExtractKey   pfnExtractKey,  // Extract key from record
    PFnCalcKeyHash  pfnCalcKeyHash, // Calculate hash signature of key
    PFnEqualKeys    pfnEqualKeys,   // Compare two keys
    PFnAddRefRecord pfnAddRefRecord,// AddRef in FindKey, etc
    double          maxload,        // Upperbound on the average chain length
    DWORD           initsize,       // Initial size of hash table.
    DWORD         /*num_subtbls*/,  // for compatiblity with CLKRHashTable
    bool            fMultiKeys      // Allow multiple identical keys?
    )
    :
#ifdef LOCK_INSTRUMENTATION
      m_Lock(_LockName()),
#endif // LOCK_INSTRUMENTATION
      m_nTableLockType(static_cast<BYTE>(TableLock::LockType())),
      m_nBucketLockType(static_cast<BYTE>(BucketLock::LockType())),
      m_phtParent(NULL),    // directly created, no owning table
      m_fMultiKeys(fMultiKeys)
{
#ifndef LOCK_INSTRUMENTATION
    STATIC_ASSERT(1 <= LK_DFLT_MAXLOAD  && LK_DFLT_MAXLOAD <= NODES_PER_CLUMP);
#endif // !LOCK_INSTRUMENTATION
    STATIC_ASSERT(0 <= NODE_BEGIN  &&  NODE_BEGIN < NODES_PER_CLUMP);
    STATIC_ASSERT(!(0 <= NODE_END  &&  NODE_END < NODES_PER_CLUMP));

    IRTLVERIFY(LK_SUCCESS
               == _Initialize(pfnExtractKey, pfnCalcKeyHash, pfnEqualKeys,
                              pfnAddRefRecord, pszName, maxload, initsize));

    _InsertThisIntoGlobalList();
} // CLKRLinearHashTable::CLKRLinearHashTable



// CLKRLinearHashTable --------------------------------------------------------
// Private Constructor for class CLKRLinearHashTable, used by CLKRHashTable.
// -------------------------------------------------------------------------

CLKRLinearHashTable::CLKRLinearHashTable(
    LPCSTR          pszName,        // An identifier for debugging
    PFnExtractKey   pfnExtractKey,  // Extract key from record
    PFnCalcKeyHash  pfnCalcKeyHash, // Calculate hash signature of key
    PFnEqualKeys    pfnEqualKeys,   // Compare two keys
    PFnAddRefRecord pfnAddRefRecord,// AddRef in FindKey, etc
    double          maxload,        // Upperbound on the average chain length
    DWORD           initsize,       // Initial size of hash table.
    CLKRHashTable*  phtParent,      // Owning table.
    bool            fMultiKeys      // Allow multiple identical keys?
    )
    :
#ifdef LOCK_INSTRUMENTATION
      m_Lock(_LockName()),
#endif // LOCK_INSTRUMENTATION
      m_nTableLockType(static_cast<BYTE>(TableLock::LockType())),
      m_nBucketLockType(static_cast<BYTE>(BucketLock::LockType())),
      m_phtParent(phtParent),
      m_fMultiKeys(fMultiKeys)
{
    IRTLASSERT(m_phtParent != NULL);
    IRTLVERIFY(LK_SUCCESS
               == _Initialize(pfnExtractKey, pfnCalcKeyHash, pfnEqualKeys,
                              pfnAddRefRecord, pszName, maxload, initsize));

    _InsertThisIntoGlobalList();
} // CLKRLinearHashTable::CLKRLinearHashTable



// _Initialize -------------------------------------------------------------
// Do all the real work of constructing a CLKRLinearHashTable
// -------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_Initialize(
    PFnExtractKey   pfnExtractKey,
    PFnCalcKeyHash  pfnCalcKeyHash,
    PFnEqualKeys    pfnEqualKeys,
    PFnAddRefRecord pfnAddRefRecord,
    LPCSTR          pszName,
    double          maxload,
    DWORD           initsize)
{
    m_dwSignature =     SIGNATURE;
    m_dwBktAddrMask0 =  0;
    m_dwBktAddrMask1 =  0;
    m_iExpansionIdx =   0;
    m_paDirSegs =       NULL;
    m_lkts =            LK_MEDIUM_TABLESIZE;
    m_dwSegBits =       0;
    m_dwSegSize =       0;
    m_dwSegMask =       0;
    m_lkrcState =       LK_UNUSABLE;
    m_MaxLoad =         LK_DFLT_MAXLOAD;
    m_nLevel =          0;
    m_cDirSegs =        0;
    m_cRecords =        0;
    m_cActiveBuckets =  0;
    m_wBucketLockSpins= LOCK_USE_DEFAULT_SPINS;
    m_pfnExtractKey =   pfnExtractKey;
    m_pfnCalcKeyHash =  pfnCalcKeyHash;
    m_pfnEqualKeys =    pfnEqualKeys;
    m_pfnAddRefRecord = pfnAddRefRecord;

    strncpy(m_szName, pszName, NAME_SIZE-1);
    m_szName[NAME_SIZE-1] = '\0';

    IRTLASSERT(m_pfnExtractKey != NULL
               && m_pfnCalcKeyHash != NULL
               && m_pfnEqualKeys != NULL
               && m_pfnAddRefRecord != NULL);

    IRTLASSERT(s_fInitialized);

    if (!s_fInitialized)
        return (m_lkrcState = LK_NOT_INITIALIZED);

    if (m_pfnExtractKey == NULL
            || m_pfnCalcKeyHash == NULL
            || m_pfnEqualKeys == NULL
            || m_pfnAddRefRecord == NULL)
        return (m_lkrcState = LK_BAD_PARAMETERS);

    // TODO: better sanity check for ridiculous values?
    m_MaxLoad = (maxload <= 1.0)  ?  LK_DFLT_MAXLOAD  :  maxload;
    m_MaxLoad = min(m_MaxLoad, 10 * NODES_PER_CLUMP);

    // Choose the size of the segments according to the desired "size" of
    // the table, small, medium, or large.
    LK_TABLESIZE lkts;

    if (initsize == LK_SMALL_TABLESIZE)
    {
        lkts = LK_SMALL_TABLESIZE;
        initsize = CSmallSegment::INITSIZE;
    }
    else if (initsize == LK_MEDIUM_TABLESIZE)
    {
        lkts = LK_MEDIUM_TABLESIZE;
        initsize = CMediumSegment::INITSIZE;
    }
    else if (initsize == LK_LARGE_TABLESIZE)
    {
        lkts = LK_LARGE_TABLESIZE;
        initsize = CLargeSegment::INITSIZE;
    }

    // specified an explicit initial size
    else
    {
        // force Small::INITSIZE  <= initsize <=  MAX_DIRSIZE * Large::INITSIZE
        initsize = min(max(initsize, CSmallSegment::INITSIZE),
                       (MAX_DIRSIZE >> CLargeSegment::SEGBITS)
                            * CLargeSegment::INITSIZE);

        // Guess a table size
        if (initsize <= 8 * CSmallSegment::INITSIZE)
            lkts = LK_SMALL_TABLESIZE;
        else if (initsize >= CLargeSegment::INITSIZE)
            lkts = LK_LARGE_TABLESIZE;
        else
            lkts = LK_MEDIUM_TABLESIZE;
    }

    return _SetSegVars(lkts, initsize);
} // CLKRLinearHashTable::_Initialize



// CLKRHashTable ----------------------------------------------------------
// Constructor for class CLKRHashTable.
// ---------------------------------------------------------------------

CLKRHashTable::CLKRHashTable(
    LPCSTR          pszName,        // An identifier for debugging
    PFnExtractKey   pfnExtractKey,  // Extract key from record
    PFnCalcKeyHash  pfnCalcKeyHash, // Calculate hash signature of key
    PFnEqualKeys    pfnEqualKeys,   // Compare two keys
    PFnAddRefRecord pfnAddRefRecord,// AddRef in FindKey, etc
    double          maxload,        // Bound on the average chain length
    DWORD           initsize,       // Initial size of hash table.
    DWORD           num_subtbls,    // Number of subordinate hash tables.
    bool            fMultiKeys      // Allow multiple identical keys?
    )
    : m_dwSignature(SIGNATURE),
      m_cSubTables(0),
      m_palhtDir(NULL),
      m_pfnExtractKey(pfnExtractKey),
      m_pfnCalcKeyHash(pfnCalcKeyHash),
      m_lkrcState(LK_BAD_PARAMETERS)
{
    strncpy(m_szName, pszName, NAME_SIZE-1);
    m_szName[NAME_SIZE-1] = '\0';

    _InsertThisIntoGlobalList();

    IRTLASSERT(pfnExtractKey != NULL
               && pfnCalcKeyHash != NULL
               && pfnEqualKeys != NULL
               && pfnAddRefRecord != NULL);

    if (pfnExtractKey == NULL
            || pfnCalcKeyHash == NULL
            || pfnEqualKeys == NULL
            || pfnAddRefRecord == NULL)
        return;

    if (!s_fInitialized)
    {
        m_lkrcState = LK_NOT_INITIALIZED;
        return;
    }

    LK_TABLESIZE lkts = NumSubTables(initsize, num_subtbls);

#ifdef IRTLDEBUG
    int cBuckets = initsize;
    if (initsize == LK_SMALL_TABLESIZE)
        cBuckets = CSmallSegment::INITSIZE;
    else if (initsize == LK_MEDIUM_TABLESIZE)
        cBuckets = CMediumSegment::INITSIZE;
    else if (initsize == LK_LARGE_TABLESIZE)
        cBuckets = CLargeSegment::INITSIZE;

    IRTLTRACE(TEXT("CLKRHashTable: %s, %d subtables, initsize = %d, ")
              TEXT("total #buckets = %d\n"),
              ((lkts == LK_SMALL_TABLESIZE) ? "small" : 
               (lkts == LK_MEDIUM_TABLESIZE) ? "medium" : "large"),
              num_subtbls, initsize, cBuckets * num_subtbls);
#else
    UNREFERENCED_PARAMETER(lkts);
#endif // IRTLDEBUG

    m_lkrcState = LK_ALLOC_FAIL;
    m_palhtDir  = _AllocateSubTableArray(num_subtbls);

    if (m_palhtDir == NULL)
        return;
    else
    {
        m_cSubTables = num_subtbls;
        for (DWORD i = 0;  i < m_cSubTables;  i++)
            m_palhtDir[i] = NULL;
    }

    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        m_palhtDir[i] = _AllocateSubTable(pszName, pfnExtractKey,
                                          pfnCalcKeyHash, pfnEqualKeys,
                                          pfnAddRefRecord, maxload,
                                          initsize, this, fMultiKeys);

        // Failed to allocate a subtable.  Destroy everything allocated so far.
        if (m_palhtDir[i] == NULL  ||  !m_palhtDir[i]->IsValid())
        {
            for (DWORD j = i;  j-- > 0;  )
                _FreeSubTable(m_palhtDir[j]);
            _FreeSubTableArray(m_palhtDir);
            m_cSubTables = 0;
            m_palhtDir   = NULL;

            return;
        }
    }

    m_nSubTableMask = m_cSubTables - 1;
    // power of 2?
    if ((m_nSubTableMask & m_cSubTables) != 0)
        m_nSubTableMask = -1;

    m_lkrcState = LK_SUCCESS; // so IsValid/IsUsable won't fail
} // CLKRHashTable::CLKRHashTable



// ~CLKRLinearHashTable ------------------------------------------------------
// Destructor for class CLKRLinearHashTable
//-------------------------------------------------------------------------

CLKRLinearHashTable::~CLKRLinearHashTable()
{
    // must acquire all locks before deleting to make sure
    // that no other threads are using the table
    WriteLock();
    _Clear(false);
    WriteUnlock();

    _RemoveThisFromGlobalList();

    m_dwSignature = SIGNATURE_FREE;
    m_lkrcState = LK_UNUSABLE; // so IsUsable will fail
} // CLKRLinearHashTable::~CLKRLinearHashTable



// ~CLKRHashTable ------------------------------------------------------------
// Destructor for class CLKRHashTable
//-------------------------------------------------------------------------
CLKRHashTable::~CLKRHashTable()
{
    // delete in reverse order, just like delete[].
    for (DWORD i = m_cSubTables;  i-- > 0;  )
        _FreeSubTable(m_palhtDir[i]);

    _FreeSubTableArray(m_palhtDir);

    _RemoveThisFromGlobalList();

    m_dwSignature = SIGNATURE_FREE;
    m_lkrcState = LK_UNUSABLE; // so IsUsable will fail
} // CLKRHashTable::~CLKRHashTable



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::NumSubTables
// Synopsis: 
//------------------------------------------------------------------------

LK_TABLESIZE
CLKRLinearHashTable::NumSubTables(
    DWORD&, DWORD&)
{
    LK_TABLESIZE lkts = LK_MEDIUM_TABLESIZE;

    return lkts;
} // CLKRLinearHashTable::NumSubTables



//------------------------------------------------------------------------
// Function: CLKRHashTable::NumSubTables
// Synopsis: 
//------------------------------------------------------------------------

LK_TABLESIZE
CLKRHashTable::NumSubTables(
    DWORD& rinitsize,
    DWORD& rnum_subtbls)
{
    LK_TABLESIZE lkts;
    
    // Establish the table size
    if (rinitsize == LK_SMALL_TABLESIZE
        ||  rinitsize == LK_MEDIUM_TABLESIZE
        ||  rinitsize == LK_LARGE_TABLESIZE)
    {
        lkts = static_cast<LK_TABLESIZE>(rinitsize);
    }
    else
    {
        if (rnum_subtbls != LK_DFLT_NUM_SUBTBLS)
        {
            rinitsize = (rinitsize - 1) / rnum_subtbls + 1;

            if (rinitsize <= CSmallSegment::SEGSIZE)
                lkts = LK_SMALL_TABLESIZE;
            else if (rinitsize >= CLargeSegment::SEGSIZE)
                lkts = LK_LARGE_TABLESIZE;
            else
                lkts = LK_MEDIUM_TABLESIZE;
        }
        else
        {
            lkts = LK_MEDIUM_TABLESIZE;
        }
    }

    // Choose a suitable number of subtables
    if (rnum_subtbls == LK_DFLT_NUM_SUBTBLS)
    {
        int nCPUs = NumProcessors();
        switch (lkts)
        {
        case LK_SMALL_TABLESIZE:
            rnum_subtbls = max(1, nCPUs);
            break;
        
        case LK_MEDIUM_TABLESIZE:
            rnum_subtbls = 2 * nCPUs;
            break;
        
        case LK_LARGE_TABLESIZE:
            rnum_subtbls = 4 * nCPUs;
            break;
        }
    }

    rnum_subtbls = min(MAX_SUBTABLES, rnum_subtbls);

    return lkts;
} // CLKRHashTable::NumSubTables



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_FindBucket
// Synopsis: Find a bucket, given its signature. The bucket is locked
//           before returning. Assumes table is already locked, to avoid
//           race conditions.
//------------------------------------------------------------------------

LOCK_FORCEINLINE
CBucket*
CLKRLinearHashTable::_FindBucket(
    DWORD dwSignature,
    bool  fLockForWrite) const
{
    IRTLASSERT(IsValid());
    IRTLASSERT(m_dwBktAddrMask0 > 0);
    IRTLASSERT((m_dwBktAddrMask0 & (m_dwBktAddrMask0+1)) == 0); // 00011..111
    IRTLASSERT(m_dwBktAddrMask0 == (1U << m_nLevel) - 1);
    IRTLASSERT(m_dwBktAddrMask1 == ((m_dwBktAddrMask0 << 1) | 1));
    IRTLASSERT((m_dwBktAddrMask1 & (m_dwBktAddrMask1+1)) == 0);
    IRTLASSERT(m_iExpansionIdx <= m_dwBktAddrMask0);
    IRTLASSERT(2 < m_dwSegBits  &&  m_dwSegBits < 20
               &&  m_dwSegSize == (1U << m_dwSegBits)
               &&  m_dwSegMask == (m_dwSegSize - 1));
    IRTLASSERT(IsReadLocked()  ||  IsWriteLocked());
    
    const DWORD dwBktAddr = _BucketAddress(dwSignature);
    IRTLASSERT(dwBktAddr < m_cActiveBuckets);
    
    CBucket* const pbkt = _Bucket(dwBktAddr);
    IRTLASSERT(pbkt != NULL);
    
    if (fLockForWrite)
        pbkt->WriteLock();
    else
        pbkt->ReadLock();
    
    return pbkt;
} // CLKRLinearHashTable::_FindBucket



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_IsNodeCompact
// Synopsis: validates that a node is correctly compacted
//------------------------------------------------------------------------

int
CLKRLinearHashTable::_IsNodeCompact(
    CBucket* const pbkt) const
{
    CNodeClump* pncCurr;
    CNodeClump* pncPrev;
    bool fEmpty  = pbkt->m_ncFirst.InvalidSignature(NODE_BEGIN);
    int  cErrors = fEmpty ? !pbkt->m_ncFirst.IsLastClump() : 0;

    for (pncCurr = &pbkt->m_ncFirst, pncPrev = NULL;
         pncCurr != NULL;
         pncPrev = pncCurr, pncCurr = pncCurr->m_pncNext)
    {
        int i;

        FOR_EACH_NODE(i)
        {
            if (fEmpty)
            {
                cErrors += (!pncCurr->InvalidSignature(i));
                cErrors += (!pncCurr->IsEmptyNode(i));
            }
            else if (pncCurr->InvalidSignature(i))
            {
                fEmpty = true;
                cErrors += (!pncCurr->IsEmptyNode(i));
                cErrors += (!pncCurr->IsLastClump());
            }
            else // still in non-empty portion
            {
                cErrors += (pncCurr->InvalidSignature(i));
                cErrors += (pncCurr->IsEmptyNode(i));
            }
        }
    }

    return cErrors;
} // CLKRLinearHashTable::_IsNodeCompact



//------------------------------------------------------------------------
// Function: CLKRHashTable::_SubTable
// Synopsis:
//------------------------------------------------------------------------

LOCK_FORCEINLINE
CLKRHashTable::SubTable*
CLKRHashTable::_SubTable(
    DWORD dwSignature) const
{
    IRTLASSERT(m_lkrcState == LK_SUCCESS
               &&  m_palhtDir != NULL  &&  m_cSubTables > 0);
    
    const DWORD PRIME = 1048583UL;  // used to scramble the hash sig
    DWORD       index = dwSignature;
    
    index = (((index * PRIME + 12345) >> 16)
             | ((index * 69069 + 1) & 0xffff0000));
    
    if (m_nSubTableMask >= 0)
        index &= m_nSubTableMask;
    else
        index %= m_cSubTables;

    return m_palhtDir[index];
} // CLKRHashTable::_SubTable



//------------------------------------------------------------------------
// Function: CLKRHashTable::_SubTableIndex
// Synopsis:
//------------------------------------------------------------------------

int
CLKRHashTable::_SubTableIndex(
    CLKRHashTable::SubTable* pst) const
{
    int index = -1;
    
    for (int i = 0;  i < (int) m_cSubTables;  ++i)
    {
        if (pst == m_palhtDir[i])
        {
            index = i;
            break;
        }
    }

    IRTLASSERT(index >= 0);

    return index;
} // CLKRHashTable::_SubTableIndex



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_InsertRecord
// Synopsis: Inserts a new record into the hash table. If this causes the
//           average chain length to exceed the upper bound, the table is
//           expanded by one bucket.
// Output:   LK_SUCCESS,    if the record was inserted.
//           LK_KEY_EXISTS, if the record was not inserted (because a record
//               with the same key value already exists in the table, unless
//               fOverwrite==true).
//           LK_ALLOC_FAIL, if failed to allocate the required space
//           LK_UNUSABLE,   if hash table not in usable state
//           LK_BAD_RECORD, if record is bad.
//
// TODO: honor m_fMultiKeys and allow multiple identical keys.
// This will require keeping all identical signatures contiguously
// within a bucket chain, and keeping all identical keys contigously
// within that set of contigous signatures. With a good hash function,
// there should not be identical signatures without also having
// identical keys. Also, need to modify _DeleteNode. This modification
// is needed for EqualRange and for hash_multiset and hash_multimap
// to work.
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_InsertRecord(
    const void* pvRecord,   // Pointer to the record to add to table
    DWORD       dwSignature,// hash signature
    bool        fOverwrite  // overwrite record if key already present
#ifdef LKR_STL_ITERATORS
  , Iterator*   piterResult
#endif // LKR_STL_ITERATORS
    )
{
    IRTLASSERT(IsUsable()
               &&  pvRecord != NULL
               &&  dwSignature != HASH_INVALID_SIGNATURE);

    // find the beginning of the correct bucket chain
    WriteLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

#ifdef LKR_STL_ITERATORS
    const DWORD dwBktAddr = _BucketAddress(dwSignature);
    IRTLASSERT(dwBktAddr < m_cActiveBuckets);
#endif // LKR_STL_ITERATORS
    
    CBucket* const pbkt = _FindBucket(dwSignature, true);
    IRTLASSERT(pbkt != NULL);
    IRTLASSERT(pbkt->IsWriteLocked());
    WriteUnlock();

    // check that no record with the same key value exists
    // and save a pointer to the last element on the chain
    LK_RETCODE lkrc = LK_SUCCESS;
    CNodeClump* pncFree = NULL;
    int         iFreePos = NODE_BEGIN - NODE_STEP;
    CNodeClump* pncPrev = NULL;
    bool        fUpdate = false;
    const DWORD_PTR pnKey = _ExtractKey(pvRecord);

    // walk down the entire bucket chain, looking for matching hash
    // signatures and keys
    
    CNodeClump* pncCurr = &pbkt->m_ncFirst;

    do
    {
        IRTLASSERT(pncCurr != NULL) ;

        int i;

        FOR_EACH_NODE(i)
        {
            if (pncCurr->IsEmptySlot(i))
            {
                IRTLASSERT(pncCurr->IsEmptyAndInvalid(i));
                IRTLASSERT(0 == _IsNodeCompact(pbkt));
                IRTLASSERT(pncCurr->IsLastClump());

                pncFree  = pncCurr;
                iFreePos = i;
                goto insert;
            }

            if (dwSignature == pncCurr->m_dwKeySigs[i]
                &&  (pvRecord == pncCurr->m_pvNode[i]  ||
                    _EqualKeys(pnKey,  _ExtractKey(pncCurr->m_pvNode[i]))))
            {
                if (fOverwrite)
                {
                    // If we allow overwrites, this is the slot to do it to
                    fUpdate  = true;
                    pncFree  = pncCurr;
                    iFreePos = i;
                    goto insert;
                }
                else
                {
                    // overwrites forbidden: return an error
                    lkrc = LK_KEY_EXISTS;
                    goto exit;
                }
            }
        }

        pncPrev = pncCurr;
        pncCurr = pncCurr->m_pncNext;

    } while (pncCurr != NULL);

  insert:
    if (pncFree != NULL)
    {
        pncCurr = pncFree;
        IRTLASSERT(0 <= iFreePos  &&  iFreePos < NODES_PER_CLUMP);
    }
    else
    {
        // No free slots.  Attach the new node to the end of the chain
        IRTLASSERT(iFreePos == NODE_BEGIN - NODE_STEP);
        pncCurr = _AllocateNodeClump();

        if (pncCurr == NULL)
        {
            lkrc = LK_ALLOC_FAIL;
            goto exit;
        }

        IRTLASSERT(pncPrev != NULL  &&  pncPrev->IsLastClump());
        pncPrev->m_pncNext = pncCurr;
        iFreePos = NODE_BEGIN;
    }

    // Bump the new record's reference count upwards
    _AddRefRecord(pvRecord, +1);

    if (fUpdate)
    {
        // We're overwriting an existing record.  Adjust the old record's
        // refcount downwards.  (Doing ++new, --old in this order ensures
        // that the refcount won't briefly go to zero if new and old are
        // the same record.)
        IRTLASSERT(!pncCurr->IsEmptyAndInvalid(iFreePos));
        _AddRefRecord(pncCurr->m_pvNode[iFreePos], -1);
    }
    else
    {
        IRTLASSERT(pncCurr->IsEmptyAndInvalid(iFreePos));
        InterlockedIncrement(reinterpret_cast<LONG*>(&m_cRecords));
    }

    pncCurr->m_dwKeySigs[iFreePos] = dwSignature;
    pncCurr->m_pvNode[iFreePos]    = pvRecord;

  exit:
    pbkt->WriteUnlock();

    if (lkrc == LK_SUCCESS)
    {
#ifdef LKR_STL_ITERATORS
        // Don't call _Expand() if we're putting the result into an
        // iterator, as _Expand() tends to invalidate any other
        // iterators that might be in use.
        if (piterResult != NULL)
        {
            piterResult->m_plht =         this;
            piterResult->m_pnc =          pncCurr;
            piterResult->m_dwBucketAddr = dwBktAddr;
            piterResult->m_iNode =        (short) iFreePos;

            // Add an extra reference on the record, as the one added by
            // _InsertRecord will be lost when the iterator's destructor
            // fires or its assignment operator is used
            piterResult->_AddRef(+1);
        }
        else
#endif // LKR_STL_ITERATORS
        {
            // If the average load factor has grown too high, we grow the
            // table one bucket at a time.
            while (m_cRecords > m_MaxLoad * m_cActiveBuckets)
            {
                // If _Expand returns an error code (viz. LK_ALLOC_FAIL), it
                // just means that there isn't enough spare memory to expand
                // the table by one bucket. This is likely to cause problems
                // elsewhere soon, but this hashtable has not been corrupted.
                // If the call to _AllocateNodeClump above failed, then we do
                // have a real error that must be propagated back to the caller
                // because we were unable to insert the element at all.
                if (_Expand() != LK_SUCCESS)
                    break;  // expansion failed
            }
        }
    }

    return lkrc;
} // CLKRLinearHashTable::_InsertRecord



//------------------------------------------------------------------------
// Function: CLKRHashTable::InsertRecord
// Synopsis: Thin wrapper for the corresponding method in CLKRLinearHashTable
//------------------------------------------------------------------------

LK_RETCODE
CLKRHashTable::InsertRecord(
    const void* pvRecord,
    bool fOverwrite /*=false*/)
{
    if (!IsUsable())
        return m_lkrcState;
    
    if (pvRecord == NULL)
        return LK_BAD_RECORD;
    
    LKRHASH_GLOBAL_WRITE_LOCK();    // usu. no-op

    DWORD     hash_val  = _CalcKeyHash(_ExtractKey(pvRecord));
    SubTable* const pst = _SubTable(hash_val);
    LK_RETCODE lk = pst->_InsertRecord(pvRecord, hash_val, fOverwrite);

    LKRHASH_GLOBAL_WRITE_UNLOCK();    // usu. no-op
    return lk;
} // CLKRHashTable::InsertRecord



//-------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_DeleteKey
// Synopsis: Deletes the record with the given key value from the hash
//           table (if it exists).
// Returns:  LK_SUCCESS, if record found and deleted.
//           LK_NO_SUCH_KEY, if no record with the given key value was found.
//           LK_UNUSABLE, if hash table not in usable state
//-------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_DeleteKey(
    const DWORD_PTR pnKey,      // Key value of the record, depends on key type
    DWORD           dwSignature
    )
{
    IRTLASSERT(IsUsable());

    LK_RETCODE lkrc = LK_NO_SUCH_KEY;

    // locate the beginning of the correct bucket chain
    WriteLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    CBucket* const pbkt = _FindBucket(dwSignature, true);
    IRTLASSERT(pbkt != NULL);
    IRTLASSERT(pbkt->IsWriteLocked());
    WriteUnlock();

    // scan down the bucket chain, looking for the victim
    for (CNodeClump* pncCurr = &pbkt->m_ncFirst, *pncPrev = NULL;
         pncCurr != NULL;
         pncPrev = pncCurr, pncCurr = pncCurr->m_pncNext)
    {
        int i;

        FOR_EACH_NODE(i)
        {
            if (pncCurr->IsEmptySlot(i))
            {
                IRTLASSERT(pncCurr->IsEmptyAndInvalid(i));
                IRTLASSERT(0 == _IsNodeCompact(pbkt));
                IRTLASSERT(pncCurr->IsLastClump());
                goto exit;
            }

            if (dwSignature != pncCurr->m_dwKeySigs[i])
                continue;

            const DWORD_PTR pnKey2 = _ExtractKey(pncCurr->m_pvNode[i]);

            if (pnKey == pnKey2  ||  _EqualKeys(pnKey,  pnKey2))
            {
                IRTLVERIFY(_DeleteNode(pbkt, pncCurr, pncPrev, i));

                lkrc = LK_SUCCESS;
                goto exit;
            }
        }
    }

  exit:
    pbkt->WriteUnlock();

    if (lkrc == LK_SUCCESS)
    {
        // contract the table if necessary
        double maxcontract = 1.0 / static_cast<double>(m_MaxLoad);

        for (int contractions = 0;
             m_cRecords < m_MaxLoad * m_cActiveBuckets
                 &&  m_cActiveBuckets > m_dwSegSize * MIN_DIRSIZE
                 &&  contractions < maxcontract;
             ++contractions)
        {
            // If _Contract returns an error code (viz. LK_ALLOC_FAIL), it
            // just means that there isn't enough spare memory to contract
            // the table by one bucket. This is likely to cause problems
            // elsewhere soon, but this hashtable has not been corrupted.
            if (_Contract() != LK_SUCCESS)
                break;
        }
    }

    return lkrc;
} // CLKRLinearHashTable::_DeleteKey



//------------------------------------------------------------------------
// Function: CLKRHashTable::DeleteKey
// Synopsis: Thin wrapper for the corresponding method in CLKRLinearHashTable
//------------------------------------------------------------------------

LK_RETCODE
CLKRHashTable::DeleteKey(
    const DWORD_PTR pnKey)
{
    if (!IsUsable())
        return m_lkrcState;
    
    LKRHASH_GLOBAL_WRITE_LOCK();    // usu. no-op

    DWORD     hash_val  = _CalcKeyHash(pnKey);
    SubTable* const pst = _SubTable(hash_val);
    LK_RETCODE lk       = pst->_DeleteKey(pnKey, hash_val);

    LKRHASH_GLOBAL_WRITE_UNLOCK();    // usu. no-op
    return lk;
} // CLKRHashTable::DeleteKey



//-------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_DeleteRecord
// Synopsis: Deletes the specified record from the hash table (if it
//           exists).  This is not the same thing as calling
//           DeleteKey(_ExtractKey(pvRecord)).  If _DeleteKey were called for
//           a record that doesn't exist in the table, it could delete some
//           completely unrelated record that happened to have the same key.
// Returns:  LK_SUCCESS, if record found and deleted.
//           LK_NO_SUCH_KEY, if the record is not found in the table.
//           LK_UNUSABLE, if hash table not in usable state.
//-------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_DeleteRecord(
    const void* pvRecord,   // Pointer to the record to delete from the table
    DWORD       dwSignature
    )
{
    IRTLASSERT(IsUsable()  &&  pvRecord != NULL);

    LK_RETCODE lkrc = LK_NO_SUCH_KEY;

    // locate the beginning of the correct bucket chain
    WriteLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    CBucket* const pbkt = _FindBucket(dwSignature, true);
    IRTLASSERT(pbkt != NULL);
    IRTLASSERT(pbkt->IsWriteLocked());
    WriteUnlock();

    const DWORD_PTR pnKey = _ExtractKey(pvRecord);

    UNREFERENCED_PARAMETER(pnKey);
    IRTLASSERT(dwSignature == _CalcKeyHash(pnKey));

    // scan down the bucket chain, looking for the victim
    for (CNodeClump* pncCurr = &pbkt->m_ncFirst, *pncPrev = NULL;
         pncCurr != NULL;
         pncPrev = pncCurr, pncCurr = pncCurr->m_pncNext)
    {
        int i;

        FOR_EACH_NODE(i)
        {
            if (pncCurr->IsEmptySlot(i))
            {
                IRTLASSERT(pncCurr->IsEmptyAndInvalid(i));
                IRTLASSERT(0 == _IsNodeCompact(pbkt));
                IRTLASSERT(pncCurr->IsLastClump());
                goto exit;
            }

            if (pncCurr->m_pvNode[i] == pvRecord)
            {
                IRTLASSERT(_EqualKeys(pnKey,
                                      _ExtractKey(pncCurr->m_pvNode[i])));
                IRTLASSERT(dwSignature == pncCurr->m_dwKeySigs[i]);

                IRTLVERIFY(_DeleteNode(pbkt, pncCurr, pncPrev, i));

                lkrc = LK_SUCCESS;
                goto exit;
            }
        }
    }

  exit:
    pbkt->WriteUnlock();

    if (lkrc == LK_SUCCESS)
    {
        // contract the table if necessary
        double maxcontract = 1.0 / static_cast<double>(m_MaxLoad);

        for (int contractions = 0;
             m_cRecords < m_MaxLoad * m_cActiveBuckets
                 &&  m_cActiveBuckets > m_dwSegSize * MIN_DIRSIZE
                 &&  contractions < maxcontract;
             ++contractions)
        {
            // If _Contract returns an error code (viz. LK_ALLOC_FAIL), it
            // just means that there isn't enough spare memory to contract
            // the table by one bucket. This is likely to cause problems
            // elsewhere soon, but this hashtable has not been corrupted.
            if (_Contract() != LK_SUCCESS)
                break;
        }
    }

    return lkrc;
} // CLKRLinearHashTable::_DeleteRecord



//------------------------------------------------------------------------
// Function: CLKRHashTable::DeleteRecord
// Synopsis: Thin wrapper for the corresponding method in CLKRLinearHashTable
//------------------------------------------------------------------------

LK_RETCODE
CLKRHashTable::DeleteRecord(
    const void* pvRecord)
{
    if (!IsUsable())
        return m_lkrcState;
    
    if (pvRecord == NULL)
        return LK_BAD_RECORD;
    
    LKRHASH_GLOBAL_WRITE_LOCK();    // usu. no-op

    DWORD     hash_val  = _CalcKeyHash(_ExtractKey(pvRecord));
    SubTable* const pst = _SubTable(hash_val);
    LK_RETCODE lk       = pst->_DeleteRecord(pvRecord, hash_val);

    LKRHASH_GLOBAL_WRITE_UNLOCK();    // usu. no-op
    return lk;
} // CLKRHashTable::DeleteRecord



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_DeleteNode
// Synopsis: Deletes a node; removes the node clump if empty
// Returns:  true if successful
//
// TODO: Is the rpncPrev parameter really necessary?
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::_DeleteNode(
    CBucket*     pbkt,      // bucket chain containing node
    CNodeClump*& rpnc,      // actual node
    CNodeClump*& rpncPrev,  // predecessor of actual node, or NULL
    int&         riNode)    // index within node
{
    IRTLASSERT(pbkt != NULL  &&  pbkt->IsWriteLocked());
    IRTLASSERT(rpnc != NULL);
    IRTLASSERT(rpncPrev == NULL  ||  rpncPrev->m_pncNext == rpnc);
    IRTLASSERT(0 <= riNode  &&  riNode < NODES_PER_CLUMP);
    IRTLASSERT(!rpnc->IsEmptyAndInvalid(riNode));

#ifdef IRTLDEBUG
    // Check that the node clump really does belong to the bucket
    CNodeClump* pnc1 = &pbkt->m_ncFirst;

    while (pnc1 != NULL  &&  pnc1 != rpnc)
         pnc1 = pnc1->m_pncNext;

    IRTLASSERT(pnc1 == rpnc);
#endif // IRTLDEBUG

    // Release the reference to the record
    _AddRefRecord(rpnc->m_pvNode[riNode], -1);

    IRTLASSERT(0 == _IsNodeCompact(pbkt));

    // TODO: honor m_fMultiKeys

    // Compact the nodeclump by moving the very last node back to the
    // newly freed slot
    CNodeClump* pnc2   = rpnc;
    int         iNode2 = riNode;

    // Find the last nodeclump in the chain
    while (!pnc2->IsLastClump())
    {
         pnc2 = pnc2->m_pncNext;
         iNode2 = NODE_BEGIN;
    }

    IRTLASSERT(0 <= iNode2  &&  iNode2 < NODES_PER_CLUMP);
    IRTLASSERT(!pnc2->IsEmptyAndInvalid(iNode2));

    // Find the first empty slot in the nodeclump
    while (iNode2 != NODE_END  &&  !pnc2->IsEmptySlot(iNode2))
    {
        iNode2 += NODE_STEP;
    }

    // Back up to last non-empty slot
    iNode2 -= NODE_STEP;
    IRTLASSERT(0 <= iNode2  &&  iNode2 < NODES_PER_CLUMP
               &&  !pnc2->IsEmptyAndInvalid(iNode2));
    IRTLASSERT(iNode2+NODE_STEP == NODE_END
               ||  pnc2->IsEmptyAndInvalid(iNode2+NODE_STEP));

#ifdef IRTLDEBUG
    // Check that all the remaining nodes are empty
    IRTLASSERT(pnc2->IsLastClump());
    for (int iNode3 = iNode2 + NODE_STEP;
         iNode3 != NODE_END;
         iNode3 += NODE_STEP)
    {
        IRTLASSERT(pnc2->IsEmptyAndInvalid(iNode3));
    }
#endif // IRTLDEBUG

    // Move the last node's data back to the current node
    rpnc->m_pvNode[riNode]    = pnc2->m_pvNode[iNode2];
    rpnc->m_dwKeySigs[riNode] = pnc2->m_dwKeySigs[iNode2];

    // Blank the old last node.
    // Correct even if (rpnc, riNode) == (pnc2, iNode2).
    pnc2->m_pvNode[iNode2]    = NULL;
    pnc2->m_dwKeySigs[iNode2] = HASH_INVALID_SIGNATURE;

    IRTLASSERT(0 == _IsNodeCompact(pbkt));

    // Back up riNode by one, so that the next iteration of the loop
    // calling _DeleteNode will end up pointing to the same spot.
    if (riNode != NODE_BEGIN)
    {
        riNode -= NODE_STEP;
    }
    else
    {
        // rewind rpnc and rpncPrev to previous node
        if (rpnc == &pbkt->m_ncFirst)
        {
            riNode = NODE_BEGIN - NODE_STEP;
        }
        else
        {
            riNode = NODE_END;
            rpnc = rpncPrev;
            if (rpnc == &pbkt->m_ncFirst)
            {
                rpncPrev = NULL;
            }
            else
            {
                for (rpncPrev = &pbkt->m_ncFirst;
                     rpncPrev->m_pncNext != rpnc;
                     rpncPrev = rpncPrev->m_pncNext)
                {}
            }
        }
    }

    // Is the last node clump now completely empty?  Delete, if possible
    if (iNode2 == NODE_BEGIN  &&  pnc2 != &pbkt->m_ncFirst)
    {
        // Find preceding nodeclump
        CNodeClump* pnc3 = &pbkt->m_ncFirst;
        while (pnc3->m_pncNext != pnc2)
        {
            pnc3 = pnc3->m_pncNext;
            IRTLASSERT(pnc3 != NULL);
        }

        pnc3->m_pncNext = NULL;
#ifdef IRTLDEBUG
        pnc2->m_pncNext = NULL; // or dtor will ASSERT
#endif // IRTLDEBUG
        _FreeNodeClump(pnc2);
    }

    IRTLASSERT(rpncPrev == NULL  ||  rpncPrev->m_pncNext == rpnc);

    InterlockedDecrement(reinterpret_cast<LONG*>(&m_cRecords));

    return true;
} // CLKRLinearHashTable::_DeleteNode



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_FindKey
// Synopsis: Locate the record associated with the given key value.
// Returns:  Pointer to the record, if it is found.
//           NULL, if the record is not found.
// Returns:  LK_SUCCESS, if record found (record is returned in *ppvRecord)
//           LK_BAD_RECORD, if ppvRecord is invalid
//           LK_NO_SUCH_KEY, if no record with the given key value was found.
//           LK_UNUSABLE, if hash table not in usable state
// Note:     the record is AddRef'd.  You must decrement the reference count
//           when you are finished with the record (if you're implementing
//           refcounting semantics).
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_FindKey(
    const DWORD_PTR  pnKey,  // Key value of the record, depends on key type
    DWORD        dwSignature,// hash signature
    const void** ppvRecord   // resultant record
#ifdef LKR_STL_ITERATORS
  , Iterator*   piterResult
#endif // LKR_STL_ITERATORS
    ) const
{
    IRTLASSERT(IsUsable()  &&  ppvRecord != NULL);

    *ppvRecord = NULL;
    LK_RETCODE lkrc = LK_NO_SUCH_KEY;
    int iNode = NODE_BEGIN - NODE_STEP;

    // locate the beginning of the correct bucket chain
    bool fReadLocked = _ReadOrWriteLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

#ifdef LKR_STL_ITERATORS
    const DWORD dwBktAddr = _BucketAddress(dwSignature);
    IRTLASSERT(dwBktAddr < m_cActiveBuckets);
#endif // LKR_STL_ITERATORS
    
    CBucket* const pbkt = _FindBucket(dwSignature, false);
    IRTLASSERT(pbkt != NULL);
    IRTLASSERT(pbkt->IsReadLocked());
    _ReadOrWriteUnlock(fReadLocked);

    // walk down the bucket chain
	CNodeClump* pncCurr;
    for (pncCurr = &pbkt->m_ncFirst;
         pncCurr != NULL;
         pncCurr = pncCurr->m_pncNext)
    {
        FOR_EACH_NODE(iNode)
        {
            if (pncCurr->IsEmptySlot(iNode))
            {
                IRTLASSERT(pncCurr->IsEmptyAndInvalid(iNode));
                IRTLASSERT(0 == _IsNodeCompact(pbkt));
                IRTLASSERT(pncCurr->IsLastClump());
                goto exit;
            }

            if (dwSignature != pncCurr->m_dwKeySigs[iNode])
                continue;

            const DWORD_PTR pnKey2 = _ExtractKey(pncCurr->m_pvNode[iNode]);

            if (pnKey == pnKey2  ||  _EqualKeys(pnKey,  pnKey2))
            {
                    *ppvRecord = pncCurr->m_pvNode[iNode];
                    lkrc = LK_SUCCESS;

                    // bump the reference count before handing the record
                    // back to the user.  The user should decrement the
                    // reference count when finished with this record.
                    _AddRefRecord(*ppvRecord, +1);
                    goto exit;
            }
        }
    }

  exit:
    pbkt->ReadUnlock();

#ifdef LKR_STL_ITERATORS
    if (piterResult != NULL  &&  lkrc == LK_SUCCESS)
    {
        piterResult->m_plht =         const_cast<CLKRLinearHashTable*>(this);
        piterResult->m_pnc =          pncCurr;
        piterResult->m_dwBucketAddr = dwBktAddr;
        piterResult->m_iNode =        (short) iNode;
    }
#endif // LKR_STL_ITERATORS

    return lkrc;
} // CLKRLinearHashTable::_FindKey



//------------------------------------------------------------------------
// Function: CLKRHashTable::FindKey
// Synopsis: Thin wrapper for the corresponding method in CLKRLinearHashTable
//------------------------------------------------------------------------

LK_RETCODE
CLKRHashTable::FindKey(
    const DWORD_PTR pnKey,
    const void**    ppvRecord) const
{
    if (!IsUsable())
        return m_lkrcState;
    
    if (ppvRecord == NULL)
        return LK_BAD_RECORD;
    
    LKRHASH_GLOBAL_READ_LOCK();    // usu. no-op
    DWORD     hash_val   = _CalcKeyHash(pnKey);
    SubTable* const pst  = _SubTable(hash_val);
    LK_RETCODE lkrc      = pst->_FindKey(pnKey, hash_val, ppvRecord);
    LKRHASH_GLOBAL_READ_UNLOCK();    // usu. no-op

    return lkrc;
} // CLKRHashTable::FindKey



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_FindRecord
// Synopsis: Sees if the record is contained in the table
// Returns:  Pointer to the record, if it is found.
//           NULL, if the record is not found.
// Returns:  LK_SUCCESS, if record found
//           LK_BAD_RECORD, if pvRecord is invalid
//           LK_NO_SUCH_KEY, if the record was not found in the table
//           LK_UNUSABLE, if hash table not in usable state
// Note:     The record is *not* AddRef'd.
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_FindRecord(
    const void* pvRecord,    // Pointer to the record to find in the table
    DWORD       dwSignature  // hash signature
    ) const
{
    IRTLASSERT(IsUsable()  &&  pvRecord != NULL);

    LK_RETCODE lkrc = LK_NO_SUCH_KEY;

    // locate the beginning of the correct bucket chain
    bool fReadLocked = _ReadOrWriteLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    CBucket* const pbkt = _FindBucket(dwSignature, false);
    IRTLASSERT(pbkt != NULL);
    IRTLASSERT(pbkt->IsReadLocked());
    _ReadOrWriteUnlock(fReadLocked);

    const DWORD_PTR pnKey = _ExtractKey(pvRecord);

    UNREFERENCED_PARAMETER(pnKey);
    IRTLASSERT(dwSignature == _CalcKeyHash(pnKey));

    // walk down the bucket chain
    for (CNodeClump* pncCurr = &pbkt->m_ncFirst;
         pncCurr != NULL;
         pncCurr = pncCurr->m_pncNext)
    {
        int i;

        FOR_EACH_NODE(i)
        {
            if (pncCurr->IsEmptySlot(i))
            {
                IRTLASSERT(pncCurr->IsEmptyAndInvalid(i));
                IRTLASSERT(0 == _IsNodeCompact(pbkt));
                IRTLASSERT(pncCurr->IsLastClump());
                goto exit;
            }

            if (pncCurr->m_pvNode[i] == pvRecord)
            {
                IRTLASSERT(dwSignature == pncCurr->m_dwKeySigs[i]);
                IRTLASSERT(_EqualKeys(pnKey,
                                      _ExtractKey(pncCurr->m_pvNode[i])));
                lkrc = LK_SUCCESS;

                goto exit;
            }
        }
    }

  exit:
    pbkt->ReadUnlock();
    return lkrc;
} // CLKRLinearHashTable::_FindRecord



//------------------------------------------------------------------------
// Function: CLKRHashTable::FindRecord
// Synopsis: Thin wrapper for the corresponding method in CLKRLinearHashTable
//------------------------------------------------------------------------

LK_RETCODE
CLKRHashTable::FindRecord(
    const void* pvRecord) const
{
    if (!IsUsable())
        return m_lkrcState;
    
    if (pvRecord == NULL)
        return LK_BAD_RECORD;
    
    LKRHASH_GLOBAL_READ_LOCK();    // usu. no-op
    DWORD     hash_val   = _CalcKeyHash(_ExtractKey(pvRecord));
    SubTable* const pst  = _SubTable(hash_val);
    LK_RETCODE lkrc      = pst->_FindRecord(pvRecord, hash_val);
    LKRHASH_GLOBAL_READ_UNLOCK();    // usu. no-op

    return lkrc;
} // CLKRHashTable::FindRecord



#ifdef LKR_APPLY_IF

//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::Apply
// Synopsis:
// Returns:
//------------------------------------------------------------------------

DWORD
CLKRLinearHashTable::Apply(
    PFnRecordAction pfnAction,
    void*           pvState,
    LK_LOCKTYPE    lkl)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    LK_PREDICATE lkp = LKP_PERFORM;
    if (lkl == LKL_WRITELOCK)
        WriteLock();
    else
        ReadLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    DWORD dw = _Apply(pfnAction, pvState, lkl, lkp);
    if (lkl == LKL_WRITELOCK)
        WriteUnlock();
    else
        ReadUnlock();

    return dw;
} // CLKRLinearHashTable::Apply



//------------------------------------------------------------------------
// Function: CLKRHashTable::Apply
// Synopsis:
// Returns:
//------------------------------------------------------------------------

DWORD
CLKRHashTable::Apply(
    PFnRecordAction pfnAction,
    void*           pvState,
    LK_LOCKTYPE    lkl)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    DWORD dw = 0;
    LK_PREDICATE lkp = LKP_PERFORM;

    if (lkl == LKL_WRITELOCK)
        WriteLock();
    else
        ReadLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    if (IsValid())
    {
        for (DWORD i = 0;  i < m_cSubTables;  i++)
        {
            dw += m_palhtDir[i]->_Apply(pfnAction, pvState, lkl, lkp);
            if (lkp == LKP_ABORT  ||  lkp == LKP_PERFORM_STOP
                ||  lkp == LKP_DELETE_STOP)
                break;
        }
    }

    if (lkl == LKL_WRITELOCK)
        WriteUnlock();
    else
        ReadUnlock();

    return dw;
} // CLKRHashTable::Apply



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::ApplyIf
// Synopsis:
// Returns:
//------------------------------------------------------------------------

DWORD
CLKRLinearHashTable::ApplyIf(
    PFnRecordPred   pfnPredicate,
    PFnRecordAction pfnAction,
    void*           pvState,
    LK_LOCKTYPE    lkl)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    DWORD dw = 0;
    LK_PREDICATE lkp = LKP_PERFORM;

    if (lkl == LKL_WRITELOCK)
        WriteLock();
    else
        ReadLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    if (IsValid())
    {
        dw = _ApplyIf(pfnPredicate, pfnAction, pvState, lkl, lkp);
    }

    if (lkl == LKL_WRITELOCK)
        WriteUnlock();
    else
        ReadUnlock();
    return dw;
} // CLKRLinearHashTable::ApplyIf



//------------------------------------------------------------------------
// Function: CLKRHashTable::ApplyIf
// Synopsis:
// Returns:
//------------------------------------------------------------------------

DWORD
CLKRHashTable::ApplyIf(
    PFnRecordPred   pfnPredicate,
    PFnRecordAction pfnAction,
    void*           pvState,
    LK_LOCKTYPE    lkl)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    DWORD dw = 0;
    LK_PREDICATE lkp = LKP_PERFORM;

    if (lkl == LKL_WRITELOCK)
        WriteLock();
    else
        ReadLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    if (IsValid())
    {
        for (DWORD i = 0;  i < m_cSubTables;  i++)
        {
            dw += m_palhtDir[i]->_ApplyIf(pfnPredicate, pfnAction,
                                          pvState, lkl, lkp);
            if (lkp == LKP_ABORT  ||  lkp == LKP_PERFORM_STOP
                ||  lkp == LKP_DELETE_STOP)
                break;
        }
    }

    if (lkl == LKL_WRITELOCK)
        WriteUnlock();
    else
        ReadUnlock();

    return dw;
} // CLKRHashTable::ApplyIf



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::DeleteIf
// Synopsis:
// Returns:
//------------------------------------------------------------------------

DWORD
CLKRLinearHashTable::DeleteIf(
    PFnRecordPred pfnPredicate,
    void*         pvState)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    DWORD dw = 0;
    LK_PREDICATE lkp = LKP_PERFORM;

    WriteLock();
    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());
    if (IsValid())
        dw = _DeleteIf(pfnPredicate, pvState, lkp);
    WriteUnlock();

    return dw;
} // CLKRLinearHashTable::DeleteIf



//------------------------------------------------------------------------
// Function: CLKRHashTable::DeleteIf
// Synopsis:
// Returns:
//------------------------------------------------------------------------

DWORD
CLKRHashTable::DeleteIf(
    PFnRecordPred pfnPredicate,
    void*         pvState)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    DWORD dw = 0;
    LK_PREDICATE lkp = LKP_PERFORM;

    WriteLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    if (IsValid())
    {
        for (DWORD i = 0;  i < m_cSubTables;  i++)
        {
            dw += m_palhtDir[i]->_DeleteIf(pfnPredicate, pvState, lkp);
            if (lkp == LKP_ABORT  ||  lkp == LKP_PERFORM_STOP
                ||  lkp == LKP_DELETE_STOP)
                break;
        }
    }

    WriteUnlock();

    return dw;
} // CLKRHashTable::DeleteIf



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_Apply
// Synopsis:
// Returns:
//------------------------------------------------------------------------

DWORD
CLKRLinearHashTable::_Apply(
    PFnRecordAction pfnAction,
    void*           pvState,
    LK_LOCKTYPE    lkl,
    LK_PREDICATE&  rlkp)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    IRTLASSERT(lkl == LKL_WRITELOCK  ?  IsWriteLocked()  :  IsReadLocked());
    return _ApplyIf(_PredTrue, pfnAction, pvState, lkl, rlkp);
} // CLKRLinearHashTable::_Apply



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_ApplyIf
// Synopsis:
// Returns:  Number of successful actions
//------------------------------------------------------------------------

DWORD
CLKRLinearHashTable::_ApplyIf(
    PFnRecordPred   pfnPredicate,
    PFnRecordAction pfnAction,
    void*           pvState,
    LK_LOCKTYPE    lkl,
    LK_PREDICATE&  rlkp)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    IRTLASSERT(lkl == LKL_WRITELOCK  ?  IsWriteLocked()  :  IsReadLocked());
    IRTLASSERT(pfnPredicate != NULL  &&  pfnAction != NULL);

    if ((lkl == LKL_WRITELOCK  ?  !IsWriteLocked()  :  !IsReadLocked())
            ||  pfnPredicate == NULL  ||  pfnAction == NULL)
        return 0;

    DWORD cActions = 0;

    for (DWORD iBkt = 0;  iBkt < m_cActiveBuckets;  ++iBkt)
    {
        CBucket* const pbkt = _Bucket(iBkt);
        IRTLASSERT(pbkt != NULL);

        if (lkl == LKL_WRITELOCK)
            pbkt->WriteLock();
        else
            pbkt->ReadLock();

        for (CNodeClump* pncCurr = &pbkt->m_ncFirst, *pncPrev = NULL;
             pncCurr != NULL;
             pncPrev = pncCurr, pncCurr = pncCurr->m_pncNext)
        {
            int i;

            FOR_EACH_NODE(i)
            {
                if (pncCurr->IsEmptySlot(i))
                {
                    IRTLASSERT(pncCurr->IsEmptyAndInvalid(i));
                    IRTLASSERT(0 == _IsNodeCompact(pbkt));
                    IRTLASSERT(pncCurr->IsLastClump());
                    goto unlock;
                }
                else
                {
                    rlkp = (*pfnPredicate)(pncCurr->m_pvNode[i], pvState);

                    switch (rlkp)
                    {
                    case LKP_ABORT:
                        if (lkl == LKL_WRITELOCK)
                            pbkt->WriteUnlock();
                        else
                            pbkt->ReadUnlock();
                        return cActions;
                        break;

                    case LKP_NO_ACTION:
                        // nothing to do
                        break;

                    case LKP_DELETE:
                    case LKP_DELETE_STOP:
                        if (lkl != LKL_WRITELOCK)
                        {
                            pbkt->ReadUnlock();
                            return cActions;
                        }

                        // fall through

                    case LKP_PERFORM:
                    case LKP_PERFORM_STOP:
                    {
                        LK_ACTION lka;

                        if (rlkp == LKP_DELETE  ||  rlkp == LKP_DELETE_STOP)
                        {
                            IRTLVERIFY(_DeleteNode(pbkt, pncCurr, pncPrev, i));

                            ++cActions;
                            lka = LKA_SUCCEEDED;
                        }
                        else
                        {
                            lka = (*pfnAction)(pncCurr->m_pvNode[i], pvState);

                            switch (lka)
                            {
                            case LKA_ABORT:
                                if (lkl == LKL_WRITELOCK)
                                    pbkt->WriteUnlock();
                                else
                                    pbkt->ReadUnlock();
                                return cActions;
                                
                            case LKA_FAILED:
                                // nothing to do
                                break;
                                
                            case LKA_SUCCEEDED:
                                ++cActions;
                                break;
                                
                            default:
                                IRTLASSERT(! "Unknown LK_ACTION in ApplyIf");
                                break;
                            }
                        }

                        if (rlkp == LKP_PERFORM_STOP
                            ||  rlkp == LKP_DELETE_STOP)
                        {
                            if (lkl == LKL_WRITELOCK)
                                pbkt->WriteUnlock();
                            else
                                pbkt->ReadUnlock();
                            return cActions;
                        }

                        break;
                    }

                    default:
                        IRTLASSERT(! "Unknown LK_PREDICATE in ApplyIf");
                        break;
                    }
                }
            }
        }

      unlock:
        if (lkl == LKL_WRITELOCK)
            pbkt->WriteUnlock();
        else
            pbkt->ReadUnlock();
    }

    return cActions;
} // CLKRLinearHashTable::_ApplyIf



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_DeleteIf
// Synopsis: Deletes all records that match the predicate
// Returns:  Count of successful deletions
//------------------------------------------------------------------------

DWORD
CLKRLinearHashTable::_DeleteIf(
    PFnRecordPred  pfnPredicate,
    void*          pvState,
    LK_PREDICATE& rlkp)
{
    if (!IsUsable())
        return static_cast<DWORD>(LK_UNUSABLE);

    IRTLASSERT(IsWriteLocked());
    IRTLASSERT(pfnPredicate != NULL);

    if (!IsWriteLocked()  ||  pfnPredicate == NULL)
        return 0;

    DWORD cActions = 0;

    for (DWORD iBkt = 0;  iBkt < m_cActiveBuckets;  ++iBkt)
    {
        CBucket* const pbkt = _Bucket(iBkt);
        IRTLASSERT(pbkt != NULL);
        pbkt->WriteLock();

        for (CNodeClump* pncCurr = &pbkt->m_ncFirst, *pncPrev = NULL;
             pncCurr != NULL;
             pncPrev = pncCurr, pncCurr = pncCurr->m_pncNext)
        {
            int i;

            FOR_EACH_NODE(i)
            {
                if (pncCurr->IsEmptySlot(i))
                {
                    IRTLASSERT(pncCurr->IsEmptyAndInvalid(i));
                    IRTLASSERT(0 == _IsNodeCompact(pbkt));
                    IRTLASSERT(pncCurr->IsLastClump());
                    goto unlock;
                }
                else
                {
                    rlkp = (*pfnPredicate)(pncCurr->m_pvNode[i], pvState);

                    switch (rlkp)
                    {
                    case LKP_ABORT:
                        pbkt->WriteUnlock();
                        return cActions;
                        break;

                    case LKP_NO_ACTION:
                        // nothing to do
                        break;

                    case LKP_PERFORM:
                    case LKP_PERFORM_STOP:
                    case LKP_DELETE:
                    case LKP_DELETE_STOP:
                    {
                        IRTLVERIFY(_DeleteNode(pbkt, pncCurr, pncPrev, i));

                        ++cActions;

                        if (rlkp == LKP_PERFORM_STOP
                            ||  rlkp == LKP_DELETE_STOP)
                        {
                            pbkt->WriteUnlock();
                            return cActions;
                        }

                        break;
                    }

                    default:
                        IRTLASSERT(! "Unknown LK_PREDICATE in DeleteIf");
                        break;
                    }
                }
            }
        }

      unlock:
        pbkt->WriteUnlock();
    }

    return cActions;
} // CLKRLinearHashTable::_DeleteIf

#endif // LKR_APPLY_IF



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::CheckTable
// Synopsis: Verify that all records are in the right place and can be located.
// Returns:   0 => hash table is consistent
//           >0 => that many misplaced records
//           <0 => otherwise invalid
//------------------------------------------------------------------------

int
CLKRLinearHashTable::CheckTable() const
{
    if (!IsUsable())
        return LK_UNUSABLE;

    bool fReadLocked = _ReadOrWriteLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());

    if (!IsValid())
    {
        _ReadOrWriteUnlock(fReadLocked);
        return LK_UNUSABLE;
    }

    int       cMisplaced = 0;
    DWORD     cRecords = 0;
    int       retcode = 0;

    // Check every bucket
    for (DWORD i = 0;  i < m_cActiveBuckets;  i++)
    {
        CBucket* const pbkt = _Bucket(i);

        IRTLASSERT(pbkt != NULL);
        retcode += !(pbkt != NULL);

        pbkt->ReadLock();

        IRTLASSERT(0 == _IsNodeCompact(pbkt));

        // Walk the bucket chain
        for (CNodeClump* pncCurr = &pbkt->m_ncFirst, *pncPrev = NULL;
             pncCurr != NULL;
             pncPrev = pncCurr, pncCurr = pncCurr->m_pncNext)
        {
            int j;

            FOR_EACH_NODE(j)
            {
                if (pncCurr->IsEmptySlot(j))
                {
                    IRTLASSERT(pncCurr->IsLastClump());
                    retcode += !(pncCurr->IsLastClump());

                    for (int k = j;  k != NODE_END;  k += NODE_STEP)
                    {
                        IRTLASSERT(pncCurr->IsEmptyNode(k));
                        retcode += !pncCurr->IsEmptyNode(k);
                        IRTLASSERT(pncCurr->InvalidSignature(k));
                        retcode += !pncCurr->InvalidSignature(k);
                    }
                    break;
                }

                if (!pncCurr->IsEmptySlot(j))
                {
                    ++cRecords;

                    const DWORD_PTR pnKey = _ExtractKey(pncCurr->m_pvNode[j]);

                    DWORD dwSignature = _CalcKeyHash(pnKey);
                    IRTLASSERT(dwSignature != HASH_INVALID_SIGNATURE);
                    retcode += !(dwSignature != HASH_INVALID_SIGNATURE);
                    IRTLASSERT(dwSignature == pncCurr->m_dwKeySigs[j]);
                    retcode += !(dwSignature == pncCurr->m_dwKeySigs[j]);

                    DWORD address = _BucketAddress(dwSignature);
                    IRTLASSERT(address == i);
                    retcode += !(address == i);

                    if (address != i || dwSignature != pncCurr->m_dwKeySigs[j])
                        cMisplaced++;
                }
                else // pncCurr->IsEmptySlot(j)
                {
                    IRTLASSERT(pncCurr->IsEmptyAndInvalid(j));
                    retcode += !pncCurr->IsEmptyAndInvalid(j);
                }
            }
            if (pncPrev != NULL)
            {
                IRTLASSERT(pncPrev->m_pncNext == pncCurr);
                retcode += !(pncPrev->m_pncNext == pncCurr);
            }
        }
        pbkt->ReadUnlock();
    }

    if (cRecords != m_cRecords)
        ++retcode;

    IRTLASSERT(cRecords == m_cRecords);
    retcode += !(cRecords == m_cRecords);

    if (cMisplaced > 0)
        retcode = cMisplaced;

    IRTLASSERT(cMisplaced == 0);
    retcode += !(cMisplaced == 0);

    _ReadOrWriteUnlock(fReadLocked);

    return retcode;
} // CLKRLinearHashTable::CheckTable



//------------------------------------------------------------------------
// Function: CLKRHashTable::CheckTable
// Synopsis: Verify that all records are in the right place and can be located.
// Returns:   0 => hash table is consistent
//           >0 => that many misplaced records
//           <0 => otherwise invalid
//------------------------------------------------------------------------
int
CLKRHashTable::CheckTable() const
{
    if (!IsUsable())
        return LK_UNUSABLE;

    int retcode = 0;

    for (DWORD i = 0;  i < m_cSubTables;  i++)
        retcode += m_palhtDir[i]->CheckTable();

    return retcode;
} // CLKRHashTable::CheckTable



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_Clear
// Synopsis: Remove all data from the table
//------------------------------------------------------------------------

void
CLKRLinearHashTable::_Clear(
    bool fShrinkDirectory)  // Shrink to min size but don't destroy entirely?
{
    if (!IsUsable())
        return;

    IRTLASSERT(IsWriteLocked());

    if (0 == m_cRecords)
        return;

#ifdef IRTLDEBUG
    DWORD cDeleted = 0;
    DWORD cOldRecords = m_cRecords;
#endif // IRTLDEBUG

    for (DWORD iBkt = 0;  iBkt < m_cActiveBuckets;  ++iBkt)
    {
        CBucket* const pbkt = _Bucket(iBkt);
        IRTLASSERT(pbkt != NULL);
        pbkt->WriteLock();

        IRTLASSERT(0 == _IsNodeCompact(pbkt));

        for (CNodeClump* pncCurr = &pbkt->m_ncFirst, *pncPrev = NULL;
             pncCurr != NULL;
             )
        {
            int i;

            FOR_EACH_NODE(i)
            {

                if (pncCurr->IsEmptySlot(i))
                {
                    IRTLASSERT(pncCurr->IsEmptyAndInvalid(i));
                    IRTLASSERT(pncCurr->IsLastClump());
                    break;
                }
                else
                {
                    _AddRefRecord(pncCurr->m_pvNode[i], -1);
                    pncCurr->m_pvNode[i]    = NULL;
                    pncCurr->m_dwKeySigs[i] = HASH_INVALID_SIGNATURE;
                    m_cRecords--;

#ifdef IRTLDEBUG
                    ++cDeleted;
#endif // IRTLDEBUG
                }
            } // for (i ...

            pncPrev = pncCurr;
            pncCurr = pncCurr->m_pncNext;
            pncPrev->m_pncNext = NULL;

            if (pncPrev != &pbkt->m_ncFirst)
                _FreeNodeClump(pncPrev);
        } // for (pncCurr ...

        pbkt->WriteUnlock();
    } // for (iBkt ...

    IRTLASSERT(m_cRecords == 0  &&  cDeleted == cOldRecords);

    // delete all segments
    for (DWORD iSeg = 0;  iSeg < m_cActiveBuckets;  iSeg += m_dwSegSize)
    {
        _FreeSegment(_Segment(iSeg));
        _Segment(iSeg) = NULL;
    }

    _FreeSegmentDirectory();
    m_nLevel = m_cActiveBuckets = m_iExpansionIdx = 0;
    m_dwBktAddrMask0 = 1;
    m_dwBktAddrMask1 = (m_dwBktAddrMask0 << 1) | 1;

    // set directory of segments to minimum size
    if (fShrinkDirectory)
    {
        DWORD cInitialBuckets = 0;

        if (LK_SMALL_TABLESIZE == m_lkts)
            cInitialBuckets = CSmallSegment::INITSIZE;
        else if (LK_MEDIUM_TABLESIZE == m_lkts)
            cInitialBuckets = CMediumSegment::INITSIZE;
        else if (LK_LARGE_TABLESIZE == m_lkts)
            cInitialBuckets = CLargeSegment::INITSIZE;
        else
            IRTLASSERT(! "Unknown LK_TABLESIZE");

        _SetSegVars(m_lkts, cInitialBuckets);
    }
} // CLKRLinearHashTable::_Clear



//------------------------------------------------------------------------
// Function: CLKRHashTable::Clear
// Synopsis: Remove all data from the table
//------------------------------------------------------------------------

void
CLKRHashTable::Clear()
{
    WriteLock();
    for (DWORD i = 0;  i < m_cSubTables;  i++)
        m_palhtDir[i]->_Clear(true);
    WriteUnlock();
} // CLKRHashTable::Clear



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::GetStatistics
// Synopsis: Gather statistics about the table
//------------------------------------------------------------------------

CLKRHashTableStats
CLKRLinearHashTable::GetStatistics() const
{
    CLKRHashTableStats stats;

    if (!IsUsable())
        return stats;

    if (m_paDirSegs != NULL)
    {
        stats.RecordCount   = m_cRecords;
        stats.TableSize     = m_cActiveBuckets;
        stats.SplitFactor   = static_cast<double>(m_iExpansionIdx)
                              / (1ui64 << m_nLevel);
        stats.DirectorySize = m_cDirSegs;
        stats.NodeClumpSize = NODES_PER_CLUMP;
        stats.CBucketSize   = sizeof(CBucket);

#ifdef LOCK_INSTRUMENTATION
        stats.m_alsBucketsAvg.m_nContentions     = 0;
        stats.m_alsBucketsAvg.m_nSleeps          = 0;
        stats.m_alsBucketsAvg.m_nContentionSpins = 0;
        stats.m_alsBucketsAvg.m_nAverageSpins    = 0;
        stats.m_alsBucketsAvg.m_nReadLocks       = 0;
        stats.m_alsBucketsAvg.m_nWriteLocks      = 0;
        stats.m_alsBucketsAvg.m_nItems           = 0;
#endif // LOCK_INSTRUMENTATION

        int empty = 0;
        int totacc = 0;
        int low_count = 0;
        int high_count = 0;
        int max_length = 0;

        for (DWORD i = 0;  i < m_cActiveBuckets;  i++)
        {
            int acc = 0;

            for (CNodeClump* pncCurr = &_Bucket(i)->m_ncFirst;
                 pncCurr != NULL;
                 pncCurr = pncCurr->m_pncNext)
            {
                int j;

                FOR_EACH_NODE(j)
                {
                    if (!pncCurr->IsEmptySlot(j))
                    {
                        acc++;
                        totacc += acc;
                        int iBucketIndex = stats.BucketIndex(acc);
                        ++stats.m_aBucketLenHistogram[iBucketIndex];
                    }
                }
            }

#ifdef LOCK_INSTRUMENTATION
            CLockStatistics ls = _Bucket(i)->LockStats();

            stats.m_alsBucketsAvg.m_nContentions     += ls.m_nContentions;
            stats.m_alsBucketsAvg.m_nSleeps          += ls.m_nSleeps;
            stats.m_alsBucketsAvg.m_nContentionSpins += ls.m_nContentionSpins;
            stats.m_alsBucketsAvg.m_nAverageSpins    += ls.m_nAverageSpins;
            stats.m_alsBucketsAvg.m_nReadLocks       += ls.m_nReadLocks;
            stats.m_alsBucketsAvg.m_nWriteLocks      += ls.m_nWriteLocks;
            stats.m_alsBucketsAvg.m_nItems           ++;
#endif // LOCK_INSTRUMENTATION

            max_length = max(max_length, acc);
            if (acc == 0)
                empty++;

            if (_H0(i) < m_iExpansionIdx)
            {
                low_count += acc;
            }
            else
            {
                high_count += acc;
            }
        }

        stats.LongestChain = max_length;
        stats.EmptySlots   = empty;

        if (m_cActiveBuckets > 0)
        {
            if (m_cRecords > 0)
            {
                double x=static_cast<double>(m_iExpansionIdx) /(1ui64 << m_nLevel);
                double alpha= static_cast<double>(m_cRecords)/m_cActiveBuckets;
                double low_sl = 0.0;
                double high_sl = 0.0;
                
                stats.AvgSearchLength= static_cast<double>(totacc) /m_cRecords;
                stats.ExpSearchLength  = 1 + alpha * 0.25 * (2 + x - x*x);
                
                if (m_iExpansionIdx > 0)
                    low_sl  = static_cast<double>(low_count)
                        / (2.0 * m_iExpansionIdx);
                if (m_cActiveBuckets - 2 * m_iExpansionIdx > 0)
                    high_sl = static_cast<double>(high_count)
                        / (m_cActiveBuckets - 2.0 * m_iExpansionIdx);
                stats.AvgUSearchLength = low_sl * x + high_sl * (1.0 - x);
                stats.ExpUSearchLength = alpha * 0.5 * (2 + x - x*x);
            }

#ifdef LOCK_INSTRUMENTATION
            stats.m_alsBucketsAvg.m_nContentions     /= m_cActiveBuckets;
            stats.m_alsBucketsAvg.m_nSleeps          /= m_cActiveBuckets;
            stats.m_alsBucketsAvg.m_nContentionSpins /= m_cActiveBuckets;
            stats.m_alsBucketsAvg.m_nAverageSpins    /= m_cActiveBuckets;
            stats.m_alsBucketsAvg.m_nReadLocks       /= m_cActiveBuckets;
            stats.m_alsBucketsAvg.m_nWriteLocks      /= m_cActiveBuckets;
#endif // LOCK_INSTRUMENTATION

        }
        else
        {
            stats.AvgSearchLength  = 0.0;
            stats.ExpSearchLength  = 0.0;
            stats.AvgUSearchLength = 0.0;
            stats.ExpUSearchLength = 0.0;
        }
    }

#ifdef LOCK_INSTRUMENTATION
    stats.m_gls     = TableLock::GlobalStatistics();
    CLockStatistics ls = _LockStats();

    stats.m_alsTable.m_nContentions     = ls.m_nContentions;
    stats.m_alsTable.m_nSleeps          = ls.m_nSleeps;
    stats.m_alsTable.m_nContentionSpins = ls.m_nContentionSpins;
    stats.m_alsTable.m_nAverageSpins    = ls.m_nAverageSpins;
    stats.m_alsTable.m_nReadLocks       = ls.m_nReadLocks;
    stats.m_alsTable.m_nWriteLocks      = ls.m_nWriteLocks;
    stats.m_alsTable.m_nItems           = 1;
#endif // LOCK_INSTRUMENTATION

    return stats;
} // CLKRLinearHashTable::GetStatistics



//------------------------------------------------------------------------
// Function: CLKRHashTable::GetStatistics
// Synopsis: Gather statistics about the table
//------------------------------------------------------------------------

CLKRHashTableStats
CLKRHashTable::GetStatistics() const
{
    CLKRHashTableStats hts;

    if (!IsUsable())
        return hts;

    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        CLKRHashTableStats stats = m_palhtDir[i]->GetStatistics();

        hts.RecordCount +=      stats.RecordCount;
        hts.TableSize +=        stats.TableSize;
        hts.DirectorySize +=    stats.DirectorySize;
        hts.LongestChain =      max(hts.LongestChain, stats.LongestChain);
        hts.EmptySlots +=       stats.EmptySlots;
        hts.SplitFactor +=      stats.SplitFactor;
        hts.AvgSearchLength +=  stats.AvgSearchLength;
        hts.ExpSearchLength +=  stats.ExpSearchLength;
        hts.AvgUSearchLength += stats.AvgUSearchLength;
        hts.ExpUSearchLength += stats.ExpUSearchLength;
        hts.NodeClumpSize =     stats.NodeClumpSize;
        hts.CBucketSize =       stats.CBucketSize;

        for (int j = 0;  j < CLKRHashTableStats::MAX_BUCKETS;  ++j)
            hts.m_aBucketLenHistogram[j] += stats.m_aBucketLenHistogram[j];

#ifdef LOCK_INSTRUMENTATION
        hts.m_alsTable.m_nContentions     += stats.m_alsTable.m_nContentions;
        hts.m_alsTable.m_nSleeps          += stats.m_alsTable.m_nSleeps;
        hts.m_alsTable.m_nContentionSpins
            += stats.m_alsTable.m_nContentionSpins;
        hts.m_alsTable.m_nAverageSpins    += stats.m_alsTable.m_nAverageSpins;
        hts.m_alsTable.m_nReadLocks       += stats.m_alsTable.m_nReadLocks;
        hts.m_alsTable.m_nWriteLocks      += stats.m_alsTable.m_nWriteLocks;
        
        hts.m_alsBucketsAvg.m_nContentions
            += stats.m_alsBucketsAvg.m_nContentions;
        hts.m_alsBucketsAvg.m_nSleeps
            += stats.m_alsBucketsAvg.m_nSleeps;
        hts.m_alsBucketsAvg.m_nContentionSpins
            += stats.m_alsBucketsAvg.m_nContentionSpins;
        hts.m_alsBucketsAvg.m_nAverageSpins
            += stats.m_alsBucketsAvg.m_nAverageSpins;
        hts.m_alsBucketsAvg.m_nReadLocks
            += stats.m_alsBucketsAvg.m_nReadLocks;
        hts.m_alsBucketsAvg.m_nWriteLocks
            += stats.m_alsBucketsAvg.m_nWriteLocks;
        hts.m_alsBucketsAvg.m_nItems
            += stats.m_alsBucketsAvg.m_nItems;
        
        hts.m_gls = stats.m_gls;
#endif // LOCK_INSTRUMENTATION
    }

    // Average out the subtables statistics.  (Does this make sense
    // for all of these fields?)
    hts.DirectorySize /=    m_cSubTables;
    hts.SplitFactor /=      m_cSubTables;
    hts.AvgSearchLength /=  m_cSubTables;
    hts.ExpSearchLength /=  m_cSubTables;
    hts.AvgUSearchLength /= m_cSubTables;
    hts.ExpUSearchLength /= m_cSubTables;

#ifdef LOCK_INSTRUMENTATION
    hts.m_alsTable.m_nContentions     /= m_cSubTables;
    hts.m_alsTable.m_nSleeps          /= m_cSubTables;
    hts.m_alsTable.m_nContentionSpins /= m_cSubTables;
    hts.m_alsTable.m_nAverageSpins    /= m_cSubTables;
    hts.m_alsTable.m_nReadLocks       /= m_cSubTables;
    hts.m_alsTable.m_nWriteLocks      /= m_cSubTables;
    hts.m_alsTable.m_nItems            = m_cSubTables;

    hts.m_alsBucketsAvg.m_nContentions     /= m_cSubTables;
    hts.m_alsBucketsAvg.m_nSleeps          /= m_cSubTables;
    hts.m_alsBucketsAvg.m_nContentionSpins /= m_cSubTables;
    hts.m_alsBucketsAvg.m_nAverageSpins    /= m_cSubTables;
    hts.m_alsBucketsAvg.m_nReadLocks       /= m_cSubTables;
    hts.m_alsBucketsAvg.m_nWriteLocks      /= m_cSubTables;
#endif // LOCK_INSTRUMENTATION

    return hts;
} // CLKRHashTable::GetStatistics



//-----------------------------------------------------------------------
// Function: CLKRLinearHashTable::_SetSegVars
// Synopsis: sets the size-specific segment variables
//-----------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_SetSegVars(
    LK_TABLESIZE lkts,
    DWORD        cInitialBuckets)
{
    switch (lkts)
    {
    case LK_SMALL_TABLESIZE:
      {
        m_lkts      = LK_SMALL_TABLESIZE;
        m_dwSegBits = CSmallSegment::SEGBITS;
        m_dwSegSize = CSmallSegment::SEGSIZE;
        m_dwSegMask = CSmallSegment::SEGMASK;
        STATIC_ASSERT(CSmallSegment::SEGSIZE == (1U<<CSmallSegment::SEGBITS));
        STATIC_ASSERT(CSmallSegment::SEGMASK == (CSmallSegment::SEGSIZE-1));
        break;
      }
        
    default:
        IRTLASSERT(! "Unknown LK_TABLESIZE");
        // fall-through
        
    case LK_MEDIUM_TABLESIZE:
      {
        m_lkts      = LK_MEDIUM_TABLESIZE;
        m_dwSegBits = CMediumSegment::SEGBITS;
        m_dwSegSize = CMediumSegment::SEGSIZE;
        m_dwSegMask = CMediumSegment::SEGMASK;
        STATIC_ASSERT(CMediumSegment::SEGSIZE ==(1U<<CMediumSegment::SEGBITS));
        STATIC_ASSERT(CMediumSegment::SEGMASK == (CMediumSegment::SEGSIZE-1));
        break;
      }
        
    case LK_LARGE_TABLESIZE:
      {
        m_lkts      = LK_LARGE_TABLESIZE;
        m_dwSegBits = CLargeSegment::SEGBITS;
        m_dwSegSize = CLargeSegment::SEGSIZE;
        m_dwSegMask = CLargeSegment::SEGMASK;
        STATIC_ASSERT(CLargeSegment::SEGSIZE == (1U<<CLargeSegment::SEGBITS));
        STATIC_ASSERT(CLargeSegment::SEGMASK == (CLargeSegment::SEGSIZE-1));
        break;
      }
    }

    m_dwBktAddrMask0 = m_dwSegMask;
    m_dwBktAddrMask1 = (m_dwBktAddrMask0 << 1) | 1;
    m_nLevel         = m_dwSegBits;
    m_cActiveBuckets = cInitialBuckets;

    IRTLASSERT(m_cActiveBuckets > 0);

    IRTLASSERT(m_nLevel == m_dwSegBits);
    IRTLASSERT(m_dwBktAddrMask0 == (1U << m_nLevel) - 1);
    IRTLASSERT(m_dwBktAddrMask1 == ((m_dwBktAddrMask0 << 1) | 1));

    IRTLASSERT(m_dwSegBits > 0);
    IRTLASSERT(m_dwSegSize == (1U << m_dwSegBits));
    IRTLASSERT(m_dwSegMask == (m_dwSegSize - 1));
    IRTLASSERT(m_dwBktAddrMask0 == m_dwSegMask);

    // adjust m_dwBktAddrMask0 (== m_dwSegMask) to make it large
    // enough to distribute the buckets across the address space
    for (DWORD tmp = m_cActiveBuckets >> m_dwSegBits;  tmp > 1;  tmp >>= 1)
    {
        ++m_nLevel;
        m_dwBktAddrMask0 = (m_dwBktAddrMask0 << 1) | 1;
    }

    m_dwBktAddrMask1 = (m_dwBktAddrMask0 << 1) | 1;

    IRTLASSERT(_H1(m_cActiveBuckets) == m_cActiveBuckets);
    m_iExpansionIdx = m_cActiveBuckets & m_dwBktAddrMask0;

    // create and clear directory of segments
    DWORD cDirSegs = MIN_DIRSIZE;
    while (cDirSegs < (m_cActiveBuckets >> m_dwSegBits))
        cDirSegs <<= 1;

    cDirSegs = min(cDirSegs, MAX_DIRSIZE);
    IRTLASSERT((cDirSegs << m_dwSegBits) >= m_cActiveBuckets);

    m_lkrcState = LK_ALLOC_FAIL;
    m_paDirSegs = _AllocateSegmentDirectory(cDirSegs);

    if (m_paDirSegs != NULL)
    {
        m_cDirSegs = cDirSegs;
        IRTLASSERT(m_cDirSegs >= MIN_DIRSIZE
                   &&  (m_cDirSegs & (m_cDirSegs-1)) == 0);  // == (1 << N)

        // create and initialize only the required segments
        DWORD dwMaxSegs = (m_cActiveBuckets + m_dwSegSize - 1) >> m_dwSegBits;
        IRTLASSERT(dwMaxSegs <= m_cDirSegs);

        IRTLTRACE(TEXT("InitSegDir: m_lkts = %d, m_cActiveBuckets = %lu, ")
                  TEXT("m_dwSegSize = %lu, bits = %lu\n")
                  TEXT("m_cDirSegs = %lu, dwMaxSegs = %lu, ")
                  TEXT("segment total size = %lu bytes\n"),
                  m_lkts, m_cActiveBuckets,
                  m_dwSegSize, m_dwSegBits,
                  m_cDirSegs, dwMaxSegs,
                  m_dwSegSize * sizeof(CBucket));

        m_lkrcState = LK_SUCCESS; // so IsValid/IsUsable won't fail

        for (DWORD i = 0;  i < dwMaxSegs;  i++)
        {
            CSegment* pSeg = _AllocateSegment();
            if (pSeg != NULL)
                m_paDirSegs[i].m_pseg = pSeg;
            else
            {
                // problem: deallocate everything
                m_lkrcState = LK_ALLOC_FAIL;
                for (DWORD j = i;  j-- > 0;  )
                {
                    _FreeSegment(m_paDirSegs[j].m_pseg);
                    m_paDirSegs[j].m_pseg = NULL;
                }
                _FreeSegmentDirectory();
                break;
            }
        }
    }

    if (m_lkrcState != LK_SUCCESS)
    {
        m_paDirSegs = NULL;
        m_cDirSegs  = m_cActiveBuckets = m_iExpansionIdx = 0;

        // Propagate error back up to parent (if it exists). This ensures
        // that all of the parent's public methods will start failing.
        if (NULL != m_phtParent)
            m_phtParent->m_lkrcState = m_lkrcState;
    }

    return m_lkrcState;
} // CLKRLinearHashTable::_SetSegVars




#include <stdlib.h>

LONG g_cAllocDirEntry = 0;
LONG g_cAllocNodeClump = 0;
LONG g_cAllocSmallSegment = 0;
LONG g_cAllocMediumSegment = 0;
LONG g_cAllocLargeSegment = 0;

extern "C"
__declspec(dllexport)
bool
GetAllocCounters()
{
return true;
}

// #define LKR_RANDOM_MEMORY_FAILURES 1000  // 1..RAND_MAX (32767)

// Memory allocation wrappers to allow us to simulate allocation
// failures during testing

//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_AllocateSegmentDirectory
// Synopsis: 
//------------------------------------------------------------------------

CDirEntry* const
CLKRLinearHashTable::_AllocateSegmentDirectory(
    size_t n)
{
#ifdef LKR_RANDOM_MEMORY_FAILURES
    if (rand() < LKR_RANDOM_MEMORY_FAILURES)
        return NULL;
#endif // LKR_RANDOM_MEMORY_FAILURES
    // InterlockedIncrement(&g_cAllocDirEntry);

    //  48760 - Can we allocate the requested size?  If not,
    //  treat it the same as an out-of-memory condition.
    if(n > (0xFFFFFFFF / sizeof(CDirEntry)))
        return NULL;

    CDirEntry* const paDirSegs = new CDirEntry [n];

#ifdef IRTLDEBUG
	if (NULL != paDirSegs)
	{
    	for (size_t i = 0;  i < n;  ++i)
        	IRTLASSERT(paDirSegs[i].m_pseg == NULL);
    }
#endif // IRTLDEBUG

    return paDirSegs;
} // CLKRLinearHashTable::_AllocateSegmentDirectory



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_FreeSegmentDirectory
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::_FreeSegmentDirectory()
{
#ifdef IRTLDEBUG
    for (size_t i = 0;  i < m_cDirSegs;  ++i)
        IRTLASSERT(m_paDirSegs[i].m_pseg == NULL);
#endif // IRTLDEBUG

    delete [] m_paDirSegs;
    m_paDirSegs = NULL;
    m_cDirSegs = 0;
    return true;
} // CLKRLinearHashTable::_FreeSegmentDirectory



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_AllocateNodeClump
// Synopsis: 
//------------------------------------------------------------------------

CNodeClump* const
CLKRLinearHashTable::_AllocateNodeClump()
{
#ifdef LKR_RANDOM_MEMORY_FAILURES
    if (rand() < LKR_RANDOM_MEMORY_FAILURES)
        return NULL;
#endif // LKR_RANDOM_MEMORY_FAILURES
    // InterlockedIncrement(&g_cAllocNodeClump);
    return new CNodeClump;
} // CLKRLinearHashTable::_AllocateNodeClump



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_FreeNodeClump
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::_FreeNodeClump(
    CNodeClump* pnc)
{
    delete pnc;
    return true;
} // CLKRLinearHashTable::_FreeNodeClump



//-----------------------------------------------------------------------
// Function: CLKRLinearHashTable::_AllocateSegment
// Synopsis: creates a new segment of the approriate size
// Output:   pointer to the new segment; NULL => failure
//-----------------------------------------------------------------------

CSegment* const
CLKRLinearHashTable::_AllocateSegment(
    ) const
{
#ifdef LKR_RANDOM_MEMORY_FAILURES
    if (rand() < LKR_RANDOM_MEMORY_FAILURES)
        return NULL;
#endif // LKR_RANDOM_MEMORY_FAILURES

    STATIC_ASSERT(offsetof(CSegment, m_bktSlots) + sizeof(CBucket)
                  == offsetof(CSmallSegment, m_bktSlots2));

    STATIC_ASSERT(offsetof(CSegment, m_bktSlots) + sizeof(CBucket)
                  == offsetof(CMediumSegment, m_bktSlots2));

    STATIC_ASSERT(offsetof(CSegment, m_bktSlots) + sizeof(CBucket)
                  == offsetof(CLargeSegment, m_bktSlots2));

    CSegment* pseg = NULL;

    switch (m_lkts)
    {
    case LK_SMALL_TABLESIZE:
#ifdef LKRHASH_ALLOCATOR_NEW
        IRTLASSERT(CSmallSegment::sm_palloc != NULL);
#endif // LKRHASH_ALLOCATOR_NEW
        // InterlockedIncrement(&g_cAllocSmallSegment);
        pseg = new CSmallSegment;
        break;
        
    default:
        IRTLASSERT(! "Unknown LK_TABLESIZE");
        // fall-through
        
    case LK_MEDIUM_TABLESIZE:
#ifdef LKRHASH_ALLOCATOR_NEW
        IRTLASSERT(CMediumSegment::sm_palloc != NULL);
#endif // LKRHASH_ALLOCATOR_NEW
        // InterlockedIncrement(&g_cAllocMediumSegment);
        pseg = new CMediumSegment;
        break;
        
    case LK_LARGE_TABLESIZE:
#ifdef LKRHASH_ALLOCATOR_NEW
        IRTLASSERT(CLargeSegment::sm_palloc != NULL);
#endif // LKRHASH_ALLOCATOR_NEW
        // InterlockedIncrement(&g_cAllocLargeSegment);
        pseg = new CLargeSegment;
        break;
    }

    IRTLASSERT(pseg != NULL);

    if (pseg != NULL  &&  BucketLock::PerLockSpin() == LOCK_INDIVIDUAL_SPIN)
    {
        for (DWORD i = 0;  i < m_dwSegSize;  ++i)
            pseg->Slot(i).SetSpinCount(m_wBucketLockSpins);
    }

    return pseg;
} // CLKRLinearHashTable::_AllocateSegment



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_FreeSegment
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::_FreeSegment(
    CSegment* pseg) const
{
    switch (m_lkts)
    {
    case LK_SMALL_TABLESIZE:
        delete static_cast<CSmallSegment*>(pseg);
        break;
        
    default:
        IRTLASSERT(! "Unknown LK_TABLESIZE");
        // fall-through
        
    case LK_MEDIUM_TABLESIZE:
        delete static_cast<CMediumSegment*>(pseg);
        break;
        
    case LK_LARGE_TABLESIZE:
        delete static_cast<CLargeSegment*>(pseg);
        break;
    }

    return true;
} // CLKRLinearHashTable::_FreeSegment



//------------------------------------------------------------------------
// Function: CLKRHashTable::_AllocateSubTableArray
// Synopsis: 
//------------------------------------------------------------------------

CLKRHashTable::SubTable** const
CLKRHashTable::_AllocateSubTableArray(
    size_t n)
{
#ifdef LKR_RANDOM_MEMORY_FAILURES
    if (rand() < LKR_RANDOM_MEMORY_FAILURES)
        return NULL;
#endif // LKR_RANDOM_MEMORY_FAILURES
    return new SubTable* [n];
} // CLKRHashTable::_AllocateSubTableArray



//------------------------------------------------------------------------
// Function: CLKRHashTable::_FreeSubTableArray
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRHashTable::_FreeSubTableArray(
    CLKRHashTable::SubTable** palht)
{
    delete [] palht;
    return true;
} // CLKRHashTable::_FreeSubTableArray



//------------------------------------------------------------------------
// Function: CLKRHashTable::_AllocateSubTable
// Synopsis: 
//------------------------------------------------------------------------

CLKRHashTable::SubTable* const
CLKRHashTable::_AllocateSubTable(
    LPCSTR          pszName,        // An identifier for debugging
    PFnExtractKey   pfnExtractKey,  // Extract key from record
    PFnCalcKeyHash  pfnCalcKeyHash, // Calculate hash signature of key
    PFnEqualKeys    pfnEqualKeys,   // Compare two keys
    PFnAddRefRecord pfnAddRefRecord,// AddRef in FindKey, etc
    double          maxload,        // Upperbound on average chain length
    DWORD           initsize,       // Initial size of hash table.
    CLKRHashTable*  phtParent,      // Owning table.
    bool            fMultiKeys      // Allow multiple identical keys?
    )
{
#ifdef LKR_RANDOM_MEMORY_FAILURES
    if (rand() < LKR_RANDOM_MEMORY_FAILURES)
        return NULL;
#endif // LKR_RANDOM_MEMORY_FAILURES
    return new SubTable(pszName, pfnExtractKey, pfnCalcKeyHash,
                        pfnEqualKeys,  pfnAddRefRecord,
                        maxload, initsize, phtParent, fMultiKeys);
} // CLKRHashTable::_AllocateSubTable



//------------------------------------------------------------------------
// Function: CLKRHashTable::_FreeSubTable
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRHashTable::_FreeSubTable(
    CLKRHashTable::SubTable* plht)
{
    delete plht;
    return true;
} // CLKRHashTable::_FreeSubTable




//-----------------------------------------------------------------------
// Function: CLKRLinearHashTable::_Expand
// Synopsis: Expands the table by one bucket. Done by splitting the
//           bucket pointed to by m_iExpansionIdx.
// Output:   LK_SUCCESS, if expansion was successful.
//           LK_ALLOC_FAIL, if expansion failed due to lack of memory.
//-----------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_Expand()
{
    if (m_cActiveBuckets >= MAX_DIRSIZE * m_dwSegSize - 1)
        return LK_ALLOC_FAIL;  // table is not allowed to grow any more

    WriteLock();

    // double segment directory size if necessary
    if (m_cActiveBuckets >= m_cDirSegs * m_dwSegSize)
    {
        IRTLASSERT(m_cDirSegs < MAX_DIRSIZE);
        DWORD cDirSegsNew = (m_cDirSegs == 0) ? MIN_DIRSIZE : m_cDirSegs << 1;
        CDirEntry* paDirSegsNew = _AllocateSegmentDirectory(cDirSegsNew);

        if (paDirSegsNew != NULL)
        {
            for (DWORD j = 0;  j < m_cDirSegs;  j++)
            {
                paDirSegsNew[j] = m_paDirSegs[j];
                m_paDirSegs[j].m_pseg = NULL;
            }

            _FreeSegmentDirectory();
            m_paDirSegs = paDirSegsNew;
            m_cDirSegs  = cDirSegsNew;
        }
        else
        {
            WriteUnlock();
            return LK_ALLOC_FAIL;  // expansion failed
        }
    }

    // locate the new bucket, creating a new segment if necessary
    ++m_cActiveBuckets;

    DWORD     dwOldBkt = m_iExpansionIdx;
    DWORD     dwNewBkt = (1 << m_nLevel) | dwOldBkt;

    IRTLASSERT(dwOldBkt < m_cActiveBuckets);
    IRTLASSERT(dwNewBkt < m_cActiveBuckets);

    IRTLASSERT(_Segment(dwOldBkt) != NULL);
    CSegment* psegNew  = _Segment(dwNewBkt);

    if (psegNew == NULL)
    {
        psegNew = _AllocateSegment();
        if (psegNew == NULL)
        {
            --m_cActiveBuckets;
            WriteUnlock();
            return LK_ALLOC_FAIL;  // expansion failed
        }
        _Segment(dwNewBkt) = psegNew;
    }

    // prepare to relocate records to the new bucket
    CBucket* pbktOld = _Bucket(dwOldBkt);
    CBucket* pbktNew = _Bucket(dwNewBkt);

    // get locks on the two buckets involved
    pbktOld->WriteLock();
    pbktNew->WriteLock();

    // Now work out if we need to allocate any extra CNodeClumps.  We do
    // this up front, before calling _SplitRecordSet, as it's hard to
    // gracefully recover from the depths of that routine should we run
    // out of memory.

    CNodeClump* pncFreeList = NULL;
    LK_RETCODE  lkrc        = LK_SUCCESS;

    // If the old bucket has more than one CNodeClump, there's a chance that
    // we'll need extra CNodeClumps in the new bucket too.  If it doesn't,
    // we definitely won't. One CNodeClump is enough to prime the freelist.
    if (!pbktOld->m_ncFirst.IsLastClump())
    {
        pncFreeList = _AllocateNodeClump();
        if (pncFreeList == NULL)
        {
            lkrc = LK_ALLOC_FAIL;
            --m_cActiveBuckets;
        }
    }

    // adjust expansion pointer, level, and mask
    if (lkrc == LK_SUCCESS)
    {
        if (++m_iExpansionIdx == (1U << m_nLevel))
        {
            ++m_nLevel;
            m_iExpansionIdx = 0;
            m_dwBktAddrMask0 = (m_dwBktAddrMask0 << 1) | 1;
            // m_dwBktAddrMask0 = 00011..111
            IRTLASSERT((m_dwBktAddrMask0 & (m_dwBktAddrMask0+1)) == 0);
            m_dwBktAddrMask1 = (m_dwBktAddrMask0 << 1) | 1;
            IRTLASSERT((m_dwBktAddrMask1 & (m_dwBktAddrMask1+1)) == 0);
        }
    }

    DWORD iExpansionIdx = m_iExpansionIdx;  // save to avoid race conditions
    DWORD dwBktAddrMask = m_dwBktAddrMask0; // ditto

    // Release the table lock before doing the actual relocation
    WriteUnlock();

    if (lkrc == LK_SUCCESS)
    {
        lkrc = _SplitRecordSet(&pbktOld->m_ncFirst, &pbktNew->m_ncFirst,
                               iExpansionIdx, dwBktAddrMask,
                               dwNewBkt, pncFreeList);
    }

    pbktNew->WriteUnlock();
    pbktOld->WriteUnlock();

    return lkrc;
} // CLKRLinearHashTable::_Expand



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_SplitRecordSet
// Synopsis: Split records between the old and new buckets.
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_SplitRecordSet(
    CNodeClump* pncOldTarget,
    CNodeClump* pncNewTarget,
    DWORD       iExpansionIdx,
    DWORD       dwBktAddrMask,
    DWORD       dwNewBkt,
    CNodeClump* pncFreeList     // list of free nodes available for reuse
    )
{
    CNodeClump  ncFirst = *pncOldTarget;    // save head of old target chain
    CNodeClump* pncOldList = &ncFirst;
    CNodeClump* pncTmp;
    int         iOldSlot = NODE_BEGIN;
    int         iNewSlot = NODE_BEGIN;

    // clear target buckets
    pncOldTarget->Clear();
    pncNewTarget->Clear();

    // scan through the old bucket chain and decide where to move each record
    while (pncOldList != NULL)
    {
        int i;

        FOR_EACH_NODE(i)
        {
            // node already empty?
            if (pncOldList->IsEmptySlot(i))
            {
                IRTLASSERT(pncOldList->IsEmptyAndInvalid(i));
                continue;
            }

            // calculate bucket address of this node
            DWORD dwBkt = _H0(pncOldList->m_dwKeySigs[i], dwBktAddrMask);
            if (dwBkt < iExpansionIdx)
                dwBkt = _H1(pncOldList->m_dwKeySigs[i], dwBktAddrMask);

            // record to be moved to the new address?
            if (dwBkt == dwNewBkt)
            {
                // node in new bucket chain full?
                if (iNewSlot == NODE_END)
                {
                    // the calling routine has passed in a FreeList adequate
                    // for all needs
                    IRTLASSERT(pncFreeList != NULL);
                    pncTmp = pncFreeList;
                    pncFreeList = pncFreeList->m_pncNext;
                    pncTmp->Clear();
                    pncNewTarget->m_pncNext = pncTmp;
                    pncNewTarget = pncTmp;
                    iNewSlot = NODE_BEGIN;
                }

                pncNewTarget->m_dwKeySigs[iNewSlot]
                    = pncOldList->m_dwKeySigs[i];
                pncNewTarget->m_pvNode[iNewSlot]
                    = pncOldList->m_pvNode[i];
                iNewSlot += NODE_STEP;
            }

            // no, record stays in its current bucket chain
            else
            {
                // node in old bucket chain full?
                if (iOldSlot == NODE_END)
                {
                    // the calling routine has passed in a FreeList adequate
                    // for all needs
                    IRTLASSERT(pncFreeList != NULL);
                    pncTmp = pncFreeList;
                    pncFreeList = pncFreeList->m_pncNext;
                    pncTmp->Clear();
                    pncOldTarget->m_pncNext = pncTmp;
                    pncOldTarget = pncTmp;
                    iOldSlot = NODE_BEGIN;
                }

                pncOldTarget->m_dwKeySigs[iOldSlot]
                    = pncOldList->m_dwKeySigs[i];
                pncOldTarget->m_pvNode[iOldSlot]
                    = pncOldList->m_pvNode[i];
                iOldSlot += NODE_STEP;
            }

            // clear old slot
            pncOldList->m_dwKeySigs[i] = HASH_INVALID_SIGNATURE;
            pncOldList->m_pvNode[i]    = NULL;
        }

        // keep walking down the original bucket chain
        pncTmp     = pncOldList;
        pncOldList = pncOldList->m_pncNext;

        // ncFirst is a stack variable, not allocated on the heap
        if (pncTmp != &ncFirst)
        {
            pncTmp->m_pncNext = pncFreeList;
            pncFreeList = pncTmp;
        }
    }

    // delete any leftover nodes
    while (pncFreeList != NULL)
    {
        pncTmp = pncFreeList;
        pncFreeList = pncFreeList->m_pncNext;
#ifdef IRTLDEBUG
        pncTmp->m_pncNext = NULL; // or ~CNodeClump will ASSERT
#endif // IRTLDEBUG
        _FreeNodeClump(pncTmp);
    }

#ifdef IRTLDEBUG
    ncFirst.m_pncNext = NULL; // or ~CNodeClump will ASSERT
#endif // IRTLDEBUG

    return LK_SUCCESS;
} // CLKRLinearHashTable::_SplitRecordSet



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_Contract
// Synopsis: Contract the table by deleting the last bucket in the active
//           address space. Return the records to the "buddy" of the
//           deleted bucket.
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_Contract()
{
    WriteLock();

    // update the state variables (expansion ptr, level and mask)
    if (m_iExpansionIdx > 0)
        --m_iExpansionIdx;
    else
    {
        --m_nLevel;
        m_iExpansionIdx = (1 << m_nLevel) - 1;
        IRTLASSERT(m_nLevel > 0  &&  m_iExpansionIdx > 0);
        m_dwBktAddrMask0 >>= 1;
        IRTLASSERT((m_dwBktAddrMask0 & (m_dwBktAddrMask0+1)) == 0); // 00011..111
        m_dwBktAddrMask1 >>= 1;
        IRTLASSERT(m_dwBktAddrMask1 == ((m_dwBktAddrMask0 << 1) | 1));
        IRTLASSERT((m_dwBktAddrMask1 & (m_dwBktAddrMask1+1)) == 0);
    }

    // The last bucket is the one that will be emptied
    CBucket* pbktLast = _Bucket(m_cActiveBuckets - 1);
    pbktLast->WriteLock();

    // Decrement after calculating pbktLast, or _Bucket() will assert.
    --m_cActiveBuckets;

    // Where the nodes from pbktLast will end up
    CBucket* pbktNew = _Bucket(m_iExpansionIdx);
    pbktNew->WriteLock();

    // Now we work out if we need to allocate any extra CNodeClumps.  We do
    // this up front, before calling _MergeRecordSets, as it's hard to
    // gracefully recover from the depths of that routine should we run
    // out of memory.
    
    CNodeClump* pnc;
    int         c = 0;

    // First, count the number of items in the old bucket
    for (pnc = &pbktLast->m_ncFirst;  pnc != NULL;  pnc = pnc->m_pncNext)
    {
        int i;

        FOR_EACH_NODE(i)
        {
            if (!pnc->IsEmptySlot(i))
            {
                IRTLASSERT(!pnc->IsEmptyAndInvalid(i));
                c++;
            }
        }
    }

    // Then, subtract off the number of empty slots in the new bucket
    for (pnc = &pbktNew->m_ncFirst;  pnc != NULL;  pnc = pnc->m_pncNext)
    {
        int i;

        FOR_EACH_NODE(i)
        {
            if (pnc->IsEmptySlot(i))
            {
                IRTLASSERT(pnc->IsEmptyAndInvalid(i));
                c--;
            }
        }
    }

    CNodeClump* pncFreeList = NULL;  // list of nodes available for reuse
    LK_RETCODE  lkrc        = LK_SUCCESS;

    // Do we need to allocate CNodeClumps to accommodate the surplus items?
    if (c > 0)
    {
        pncFreeList = _AllocateNodeClump();
        if (pncFreeList == NULL)
            lkrc = LK_ALLOC_FAIL;
        else if (c > NODES_PER_CLUMP)
        {
            // In the worst case, we need a 2-element freelist for
            // _MergeRecordSets. Two CNodeClumps always suffice since the
            // freelist will be augmented by the CNodeClumps from the old
            // bucket as they are processed.
            pnc = _AllocateNodeClump();
            if (pnc == NULL)
            {
                _FreeNodeClump(pncFreeList);
                lkrc = LK_ALLOC_FAIL;
            }
            else
                pncFreeList->m_pncNext = pnc;
        }
    }

    // Abort if we couldn't allocate enough CNodeClumps
    if (lkrc != LK_SUCCESS)
    {
        // undo the changes to the state variables
        if (++m_iExpansionIdx == (1U << m_nLevel))
        {
            ++m_nLevel;
            m_iExpansionIdx  = 0;
            m_dwBktAddrMask0 = (m_dwBktAddrMask0 << 1) | 1;
            m_dwBktAddrMask1 = (m_dwBktAddrMask0 << 1) | 1;
        }
        ++m_cActiveBuckets;

        // Unlock the buckets and the table
        pbktLast->WriteUnlock();
        pbktNew->WriteUnlock();
        WriteUnlock();

        return lkrc;
    }

    // Copy the chain of records from pbktLast
    CNodeClump ncOldFirst = pbktLast->m_ncFirst;

    // destroy pbktLast
    pbktLast->m_ncFirst.Clear();
    pbktLast->WriteUnlock();

    // remove segment, if empty
    if (_SegIndex(m_cActiveBuckets) == 0)
    {
#ifdef IRTLDEBUG
        // double-check that the supposedly empty segment is really empty
        IRTLASSERT(_Segment(m_cActiveBuckets) != NULL);
        for (DWORD i = 0;  i < m_dwSegSize;  ++i)
        {
            CBucket* pbkt = &_Segment(m_cActiveBuckets)->Slot(i);
            IRTLASSERT(pbkt->IsWriteUnlocked()  &&  pbkt->IsReadUnlocked());
            IRTLASSERT(pbkt->m_ncFirst.IsLastClump());

            int j;

            FOR_EACH_NODE(j)
            {
                IRTLASSERT(pbkt->m_ncFirst.IsEmptyAndInvalid(j));
            }
        }
#endif // IRTLDEBUG
        _FreeSegment(_Segment(m_cActiveBuckets));
        _Segment(m_cActiveBuckets) = NULL;
    }

    // reduce directory of segments if possible
    if (m_cActiveBuckets <= (m_cDirSegs * m_dwSegSize) >> 1
        &&  m_cDirSegs > MIN_DIRSIZE)
    {
        DWORD cDirSegsNew = m_cDirSegs >> 1;
        CDirEntry* paDirSegsNew = _AllocateSegmentDirectory(cDirSegsNew);

        // Memory allocation failure here does not require us to abort; it
        // just means that the directory of segments is larger than we'd like.
        if (paDirSegsNew != NULL)
        {
			DWORD j;

            for (j = 0;  j < cDirSegsNew;  j++)
                paDirSegsNew[j] = m_paDirSegs[j];
            for (j = 0;  j < m_cDirSegs;  j++)
                m_paDirSegs[j].m_pseg = NULL;

            _FreeSegmentDirectory();
            m_paDirSegs = paDirSegsNew;
            m_cDirSegs  = cDirSegsNew;
        }
    }

    // release the table lock before doing the reorg
    WriteUnlock();

    lkrc = _MergeRecordSets(pbktNew, &ncOldFirst, pncFreeList);

    pbktNew->WriteUnlock();

#ifdef IRTLDEBUG
    ncOldFirst.m_pncNext = NULL; // or ~CNodeClump will ASSERT
#endif // IRTLDEBUG

    return lkrc;
} // CLKRLinearHashTable::_Contract



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_MergeRecordSets
// Synopsis: Merge two record sets.  Copy the contents of pncOldList
//           into pbktNewTarget.
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_MergeRecordSets(
    CBucket*    pbktNewTarget,
    CNodeClump* pncOldList,
    CNodeClump* pncFreeList
    )
{
    IRTLASSERT(pbktNewTarget != NULL  &&  pncOldList != NULL);

    CNodeClump*   pncTmp = NULL;
    CNodeClump* const pncOldFirst = pncOldList;
    CNodeClump*   pncNewTarget = &pbktNewTarget->m_ncFirst;
    int           iNewSlot;

    // find the first nodeclump in the new target bucket with an empty slot
    while (!pncNewTarget->IsLastClump())
    {
        FOR_EACH_NODE(iNewSlot)
        {
            if (pncNewTarget->IsEmptySlot(iNewSlot))
                break;
        }

        if (iNewSlot == NODE_END)
            pncNewTarget = pncNewTarget->m_pncNext;
        else
            break;
    }

    IRTLASSERT(pncNewTarget != NULL);

    // find the first empty slot in pncNewTarget;
    // if none, iNewSlot == NODE_END
    FOR_EACH_NODE(iNewSlot)
    {
        if (pncNewTarget->IsEmptySlot(iNewSlot))
        {
            break;
        }
    }
    
    while (pncOldList != NULL)
    {
        int i;

        FOR_EACH_NODE(i)
        {
            if (!pncOldList->IsEmptySlot(i))
            {
                // any empty slots left in pncNewTarget?
                if (iNewSlot == NODE_END)
                {
                    // no, so walk down pncNewTarget until we find another
                    // empty slot
                    while (!pncNewTarget->IsLastClump())
                    {
                        pncNewTarget = pncNewTarget->m_pncNext;

                        FOR_EACH_NODE(iNewSlot)
                        {
                            if (pncNewTarget->IsEmptySlot(iNewSlot))
                                goto found_slot;
                        }
                    }

                    // Oops, reached the last nodeclump in pncNewTarget
                    // and it's full.  Get a new nodeclump off the free
                    // list, which is big enough to handle all needs.
                    IRTLASSERT(pncNewTarget != NULL);
                    IRTLASSERT(pncFreeList != NULL);
                    pncTmp = pncFreeList;
                    pncFreeList = pncFreeList->m_pncNext;
                    pncTmp->Clear();
                    pncNewTarget->m_pncNext = pncTmp;
                    pncNewTarget = pncTmp;
                    iNewSlot = NODE_BEGIN;
                }

              found_slot:
                // We have an empty slot in pncNewTarget
                IRTLASSERT(0 <= iNewSlot  &&  iNewSlot < NODES_PER_CLUMP
                       &&  pncNewTarget != NULL
                       &&  pncNewTarget->IsEmptyAndInvalid(iNewSlot));

                // Let's copy the node from pncOldList
                pncNewTarget->m_dwKeySigs[iNewSlot]
                    = pncOldList->m_dwKeySigs[i];
                pncNewTarget->m_pvNode[iNewSlot]
                    = pncOldList->m_pvNode[i];

                // Clear old slot
                pncOldList->m_dwKeySigs[i] = HASH_INVALID_SIGNATURE;
                pncOldList->m_pvNode[i]    = NULL;

                // find the next free slot in pncNewTarget
                while ((iNewSlot += NODE_STEP) != NODE_END)
                {
                    if (pncNewTarget->IsEmptySlot(iNewSlot))
                    {
                        break;
                    }
                }
            }
            else // iNewSlot != NODE_END
            {
                IRTLASSERT(pncOldList->IsEmptyAndInvalid(i));
            }
        }

        // Move into the next nodeclump in pncOldList
        pncTmp = pncOldList;
        pncOldList = pncOldList->m_pncNext;

        // Append to the free list.  Don't put the first node of
        // pncOldList on the free list, as it's a stack variable.
        if (pncTmp != pncOldFirst)
        {
            pncTmp->m_pncNext = pncFreeList;
            pncFreeList = pncTmp;
        }
    }

    // delete any leftover nodes
    while (pncFreeList != NULL)
    {
        pncTmp = pncFreeList;
        pncFreeList = pncFreeList->m_pncNext;
#ifdef IRTLDEBUG
        pncTmp->m_pncNext = NULL; // or ~CNodeClump will ASSERT
#endif // IRTLDEBUG
        _FreeNodeClump(pncTmp);
    }

    return LK_SUCCESS;
} // CLKRLinearHashTable::_MergeRecordSets



#ifdef LKR_DEPRECATED_ITERATORS

//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_InitializeIterator
// Synopsis: Make the iterator point to the first record in the hash table.
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_InitializeIterator(
    CIterator* piter)
{
    if (!IsUsable())
        return LK_UNUSABLE;

    IRTLASSERT(piter != NULL);
    IRTLASSERT(piter->m_lkl == LKL_WRITELOCK
               ?  IsWriteLocked()
               :  IsReadLocked());
    if (piter == NULL  ||  piter->m_plht != NULL)
        return LK_BAD_ITERATOR;

    piter->m_plht = this;
    piter->m_dwBucketAddr = 0;

    CBucket* pbkt = _Bucket(piter->m_dwBucketAddr);
    IRTLASSERT(pbkt != NULL);
    if (piter->m_lkl == LKL_WRITELOCK)
        pbkt->WriteLock();
    else
        pbkt->ReadLock();

    piter->m_pnc = &pbkt->m_ncFirst;
    piter->m_iNode = NODE_BEGIN - NODE_STEP;

    // Let IncrementIterator do the hard work of finding the first
    // slot in use.
    return IncrementIterator(piter);
} // CLKRLinearHashTable::_InitializeIterator



//------------------------------------------------------------------------
// Function: CLKRHashTable::InitializeIterator
// Synopsis: make the iterator point to the first record in the hash table
//------------------------------------------------------------------------

LK_RETCODE
CLKRHashTable::InitializeIterator(
    CIterator* piter)
{
    if (!IsUsable())
        return LK_UNUSABLE;

    IRTLASSERT(piter != NULL  &&  piter->m_pht == NULL);
    if (piter == NULL  ||  piter->m_pht != NULL)
        return LK_BAD_ITERATOR;

    // First, lock all the subtables
    if (piter->m_lkl == LKL_WRITELOCK)
        WriteLock();
    else
        ReadLock();

    // Must call IsValid inside a lock to ensure that none of the state
    // variables change while it's being evaluated
    IRTLASSERT(IsValid());
    if (!IsValid())
        return LK_UNUSABLE;

    piter->m_pht  = this;
    piter->m_ist  = -1;
    piter->m_plht = NULL;

    // Let IncrementIterator do the hard work of finding the first
    // valid node in the subtables.
    return IncrementIterator(piter);
} // CLKRHashTable::InitializeIterator



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::IncrementIterator
// Synopsis: move the iterator on to the next record in the hash table
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::IncrementIterator(
    CIterator* piter)
{
    if (!IsUsable())
        return LK_UNUSABLE;

    IRTLASSERT(piter != NULL);
    IRTLASSERT(piter->m_plht == this);
    IRTLASSERT(piter->m_lkl == LKL_WRITELOCK
               ?  IsWriteLocked()
               :  IsReadLocked());
    IRTLASSERT(piter->m_dwBucketAddr < m_cActiveBuckets);
    IRTLASSERT(piter->m_pnc != NULL);
    IRTLASSERT((0 <= piter->m_iNode  &&  piter->m_iNode < NODES_PER_CLUMP)
               || (NODE_BEGIN - NODE_STEP == piter->m_iNode));

    if (piter == NULL  ||  piter->m_plht != this)
        return LK_BAD_ITERATOR;

    const void* pvRecord = NULL;

    if (piter->m_iNode != NODE_BEGIN - NODE_STEP)
    {
        // Release the reference acquired in the previous call to
        // IncrementIterator
        pvRecord = piter->m_pnc->m_pvNode[piter->m_iNode];
        _AddRefRecord(pvRecord, -1);
    }

    do
    {
        do
        {
            // find the next slot in the nodeclump that's in use
            while ((piter->m_iNode += NODE_STEP) != NODE_END)
            {
                pvRecord = piter->m_pnc->m_pvNode[piter->m_iNode];
                if (pvRecord != NULL)
                {
                    // Add a new reference
                    _AddRefRecord(pvRecord, +1);
                    return LK_SUCCESS;
                }
                else // pvRecord == NULL
                {
#ifdef IRTLDEBUG
                    // Check that all the remaining nodes are empty
                    IRTLASSERT(piter->m_pnc->IsLastClump());
                    for (int i = piter->m_iNode;
                         i != NODE_END;
                         i += NODE_STEP)
                    {
                        IRTLASSERT(piter->m_pnc->IsEmptyAndInvalid(i));
                    }
#endif // IRTLDEBUG
                    break; // rest of nodeclump is empty
                }
            }

            // try the next nodeclump in the bucket chain
            piter->m_iNode = NODE_BEGIN - NODE_STEP;
            piter->m_pnc = piter->m_pnc->m_pncNext;
        } while (piter->m_pnc != NULL);

        // Exhausted this bucket chain.  Unlock it.
        CBucket* pbkt = _Bucket(piter->m_dwBucketAddr);
        IRTLASSERT(pbkt != NULL);
        IRTLASSERT(piter->m_lkl == LKL_WRITELOCK
                   ?  pbkt->IsWriteLocked()
                   :  pbkt->IsReadLocked());
        if (piter->m_lkl == LKL_WRITELOCK)
            pbkt->WriteUnlock();
        else
            pbkt->ReadUnlock();

        // Try the next bucket, if there is one
        if (++piter->m_dwBucketAddr < m_cActiveBuckets)
        {
            pbkt = _Bucket(piter->m_dwBucketAddr);
            IRTLASSERT(pbkt != NULL);
            if (piter->m_lkl == LKL_WRITELOCK)
                pbkt->WriteLock();
            else
                pbkt->ReadLock();
            piter->m_pnc = &pbkt->m_ncFirst;
        }
    } while (piter->m_dwBucketAddr < m_cActiveBuckets);

    // We have fallen off the end of the hashtable
    piter->m_iNode = NODE_BEGIN - NODE_STEP;
    piter->m_pnc = NULL;

    return LK_NO_MORE_ELEMENTS;
} // CLKRLinearHashTable::IncrementIterator



//------------------------------------------------------------------------
// Function: CLKRHashTable::IncrementIterator
// Synopsis: move the iterator on to the next record in the hash table
//------------------------------------------------------------------------

LK_RETCODE
CLKRHashTable::IncrementIterator(
    CIterator* piter)
{
    if (!IsUsable())
        return LK_UNUSABLE;

    IRTLASSERT(piter != NULL);
    IRTLASSERT(piter->m_pht == this);
    IRTLASSERT(-1 <= piter->m_ist
               &&  piter->m_ist < static_cast<int>(m_cSubTables));

    if (piter == NULL  ||  piter->m_pht != this)
        return LK_BAD_ITERATOR;

    // Table is already locked
    if (!IsValid())
        return LK_UNUSABLE;

    LK_RETCODE lkrc;
    CLHTIterator* pBaseIter = static_cast<CLHTIterator*>(piter);

    for (;;)
    {
        // Do we have a valid iterator into a subtable?  If not, get one.
        while (piter->m_plht == NULL)
        {
            while (++piter->m_ist < static_cast<int>(m_cSubTables))
            {
                lkrc = m_palhtDir[piter->m_ist]->_InitializeIterator(piter);
                if (lkrc == LK_SUCCESS)
                {
                    IRTLASSERT(m_palhtDir[piter->m_ist] == piter->m_plht);
                    return lkrc;
                }
                else if (lkrc == LK_NO_MORE_ELEMENTS)
                    lkrc = piter->m_plht->_CloseIterator(pBaseIter);

                if (lkrc != LK_SUCCESS)
                    return lkrc;
            }

            // There are no more subtables left.
            return LK_NO_MORE_ELEMENTS;
        }

        // We already have a valid iterator into a subtable.  Increment it.
        lkrc = piter->m_plht->IncrementIterator(pBaseIter);
        if (lkrc == LK_SUCCESS)
            return lkrc;

        // We've exhausted that subtable.  Move on.
        if (lkrc == LK_NO_MORE_ELEMENTS)
            lkrc = piter->m_plht->_CloseIterator(pBaseIter);

        if (lkrc != LK_SUCCESS)
            return lkrc;
    }
} // CLKRHashTable::IncrementIterator



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_CloseIterator
// Synopsis: release the resources held by the iterator
//------------------------------------------------------------------------

LK_RETCODE
CLKRLinearHashTable::_CloseIterator(
    CIterator* piter)
{
    if (!IsUsable())
        return LK_UNUSABLE;

    IRTLASSERT(piter != NULL);
    IRTLASSERT(piter->m_plht == this);
    IRTLASSERT(piter->m_lkl == LKL_WRITELOCK
               ?  IsWriteLocked()
               :  IsReadLocked());
    IRTLASSERT(piter->m_dwBucketAddr <= m_cActiveBuckets);
    IRTLASSERT((0 <= piter->m_iNode  &&  piter->m_iNode < NODES_PER_CLUMP)
               || (NODE_BEGIN - NODE_STEP == piter->m_iNode));

    if (piter == NULL  ||  piter->m_plht != this)
        return LK_BAD_ITERATOR;

    // Are we abandoning the iterator before the end of the table?
    // If so, need to unlock the bucket.
    if (piter->m_dwBucketAddr < m_cActiveBuckets)
    {
        CBucket* pbkt = _Bucket(piter->m_dwBucketAddr);
        IRTLASSERT(pbkt != NULL);
        IRTLASSERT(piter->m_lkl == LKL_WRITELOCK
                   ?  pbkt->IsWriteLocked()
                   :  pbkt->IsReadLocked());
        if (0 <= piter->m_iNode  &&  piter->m_iNode < NODES_PER_CLUMP)
        {
            IRTLASSERT(piter->m_pnc != NULL);
            const void* pvRecord = piter->m_pnc->m_pvNode[piter->m_iNode];
            _AddRefRecord(pvRecord, -1);
        }
        if (piter->m_lkl == LKL_WRITELOCK)
            pbkt->WriteUnlock();
        else
            pbkt->ReadUnlock();
    }

    piter->m_plht = NULL;
    piter->m_pnc  = NULL;

    return LK_SUCCESS;
} // CLKRLinearHashTable::_CloseIterator



//------------------------------------------------------------------------
// Function: CLKRHashTable::CloseIterator
// Synopsis: release the resources held by the iterator
//------------------------------------------------------------------------

LK_RETCODE
CLKRHashTable::CloseIterator(
    CIterator* piter)
{
    if (!IsUsable())
        return LK_UNUSABLE;

    IRTLASSERT(piter != NULL);
    IRTLASSERT(piter->m_pht == this);
    IRTLASSERT(-1 <= piter->m_ist
               &&  piter->m_ist <= static_cast<int>(m_cSubTables));

    if (piter == NULL  ||  piter->m_pht != this)
        return LK_BAD_ITERATOR;

    LK_RETCODE lkrc = LK_SUCCESS;

    if (!IsValid())
        lkrc = LK_UNUSABLE;
    else
    {
        // Are we abandoning the iterator before we've reached the end?
        // If so, close the subtable iterator.
        if (piter->m_plht != NULL)
        {
            IRTLASSERT(piter->m_ist < static_cast<int>(m_cSubTables));
            CLHTIterator* pBaseIter = static_cast<CLHTIterator*>(piter);
            piter->m_plht->_CloseIterator(pBaseIter);
        }
    }

    // Unlock all the subtables
    if (piter->m_lkl == LKL_WRITELOCK)
        WriteUnlock();
    else
        ReadUnlock();

    piter->m_plht = NULL;
    piter->m_pht  = NULL;
    piter->m_ist  = -1;

    return lkrc;
} // CLKRHashTable::CloseIterator

#endif // LKR_DEPRECATED_ITERATORS



#ifdef LKR_STL_ITERATORS

//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::Begin
// Synopsis: Make the iterator point to the first record in the hash table.
//------------------------------------------------------------------------

CLKRLinearHashTable::Iterator
CLKRLinearHashTable::Begin()
{
    Iterator iter(this, &_Bucket(0)->m_ncFirst, 0, NODE_BEGIN - NODE_STEP);

    LKR_ITER_TRACE(_TEXT("  LKLH:Begin(it=%p, plht=%p)\n"), &iter, this);
    
    // Let Increment do the hard work of finding the first slot in use.
    iter._Increment(false);

    IRTLASSERT(iter.m_iNode != NODE_BEGIN - NODE_STEP);
    IRTLASSERT(iter == End()  ||  _IsValidIterator(iter));

    return iter;
} // CLKRLinearHashTable::Begin



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable_Iterator::Increment()
// Synopsis: move iterator to next valid record in table
//------------------------------------------------------------------------

bool
CLKRLinearHashTable_Iterator::_Increment(
    bool fDecrementOldValue)
{
    IRTLASSERT(m_plht != NULL);
    IRTLASSERT(m_dwBucketAddr < m_plht->m_cActiveBuckets);
    IRTLASSERT(m_pnc != NULL);
    IRTLASSERT((0 <= m_iNode  &&  m_iNode < NODES_PER_CLUMP)
               || (NODE_BEGIN - NODE_STEP == m_iNode));

    // Release the reference acquired in the previous call to _Increment
    if (fDecrementOldValue)
        _AddRef(-1);

    do
    {
        do
        {
            // find the next slot in the nodeclump that's in use
            while ((m_iNode += NODE_STEP) != NODE_END)
            {
                const void* pvRecord = m_pnc->m_pvNode[m_iNode];

                if (pvRecord != NULL)
                {
                    IRTLASSERT(!m_pnc->InvalidSignature(m_iNode));

                    // Add a new reference
                    _AddRef(+1);

                    LKR_ITER_TRACE(_TEXT("  LKLH:++(this=%p, plht=%p, NC=%p, ")
                                   _TEXT("BA=%u, IN=%d, Rec=%p)\n"),
                                   this, m_plht, m_pnc,
                                   m_dwBucketAddr, m_iNode, pvRecord);

                    return true;
                }
                else // pvRecord == NULL
                {
#if 0 //// #ifdef IRTLDEBUG
                    // Check that all the remaining nodes are empty
                    IRTLASSERT(m_pnc->IsLastClump());

                    for (int i = m_iNode;  i != NODE_END;  i += NODE_STEP)
                    {
                        IRTLASSERT(m_pnc->IsEmptyAndInvalid(i));
                    }
#endif // IRTLDEBUG
                    break; // rest of nodeclump is empty
                }
            }

            // try the next nodeclump in the bucket chain
            m_iNode = NODE_BEGIN - NODE_STEP;
            m_pnc = m_pnc->m_pncNext;

        } while (m_pnc != NULL);

        // Try the next bucket, if there is one
        if (++m_dwBucketAddr < m_plht->m_cActiveBuckets)
        {
            CBucket* pbkt = m_plht->_Bucket(m_dwBucketAddr);
            IRTLASSERT(pbkt != NULL);
            m_pnc = &pbkt->m_ncFirst;
        }

    } while (m_dwBucketAddr < m_plht->m_cActiveBuckets);

    // We have fallen off the end of the hashtable. Set iterator equal
    // to end(), the empty iterator.
    LKR_ITER_TRACE(_TEXT("  LKLH:End(this=%p, plht=%p)\n"), this, m_plht);

    m_plht = NULL;
    m_pnc = NULL;
    m_dwBucketAddr = 0;
    m_iNode = 0;

    //// IRTLASSERT(this->operator==(Iterator())); // == end()

    return false;
} // CLKRLinearHashTable_Iterator::_Increment()



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::Insert
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::Insert(
    const void* pvRecord,
    Iterator&   riterResult,
    bool        fOverwrite)
{
    riterResult = End();

    if (!IsUsable()  ||  pvRecord == NULL)
        return false;
    
    bool fSuccess = (_InsertRecord(pvRecord,
                                  _CalcKeyHash(_ExtractKey(pvRecord)),
                                  fOverwrite,
                                  &riterResult)
                     == LK_SUCCESS);

    IRTLASSERT(riterResult.m_iNode != NODE_BEGIN - NODE_STEP);
    IRTLASSERT(fSuccess
               ?  _IsValidIterator(riterResult)
               :  riterResult == End());

    return fSuccess;
} // CLKRLinearHashTable::Insert()



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::_Erase
// Synopsis:
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::_Erase(
    Iterator& riter,
    DWORD     dwSignature)
{
    CNodeClump* pncCurr, *pncPrev;
    CBucket* const pbkt = riter.m_plht->_Bucket(riter.m_dwBucketAddr);

    LKR_ITER_TRACE(_TEXT("  LKLH:_Erase:pre(iter=%p, plht=%p, NC=%p, ")
                   _TEXT("BA=%u, IN=%d, Sig=%x, Rec=%p)\n"),
                   &riter, riter.m_plht, riter.m_pnc,
                   riter.m_dwBucketAddr, riter.m_iNode, dwSignature,
                   riter.m_pnc ? riter.m_pnc->m_pvNode[riter.m_iNode] : NULL);

    pbkt->WriteLock();

    for (pncCurr = &pbkt->m_ncFirst, pncPrev = NULL;
         pncCurr != NULL;
         pncPrev = pncCurr, pncCurr = pncCurr->m_pncNext)
    {
        if (pncCurr == riter.m_pnc)
            break;
    }
    IRTLASSERT(pncCurr != NULL);

    // Release the iterator's reference on the record
    const void* pvRecord = riter.m_pnc->m_pvNode[riter.m_iNode];
    IRTLASSERT(pvRecord != NULL);
    _AddRefRecord(pvRecord, -1);

    // _DeleteNode will leave iterator members pointing to the
    // preceding record
    int iNode = riter.m_iNode;
    IRTLVERIFY(_DeleteNode(pbkt, riter.m_pnc, pncPrev, iNode));

    if (iNode == NODE_END)
    {
        LKR_ITER_TRACE(_TEXT("\t_Erase(BKT=%p, PNC=%p, PREV=%p, INODE=%d)\n"),
                       pbkt, riter.m_pnc, pncPrev, iNode);
    }
                  
    riter.m_iNode = (short) ((iNode == NODE_END)  ? NODE_END-NODE_STEP : iNode);

    pbkt->WriteUnlock();

    // Don't contract the table. Likely to invalidate the iterator,
    // if iterator is being used in a loop

    return true;
} // CLKRLinearHashTable::_Erase()



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::Erase
// Synopsis:
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::Erase(
    Iterator& riter)
{
    if (!IsUsable()  ||  !_IsValidIterator(riter))
        return false;
    
    DWORD dwSignature = _CalcKeyHash(_ExtractKey(riter.Record()));
    
    LKR_ITER_TRACE(_TEXT("  LKLH:Erase:pre(iter=%p, plht=%p, NC=%p, BA=%u, ")
                   _TEXT("IN=%d, Sig=%x, Rec=%p)\n"),
                   &riter, riter.m_plht, riter.m_pnc, riter.m_dwBucketAddr,
                   riter.m_iNode, dwSignature,
                   riter.m_pnc ? riter.m_pnc->m_pvNode[riter.m_iNode] : NULL);
    
    bool fSuccess = _Erase(riter, dwSignature);
    bool fIncrement = false;
    
    LKR_ITER_TRACE(_TEXT("  LKLH:Erase:post(iter=%p, plht=%p, NC=%p, BA=%u, ")
                   _TEXT("IN=%d, Sig=%x, Rec=%p, Success=%s)\n"),
                   &riter, riter.m_plht, riter.m_pnc, riter.m_dwBucketAddr,
                   riter.m_iNode, dwSignature,
                   riter.m_pnc ? riter.m_pnc->m_pvNode[riter.m_iNode] : NULL,
                   (fSuccess ? "true" : "false"));
    
    // _Erase left riter pointing to the preceding record.
    // Move to next record.
    if (fSuccess)
        fIncrement = riter._Increment(false);

    IRTLASSERT(riter.m_iNode != NODE_BEGIN - NODE_STEP);
    IRTLASSERT(fIncrement  ?  _IsValidIterator(riter)  :  riter == End());
    
    LKR_ITER_TRACE(_TEXT("  LKLH:Erase:post++(iter=%p, plht=%p, NC=%p, ")
                   _TEXT("BA=%u, IN=%d, Sig=%x, Rec=%p)\n"),
                   &riter, riter.m_plht, riter.m_pnc,
                   riter.m_dwBucketAddr, riter.m_iNode, dwSignature,
                   riter.m_pnc ? riter.m_pnc->m_pvNode[riter.m_iNode] : NULL);
    
    return fSuccess;
} // CLKRLinearHashTable::Erase



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::Erase
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::Erase(
    Iterator& riterFirst,
    Iterator& riterLast)
{
    LKR_ITER_TRACE(_TEXT(" LKHT:Erase2(%p, %p)\n"), &riterFirst, &riterLast);

    bool fSuccess;
    int cRecords = 0;

    do
    {
        LKR_ITER_TRACE(_TEXT("\n  LKLH:Erase2(%d, %p)\n"),
                       ++cRecords, &riterFirst);
        fSuccess = Erase(riterFirst);
    } while (fSuccess  &&  riterFirst != End()  &&  riterFirst != riterLast);

    LKR_ITER_TRACE(_TEXT("  LKLH:Erase2: fSuccess = %s\n"),
                   (fSuccess ? "true" : "false"));

    return fSuccess;
} // CLKRLinearHashTable::Erase



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::Find
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::Find(
    DWORD_PTR pnKey,
    Iterator& riterResult)
{
    riterResult = End();

    if (!IsUsable())
        return false;
    
    const void* pvRecord = NULL;
    DWORD       hash_val = _CalcKeyHash(pnKey);
    bool        fFound   = (_FindKey(pnKey, hash_val, &pvRecord, &riterResult)
                            == LK_SUCCESS);

    IRTLASSERT(fFound
               ?  _IsValidIterator(riterResult)  &&  riterResult.Key() == pnKey
               :  riterResult == End());
    IRTLASSERT(riterResult.m_iNode != NODE_BEGIN - NODE_STEP);

    return fFound;
} // CLKRLinearHashTable::Find



//------------------------------------------------------------------------
// Function: CLKRLinearHashTable::EqualRange
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRLinearHashTable::EqualRange(
    DWORD_PTR pnKey,
    Iterator& riterFirst,
    Iterator& riterLast)
{
    LKR_ITER_TRACE(_TEXT("  LKLH:EqualRange: Key=%p)\n"), (void*) pnKey);

    riterLast = End();

    bool fFound = Find(pnKey, riterFirst);

    if (fFound)
    {
        riterLast = riterFirst;
        IRTLASSERT(riterLast != End());

        do
        {
            riterLast._Increment();
        } while (riterLast != End()  &&  riterLast.Key() == pnKey);
    }

    IRTLASSERT(riterFirst.m_iNode != NODE_BEGIN - NODE_STEP);
    IRTLASSERT(fFound ?  _IsValidIterator(riterFirst) :  riterFirst == End());

    IRTLASSERT(riterLast.m_iNode  != NODE_BEGIN - NODE_STEP);
    IRTLASSERT(fFound  ||  riterLast == End());

    return fFound;
} // CLKRLinearHashTable::EqualRange



//------------------------------------------------------------------------
// Function: CLKRHashTable::Begin
// Synopsis: Make the iterator point to the first record in the hash table.
//------------------------------------------------------------------------

CLKRHashTable::Iterator
CLKRHashTable::Begin()
{
    Iterator iter(this, -1);

    LKR_ITER_TRACE(_TEXT(" LKHT:Begin(it=%p, pht=%p)\n"), &iter, this);

    // Let Increment do the hard work of finding the first slot in use.
    iter._Increment(false);

    IRTLASSERT(iter.m_ist != -1);
    IRTLASSERT(iter == End()  ||  _IsValidIterator(iter));

    return iter;
} // CLKRHashTable::Begin



//------------------------------------------------------------------------
// Function: CLKRHashTable_Iterator::_Increment()
// Synopsis: move iterator to next valid record in table
//------------------------------------------------------------------------

bool
CLKRHashTable_Iterator::_Increment(
    bool fDecrementOldValue)
{
    IRTLASSERT(m_pht != NULL);
    IRTLASSERT(-1 <= m_ist
               &&  m_ist < static_cast<int>(m_pht->m_cSubTables));

    for (;;)
    {
        // Do we have a valid iterator into a subtable?  If not, get one.
        while (m_subiter.m_plht == NULL)
        {
            while (++m_ist < static_cast<int>(m_pht->m_cSubTables))
            {
                LKR_ITER_TRACE(_TEXT(" LKHT:++IST=%d\n"), m_ist);
                m_subiter = m_pht->m_palhtDir[m_ist]->Begin();

                if (m_subiter.m_plht != NULL)
                {
                    LKR_ITER_TRACE(_TEXT(" LKHT:++(this=%p, pht=%p, IST=%d, ")
                                   _TEXT("LHT=%p, NC=%p, ")
                                   _TEXT("BA=%u, IN=%d, Rec=%p)\n"),
                                   this, m_pht, m_ist,
                                   m_subiter.m_plht, m_subiter.m_pnc,
                                   m_subiter.m_dwBucketAddr, m_subiter.m_iNode,
                                   m_subiter.m_pnc->m_pvNode[m_subiter.m_iNode]
                                  );
                    return true;
                }
            }
            
            // There are no more subtables left.
            LKR_ITER_TRACE(_TEXT(" LKHT:End(this=%p, pht=%p)\n"), this, m_pht);

            m_pht = NULL;
            m_ist = 0;

            //// IRTLASSERT(this->operator==(Iterator())); // == end()
            
            return false;
        }

        // We already have a valid iterator into a subtable.  Increment it.
        m_subiter._Increment(fDecrementOldValue);

        if (m_subiter.m_plht != NULL)
        {
            LKR_ITER_TRACE(_TEXT(" LKHT:++(this=%p, pht=%p, IST=%d, ")
                           _TEXT("LHT=%p, NC=%p, BA=%u, IN=%d, Rec=%p)\n"),
                           this, m_pht, m_ist,
                           m_subiter.m_plht, m_subiter.m_pnc,
                           m_subiter.m_dwBucketAddr, m_subiter.m_iNode, 
                           m_subiter.m_pnc->m_pvNode[m_subiter.m_iNode]);
            return true;
        }
    }
} // CLKRHashTable_Iterator::_Increment()



//------------------------------------------------------------------------
// Function: CLKRHashTable::Insert
// Synopsis:
//------------------------------------------------------------------------

bool
CLKRHashTable::Insert(
    const void* pvRecord,
    Iterator&   riterResult,
    bool        fOverwrite)
{
    riterResult = End();

    if (!IsUsable()  ||  pvRecord == NULL)
        return false;
    
    DWORD     hash_val  = _CalcKeyHash(_ExtractKey(pvRecord));
    SubTable* const pst = _SubTable(hash_val);

    bool f = (pst->_InsertRecord(pvRecord, hash_val, fOverwrite,
                                 &riterResult.m_subiter)
              == LK_SUCCESS);

    if (f)
    {
        riterResult.m_pht = this;
        riterResult.m_ist = (short) _SubTableIndex(pst);
    }

    IRTLASSERT(riterResult.m_ist != -1);
    IRTLASSERT(f  ?  _IsValidIterator(riterResult)  :  riterResult == End());

    return f;
} // CLKRHashTable::Insert



//------------------------------------------------------------------------
// Function: CLKRHashTable::Erase
// Synopsis:
//------------------------------------------------------------------------

bool
CLKRHashTable::Erase(
    Iterator& riter)
{
    if (!IsUsable()  ||  !_IsValidIterator(riter))
        return false;
    
    DWORD     dwSignature = _CalcKeyHash(_ExtractKey(riter.Record()));
    SubTable* const pst   = _SubTable(dwSignature);

    IRTLASSERT(pst == riter.m_subiter.m_plht);

    if (pst != riter.m_subiter.m_plht)
        return false;

    LKR_ITER_TRACE(_TEXT(" LKHT:Erase:pre(iter=%p, pht=%p, ist=%d, plht=%p, ")
                   _TEXT("NC=%p, BA=%u, IN=%d, Sig=%x, Rec=%p)\n"),
                   &riter, riter.m_pht, riter.m_ist,
                   riter.m_subiter.m_plht, riter.m_subiter.m_pnc,
                   riter.m_subiter.m_dwBucketAddr, riter.m_subiter.m_iNode,
                   dwSignature,
                   (riter.m_subiter.m_pnc ? riter.Record() : NULL));

    // _Erase left riter pointing to the preceding record. Move to
    // next record.
    bool fSuccess = pst->_Erase(riter.m_subiter, dwSignature);
    bool fIncrement = false;

    LKR_ITER_TRACE(_TEXT(" LKHT:Erase:post(iter=%p, pht=%p, ist=%d, plht=%p, ")
                   _TEXT("NC=%p, BA=%u, IN=%d, Sig=%x, Rec=%p, Success=%s)\n"),
                   &riter, riter.m_pht, riter.m_ist,
                   riter.m_subiter.m_plht, riter.m_subiter.m_pnc,
                   riter.m_subiter.m_dwBucketAddr, riter.m_subiter.m_iNode,
                   dwSignature,
                   ((riter.m_subiter.m_pnc && riter.m_subiter.m_iNode >= 0)
                        ? riter.Record() : NULL),
                   (fSuccess ? "true" : "false"));

    if (fSuccess)
        fIncrement = riter._Increment(false);

    IRTLASSERT(riter.m_ist != -1);
    IRTLASSERT(fIncrement  ?  _IsValidIterator(riter)  :  riter  == End());

    LKR_ITER_TRACE(_TEXT(" LKHT:Erase:post++(iter=%p, pht=%p, ist=%d, ")
                   _TEXT("plht=%p, NC=%p, ")
                   _TEXT("BA=%u, IN=%d, Sig=%x, Rec=%p)\n"),
                   &riter, riter.m_pht, riter.m_ist,
                   riter.m_subiter.m_plht, riter.m_subiter.m_pnc,
                   riter.m_subiter.m_dwBucketAddr, riter.m_subiter.m_iNode,
                   dwSignature,
                   (riter.m_subiter.m_pnc ? riter.Record() : NULL));

    return fSuccess;
} // CLKRHashTable::Erase



//------------------------------------------------------------------------
// Function: CLKRHashTable::Erase
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRHashTable::Erase(
    Iterator& riterFirst,
    Iterator& riterLast)
{
    LKR_ITER_TRACE(_TEXT(" LKHT:Erase2(%p, %p)\n"), &riterFirst, &riterLast);

    bool fSuccess;
    int cRecords = 0;

    do
    {
        LKR_ITER_TRACE(_TEXT("\n LKHT:Erase2(%d, %p)\n"),
                       ++cRecords, &riterFirst);
        fSuccess = Erase(riterFirst);
    } while (fSuccess  &&  riterFirst != End()  &&  riterFirst != riterLast);

    LKR_ITER_TRACE(_TEXT(" LKHT:Erase2: fSuccess = %s\n"),
                   (fSuccess ? "true" : "false"));

    return fSuccess;
} // CLKRHashTable::Erase



//------------------------------------------------------------------------
// Function: CLKRHashTable::Find
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRHashTable::Find(
    DWORD_PTR pnKey,
    Iterator& riterResult)
{
    riterResult = End();

    if (!IsUsable())
        return false;
    
    const void* pvRecord = NULL;
    DWORD       hash_val = _CalcKeyHash(pnKey);
    SubTable* const pst  = _SubTable(hash_val);
    bool        fFound   = (pst->_FindKey(pnKey, hash_val, &pvRecord,
                                          &riterResult.m_subiter)
                            == LK_SUCCESS);
    if (fFound)
    {
        riterResult.m_pht = this;
        riterResult.m_ist = (short) _SubTableIndex(pst);
    }

    IRTLASSERT(riterResult.m_ist != -1);
    IRTLASSERT(fFound
               ?  _IsValidIterator(riterResult)  &&  riterResult.Key() == pnKey
               :  riterResult == End());

    return fFound;
} // CLKRHashTable::Find



//------------------------------------------------------------------------
// Function: CLKRHashTable::EqualRange
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRHashTable::EqualRange(
    DWORD_PTR pnKey,
    Iterator& riterFirst,
    Iterator& riterLast)
{
    LKR_ITER_TRACE(_TEXT(" LKHT:EqualRange: Key=%p)\n"), (void*) pnKey);

    riterLast = End();

    bool fFound = Find(pnKey, riterFirst);

    if (fFound)
    {
        riterLast = riterFirst;
        IRTLASSERT(riterLast != End());

        do
        {
            riterLast._Increment();
        } while (riterLast != End()  &&  riterLast.Key() == pnKey);
    }

    IRTLASSERT(riterFirst.m_ist != -1);
    IRTLASSERT(fFound ? _IsValidIterator(riterFirst) : riterFirst == End());

    IRTLASSERT(riterLast.m_ist != -1);
    IRTLASSERT(fFound  ||  riterLast == End());

    return fFound;
} // CLKRHashTable::EqualRange


#endif // LKR_STL_ITERATORS



//------------------------------------------------------------------------
// Function: CLKRHashTable::WriteLock
// Synopsis: Lock all subtables for writing
//------------------------------------------------------------------------

void
CLKRHashTable::WriteLock()
{
    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        m_palhtDir[i]->WriteLock();
        IRTLASSERT(m_palhtDir[i]->IsWriteLocked());
    }
} // CLKRHashTable::WriteLock



//------------------------------------------------------------------------
// Function: CLKRHashTable::ReadLock
// Synopsis: Lock all subtables for reading
//------------------------------------------------------------------------

void
CLKRHashTable::ReadLock() const
{
    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        m_palhtDir[i]->ReadLock();
        IRTLASSERT(m_palhtDir[i]->IsReadLocked());
    }
} // CLKRHashTable::ReadLock



//------------------------------------------------------------------------
// Function: CLKRHashTable::WriteUnlock
// Synopsis: Unlock all subtables
//------------------------------------------------------------------------

void
CLKRHashTable::WriteUnlock() const
{
    // unlock in reverse order: LIFO
    for (DWORD i = m_cSubTables;  i-- > 0;  )
    {
        IRTLASSERT(m_palhtDir[i]->IsWriteLocked());
        m_palhtDir[i]->WriteUnlock();
        IRTLASSERT(m_palhtDir[i]->IsWriteUnlocked());
    }
} // CLKRHashTable::WriteUnlock



//------------------------------------------------------------------------
// Function: CLKRHashTable::ReadUnlock
// Synopsis: Unlock all subtables
//------------------------------------------------------------------------

void
CLKRHashTable::ReadUnlock() const
{
    // unlock in reverse order: LIFO
    for (DWORD i = m_cSubTables;  i-- > 0;  )
    {
        IRTLASSERT(m_palhtDir[i]->IsReadLocked());
        m_palhtDir[i]->ReadUnlock();
        IRTLASSERT(m_palhtDir[i]->IsReadUnlocked());
    }
} // CLKRHashTable::ReadUnlock



//------------------------------------------------------------------------
// Function: CLKRHashTable::IsWriteLocked
// Synopsis: Are all subtables write-locked?
//------------------------------------------------------------------------

bool
CLKRHashTable::IsWriteLocked() const
{
    bool fLocked = (m_cSubTables > 0);
    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        fLocked = fLocked && m_palhtDir[i]->IsWriteLocked();
    }
    return fLocked;
} // CLKRHashTable::IsWriteLocked



//------------------------------------------------------------------------
// Function: CLKRHashTable::IsReadLocked
// Synopsis: Are all subtables read-locked?
//------------------------------------------------------------------------

bool
CLKRHashTable::IsReadLocked() const
{
    bool fLocked = (m_cSubTables > 0);
    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        fLocked = fLocked && m_palhtDir[i]->IsReadLocked();
    }
    return fLocked;
} // CLKRHashTable::IsReadLocked



//------------------------------------------------------------------------
// Function: CLKRHashTable::IsWriteUnlocked
// Synopsis: Are all subtables write-unlocked?
//------------------------------------------------------------------------

bool
CLKRHashTable::IsWriteUnlocked() const
{
    bool fUnlocked = (m_cSubTables > 0);
    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        fUnlocked = fUnlocked && m_palhtDir[i]->IsWriteUnlocked();
    }
    return fUnlocked;
} // CLKRHashTable::IsWriteUnlocked



//------------------------------------------------------------------------
// Function: CLKRHashTable::IsReadUnlocked
// Synopsis: Are all subtables read-unlocked?
//------------------------------------------------------------------------

bool
CLKRHashTable::IsReadUnlocked() const
{
    bool fUnlocked = (m_cSubTables > 0);
    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        fUnlocked = fUnlocked && m_palhtDir[i]->IsReadUnlocked();
    }
    return fUnlocked;
} // CLKRHashTable::IsReadUnlocked



//------------------------------------------------------------------------
// Function: CLKRHashTable::ConvertSharedToExclusive
// Synopsis: Convert the read lock to a write lock
//------------------------------------------------------------------------

void
CLKRHashTable::ConvertSharedToExclusive() const
{
    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        m_palhtDir[i]->ConvertSharedToExclusive();
        IRTLASSERT(m_palhtDir[i]->IsWriteLocked());
    }
} // CLKRHashTable::ConvertSharedToExclusive



//------------------------------------------------------------------------
// Function: CLKRHashTable::ConvertExclusiveToShared
// Synopsis: Convert the write lock to a read lock
//------------------------------------------------------------------------

void
CLKRHashTable::ConvertExclusiveToShared() const
{
    for (DWORD i = 0;  i < m_cSubTables;  i++)
    {
        m_palhtDir[i]->ConvertExclusiveToShared();
        IRTLASSERT(m_palhtDir[i]->IsReadLocked());
    }
} // CLKRHashTable::ConvertExclusiveToShared



//------------------------------------------------------------------------
// Function: CLKRHashTable::Size
// Synopsis: Number of elements in the table
//------------------------------------------------------------------------

DWORD
CLKRHashTable::Size() const
{
    DWORD cSize = 0;

    for (DWORD i = 0;  i < m_cSubTables;  i++)
        cSize += m_palhtDir[i]->Size();

    return cSize;
} // CLKRHashTable::Size



//------------------------------------------------------------------------
// Function: CLKRHashTable::MaxSize
// Synopsis: Maximum possible number of elements in the table
//------------------------------------------------------------------------

DWORD
CLKRHashTable::MaxSize() const
{
    return (m_cSubTables == 0)  ? 0  : m_cSubTables * m_palhtDir[0]->MaxSize();
} // CLKRHashTable::MaxSize



//------------------------------------------------------------------------
// Function: CLKRHashTable::IsValid
// Synopsis: is the table valid?
//------------------------------------------------------------------------

bool
CLKRHashTable::IsValid() const
{
    bool f = (m_lkrcState == LK_SUCCESS     // serious internal failure?
              &&  (m_palhtDir != NULL  &&  m_cSubTables > 0)
              &&  ValidSignature());

    for (DWORD i = 0;  f  &&  i < m_cSubTables;  i++)
        f = f && m_palhtDir[i]->IsValid();

    if (!f)
        m_lkrcState = LK_UNUSABLE;

    return f;
} // CLKRHashTable::IsValid



//------------------------------------------------------------------------
// Function: CLKRHashTable::SetBucketLockSpinCount
// Synopsis: 
//------------------------------------------------------------------------

void
CLKRLinearHashTable::SetBucketLockSpinCount(
    WORD wSpins)
{
    m_wBucketLockSpins = wSpins;

    if (BucketLock::PerLockSpin() != LOCK_INDIVIDUAL_SPIN)
        return;
    
    for (DWORD i = 0;  i < m_cDirSegs;  i++)
    {
        CSegment* pseg = m_paDirSegs[i].m_pseg;

        if (pseg != NULL)
        {
            for (DWORD j = 0;  j < m_dwSegSize;  ++j)
            {
                pseg->Slot(j).SetSpinCount(wSpins);
            }
        }
    }
} // CLKRLinearHashTable::SetBucketLockSpinCount



//------------------------------------------------------------------------
// Function: CLKRHashTable::SetBucketLockSpinCount
// Synopsis: 
//------------------------------------------------------------------------

WORD
CLKRLinearHashTable::GetBucketLockSpinCount() const
{
    return m_wBucketLockSpins;
} // CLKRLinearHashTable::GetBucketLockSpinCount



//------------------------------------------------------------------------
// Function: CLKRHashTable::SetTableLockSpinCount
// Synopsis: 
//------------------------------------------------------------------------

void
CLKRHashTable::SetTableLockSpinCount(
    WORD wSpins)
{
    for (DWORD i = 0;  i < m_cSubTables;  i++)
        m_palhtDir[i]->SetTableLockSpinCount(wSpins);
} // CLKRHashTable::SetTableLockSpinCount



//------------------------------------------------------------------------
// Function: CLKRHashTable::GetTableLockSpinCount
// Synopsis: 
//------------------------------------------------------------------------

WORD
CLKRHashTable::GetTableLockSpinCount() const
{
    return ((m_cSubTables == 0)
            ?  (WORD) LOCK_DEFAULT_SPINS
            :  m_palhtDir[0]->GetTableLockSpinCount());
} // CLKRHashTable::GetTableLockSpinCount



//------------------------------------------------------------------------
// Function: CLKRHashTable::SetBucketLockSpinCount
// Synopsis: 
//------------------------------------------------------------------------

void
CLKRHashTable::SetBucketLockSpinCount(
    WORD wSpins)
{
    for (DWORD i = 0;  i < m_cSubTables;  i++)
        m_palhtDir[i]->SetBucketLockSpinCount(wSpins);
} // CLKRHashTable::SetBucketLockSpinCount



//------------------------------------------------------------------------
// Function: CLKRHashTable::GetBucketLockSpinCount
// Synopsis: 
//------------------------------------------------------------------------

WORD
CLKRHashTable::GetBucketLockSpinCount() const
{
    return ((m_cSubTables == 0)
            ?  (WORD) LOCK_DEFAULT_SPINS
            :  m_palhtDir[0]->GetBucketLockSpinCount());
} // CLKRHashTable::GetBucketLockSpinCount



//------------------------------------------------------------------------
// Function: CLKRHashTable::MultiKeys
// Synopsis: 
//------------------------------------------------------------------------

bool
CLKRHashTable::MultiKeys() const
{
    return ((m_cSubTables == 0)
            ?  false
            :  m_palhtDir[0]->MultiKeys());
} // CLKRHashTable::MultiKeys



#ifndef __LKRHASH_NO_NAMESPACE__
}
#endif // !__LKRHASH_NO_NAMESPACE__
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\_locks.h ===
#define LOCKS_SWITCH_TO_THREAD

extern "C" {

BOOL
Locks_Initialize();

BOOL
Locks_Cleanup();

}; // extern "C"


class CSimpleLock
{
  public:
    CSimpleLock()
        : m_l(0)
    {}

    void Enter()
    {
        while (Lock_AtomicExchange(const_cast<LONG*>(&m_l), 1) != 0)
            Sleep(0);
    }

    void Leave()
    {
        Lock_AtomicExchange(const_cast<LONG*>(&m_l), 0);
    }

    volatile LONG m_l;
};
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\dvt\dvt.cpp ===
// This is the main project file for VC++ application project 
// generated using an Application Wizard.

#include "stdafx.h"

typedef struct _TEST_RECORD
{
    DWORD key;
    DWORD value;
} TEST_RECORD;

const DWORD_PTR WINAPI ExtractKey(const void* pvRecord)
{
    return ((TEST_RECORD*)pvRecord)->key;
}

DWORD WINAPI CalcKeyHash(const DWORD_PTR pnKey)
{
    return (DWORD)pnKey;
}

bool WINAPI EqualKeys(const DWORD_PTR pnKey1, const DWORD_PTR pnKey2)
{
    return (((TEST_RECORD*)pnKey1)->key == ((TEST_RECORD*)pnKey2)->key);
}

void WINAPI AddRefRecord(const void* pvRecord, int nIncr)
{
}


void TC_CLKRLinearHashTable__AllocateSegmentDirectory_Pos()
{
    CLKRLinearHashTable* pHashTable = new CLKRLinearHashTable(
        "HashTest", 
        ExtractKey,
        CalcKeyHash,
        EqualKeys,
        AddRefRecord
        );

    printf("Test case TC_CLKRLinearHashTable__AllocateSegmentDirectory_Pos %s.", (pHashTable != NULL ? "succeeded" :"failed" ));

    if(pHashTable != NULL)
        delete pHashTable;
}

void TC_CLKRLinearHashTable__AllocateSegmentDirectory_Neg_48760()
{
    CLKRLinearHashTable* pHashTable = new CLKRLinearHashTable(
        "HashTest", 
        ExtractKey,
        CalcKeyHash,
        EqualKeys,
        AddRefRecord,
        LK_DFLT_MAXLOAD,
        0xFFFFFFFF
        );

    printf("Test case TC_CLKRLinearHashTable__AllocateSegmentDirectory_Pos %s.", (pHashTable != NULL ? "succeeded" :"failed" ));

    if(pHashTable != NULL)
        delete pHashTable;
}

int __cdecl _tmain()
{
    TC_CLKRLinearHashTable__AllocateSegmentDirectory_Pos();
    TC_CLKRLinearHashTable__AllocateSegmentDirectory_Neg_48760();

	return 0;
}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\dvt\stdafx.h ===
// stdafx.h : include file for standard system include files,
// or project specific include files that are used frequently, but
// are changed infrequently
//

#include <windows.h>
#include <wincrypt.h>
#include <stdio.h>
#include <atlbase.h>

#include <lkrhash.h>
using namespace LKRhash;
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\cache.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "Heap.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control the maximum size of        */
    /*   the cache.                                                     */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MaxCacheSize			  = ((2 << 16)-1);

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new allocation cache and prepare it for use.  A       */
    /*   is inactive until the first request is received at which       */
    /*   time it springs into life.                                     */
    /*                                                                  */
    /********************************************************************/

CACHE::CACHE
		( 
		SBIT32						  NewAllocationSize,
		SBIT32						  NewCacheSize,
		SBIT32						  NewChunkSize,
		SBIT32						  NewPageSize,
		BOOLEAN						  NewStealing,
		THREAD_SAFE					  *NewThreadSafe
		) :
		//
		//   Call the constructors for the contained classes.
		//
		BUCKET( NewAllocationSize,NewChunkSize,NewPageSize )
    {
	//
	//   We need to be very careful with the configuration
	//   information as it has come indirectly from the
	//   user and my be bogus.
	//
	if ( (NewCacheSize >= 0) && (NewCacheSize < MaxCacheSize) )
		{
		//
		//   Setup the cache and mark it as inactive.
		//
		Active = False;
		Stealing = NewStealing;
		ThreadSafe = NewThreadSafe;
#ifdef ENABLE_HEAP_STATISTICS

		CacheFills = 0;
		CacheFlushes = 0;
		HighTide = 0;
		HighWater = 0;
		InUse = 0;
#endif

		CacheSize = ((SBIT16) NewCacheSize);
		FillSize = 1;
		NumberOfChildren = 0;

		//
		//   The stacks that may later contain allocations
		//   are set to zero just to be neat.
		//
		DeleteStack = NULL;
		NewStack = NULL;

		TopOfDeleteStack = 0;
		TopOfNewStack = 0;
		}
	else
		{ Failure( "Cache size in constructor for CACHE" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Create the cache stacks.                                       */
    /*                                                                  */
    /*   A cache is created on demand.  We do this when we get the      */
    /*   first allocation or deallocation request.                      */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::CreateCacheStacks( VOID )
	{
	//
	//   We allocate the cache stacks from the internal
	//   new page allocator if we have not done it already.
	//
	if ( DeleteStack == NULL )
		{
		REGISTER SBIT32 Size = (CacheSize * sizeof(ADDRESS_AND_PAGE));

		DeleteStack = 
			((ADDRESS_AND_PAGE*) (NewPage -> NewCacheStack( Size )));
		}

	if ( NewStack == NULL )
		{
		REGISTER SBIT32 Size = (CacheSize * sizeof(VOID*));

		NewStack = 
			((VOID**) (NewPage -> NewCacheStack( Size )));
		}

	//
	//   We can now activate the cache as long as we 
	//   were able to allocate both stacks.
	//
	if ( (NewStack != NULL ) && (DeleteStack != NULL ) )
		{
		//
		//   We have completed creating the cache so set
		//   various flags and zero various counters.
		//
		Active = True;

		//
		//   Setup the fill size.
		//
		FillSize = 1;

		//
		//   Zero the stack tops.
		//
		TopOfDeleteStack = 0;
		TopOfNewStack = 0;
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Create a new data page.                                        */
    /*                                                                  */
    /*   When we create a new page we also need to allocate some        */
    /*   memory to hold the associated data.                            */
    /*                                                                  */
    /********************************************************************/

VOID *CACHE::CreateDataPage( VOID )
	{
	REGISTER VOID *NewMemory;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Create a data page.
	//
	NewMemory = ((BUCKET*) this) -> New( True );

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return NewMemory;
	}
#ifdef ENABLE_HEAP_STATISTICS

    /********************************************************************/
    /*                                                                  */
    /*   Compute high water.                                            */
    /*                                                                  */
    /*   Compute the high water mark for the current cache.             */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::ComputeHighWater( SBIT32 Size )
	{
	//
	//   Update the usage statistics.
	//
	if ( (InUse += Size) > HighTide )
		{ 
		HighTide = InUse;
		
		if ( HighTide > HighWater )
			{ HighWater = HighTide; }
		}
	}
#endif

    /********************************************************************/
    /*                                                                  */
    /*   A memory deallocation cache.                                   */
    /*                                                                  */
    /*   We cache memory deallocation requests to improve performance.  */
    /*   We do this by stacking requests until we have a batch.         */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::Delete( VOID *Address,PAGE *Page,SBIT32 Version )
	{
	REGISTER BOOLEAN Result;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   At various times the cache may be either disabled
	//   or inactive.  Here we ensure that we are able to use
	//   the cache.  If not we bypass it and call the bucket 
	//   directly.
	//
	if ( Active )
		{
		//
		//   If recycling is allowed and the address is
		//   on the current page or a previous page and
		//   there is space on the new stack then put the
		//   element in the new stack for immediate reuse.
		//
		if 
				(
				(Stealing)
					&&
				(Address < GetCurrentPage())
					&&
				(TopOfNewStack < CacheSize)
				)
			{
			//
			//   The address is suitable for immediate
			//   reuse.  So put it on the stack of new
			//   elements.
			//
			NewStack[ (TopOfNewStack ++) ] = Address;

			Result = True;
			}
		else
			{
			REGISTER ADDRESS_AND_PAGE *Current = 
				(& DeleteStack[ TopOfDeleteStack ++ ]);

			//
			//   The address would best be deleted before
			//   being reused.
			//
			Current -> Address = Address;
			Current -> Page = Page;
			Current -> Version = Version;

			//
			//   When the delete stack is full we flush it.
			//
			if ( TopOfDeleteStack >= CacheSize )
				{
				AUTO SBIT32 Deleted;

				//
				//   Flush the delete stack.
				//
				Result = 
					(
					((BUCKET*) this) -> MultipleDelete
						(
						DeleteStack,
						& Deleted,
						TopOfDeleteStack 
						)
					);
#ifdef ENABLE_HEAP_STATISTICS

				//
				//   Update the usage statistics.  There
				//   is a nasty case here where we cache
				//   a delete only to find out later that
				//   it was bogus.   When this occurs we
				//   have to increase the 'InUse' count 
				//   to allow for this situation.
				//
				CacheFlushes ++;
				
				InUse += (TopOfDeleteStack - Deleted);
#endif

				//
				//   Zero the top of the stack.
				//
				TopOfDeleteStack = 0;
				}
			else
				{ Result = True; }
			}
		}
	else
		{
		//
		//   Delete the element.
		//
		Result = 
			(((BUCKET*) this) -> Delete( Address,Page,Version )); 
		}
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Update the usage statistics.
	//
	if ( Result )
		{ InUse --; }
#endif

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete all allocations.                                        */
    /*                                                                  */
    /*   The entire heap is about to be deleted under our feet.  We     */
    /*   need to prepare for this by disabling the cache as its         */
    /*   contents will disappear as well.                               */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::DeleteAll( VOID )
	{
	//
	//   Disable the cache if needed.
	//
	Active = False;
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Zero the statistics.
	//
	HighTide = 0;
	InUse = 0;
#endif

	//
	//   Setup the fill size.
	//
	FillSize = 1;

	//
	//   Zero the top of stacks.
	//
	TopOfDeleteStack = 0;
	TopOfNewStack = 0;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete a data page.                                            */
    /*                                                                  */
    /*   Delete a data page that was associated with a smaller cache    */
    /*   so its space can be reused.                                    */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::DeleteDataPage( VOID *Address )
	{
	AUTO SEARCH_PAGE Details;
	REGISTER BOOLEAN Result;
	REGISTER PAGE *Page;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Find the description of the data page we need to 
	//   delete and make sure it is valid.
	//
	PrivateFind -> ClaimFindShareLock();

	Page = FindParentPage( Address,PrivateFind );

	if ( Page != NULL )
		{ Page = (Page -> FindPage( Address,& Details,PrivateFind,False )); }

	PrivateFind -> ReleaseFindShareLock();

	//
	//   Delete the data page.
	//
	if ( Page != NULL )
	{ 
		Result = (Page -> Delete( & Details )); 
	}
	else
	{ 
		Result = FALSE; 
		Failure( "No data page in DeleteDataPage" ); 
	}

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find a child page.                                             */
    /*                                                                  */
    /*   Find a child page in the local heap given an address and       */
    /*   the current memory allocation cache.                           */
    /*                                                                  */
    /********************************************************************/

PAGE *CACHE::FindChildPage( VOID *Address,FIND *Find )
	{
	return 
		(
		Find -> FindPage
			( 
			((VOID*) (((BIT32) Address) & ~(GetAllocationSize()-1))),
			(CACHE*) this
			)
		); 
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find a parent page.                                            */
    /*                                                                  */
    /*   Find a parent page in the local heap given an address and      */
    /*   the current memory allocation cache.                           */
    /*                                                                  */
    /********************************************************************/

PAGE *CACHE::FindParentPage( VOID *Address,FIND *Find )
	{
	return 
		(
		Find -> FindPage
			( 
			((VOID*) (((BIT32) Address) & ~(GetPageSize()-1))),
			ParentCache
			)
		); 
	}

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory allocations.                                   */
    /*                                                                  */
    /*   The allocation cache contains preallocated memory from the     */
    /*   associated allocation bucket.  The cache will supply these     */
    /*   preallocated elements with the minimum fuss to any caller.     */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::MultipleNew( SBIT32 *Actual,VOID *Array[],SBIT32 Requested )
	{
	REGISTER BOOLEAN Result;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   At various times the cache may be either disabled
	//   or inactive.  Here we ensure that we are able to use
	//   the cache.  If not we bypass it and call the bucket 
	//   directly.
	//
	if ( Active )
		{
		//
		//   We have been asked to allocalte multiple
		//   new elements.  If it appears that we don't  
		//   have enough elements available but stealing 
		//   is allowed we can try raiding the deleted 
		//   stack.
		//
		if ( (Requested > TopOfNewStack) && (Stealing) )
			{
			while ( (TopOfDeleteStack > 0) && (TopOfNewStack < CacheSize) )
				{
				NewStack[ (TopOfNewStack ++) ] = 
					(DeleteStack[ (-- TopOfDeleteStack) ].Address);
				}
			}

		//
		//   We will allocate from the cache if requested 
		//   size is smaller than the number of available 
		//   elements.
		//
		if ( Requested <= TopOfNewStack )
			{
			REGISTER SBIT32 Count;

			//
			//   We need to copy the elements out of the
			//   cache into the callers array.
			//
			for ( Count=0;Count < Requested;Count ++ )
				{ Array[ Count ] = NewStack[ (-- TopOfNewStack) ]; }

			(*Actual) = Requested;

			Result = True;
			}
		else
			{
			REGISTER BUCKET *Bucket = ((BUCKET*) this);

			//
			//   We don't have enough elements in the cache 
			//   so we allocate directly from the bucket.
			//
			Result =
				(
				Bucket -> MultipleNew
					( 
					Actual,
					Array,
					Requested
					)
				);

			//
			//   We fill up the cache so we have a good 
			//   chance of dealing with any following 
			//   requests if it is less than half full.
			//
			if ( TopOfNewStack <= (CacheSize / 2) )
				{
				AUTO SBIT32 NewSize;
				REGISTER SBIT32 MaxSize = (CacheSize - TopOfNewStack);

				//
				//   We slowly increse the fill size
				//   of the cache to make sure we don't
				//   waste too much space.
				//
				if ( FillSize < CacheSize )
					{
					if ( (FillSize *= 2) > CacheSize )
						{ FillSize = CacheSize; }
					}

				//
				//   Bulk load the cache with new
				//   elements.
				//
				Bucket -> MultipleNew
					( 
					& NewSize, 
					& NewStack[ TopOfNewStack ],
					((FillSize < MaxSize) ? FillSize : MaxSize)
					);
#ifdef ENABLE_HEAP_STATISTICS

				CacheFills ++;
#endif
				TopOfNewStack += NewSize;
				}
			}
		}
	else
		{
		//
		//   We may want to enable the cache for next
		//   time so see if this needs to be done.
		//
		if ( CacheSize > 1 )
			{ CreateCacheStacks(); }

		//
		//   The cache is disabled so go directly to the
		//   bucket.
		//
		Result = ((BUCKET*) this) -> MultipleNew
			( 
			Actual,
			Array,
			Requested
			);
		}
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Update the usage statistics.
	//
	ComputeHighWater( (*Actual) );
#endif

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Memory allocation.                                             */
    /*                                                                  */
    /*   The allocation cache contains preallocated memory from the     */
    /*   associated allocation bucket.  The cache will supply these     */
    /*   preallocated elements with the minimum fuss to any caller.     */
    /*                                                                  */
    /********************************************************************/

VOID *CACHE::New( VOID )
	{
	REGISTER VOID *NewMemory;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   At various times the cache may be either disabled
	//   or inactive.  Here we ensure that we are able to use
	//   the cache.  If not we bypass it and call the bucket 
	//   directly.
	//
	if ( Active )
		{
		//
		//   We first try the stack for new allocations
		//   to see if there are any available elements.
		//
		if ( TopOfNewStack > 0 )
			{ NewMemory = (NewStack[ (-- TopOfNewStack) ]); }
		else
			{
			//
			//   When stealing is allowed we will recycle
			//   elements from the top of the deleted stack.
			//
			if ( (TopOfDeleteStack > 0) && (Stealing) )
				{ NewMemory = (DeleteStack[ (-- TopOfDeleteStack) ].Address); }
			else
				{
				//
				//   We slowly increse the fill size
				//   of the cache to make sure we don't
				//   waste too much space.
				//
				if ( FillSize < CacheSize )
					{
					if ( (FillSize *= 2) > CacheSize )
						{ FillSize = CacheSize; }
					}

				//
				//   We need to bulk load some new  
				//   memory from the heap.
				//
				if 
						( 
						((BUCKET*) this) -> MultipleNew
							( 
							& TopOfNewStack,
							NewStack,
							FillSize
							) 
						)
					{
					//
					//   Update the statistics and return
					//   the top element on the stack.
					//
#ifdef ENABLE_HEAP_STATISTICS
					CacheFills ++;
#endif
					NewMemory = NewStack[ (-- TopOfNewStack) ]; 
					}
				else
					{
					//
					//   Update the statistics and fail
					//   the request for memeory.
					//
					NewMemory = ((VOID*) AllocationFailure);
					}
				}
			}
		}
	else
		{ 
		//
		//   We may want to enable the cache for next
		//   time so see if this needs to be done.
		//
		if ( CacheSize > 1 )
			{ CreateCacheStacks(); }

		//
		//   The cache is disabled so go directly to the
		//   bucket.
		//
		NewMemory = ((BUCKET*) this) -> New( False ); 
		}
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Update the usage statistics.
	//
	ComputeHighWater( (NewMemory != ((VOID*) AllocationFailure)) );
#endif

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	//
	//   Prefetch the first cache line if we are running
	//   a Pentium III or better.
	//
	Prefetch.L1( ((CHAR*) NewMemory),1 );

	return NewMemory;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Memory allocation for non-standard sizes.                      */
    /*                                                                  */
    /*   A non standard sized allocation simply by-passes the cache     */
    /*   but it still needs to hold the lock to prevent failure on      */
    /*   SMP systems.                                                   */
    /*                                                                  */
    /********************************************************************/

VOID *CACHE::New( BOOLEAN SubDivided,SBIT32 NewSize )
	{
	REGISTER VOID *NewMemory;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Allocate a non-standard sized block.
	//
	NewMemory = ((BUCKET*) this) -> New( SubDivided,NewSize );
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Update the usage statistics.
	//
	ComputeHighWater( (NewMemory != ((VOID*) AllocationFailure)) );
#endif

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return NewMemory;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release free space.                                            */
    /*                                                                  */
    /*   We sometimes do not release free space from a bucket as        */
    /*   returning it to the operating system and getting it again      */
    /*   later is very expensive.  Here we flush any free space we      */
    /*   have aquired over the user supplied limit.                     */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::ReleaseSpace( SBIT32 MaxActivePages )
	{
	//
	//   When there is a potential for multiple threads 
	//   we claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Release the free space from the backet.
	//
	((BUCKET*) this) -> ReleaseSpace( MaxActivePages );

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   Search the cacahe for an allocation.                           */
    /*                                                                  */
    /*   We sometimes need to search the cache to see if an             */
    /*   allocation is currently in the cacahe awaiting allocation      */
    /*   or release.                                                    */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::SearchCache( VOID *Address )
	{
	REGISTER BOOLEAN Result = False;

	//
	//   We check to see if the cache is active.
	//
	if ( Active )
		{
		//
		//   When there is a potential for multiple 
		//   threads we claim the cache lock.
		//
		ClaimCacheLock();

		//
		//   We check to see if the cache is still 
		//   active.
		//
		if ( Active )
			{
			REGISTER SBIT32 Count;

			//
			//   Search the allocated cache.
			//
			for ( Count=(TopOfNewStack-1);Count >= 0;Count -- )
				{ 
				if ( Address == NewStack[ Count ] )
					{
					Result = True;
					break;
					}
				}

			//
			//   If it has not been found yet then try
			//   the deleted cache.
			//
			if ( ! Result )
				{
				//
				//   Search the deleted cache.
				//
				for ( Count=(TopOfDeleteStack-1);Count >= 0;Count -- )
					{ 
					if ( Address == DeleteStack[ Count ].Address )
						{
						Result = True;
						break;
						}
					}
				}
			}

		//
		//   Release any lock we may have claimed earlier.
		//
		ReleaseCacheLock();
		}

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Truncate the heap.                                             */
    /*                                                                  */
    /*   Flush the cache to release the maximum amount of space back    */
    /*   to the operating system.  This is slow but may be very         */
    /*   valuable in some situations.                                   */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::Truncate( VOID )
	{
	REGISTER BOOLEAN Result = True;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Disable the cache if needed.
	//
	Active = False;

	//
	//   Setup the fill size.
	//
	FillSize = 1;

	//
	//   Flush any elements in the delete cache.
	//   We do this now because we need to use 
	//   the delete cache below.
	//
	if ( TopOfDeleteStack > 0 )
		{
		AUTO SBIT32 Deleted;

		//
		//   Flush the delete stack.
		//
		Result = 
			(
			((BUCKET*) this) -> MultipleDelete
				(
				DeleteStack,
				& Deleted,
				TopOfDeleteStack 
				)
				&&
			(Result)
			);
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Update the usage statistics.  There
		//   is a nasty case here where we cache
		//   a delete only to find out later that
		//   it was bogus.   When this occurs we
		//   have to increase the 'InUse' count 
		//   to allow for this situation.
		//
		CacheFlushes ++;
		
		InUse += (TopOfDeleteStack - Deleted);
#endif
		
		//
		//   Zero the top of the stack.
		//
		TopOfDeleteStack = 0;
		}
	
	//
	//   Flush any elements in the new cache by
	//   copying them over to the delete cache
	//   and adding the additional information
	//   required.
	//
	if ( TopOfNewStack > 0 )
		{
		//
		//   We need to find the data page for each  
		//   allocation we have in the new cache.
		//   Claim the lock here to make things a
		//   little more efficient.
		//
		PrivateFind -> ClaimFindShareLock();

		//
		//   We copy each allocation across and 
		//   add the associated page information.
		//
		for ( TopOfNewStack --;TopOfNewStack >= 0;TopOfNewStack -- )
			{
			REGISTER VOID *Address = 
				(NewStack[ TopOfNewStack ]);
			REGISTER PAGE *Page = 
				(ParentCache -> FindChildPage( Address,PrivateFind ));

			//
			//   You would think that any memory in the
			//   new cache had to be valid.   Well it
			//   does except in the case when we have
			//   'Recycle' set and somebody does a double
			//   delete on a valid heap address.
			//
			if ( Page != NULL )
				{
				REGISTER ADDRESS_AND_PAGE *Current = 
					(& DeleteStack[ TopOfDeleteStack ++ ]);

				//
				//   We need to find the allocation page
				//   where the memory was allocated from
				//   so we can delete it.
				//
				Current -> Address = Address;
				Current -> Page = Page;
				Current -> Version = Page -> GetVersion();
				}
			else
				{ 
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   Update the usage statistics.  There
				//   is a nasty case here where we cache
				//   a delete only to find out later that
				//   it was bogus.   When this occurs we
				//   have to increase the 'InUse' count 
				//   to allow for this situation.
				//
				InUse ++;

#endif
				Result = False; 
				}
			}

		//
		//   Release the lock.
		//
		PrivateFind -> ReleaseFindShareLock();
		}

	//
	//   Flush the delete cache again to delete
	//   any new elements that we added to it
	//   above.
	//
	if ( TopOfDeleteStack > 0 )
		{
		AUTO SBIT32 Deleted;

		//
		//   Flush the delete stack.
		//
		Result = 
			(
			((BUCKET*) this) -> MultipleDelete
				(
				DeleteStack,
				& Deleted,
				TopOfDeleteStack 
				)
				&&
			(Result)
			);
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Update the usage statistics.  There
		//   is a nasty case here where we cache
		//   a delete only to find out later that
		//   it was bogus.   When this occurs we
		//   have to increase the 'InUse' count 
		//   to allow for this situation.
		//
		CacheFlushes ++;
		
		InUse += (TopOfDeleteStack - Deleted);
#endif
		
		//
		//   Zero the top of the stack.
		//
		TopOfDeleteStack = 0;
		}

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Update the bucket information.                                 */
    /*                                                                  */
    /*   When we create the bucket there is some information that       */
    /*   is not available.  Here we update the bucket to make sure      */
    /*   it has all the data it needs.                                  */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::UpdateCache
		( 
		HEAP						  *NewHeap,
		NEW_PAGE					  *NewPages,
		CACHE						  *NewParentCache,
		FIND						  *NewPrivateFind,
		FIND						  *NewPublicFind
		)
	{
	//
	//   Notify the parent cache that it has a new
	//   child.
	//
	if ( NewParentCache != ((CACHE*) GlobalRoot) )
		{ NewParentCache -> NumberOfChildren ++; }

	//
	//   Update the allocation bucket.
	//
	UpdateBucket
		( 
		NewHeap,
		NewPages,
		NewParentCache, 
		NewPrivateFind,
		NewPublicFind
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the cache and ensure it is disabled.                   */
    /*                                                                  */
    /********************************************************************/

CACHE::~CACHE( VOID )
	{
	if ( Active )
		{ Failure( "Cache active in destructor for CACHE" ); }
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\bucket.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Bucket.hpp"
#include "Cache.hpp"
#include "Heap.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here relate the compuation of the       */
    /*   current active page address range.                             */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 HighestAddress			  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new allocation bucket and prepare it for use.         */
    /*   We need to be sure to carefully check everything we have       */
    /*   been supplied as it has come indirectly from the user.         */
    /*                                                                  */
    /********************************************************************/

BUCKET::BUCKET
		( 
		SBIT32						  NewAllocationSize,
		SBIT32						  NewChunkSize,
		SBIT32						  NewPageSize 
		)
    {
	//
	//   We want to make sure that the bucket configuration
	//   appears to make basic sense.  If not we have no 
	//   alternative than to throw an expection.
	//
	if
			(
			(NewAllocationSize > 0)
				&&
			(NewChunkSize >= NewAllocationSize)
				&&
			(NewChunkSize <= NewPageSize)
				&&
			PowerOfTwo( NewPageSize )
			)
		{
		//
		//   Create the bucket and prepare it for use.
		//   Pre-compute any information we can here to
		//   save work later.
		//
		AllocationSize = NewAllocationSize;
		ChunkSize = NewChunkSize;
		PageSize = NewPageSize;

		ActivePages = 0;
		AllocationShift = 0;
		ChunkShift = 0;

		//
		//   Compute the optimization level from the available
		//   bucket information.  The highest level means
		//   everything is a power of two (just shifts - yipee !!).
		//   The next means no chunks (i.e. simple scaling), The
		//   next means simple chunks (i.e. complex scaling).
		//   The final alternative is to horrid to discuss. 
		//   
		if ( ConvertDivideToShift( AllocationSize,& AllocationShift ) )
			{
			//
			//   If we are not using chunking we can skip the
			//   extra compuation that is needed.  We can tell
			//   this is the case if the chunk size and the page
			//   size match or if the chunk size is a multiple
			//   of the allocation size.
			//
			if 
					( 
					(ChunkSize == PageSize)
						||
					((ChunkSize % AllocationSize) == 0)
					)
				{
				//
				//   The best case is when we can use shifts
				//   instead of multiply and divide.
				//
				ComputeAddressFunction = ComputeAddressBestCase;
				ComputeOffsetFunction = ComputeOffsetBestCase;
				}
			else
				{
				//
				//   When we have chunks we have to do more 
				//   work invloving additional multiples and
				//   divides.  Nonetheless, we try to minimize
				//   these as far as possible.
				// 
				if ( ConvertDivideToShift( ChunkSize,& ChunkShift ) )
					{
					//
					//   We have managed to replace some of the
					//   multiplies and divides with shifts.
					//
					ComputeAddressFunction = ComputeAddressPoorCase;
					ComputeOffsetFunction = ComputeOffsetPoorCase;
					}
				else
					{
					//
					//   We are unable to optimize this case.
					//   These calls will really hurt.
					//
					ComputeAddressFunction = ComputeAddressWorstCase;
					ComputeOffsetFunction = ComputeOffsetWorstCase;
					}
				}
			}
		else
			{
			//
			//   If we are not using chunking we can skip the
			//   extra compuation that is needed.  We can tell
			//   this is the case if the chunk size and the page
			//   size match or if the chunk size is a multiple
			//   of the allocation size.
			//
			if 
					( 
					(ChunkSize == PageSize)
						||
					((ChunkSize % AllocationSize) == 0)
					)
				{ 
				//
				//   A good case is when we can use a few
				//   simple multiplies and divides to do simple
				//   scaling.
				//
				ComputeAddressFunction = ComputeAddressGoodCase;
				ComputeOffsetFunction = ComputeOffsetGoodCase;
				}
			else
				{ 
				//
				//   When we have chunks we have to do more 
				//   work invloving additional multiples and
				//   divides.  Nonetheless, we try to minimize
				//   these as far as possible.
				// 
				if ( ConvertDivideToShift( ChunkSize,& ChunkShift ) )
					{
					//
					//   We have managed to replace some of the
					//   multiplies and divides with shifts.
					//
					ComputeAddressFunction = ComputeAddressPoorCase;
					ComputeOffsetFunction = ComputeOffsetPoorCase;
					}
				else
					{
					//
					//   We are unable to optimize this case.
					//   These calls will really hurt.
					//
					ComputeAddressFunction = ComputeAddressWorstCase;
					ComputeOffsetFunction = ComputeOffsetWorstCase;
					}
				}
			}

		//
		//   Compute all the information that will be
		//   needed later to describe the allocation
		//   pages.
		//
		NumberOfElements = 
			((SBIT16) ((PageSize / ChunkSize) * (ChunkSize / AllocationSize)));
		SizeOfChunks = (SBIT16)
			((SBIT16) (ChunkSize / AllocationSize));
		SizeOfElements = (SBIT16)
			((SBIT16) (((NumberOfElements-1) / OverheadBitsPerWord) + 1));
		SizeKey = NoSizeKey;
		}
	else
		{ Failure( "Configuration in constructor for BUCKET" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the allocation address.                                */
    /*                                                                  */
    /*   Compute the allocation address given the page address and      */
    /*   the vector offset in the page.                                 */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::ComputeAddressBestCase( CHAR *Address,SBIT32 Offset )
	{ return ((VOID*) (Address + (Offset << AllocationShift))); }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the allocation address.                                */
    /*                                                                  */
    /*   Compute the allocation address given the page address and      */
    /*   the vector offset in the page.                                 */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::ComputeAddressGoodCase( CHAR *Address,SBIT32 Offset )
	{ return ((VOID*) (Address + (Offset * AllocationSize))); }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the allocation address.                                */
    /*                                                                  */
    /*   Compute the allocation address given the page address and      */
    /*   the vector offset in the page.                                 */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::ComputeAddressPoorCase( CHAR *Address,SBIT32 Offset )
	{
	REGISTER SBIT32 ChunkNumber = (Offset / SizeOfChunks);
	REGISTER SBIT32 ChunkOffset = (ChunkNumber * SizeOfChunks);
	REGISTER SBIT32 AllocationNumber = (Offset - ChunkOffset);

	return
		((VOID*)
			(
			Address 
				+
			(ChunkNumber << ChunkShift)
				+
			(AllocationNumber * AllocationSize)
			)
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the allocation address.                                */
    /*                                                                  */
    /*   Compute the allocation address given the page address and      */
    /*   the vector offset in the page.                                 */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::ComputeAddressWorstCase( CHAR *Address,SBIT32 Offset )
	{
	REGISTER SBIT32 ChunkNumber = (Offset / SizeOfChunks);
	REGISTER SBIT32 ChunkOffset = (ChunkNumber * SizeOfChunks);
	REGISTER SBIT32 AllocationNumber = (Offset - ChunkOffset);

	return
		((VOID*)
			(
			Address 
				+
			(ChunkNumber * ChunkSize)
				+
			(AllocationNumber * AllocationSize)
			)
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the bit vector offset.                                 */
    /*                                                                  */
    /*   Compute the bit vector offset given the address of the         */
    /*   memory allocation in the page.                                 */
    /*                                                                  */
    /********************************************************************/

SBIT32 BUCKET::ComputeOffsetBestCase( SBIT32 Displacement,BOOLEAN *Found )
	{
	REGISTER SBIT32 ArrayOffset = (Displacement >> AllocationShift);

	(*Found) = (Displacement == (ArrayOffset << AllocationShift));
#ifdef DEBUGGING

	if ( ArrayOffset >= NumberOfElements )
		{ Failure( "Array offset in ComputeOffsetBestCase" ); }
#endif

	return ArrayOffset;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the bit vector offset.                                 */
    /*                                                                  */
    /*   Compute the bit vector offset given the address of the         */
    /*   memory allocation in the page.                                 */
    /*                                                                  */
    /********************************************************************/

SBIT32 BUCKET::ComputeOffsetGoodCase( SBIT32 Displacement,BOOLEAN *Found )
	{
	REGISTER SBIT32 ArrayOffset = (Displacement / AllocationSize);

	(*Found) = (Displacement == (ArrayOffset * AllocationSize));
#ifdef DEBUGGING

	if ( ArrayOffset >= NumberOfElements )
		{ Failure( "Array offset in ComputeOffsetGoodCase" ); }
#endif

	return ArrayOffset;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the bit vector offset.                                 */
    /*                                                                  */
    /*   Compute the bit vector offset given the address of the         */
    /*   memory allocation in the page.                                 */
    /*                                                                  */
    /********************************************************************/

SBIT32 BUCKET::ComputeOffsetPoorCase( SBIT32 Displacement,BOOLEAN *Found )
	{
	REGISTER SBIT32 ArrayOffset;
	REGISTER SBIT32 ChunkNumber = (Displacement >> ChunkShift);
	REGISTER SBIT32 ChunkAddress = (ChunkNumber << ChunkShift);
	REGISTER SBIT32 ChunkOffset = (Displacement - ChunkAddress);
	REGISTER SBIT32 AllocationNumber = (ChunkOffset / AllocationSize);

	ArrayOffset = ((ChunkNumber * SizeOfChunks) + AllocationNumber);

	(*Found) = 
		(
		(Displacement) 
			== 
		(ChunkAddress + (AllocationNumber * AllocationSize))
		);
#ifdef DEBUGGING

	if ( ArrayOffset >= NumberOfElements )
		{ Failure( "Array offset in ComputeOffsetPoorCase" ); }
#endif

	return ArrayOffset;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the bit vector offset.                                 */
    /*                                                                  */
    /*   Compute the bit vector offset given the address of the         */
    /*   memory allocation in the page.                                 */
    /*                                                                  */
    /********************************************************************/

SBIT32 BUCKET::ComputeOffsetWorstCase( SBIT32 Displacement,BOOLEAN *Found )
	{
	REGISTER SBIT32 ArrayOffset;
	REGISTER SBIT32 ChunkNumber = (Displacement / ChunkSize);
	REGISTER SBIT32 ChunkAddress = (ChunkNumber * ChunkSize);
	REGISTER SBIT32 ChunkOffset = (Displacement - ChunkAddress);
	REGISTER SBIT32 AllocationNumber = (ChunkOffset / AllocationSize);

	ArrayOffset = ((ChunkNumber * SizeOfChunks) + AllocationNumber);

	(*Found) = 
		(
		(Displacement) 
			== 
		(ChunkAddress + (AllocationNumber * AllocationSize))
		);
#ifdef DEBUGGING

	if ( ArrayOffset >= NumberOfElements )
		{ Failure( "Array offset in ComputeOffsetWorstCase" ); }
#endif

	return ArrayOffset;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete a memory allocation.                                    */
    /*                                                                  */
    /*   We need to delete a single memory allocation from a bucket.    */
    /*   We do this by passing the request on to the page.              */
    /*                                                                  */
    /********************************************************************/

BOOLEAN BUCKET::Delete( VOID *Address,PAGE *Page,SBIT32 Version )
	{
	AUTO SEARCH_PAGE Details;

	//
	//   When we delete an allocation we need to ensure 
	//   the page has not radically changed since we found
	//   it.  Hence, we compare the current page version  
	//   number with the one we found earlier.  If all is 
	//   well we get the details relating to the allocation
	//   and then delete it.
	//
	return
		(
		((Page -> GetVersion()) == Version)
			&&
		(Page -> FindPage( Address,& Details,PrivateFind,False ) != NULL)
			&&
		(Page -> Delete( & Details ))
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete a page from the bucket list.                            */
    /*                                                                  */
    /*   When a page becomes full it is removed from the bucket list    */
    /*   so it will be no longer inspected when looking for free space. */
    /*                                                                  */
    /********************************************************************/

VOID BUCKET::DeleteFromBucketList( PAGE *Page )
	{
	//
	//   We keep track of the number of active pages on the 
	//   bucket list.  This helps us when we need to scan the
	//   bucket list for some reason later.
	//
	if ( (-- ActivePages) >= 0 )
		{
		//
		//   Delete the page from the bucket list as it is 
		//   no longer needed.  There are two cases when this 
		//   happens.  When the page is full and when the page 
		//   is about to be deleted.
		//
		Page -> DeleteFromBucketList( & BucketList );

		//
		//   Compute the highest address on the first page.  We 
		//   use this information to figure out whether to 
		//   recycle an allocation or pass it along for deletion
		//   in the cache.
		//
		Page = (PAGE::FirstInBucketList( & BucketList ));
		
		if ( ! Page -> EndOfBucketList() )
			{
			CurrentPage =
				(
				((VOID*) (((LONG) Page -> GetAddress()) + (PageSize - 1)))
				);
			}
		else
			{ CurrentPage = ((VOID*) HighestAddress); }
		}
	else
		{ Failure( "Active page count in DeleteFromBucketList" ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Insert a page into the bucket list.                            */
    /*                                                                  */
    /*   When a page is created or when it changes from being full      */
    /*   to having at least one free slot it is added to the bucket     */
    /*   list so that it can be used to allocate space.                 */
    /*                                                                  */
    /********************************************************************/

VOID BUCKET::InsertInBucketList( PAGE *Page )
	{
	//
	//   We keep track of the number of active pages on the 
	//   bucket list.  This helps us when we need to scan the
	//   bucket list for some reason later.
	//
	ActivePages ++;

	//
	//   We insert pages into the list in ascending address
	//   order.  This ensures that we always allocate the 
	//   lowest addresses first.  This is done to try to keep 
	//   the working set small and compact.
	//
	if ( ! BucketList.EndOfList() )
		{
		REGISTER VOID *Address = (Page -> GetAddress());
		REGISTER PAGE *Last = (Page -> LastInBucketList( & BucketList ));

		//
		//   We are about to walk the entire page list
		//   trying to find where to insert this page.
		//   Lets see if the page needs to be inserted
		//   at the end of the list.  If so have saved
		//   ourseleves a lot of work and we can exit 
		//   early.
		//   
		if ( Address < (Last -> GetAddress()) )
			{
			REGISTER PAGE *Current;

			//
			//   Well it looks like we need to walk along 
			//   the entire page list to find the correct 
			//   place to insert this element.
			//
			for 
					( 
					Current = (Page -> FirstInBucketList( & BucketList ));
					! Current -> EndOfBucketList();
					Current = Current -> NextInBucketList() 
					)
				{
				//
				//   While the current address is lower 
				//   than ours we need to keep on walking.
				//
				if ( Address < (Current -> GetAddress()) )
					{
					//
					//   We have found the spot so insert 
					//   the bucket just before the current 
					//   bucket.
					//
					Current -> InsertBeforeInBucketList( & BucketList,Page );

					break;
					}
				}
			}
		else
			{
			//
			//   The page has the highest address so insert
			//   it at the end of the list.
			//
			Last -> InsertAfterInBucketList( & BucketList,Page );
			}
		}
	else
		{ Page -> InsertInBucketList( & BucketList ); }

	//
	//   Compute the highest address on the first page.  We can
	//   use this information to figure out whether to recycle an
	//   allocation or pass it along for deletion in the cache.
	//
	Page = (PAGE::FirstInBucketList( & BucketList ));
	
	CurrentPage =
		(
		((VOID*) (((LONG) Page -> GetAddress()) + (PageSize - 1)))
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory deallocations.                                 */
    /*                                                                  */
    /*   When the delete cache becomes full we complete any pending     */
    /*   delete requests.  We also flush the delete cache when if       */
    /*   we need to allocate additional memory unless recycling is      */
    /*   enabled in which case we just steal it directly from the       */
    /*   delete cache.                                                  */
    /*                                                                  */
    /********************************************************************/

BOOLEAN BUCKET::MultipleDelete
		( 
		ADDRESS_AND_PAGE			  *Array,
		SBIT32						  *Deleted,
		SBIT32						  Size 
		)
	{
	AUTO SEARCH_PAGE Details;
	REGISTER SBIT32 Count;

	//
	//   Zero the count of deleted items.
	//
	(*Deleted) = 0;

	//
	//   Delete each element one at a time.  We would love to
	//   delete them all at once but we haven't got a clue where
	//   they have come from so we have to do it one at a time. 
	//   
	for ( Count=0;Count < Size;Count ++ )
		{
		REGISTER ADDRESS_AND_PAGE *Current = & Array[ Count ];
		REGISTER VOID *Address = Current -> Address;
		REGISTER PAGE *Page = Current -> Page;

		//
		//   It may see like a waste of time to batch up all
		//   the deletions.  Why not do them as they arrive.
		//   There are a number of reasons.  The deletes can
		//   be recycled, batchs of deletes is faster than
		//   single deletes (due to cache effects) and so on.
		//
		if
				(
				(Current -> Version == Page -> GetVersion())
					&&
				(Page -> FindPage( Address,& Details,PrivateFind,False ) != NULL)
					&&
				(Page -> Delete( & Details ))
				)
			{ (*Deleted) ++; }
		}

	return ((*Deleted) == Size);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory allocations.                                   */
    /*                                                                  */
    /*   We need to make a multiple memory allocation from this			*/
    /*   bucket so walk the bucket list allocating any available        */
    /*   space and return it to the caller.                             */
    /*                                                                  */
    /********************************************************************/

BOOLEAN BUCKET::MultipleNew
		( 
		SBIT32						  *Actual,
		VOID						  *Array[],
		SBIT32						  Requested 
		)
    {
	//
	//   Zero the count of allocated elements.
	//
	(*Actual) = 0;

	//
	//   We walk the sorted list of pages with available
	//   allocations searching for elements to allocate.
	//
	do
		{
		REGISTER PAGE *Page;
		REGISTER PAGE *NextPage;

		//
		//   Walk the bucket list looking for any available
		//   free space.
		//
		for 
				( 
				Page = (PAGE::FirstInBucketList( & BucketList ));
				! Page -> EndOfBucketList();
				Page = NextPage
				)
			{
			REGISTER SBIT32 ActualSize = (Page -> GetPageSize());

			//
			//   Lets find the next page now as the current 
			//   bucket may be removed from the bucket list
			//   by the following allocation call.
			//
			NextPage = Page -> NextInBucketList();

			//
			//   We allow the page size to be dynamically
			//   modified to support a variety of wierd
			//   data layouts for BBT.   If the current page
			//   is not the standard size then skip it.
			//
			if ( (ActualSize == NoSize) || (ActualSize == PageSize) )
				{
				//
				//   We try allocate all the space we need 
				//   from each page in the bucket list.  If 
				//   the page has enough space we can exit 
				//   early if not we go round the loop and
				//   try the next page.
				//
				if ( Page -> MultipleNew( Actual,Array,Requested ) )
					{ return True; }
				}
			}
		}
	while 
		( 
		NewPage -> CreatePage( (CACHE*) this )
			!= 
		((PAGE*) AllocationFailure) 
		);

	//
	//   We see if we managed to allocate all the elements
	//   we wanted.  If so we are happy and we can get out 
	//   of here.
	//
	if ( (*Actual) < Requested )
		{
		//
		//   We see if we managed to allocate any elements 
		//   at all.  If not we fail the request.
		//
		if ( (*Actual) > 0 )
			{
			REGISTER SBIT32 Count;
			REGISTER SBIT32 Delta = ((Requested) - (*Actual));

			//
			//   We are very naughty when we allocate multiple
			//   elements in that we put them in the array in
			//   reverse order.  The logic is that this is just
			//   what we want when we allocate out of the cache.
			//   However, if we are unable to allocate all the
			//   elements we needed then we have to move the 
			//   pointers down to the base of the array.
			//
			for ( Count=0;Count < (*Actual);Count ++ )
				{ Array[ Count ] = Array[ (Count + Delta) ]; }
			}
		else
			{ return False; }
		}

	return True;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Memory allocation.                                             */
    /*                                                                  */
    /*   We need to make a new memory allocation from this bucket       */
    /*   so search the page list of available space and return a        */
    /*   free element.                                                  */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::New( BOOLEAN SubDivided,SBIT32 NewSize )
    {
	do
		{
		REGISTER PAGE *Page;

		//
		//   Walk the bucket list looking for any available
		//   free space.
		//
		for 
				( 
				Page = (PAGE::FirstInBucketList( & BucketList ));
				! Page -> EndOfBucketList();
				Page = Page -> NextInBucketList()
				)
			{
			REGISTER SBIT32 ActualSize = (Page -> GetPageSize());

			//
			//   We allow the page size to be dynamically
			//   modified to support a variety of wierd
			//   data layouts for BBT.   If the current page
			//   is not the correct size then skip it.
			//
			if 
					( 
					(ActualSize == NoSize) 
						|| 
					(ActualSize == ((NewSize == NoSize) ? PageSize : NewSize))
					)
				{
				//
				//   We know that any page that appears in 
				//   the bucket list will have at least one 
				//   free element available.  So if we find
				//   that the bucket list a suitable page 
				//   then we know that we can allocate something.
				//
				return (Page -> New( SubDivided ));
				}
			}
		}
	while 
		( 
		NewPage -> CreatePage( ((CACHE*) this),NewSize ) 
			!= 
		((PAGE*) AllocationFailure) 
		);

	//
	//   We were unable to find anything we could allocate
	//   so fail the request.
	//
	return ((VOID*) AllocationFailure);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release free space.                                            */
    /*                                                                  */
    /*   We sometimes do not release free space from a bucket as        */
    /*   returning it to the operating system and getting it again      */
    /*   later is very expensive.  Here we flush any free space we      */
    /*   have aquired over the user supplied limit.                     */
    /*                                                                  */
    /********************************************************************/

VOID BUCKET::ReleaseSpace( SBIT32 MaxActivePages )
    {
	REGISTER SBIT32 Current = ActivePages;

	//
	//   We only bother to try to trim the number of
	//   active pages if we are over the limit.
	//
	if ( Current > MaxActivePages )
		{
		REGISTER PAGE *NextPage;
		REGISTER PAGE *Page;

		//
		//   Walk the backwards along the bucket list 
		//   and delete the highest addressed free pages
		//   if we are over the limit.
		//
		for 
				( 
				Page = (PAGE::LastInBucketList( & BucketList ));
				(Current > MaxActivePages) 
					&& 
				(! Page -> EndOfBucketList());
				Page = NextPage
				)
			{
			//
			//   We are walking backwards down the bucket
			//   list looking for empty pages to delete.
			//   However, if we find a page we can remove
			//   it will be automatically removed from the
			//   list so we need to get the next pointer
			//   before this happens.
			//
			NextPage = Page -> PreviousInBucketList();

			//
			//   We can only release a page if it is empty
			//   if not we must skip it.
			//
			if ( Page -> Empty() )
				{
				Current --;

				DeletePage( Page ); 
				}
			}
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Update the bucket information.                                 */
    /*                                                                  */
    /*   When we create the bucket there is some information that       */
    /*   is not available.  Here we update the bucket to make sure      */
    /*   it has all the data we need.                                   */
    /*                                                                  */
    /********************************************************************/

VOID BUCKET::UpdateBucket
		( 
		HEAP						  *NewHeap,
		NEW_PAGE					  *NewPages,
		CACHE						  *NewParentCache,
		FIND						  *NewPrivateFind,
		FIND						  *NewPublicFind
		)
	{
	REGISTER SBIT16 NewSizeKey = (NewPages -> FindSizeKey( NumberOfElements ));

	//
	//   We compute and verify the size key to make sure
	//   it is suitable for all the pages that we will
	//   create after the heap constructor is completed.
	//
	if ( NewSizeKey != NoSizeKey )
		{
		//
		//   Update the size key and the connections.
		//
		SizeKey = NewSizeKey;

		UpdateConnections
			( 
			NewHeap,
			NewPages,
			NewParentCache, 
			NewPrivateFind,
			NewPublicFind
			);
		}
	else
		{ Failure( "Bucket can't get a size key in UpdateBucket" ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the allocation bucket.                                 */
    /*                                                                  */
    /********************************************************************/

BUCKET::~BUCKET( VOID )
	{ /* void */ }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\connections.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Connections.hpp"
#include "Cache.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "NewPage.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   There are a variety of connections that need to be made        */
    /*   after all the classes are ready for use.  However, we          */
    /*   initially zero all these connection pointers until we are      */
    /*   ready to link everything.                                      */
    /*                                                                  */
    /********************************************************************/

CONNECTIONS::CONNECTIONS( VOID )
    {
	Active = False;

	Heap = NULL;
	NewPage = NULL;
	ParentCache = NULL;
 	PrivateFind = NULL;
	PublicFind = NULL;
   }

    /********************************************************************/
    /*                                                                  */
    /*   Delete from the find lists.                                    */
    /*                                                                  */
    /*   When we delete a page we need to remove it from the private    */
    /*   and public find tables as needed.                              */
    /*                                                                  */
    /********************************************************************/

VOID CONNECTIONS::DeleteFromFindList( PAGE *Page )
	{
	//
	//   Delete from any active public find table.
	//
	if ( PublicFind != NULL )
		{ PublicFind -> DeleteFromFindList( Page ); }

	//
	//   Delete from any active private find table.
	//
	if ( PrivateFind != NULL )
		{ PrivateFind -> DeleteFromFindList( Page ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Add to the find lists.                                         */
    /*                                                                  */
    /*   When we create a page we need to insert it into the private    */
    /*   and public find tables as needed.                              */
    /*                                                                  */
    /********************************************************************/

VOID CONNECTIONS::InsertInFindList( PAGE *Page )
	{

	//
	//   Insert into any active private find table.
	//
	if ( PrivateFind != NULL )
		{ PrivateFind -> InsertInFindList( Page ); }

	//
	//   Insert into any active public find table.
	//
	if ( PublicFind != NULL )
		{ PublicFind -> InsertInFindList( Page ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Update the connections.                                        */
    /*                                                                  */
    /*   When we create an allocator there is some information that     */
    /*   is not available.  Here we update the connection information   */
    /*   so we can locate the correct instances of various other        */
    /*   classes.                                                       */
    /*                                                                  */
    /********************************************************************/

VOID CONNECTIONS::UpdateConnections
		( 
		HEAP						  *NewHeap,
		NEW_PAGE					  *NewPages,
		CACHE						  *NewParentCache,
		FIND						  *NewPrivateFind,
		FIND						  *NewPublicFind
		)
	{
	//
	//   We typically only need to update the connections once
	//   but in some situations multiple updates can occur.  If
	//   this is the case we carefully check the update is 
	//   consistent with the previous update.
	//
	if ( ! Active )
		{
		//
		//   We now have the information we need to update the 
		//   connections.
		//
		Active = True;
		Heap = NewHeap;
		NewPage = NewPages;
		ParentCache = NewParentCache;
		PrivateFind = NewPrivateFind;
		PublicFind = NewPublicFind;
		}
	else
		{
		//
		//   Nasty, we have already updated the connections once.  
		//   Since we have been called again we know this node 
		//   must be shared between two heaps.  We can deal with  
		//   this as long as selected pointers are the same.
		//
		if 
				(
				(PublicFind != NewPublicFind)
					||
				(NewPage != NewPages)
					||
				(ParentCache != NewParentCache)
				)
			{ Failure( "Sharing violation in UpdateConnections" ); }
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the connections.                                       */
    /*                                                                  */
    /********************************************************************/

CONNECTIONS::~CONNECTIONS( VOID )
    {
	PublicFind = NULL;
	PrivateFind = NULL;
	ParentCache = NULL;
	NewPage = NULL;
	Heap = NULL;

	Active = False;
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\connections.hpp ===
#ifndef _CONNECTIONS_HPP_
#define _CONNECTIONS_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Environment.hpp"
#include "Common.hpp"
#include "Find.hpp"
#include "NewPage.hpp"
#include "Prefetch.hpp"
  
    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   At the top level the parent of all caches is a constant        */
    /*   called 'GlobalRoot'.                                           */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 GlobalRoot				  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;
class HEAP;
class PAGE;

    /********************************************************************/
    /*                                                                  */
    /*   Data structures exported from the class.                       */
    /*                                                                  */
    /*   We communicate between a page and the associated cache         */
    /*   using an address pointer, page pointer and version triple.     */
    /*                                                                  */
    /********************************************************************/

typedef struct
	{
	VOID							  *Address;
	PAGE							  *Page;
	SBIT32							  Version;
	}
ADDRESS_AND_PAGE;

    /********************************************************************/
    /*                                                                  */
    /*   Connections to other classes.                                  */
    /*                                                                  */
    /*   The connections between the various classes in the memory      */
    /*   allocator is a twisted mess.  The root cause is that at a      */
    /*   fundamental level.  Every part depends on every other part.    */
    /*   Nonetheless, a significant effort has been made to seperate    */
    /*   the parts as best as possible.  The various classes are        */
    /*   linked here so every part can find the correct instance of     */
    /*   every other part.                                              */
    /*                                                                  */
    /********************************************************************/

class CONNECTIONS : public ENVIRONMENT, public COMMON
    {
		//
		//   Private data.
		//
		BOOLEAN						  Active;

   public:
		//
		//   Public data.
		//
		//   All the classes that inherit this class get
		//   pointers to related classes they need to call
		//   from time to time. 
		//
		HEAP                          *Heap;
		NEW_PAGE					  *NewPage;
		CACHE						  *ParentCache;
		FIND                          *PrivateFind;
		FIND                          *PublicFind;

		//
		//   The 'Prefetch' is a class that will trigger
		//   a cache fetch if the CPU supports it.
		//   
		PREFETCH					  Prefetch;

        //
        //   Public functions.
		//
		//   The sole job of this class is to provide 
		//   pointers to related classes.  These pointers
		//   are unknown until after the heap has been
		//   created and this need to be dynamically
		//   linked during the execution of the top 
		//   level heap constructor.
        //
        CONNECTIONS( VOID );

		VOID DeleteFromFindList( PAGE *Page );

		VOID InsertInFindList( PAGE *Page );

		VOID UpdateConnections
			( 
			HEAP					  *NewHeap,
			NEW_PAGE				  *NewPages,
			CACHE					  *NewParentCache,
			FIND					  *NewPrivateFind,
			FIND					  *NewPublicFind
			);

        ~CONNECTIONS( VOID );

		//
		//   Public inline functions.
		//
		//   The complex linkages in the heap sometimes 
		//   lead to the case where a class has a pointer
		//   to it's cache but not to the class it needs
		//   to call.  Thus, to avoid replicating large
		//   numbers of pointers we export call interfaces
		//   from here to allow the required calls to be
		//   made indirectly.
		//
		INLINE VOID DeletePage( PAGE *Page )
			{ NewPage -> DeletePage( Page ); }

		INLINE HEAP *GetHeap( VOID )
			{ return Heap; }

		INLINE CACHE *GetParentCache( VOID )
			{ return ParentCache; }

		INLINE BOOLEAN TopCache( VOID )
			{ return (ParentCache == ((CACHE*) GlobalRoot)); }

	private:
        //
        //   Disabled operations.
        //
        CONNECTIONS( CONST CONNECTIONS & Copy );

        VOID operator=( CONST CONNECTIONS & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\bucketlist.hpp ===
#ifndef _BUCKET_LIST_HPP_
#define _BUCKET_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "List.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class PAGE;

    /********************************************************************/
    /*                                                                  */
    /*   The bucket list.                                               */
    /*                                                                  */
    /*   All allocation buckets have a linked list of pages with        */
    /*   available space in ascending order of address.                 */
    /*                                                                  */
    /********************************************************************/

class BUCKET_LIST
    {
		//
		//   Private data.
		//
 		LIST						  BucketList;

   public:
        //
        //   Public inline functions.
		//
		//   All page descriptions contain four linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
        //
        BUCKET_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromBucketList( LIST *HeadOfList )
			{ BucketList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfBucketList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInBucketList( LIST *HeadOfList )
			{ return ((PAGE*) HeadOfList -> First()); }

		INLINE VOID InsertInBucketList( LIST *HeadOfList )
			{ BucketList.Insert( HeadOfList ); }

		INLINE VOID InsertAfterInBucketList( LIST *HeadOfList,PAGE *Page )
			{ BucketList.InsertAfter( HeadOfList,(LIST*) Page ); }

		INLINE VOID InsertBeforeInBucketList( LIST *HeadOfList,PAGE *Page )
			{ BucketList.InsertBefore( HeadOfList,(LIST*) Page ); }

		STATIC INLINE PAGE *LastInBucketList( LIST *HeadOfList )
			{ return ((PAGE*) HeadOfList -> Last()); }

		INLINE PAGE *NextInBucketList( VOID )
			{ return ((PAGE*) BucketList.Next()); }

		INLINE PAGE *PreviousInBucketList( VOID )
			{ return ((PAGE*) BucketList.Previous()); }

        ~BUCKET_LIST( VOID )
			{ /* void */ };

	private:
        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        BUCKET_LIST( CONST BUCKET_LIST & Copy );

        VOID operator=( CONST BUCKET_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\bucket.hpp ===
#ifndef _BUCKET_HPP_
#define _BUCKET_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Connections.hpp"
#include "Page.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;
class HEAP;

    /********************************************************************/
    /*                                                                  */
    /*   A collection of pages.                                         */
    /*                                                                  */
    /*   A bucket is a collection of pages capable of allocating        */
    /*   fixed sized memory elements.  The pages are allocated from     */
    /*   from larger buckets and are stored in a linked list in         */
    /*   order of ascending of page addresses.                          */
    /*                                                                  */
    /********************************************************************/

class BUCKET : public CONNECTIONS
    {
		//
		//   Private type definitions.
		//
		//   All allocations are registered in bit vectors.
		//   Here we have some prototypes for seriously  
		//   optimized functions to do address to bit 
		//   vector computations.
		//
		typedef VOID *(BUCKET::*COMPUTE_ADDRESS)
			( 
			CHAR					  *Address,
			SBIT32					  Offset 
			);

		typedef SBIT32 (BUCKET::*COMPUTE_OFFSET)
			( 
			SBIT32					  Displacement,
			BOOLEAN					  *Found 
			);

		//
		//   Private data.
		//
		//   A bucket owns all the memory of a given size
		//   and manages it.  Above it is a cache to 
		//   protect it from huge number of calls and
		//   below it are the connections to various 
		//   other classes.  The 'AllocationSize' is the
		//   buckets allocation size.  The 'ChunkSize' is
		//   chunking size which is typically half way
		//   between the 'AllocationSize' and the 'PageSize'.
		//   The 'PageSize' is the size of the bucket
		//   where this bucket gets its space.
		//   
		//
		SBIT32                        AllocationSize;
		SBIT32						  ChunkSize;
		SBIT32						  PageSize;

		//
		//   It is the job of the bucket to keep track of
		//   all the information relating to allocations
		//   of a given 'AllocationSize'.  The 'ActivePages'
		//   keeps track of the number of available pages
		//   in the 'BucketList'.  The 'BucketList' is a
		//   linked list of pages that have available space.
		//   The 'CurrentPage' contains the highest address
		//   of the first page in the 'BucketList'.
		//
		SBIT32						  ActivePages;
		LIST						  BucketList;
		VOID						  *CurrentPage;

		//
		//   A bucket needs to be able to quickly convert
		//   bit vector offsets to addresses (and vice versa).
		//   The 'AllocationShift' is set when the 
		//   'AllocationSize' is a power of two to avoid 
		//   any divides.  The 'ChunkShift' is set when the
		//   'ChunckSize' is a power of two to avoid some
		//   divides.  The 'ComputeAddressFunction' and
		//   'ComputeOffsetFunction' point to optimized
		//   functions to do conversions that are selected
		//   by the constructor.
		//
		SBIT32						  AllocationShift;
		SBIT32						  ChunkShift;
		COMPUTE_ADDRESS				  ComputeAddressFunction;
		COMPUTE_OFFSET				  ComputeOffsetFunction;

		//
		//   A bucket typically contains a collection of
		//   pages.  As all pages are the same data that
		//   should really be stored in page descriptions
		//   is instead stored in the bucket to save space.
		//   The 'NumberOfElements' contains the number of
		//   elements in each pages bit vector.  The 
		//   'SizeOfChunks' contains the pre-computed chunk
		//   size.  The 'SizeOfElements' contains the number
		//   of words in the pages bit vector.  The 'SizeKey'
		//   contains an index which selects the size of the
		//   bit vector when a new page is created.
		//
		SBIT16						  NumberOfElements;
		SBIT16						  SizeOfChunks;
		SBIT16						  SizeOfElements;
		SBIT16						  SizeKey;

   public:
		//
		//   Public functions.
		//
		//   The functionality provided by this class pretty
		//   much matches the external API.  Nonetheless, these
		//   APIs are protected from excessive calls by a fast
		//   cache that is derived from this class.
		//
        BUCKET
			( 
			SBIT32					  NewAllocationSize,
			SBIT32					  NewChunkSize,
			SBIT32					  NewPageSize 
			);

		BOOLEAN Delete( VOID *Address,PAGE *Page,SBIT32 Version );

		VOID DeleteFromBucketList( PAGE *Page );

		VOID InsertInBucketList( PAGE *Page );

		BOOLEAN MultipleDelete
			( 
			ADDRESS_AND_PAGE		  *Array,
			SBIT32					  *Deleted,
			SBIT32					  Size 
			);

		BOOLEAN MultipleNew
			( 
			SBIT32					  *Actual,
			VOID					  *Array[],
			SBIT32					  Requested 
			);

		VOID *New( BOOLEAN SubDivided,SBIT32 NewSize = NoSize );

		VOID ReleaseSpace( SBIT32 MaxActivePages );

		VOID UpdateBucket
			( 
			HEAP					  *NewHeap,
			NEW_PAGE				  *NewPages,
			CACHE					  *NewParentCache,
			FIND					  *NewPrivateFind,
			FIND					  *NewPublicFind
			);

        ~BUCKET( VOID );

		//
		//   Public inline functions.
		//
		//   It saves a significant amount of space by putting
		//   common information in the bucket instead of a 
		//   separate copy in each page description.  Nonetheless,
		//   it means that both classes are very much dependent
		//   upon each other.
		//
		INLINE VOID *ComputeAddress( CHAR *Address,SBIT32 Offset )
			{ return (this ->* ComputeAddressFunction)( Address,Offset ); }

		INLINE SBIT32 ComputeOffset( SBIT32 Displacement,BOOLEAN *Found )
			{ return (this ->* ComputeOffsetFunction)( Displacement,Found ); }

		INLINE SBIT32 GetAllocationSize( VOID )
			{ return AllocationSize; }

		INLINE SBIT32 GetChunkSize( VOID )
			{ return ChunkSize; }

		VOID *GetCurrentPage( VOID )
			{ return CurrentPage; }

		INLINE SBIT16 GetNumberOfElements( VOID )
			{ return NumberOfElements; }

		INLINE SBIT32 GetPageSize( VOID )
			{ return PageSize; }

		INLINE SBIT16 GetSizeOfChunks( VOID )
			{ return SizeOfChunks; }

		INLINE SBIT16 GetSizeOfElements( VOID )
			{ return SizeOfElements; }

		INLINE SBIT16 GetSizeKey( VOID )
			{ return SizeKey; }

	private:
		//
		//   Private functions.
		//
		//   When we need to convert an address to a bit 
		//   offset (or vice versa) we use one of the following 
		//   functions.
		//
		VOID *ComputeAddressBestCase( CHAR *Address,SBIT32 Offset );
		VOID *ComputeAddressGoodCase( CHAR *Address,SBIT32 Offset );
		VOID *ComputeAddressPoorCase( CHAR *Address,SBIT32 Offset );
		VOID *ComputeAddressWorstCase( CHAR *Address,SBIT32 Offset );

		SBIT32 ComputeOffsetBestCase( SBIT32 Displacement,BOOLEAN *Found );
		SBIT32 ComputeOffsetGoodCase( SBIT32 Displacement,BOOLEAN *Found );
		SBIT32 ComputeOffsetPoorCase( SBIT32 Displacement,BOOLEAN *Found );
		SBIT32 ComputeOffsetWorstCase( SBIT32 Displacement,BOOLEAN *Found );

        //
        //   Disabled operations.
 		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
		//
        BUCKET( CONST BUCKET & Copy );

        VOID operator=( CONST BUCKET & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\cache.hpp ===
#ifndef _CACHE_HPP_
#define _CACHE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Bucket.hpp"
#include "Find.hpp"
#include "NewPage.hpp"
#include "ThreadSafe.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The allocation cache.                                          */
    /*                                                                  */
    /*   The memory allocation cache consists of two stacks.  The       */
    /*   first stack contains preallocated elements which are           */
    /*   available for use.  The second stack contains elements         */
    /*   which have been deallocated and are about to be recycled.      */
    /*                                                                  */
    /********************************************************************/

class CACHE : public BUCKET
    {
		//
		//   Private data.
		//
		//   A cache sits on top of a bucket and shields 
		//   it from being swamped by calls.  The 'Active'
		//   flag is set when the cache is active.  The
		//   'Stealing' flag indicates that deallocated
		//   memory can be stolen and reallocated.  The
		//   'ThreadSafe' flag indicates that locking is
		//   required.
		//
		BOOLEAN						  Active;
		BOOLEAN						  Stealing;
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   When we are collecting statistics we enable 
		//   the following variables.  The 'CacheFills' 
		//   count keeps track of the number of times
		//   the cache was filled from the bucket.  The
		//   'CacheFlushes' count keeps track of the 
		//   number of times the cache flushed deleted
		//   elements to the bucket.  The 'HighTide' count  
		//   keeps track the the highest number of outstanding
		//   allocations since the last "DeleteAll()'.  The 
		//   'HighWater' count keeps track of the maximum 
		//   number of allocations at any point.  The
		//   'InUse' counts the the current number of outstanding 
		//   allocations.
		//
		SBIT32						  CacheFills;
		SBIT32						  CacheFlushes;
		SBIT32						  HighTide;
		SBIT32						  HighWater;
		SBIT32						  InUse;
#endif

		//
		//   A cache can be controlled by the user.  The
		//   'CacheSize' controls the number of allocations
		//   that can be preallocated or queued for 
		//   deletion.  The 'NumberOfChildren' is a count
		//   of the number of caches that allocate space
		//   from this cache.
		//
		SBIT16						  CacheSize;
		SBIT16						  FillSize;
		SBIT16						  NumberOfChildren;

		//
		//   The cache consists of two stacks.  The
		//   'DeleteStack' contains elements that are 
		//   waiting to be deleted.  The 'NewStack' 
		//   contains elements waiting to be allocated.
		//
		ADDRESS_AND_PAGE			  *DeleteStack;
		VOID						  **NewStack;
		THREAD_SAFE					  *ThreadSafe;

		//
		//   The top of the deleted stack is kept in
		//   'TopOfDeleteStack' and the top of the new
		//   stack is kept in 'TopOfNewStack'.
		//
		SBIT32						  TopOfDeleteStack;
		SBIT32						  TopOfNewStack;

		//
		//   The 'Spinlock' is a fast lock employed to
		//   make the cache multi-threaded if 'ThreadSafe'
		//   is true.
		//   
		SPINLOCK					  Spinlock;

   public:
		//
		//   Public functions.
		//
		//   The cacahe is a subset of the full haep interface
		//   a certain calls simply bypass it.  However, there
		//   are a few additional functions for cases where the
		//   cache needs to be notified of significant heap
		//   events.
		//
        CACHE
			( 
			SBIT32					  NewAllocationSize,
			SBIT32					  NewCacheSize,
			SBIT32					  NewChunkSize,
			SBIT32					  NewPageSize,
			BOOLEAN					  NewStealing,
			THREAD_SAFE				  *NewThreadSafe
			);

		VOID *CreateDataPage( VOID );

		BOOLEAN Delete( VOID *Address,PAGE *Page,SBIT32 Version );

		VOID DeleteAll( VOID );

		BOOLEAN DeleteDataPage( VOID *Address );

		PAGE *FindChildPage( VOID *Address,FIND *Find );

		PAGE *FindParentPage( VOID *Address,FIND *Find );

		BOOLEAN MultipleNew
			( 
			SBIT32					  *Actual,
			VOID					  *Array[],
			SBIT32					  Requested 
			);

		VOID *New( VOID );

		VOID *New( BOOLEAN SubDivided,SBIT32 NewSize = NoSize );

		VOID ReleaseSpace( SBIT32 MaxActivePages );

		BOOLEAN SearchCache( VOID *Address );

		BOOLEAN Truncate( VOID );

		VOID UpdateCache
			( 
			HEAP					  *NewHeap,
			NEW_PAGE				  *NewPages,
			CACHE					  *NewParentCache,
			FIND					  *NewPrivateFind,
			FIND					  *NewPublicFind
			);

        ~CACHE( VOID );

		//
		//   Public inline functions.
		//
		//   A cache just like its parent bucket is closely
		//   coupled to various other classes and provides
		//   then is vital information.
		//
		INLINE VOID ClaimCacheLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Spinlock.ClaimLock(); } 
			}

		INLINE SBIT16 GetCacheSize( VOID )
			{ return CacheSize; }

		INLINE SBIT32 GetNumberOfChildren( VOID )
			{ return NumberOfChildren; }

		INLINE VOID ReleaseCacheLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Spinlock.ReleaseLock(); } 
			}

		INLINE BOOLEAN Walk( SEARCH_PAGE *Details,FIND *Find )
			{ return NewPage -> Walk( Details,Find ); }
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Cache statistics.
		//
		//   A cache has a collection statistics which it
		//   uses to measure how it is doing.  It is possible
		//   to get access to this data for the purpose of
		//   outputing various reports.
		//
		INLINE SBIT32 GetCacheFills( VOID )
			{ return CacheFills; }

		INLINE SBIT32 GetCacheFlushes( VOID )
			{ return CacheFlushes; }

		INLINE SBIT32 GetHighTide( VOID )
			{ return HighTide; }

		INLINE SBIT32 GetHighWater( VOID )
			{ return HighWater; }

		INLINE SBIT32 GetInUse( VOID )
			{ return InUse; }
#endif

	private:
		//
		//   Private functions.
		//
		//   A cache is initially inactive.  If at least one
		//   allocation request is made it will spring into
		//   life, allocate any space needed and prepare itself
		//   for use.
		//
		VOID CreateCacheStacks( VOID );
#ifdef ENABLE_HEAP_STATISTICS

		VOID ComputeHighWater( SBIT32 Size );
#endif

        //
        //   Disabled operations.
 		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        CACHE( CONST CACHE & Copy );

        VOID operator=( CONST CACHE & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\heappch.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\findlist.hpp ===
#ifndef _FIND_LIST_HPP_
#define _FIND_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "BucketList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The find list.                                                 */
    /*                                                                  */
    /*   The find list links all the pages in the same hash bucket      */
    /*   together so that the correct page can be found.                */
    /*                                                                  */
    /********************************************************************/

class FIND_LIST : public BUCKET_LIST
    {
		//
		//   Private data.
		//
 		LIST						  FindList;

   public:
		//
		//   Public inline functions.
		//
		//   All page descriptions contain three linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
		//
        FIND_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromFindList( LIST *HeadOfList )
			{ FindList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfFindList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInFindList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> First()) ); }

		INLINE VOID InsertInFindList( LIST *HeadOfList )
			{ FindList.Insert( HeadOfList ); }

		INLINE PAGE *NextInFindList( VOID )
			{ return ComputePageAddress( ((CHAR*) FindList.Next()) ); }

        ~FIND_LIST( VOID )
			{ /* void */ };

	private:
		//
		//   Private functions.
		//
		//   Compute the actual start address of the page
		//   and return it to allow the linked list to
		//   be correctly walked.
		//
		STATIC INLINE PAGE *ComputePageAddress( CHAR *Address )
			{
			if ( Address != NULL )
				{ return ((PAGE*) (Address - sizeof(BUCKET_LIST))); }
			else
				{ return ((PAGE*) NULL); }
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        FIND_LIST( CONST FIND_LIST & Copy );

        VOID operator=( CONST FIND_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\find.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "New.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control the size of the hash       */
    /*   table and other related features.                              */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MinHash				  = 1024;
CONST SBIT32 MinHashSpace			  = (100/25);
CONST SBIT32 MinLookAside			  = 128;

CONST BIT32 NoAddressMask			  = ((BIT32) -1);
CONST SBIT32 NoCacheEntry			  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create the hash table and initialize it ready for use. The     */
    /*   configuration information supplied from the parameters needs   */
    /*   to be carefully checked as it has come indirectly from the     */
    /*   user and may be bogus.                                         */
    /*                                                                  */
    /********************************************************************/

FIND::FIND
		( 
		SBIT32						  NewMaxHash,
		SBIT32						  NewMaxLookAside,
		SBIT32						  NewFindThreshold,
		BOOLEAN						  NewPublic, 
		BOOLEAN						  NewResize, 
		ROCKALL_BACK_END			  *NewRockallBackEnd,
		THREAD_SAFE					  *NewThreadSafe 
		)
    {
	REGISTER SBIT32 AlignMask = (NewRockallBackEnd -> NaturalSize()-1);

	//
	//   We need to make sure that the size of the hash table
	//   makes sense.  The hash table size needs to be a reasonable
	//   size (say 1k or larger) and a power of 2 (so we don't need
	//   to do any divides).
	//   
	if 
			(
			PowerOfTwo( (AlignMask+1) )
				&&
			(NewFindThreshold >= 0 )
				&&
			(NewMaxHash >= MinHash) 
				&&
			(ConvertDivideToShift( NewMaxHash,& HashMask ))
				&& 
			(NewMaxLookAside >= MinLookAside) 
				&& 
			(ConvertDivideToShift( NewMaxLookAside,& LookAsideMask ))
			)
		{
		REGISTER SBIT32 HashSizeLocal = (NewMaxHash * sizeof(LIST));
		REGISTER SBIT32 LookAsideSize = (NewMaxLookAside * sizeof(LOOK_ASIDE));
		REGISTER SBIT32 TotalSize = (HashSizeLocal + LookAsideSize);

		//
		//   Set up the hash table.
		//
		MaxHash = NewMaxHash;

		HashShift = (32-HashMask);
		HashMask = ((1 << HashMask)-1);
		Public = NewPublic;
		Resize = NewResize;

		//
		//   Set up the lookaside table.
		//
		MaxLookAside = NewMaxLookAside;

		MaxAddressMask = NoAddressMask;
		MinAddressMask = NoAddressMask;

		LookAsideActions = 0;
		LookAsideShift = (32-LookAsideMask);
		LookAsideMask = ((1 << LookAsideMask)-1);
		LookAsideThreshold = NewFindThreshold;

		RockallBackEnd = NewRockallBackEnd;

		ThreadSafe = NewThreadSafe;

		//
		//   Create some space for the find table and the 
		//   look aside table.
		//
		Hash = 
			((LIST*) RockallBackEnd -> NewArea
				( 
				AlignMask,
				TotalSize,
				False 
				)
			);

		LookAside = ((LOOK_ASIDE*) & Hash[ MaxHash ]);

		//
		//   If the memory allocation request for the hash
		//   table fails we are doomed.  If it works we need
		//   to call the constructor for each linked list
		//   head node.
		//
		if ( Hash != ((LIST*) AllocationFailure) )
			{
			REGISTER SBIT32 Count;

			//
			//   Call the constructor for each hash table
			//   linked list header.
			//
			for ( Count=0;Count < NewMaxHash;Count ++ )
				{ PLACEMENT_NEW( & Hash[ Count ],LIST ); }

			//
			//   Zero the look aside structures.  We need
			//   to do this to ensure they do not match a
			//   valid allocation address later.
			//
			for ( Count=0;Count < MaxLookAside;Count ++ )
				{
				REGISTER LOOK_ASIDE *Current = & LookAside[ Count ];

				Current -> Address = ((VOID*) NoCacheEntry);
				Current -> Page = ((PAGE*) NoCacheEntry);
#ifdef DEBUGGING
				Current -> Version = ((SBIT32) NoCacheEntry);
#endif
				}
#ifdef ENABLE_HEAP_STATISTICS

			//
			//   Zero the statistics information.
			//
			Fills = 0;
			Hits = 0;
			MaxPages = 0;
			MaxTests = 0;
			Misses = 0;
			Scans = 0;
			Tests = 0;
#endif
			Used = 0;
			}
		else
			{ Failure( "Create hash fails in constructor for FIND" ); }
		}
	else
		{ Failure( "Hash table size in constructor for FIND" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Delete a memory allocation.                                    */
    /*                                                                  */
    /*   We need to delete a particular memory allocation.  All         */
    /*   we have is an address.  We use this to find the largest        */
    /*   allocation page this address is contained in and then          */
    /*   navigate through the sub-divisions of this page until we       */
    /*   find the allocation we need to delete.                         */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::Delete( VOID *Address,CACHE *ParentCache )
    {
	REGISTER PAGE *Page;
	REGISTER BOOLEAN Update;
	
	//
	//   If we need to be thread safe then claim a sharable lock
	//   on the hash table to stop it being changed under our feet.
	//
	ClaimFindShareLock();

	//
	//   Lets try the lookaside table.  There is a pretty
	//   good chance that we will have the details we need 
	//   already in the cache.  If not we need to find it
	//   the hard way.  During the process we add the mapping
	//   into the lookaside for next time.
	//
	if
			( 
			Update = 
				(
				! FindLookAside
					( 
					((VOID*) (((LONG) Address) & ~MinAddressMask)),
					& Page 
					)
				)
			)
		{
		//
		//   Find the allocation page and get the details of entry.
		//   We do this by finding the parent of the top cache.
		//   We  know that this is the global root and will find
		//   the correct page even if it is on another heap (as
		//   long as the find table is globally shared).
		//
		Page = (ParentCache -> FindParentPage( Address,this ));

		if ( Page != ((PAGE*) NULL) )
			{ Page = (Page -> FindPage( Address,NULL,this,True )); }
		}

	//
	//   We may have failed to find the address.  If so
	//   we simply fail the call.  If not we put the deleted 
	//   element back in the associated cache.
	//
	if ( Page != ((PAGE*) NULL) )
 		{
		REGISTER CACHE *Cache = (Page -> GetCache());
		REGISTER SBIT32 Original = (Page -> GetVersion());

		//
		//   Prefetch the class data if we are running a
		//   Pentium III or better with locks.  We do this
		//   because prefetching hot SMP data structures
		//   really helps.  However, if the structures are
		//   not shared (i.e. no locks) then it is worthless
		//   overhead.
		//
		if ( ThreadSafe )
			{ Prefetch.Nta( ((CHAR*) Cache),sizeof(CACHE) ); }

		//
		//   Release the lock if we claimed it earlier and
		//   update the lookaside if needed.
		//
		if ( Update )
			{ ReleaseFindShareLockAndUpdate( Address,Page,Original ); }
		else
			{ ReleaseFindShareLock(); }

		//
		//   We have found the associated page description
		//   so pass the delete request along to the cache
		//   and get out of here.
		//
		return (Cache -> Delete( Address,Page,Original ));
		}
	else
		{ 
		//
		//   Release the lock if we claimed it earlier.
		//
		ReleaseFindShareLock();

		return False; 
		}
  }

    /********************************************************************/
    /*                                                                  */
    /*   Delete an item from the find table.                            */
    /*                                                                  */
    /*   We need to delete page from the find list.  We expect          */
    /*   this to take quite a while as multiple threads can be          */
    /*   using this class at the same time.                             */
    /*                                                                  */
    /********************************************************************/

VOID FIND::DeleteFromFindList( PAGE *Page )
	{
	REGISTER VOID *Address = (Page -> GetAddress());

	//
	//   Claim an exclusive lock so we can update the 
	//   hash and lookaside as needed.
	//
	ClaimFindExclusiveLock();

	//
	//   Delete the page from the hash table.
	//
	if ( ! Public )
		{ Page -> DeleteFromPrivateFindList( FindHashHead( Address ) ); }
	else
		{ Page -> DeleteFromPublicFindList( FindHashHead( Address ) ); }

	//
	//   When we create very small heaps (i.e. a heap
	//   where only 20-30 allocations are requested)
	//   the various caches become a problem as they
	//   tend to front load work.  So we allow a limit
	//   to be set before which we run with caches 
	//   disabled.
	//   
	if ( LookAsideActions >= LookAsideThreshold )
		{
		REGISTER SBIT32 Count;
		REGISTER CACHE *Cache = (Page -> GetCache());
		REGISTER SBIT32 Stride = (Cache -> GetAllocationSize());

		//
		//   We are about look up various look aside entries
		//   and delete any that are stale.  We need to do
		//   this for every lookaside slot that relates to
		//   the page.  If the allocation size is smaller
		//   than the lookaside slot size we can save some
		//   iterations by increasing the stride size.
		//
		if ( Stride <= ((SBIT32) MinAddressMask) )
			{ Stride = ((SBIT32) (MinAddressMask+1)); }

		//
		//   Whenever we delete an entry from the hash table
		//   the lookaside is potentially corrupt.  So we 
		//   need to delete any look aside entries relating
		//   to this page.
		//
		for ( Count=0;Count < Cache -> GetPageSize();Count += Stride )
			{
			REGISTER VOID *Segment = 
				((VOID*) ((((LONG) Address) + Count) & ~MinAddressMask));
			REGISTER LOOK_ASIDE *Current = 
				(FindLookAsideHead( Segment ));

			//
			//   Delete the look aside entry if it is stale.
			//
			if ( Segment == Current -> Address )
				{
				Current -> Address = ((VOID*) NoCacheEntry);
				Current -> Page = ((PAGE*) NoCacheEntry);
#ifdef DEBUGGING
				Current -> Version = ((SBIT32) NoCacheEntry);
#endif
				}
			}
		}

	//
	//   Update the statistics.
	//
	Used --;

	//
	//   Release the lock if we claimed it earlier.
	//
	ReleaseFindExclusiveLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   Details of a memory allocation.                                */
    /*                                                                  */
    /*   We need to the details of a particular memory allocation.      */
    /*   All we have is an address.  We use this to find the largest    */
    /*   allocation page this address is contained in and then          */
    /*   navigate through the sub-divisions of this page until we       */
    /*   find the allocation.                                           */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::Details
		( 
		VOID						  *Address,
		SEARCH_PAGE					  *Details,
		CACHE						  *ParentCache,
		SBIT32						  *Size 
		)
    {
	REGISTER PAGE *Page;
	REGISTER BOOLEAN Result;
	REGISTER BOOLEAN Update;
	
	//
	//   If we need to be thread safe then claim a sharable lock
	//   on the hash table to stop it being changed under our feet.
	//
	ClaimFindShareLock();

	//
	//   Lets try the lookaside table.  There is a pretty
	//   good chance that we will have the deatils we need 
	//   already in the cache.  If not we need to find it
	//   the hard way.  During the process we add the mapping
	//   into the lookaside for next time.
	//
	if
			( 
			Update = 
				(
				! FindLookAside
					( 
					((VOID*) (((LONG) Address) & ~MinAddressMask)),
					& Page 
					)
				)
			)
		{
		//
		//   Find the allocation page and get the details of entry.
		//   We do this by finding the parent of the top cache.
		//   We  know that this is the global root and will find
		//   the correct page even if it is on another heap (as
		//   long as the find table is globally shared).
		//
		Page = (ParentCache -> FindParentPage( Address,this ));

		if ( Page != ((PAGE*) NULL) )
			{ Page = (Page -> FindPage( Address,Details,this,True )); }
		}
	else
		{
		//
		//   We may need to provide the all the details of the
		//   allocation for some reason.
		//
		if ( Details != NULL )
			{ Page = (Page -> FindPage( Address,Details,this,True )); }
		}

	//
	//   We may have failed to find the address.  If so
	//   we simply fail the call.  If not we extract the 
	//   information we want.
	//
	if ( Result = (Page != ((PAGE*) NULL)) )
 		{
		//
		//   Compute the size.  We would normally expect
		//   this to be the cache size.  However, there
		//   are some weird pages that sometimes have
		//   other sizes.
		//
		(*Size) = (Page -> ActualSize());
		}

	//
	//   Release the lock if we claimed it earlier and 
	//   update the lookaside if needed.
	//
	if ( (Update) && (Result) )
		{ ReleaseFindShareLockAndUpdate( Address,Page,Page -> GetVersion() ); }
	else
		{ ReleaseFindShareLock(); }

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Find in the look aside.                                        */
    /*                                                                  */
    /*   We need to find a particular page in the look aside.  So we    */
    /*   try a simple look up (no lists or chains).                     */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::FindLookAside( VOID *Address,PAGE **Page )
    {
	//
	//   When we create very small heaps (i.e. a heap
	//   where only 20-30 allocations are requested)
	//   the various caches become a problem as they
	//   tend to front load work.  So we allow a limit
	//   to be set before which we run with caches 
	//   disabled.
	//   
	if ( LookAsideActions >= LookAsideThreshold )
		{
		REGISTER LOOK_ASIDE *Current = FindLookAsideHead( Address );

		//
		//   We have hashed to a lookaside slot.  Maybe
		//   it contains what we want or maybe not.
		//
		if ( Address == Current -> Address )
			{
#ifdef DEBUGGING
			if ( Current -> Version == (Current -> Page -> GetVersion()) )
				{
#endif
				//
				//   We hit the lookaside and the 
				//   contents are valid.
				//
				(*Page) = (Current -> Page);
#ifdef ENABLE_HEAP_STATISTICS

				//
				//   Update the statistics.
				//
				Hits ++;
#endif

				return True;
#ifdef DEBUGGING
				}
			else
				{ Failure( "Deleted page in FindLookAside" ); }
#endif
			}
		}
	else
		{
		//
		//   We update number of times we tried to
		//   use the lookaside and it was disabled.  
		//   After a while this will lead to the 
		//   lookaside being enabled.
		//
		LookAsideActions ++; 
		}
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   We missed the lookaside so update the 
	//   statistics to reflect our misfortune.
	//
	Misses ++;
#endif

	return False; 
    }

    /********************************************************************/
    /*                                                                  */
    /*   Find a page.                                                   */
    /*                                                                  */
    /*   We need to find a particular page in the hash table.  So we    */
    /*   scan along the associated linked list looking for a match.     */
    /*                                                                  */
    /********************************************************************/

PAGE *FIND::FindPage( VOID *Address,CACHE *ParentCache )
    {
#ifdef ENABLE_HEAP_STATISTICS
	REGISTER SBIT32 Cycles = 0;
	REGISTER PAGE *Result = NULL;
#endif
	//
	//   There are two find lists.  There is the
	//   private find list and the public find list.
	//   We choose which one to walk along.
	//
	if ( ! Public )
		{
		REGISTER PAGE *Page;

		//
		//   Find the associated hash bucket and then walk
		//   along the linked list for this looking for
		//   the correct page description.
		//
		for 
				( 
				Page = PAGE::FirstInPrivateFindList( FindHashHead( Address ) );
				! Page -> EndOfPrivateFindList();
				Page = Page -> NextInPrivateFindList()
				)
			{
#ifdef ENABLE_HEAP_STATISTICS
			//
			//   Count the number of iterations in when we
			//   are recording statistics so we can calculate
			//   the average chain length.
			//
			Cycles ++;

#endif
			//
			//   We can identify the the target page by two key
			//   characteristics.  These are the start address and
			//   the parent page.   Although we may have sub-divided
			//   a page into various chunks each chunk will have
			//   a different parent (although its start address
			//   may sometimes be the same).
			//
			if 
					( 
					(Address == (Page -> GetAddress())) 
						&& 
					(ParentCache == (Page -> GetParentPage()))
					)
				{
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   We have found the target page.  So return it
				//   to the caller.
				//
				if ( Page -> ValidPage() )
					{
					Result = Page;
					break;
					}
				else
					{ Failure( "Deleted page in FindPage" ); }
#else
				return Page;
#endif
				}
			}
		}
	else
		{
		REGISTER PAGE *Page;

		//
		//   Find the associated hash bucket and then walk
		//   along the linked list for this looking for
		//   the correct page description.
		//
		for 
				( 
				Page = PAGE::FirstInPublicFindList( FindHashHead( Address ) );
				! Page -> EndOfPublicFindList();
				Page = Page -> NextInPublicFindList()
				)
			{
#ifdef ENABLE_HEAP_STATISTICS
			//
			//   Count the number of iterations in when we
			//   are recording statistics so we can calculate
			//   the average chain length.
			//
			Cycles ++;

#endif
			//
			//   We can identify the the target page by two key
			//   characteristics.  These are the start address and
			//   the parent page.   Although we may have sub-divided
			//   a page into various chunks each chunk will have
			//   a different parent (although its start address
			//   may sometimes be the same).
			//
			if 
					( 
					(Address == (Page -> GetAddress())) 
						&& 
					(ParentCache == (Page -> GetParentPage()))
					)
				{
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   We have found the target page.  So return it
				//   to the caller.
				//
				if ( Page -> ValidPage() )
					{
					Result = Page;
					break;
					}
				else
					{ Failure( "Deleted page in FindPage" ); }
#else
				return Page;
#endif
				}
			}
		}

#ifdef ENABLE_HEAP_STATISTICS
	//
	//   When we are in statistics mode we need to update the
	//   information so we can output it at the end of the
	//   run.
	//
	if ( MaxTests < Cycles )
		{ MaxTests = Cycles; }

	Tests += Cycles;

	Scans ++;

	return Result;
#else
	return NULL;
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Insert an item into the find table.                            */
    /*                                                                  */
    /*   We need to insert a new page into the find table.  We expect   */
    /*   this to take quite a while as multiple threads can be using    */
    /*   this class at the same time.                                   */
    /*                                                                  */
    /********************************************************************/

VOID FIND::InsertInFindList( PAGE *Page )
	{
	REGISTER VOID *Address = (Page -> GetAddress());

	//
	//   Claim an exclusive lock so we can update the 
	//   find table and lookaside as needed.
	//
	ClaimFindExclusiveLock();

	//
	//   Insert a new page into the find table.
	//
	if ( ! Public )
		{ Page -> InsertInPrivateFindList( FindHashHead( Address ) ); }
	else
		{ Page -> InsertInPublicFindList( FindHashHead( Address ) ); }

	//
	//   When we create very small heaps (i.e. a heap
	//   where only 20-30 allocations are requested)
	//   the various caches become a problem as they
	//   tend to front load work.  So we allow a limit
	//   to be set before which we run with caches 
	//   disabled.
	//   
	if ( LookAsideActions >= LookAsideThreshold )
		{
		REGISTER SBIT32 Count;
		REGISTER CACHE *Cache = (Page -> GetCache());
		REGISTER SBIT32 Stride = (Cache -> GetAllocationSize());

		//
		//   We are about look up various lookaside entries
		//   and update any that are stale.  We need to do
		//   this for every lookaside slot that relates to
		//   the page.  If the allocation size is smaller
		//   than the lookaside slot size we can save some
		//   iterations by increasing the stride size.
		//
		if ( Stride <= ((SBIT32) MinAddressMask) )
			{ Stride = ((SBIT32) (MinAddressMask+1)); }

		//
		//   Whenever we add an entry from the find table
		//   the lookaside is potentially corrupt.  So we 
		//   need to update any lookaside entries relating
		//   to the page.
		//
		for ( Count=0;Count < Cache -> GetPageSize();Count += Stride )
			{
			REGISTER VOID *Segment = 
				((VOID*) ((((LONG) Address) + Count) & ~MinAddressMask));
			REGISTER LOOK_ASIDE *Current = 
				(FindLookAsideHead( Segment ));

			//
			//   Add the new page to the lookaside as we
			//   expect it to get hit pretty soon one way
			//   or another.
			//
			Current -> Address = Segment;
			Current -> Page = Page;
#ifdef DEBUGGING
			Current -> Version = Page -> GetVersion();
#endif
			}
		}

	//
	//   Update the statistics and resize the find
	//   table if it is over capacity.
	//
	if ( ((++ Used) + (MaxHash / MinHashSpace)) > MaxHash )
		{ ResizeHashTable(); }
#ifdef ENABLE_HEAP_STATISTICS

	if ( Used > MaxPages )
		{ MaxPages = Used; }
#endif

	//
	//   Release the lock if we claimed it earlier.
	//
	ReleaseFindExclusiveLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   A known area.                                                  */
    /*                                                                  */
    /*   We have an address and don't have a clue which heap            */
    /*   owns the space.  Here we take a look at the address            */
    /*   and figure out if it is known to the current heap.             */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::KnownArea( VOID *Address,CACHE *ParentCache )
    {
	REGISTER PAGE *Page;
	
	//
	//   If we need to be thread safe then claim a sharable lock
	//   on the hash table to stop it being changed under our feet.
	//
	ClaimFindShareLock();

	//
	//   Find out if the address belongs to this heap
	//   or any other heap of which we are aware (i.e.
	//   when single image is active).
	//
	Page = (ParentCache -> FindParentPage( Address,this ));

	//
	//   Release the lock if we claimed it earlier.
	//
	ReleaseFindShareLock();

	return (Page != ((PAGE*) NULL));
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release a shared lock and update.                              */
    /*                                                                  */
    /*   We have been asked to insert a page into the lookaside.        */
    /*   We assume the caller already has a share lock which we         */
    /*   release when we are finished.                                  */
    /*                                                                  */
    /********************************************************************/

VOID FIND::ReleaseFindShareLockAndUpdate
		( 
		VOID						  *Address,
		PAGE						  *Page,
		SBIT32						  Version
		)
    {
	//
	//   When we create very small heaps (i.e. a heap
	//   where only 20-30 allocations are requested)
	//   the various caches become a problem as they
	//   tend to front load work.  So we allow a limit
	//   to be set before which we run with caches 
	//   disabled.
	//   
	if ( LookAsideActions >= LookAsideThreshold )
		{
		//
		//   Claim an exclusive lock so we can update the 
		//   lookaside as needed.
		//
		ChangeToExclusiveLock();

#ifdef DEBUGGING
		if ( Page -> ValidPage() )
			{
#endif
			if ( Version == (Page -> GetVersion()) )
				{
				REGISTER LONG Base = (((LONG) Address) & ~MinAddressMask);
				REGISTER VOID *Segment = ((VOID*) Base);
				REGISTER LOOK_ASIDE *Current = FindLookAsideHead( Segment );

				//
				//   Overwrite any existing information.
				//
				Current -> Address = Segment;
				Current -> Page = Page;
#ifdef DEBUGGING
				Current -> Version = Page -> GetVersion();
#endif
#ifdef ENABLE_HEAP_STATISTICS

				//
				//   Update the statistics.
				//
				Fills ++;
#endif
				}
#ifdef DEBUGGING
			}
		else
			{ Failure( "Deleted page in ReleaseFindShareLockAndUpdate" ); }
#endif

		//
		//   Release the lock if we claimed it earlier.
		//
		ReleaseFindExclusiveLock();
		}
	else
		{ 
		//
		//   Release the lock if we claimed it earlier.
		//
		ReleaseFindShareLock(); 
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Resize the find table.                                         */
    /*                                                                  */
    /*   We need to grow the hash table as it appears to be a little    */
    /*   small given the number of pages that have been created.        */
    /*                                                                  */
    /********************************************************************/

VOID FIND::ResizeHashTable( VOID )
    {
	AUTO SBIT32 NewHashMask;
	AUTO SBIT32 NewLookAsideMask;

	//
	//   When we need to resize the hash table it is a
	//   straight race.  The first thread to claim the
	//   lock gets to do the work.  Everyone else just
	//   exits.
	//
	if ( (Resize) && (Spinlock.ClaimLock(0)) )
		{
		REGISTER SBIT32 AlignMask = (RockallBackEnd -> NaturalSize()-1);
		REGISTER SBIT32 NewMaxHash = (MaxHash * ExpandStore);
		REGISTER SBIT32 NewMaxLookAside = (MaxLookAside * ExpandStore);
		REGISTER SBIT32 NewHashSize = (NewMaxHash * sizeof(LIST));
		REGISTER SBIT32 NewLookAsideSize = (NewMaxLookAside * sizeof(LOOK_ASIDE));
		REGISTER SBIT32 NewTotalSize = (NewHashSize + NewLookAsideSize);
		REGISTER SBIT32 HashSizeLocal = (MaxHash * sizeof(LIST));
		REGISTER SBIT32 LookAsideSize = (MaxLookAside * sizeof(LOOK_ASIDE));
		REGISTER SBIT32 TotalSize = (HashSizeLocal + LookAsideSize);

		//
		//   It is actually possible for a thread to get
		//   delayed for so long that it thinks the hash 
		//   table still needs to be resized long after the 
		//   work has been completed.  Additionally, we want
		//   to make sure that all the new values are sane.
		//
		if 
				(
				PowerOfTwo( (AlignMask+1) )
					&&
				(NewMaxHash > 0)
					&&
				(ConvertDivideToShift( NewMaxHash,& NewHashMask ))
					&&
				(NewMaxLookAside > 0)
					&& 
				(ConvertDivideToShift( NewMaxLookAside,& NewLookAsideMask ))
					&&
				((Used + (MaxHash / MinHashSpace)) > MaxHash)
				)
			{
			REGISTER LIST *NewHash;
			REGISTER LOOK_ASIDE *NewLookAside;

			//
			//   We have been picked as the victim who
			//   needs to resize the hash table.  We are
			//   going to call the external allocator 
			//   to get more memory.  As we know this is 
			//   likely to to nail us we drop the lock to 
			//   allow other threads to continue.
			//
			ReleaseFindExclusiveLock();

			//
			//   We know that allocating a new table and 
			//   initializing it is going to take ages.
			//   Well at least everyone else gets to carry
			//   on in the mean time.
			//
			NewHash = 
				((LIST*) RockallBackEnd -> NewArea
					( 
					AlignMask,
					NewTotalSize,
					False 
					)
				);

			NewLookAside = 
				((LOOK_ASIDE*) & NewHash[ NewMaxHash ]);

			//
			//   If the memory allocation request for the hash
			//   table fails we exit and try again later. 
			//
			if ( NewHash != ((LIST*) AllocationFailure) )
				{
				REGISTER SBIT32 Count;

				//
				//   Call the constructor for each hash table
				//   linked list header.
				//
				for ( Count=0;Count < NewMaxHash;Count ++ )
					{ PLACEMENT_NEW( & NewHash[ Count ],LIST ); }

				//
				//   Zero the look aside structure.
				//
				for ( Count=0;Count < NewMaxLookAside;Count ++ )
					{
					REGISTER LOOK_ASIDE *Current = & NewLookAside[ Count ];

					Current -> Address = ((VOID*) NoCacheEntry);
					Current -> Page = ((PAGE*) NoCacheEntry);
#ifdef DEBUGGING
					Current -> Version = ((SBIT32) NoCacheEntry);
#endif
					}
				}

			//
			//   Claim an exclusive lock so we can resize  
			//   the hash table.
			//
			ClaimFindExclusiveLock();

			//
			//   If we have allocated the new find table
			//   we can now rehash the existing entries.
			//   If not we are out of here.
			//
			if ( NewHash != ((LIST*) AllocationFailure) )
				{
				REGISTER SBIT32 Count;
				REGISTER SBIT32 MaxOldHash = MaxHash;
				REGISTER LIST *OldHash = Hash;

				//
				//   Update the control information 
				//   for the new hash table.
				//
				MaxHash = NewMaxHash;
				HashShift = (32-NewHashMask);
				HashMask = ((1 << NewHashMask)-1);

				MaxLookAside = NewMaxLookAside;
				LookAsideShift = (32-NewLookAsideMask);
				LookAsideMask = ((1 << NewLookAsideMask)-1);

				Hash = NewHash;
				LookAside = NewLookAside;

				//
				//   Delete all the existing records
				//   from the old hash table and insert
				//   them into the new hash table.
				//
				for ( Count=0;Count < MaxOldHash;Count ++ )
					{
					REGISTER LIST *Current = & OldHash[ Count ];

					//
					//   There are two find lists.  There 
					//   is the private find list and the
					//   public find list.  We choose which
					//   one to walk along.
					//
					if ( ! Public )
						{
						//
						//   Walk along each hash bucket 
						//   deleting the records and inserting
						//   them into the new hash table.
						//
						while ( ! Current -> EndOfList() )
							{
							REGISTER PAGE *Page = 
								(PAGE::FirstInPrivateFindList( Current ));
							REGISTER VOID *Address = 
								(Page -> GetAddress());
							REGISTER LIST *HeadOfList = 
								(FindHashHead( Address ));

							//
							//   Delele from the old find list
							//   and add into the new find
							//   list.
							//
							Page -> DeleteFromPrivateFindList( Current );

							Page -> InsertInPrivateFindList( HeadOfList );
							}
						}
					else
						{
						//
						//   Walk along each hash bucket 
						//   deleting the records and inserting
						//   them into the new hash table.
						//
						while ( ! Current -> EndOfList() )
							{
							REGISTER PAGE *Page = 
								(PAGE::FirstInPublicFindList( Current ));
							REGISTER VOID *Address = 
								(Page -> GetAddress());
							REGISTER LIST *HeadOfList = 
								(FindHashHead( Address ));

							//
							//   Delele from the old find list
							//   and add into the new find
							//   list.
							//
							Page -> DeleteFromPublicFindList( Current );

							Page -> InsertInPublicFindList( HeadOfList );
							}
						}

					}

				//
				//   Time to do more operating system work
				//   so lets drop the lock again.
				//
				ReleaseFindExclusiveLock();

				//
				//   Delete all the list heads and return the
				//   original allocation to the operating system.
				//
				for ( Count=0;Count < MaxOldHash;Count ++ )
					{ PLACEMENT_DELETE( & OldHash[ Count ],LIST ); }

				//
				//   Deallocate the old extent.
				//
				RockallBackEnd -> DeleteArea
					( 
					((VOID*) OldHash),
					TotalSize,
					False 
					);

				//
				//   We are finished so reclaim the lock
				//   so we can exit.
				//
				ClaimFindExclusiveLock();
				}
			else
				{ Resize = False; }
			}

		Spinlock.ReleaseLock();
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Update the find table.                                         */
    /*                                                                  */
    /*   We need to update the find table with certain information      */
    /*   to ensure it is used correctly and consistently.               */
    /*                                                                  */
    /********************************************************************/

VOID FIND::UpdateFind( BIT32 NewMaxAddressMask,BIT32 NewMinAddressMask )
    {
	//
	//   When we have a single heap image all the 'TopCache' sizes
	//   must be the same.
	//
	if 
			( 
			(MaxAddressMask == NoAddressMask) 
				|| 
			(MaxAddressMask == NewMaxAddressMask) 
			)
		{
		//
		//   If we need to be thread safe then claim a sharable lock
		//   on the hash table to stop it being changed under our feet.
		//
		ClaimFindExclusiveLock();

		//
		//   Update the max address mask if it is not the current
		//   value but yet consistent.
		//
		MaxAddressMask = NewMaxAddressMask;

		//
		//   Update the address mask is the new heap has a smaller
		//   parent than all of the other heaps.
		//
		if ( MinAddressMask > NewMinAddressMask )
			{ MinAddressMask = NewMinAddressMask; }

		//
		//   Release the lock if we claimed it earlier.
		//
		ReleaseFindExclusiveLock();
		}
	else
		{ Failure( "Different 'TopCache' sizes with 'SingleImage'" ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Walk the heap.                                                 */
    /*                                                                  */
    /*   We have been asked to walk the heap.  It is hard to know       */
    /*   whay anybody might want to do this given the rest of the       */
    /*   functionality available.  Nonetheless, we just do what is      */
    /*   required to keep everyone happy.                               */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::Walk
		( 
		BOOLEAN						  *Active,
		VOID						  **Address,
		CACHE						  *ParentCache,
		SBIT32						  *Size 
		)
    {
	REGISTER VOID *Memory = (*Address);
	REGISTER BOOLEAN Result;
	REGISTER BOOLEAN Update;
	REGISTER PAGE *Page;
	
	//
	//   If we need to be thread safe then claim a sharable lock
	//   on the hash table to stop it being changed under our feet.
	//
	ClaimFindShareLock();

	//
	//   When the address is null we need to set up the heap
	//   walk.  In all other cases we just extract the next
	//   allocation in the list.
	//
	if ( Memory != NULL )
		{
		AUTO SEARCH_PAGE Details;

		//
		//   Lets try the lookaside table.  There is a pretty
		//   good chance that we will have the details we need 
		//   already in the cache.  If not we need to find it
		//   the hard way.  During the process we add the mapping
		//   into the lookaside for next time.
		//
		if
				(
				Update =
					( 
					! FindLookAside
						( 
						((VOID*) (((LONG) Memory) & ~MinAddressMask)),
						& Page 
						) 
					)
				)
			{
			//
			//   Find the allocation page and get the details of entry.
			//   We do this by finding the parent of the top cache.
			//   We  know that this is the global root and will find
			//   the correct page even if it is on another heap (as
			//   long as the find table is globally shared).
			//
			Page = (ParentCache -> FindParentPage( Memory,this ));
			}

		//
		//   We now compute all the details relating to the address
		//   so we can find any subsequent allocation.
		//
		if ( Page != ((PAGE*) NULL) )
			{ Page = (Page -> FindPage( Memory,& Details,this,True )); }

		//
		//   We may have failed to find the address  .If so
		//   we simply fail the call.  If not we find the next
		//   allocation in the heap.
		//
		if ( Result = ((Page != ((PAGE*) NULL)) && (Details.Found)) )
 			{
			//
			//   We need to walk the heap to get te details
			//   of the next allocation.
			//
			if ( Result = (Page -> Walk( & Details,this )) )
				{
				REGISTER BIT32 AllocationBit =
					((*Details.VectorWord) & Details.AllocationMask);

				(*Active) = (AllocationBit != 0);
				(*Address) = Details.Address;
				(*Size) = (Details.Page -> ActualSize());

				//
				//   If we are considering putting something
				//   in the lookaside lets make sure that
				//   we will get to hit the cache entry at
				//   least once.  If not lets forget putting
				//   it in the cache.
				//
				if ( Update )
					{
					Update =
						(
						(((LONG) Memory) & ~MinAddressMask)
							==
						(((LONG) Details.Address) & ~MinAddressMask)
						);
					}
				}
			}
		}
	else
		{
		AUTO SEARCH_PAGE Details;

		//
		//   We start a heap walk by setting the initial 
		//   address to the value null.
		//
		Details.Address = NULL;
		Details.Cache = ParentCache;
		Details.Page = NULL;

		Page = NULL;
		Update = False;

		//
		//   We walk the heap to get te details of the
		//   first heap allocation.
		//
		if ( Result = (Page -> Walk( & Details,this )) )
			{
			REGISTER BIT32 AllocationBit =
				((*Details.VectorWord) & Details.AllocationMask);

			(*Active) = (AllocationBit != 0);
			(*Address) = Details.Address;
			(*Size) = (Details.Page -> ActualSize());
			}
		}

	//
	//   Release the lock if we claimed it earlier and
	//   update the lookaside if needed.
	//
	if ( (Update) && (Result) )
		{ ReleaseFindShareLockAndUpdate( Memory,Page,Page -> GetVersion() ); }
	else
		{ ReleaseFindShareLock(); }

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Delete the hash table and release all the associated memory.   */
    /*                                                                  */
    /********************************************************************/

FIND::~FIND( VOID )
    {
	REGISTER SBIT32 Count;
	REGISTER SBIT32 HashSizeLocal = (MaxHash * sizeof(LIST));
	REGISTER SBIT32 LookAsideSize = (MaxLookAside * sizeof(LOOK_ASIDE));
	REGISTER SBIT32 TotalSize = (HashSizeLocal + LookAsideSize);

	//
	//   Call the destructor for each hash table
	//   linked list header.
	//
	for ( Count=0;Count < MaxHash;Count ++ )
		{ PLACEMENT_DELETE( & Hash[ Count ],LIST ); }

	//
	//   Deallocate the area.
	//
	RockallBackEnd -> DeleteArea
		( 
		((VOID*) Hash),
		TotalSize,
		False 
		);
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\heap.hpp ===
#ifndef _HEAP_HPP_
#define _HEAP_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Common.hpp"
#include "Environment.hpp"
#include "Find.hpp"
#include "NewPage.hpp"
#include "Prefetch.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class BUCKET;
class CACHE;
class ROCKALL_BACK_END;

    /********************************************************************/
    /*                                                                  */
    /*   The heap interface.                                            */
    /*                                                                  */
    /*   The traditional memory allocation interface only supports      */
    /*   a single allocation heap.  This memory allocator supports      */
    /*   multiple allocation heaps.  However, the interface nicely      */
    /*   hides this so at this point we are back to the traditional     */
    /*   single heap interface.                                         */
    /*                                                                  */
    /********************************************************************/

class HEAP : public ENVIRONMENT, public COMMON
    {
		//
		//   Private data.
		//
		//   The heap is the top level container of all the
		//   functionality in the other classes.  The 'Active'
		//   flag indicates if the heap has been initialized.
		//   The 'MaxFreePages' controls the amount of free
		//   space the heap will slave before it starts to
		//   return it the the external allocator.  The
		//   'SmallestParentMask' is mask that shows which 
		//   parts of an address can be safely masked off
		//   and still ensure a hit in the find lookaside
		//   cache.
		//
		BOOLEAN						  Active;
		SBIT32						  MaxFreePages;
		BIT32						  SmallestParentMask;

		//
		//   A heap is merely a collection of fixed sized
		//   allocation buckets (each with an optional cache).
		//   The 'CachesSize' is the total number of buckets.
		//   The 'MinCacheSize' is the allocation size of the
		//   smallest bucket.  The 'MidCacheSize' is the size
		//   of the bucket where the stride changes.  The
		//   'MaxCacheSize' is the allocation size of the 
		//   largest bucket externally visable.
		//
		SBIT32						  CachesSize;
		SBIT32						  MinCacheSize;
		SBIT32						  MidCacheSize;
		SBIT32						  MaxCacheSize;

		//
		//   A key function of the heap is to convert the
		//   requested allocation size into a pointer to
		//   the appropriate bucket (and cache).  This has
		//   to be very fast and is achieved using a direct
		//   lookup (i.e. an array).  The lookup array 
		//   consists of two sections (i.e. for small sizes
		//   and large sizes) to minimize space.  The 
		//   'MaxTable1' and 'MaxTable2' variables contain 
		//   the size of each section of the array.  The 
		//   'ShiftSize1' and 'ShiftSize2' variables contain
		//   the shift that should be applied to the size to
		//   obtain the appropriate index.  The 'SizeToCache1'
		//   and 'SizeToCache2' pointers refer to the direct
		//   lookup tables.
		//   
		SBIT32						  MaxTable1;
		SBIT32						  MaxTable2;
		SBIT32						  ShiftSize1;
		SBIT32						  ShiftSize2;
		CACHE                         **SizeToCache1;
		CACHE                         **SizeToCache2;

		//
		//   The heap needs to have access to most of the 
		//   other classes.  The 'Caches' class sits on
		//   top of an allocation bucket which owns all
		//   the allocated memory for a given size.  The
		//   'ExternalCache' is a special bucket that 
		//   contains weird sized pages.  The 'Find' class
		//   translates allocation addresses to page 
		//   descriptions.  The 'Services' class is needed
		//   to gain access to the external allocation APIs.
		//   The 'NewPage' class owns all page descriptions
		//   and plays a significant role in whole heap
		//   operations.  The 'TopCache' is the largest 
		//   bucket size and owns almost all the externally
		//   allocated memory.  The 'ThreadSafe' class  
		//   indicates whether locking being used.
		//
		CACHE						  **Caches;
		CACHE						  *ExternalCache;
		NEW_PAGE					  *NewPage;
		PREFETCH					  Prefetch;
		FIND						  *PrivateFind;
		FIND						  *PublicFind;
		ROCKALL_BACK_END			  *RockallBackEnd;
		CACHE						  *TopCache;
		THREAD_SAFE					  *ThreadSafe;
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Statistics data.
		//
		//   A key feature of this heap is its ability to be
		//   significantly reconfigured at run time.  A great
		//   deal of complexity could have been removed if 
		//   certain static choices had been made.  Although
		//   this flexibility is nice the support of statistics
		//   here allows precise information to be collected so
		//   to enable the value of this to be maximized.
		//   
		//
		SBIT32						  CopyMisses;
		SBIT32						  MaxCopySize;
		SBIT32						  MaxNewSize;
		SBIT32						  NewMisses;
		SBIT32						  Reallocations;
		SBIT32						  *Statistics;
		SBIT32						  TotalCopySize;
		SBIT32						  TotalNewSize;
#endif

   public:
		//
		//   Public functions.
		//
		//   The heap exports the high level interface
		//   out to the world.  Any request a developer
		//   can make must come through one of these
		//   functions.
		//
        HEAP
			(
			CACHE					  *Caches1[],
			CACHE					  *Caches2[],
			SBIT32					  MaxFreeSpace,
			NEW_PAGE				  *NewPages,
			FIND					  *NewPrivateFind,
			FIND					  *NewPublicFind,
			ROCKALL_BACK_END		  *NewRockallBackEnd,
			SBIT32					  Size1,
			SBIT32					  Size2,
			SBIT32					  Stride1,
			SBIT32					  Stride2,
			THREAD_SAFE				  *NewThredSafe
			);

		BOOLEAN Delete( VOID *Address,SBIT32 Size = NoSize );

		VOID DeleteAll( BOOLEAN Recycle = True );

		BOOLEAN Details
			( 
			VOID					  *Address,
			SEARCH_PAGE				  *Details = NULL,
			SBIT32					  *Size = NULL 
			);

		BOOLEAN KnownArea( VOID *Address );

		VOID LockAll( VOID );

		BOOLEAN MultipleDelete
			( 
			SBIT32					  Actual,
			VOID					  *Array[],
			SBIT32					  Size = NoSize
			);

		BOOLEAN MultipleNew
			( 
			SBIT32					  *Actual,
			VOID					  *Array[],
			SBIT32					  Requested,
			SBIT32					  Size,
			SBIT32					  *Space = NULL,
			BOOLEAN					  Zero = False
			);

		VOID *New
			( 
			SBIT32					  Size,
			SBIT32					  *Space = NULL,
			BOOLEAN					  Zero = False
			);

		VOID *Resize
			( 
			VOID					  *Address,
			SBIT32					  NewSize,
			SBIT32					  Move = 1,
			SBIT32					  *Space = NULL,
			BOOLEAN					  NoDelete = False,
			BOOLEAN					  Zero = False
			);

		BOOLEAN Truncate( SBIT32 MaxFreeSpace = 0 );

		VOID UnlockAll( BOOLEAN Partial = False );

		BOOLEAN Verify( VOID *Address,SBIT32 *Size = NULL );

		BOOLEAN Walk
			( 
			BOOLEAN					  *Active,
			VOID					  **Address,
			SBIT32					  *Size 
			);

        ~HEAP( VOID );

		//
		//   Public inline functions.
		//
		//   Although these functions are public they mostly
		//   intended for internal consumption and are not
		//   to be called externally.
		//
		INLINE SBIT32 GetMaxFreePages( VOID )
			{ return MaxFreePages; }

		INLINE VOID *SpecialNew( SBIT32 Size )
			{ return NewPage -> NewCacheStack( Size ); }

	private:
		//
		//   Private functions.
		//
		//   All of the statistical information is 
		//   generated and output when the heaps
		//   destructor executes.
		//
		CACHE *FindCache( SBIT32 Size );

#ifdef ENABLE_HEAP_STATISTICS
		VOID PrintHeapStatistics( VOID );

#endif
		//
		//   Private inline functions.
		//
		//   The notion that resizing an allocation is 
		//   cheap has worked its way into the minds of 
		//   a large number of developers.  As a result
		//   parameter has been added to the function to
		//   allow the actual behavior to be controlled.
		//
		INLINE BOOLEAN ResizeTest( SBIT32 Delta,SBIT32 Move )
			{
			return
				(
				((Move > 0) && ((((Delta >= 0) ? Delta : -Delta) >= Move)))
					||
				((Move < 0) && ((Delta > 0) || (Delta <= Move)))
				);
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        HEAP( CONST HEAP & Copy );

        VOID operator=( CONST HEAP & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\heap.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "RockallBackEnd.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control minimum size of an         */
    /*   allocation bucket.                                             */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MinParentSize			  = 32;
CONST SBIT32 MaxSummaryColumns		  = 2;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a heap and prepare it for use.  Additionally, make      */
    /*   sure that the heap configuration makes sense.  This is         */
    /*   tricky as the whole structure of the heap can be changed       */
    /*   by the external configuration information.                     */
    /*                                                                  */
    /********************************************************************/

HEAP::HEAP
		(
		CACHE						  *Caches1[],
		CACHE						  *Caches2[],
		SBIT32						  MaxFreeSpace,
		NEW_PAGE					  *NewPages,
		FIND						  *NewPrivateFind,
		FIND						  *NewPublicFind,
		ROCKALL_BACK_END			  *NewRockallBackEnd,
		SBIT32						  Size1,
		SBIT32						  Size2,
		SBIT32						  Stride1,
		SBIT32						  Stride2,
		THREAD_SAFE					  *NewThreadSafe
		)
    {
	//
	//   The top three buckets are special and a user can not 
	//   allocate memory from two of them.  Thus, unless we have  
	//   at least four buckets the memory allocator is not going 
	//   to be very useful. 
	//
	if ( (Size1 >= 1) && (Size2 >= 3) )
		{
		REGISTER CACHE *FirstCache = Caches1[0];
		REGISTER CACHE *MiddleCache = Caches2[0];
		REGISTER CACHE *LastCache = Caches2[ (Size2-3) ];

		//
		//   Calculate the minimum and maximum allocation sizes.
		//   All allocations outside of this range will be passed
		//   directly to the external allocator.
		//
		CachesSize = (Size1 + Size2);
		MinCacheSize = FirstCache -> GetAllocationSize();
		MidCacheSize = MiddleCache -> GetAllocationSize();
		MaxCacheSize = LastCache -> GetAllocationSize();

		//
		//   Calculate and save various useful pointers needed
		//   during the course of execution.
		//
		Caches = Caches1;
		ExternalCache = (Caches2[ (Size2-1) ]);
		NewPage = NewPages;
		PrivateFind = NewPrivateFind;
		PublicFind = NewPublicFind;
		RockallBackEnd = NewRockallBackEnd;
		TopCache = (Caches2[ (Size2-2) ]);
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Zero the heap statistics.
		//
		CopyMisses = 0;
		MaxCopySize = 0;
		MaxNewSize = 0;
		NewMisses = 0;
		Reallocations = 0;
		TotalCopySize = 0;
		TotalNewSize = 0;
#endif

		//
		//   The external allocation size must be reasonable.
		//   All allocation sizes must be a multiple of the
		//   minimum allocation size.  The minimum allocation
		//   size and the middle allocation size must be a 
		//   power of two.
		//   
		if 
				( 
				(ExternalCache -> GetPageSize() == TopCache -> GetPageSize())
					&& 
				(PowerOfTwo( RockallBackEnd -> NaturalSize() ))
					&&
				(RockallBackEnd -> NaturalSize() >= PageSize())
					&&
				(TopCache -> GetPageSize() >= PageSize())
					&&
				(PowerOfTwo( TopCache -> GetPageSize() ))
					&&
				((Stride1 > 0) && (PowerOfTwo( Stride1 )))
					&&
				((Stride2 >= Stride1) && (PowerOfTwo( Stride2 )))
					&&
				(ConvertDivideToShift( Stride1,& ShiftSize1 ))
					&&
				(ConvertDivideToShift( Stride2,& ShiftSize2 ))
				)
			{
			REGISTER SBIT32 Count1;
			REGISTER SBIT32 TopCacheSize = (TopCache -> GetPageSize());
			REGISTER SBIT32 MaxSize1 = (MidCacheSize / Stride1);
			REGISTER SBIT32 MaxSize2 = (TopCacheSize / Stride2);

			//
			//   Calculate the maximum number of free pages 
			//   that can be kept.  Also set the smallest parent
			//   mask to the maximum value.
			//
			MaxFreePages = (MaxFreeSpace / (TopCache -> GetAllocationSize()));
			SmallestParentMask = ((TopCache -> GetAllocationSize())-1);
			ThreadSafe = NewThreadSafe;

			//
			//   Calculate the sizes of the arrays that map 
			//   sizes to caches.
			//
			MaxTable1 = (MaxSize1 * sizeof(CACHE*));
			MaxTable2 = (MaxSize2 * sizeof(CACHE*));

			//
			//   The heap pages must be specified in asceding
			//   order of size and be an exact multiple of the
			//   minimum allocation size.
			//
			for ( Count1=0;Count1 < Size1;Count1 ++ )
				{
				REGISTER CACHE *Current = Caches1[ Count1 ];
				REGISTER CACHE *Next = Caches1[ (Count1+1) ];
				REGISTER SBIT32 AllocationSize = Current -> GetAllocationSize();
				REGISTER SBIT32 ChunkSize = Current -> GetChunkSize();
				REGISTER SBIT32 PageSize = Current -> GetPageSize();

				//
				//   Ensure each cache specification meets the
				//   requirements of the heap.  If not fail
				//   the heap entire heap creation.
				//
				if ( (AllocationSize % Stride1) != 0 )
					{ Failure( "Cache size not multiple of stride" ); }

				if ( AllocationSize >= Next -> GetAllocationSize() )
					{ Failure( "Cache sizes not in ascending order" ); }

				if ( (AllocationSize > ChunkSize) || (ChunkSize > PageSize) )
					{ Failure( "Chunk size not suitable for cache" ); }

				if ( AllocationSize >= PageSize )
					{ Failure( "Cache size larger than parent size" ); }

				if ( PageSize > TopCacheSize )
					{ Failure( "Parent size exceeds 'TopCache' size" ); }
				}

			//
			//   The heap pages must be specified in asceding
			//   order of size and be an exact multiple of the
			//   minimum allocation size.
			//
			for ( Count1=0;Count1 < (Size2-2);Count1 ++ )
				{
				REGISTER CACHE *Current = Caches2[ Count1 ];
				REGISTER CACHE *Next = Caches2[ (Count1+1) ];
				REGISTER SBIT32 AllocationSize = Current -> GetAllocationSize();
				REGISTER SBIT32 ChunkSize = Current -> GetChunkSize();
				REGISTER SBIT32 PageSize = Current -> GetPageSize();

				//
				//   Ensure each cache specification meets the
				//   requirements of the heap.  If not fail
				//   the heap entire heap creation.
				//
				if ( (AllocationSize % Stride2) != 0 )
					{ Failure( "Cache size not multiple of stride" ); }

				if ( AllocationSize >= Next -> GetAllocationSize() )
					{ Failure( "Cache sizes not in ascending order" ); }

				if ( (AllocationSize > ChunkSize) || (ChunkSize > PageSize) )
					{ Failure( "Chunk size not suitable for cache" ); }

				if ( AllocationSize >= PageSize )
					{ Failure( "Cache size larger than parent size" ); }

				if ( PageSize > TopCacheSize )
					{ Failure( "Parent size exceeds 'TopCache' size" ); }
				}

			//
			//   The external and top caches have special rules
			//   which must be checked to ensure these caches
			//   are valid.
			//
			for ( Count1=(Size2-2);Count1 < Size2;Count1 ++ )
				{
				REGISTER CACHE *Current = Caches2[ Count1 ];
				REGISTER SBIT32 AllocationSize = Current -> GetAllocationSize();

				//
				//   Ensure each cache specification meets the
				//   requirements of the heap.  If not fail
				//   the heap entire heap creation.
				//
				if ( (AllocationSize % Stride2) != 0 )
					{ Failure( "Top cache size not multiple of minimum" ); }

				if ( AllocationSize != Current -> GetChunkSize() )
					{ Failure( "Chunk size not suitable for top cache" ); }

				if ( AllocationSize != Current -> GetPageSize() )
					{ Failure( "Page size not suitable for top cache" ); }

				if ( Current -> GetCacheSize() != 0 )
					{ Failure( "Cache size not zero for top cache" ); }
				}

			//
			//   We need to allocate two arrays to enable requested
			//   sizes to be quickly mapped to allocation caches.
			//   Here we allocate the tables and later fill in all
			//   the necessary mapping information.
			//
			SizeToCache1 = (CACHE**) 
				(
				RockallBackEnd -> NewArea
					(
					(RockallBackEnd -> NaturalSize() - 1),
					(MaxTable1 + MaxTable2),
					False
					)
				);
#ifdef ENABLE_HEAP_STATISTICS

			//
			//   When we are compiled for statistics we keep
			//   information on all the allocations we see.
			//
			Statistics = (SBIT32*)
				(
				RockallBackEnd -> NewArea
					(
					(RockallBackEnd -> NaturalSize() - 1),
					(MaxCacheSize * sizeof(SBIT32)),
					False
					)
				);
#endif

			//
			//   We make sure that the allocations we made 
			//   did not fail.  If not we have to fail the 
			//   creation of the whole heap.
			//
			if 
					( 
					(SizeToCache1 != ((CACHE**) AllocationFailure))
#ifdef ENABLE_HEAP_STATISTICS
						&&
					(Statistics != ((SBIT32*) AllocationFailure))
#endif
					) 
				{
				REGISTER SBIT32 Count2;

				//
				//   Cycle through the first segment of the 
				//   mapping table creating approriate 
				//   translations.
				//
				for ( Count1=0,Count2=0;Count1 < MaxSize1;Count1 ++ )
					{
					//
					//   We make sure that the current allocation
					//   page is large enough to hold an element
					//   of some given size.  If not we move on to
					//   the next allocation page.
					//
					if 
							( 
							((Count1 + 1) * Stride1)
								> 
							(Caches1[ Count2 ] -> GetAllocationSize()) 
							)
						{ Count2 ++; }

					//
					//   Store a pointer so that a request for
					//   this size of allocation goes directly
					//   to the correct page.
					//
					SizeToCache1[ Count1 ] = Caches1[ Count2 ];
					}

				//
				//   Compute the start address for the second
				//   segment of the table.
				//
				SizeToCache2 = 
					((CACHE**) & ((CHAR*) SizeToCache1)[ MaxTable1 ]);

				//
				//   Cycle through the second segment of the 
				//   mapping table creating approriate 
				//   translations.
				//
				for ( Count1=0,Count2=0;Count1 < MaxSize2;Count1 ++ )
					{
					//
					//   We make sure that the current allocation
					//   page is large enough to hold an element
					//   of some given size.  If not we move on to
					//   the next allocation page.
					//
					if 
							( 
							((Count1 + 1) * Stride2)
								> 
							(Caches2[ Count2 ] -> GetAllocationSize()) 
							)
						{ Count2 ++; }

					//
					//   Store a pointer so that a request for
					//   this size of allocation goes directly
					//   to the correct page.
					//
					SizeToCache2[ Count1 ] = Caches2[ Count2 ];
					}

				//
				//   Now that we have created the size to cache 
				//   mappings lets use them to link each cache to  
				//   the cache it uses to allocate additional 
				//   memory.
				//
				for ( Count1=0;Count1 < (CachesSize-1);Count1 ++ )
					{
					REGISTER CACHE *CurrentCache = Caches[ Count1 ];
					REGISTER SBIT32 PageSize = CurrentCache -> GetPageSize();
					REGISTER CACHE *ParentCache = FindCache( PageSize );
					REGISTER BOOLEAN Top = (CurrentCache == ParentCache);

					//
					//   Ensure that the parent cache is suitable
					//   and in line with what we were expecting. 
					//
					if 
							(
							(PowerOfTwo( PageSize ))
								&&
							(PageSize >= MinParentSize)
								&&
							(PageSize == (ParentCache -> GetAllocationSize()))
							)
						{
						//
						//   We keep track of the smallest
						//   cache that is a parent.  We can
						//   use this to improve the performance
						//   of the find hash table.
						//
						if ( ((BIT32) PageSize) < SmallestParentMask )
							{ SmallestParentMask = (PageSize-1); }

						//
						//   Update the current cache with  
						//   information about it's parent 
						//   cache.
						//
						CurrentCache -> UpdateCache
							(
							this,
							NewPages,
							((Top) ? ((CACHE*) GlobalRoot) : ParentCache),
							PrivateFind,
							PublicFind
							); 
						} 
					else
						{ Failure( "Parent bucket is invalid" ); }
					}
#ifdef ENABLE_HEAP_STATISTICS

				//
				//   It is probably a good idea to zero the 
				//   statistics area.
				//
				ZeroMemory( Statistics,(MaxCacheSize * sizeof(SBIT32)) );
#endif

				//
				//   The external cache is an exact duplicate
				//   of the top cache and is used to hold all
				//   memory allocations that are too large for
				//   any bucket.  Nonetheless, its parent is
				//   still the top cache.
				//
				ExternalCache -> UpdateCache
					(
					this,
					NewPages,
					TopCache,
					PrivateFind,
					PublicFind
					);

				//
				//   Update the new page structure with the 
				//   details of the top cache.
				//
				NewPage -> UpdateNewPage( TopCache );

				//
				//   Update the hash table with the minimum
				//   parent size for this heap.
				//
				PrivateFind -> UpdateFind
					(
					(TopCache -> GetAllocationSize()-1),
					SmallestParentMask 
					);

				//
				//   If there is a public find table then
				//   update the hash table with the minimum
				//   parent size for this heap.
				//
				if ( PublicFind != NULL )
					{
					PublicFind -> UpdateFind
						(
						(TopCache -> GetAllocationSize()-1),
						SmallestParentMask 
						);
					}

				//
				//   Activate the heap.
				//
				Active = True;
				}
			else
				{ Failure( "Mapping table in constructor for HEAP" ); }
			}
		else
			{ Failure( "The allocation sizes in constructor for HEAP" ); }
		}
	else
		{ Failure( "A heap size in constructor for HEAP" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Memory deallocation.                                           */
    /*                                                                  */
    /*   We need to release some memory.  First we try to slave the     */
    /*   request in the free cache so we can do a batch of releases     */
    /*   later.  If not we are forced to do it at once.                 */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Delete( VOID *Address,SBIT32 Size )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   When the caller gives us the size of the 
		//   allocation we can short cut the deallocation 
		//   process by skipping directly to the correct 
		//   cache.  However, if the user supplies us
		//   with bogus data we will retry using the
		//   the full deallocation process.
		//
		if ( (Size > 0) && (Size <= MaxCacheSize) )
			{
			REGISTER CACHE *Cache = (FindCache( Size ));

			if ( PrivateFind -> Delete( Address,Cache ) )
				{ return True; }
			}

		//
		//   It looks like all we have is the address so 
		//   deallocate using the long path.
		//
		if ( PrivateFind -> Delete( Address,TopCache ) )
			{ return True; }
		else
			{
			//
			//   The 'Address' does not belong to this
			//   heap so lets try the public find table.
			//
			if ( PublicFind != NULL )
				{
				//
				//   When the caller gives us the size of the 
				//   allocation we can short cut the deallocation 
				//   process by skipping directly to the correct 
				//   cache.  However, if the user supplies us
				//   with bogus data we will retry using the
				//   the full deallocation process.
				//
				if ( (Size > 0) && (Size <= MaxCacheSize) )
					{
					REGISTER CACHE *Cache = (FindCache( Size ));

					if ( PublicFind -> Delete( Address,Cache ) )
						{ return True; }
					}

				//
				//   It looks like all we have is the address  
				//   so deallocate using the long path.
				//
				return (PublicFind -> Delete( Address,TopCache ));
				}
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete all allocations.                                        */
    /*                                                                  */
    /*   We delete the entire heap and free all existing allocations.   */
    /*   If 'Recycle' is requested we slave the allocated memory as     */
    /*   we expect some new allocations.  If not we return all the      */
    /*   memory to the external allocator.                              */
    /*                                                                  */
    /********************************************************************/

VOID HEAP::DeleteAll( BOOLEAN Recycle )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		REGISTER SBIT32 Count;

		//
		//   We claim all of the heap locks to freeze
		//   all new allocations or deletions.
		//
		LockAll();

		//
		//   Now reset all the caches and the find
		//   hash table statistics.
		//
		PrivateFind -> DeleteAll();

		for ( Count=0;Count < CachesSize;Count ++ )
			{ Caches[ Count ] -> DeleteAll(); }

		//
		//   Delete the heap.
		//
		NewPage -> DeleteAll( Recycle );

		//
		//   Now release all the heap locks we claimed
		//   earlier and unfreeze the heap.
		//
		UnlockAll();

		//
		//   Trim the free space if needed.
		//
		if ( Recycle )
			{ TopCache -> ReleaseSpace( MaxFreePages ); }
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Details of a memory allocation.                                */
    /*                                                                  */
    /*   We need to the details of a particular memory allocation.      */
    /*   All we have is an address.  We use this to find the largest    */
    /*   allocation page this address is contained in and then          */
    /*   navigate through the sub-divisions of this page until we       */
    /*   find the allocation.                                           */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Details
		(
		VOID						  *Address,
		SEARCH_PAGE					  *Details,
		SBIT32						  *Size
		)
    {
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		AUTO SBIT32 Dummy;

		//
		//   We allow the caller to omit the 'Size' parameter.
		//   I can see little reason for this but it is supported
		//   anyway.
		//
		if ( Size == NULL )
			{ Size = & Dummy; }

		//
		//   We may need to try more than one find table
		//   but we always try the the private one
		//   first to minimize shared memory accesses.
		//
		if ( PrivateFind -> Details( Address,Details,TopCache,Size ) )
			{ return True; }
		else
			{
			//
			//   We need to try the public find table
			//   as the private find table could not 
			//   locate the address.
			//
			return
				(
				(PublicFind != NULL)
					&&
				(PublicFind -> Details( Address,Details,TopCache,Size ))
				);
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find a cache.                                                  */
    /*                                                                  */
    /*   Find the allocation cache for the size supplied and return     */
    /*   a pointer to it.                                               */
    /*                                                                  */
    /********************************************************************/

CACHE *HEAP::FindCache( SBIT32 Size )
	{
#ifdef DISABLED_AT_PRESENT
	REGISTER CACHE *Cache;

#endif
	//
	//   Compute the cache address.
	//
	if ( Size < MidCacheSize )
		{ return (SizeToCache1[ ((Size-1) >> ShiftSize1) ]); }
	else
		{ return (SizeToCache2[ ((Size-1) >> ShiftSize2) ]); }
#ifdef DISABLED_AT_PRESENT

	//
	//   Prefetch the class data if we are running a
	//   Pentium III or better with locks.  We do this
	//   because prefetching hot SMP data structures
	//   really helps.  However, if the structures are
	//   not shared (i.e. no locks) then it is worthless
	//   overhead.
	//
	if ( ThreadSafe )
		{ Prefetch.Nta( ((CHAR*) Cache),sizeof(CACHE) ); }

	return Cache;
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   A known area.                                                  */
    /*                                                                  */
    /*   A known area is an address that is understood to be            */
    /*   accessable from the current heap.  If the 'SingleImage'        */
    /*   flag is set it may actually be part of another heap that       */
    /*   the current heap can access.                                   */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::KnownArea( VOID *Address )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We may need to try more than one find table
		//   but we always try the the private one
		//   first to minimize shared memory accesses.
		//
		if ( PrivateFind -> KnownArea( Address,TopCache ) )
			{ return True; }
		else
			{
			//
			//   We need to try the public find table
			//   as the private find table could not 
			//   locate the area.
			//
			if ( PublicFind != NULL )
				{ return (PublicFind -> KnownArea( Address,TopCache )); }
			}
		}

	return False;
	}
    /********************************************************************/
    /*                                                                  */
    /*   Claim a lock on the entire heap.                               */
    /*                                                                  */
    /*   We claim a lock on the heap to improve performance             */
    /*   or prevent others from performing heap operations.             */
    /*                                                                  */
    /********************************************************************/

VOID HEAP::LockAll( VOID )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We claim the locks if we have not already
		//   claimed them earlier.
		//
		if ( ThreadSafe -> ClaimGlobalLock() )
			{
			REGISTER SBIT32 Count;

			//
			//   We claim all of the heap locks to freeze
			//   all new allocations or deletions.
			//
			for ( Count=0;Count < CachesSize;Count ++ )
				{ Caches[ Count ] -> ClaimCacheLock(); }

			//
			//  Although the heap is frozen at this point
			//  we claim the last few locks just to be
			//  tidy.
			//
			PrivateFind -> ClaimFindExclusiveLock();

			NewPage -> ClaimNewPageLock();

			//
			//   Engage the global lock and make it active
			//   to prevent further lock calls on this
			//   thread.
			//
			ThreadSafe -> EngageGlobalLock();
			}
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete multiple allocations.                                   */
    /*                                                                  */
    /*   We need to release multiple memory allocations.  First we try  */
    /*   to slave the requets in the free cache so we can do a batch    */
    /*   of releases later.  If not we are forced to do it immediately. */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::MultipleDelete
		( 
		SBIT32						  Actual,
		VOID						  *Array[],
		SBIT32						  Size 
		)
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		REGISTER SBIT32 Count;
		REGISTER BOOLEAN Result = True;
		REGISTER CACHE *ParentCache = ((CACHE*) GlobalRoot);

		//
		//   When the caller gives us the size of the allocation
		//   we can short cut the deallocation process by skipping
		//   directly to the correct cache.  However, if the user
		//   supplies us with bogus data we will retry using the
		//   the long path.
		//
		if ( (Size > 0) && (Size <= MaxCacheSize) )
			{
			REGISTER CACHE *Cache = (FindCache( Size ));

			//
			//   Compute a pointer to the parent cache
			//   so we can optimize the deletes.
			//
			ParentCache = (Cache -> GetParentCache());

			//
			//   Delete each memory allocation one at a time.
			//   We would like to delete them all at once but
			//   we can't be sure they are all vaild or related.
			//
			for ( Count=0;Count < Actual;Count ++ )
				{
				REGISTER VOID *Address = Array[ Count ];

				//
				//   Lets try to optimize the delete.
				//
				if ( ! PrivateFind -> Delete( Address,ParentCache ) ) 
					{
					//
					//   Lets try a standard full delete.
					//
					if ( ! PrivateFind -> Delete( Address,TopCache ) )
						{
						//
						//   The 'Address' does not belong
						//   to the current heap so lets
						//   try using the global find table
						//   to try a global delete.
						//
						if ( ! PublicFind -> Delete( Address,TopCache ) )
							{ Result = False; }
						}
					}
				}
			}
		else
			{
			//
			//   Delete each memory allocation one at a time.
			//   We would like to delete them all at once but
			//   we can't be sure they are all vaild or related.
			//
			for ( Count=0;Count < Actual;Count ++ )
				{
				REGISTER VOID *Address = Array[ Count ];

				//
				//   Lets try a standard full delete.
				//
				if ( ! PrivateFind -> Delete( Address,TopCache ) )
					{
					//
					//   The 'Address' does not belong to
					//   the current heap so lets try using
					//   the global find table to try a
					//   global delete.
					//
					if ( ! PublicFind -> Delete( Address,TopCache ) )
						{ Result = False; }
					}
				}
			}

		return Result;
		}
	else
		{ return False; }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory allocations.                                   */
    /*                                                                  */
    /*   We have been asked to allocate muliple memory blocks.   We     */
    /*   we do this by using the cache and then claiming and addition   */
    /*   space from the heap as needed.                                 */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::MultipleNew
		( 
		SBIT32						  *Actual,
		VOID						  *Array[],
		SBIT32						  Requested,
		SBIT32						  Size,
		SBIT32						  *Space,
		BOOLEAN						  Zero
		)
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		AUTO SBIT32 Dummy;

		//
		//   We allow the caller to omit the 'Actual' parameter.
		//   I can see little reason for this but it is supported
		//   anyway.  Regardless we zero it.
		//
		if ( Actual == NULL )
			{ Actual = & Dummy; }

		(*Actual) = 0;

		//
		//   We need to be sure that the size requested is in the 
		//   range supported by the memory allocator.  If not we
		//   do a series of single allocations from the default
		//   allocator.
		//
		if ( (Size > 0) && (Size <= MaxCacheSize) )
			{
			REGISTER CACHE *Cache = (FindCache( Size ));
			REGISTER SBIT32 NewSize = (Cache -> GetAllocationSize());

			//
			//   Allocate memory from the appropriate 
			//   allocation bucket.
			//
			(VOID) Cache -> MultipleNew( Actual,Array,Requested );

			//
			//   If needed return the actual amount  
			//   of space allocated for each element.
			//
			if ( Space != NULL )
				{ (*Space) = NewSize; }
#ifdef ENABLE_HEAP_STATISTICS

			//
			//   Update the allocation statistics.
			//
			Statistics[ (Size-1) ] += Requested;
#endif

			//
			//   If needed zero each element that is  
			//   allocated.
			//
			if ( Zero )
				{
				REGISTER SBIT32 Count;

				for ( Count=((*Actual)-1);Count >= 0;Count -- )
					{ ZeroMemory( Array[ Count ],NewSize ); }
				}

			return ((*Actual) == Requested);
			}
		else
			{
			//
			//   If the allocation size is greater than
			//   zero we create the allocations.  If not
			//   we fail the request.
			//
			if ( Size > 0 )
				{
				//
				//   We have got a request for an element size
				//   larger than the largest bucket size.  So 
				//   we call the single allocation interface 
				//   as this supports large sizes.
				//
				for 
					( 
					/* void */;
					((*Actual) < Requested)
						&&
					((Array[ (*Actual) ] = New( Size )) != AllocationFailure);
					(*Actual) ++ 
					);

				//
				//   If needed return the actual amount of space 
				//   allocated for each element.
				//
				if ( Space != NULL )
					{ (*Space) = Size; }

				return ((*Actual) == Requested);
				}
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Memory allocation.                                             */
    /*                                                                  */
    /*   We have been asked to allocate some memory.  Hopefully,        */
    /*   we will be able to do this out of the cache.  If not we        */
    /*   will need to pass it along to the appropriate allocation       */
    /*   bucket.                                                        */
    /*                                                                  */
    /********************************************************************/

VOID *HEAP::New( SBIT32 Size,SBIT32 *Space,BOOLEAN Zero )
	{
	REGISTER VOID *NewMemory = ((VOID*) AllocationFailure);

	//
	//   Although normally a class is never called before
	//   its constructor. The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We ensure the allocation size is in
		//   the range supported by the heap.
		//
		if ( (Size > 0) && (Size <= MaxCacheSize) )
			{
			REGISTER CACHE *Cache = (FindCache( Size ));
#ifdef ENABLE_HEAP_STATISTICS

			//
			//   Update the allocation statistics.
			//
			Statistics[ (Size-1) ] ++;
#endif

			//
			//   Allocate memory from the appropriate
			//   cache in the heap.
			//
			NewMemory = (Cache -> New()); 
			Size = (Cache -> GetAllocationSize());
			}
		else
			{ 
			//
			//   If the allocation size is greater than
			//   zero we create the allocation.  If not
			//   we fail the request.
			//
			if ( Size > 0 )
				{
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   Update the allocation statistics.
				//
				if ( Size > MaxNewSize )
					{ MaxNewSize = Size; }

				NewMisses ++;
				TotalNewSize += Size;

#endif
				//
				//   Allocate memory from a special
				//   cache bucket which gets space
				//   externally.
				//
				NewMemory = (ExternalCache -> New( False,Size ));
				}
			else
				{ NewMemory = ((VOID*) AllocationFailure); }
			}

		//
		//   We need to be sure that the allocation 
		//   request did not fail.
		//
		if ( NewMemory != ((VOID*) AllocationFailure) )
			{
			//
			//   If needed return the actual amount of space 
			//   allocated for this request.
			//
			if ( Space != NULL )
				{ (*Space) = Size; }

			//
			//   Zero the memory if the needed.
			//
			if ( Zero )
				{ ZeroMemory( NewMemory,Size ); }
			}
		}

	return NewMemory;
	}
#ifdef ENABLE_HEAP_STATISTICS

    /********************************************************************/
    /*                                                                  */
    /*   Print statistics.                                              */
    /*                                                                  */
    /*   We output the allocation statistics to the debug console.      */
    /*                                                                  */
    /********************************************************************/

VOID HEAP::PrintHeapStatistics( VOID )
	{
	REGISTER SBIT32 Count1;
	REGISTER SBIT32 Count2;
	REGISTER SBIT32 HighWater = 0;
	REGISTER SBIT32 Total = 0;
	STATIC GLOBALLOCK Globallock;

	//
	//   Claim a lock so that multiple threads have
	//   to wait to output any heap statistics.
	//
	Globallock.ClaimLock();

	//
	//
	//   Output the heap details to the debug
	//   console along with an explaination.
	//
	DebugPrint
		(
		"\n"
		"Heap at 0x%x\n"
		"\n"
		"A summary of all the requested sizes, "
		"supplied sizes and associated counts.\n"
		"A brief examination of this summary "
		"should provide a good understanding of\n"
		"an applications overall heap usage"
		"patterns.\n"
		"\n",
		this
		);

	//
	//   Output the titles for the summary table.
	//
	for ( Count1=0;Count1 < MaxSummaryColumns;Count1 ++ )
		{ DebugPrint( "   Actual  Supplied    Total            " ); }

	//
	//   Skip to a new line.
	//
	DebugPrint( "\n" );

	for ( Count1=0;Count1 < MaxSummaryColumns;Count1 ++ )
		{ DebugPrint( "    Size     Size      Calls            " ); }

	//
	//   Skip to a new line.
	//
	DebugPrint( "\n" );

	//
	//   Output the contents of the summary table.
	//
	for ( Count1=0;Count1 < MaxCacheSize;/* void */ )
		{
		//
		//   Output the each non-zero data point.
		//
		for 
				( 
				Count2=0;
				(Count1 < MaxCacheSize) && (Count2 < MaxSummaryColumns);
				Count1 ++ 
				)
			{
			REGISTER SBIT32 Hits = Statistics[ Count1 ];

			//
			//   When the nimber of hits is 
			//   non-zero we output the data.
			//
			if ( Hits > 0 )
				{
				REGISTER CACHE *Cache = FindCache( (Count1+1) );

				//
				//   Output the values.
				//
				DebugPrint
					(
					"%8d  %8d  %8d            ",
					(Count1 + 1),
					Cache -> GetAllocationSize(),
					Hits
					);

				//
				//   Update the column and totals.
				//
				Count2 ++;

				Total += Hits;
				}
			}

		//
		//   Skip to a new line.
		//
		DebugPrint( "\n" );
		}

	//
	//
	//   Output the cache details to the debug
	//   console along with an explaination.
	//
	DebugPrint
		(
		"\n"
		"A summary of the activity of all the "
		"heap caches.  A brief examination of\n"
		"this summary should provide a good "
		"understanding of how the heap dealt\n"
		"with the applications heap usage"
		"patterns.\n"
		);

	//
	//   Output the titles to the debug console.
	//
	DebugPrint
		( 
		"\n"
		"   Actual    Cache     Cache      High      High     Active\n"
		"    Size     Fills    Flushes     Tide      Water    In Use\n"
		);

	//
	//   Output details for every sample size.
	//
	for ( Count1=0;Count1 < CachesSize;Count1 ++ )
		{
		REGISTER CACHE *Cache = Caches[ Count1 ];

		//
		//   Skip this cache if it was not active
		//   as the statistics will be all zeros.
		//
		if ( Cache -> GetHighWater() > 0 )
			{
			//
			//   Output the cache details.
			//
			DebugPrint
				(
				"%8d  %8d  %8d  %8d  %8d  %8d\n",
				Cache -> GetAllocationSize(),
				Cache -> GetCacheFills(),
				Cache -> GetCacheFlushes(),
				Cache -> GetHighTide(),
				Cache -> GetHighWater(),
				Cache -> GetInUse()
				);
			
			//
			//   Compute the space high water mark.
			//
			HighWater += 
				(Cache -> GetHighWater() * Cache -> GetAllocationSize());
			}
		}

	//
	//   Print the private hash table statistics.
	//
	DebugPrint
		(
		"\n"
		"Private Hash Table Statistics\n"
		"-----------------------------\n"
		"\t*** Cache ***\n"
		"\tFills\t\t: %d\n"
		"\tHits\t\t: %d\n"
		"\tMisses\t\t: %d\n"
		"\t*** Table ***\n"
		"\tAverage\t\t: %d\n"
		"\tMax\t\t: %d\n"
		"\tScans\t\t: %d\n"
		"\tMax Hash\t: %d\n"
		"\tMax LookAside\t: %d\n"
		"\tUsage\t\t: %d%%\n",
		PrivateFind -> CacheFills(),
		PrivateFind -> CacheHits(),
		PrivateFind -> CacheMisses(),
		PrivateFind -> AverageHashLength(),
		PrivateFind -> MaxHashLength(),
		PrivateFind -> TotalScans(),
		PrivateFind -> MaxHashSize(),
		PrivateFind -> MaxLookAsideSize(),
		PrivateFind -> MaxUsage()
		);

	
	//
	//   Print the public hash table statistics
	//   (if applicable).
	//
	if ( PublicFind != NULL )
		{
		DebugPrint
			(
			"\n"
			"Public Hash Table Statistics\n"
			"----------------------------\n"
			"\t*** Cache ***\n"
			"\tFills\t\t: %d\n"
			"\tHits\t\t: %d\n"
			"\tMisses\t\t: %d\n"
			"\t*** Table ***\n"
			"\tAverage\t\t: %d\n"
			"\tMax\t\t: %d\n"
			"\tScans\t\t: %d\n"
			"\tMax Hash\t: %d\n"
			"\tMax LookAside\t: %d\n"
			"\tUsage\t\t: %d%%\n",
			PublicFind -> CacheFills(),
			PublicFind -> CacheHits(),
			PublicFind -> CacheMisses(),
			PublicFind -> AverageHashLength(),
			PublicFind -> MaxHashLength(),
			PublicFind -> TotalScans(),
			PublicFind -> MaxHashSize(),
			PublicFind -> MaxLookAsideSize(),
			PublicFind -> MaxUsage()
			);
		}

	//
	//   Print the reallocation statistics.
	//

	DebugPrint
		(
		"\n"
		"Oversize Statistics\n"
		"-------------------\n"
		"\tAverage Size\t: %d\n"
		"\tMax Size\t: %d\n"
		"\tMisses\t\t: %d\n",
		(TotalNewSize / ((NewMisses > 0) ? NewMisses : 1)),
		MaxNewSize,
		NewMisses
		);

	//
	//   Print the reallocation statistics.
	//
	DebugPrint
		(
		"\n"
		"Realloc Statistics\n"
		"------------------\n"
		"\tAverage Copy\t: %d\n"
		"\tCalls\t\t: %d\n"
		"\tMax Copy\t: %d\n"
		"\tTotal Copies\t: %d\n",
		(TotalCopySize / ((CopyMisses > 0) ? CopyMisses : 1)),
		Reallocations,
		MaxCopySize,
		CopyMisses
		);

	//
	//   Print the general statistics.
	//

	DebugPrint
		(
		"\n"
		"Summary Statistics\n"
		"------------------\n"
		"\tMax Heap\t: %d\n"
		"\tTotal Calls\t: %d\n",
		HighWater,
		Total
		);

	//
	//   Relesae the lock.
	//
	Globallock.ReleaseLock();
	}
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Memory reallocation.                                           */
    /*                                                                  */
    /*   We have been asked to reallocate some memory.  Hopefully,      */
    /*   we will be able to do this out of the cache.  If not we        */
    /*   will need to pass it along to the appropriate allocation       */
    /*   bucket, do a copy and free the orginal allocation.             */
    /*                                                                  */
    /********************************************************************/

VOID *HEAP::Resize
		( 
		VOID						  *Address,
		SBIT32						  NewSize,
		SBIT32						  Move,
		SBIT32						  *Space,
		BOOLEAN						  NoDelete,
		BOOLEAN						  Zero
		)
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		AUTO SBIT32 Size;
		AUTO SBIT32 NewSpace;

		//
		//   Find the details of the existing allocation.
		//   If there is no existing allocation then exit.
		//
		if ( Details( Address,NULL,& Size ) )
			{
			REGISTER VOID *NewMemory;
			REGISTER SBIT32 Smallest = ((Size < NewSize) ? Size : NewSize);

			//
			//   Make sure the sizes appear to make sense.
			//
			if ( Smallest > 0 )
				{
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   Update the statistics.
				//
				Reallocations ++;

#endif
				//
				//   When the new allocation allocation is 
				//   standard heap allocation size we check 
				//   for various optimizations.
				//
				if ( NewSize <= MaxCacheSize )
					{
					REGISTER CACHE *Cache = (FindCache( NewSize ));
					REGISTER SBIT32 CacheSize = (Cache -> GetAllocationSize());
					REGISTER SBIT32 Delta = (CacheSize - Size);
					
					//
					//   We only need to reallocate if the new
					//   size is larger than the current bucket
					//   or the new size is smaller and we have 
					//   been given permission to move the 
					//   allocation.
					//
					if ( ResizeTest( Delta,Move ) )
						{
						//
						//   We need to allocate some more
						//   memory and copy the old data.
						//   into the new area.
						//
						NewMemory = (Cache -> New());
						NewSpace = CacheSize;
#ifdef ENABLE_HEAP_STATISTICS

						//
						//   Update the statistics.
						//
						Statistics[ (NewSize-1) ] ++;
#endif
						}
					else
						{
						//
						//   If the new size is unchanged or smaller
						//   then just return the current allocation.
						//   If the new size is larger then we must
						//   fail the call.
						//
						if ( Delta <= 0 )
							{
							//
							//   The amount of memory allocated for  
							//   this request is unchanged so return  
							//   the current size.
							//
							if ( Space != NULL )
								{ (*Space) = Size; }

							return Address; 
							}
						else
							{ return ((VOID*) AllocationFailure); }
						}
					}
				else
					{
					REGISTER SBIT32 Delta = (NewSize - Size);

					//
					//   We only need to reallocate if the new
					//   size is larger than the current bucket
					//   or the new size is smaller and we have 
					//   been given permission to move the 
					//   allocation.
					//
					if ( ResizeTest( Delta,Move ) )
						{
						//
						//   One of the sizes is not within the
						//   allocation range of the heap.  So
						//   I have to punt and reallocate.
						//   
						NewMemory = 
							(
							ExternalCache -> New
								( 
								False,
								(NewSpace = NewSize)
								)
							);
#ifdef ENABLE_HEAP_STATISTICS

						//
						//   Update the allocation statistics.
						//
						if ( NewSize > MaxNewSize )
							{ MaxNewSize = NewSize; }

						NewMisses ++;
						TotalNewSize += NewSize;
#endif
						}
					else
						{
						//
						//   If the new size is unchanged or smaller
						//   then just return the current allocation.
						//   If the new size is larger then we must
						//   fail the call.
						//
						if ( Delta <= 0 )
							{
							//
							//   The amount of memory allocated for  
							//   this request is unchanged so return  
							//   the current size.
							//
							if ( Space != NULL )
								{ (*Space) = Size; }

							return Address; 
							}
						else
							{ return ((VOID*) AllocationFailure); }
						}
					}
				
				//
				//   We need to make sure we were able to allocate
				//   the new memory otherwise the copy will fail.
				//
				if ( NewMemory != ((VOID*) AllocationFailure) )
					{
					//
					//   Copy the contents of the old allocation 
					//   to the new allocation.
					//
					memcpy
						( 
						((void*) NewMemory),
						((void*) Address),
						((int) Smallest) 
						);

					//
					//   If needed return the actual amount of  
					//   space allocated for this request.
					//
					if ( Space != NULL )
						{ (*Space) = NewSpace; }

					//
					//   Delete the old allocation unless we
					//   need to keep it around.
					//
					if ( ! NoDelete )
						{
						//
						//   Delete the old allocation.
						//
						if ( ! Delete( Address,Size ) )
							{ Failure( "Deleting allocation in Resize" ); }
						}

					//
					//   Zero the memory if the needed.
					//
					if ( Zero )
						{
						REGISTER SBIT32 Difference = (NewSpace - Smallest);

						//
						//   If the new size is larger than 
						//   old size then zero the end of the
						//   new allocation.
						//
						if ( Difference > 0 )
							{ 
							REGISTER CHAR *Array = ((CHAR*) NewMemory);

							ZeroMemory( & Array[ Smallest ],Difference ); 
							} 
						}	
#ifdef ENABLE_HEAP_STATISTICS

					//
					//   Update the allocation statistics.
					//
					if ( Smallest > MaxCopySize )
						{ MaxCopySize = Smallest; }

					CopyMisses ++;
					TotalCopySize += Smallest;
#endif
					}

				return NewMemory;
				}
			}
		}

	return ((VOID*) AllocationFailure);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Truncate the heap.                                             */
    /*                                                                  */
    /*   We need to truncate the heap.  This pretty much a do nothing   */
    /*   as we do this automatically anyway.  The only thing we can     */
    /*   do is free any space the user suggested keeping earlier.       */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Truncate( SBIT32 MaxFreeSpace )
	{
	REGISTER BOOLEAN Result = True;

	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		REGISTER SBIT32 Count;

		//
		//   Flush all the caches and to free up
		//   as much space as possible.
		//
		for ( Count=0;Count < CachesSize;Count ++ )
			{
			if ( ! Caches[ Count ] -> Truncate() )
				{ Result = False; }
			}

		//
		//   We slave all available free space in the top
		//   bucket so force it to be released.
		//
		TopCache -> ReleaseSpace
			(
			(MaxFreeSpace / (TopCache -> GetAllocationSize()))
			);
		}

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release all the heap locks.                                    */
    /*                                                                  */
    /*   We release the locks so others can use the heap.               */
    /*                                                                  */
    /********************************************************************/

VOID HEAP::UnlockAll( BOOLEAN Partial )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We release the locks only if we have claimed 
		//   them earlier.
		//
		if ( ThreadSafe -> ReleaseGlobalLock( True ) )
			{
			//
			//   Now release all the heap locks we claimed
			//   earlier and unfreeze the heap.
			//
			NewPage -> ReleaseNewPageLock();

			PrivateFind -> ReleaseFindExclusiveLock();

			//
			//   When we destroy the heap we hold on
			//   to the cache locks to prevent errors.
			//
			if ( ! Partial )
				{
				REGISTER SBIT32 Count;

				//
				//   Now release all the cache locks we claimed
				//   earlier and unfreeze the cache.
				//
				for ( Count=0;Count < CachesSize;Count ++ )
					{ Caches[ Count ] -> ReleaseCacheLock(); }
				}
			}
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Verify of a memory allocation.                                 */
    /*                                                                  */
    /*   We need to verify the details of a memory allocation.          */
    /*   All we have is an address.  We use this to find the largest    */
    /*   allocation page this address is contained in and then          */
    /*   navigate through the sub-divisions of this page until we       */
    /*   find the allocation.  Finally, we check that the element       */
    /*   is not in the cache waiting to be allocated or freed.          */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Verify( VOID *Address,SBIT32 *Size )
    {
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		AUTO SEARCH_PAGE FullDetails;
		AUTO SBIT32 NewSize;

		//
		//   We extract the size of the allocation and  
		//   any associated allocation information.
		//   to see if it is present.
		//
		if ( Details( Address,& FullDetails,& NewSize ) )
			{
			//
			//   We need to be careful to make sure this 
			//   element is actually allocated.
			//
			if ( (*FullDetails.VectorWord) & FullDetails.AllocationMask )
				{
				//
				//   It is possible for a user to give an
				//   address that is in the middle of an
				//   allocation instead of at the beginning.
				//
				if ( FullDetails.Found )
					{
					//
					//   We know that the element appears to be 
					//   allocated but it may be in the cache
					//   somewhere so ensure this is not the case.
					//
					if ( (NewSize > 0) && (NewSize <= MaxCacheSize) )
						{
						if ( FullDetails.Cache -> SearchCache( Address ) )
							{ return False; }
						}

					//
					//   We have shown that the element is active
					//   so return the size if requested.
					//
					if ( Size != NULL )
						{ (*Size) = NewSize; }

					return True;
					}
				}
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Walk the heap.                                                 */
    /*                                                                  */
    /*   We have been asked to walk the heap.  It is hard to know       */
    /*   whay anybody might want to do this given the rest of the       */
    /*   functionality available.  Nonetheless, we just do what is      */
    /*   required to keep everyone happy.                               */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Walk
		( 
		BOOLEAN						  *Active,
		VOID						  **Address,
		SBIT32						  *Size 
		)
    {
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We walk the heap and find the next allocation
		//   along with some basic information.
		//
		if ( PrivateFind -> Walk( Active,Address,TopCache,Size ) )
			{
			//
			//   We know that the element appears to be 
			//   allocated but it may be in the cache
			//   somewhere so ensure this is not the case.
			//
			if ( ((*Size) > 0) && ((*Size) <= MaxCacheSize) )
				{
				if ( FindCache( (*Size) ) -> SearchCache( (*Address) ) )
					{ (*Active) = False; }
				}

			return True;
			}
		}

	return False;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   We would like to destroy the heap at the end of the run        */
    /*   just to be tidy.  However, to do this we need to know that     */
    /*   all of the other destructors have been called and that the     */
    /*   application will not request more memory or use any existing   */
    /*   allocations.  We can't know this without help from the         */
    /*   compiler and OS.                                               */
    /*                                                                  */
    /********************************************************************/

HEAP::~HEAP( VOID )
	{
	REGISTER SBIT32 Count;

	//
	//   We mark the heap as inactive.
	//
	Active = False;

	//
	//   We claim all of the heap locks to freeze
	//   all new allocations or deletions.
	//
	LockAll();
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Deal with heap statistics.
	//
	if ( Statistics != NULL ) 
		{
		//
		//   Print all the statistics.
		//
		PrintHeapStatistics();

		//
		//   Deallocate the area.
		//
		RockallBackEnd -> DeleteArea
			( 
			((VOID*) Statistics),
			(MaxCacheSize * sizeof(SBIT32)),
			False
			); 
		}
#endif

	//
	//   Now reset all the caches.
	//
	for ( Count=0;Count < CachesSize;Count ++ )
		{ Caches[ Count ] -> DeleteAll(); }

	//
	//   Delete the heap.
	//
	NewPage -> DeleteAll( False );

	//
	//   We release any of the shared locks we 
	//   cliamed earlier.
	//
	UnlockAll( True );

	//
	//   Delete the heap mapping tables.
	//
	if ( SizeToCache1 != NULL ) 
		{ 	
		//
		//   Deallocate the area.
		//
		RockallBackEnd -> DeleteArea
			( 
			((VOID*) SizeToCache1),
			(MaxTable1 + MaxTable2),
			False
			); 
		}
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\heappch.hpp ===
#ifndef _HEAP_PCH_HPP_
#define _HEAP_PCH_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#ifndef DISABLE_PRECOMPILED_HEADERS
#include "Bucket.hpp"
#include "BucketList.hpp"
#include "Cache.hpp"
#include "Connections.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "NewPage.hpp"
#include "NewPageList.hpp"
#include "Page.hpp"
#include "PrivateFindList.hpp"
#include "PublicFindList.hpp"
#include "RockallFrontEnd.hpp"
#include "ThreadSafe.hpp"

#include "LibraryPCH.hpp"
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\find.hpp ===
#ifndef _FIND_HPP_
#define _FIND_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Common.hpp"
#include "Environment.hpp"
#include "List.hpp"
#include "Page.hpp"
#include "Prefetch.hpp"
#include "RockallBackEnd.hpp"
#include "Sharelock.hpp"
#include "Spinlock.hpp"
#include "ThreadSafe.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;
class HEAP;

    /********************************************************************/
    /*                                                                  */
    /*   Find a memory allocation.                                      */
    /*                                                                  */
    /*   When a memory allocation is released all we are given is .     */
    /*   the allocation address.  This is not very helpful as the       */
    /*   allocation information is not stored relative to this          */
    /*   address.  Instead we use a hash table to map the allocation    */
    /*   address to the allocation information.                         */
    /*                                                                  */
    /********************************************************************/

class FIND : public ENVIRONMENT, public COMMON
    {
		//
		//   Private type specifications.
		//
		//   We need to do a recursive search in the find 
		//   table in order to locate the associated page
		//   from an address.  As this is expensive there
		//   is also a cache that slaves common translations
		//   to improve performance.
		//
		typedef struct
			{
			VOID					  *Address;
			PAGE					  *Page;
#ifdef DEBUGGING
			SBIT32					  Version;
#endif
			}
		LOOK_ASIDE;

		//
		//   Private data.
		//
		//   All the page descriptions are stored in the 
		//   hash table so they can be quickly found.  The
		//   key is the address of the first byte on the
		//   page.  The 'MaxHash' is the number of elements
		//   in the hash table and is always a power of two.
		//   The 'HashMask' is a bit mask to remove any 
		//   unwanted part of the hash key.  The 'HashShift'
		//   is the number of bits required to shift and is
		//   as a substitute for divide.  The 'Resize' flag
		//   indicates whether the hash table is permitted 
		//   to grow.
		//
		SBIT32						  MaxHash;

		SBIT32						  HashMask;
		SBIT32						  HashShift;
		BOOLEAN						  Public;
		BOOLEAN						  Resize;

		//
		//   The hash table allows addresses to be mapped to
		//   page descriptions quickly.  Nonetheless, it is 
		//   not fast enough.  To enhance performance a look
		//   aside cache slaves the hottest translations.  The
		//   'MaxLookAside' is the number of elements in the
		//   cache.  The 'MaxAddressMask' is a mask that removes 
		//   low order bits of an address and represents the
		//   span of each cache entry.  The 'LookAsideActions'
		//   is a simple count of requests to the cache.  The
		//   'LookAsideMask' and 'LookAsideShift' parallel the
		//   fields above in the hash table.  The 'LookAsideThreshold'
		//   determines at what point the cache will become 
		//   active.  
		//
		SBIT32						  MaxLookAside;

		BIT32						  MaxAddressMask;
		BIT32						  MinAddressMask;

		SBIT32						  LookAsideActions;
		SBIT32						  LookAsideMask;
		SBIT32						  LookAsideShift;
		SBIT32						  LookAsideThreshold;

		//
		//   When a request is made to translate an address to
		//   a page description the cache is the first port of
		//   call.  If the translation is not found then the
		//   hash table is tried.  The 'Hash' points to the hash
		//   table.  The 'LookAside' points to the lookaside
		//   hash table.  The 'Services' points to the external API
		//   to give access to the low level external allocation
		//   functions.  The 'ThreadSafe' class indicates whether
		//   locking is required.  
		//
		LIST						  *Hash;
		LOOK_ASIDE					  *LookAside;
		ROCKALL_BACK_END			  *RockallBackEnd;
		THREAD_SAFE					  *ThreadSafe;

		//
		//   The translation of addresses to page descriptions
		//   is very common.  So care has been taken to ensure
		//   it is not a bottleneck when locking is enabled.  The
		//   'Sharelock' is a fast reader/writer lock and is used
		//   almost all the time.  The 'Spinlock' is an exclusive
		//   lock and is only used when the 'Hash' and 'LookAside'
		//   tables are resized.
		//
		PREFETCH					  Prefetch;
		SHARELOCK					  Sharelock;
		SPINLOCK					  Spinlock;
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Statistics data.
		//
		//   There is a concern with any hash table about
		//   poor hashing keys and poor performance.  The
		//   statistics monitor various data so as to allow
		//   the performance metrics to be monitored.  The
		//   'Fills' counter keeps track of the number of
		//   cache fills.  The 'Hits' counter monitors the
		//   number of cache hits.  The 'MaxPages' counter
		//   is the high water mark of hash table entries.
		//   The 'MaxTests' is the max number of compares 
		//   done while searching an entry.  The 'Misses' 
		//   counter keeps track of the number of cache misses.
		//   The 'Scans' counter monitors the number of hash
		//   table searches.  The 'Tests' counter is the 
		//   total number of tests performed while searching
		//   for entries.
		//
		SBIT32						  Fills;
		SBIT32						  Hits;
		SBIT32						  MaxPages;
		SBIT32						  MaxTests;
		SBIT32						  Misses;
		SBIT32						  Scans;
		SBIT32						  Tests;
#endif
		SBIT32						  Used;

   public:
		//
		//   Public functions.
		//
		//   The translation functionality supplied by this
		//   class is only applicable after an allocation
		//   has been made.  Hence, all of the APIs supported
		//   relate to the need to translate an allocation
		//   address to the host page description.
		//
        FIND
			( 
			SBIT32					  NewMaxHash,
			SBIT32					  NewMaxLookAside,
			SBIT32					  NewFindThreshold,
			BOOLEAN					  NewPublic,
			BOOLEAN					  NewResize,
			ROCKALL_BACK_END		  *NewRockallBackEnd,
			THREAD_SAFE				  *NewThreadSafe 
			);

		BOOLEAN Delete( VOID *Address,CACHE *ParentCache );

		VOID DeleteFromFindList( PAGE *Page );

		BOOLEAN Details
			( 
			VOID					  *Address,
			SEARCH_PAGE				  *Details,
			CACHE					  *ParentCache,
			SBIT32					  *Size 
			);

		PAGE *FindPage( VOID *Address,CACHE *ParentCache );

		VOID InsertInFindList( PAGE *Page );

		BOOLEAN KnownArea( VOID *Address,CACHE *ParentCache );

		VOID ReleaseFindShareLockAndUpdate
			( 
			VOID					  *Address,
			PAGE					  *Page,
			SBIT32					  Version 
			);

		BOOLEAN Walk
			( 
			BOOLEAN					  *Active,
			VOID					  **Address,
			CACHE					  *ParentCache,
			SBIT32					  *Size 
			);

		VOID UpdateFind
			( 
			BIT32					  NewMaxAddressMask,
			BIT32					  NewMinAddressMask
			);

        ~FIND( VOID );

		//
		//   Public inline functions.
		//
		//   Although this class is perhaps the most self
		//   contained.  Nonetheless, there is still lots
		//   of situations when other classes need to 
		//   interact and get information about the current
		//   situation.
		//
		INLINE VOID ClaimFindExclusiveLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ClaimExclusiveLock(); } 
			}

		INLINE VOID ClaimFindShareLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ClaimShareLock(); } 
			}

		INLINE VOID DeleteAll( VOID )
			{ LookAsideActions = 0; }

		INLINE VOID ReleaseFindExclusiveLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ReleaseExclusiveLock(); } 
			}

		INLINE VOID ReleaseFindShareLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ReleaseShareLock(); } 
			}
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Public inline statistic functions.
		//
		//   The statistics are typically provided in 
		//   debug builds to provide good information  
		//   about allocation patterns.  
		//
		INLINE SBIT32 AverageHashLength( VOID )
			{ return (Tests / ((Scans > 0) ? Scans : 1)); }

		INLINE SBIT32 CacheFills( VOID )
			{ return Fills; }

		INLINE SBIT32 CacheHits( VOID )
			{ return Hits; }

		INLINE SBIT32 CacheMisses( VOID )
			{ return Misses; }

		INLINE SBIT32 MaxHashLength( VOID )
			{ return MaxTests; }

		INLINE SBIT32 MaxHashSize( VOID )
			{ return MaxHash; }

		INLINE SBIT32 MaxLookAsideSize( VOID )
			{ return MaxLookAside; }

		INLINE SBIT32 MaxUsage( VOID )
			{ return ((MaxPages * 100) / MaxHash); }

		INLINE SBIT32 TotalScans( VOID )
			{ return Scans; }
#endif

	private:
		//
		//   Private functions.
		//
		//   Although the hashed lookup functionality is 
		//   externally visable the look aside cache is 
		//   hidden from view along with the ability to
		//   resize the hash table.
		//
		BOOLEAN FindLookAside( VOID *Address,PAGE **Page );

		VOID ResizeHashTable( VOID );

		//
		//   Private inline functions.
		//
		//   Although I am not keen on code in the headers
		//   certain functions are so small or so hot that
		//   I have to submit to the desire to do it. 
		//
		INLINE VOID ChangeToExclusiveLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ChangeSharedLockToExclusiveLock(); } 
			}

		INLINE LIST *FindHashHead( VOID *Address )
			{
			REGISTER BIT32 Value = (((BIT32) Address) * 2964557531);

			return (& Hash[ ((Value >> HashShift) & HashMask) ]); 
			}

		INLINE LOOK_ASIDE *FindLookAsideHead( VOID *Address )
			{
			REGISTER BIT32 Value = (((BIT32) Address) * 2964557531);

			return (& LookAside[ ((Value >> LookAsideShift) & LookAsideMask) ]); 
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        FIND( CONST FIND & Copy );

        VOID operator=( CONST FIND & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\newpage.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "New.hpp"
#include "NewPage.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants set overall limits on the number and size of     */
    /*   page descriptions for pages within the memory allocator.       */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MinNewPages			  = 1;
CONST SBIT32 VectorRange			  = ((2 << 15) - 1);

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   A 'PAGE' structure has various fixed fields and a variable     */
    /*   sized allocation bit vector.  When this class is initialized   */
    /*   the user is required to supply us with an array that details   */
    /*   the sizes of allocation bit vectors supported.                 */
    /*                                                                  */
    /********************************************************************/

NEW_PAGE::NEW_PAGE
		(
		SBIT32						  NewPageSizes[],
		ROCKALL_BACK_END			  *NewRockallBackEnd,
		SBIT32						  Size,
		THREAD_SAFE					  *NewThreadSafe 
		)
    {
	REGISTER SBIT32 DefaultRootSize = (NewRockallBackEnd -> NaturalSize());
	REGISTER SBIT32 ReservedBytes = (Size * sizeof(NEW_PAGES));
	REGISTER SBIT32 SpareBytes = (DefaultRootSize - ReservedBytes);
	REGISTER SBIT32 MaxStackSize = (SpareBytes / sizeof(VOID*));

	//
	//   We need to make sure that we appear to have a valid
	//   array of 'NewPageSizes' and that the bit vector sizes
	//   do not exceed the memory addressing range.
	//
	if 
			(
			PowerOfTwo( DefaultRootSize )
				&&
			(DefaultRootSize >= PageSize())
				&&
			(Size >= MinNewPages) 
				&&
			((NewPageSizes[ (Size-1) ] * OverheadBitsPerWord) <= VectorRange)
			)
		{
		REGISTER VOID *NewMemory = 
			(
			NewRockallBackEnd -> NewArea
				( 
				(DefaultRootSize-1),
				DefaultRootSize,
				False
				)
			);

		//
		//   We are in big trouble if we can not allocate space
		//   to store this initial control information.  If the
		//   allocation fails we are forced to exit and the whole  
		//   memory allocator becomes unavailable.
		//
		if ( NewMemory != AllocationFailure )
			{
			REGISTER SBIT32 Count;
			REGISTER SBIT32 LastSize = 0;

			//
			//   We are now ready to setup the configuration
			//   information.
			//
			MaxCacheStack = 0;
			MaxNewPages = Size;
			MaxStack = MaxStackSize;

			NaturalSize = DefaultRootSize;
			RootCoreSize = DefaultRootSize;
			RootStackSize = 0;
			ThreadSafe = NewThreadSafe;
			TopOfStack = 0;
			Version = 0;

			CacheStack = NULL;
			NewPages = ((NEW_PAGES*) NewMemory);
			Stack = ((VOID**) & NewPages[ Size ]);

			RockallBackEnd = NewRockallBackEnd;
			TopCache = NULL;

			//
			//   Create a lists for the various page 
			//   sizes and prepare them for use.
			//
			for ( Count=0;Count < Size;Count ++ )
				{
				REGISTER SBIT32 CurrentSize = NewPageSizes[ Count ];

				if ( CurrentSize > LastSize )
					{
					REGISTER NEW_PAGES *NewPage = & NewPages[ Count ];

					//
					//   Create a list for the current
					//   size and fill in all the related
					//   details.
					//
					NewPage -> Elements = (CurrentSize * OverheadBitsPerWord);
					PLACEMENT_NEW( & NewPage -> ExternalList,LIST );
					PLACEMENT_NEW( & NewPage -> FullList,LIST );
					PLACEMENT_NEW( & NewPage -> FreeList,LIST );
					NewPage -> Size = (CurrentSize * sizeof(BIT32));

					LastSize = CurrentSize;
					}
				else
					{ Failure( "Sizes in constructor for NEW_PAGES" ); }
				}
			}
		else
			{ Failure( "No memory in constructor for NEW_PAGES" ); }
		}
	else
		{ Failure( "Setup of pages in constructor for NEW_PAGES" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Create a new page.                                             */
    /*                                                                  */
    /*   Create a new 'PAGE' structure and prepare it for use.  If      */
    /*   we don't already have any pages of the required size then      */
    /*   allocate memory, create new 'PAGE' structures and link them    */
    /*   into the appropriate free chain.                               */
    /*                                                                  */
    /********************************************************************/

PAGE *NEW_PAGE::CreatePage( CACHE *Cache,SBIT32 NewSize )
    {
	REGISTER PAGE *NewPage = ((PAGE*) AllocationFailure);
	REGISTER SBIT16 SizeKey = (Cache -> GetSizeKey());

	//
	//   All allocations are made from fixed sized
	//   pages.  These pages have a bit vector to
	//   keep track of which elements are allocated
	//   and available.  The 'SizeKey' is an index
	//   into 'NewPages[]' that will supply a page
	//   that has a big enough the bit vector.
	//
#ifdef DEBUGGING
	if ( (SizeKey >= 0) && (SizeKey < MaxNewPages) )
		{
#endif
		REGISTER NEW_PAGES *Current;

		//
		//   When there is a potential for multiple threads 
		//   we claim the lock.
		//
		ClaimNewPageLock();

		//
		//   We allocate 'PAGE' structures as we need them
		//   and link them together in the free list.
		//   If we don't have any structures available we 
		//   allocate some more and add tem to the list.
		//
		if ( (Current = & NewPages[ SizeKey ]) -> FreeList.EndOfList() )
			{
			REGISTER SBIT32 ArrayElements = (Current -> Size - MinVectorSize);
			REGISTER SBIT32 ArraySize = (ArrayElements * sizeof(BIT32));
			REGISTER SBIT32 TotalSize = (sizeof(PAGE) + ArraySize);
			REGISTER SBIT32 FinalSize = CacheAlignSize( TotalSize );
			REGISTER SBIT32 TotalPages = (NaturalSize / FinalSize);

			//
			//   Nasty, we have run out of stack space.  If
			//   we can not grow this table then the heap
			//   will not be able to expand any further.
			//
			if ( TopOfStack >= MaxStack )
				{
				//
				//   Try to grow the stack size.
				//
				ResizeStack();

				//
				//   Update the pointer as the table may
				//   have moved.
				//
				Current = & NewPages[ SizeKey ];
				}

			//
			//   We may find ourseleves in a situation where
			//   the size of the new 'PAGE' structure is larger
			//   than the natural allocation size or the stack
			//   is full so we can't create new pages.  If so we
			//   refuse to create any new pages so any allocation
			//   requests for this size will fail.
			//
			if ( (TotalPages > 0) && (TopOfStack < MaxStack) )
				{
				REGISTER VOID *NewMemory = 
					(VerifyNewArea( (NaturalSize-1),NaturalSize,False ));

				//
				//   We may also find ourselves unable to 
				//   anymore memory.  If so we will fail the
				//   request to create a page.
				//
				if ( NewMemory != ((VOID*) AllocationFailure) )
					{
					REGISTER CHAR *Address;
					REGISTER SBIT32 Count;

					//
					//   Add the new allocation to stack of
					//   outstanding external allocations.
					//
					Stack[ (TopOfStack ++) ] = NewMemory;

					//
					//   Add the new elements to the free list
					//   for the current allocation size.
					//
					for 
							( 
							Count=0, Address = ((CHAR*) NewMemory);
							Count < TotalPages;
							Count ++, (Address += FinalSize)
							)
						{
						REGISTER PAGE *Page = ((PAGE*) Address);

						//
						//   The page has been allocated but not 
						//   initialized so call the constructor
						//   and the destructor to get it into
						//   a sane state.
						//
						PLACEMENT_NEW( Page,PAGE ) 
							(
							NULL,
							Cache,
							0,
							NULL,
							0
							);

						PLACEMENT_DELETE( Page,PAGE );

						//
						//   Finally add the page to the free list
						//   so it can be used.
						//
						Page -> InsertInNewPageList( & Current -> FreeList ); 
						}
					}
				}
			}

		//
		//   We are now ready to create a new allocation
		//   page.  We start by requesting a page from
		//   the parent bucket.  If this works we know that 
		//   we have almost everthing we need to create the 
		//   new page.
		//
		if ( ! Current -> FreeList.EndOfList() )
			{
			REGISTER VOID *NewMemory;
			REGISTER CACHE *ParentPage = (Cache -> GetParentCache());

			NewPage = (PAGE::FirstInNewPageList( & Current -> FreeList ));

			//
			//   We have found a suitable page structure
			//   so remove it from the free list.
			//
			NewPage -> DeleteFromNewPageList( & Current -> FreeList );

			//
			//   Release any lock we might have as another
			//   thread may be waiting to delete a page and
			//   be holding the lock we need in order to
			//   create a page.
			//
			ReleaseNewPageLock();

			//
			//   We need to allocate memory to store the users 
			//   data.  After all we are the memory allocator
			//   and that is our job in life.  Typically, we do
			//   this by making a recursive internal request
			//   from a larger bucket.  Nonetheless, at some point
			//   we will reach the 'TopCache' and will be forced
			//   to request memory from an external source.
			//
			if ( (Cache -> TopCache()) || (NewSize != NoSize) )
				{
				REGISTER AlignMask = (TopCache -> GetPageSize()-1);

				//
				//   We allocate memory externally in large blocks 
				//   and sub-divide these allocations into smaller
				//   blocks.  The only exception is if the caller 
				//   caller is requesting some weird size in which
				//   case we request memory directly from the
				//   external allocator (usually the OS).
				//
				if ( NewSize == NoSize )
					{ NewSize = (Cache -> GetPageSize()); }

				//
				//   All externally allocated memory belongs
				//   to the global root.  Thus, it will be 
				//   found in the first lookup in the find
				//   table.
				//
				ParentPage = ((CACHE*) GlobalRoot);

				//
				//   Allocate from the external allocator.
				//
				NewMemory = (VerifyNewArea( AlignMask,NewSize,True ));
				}
			else
				{
				//
				//   Allocate memory from a larger cache and then
				//   sub-divide it as needed.
				//
				NewMemory = 
					(Cache -> GetParentCache() -> CreateDataPage()); 
				}

			//
			//   Reclaim any lock we have had earlier so 
			//   we can update the the new page structure.
			//
			ClaimNewPageLock();

			//
			//   Lets make sure we sucessfully allocated the
			//   memory for the data page.
			//
			if ( NewMemory != AllocationFailure )
				{
				//
				//   We now have everything we need so lets
				//   create a new page.
				//
				PLACEMENT_NEW( NewPage,PAGE ) 
					(
					NewMemory,
					Cache,
					NewSize,
					ParentPage,
					(Version += 2)
					);

				//
				//   Finally lets add the new page to the various
				//   lists so we can quickly find it again later.
				//
				Cache -> InsertInBucketList( NewPage );

				Cache -> InsertInFindList( NewPage );

				NewPage -> InsertInNewPageList
					(
					(Cache -> TopCache())
						? & Current -> ExternalList 
						: & Current -> FullList 
					); 
				}
			else
				{
				//
				//   We were unable to allocate any data space
				//   for this new page so lets free the page 
				//   description and exit.
				//
				NewPage -> InsertInNewPageList( & Current -> FreeList );

				NewPage = ((PAGE*) AllocationFailure);
				}
			}

		//
		//   We have finished so release the lock now. 
		//
		ReleaseNewPageLock();
#ifdef DEBUGGING
		}
	else
		{ Failure( "The page size key is out of range" ); }
#endif

	return NewPage;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete all allocations.                                        */
    /*                                                                  */
    /*   Delete an entire heap and return all the memory to the         */
    /*   top level pool or the external allocator (usually the OS).     */
    /*                                                                  */
    /********************************************************************/

VOID NEW_PAGE::DeleteAll( BOOLEAN Recycle )
    {
	REGISTER SBIT32 Count;

	//
	//   Claim the global lock so that the various  
	//   lists can be updated.
	//
	ClaimNewPageLock();

	//
	//   We assume at this point that we have blocked
	//   all memory allocation and dealloction requests.
	//   We are now going to walk through the various lists
	//   and just blow away things.  We are going to
	//   do this in a tidy way just in case the caller
	//   wants to use the heap again later.
	//
	for ( Count=0;Count < MaxNewPages;Count ++ )
		{
		REGISTER NEW_PAGES *Current = & NewPages[ Count ];
		REGISTER PAGE *Page;
		REGISTER PAGE *NextPage;

		//
		//   All allocations that appear in the full list
		//   have been sub-allocated from larger pages in
		//   almost all cases.
		//
		for
				(
				Page = (PAGE::FirstInNewPageList( & Current -> FullList ));
				! Page -> EndOfNewPageList();
				Page = NextPage
				)
			{
			REGISTER VOID *Address = (Page -> GetAddress());
			REGISTER CACHE *Cache = (Page -> GetCache());
			REGISTER SBIT32 PageSize = (Page -> GetPageSize());

			//
			//   We decide here how we will deal with the page.
			//   If it is empty, non-standard or we are not
			//   recycling we will blow it away.  If not we
			//   simply reset it for later use.
			//
			if ( (Page -> Empty()) || (PageSize != NoSize) || (! Recycle) )
				{
				//
				//   We need to release any associated data page.
				//   If this is the top level then release the
				//   memory back to the external allocator.  If 
				//   not we release it back to the parent bucket.
				//
				if ( PageSize == NoSize )
					{
					//
					//   If we are just recycling then we cleanly
					//   delete the page.  If not then we know it
					//   will be blown away later so why bother.
					//
					if ( Recycle )
						{
						REGISTER CACHE *ParentCache = 
							(Cache -> GetParentCache());

						if ( ! (ParentCache -> DeleteDataPage( Address )) )
							{ Failure( "Reset data page in DeleteAll" ); }
						}
					}
				else
					{ RockallBackEnd -> DeleteArea( Address,PageSize,True ); }

				//
				//   We may have been blowing away pages  
				//   randomly and now we are about to destroy 
				//   the current page.  So lets figure out 
				//   what page comes next before we continue.
				//
				NextPage = (Page -> NextInNewPageList());

				//
				//   If the page is not full it will in a 
				//   bucket list somewhere.  We need to remove
				//   it as we are about to delete the page.
				//
				if ( ! Page -> Full() )
					{ Cache -> DeleteFromBucketList( Page ); }

				//
				//   Delete the page from the find list and the
				//   new page list.
				//
				Cache -> DeleteFromFindList( Page );

				Page -> DeleteFromNewPageList( & Current -> FullList );

				//
				//   Delete the page structure.
				//
				PLACEMENT_DELETE( Page,PAGE );

				//
				//   Finally add the page to the free list
				//   so it can be recycled.
				//
				Page -> InsertInNewPageList( & Current -> FreeList );
				}
			else
				{
				//
				//   We know that the current page has at 
				//   least one allocation on it so instead
				//   of deleting it we will mark it as free
				//   (except for any sub-allocations) and
				//   leave it around for next time.  If it
				//   is never used the next top level 
				//   'DeleteAll' will delete it.
				//
				Page -> DeleteAll();

				//
				//   We have now reset the current page so  
				//   lets figure out what page comes next.
				//
				NextPage = (Page -> NextInNewPageList());
				}
			}

		//
		//   We have a choice to make.  If we intend to
		//   use this heap again we keep all top level
		//   allocated memory in a list ready for reuse.
		//   If not we return it to the external allocator
		//   (usually the OS).
		//   
		if ( ! Recycle )
			{
			//
			//   The external allocations list contains an
			//   entry for every externally allocated page
			//   except those allocated for special internal 
			//   use within this class or for weird sized
			//   pages that appeared above in the 'FullList'.
			//
			for
					(
					Page = (PAGE::FirstInNewPageList( & Current -> ExternalList ));
					! Page -> EndOfNewPageList();
					Page = (PAGE::FirstInNewPageList( & Current -> ExternalList ))
					)
				{
				REGISTER VOID *Address = (Page -> GetAddress());
				REGISTER CACHE *Cache = (Page -> GetCache());
				REGISTER SBIT32 PageSize = (Page -> GetPageSize());

				//
				//   We no longer need this top level allocation
				//   so return it to the external allocator.
				//
				RockallBackEnd -> DeleteArea( Address,PageSize,True );

				//
				//   If the page is not full it will in a 
				//   bucket list somewhere.  We need to remove
				//   it as we are about to delete the page.
				//
				if ( ! Page -> Full() )
					{ Cache -> DeleteFromBucketList( Page ); }

				//
				//   Delete the page from the find list and the
				//   new page list.
				//
				Cache -> DeleteFromFindList( Page );

				Page -> DeleteFromNewPageList( & Current -> ExternalList );

				//
				//   Delete the page structure.
				//
				PLACEMENT_DELETE( Page,PAGE );

				//
				//   Finally add the page to the free list
				//   so it can be recycled.
				//
				Page -> InsertInNewPageList( & Current -> FreeList );
				}
			}
		}

	//
	//   We have finished so release the lock now. 
	//
	ReleaseNewPageLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Delete a page.                                                 */
    /*                                                                  */
    /*   Delete a page structure, free the associated memory and        */
    /*   unlink it from the various allocation lists.                   */
    /*                                                                  */
    /********************************************************************/

VOID NEW_PAGE::DeletePage( PAGE *Page )
    {
	REGISTER CACHE *Cache = (Page -> GetCache());
	REGISTER SBIT16 SizeKey = (Cache -> GetSizeKey());

	//
	//   All allocations are made from fixed sized
	//   pages.  These pages have a bit vector to
	//   keep track of which elements are allocated
	//   and available.  The 'SizeKey' is an index
	//   into 'NewPages[]' that will supply a page
	//   that has a big enough the bit vector.
	//
#ifdef DEBUGGING
	if ( (SizeKey >= 0) && (SizeKey < MaxNewPages) )
		{
#endif
		REGISTER VOID *Address = (Page -> GetAddress());
		REGISTER NEW_PAGES *Current = & NewPages[ SizeKey ];
		REGISTER SBIT32 Size = (Page -> GetPageSize());

		//
		//   We need to release any associated data page.
		//   If this is the top level then release the
		//   memory back to the external allocator.  If 
		//   not we release it back to the parent bucket.
		//
		if ( Size == NoSize )
			{ 
			REGISTER CACHE *ParentCache = (Cache -> GetParentCache());

			if ( ! (ParentCache -> DeleteDataPage( Address )) )
				{ Failure( "Deleting data page in DeletePage" ); }
			}
		else
			{ RockallBackEnd -> DeleteArea( Address,Size,True ); }

		//
		//   Claim the global lock so that the various  
		//   lists can be updated.
		//
		ClaimNewPageLock();

		//
		//   Remove the page from the lists and delete it.
		//
		Cache -> DeleteFromBucketList( Page );

		Cache -> DeleteFromFindList( Page );

		Page -> DeleteFromNewPageList
			(
			(Cache -> TopCache())
				? & Current -> ExternalList 
				: & Current -> FullList 
			); 

		PLACEMENT_DELETE( Page,PAGE );

		//
		//   Finally add the page to the free list
		//   so it can be recycled.
		//
		Page -> InsertInNewPageList( & Current -> FreeList );

		//
		//   We have finsihed so release the lock.
		//
		ReleaseNewPageLock();
#ifdef DEBUGGING
		}
	else
		{ Failure( "The page size key out of range in DeletePage" ); }
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find the correct index in new page.                            */
    /*                                                                  */
    /*   When we come to create a new page we need to make sure the     */
    /*   bit vector is large enough for the page.  We calculate this    */
	/*   here just once to save time later.                             */
    /*                                                                  */
    /********************************************************************/

SBIT16 NEW_PAGE::FindSizeKey( SBIT16 NumberOfElements )
    {
	REGISTER SBIT32 Count;

	//
	//   Search the table of page structures looking for 
	//   elements of a suitable size.  As the table is
	//   known to be in order of increasing size we can
	//   terminate the search as soon as we find something 
	//   large enough.
	//
	for ( Count=0;Count < MaxNewPages;Count ++ )
		{
		REGISTER NEW_PAGES *Current = & NewPages[ Count ];

		if ( NumberOfElements <= Current -> Elements )
			{ return ((SBIT16) Count); }
		}

	//
	//   Nasty, we don't seem to have anything large enough
	//   to store the bit vector.
	//
	return NoSizeKey;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Create a new cache stack.                                      */
    /*                                                                  */
    /*   A cache stack is an array that contains memory allocations     */
    /*   that are waiting to be allocated or released.                  */
    /*                                                                  */
    /********************************************************************/

VOID *NEW_PAGE::NewCacheStack( SBIT32 Size )
    {
	REGISTER VOID *NewStack;

	//
	//   Claim the global lock so that the various  
	//   lists can be updated.
	//
	ClaimNewPageLock();

	//
	//   We ensure that there is enough space to make the
	//   allocation.  If not we request additional space
	//   and prepare it for use.
	//
	if ( (CacheStack == NULL) || ((MaxCacheStack + Size) > NaturalSize) )
		{
		//
		//   Nasty, we have run out of stack space.  If
		//   we can not grow this table then the heap
		//   will not be able to expand any further.
		//
		if ( TopOfStack >= MaxStack )
			{
			//
			//   Try to grow the stack size.
			//
			ResizeStack();
			}

		//
		//   We may find ourseleves in a situation where
		//   the size of the new stack structure is larger
		//   than the natural allocation size or the stack
		//   is full so we can't create new pages.  If so we
		//   refuse to create any new stacks.
		//
		if ( (Size < NaturalSize) && (TopOfStack < MaxStack) )
			{
			REGISTER VOID *NewMemory = 
				((CHAR*) VerifyNewArea( (NaturalSize-1),NaturalSize,False ));

			//
			//   We may also find ourselves unable to get 
			//   anymore memory.  If so we will fail the
			//   request to create a new cache stack.
			//
			if ( NewMemory != ((VOID*) AllocationFailure) )
				{
				//
				//   Add the new allocation to stack of
				//   outstanding external allocations.
				//
				Stack[ (TopOfStack ++) ] = NewMemory;

				//
				//   Prepare the new memory block for use.
				//   
				CacheStack = ((CHAR*) NewMemory);
				MaxCacheStack = 0;
				}
			else
				{ return NULL; }
			}
		else
			{ return NULL; }
		}

	//
	//   We allocate some space for the new cache 
	//   stack and update and align the high water
	//   mark of the space used.
	//
	NewStack = ((VOID*) & CacheStack[ MaxCacheStack ]);

	MaxCacheStack += (Size + CacheLineMask);
	MaxCacheStack &= ~CacheLineMask;

	//
	//   We have finished so release the lock now. 
	//
	ReleaseNewPageLock();

	return NewStack;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Resize the new page stack.                                     */
    /*                                                                  */
    /*   The new page stack holds pointers to all the pages owned       */
    /*   by the heap.  If this stack become full we must expand it      */
	/*   otherwise we can no longer grow the heap.                      */
    /*                                                                  */
    /********************************************************************/

VOID NEW_PAGE::ResizeStack( VOID )
    {
	REGISTER SBIT32 NewSize = 
		(((RootStackSize <= 0) ? NaturalSize : RootStackSize) * 2);

	//
	//   Lets just check that we have really run out
	//   of stack space as expanding it really hurts.
	//
	if ( TopOfStack >= MaxStack )
		{
		REGISTER VOID *NewMemory = 
			(
			RockallBackEnd -> NewArea
				( 
				(NaturalSize-1),
				NewSize,
				False
				)
			);

		//
		//   We need to verify that we were able to allocate
		//   fresh memory for the stack.
		//
		if ( NewMemory != NULL )
			{
			REGISTER BOOLEAN DeleteStack = (RootStackSize > 0);
			REGISTER VOID *OriginalMemory = ((VOID*) Stack);
			REGISTER SBIT32 OriginalSize = (MaxStack * sizeof(VOID*));

			//
			//   All is well as we were able to allocate 
			//   additional space for the stack.  All we 
			//   need to do now is to update the control 
			//   information.
			//
			MaxStack = (NewSize / sizeof(VOID*));

			RootStackSize = NewSize;

			Stack = ((VOID**) NewMemory);

			//
			//   Now lets copy across the existing data. 
			//
			memcpy( NewMemory,OriginalMemory,OriginalSize );

			//
			//   When the heap is created we put the
			//   stack on the root core page.  Later
			//   we may move it if we expand it.  If
			//   this is the case we have to delete  
			//   the previous expansion here.
			//
			if ( DeleteStack )
				{
				//
				//   Deallocate the existing stack if it
				//   is not on the root core page.
				//
				RockallBackEnd -> DeleteArea
					( 
					OriginalMemory,
					OriginalSize,
					False )
					;
				}
			}
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Verify an external allocation.                                 */
    /*                                                                  */
    /*   All memory requests are allocated from the external allocator  */
	/*   at the highest level.  Here we have a wrapper for this         */
    /*   function so we can test the result and make sure it is sane.   */
    /*                                                                  */
    /********************************************************************/

VOID *NEW_PAGE::VerifyNewArea( SBIT32 AlignMask,SBIT32 Size,BOOLEAN User )
	{
#ifdef DEBUGGING
	//
	//   We need to ensure that the alignment of the new
	//   external allocation is a power of two.
	//
	if ( PowerOfTwo( (AlignMask + 1) ) )
		{
#endif
		REGISTER VOID *NewMemory = 
			(RockallBackEnd -> NewArea( AlignMask,Size,User ));

		//
		//   We need to ensure that the external allocation
		//   request is sucessful.  If not it makes no sense
		//   to try and check it.
		//
		if ( NewMemory != ((VOID*) AllocationFailure) )
			{
			//
			//   We require the external memory allocator to always
			//   allocate memory on the requested boundary.  If not 
			//   we are forced to reject the supplied memory.
			//
			if ( (((SBIT32) NewMemory) & AlignMask) == 0 )
				{ return NewMemory; }
			else
				{ 
				RockallBackEnd -> DeleteArea( NewMemory,Size,User );
				
				Failure( "Alignment of allocation in VerifyNewArea" );
				}
			}
#ifdef DEBUGGING
		}
	else
		{ Failure( "Alignment is not a power of two in VerifyNewArea" ); }
#endif

	return ((VOID*) AllocationFailure);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Walk the heap.                                                 */
    /*                                                                  */
    /*   We have been asked to walk the heap.  It is hard to know       */
    /*   why anybody might want to do this given the rest of the        */
    /*   functionality available.  Nonetheless, we just do what is      */
    /*   required to keep everyone happy.                               */
    /*                                                                  */
    /********************************************************************/

BOOLEAN NEW_PAGE::Walk( SEARCH_PAGE *Details,FIND *Find )
    {
	//
	//   Claim the global lock so that the various  
	//   lists can be updated.
	//
	ClaimNewPageLock();

	//
	//   We examine the current address to see if it
	//   is null.  If so then this is the start of a
	//   heap walk so we need to set it up.
	//
	if ( Details -> Address == NULL )
		{
		REGISTER SBIT32 Count;

		//
		//   Walk through the list of different sized
		//   page descriptions.
		//
		for ( Count=0;Count < MaxNewPages;Count ++ )
			{
			REGISTER NEW_PAGES *Current = & NewPages[ Count ];

			//
			//   Compute a pointer to the first element
			//   of the current size.
			//
			Details -> Page = 
				(PAGE::FirstInNewPageList( & Current -> FullList ));

			//
			//   Examine the current list of full (or 
			//   partially full) pages.  If there is at  
			//   least one page then this is the starting 
			//   point for the heap walk.
			//
			if ( ! Details -> Page -> EndOfNewPageList() )
				{
				//
				//   Compute the starting address of the 
				//   heap walk.
				//
				Details -> Address = 
					(Details -> Page -> GetAddress());

				break;
				}
			}
		}
	else
		{
		REGISTER PAGE *LastPage = Details -> Page;

		//
		//   We have exhusted the current page so walk
		//   the list and find the next page.
		//
		Details -> Page = 
			(Details -> Page -> NextInNewPageList());

		//
		//   We need to ensure that we have not reached
		//   the end of the current list.
		//
		if ( Details -> Page -> EndOfNewPageList() )
			{
			REGISTER SBIT32 Count;
			REGISTER BOOLEAN Found = False;

			//
			//   We need to find a new page description
			//   list to walk so reset the current 
			//   address just in case we don't find 
			//   anything.
			//
			Details -> Address = NULL;

			//
			//   We have reached the end of the current
			//   list and we need to continue with the
			//   start of the next list.  However, we
			//   don't know which list we were using
			//   previously.  So first we identify the
			//   previous list and then select the next
			//   avaibale list.
			//
			for ( Count=0;Count < MaxNewPages;Count ++ )
				{
				REGISTER NEW_PAGES *Current = & NewPages[ Count ];

				//
				//   We search for the original list
				//   we were walking.
				//
				if ( ! Found )
					{
					//
					//   When we find the original list
					//   then we set a flag showing that
					//   the next available list is the
					//   target.
					//
					if 
							( 
							LastPage 
								== 
							(PAGE::LastInNewPageList( & Current -> FullList )) 
							)
						{ Found = True; }
					}
				else
					{
					//
					//   We have found the previous list
					//   so the first element of the next
					//   list seems a good place to continue.
					//
					Details -> Page = 
						(PAGE::FirstInNewPageList( & Current -> FullList ));

					//
					//   We check to make sure that the list
					//   has at least one active page.  If not
					//   it is worthless and we continue looking
					//   for a suitable list.
					//
					if ( ! Details -> Page -> EndOfNewPageList() )
						{
						//
						//   Compute the starting address for 
						//   the next page in the heap walk.
						//
						Details -> Address = 
							(Details -> Page -> GetAddress());

						break;
						}
					}
				}
			}
		else
			{ 
			//
			//   Compute the starting address for 
			//   the next page in the heap walk.
			//
			Details -> Address = 
				(Details -> Page -> GetAddress());
			}
		}

	//
	//   If we find a new heap page to walk we update
	//   the details.  We mark some entry's as exhusted
    //   so as to provoke other code to set them up.
	//
	if ( Details -> Address != NULL )
		{
		//
		//   Compute the new allocation details.
		//
		Details -> Page -> FindPage
			( 
			Details -> Address,
			Details,
			Find,
			False 
			);
		}

	//
	//   We have finished so release the lock now. 
	//
	ReleaseNewPageLock();

	return (Details -> Address != NULL);
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory all the page structures and release any allocated      */
    /*   memory.                                                        */
    /*                                                                  */
    /********************************************************************/

NEW_PAGE::~NEW_PAGE( VOID )
    {
	REGISTER SBIT32 Count;

	//
	//   Delete all active allocations.
	//
	DeleteAll( False );

	//
	//   We are about to delete all of the memory 
	//   allocated by this class so destroy any
	//   internal pointers.
	//
	MaxCacheStack = 0;
	CacheStack = NULL;

	//
	//   We have now deleted all the memory allocated by
	//   this heap except for the memory  allocated directly 
	//   by this class.  Here we finish off the job by 
	//   deleting these allocations and reseting the internal 
	//   data structures.
	//
	for ( Count=0;Count < TopOfStack;Count ++ )
		{
		REGISTER VOID *Current = Stack[ Count ];

		RockallBackEnd -> DeleteArea( Current,NaturalSize,False );
		}

	TopOfStack = 0;

	//
	//   If we were forced to expand the root stack then
	//   release this additional memory now.
	//
	if ( RootStackSize > 0 )
		{
		//
		//   Deallocate root stack which previously 
		//   contained pointers to all the memory
		//   allocated by this class.
		//
		RockallBackEnd -> DeleteArea
			( 
			((VOID*) Stack),
			RootStackSize,
			False 
			);
		}

	//
	//   Delete all the new page list headings just
	//   to be neat
	//
	for ( Count=0;Count < MaxNewPages;Count ++ )
		{
		REGISTER NEW_PAGES *Current = & NewPages[ Count ];

		PLACEMENT_DELETE( & Current -> ExternalList,LIST );
		PLACEMENT_DELETE( & Current -> FullList,LIST );
		PLACEMENT_DELETE( & Current -> FreeList,LIST );
		}

	//
	//   Deallocate root core page which previously 
	//   contained all the new page lists.
	//
	RockallBackEnd -> DeleteArea
		( 
		((VOID*) NewPages),
		RootCoreSize,
		False 
		);
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\page.hpp ===
#ifndef _PAGE_HPP_
#define _PAGE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "PublicFindList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The constants supplied here control the number of bits in      */
    /*   a page descriptions bit vector and its minimum size.           */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MaxBitsPerWord			  = (sizeof(BIT32) * 8);
CONST SBIT32 MinVectorSize			  = 1;
CONST SBIT32 OverheadBits			  = 2;
CONST SBIT32 OverheadBitsPerWord	  = (MaxBitsPerWord / OverheadBits);

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;
class FIND;

    /********************************************************************/
    /*                                                                  */
    /*   Data structures exported from the class.                       */
    /*                                                                  */
    /*   The page descriptions supported by this class are at the       */
    /*   heart of the memory allocator.  These pages are linked in      */
    /*   various ways so they can be quickly found.  The following      */
    /*   structure contains the results of a search for a specific      */
    /*   memory address and its related page information.               */
    /*                                                                  */
    /********************************************************************/

typedef struct
	{
	VOID							  *Address;
	CACHE							  *Cache;
	BOOLEAN							  Found;
	PAGE							  *Page;

	BIT32							  AllocationMask;
	BIT32							  SubDivisionMask;
	BIT32							  *VectorWord;

	SBIT32							  ArrayOffset;
	SBIT32							  VectorOffset;
	SBIT32							  WordShift;
	}
SEARCH_PAGE;

    /********************************************************************/
    /*                                                                  */
    /*   The page allocation mechanism.                                 */
    /*                                                                  */
    /*   The memory manager allocates storage in large chunks from      */
    /*   the external memory allocator.  It then sub-divides these      */
    /*   chunks into various sized pages and keeps track of these       */
    /*   allocations using a bit vector in each page description.       */
    /*                                                                  */
    /********************************************************************/

class PAGE : public PUBLIC_FIND_LIST
    {
		//
		//   Private data.
		//
		//   The page description contains various details
		//   about the page.  The 'Address' is the starting 
		//   address of the allocation page.  The 'PageSize'
		//   is typically empty but contains a value is the 
		//   page size is weird and not realted to the
		//   assocated bucket.  The 'Version' is a unique
		//   version number and is changed everytime a new
		//   page description is created or deleted.  This
		//   version number allows a thread to see if anyone
		//   has been significantly playing with a page  
		//   description since it last held the associated lock.
		//
		CHAR                          *Address;
		SBIT32						  PageSize;
		SBIT32						  Version;

		//
		//   We keep track of the number of elements that
		//   are currently 'Allocated' and 'Available' on
		//   the page.  Additionally, 'FirstFree' is the
		//   index of the first word in the bit vector that
		//   has at least one available slot.
		//
		SBIT16                        Allocated;
		SBIT16                        Available;
		SBIT16						  FirstFree;

		//
		//   We sometimes need to interact with other classes.
		//   The 'Cache' class typically owns a number of pages
		//   and keeps all the information about this size of
		//   allocation.  The 'ParentPage' is a pointer to 
		//   another cache from where this page was sub-allocated
		//   and where the space will need to be returned when
		//   it becomes free.
		//
		CACHE						  *Cache;
		CACHE						  *ParentPage;

		//
		//   The 'Vector' is the variable sized bit vector that
		//   contains allocation information.  Each allocation
		//   is recorded using 2 bits.  The first bit indicates
		//   whether the allocation is in use and the second bit
		//   indicates whether an active allocation has been 
		//   sub-divided into smaller chunks.  Any unused bits
		//   at the end of the final word are set to zero, assumed
		//   to be zero and should never be non-zero.
		//
		BIT32                         Vector[MinVectorSize];

   public:
		//
		//   Public functions.
		//
		//   The page description contains all the information
		//   relating to an allocation.  There is no information
		//   stored with the allocation itself.  A significant
		//   portion of the external API can find its way to
		//   this class if the many layers of caches fail to
		//   deal with the request first.
		//
        PAGE
			( 
			VOID					  *NewAddress,
			CACHE					  *NewCache,
			SBIT32					  NewPageSize,
			CACHE					  *NewParentPage,
			SBIT32					  NewVersion 
			);

		SBIT32 ActualSize( VOID );

		BOOLEAN Delete( SEARCH_PAGE *Details );

		VOID DeleteAll( VOID );

		PAGE *FindPage
			( 
			VOID					  *Address,
			SEARCH_PAGE				  *Details,
			FIND					  *Find,
			BOOLEAN					  Recursive 
			);

		BOOLEAN MultipleNew
			( 
			SBIT32					  *Available, 
			VOID					  *Array[],
			SBIT32					  Requested
			);

		VOID *New( BOOLEAN SubDivided );

		BOOLEAN Walk( SEARCH_PAGE *Details,FIND *Find );

        ~PAGE( VOID );

		//
		//   Public inline functions.
		//
		//   The page class is so central to the entire memory
		//   allocator that a number of other classes need to
		//   get at certain data from time to time.  Thus, it 
		//   is necessary for both brevity and performance to
		//   provide inline function for certain critical 
		//   information relating to a page.
		//
		INLINE BOOLEAN Empty( VOID )
			{ return (Allocated <= 0); }

		INLINE BOOLEAN Full( VOID )
			{ return (Available <= 0); }

		INLINE VOID *GetAddress( VOID )
			{ return ((VOID*) Address); }

		INLINE CACHE *GetCache( VOID )
			{ return Cache; }

		INLINE SBIT32 GetPageSize( VOID )
			{ return PageSize; }

		INLINE CACHE *GetParentPage( VOID )
			{ return ParentPage; }

		INLINE SBIT32 GetVersion( VOID )
			{ return Version; }

		INLINE BOOLEAN ValidPage( VOID )
			{ return ((BOOLEAN) ~(Version & 0x1)); }

	private:
        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        PAGE( CONST PAGE & Copy );

        VOID operator=( CONST PAGE & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\newpage.hpp ===
#ifndef _NEW_PAGE_HPP_
#define _NEW_PAGE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Common.hpp"
#include "Environment.hpp"
#include "Find.hpp"
#include "Page.hpp"
#include "RockallBackEnd.hpp"
#include "RockallFrontEnd.hpp"
#include "Spinlock.hpp"
#include "ThreadSafe.hpp"
 
    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The constants supplied here relate to various failure          */
    /*   conditions or situations where information is unknown.         */
    /*                                                                  */
    /********************************************************************/

CONST SBIT16 NoSizeKey				  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;

    /********************************************************************/
    /*                                                                  */
    /*   Create and delete pages.                                       */
    /*                                                                  */
    /*   We would normally expect a class to manage its own memory.     */
    /*   However, this is quite difficult for the 'PAGE' class as it    */
    /*   is also responsible for managing the memory for the memory     */
    /*   allocator.  So here we remove a potentially nasty chore        */
    /*   and isolate it in a class of its own.                          */
    /*                                                                  */
    /********************************************************************/

class NEW_PAGE : public ENVIRONMENT, public COMMON
    {
		//
		//   Private structures.
		//
		//   All the pages descriptions created by this
		//   class and managed by the memory allocator
		//   are linked in three list.  One of these lists
		//   is managed by this class and is called the
		//   'NewPageList'.  All pages are linked into 
		//   of three sub-lists.  The 'ExternalList' is
		//   a list of pages externally allocated pages.
		//   The 'FullList' is a list of sub-allocated
		//   space from the 'ExternalList' which is 
		//   partially or completely filled with alocations.
		//   Finally, the 'FreeList' is a collection of
		//   empty page descriptions all of the same size.
		//   
		//
		typedef struct
			{
			SBIT32                    Elements;
			LIST					  ExternalList;
			LIST					  FreeList;
			LIST					  FullList;
			SBIT32                    Size;
			}
		NEW_PAGES;
		
		//
		//   Private data.
		//
		//   We manage a collection of data structures in
		//   this class.  The fundamental data structure
		//   is a stack of externally allocated pages that
		//   typically contain page descriptions that are
		//   linked together into linked lists.  The maximum
		//   size of this stack is given by 'MaxStack'. 
		//   A few additional pages are consumed to allocate
		//   stacks for caches in other classes.
		//
		SBIT32						  MaxCacheStack;
		SBIT32						  MaxNewPages;
		SBIT32						  MaxStack;

		//
		//   We keep track of various values to save having
		//   to recompute them.  The 'NaturalSize' is the 
		//   natural allocation size of our host (i.e. the OS).
		//   The 'RootSize' is some multiple of the 
		//   'NaturalSize' that this class uses to consume 
		//   memory.  The 'ThreadSafe' flag indicates whether
		//   we need to use locks.  The "TopOfStack' is the
		//   stack which contains pointers to the externally
		//   allocated space.  The 'Version' is the global
		//   version number that is used to stamp each page
		//   whenever it is allocated or deallocated.  The
		//   version number allows the code to ensure that
		//   a page description has not been changed while
		//   it was not holding the associated lock.
		//   
		SBIT32						  NaturalSize;
		SBIT32						  RootCoreSize;
		SBIT32						  RootStackSize;
		SBIT32						  TopOfStack;
		SBIT32						  Version;

		//
		//   We keep pointers to all the interesting data
		//   structures we may need to update.  The
		//   'CacheStack' points to block of memory that
		//   is being sliced into small stacks for caches
		//   in other classes.  The 'NewPages' points to
		//   an array of linked lists of page descriptions.
		//   Each collection of page descriptions is 
		//   identical except for the size of the assocated
		//   bit vector.
		//
		CHAR						  *CacheStack;
 		NEW_PAGES					  *NewPages;
		VOID                          **Stack;

		//
		//   We sometimes need to interact with some of
		//   the other class.  The 'Find" class is a hash
		//   table of all the currently allocated pages.
		//   The 'RockallBackEnd' class contains the external
		//   API which includes the external memory memory
		//   allocation functions.  The 'TopCache' is the
		//   largest cache we support and contains details
		//   about top level allocations sizes.  The   
		//   'ThreadSafe' class indicates whether locking 
		//   is required. 
		//
		ROCKALL_BACK_END			  *RockallBackEnd;
		CACHE						  *TopCache;
		THREAD_SAFE					  *ThreadSafe;

		SPINLOCK                      Spinlock;

   public:
		//
		//   Public functions.
		//
		//   The public functions provide support for creating
		//   new page descriptions and caches for other 
		//   classes.  Although a lot of the fuinctionality
		//   of the heap is masked from this class various
		//   features such as deleting the entire heap
		//   (i.e. 'DeleteAll') are still visable.
		//
        NEW_PAGE
			(
			SBIT32					  NewPageSizes[],
			ROCKALL_BACK_END		  *NewRockallBackEnd,
			SBIT32					  Size,
			THREAD_SAFE				  *NewThreadSafe 
			);

		PAGE *CreatePage( CACHE *Cache,SBIT32 NewSize = NoSize );

		VOID DeleteAll( BOOLEAN Recycle );

		VOID DeletePage( PAGE *Page );

		SBIT16 FindSizeKey( SBIT16 NumberOfElements );

		VOID *NewCacheStack( SBIT32 Size  );

		VOID ResizeStack( VOID );

		BOOLEAN Walk( SEARCH_PAGE *Details,FIND *Find );

        ~NEW_PAGE( VOID );

		//
		//   Public inline functions.
		//
		//   The public inline functions are typically either
		//   small or highly performance sensitive.  The
		//   functions here mainly relate to locking and
		//   updating various data structures.
		//
		INLINE VOID ClaimNewPageLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Spinlock.ClaimLock(); } 
			}

		INLINE VOID ReleaseNewPageLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Spinlock.ReleaseLock(); } 
			}

		INLINE VOID UpdateNewPage( CACHE *NewTopCache )
			{ TopCache = NewTopCache; }

	private:
		//
		//   Private functions.
		//
		//   We support the overloading of the external
		//   memory allocation routines.  This is somewhat
		//   unusual and means that we need to verify
		//   that these functions do not supply us with
		//   total rubbish.
		//
		VOID *VerifyNewArea( SBIT32 AlignMask,SBIT32 Size,BOOLEAN User );

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        NEW_PAGE( CONST NEW_PAGE & Copy );

        VOID operator=( CONST NEW_PAGE & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\newpagelist.hpp ===
#ifndef _NEW_PAGE_LIST_HPP_
#define _NEW_PAGE_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "BucketList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The new page list.                                             */
    /*                                                                  */
    /*   The new page list links all the memory allocated by the low    */
    /*   level external allocator, or sub-divided pages or free pages   */
    /*   so they can be quickly found.                                  */
    /*                                                                  */
    /********************************************************************/

class NEW_PAGE_LIST : public BUCKET_LIST
    {
		//
		//   Private data.
		//
 		LIST						  NewPageList;

   public:
		//
		//   Public inline functions.
		//
		//   All page descriptions contain four linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
		//
        NEW_PAGE_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromNewPageList( LIST *HeadOfList )
			{ NewPageList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfNewPageList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInNewPageList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> First()) ); }

		INLINE VOID InsertInNewPageList( LIST *HeadOfList )
			{ NewPageList.Insert( HeadOfList ); }

		STATIC INLINE PAGE *LastInNewPageList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> Last()) ); }

		INLINE PAGE *NextInNewPageList( VOID )
			{ return ComputePageAddress( ((CHAR*) NewPageList.Next()) ); }

        ~NEW_PAGE_LIST( VOID )
			{ /* void */ };

	private:
		//
		//   Private functions.
		//
		//   Compute the actual start address of the page
		//   and return it to allow the linked list to
		//   be correctly walked.
		//
		STATIC INLINE PAGE *ComputePageAddress( CHAR *Address )
			{
			if ( Address != NULL )
				{ return ((PAGE*) (Address - sizeof(BUCKET_LIST))); }
			else
				{ return ((PAGE*) NULL); }
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        NEW_PAGE_LIST( CONST NEW_PAGE_LIST & Copy );

        VOID operator=( CONST NEW_PAGE_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\page.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "NewPage.hpp"
#include "Page.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here allow the allocation bit vector    */
    /*   to be rapidly searched for free storage.                       */
    /*                                                                  */
    /********************************************************************/

CONST BIT32 AllocatedMask			  = 0x2;
CONST BIT32 FullSearchMask			  = 0xaaaaaaaa;
CONST BIT32 FullWordShift			  = (MaxBitsPerWord - OverheadBits);
CONST BIT32 SubDividedMask			  = 0x1;
CONST BIT32 WordSearchMask			  = (AllocatedMask << FullWordShift);

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*                                                                  */
    /*   All page descriptions are actually created and deleted by      */
    /*   a separate class called 'NEW_PAGE'.  Nonetheless, as a         */
    /*   step the appropriate constructors and destructors are          */
    /*   invoked to support the standard C++ programming methodology.   */
    /*                                                                  */
    /********************************************************************/

PAGE::PAGE
		( 
		VOID						  *NewAddress,
		CACHE						  *NewCache,
		SBIT32						  NewPageSize, 
		CACHE						  *NewParentPage,
		SBIT32						  NewVersion 
		)
	{
	REGISTER SBIT32 Count;
	REGISTER SBIT16 NumberOfElements = (NewCache -> GetNumberOfElements());
	REGISTER SBIT16 SizeOfElements = (NewCache -> GetSizeOfElements());

	//
	//   Create a page description.
	//
	Address = (CHAR*) NewAddress;
	PageSize = NewPageSize;
	Version = NewVersion;

	Allocated = 0;
	Available = NumberOfElements;
	FirstFree = 0;

	//
	//   Set up the pointers to related classes.
	//
	Cache = NewCache;
	ParentPage = NewParentPage;

	//
	//   Zero the bit vector.
	//
	for ( Count=0;Count < SizeOfElements;Count ++ )
		{ Vector[ Count ] = 0; }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the actual size.                                       */
    /*                                                                  */
    /*   Almost all allocation sizes are derived from the associated    */
    /*   caches.  However, there are a few special pages that contain   */
    /*   a single allocation of some weird size.                        */
    /*                                                                  */
    /********************************************************************/

SBIT32 PAGE::ActualSize( VOID )
	{
	return
		(
		(ParentPage == ((CACHE*) GlobalRoot))
			? PageSize
			: (Cache -> GetAllocationSize())
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete an allocation.                                          */
    /*                                                                  */
    /*   We need to delete the memory allocation described by the       */
    /*   parameters.  However, as we are of an untrusting nature        */
    /*   we carefully check the request to ensure it is valid.          */
    /*                                                                  */
    /********************************************************************/

BOOLEAN PAGE::Delete( SEARCH_PAGE *Details )
    {
	//
	//   We know that no one would deallocate memory
	//   they had not previously allocated (yea - right).
	//   So here we check for this case.
	//
	if ( (*Details -> VectorWord) & Details -> AllocationMask )
		{
		//
		//   Nasty: it is possible for the user to give us an
		//   address that points to the middle of the element
		//   to be freed instead of the beginning.  This is no
		//   problem for us but we have to ponder whether the
		//   caller knew what they were doing.  If this is the 
		//   case we fail the request.
		//
		if ( Details -> Found )
			{
			//
			//   We have found that the element is allocated
			//   (as one might expect) so lets deallocate it 
			//   and update the various counters.
			//
			(*Details -> VectorWord) &= 
				~(Details -> AllocationMask | Details -> SubDivisionMask);

			//
			//   We may need to push back the pointer to the 
			//   first free element.  This will ensure that
			//   we can quickly locate the freed element for  
			//   later so we can reuse it.
			//
			if ( FirstFree > Details -> VectorOffset )
				{ FirstFree = ((SBIT16) Details -> VectorOffset); }

			//
			//   If the page was full and now has an empty
			//   slot then add it to the bucket list so that
			//   the free space can be found.
			//
			if ( Full() )
				{ Cache -> InsertInBucketList( this ); }

			//
			//   Update the allocation information.
			//
			Allocated --;
			Available ++;

			//
			//   If the page is now empty then delete 
			//   the page to conserve space.
			//
			if ( Empty() ) 
				{
				//
				//   We immediately delete empty pages
				//   except at the top level where it is
				//   under user control.
				//
				if ( ! Cache -> TopCache() )
					{ Cache -> DeletePage( this ); }
				else
					{
					REGISTER SBIT32 MaxFreePages = 
						(Cache -> GetHeap() -> GetMaxFreePages());

					((BUCKET*) Cache) -> ReleaseSpace( MaxFreePages );
					}
				}

			return True;
			}
		}

	return False;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Delete all simple allocations.                                 */
    /*                                                                  */
    /*   Although this routine may seem insignificant its effects are   */
    /*   dramatic.  When called this function deletes all the none      */
    /*   sub-allocated elements and updates the control values.         */
    /*                                                                  */
    /********************************************************************/

VOID PAGE::DeleteAll( VOID )
    {
	REGISTER BOOLEAN PageFull = Full();

	//
	//   Simply reset the allocation counts.
	//
	Allocated = 0;
	Available = (Cache -> GetNumberOfElements());
	FirstFree = 0;

	//
	//   We know that if this cache does not have any
	//   child allocations that it is safe to simply
	//   zero the bit vector.  If not we have to do it
	//   the long way.
	//
	if ( Cache -> GetNumberOfChildren() > 0 )
		{
		REGISTER SBIT32 Count;
		REGISTER SBIT16 SizeOfElements = (Cache -> GetSizeOfElements());

		//
		//   We examine each word of the bit vector 
		//   and delete all the elements that are
		//   not sub-divided into smaller sizes.
		//
		for ( Count=0;Count < SizeOfElements;Count ++ )
			{
			REGISTER BIT32 *Word = & Vector[ Count ];
			REGISTER BIT32 AllAllocations = ((*Word) & FullSearchMask);
			REGISTER BIT32 AllSubDivided = ((*Word) & (AllAllocations >> 1));
			REGISTER BIT32 FinalMask = (AllSubDivided | (AllSubDivided << 1));

			//
			//   Delete all normal allocations.
			//
			(*Word) &= FinalMask;

			//
			//   If the final mask is not zero then
			//   we still have some allocations active.
			//   We need to count these and update the
			//   control information.
			//
			if ( FinalMask != 0 )
				{
				REGISTER SBIT32 Total = 0;

				//
				//   Count the allocations.
				//
				for ( /* void */;FinalMask != 0;FinalMask >>= OverheadBits )
					{ Total += (FinalMask & 1); }

				//
				//   Update the control information.
				//
				Allocated = ((SBIT16) (Allocated + Total));
				Available = ((SBIT16) (Available - Total));
				}
			}
		}
	else
		{
		REGISTER SBIT32 Count;
		REGISTER SBIT16 SizeOfElements = (Cache -> GetSizeOfElements());

		//
		//   Zero the bit vector.
		//
		for ( Count=0;Count < SizeOfElements;Count ++ )
			{ Vector[ Count ] = 0; }
		}

	//
	//   If the page was full and now has empty
	//   slots then add it to the bucket list so 
	//   that the free space can be found.
	//
	if ( (PageFull) && (! Full()) )
		{ Cache -> InsertInBucketList( this ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Find an allocation page.                                       */
    /*                                                                  */
    /*   When we receive a request to delete an allocation we don't     */
    /*   have a clue about where to find it.  All we have is a hash     */
    /*   table (see 'FIND') of allocated pages.  So we mask off the     */
    /*   low order bits of the address and try to find the top level    */
    /*   external allocation.  If this works we see if the area we      */
    /*   are looking at has been sub-divided and if so we try the       */
    /*   same trick again until we get the the origibal allocation      */
    /*   page.                                                          */
    /*                                                                  */
    /********************************************************************/

PAGE *PAGE::FindPage
		( 
		VOID						  *Memory,
		SEARCH_PAGE					  *Details,
		FIND						  *Find,
		BOOLEAN						  Recursive 
		)
    {
	//
	//   We navigate through the pages trying to find
	//   the allocation page associated with the address.
	//   If we find a page that has no children then 
	//   we can assume we have arrived and exit early 
	//   unless the caller has requested all the realated 
	//   details.
	//
	if ( (Cache -> GetNumberOfChildren() > 0) || (Details != NULL) )
		{
		AUTO BOOLEAN Found;
		REGISTER SBIT32 Displacement = 
			((SBIT32) (((CHAR*) Memory) - Address));
		REGISTER SBIT32 ArrayOffset = 
			(Cache -> ComputeOffset( Displacement,& Found ));
		REGISTER SBIT32 VectorOffset = 
			(ArrayOffset / OverheadBitsPerWord);
		REGISTER SBIT32 WordOffset = 
			(ArrayOffset - (VectorOffset * OverheadBitsPerWord));
		REGISTER SBIT32 WordShift = 
			(((OverheadBitsPerWord-1) - WordOffset) * OverheadBits);
		REGISTER BIT32 AllocationMask = 
			(AllocatedMask << WordShift);
		REGISTER BIT32 SubDivisionMask = 
			(SubDividedMask << WordShift);
		REGISTER BIT32 *VectorWord = 
			& Vector[ VectorOffset ];

		//
		//  We will recursively search and find the target 
		//  address if requested otherwise we will just 
		//  return the details of the next level in the tree.
		//
		if 
				(
				(Recursive)
					&&
				((*VectorWord) & AllocationMask)
					&&
				((*VectorWord) & SubDivisionMask)
				)
			{
			REGISTER PAGE *Page = (Cache -> FindChildPage( Memory,Find ));

			//
			//   We have found the element and checked it. 
			//   So lets pass this request on to the
			//   child page.  However, there is a slight
			//   chance of a race condition here.  It
			//   might be that the original page was
			//   deleted and a new page is currently
			//   being created.  If this is the case
			//   then we will not find the page in the 
			//   hash table so we just exit and fail the 
			//   call.
			//
			if ( Page != ((PAGE*) NULL) )
				{ return (Page -> FindPage( Memory,Details,Find,Recursive )); }
			else
				{ return NULL; }
			}

		//
		//   We see if the caller is interested in the
		//   details relating to this address at the
		//   current level in the tree.
		//
		if ( Details != NULL )
			{
			//
			//   We have computed the details relating
			//   to this address at the current level
			//   in the tree so load them into the
			//   caller supplied structure.
			//
			Details -> Address = Memory;
			Details -> Cache = Cache;
			Details -> Found = Found;
			Details -> Page = this;

			Details -> AllocationMask = AllocationMask;
			Details -> SubDivisionMask = SubDivisionMask;
			Details -> VectorWord = VectorWord;

			Details -> ArrayOffset = ArrayOffset;
			Details -> VectorOffset = VectorOffset;
			Details -> WordShift = WordShift;
			}
		}

	return this;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory allocations.                                   */
    /*                                                                  */
    /*   Allocate available memeory elements from a page.  This is      */
    /*   done by scanning the bit vector looking for unallocated        */
    /*   slots.                                                         */
    /*                                                                  */
    /********************************************************************/

BOOLEAN PAGE::MultipleNew( SBIT32 *Actual,VOID *Array[],SBIT32 Requested )
    {
	//
	//   We begin by making sure that there is at least
	//   one element to allocate and that we need to
	//   allocated at least one element.
	//
	if ( (! Full()) && ((*Actual) < Requested) )
		{
		REGISTER SBIT16 SizeOfElements = (Cache -> GetSizeOfElements());

		//
		//   Search the bit vector from low addresses to 
		//   high addresses looking for a free slots.
		//   We keep a pointer to the first word with
		//   a free element in 'FirstFree'.  Sometimes
		//   the current word may be fully allocated so 
		//   we might need to scan.  However, there can
		//   never be any free memory before this point 
		//   in the bit vector.
		//
		for ( /* void */;FirstFree < SizeOfElements;FirstFree ++ )
			{
			REGISTER SBIT32 ArrayOffset = (FirstFree * OverheadBitsPerWord);
			REGISTER BIT32 AvailableMask = WordSearchMask;
			REGISTER BIT32 *VectorWord = & Vector[ FirstFree ];
			REGISTER SBIT32 WordOffset = 0;

			//
			//   We scan the bit vector word at a time 
			//   looking for any free allocation slots.
			//
			while ( ((*VectorWord) & FullSearchMask) != FullSearchMask )
				{
				REGISTER BIT32 Value = (*VectorWord);

				//
				//   We know there is an at least one empty  
				//   slot availabale in the current word but  
				//   don't know which one We search for the
				//   slot with the lowest address and stop
				//   when we find it.
				//
				for 
					(
					/* void */;
					(AvailableMask & Value) != 0; 
					AvailableMask >>= OverheadBits, WordOffset ++   
					);

				//
				//   We should never fail to find a free 
				//   allocation slot so if we do then the 
				//   heap must be corrupt.
				//
				if ( WordOffset < OverheadBitsPerWord )
					{
					REGISTER SBIT32 VectorOffset = (ArrayOffset + WordOffset);

					//
					//   We need to ensure that the element 
					//   we have chosen if not outside the 
					//   valid range for this page.
					//
					if ( VectorOffset < (Cache -> GetNumberOfElements()) )
						{
						//
						//   Update the allocation information.
						//
						Allocated ++;
						Available --;

						//
						//   Turn on the bits indicating that this
						//   element is in use.
						//
						(*VectorWord) |= AvailableMask;

						//
						//   If the page is full we remove it
						//   from the bucket list so we will no
						//   longer look at it when we are 
						//   trying to find free space.
						//
						if ( Full() )
							{ Cache -> DeleteFromBucketList( this ); }

						//
						//   Add the element to the allocation array
						//   so it can be returned to the caller.
						//
						Array[ (Requested - ((*Actual) ++) - 1) ] =
							(
							Cache -> ComputeAddress
								( 
								Address,
								VectorOffset
								)
							);

						//
						//   When we have got what we need we exit.
						//
						if ( ((*Actual) >= Requested) )
							{ return True; }
						}
					else
						{ break; }
					}
				else
					{ Failure( "Bit vector is corrupt in MultipleNew" ); }
				}
			}
		}

	return ((*Actual) >= Requested);
    }

    /********************************************************************/
    /*                                                                  */
    /*   A single memory allocation.                                    */
    /*                                                                  */
    /*   Allocate an available memeory element from the page.  This     */
    /*   is done by scanning the bit vector looking for unallocated     */
    /*   slots.                                                         */
    /*                                                                  */
    /********************************************************************/

VOID *PAGE::New( BOOLEAN SubDivided )
    {
	//
	//   We begin by making sure that there is at least
	//   one element to allocate.
	//
	if ( ! Full() )
		{
		REGISTER SBIT16 SizeOfElements = (Cache -> GetSizeOfElements());

		//
		//   Search the bit vector from low addresses to 
		//   high addresses looking for a free slot.
		//   We keep a pointer to the first word with
		//   a free element in 'FirstFree'.  Sometimes
		//   the current word may be fully allocated so 
		//   we might need to scan.  However, there can
		//   never be any free memory before this point 
		//   in the bit vector.
		//
		for ( /* void */;FirstFree < SizeOfElements;FirstFree ++ )
			{
			REGISTER BIT32 *VectorWord = & Vector[ FirstFree ];

			//
			//   We scan the bit vector word at a time 
			//   looking for any free allocation slots.
			//
			if ( ((*VectorWord) & FullSearchMask) != FullSearchMask )
				{
				REGISTER BIT32 AvailableMask = WordSearchMask;
				REGISTER BIT32 Value = (*VectorWord);
				REGISTER SBIT32 WordOffset = 0;

				//
				//   We know there is an at least one empty  
				//   slot availabale in the current word but  
				//   don't know which one We search for the
				//   slot with the lowest address and stop
				//   when we find it.
				//
				for 
					(
					/* void */;
					(AvailableMask & Value) != 0; 
					AvailableMask >>= OverheadBits, WordOffset ++   
					);

				//
				//   We should never fail to find a free 
				//   allocation slot so if we do then the 
				//   heap must be corrupt.
				//
				if ( WordOffset < OverheadBitsPerWord )
					{
					REGISTER SBIT32 VectorOffset = 
						((FirstFree * OverheadBitsPerWord) + WordOffset);

					//
					//   We need to ensure that the element 
					//   we have chosen if not outside the 
					//   valid range for this page.
					//
					if ( VectorOffset < (Cache -> GetNumberOfElements()) )
						{
						//
						//   Update the allocation information.
						//
						Allocated ++;
						Available --;

						//
						//   Turn on the bit indicating that this
						//   element is in use.  If the allocation 
						//   is to be sub-divided then trun on this
						//   bit as well.
						//
						(*VectorWord) |=
							(
							AvailableMask
								|
							(SubDivided ? (AvailableMask >> 1) : 0)
							);

						//
						//   If the page is full we remove it
						//   from the bucket list so we will no
						//   longer look at it when we are 
						//   trying to find free space.
						//
						if ( Full() )
							{ Cache -> DeleteFromBucketList( this ); }

						//
						//   Return the address of the allocated 
						//   memory to the caller.
						//
						return
							(
							Cache -> ComputeAddress
								( 
								Address,
								VectorOffset
								)
							);
						}
					}
				else
					{ Failure( "Bit vector is corrupt in New" ); }
				}
			}
#ifdef DEBUGGING

		if ( ! Full() )
			{ Failure( "Available count corrupt in New" ); }
#endif
		}

	return ((VOID*) AllocationFailure);
    }

    /********************************************************************/
    /*                                                                  */
    /*   Walk the heap.                                                 */
    /*                                                                  */
    /*   We have been asked to walk the heap.  It is hard to know       */
    /*   why anybody might want to do this given the rest of the        */
    /*   functionality available.  Nonetheless, we just do what is      */
    /*   required to keep everyone happy.                               */
    /*                                                                  */
    /********************************************************************/

BOOLEAN PAGE::Walk( SEARCH_PAGE *Details,FIND *Find )
    {
	REGISTER BOOLEAN FreshPage = False;

	//
	//   We have been handed the details of an allocation.
	//   We need to walk along this allocation and find
	//   the next non-subdivided allocation.
	do
		{
		//
		//   We need to setup the heap walk if the address
		//   is null so we skip the heap walk code.
		//
		if ( Details -> Address != NULL )
			{
			REGISTER SBIT32 Count;
			REGISTER SBIT32 End = Details -> Cache -> GetNumberOfElements();
			REGISTER SBIT32 Start = Details -> ArrayOffset;
			REGISTER PAGE *Page = Details -> Page;

			//
			//   Walk the current page looking for a suitable
			//   memory allocation to report to the user.  When
			//   we reach the end of the page we need to get
			//   another page to walk.
			//
			for 
					(
					Count = ((FreshPage) ? 0 : 1);
					(Start + Count) < End;
					Count ++
					)
				{
				//
				//   Compute the new address.
				//
				Details -> Address = 
					(
					Page -> Cache -> ComputeAddress
						( 
						Page -> Address,
						(Start + Count)
						)
					);

				//
				//   Compute the new allocation details.
				//
				Page -> FindPage
					( 
					Details -> Address,
					Details,
					Find,
					False 
					);

				//
				//   We skip all sub-divided allocations as they 
				//   will get reported elsewhere.
				//
				if (! ((*Details -> VectorWord) & Details -> SubDivisionMask) )
					{ return True; }
				}
			}

		//
		//   Update the flag to show that we have
		//   had to go and get a new page.
		//
		FreshPage = True;
		}
	while ( Details -> Cache -> Walk( Details,Find ) );

	return False;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the current page structure.                            */
    /*                                                                  */
    /********************************************************************/

PAGE::~PAGE( VOID )
	{
#ifdef DEBUGGING
	//
	//   Destroy the page structure.
	//
	Address = NULL;
	PageSize = 0;
	ParentPage = NULL;

	Allocated = 0;
	Available = 0;
	FirstFree = 0;

#endif
	//
	//   We update the version number whenever a page is created
	//   or destroyed.  We use the version number to ensure that
	//   a page has not been deleteed and/or recreated between
	//   releasing one lock and claiming a another other lock.
	//
	Version ++;
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\PublicFindList.hpp ===
#ifndef _PUBLIC_FIND_LIST_HPP_
#define _PUBLIC_FIND_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "PrivateFindList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The find list.                                                 */
    /*                                                                  */
    /*   The find list links all the pages in the same hash bucket      */
    /*   together so that the correct page can be found.                */
    /*                                                                  */
    /********************************************************************/

class PUBLIC_FIND_LIST : public PRIVATE_FIND_LIST
    {
		//
		//   Private data.
		//
 		LIST						  PublicFindList;

   public:
		//
		//   Public inline functions.
		//
		//   All page descriptions contain four linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
		//
        PUBLIC_FIND_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromPublicFindList( LIST *HeadOfList )
			{ PublicFindList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfPublicFindList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInPublicFindList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> First()) ); }

		INLINE VOID InsertInPublicFindList( LIST *HeadOfList )
			{ PublicFindList.Insert( HeadOfList ); }

		INLINE PAGE *NextInPublicFindList( VOID )
			{ return ComputePageAddress( ((CHAR*) PublicFindList.Next()) ); }

        ~PUBLIC_FIND_LIST( VOID )
			{ /* void */ };

	private:
		//
		//   Private functions.
		//
		//   Compute the actual start address of the page
		//   and return it to allow the linked list to
		//   be correctly walked.
		//
		STATIC INLINE PAGE *ComputePageAddress( CHAR *Address )
			{
			if ( Address != NULL )
				{ return ((PAGE*) (Address - sizeof(PRIVATE_FIND_LIST))); }
			else
				{ return ((PAGE*) NULL); }
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        PUBLIC_FIND_LIST( CONST PUBLIC_FIND_LIST & Copy );

        VOID operator=( CONST PUBLIC_FIND_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\align.hpp ===
#ifndef _ALIGN_HPP_
#define _ALIGN_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "New.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Alignment of structures to cache line boundaries.              */
    /*                                                                  */
    /*   This class aligns data structures to cache line boundaries.    */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> class ALIGN
    {
        //
        //   Private data.
        //
        TYPE                          *Aligned;
        CHAR                          *Allocated;

    public:
        //
        //   Public functions.
        //
        ALIGN( VOID );

        ~ALIGN( VOID );

		//
		//   Public inline functions.
		//
        INLINE TYPE *operator&( VOID )
			{ return Aligned; }

	private:
        //
        //   Disabled operations.
        //
        ALIGN( CONST ALIGN & Copy );

        VOID operator=( CONST ALIGN & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Ceate a memory allocation and initialize it.  This call is     */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */        
    /*                                                                  */
    /********************************************************************/

template <class TYPE> ALIGN<TYPE>::ALIGN( VOID )
    {
    REGISTER CHAR *Address;

	//
	//   Allocate space for the data structure.
	//
	Allocated = new CHAR[ (CacheLineSize + sizeof(TYPE)) ];

	//
	//   Call the constructor to initialize the structure.
	//
    Address = ((CHAR*) ((((LONG) Allocated) + CacheLineMask) & ~CacheLineMask));

    Aligned = PLACEMENT_NEW( Address,TYPE );
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the memory allocation.  This call is not thread safe   */
    /*   and should only be made in a single thread environment.        */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> ALIGN<TYPE>::~ALIGN( VOID )
    { 
	//
	//   Call the destructor for the allocated type.
	//
    PLACEMENT_DELETE( Aligned,TYPE );

	//
	//   Delete the data structure.
	//
	delete [] Allocated; 
	}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\ThreadSafe.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "ThreadSafe.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control the global lock.           */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 NoThread				  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a thread safe class and prepare it for use.  This is    */
    /*   pretty small but needs to be done with a bit of thought.       */
    /*                                                                  */
    /********************************************************************/

THREAD_SAFE::THREAD_SAFE( BOOLEAN NewThreadSafe )
    {
	//
	//   Setup the class variables.
	//
	Claim = NoThread;
	Owner = NoThread;
	Recursive = 0;
	ThreadSafe = NewThreadSafe;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Claim a global lock.                                           */
    /*                                                                  */
    /*   When we try to claim the global lock we first need to be       */
    /*   sure we have not already go it.  If not we try to claim it     */
    /*   and register our ownership.                                    */
    /*                                                                  */
    /********************************************************************/

BOOLEAN THREAD_SAFE::ClaimGlobalLock( VOID )
	{
	//
	//   We only need to do something when we have 
	//   locking enabled for this heap.
	//
	if ( ThreadSafe )
		{
		REGISTER SBIT32 CurrentThread = GetThreadId();

		//
		//   We only try to claim the global lock
		//   if we have not already got it.
		//
		if ( CurrentThread != Claim )
			{
			//
			//   Claim the associated spinlock and
			//   and then register our claim to the 
			//   global lock.
			//
			Spinlock.ClaimLock();

			Claim = CurrentThread;

			return True;
			}
		else
			{ Recursive ++; }
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Engage a global lock.                                          */
    /*                                                                  */
    /*   When we have claimed the global lock we can wait for a         */
    /*   while before we engage it.  This gives us time to get the      */
    /*   locks we want before disabling all further lock calls.         */
    /*                                                                  */
    /********************************************************************/

VOID THREAD_SAFE::EngageGlobalLock( VOID )
	{
	//
	//   We only need to do something when we have 
	//   locking enabled for this heap.
	//
	if ( ThreadSafe )
		{
		REGISTER SBIT32 CurrentThread = GetThreadId();

		//
		//   Just for fun lets make sure that the caller
		//   has already claimed the global lock.  If not
		//   then we fail.
		//
		if ( CurrentThread == Claim )
			{
			//
			//   We now engage the global lock so all future
			//   locking calls will be disabled.
			//
			Owner = CurrentThread;
			}
		else
			{ Failure( "No claim before engage in EngageGlobalLock" ); }
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release the global lock.                                       */
    /*                                                                  */
    /*   When we have finished we may release the global lock so        */
    /*   that others may use it.                                        */
    /*                                                                  */
    /********************************************************************/

BOOLEAN THREAD_SAFE::ReleaseGlobalLock( BOOLEAN Force )
	{
	//
	//   We only need to do something when we have 
	//   locking enabled for this heap.
	//
	if ( ThreadSafe )
		{
		REGISTER SBIT32 CurrentThread = GetThreadId();

		//
		//   Just for fun lets make sure that the caller
		//   has already claimed the global lock.  If not
		//   and we have not been told to force the issue
		//   then fail.
		//
		if 
				(
				(CurrentThread == Claim) 
					||
				((Force) && (Claim != NoThread))
				)
			{
			//
			//   We may have had some recursive calls.  If
			//   so then exit these calls before releasing
			//   the global lock.
			//
			if ( Recursive <= 0 )
				{
				//
				//   Delete the ownership information and 
				//   free the associated spinlock.
				//
				Claim = NoThread;
				Owner = NoThread;

				Spinlock.ReleaseLock();

				return True;
				}
			else
				{ Recursive --; }
			}
		else
			{ Failure( "No claim before release in ReleaseGlobalLock" ); }
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Delete the thread safe calls and free any associated           */
	/*   resources.                                                     */
    /*                                                                  */
    /********************************************************************/

THREAD_SAFE::~THREAD_SAFE( VOID )
    {
	//
	//   Just for fun lets just check that the
	//   lock is free.  If not we fail.
	//
	if ( (Claim != NoThread) || (Owner != NoThread) || (Recursive != 0) )
		{ Failure( "Global lock busy in destructor for THREAD_SAFE" ); }
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\PrivateFindList.hpp ===
#ifndef _PRIVATE_FIND_LIST_HPP_
#define _PRIVATE_FIND_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "NewPageList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The find list.                                                 */
    /*                                                                  */
    /*   The find list links all the pages in the same hash bucket      */
    /*   together so that the correct page can be found.                */
    /*                                                                  */
    /********************************************************************/

class PRIVATE_FIND_LIST : public NEW_PAGE_LIST
    {
		//
		//   Private data.
		//
 		LIST						  PrivateFindList;

   public:
		//
		//   Public inline functions.
		//
		//   All page descriptions contain four linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
		//
        PRIVATE_FIND_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromPrivateFindList( LIST *HeadOfList )
			{ PrivateFindList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfPrivateFindList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInPrivateFindList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> First()) ); }

		INLINE VOID InsertInPrivateFindList( LIST *HeadOfList )
			{ PrivateFindList.Insert( HeadOfList ); }

		INLINE PAGE *NextInPrivateFindList( VOID )
			{ return ComputePageAddress( ((CHAR*) PrivateFindList.Next()) ); }

        ~PRIVATE_FIND_LIST( VOID )
			{ /* void */ };

	private:
		//
		//   Private functions.
		//
		//   Compute the actual start address of the page
		//   and return it to allow the linked list to
		//   be correctly walked.
		//
		STATIC INLINE PAGE *ComputePageAddress( CHAR *Address )
			{
			if ( Address != NULL )
				{ return ((PAGE*) (Address - sizeof(NEW_PAGE_LIST))); }
			else
				{ return ((PAGE*) NULL); }
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        PRIVATE_FIND_LIST( CONST PRIVATE_FIND_LIST & Copy );

        VOID operator=( CONST PRIVATE_FIND_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\heap\ThreadSafe.hpp ===
#ifndef _THREAD_SAFE_HPP_
#define _THREAD_SAFE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Assembly.hpp"
#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Track the need for locks.                                      */
    /*                                                                  */
    /*   Although it may seem simple to know whether to take a lock     */
    /*   there are addition complications such as recursive cases.      */
    /*   We have colected all the messy code into this class.           */
    /*                                                                  */
    /********************************************************************/

class THREAD_SAFE : public ASSEMBLY
    {
		//
		//   Private data.
		//
		//   All the locking information is held here so as
		//   to simplify the code.
		//
		SBIT32						  Claim;
		SBIT32						  Owner;
		SBIT32						  Recursive;
		SPINLOCK					  Spinlock;
		BOOLEAN						  ThreadSafe;

   public:
		//
		//   Public functions.
		//
		//   The translation functionality supplied by this
		//   class is only applicable after an allocation
		//   has been made.  Hence, all of the APIs supported
		//   relate to the need to translate an allocation
		//   address to the host page description.
		//
        THREAD_SAFE( BOOLEAN NewThreadSafe );

		BOOLEAN ClaimGlobalLock( VOID );

		VOID EngageGlobalLock( VOID );

		BOOLEAN ReleaseGlobalLock( BOOLEAN Force = False );

        ~THREAD_SAFE( VOID );

		//
		//   Public inline functions.
		//
		//   Although this class is perhaps the most self
		//   contained.  Nonetheless, there is still lots
		//   of situations when other classes need to 
		//   interact and get information about the current
		//   situation.
		//
		INLINE BOOLEAN ClaimActiveLock( VOID )
			{ return ((ThreadSafe) && (GetThreadId() != Owner)); }

	private:
        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        THREAD_SAFE( CONST THREAD_SAFE & Copy );

        VOID operator=( CONST THREAD_SAFE & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\assembly.hpp ===
#ifndef _ASSEMBLY_HPP_
#define _ASSEMBLY_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The assembly constants indicate the location of the thread     */
    /*   local store.                                                   */
    /*                                                                  */
    /********************************************************************/

#define PcTeb                         0x18
#define IDTeb                         0x24

#ifdef WINDOWS_95
CONST SBIT32 TebSlot				  = 0x88;
#else
CONST SBIT32 TebSlot				  = 0xE10;
#endif

#ifndef ASSEMBLY_PREFETCH_SUPPORT
#define prefetcht0					  __asm _emit 0x0f __asm _emit 0x18 __asm _emit 0x08
#define prefetcht1					  __asm _emit 0x0f __asm _emit 0x18 __asm _emit 0x10
#define prefetcht2					  __asm _emit 0x0f __asm _emit 0x18 __asm _emit 0x18
#define prefetchnta					  __asm _emit 0x0f __asm _emit 0x18 __asm _emit 0x00
#endif

#pragma warning( disable : 4035 )

    /********************************************************************/
    /*                                                                  */
    /*   Assembly language for ultra high performance.                  */
    /*                                                                  */
    /*   We have coded a few functions in assembly language for         */
    /*   ultra high performance.                                        */
    /*                                                                  */
    /********************************************************************/

class ASSEMBLY
    {
    public:
        //
        //   Public inline functions.
        //
		ASSEMBLY( VOID )
			{ /* void */ }

		STATIC INLINE SBIT32 AtomicAdd
				( 
				VOLATILE SBIT32		  *Address,
				SBIT32				  Value 
				)
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		ecx,Address					// Load the address.
				mov		eax,Value					// Load the value.
				lock	xadd dword ptr[ecx],eax		// Increment the value.
				}
#else
			return 
				(
				(SBIT32) InterlockedExchangeAdd
					( 
					((LPLONG) Address),
					((LONG) Value) 
					)
				);
#endif
			}

		STATIC INLINE SBIT32 AtomicCompareExchange
				( 
				VOLATILE SBIT32		  *Address,
				SBIT32				  NewValue,
				SBIT32				  Value 
				)
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		ecx,Address					// Load the address.
				mov		edx,NewValue				// Load the new value.
				mov		eax,Value					// Load the value.
				lock	cmpxchg	dword ptr[ecx],edx	// Update the value.
				}
#else
			return 
				(
				(SBIT32) InterlockedCompareExchange
					( 
					((VOID**) Address),
					((VOID*) NewValue),
					((VOID*) Value)
					)
				);
#endif
			}
#ifdef ASSEMBLY_X86

		STATIC INLINE SBIT64 AtomicCompareExchange64
				( 
				VOLATILE SBIT64		  *Address,
				SBIT64				  NewValue,
				SBIT64				  Value 
				)
			{
			__asm
				{
				mov		esi, Address				// Load the address.
				mov		ebx, dword ptr NewValue[0]	// Load the new value.
				mov		ecx, dword ptr NewValue[4]	// Load the new value.
				mov		eax, dword ptr Value[0]		// Load the value.
				mov		edx, dword ptr Value[4]		// Load the value.
				lock	cmpxchg8b [esi]				// Update the value.
				}
			}
#endif

		STATIC INLINE SBIT32 AtomicDecrement
				( 
				VOLATILE SBIT32		  *Address
				)
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		ecx,Address					// Load the address.
				mov		eax,-1						// Load constant.
				lock	xadd dword ptr[ecx],eax		// Decrement value.
				dec		eax							// Correct result.
				}
#else
			return ((SBIT32) InterlockedDecrement( ((LONG*) Address) ));
#endif
			}

		STATIC INLINE SBIT32 AtomicExchange
				( 
				VOLATILE SBIT32		  *Address,
				SBIT32				  NewValue 
				)
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		ecx,Address					// Load the address.
				mov		eax,NewValue				// Load the new value.
				lock	xchg dword ptr[ecx],eax		// Exchange new value.
				}
#else
			return 
				(
				(SBIT32) InterlockedExchange
					( 
					((LONG*) Address),
					((LONG) NewValue) 
					)
				);
#endif
			}

		STATIC INLINE SBIT32 AtomicIncrement
				( 
				VOLATILE SBIT32		  *Address
				)
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		ecx,Address					// Load the address.
				mov		eax,1						// Load constant.
				lock	xadd dword ptr[ecx],eax		// Increment value.
				inc		eax							// Correct result.
				}
#else
			return ((SBIT32) InterlockedIncrement( ((LONG*) Address) ));
#endif
			}

		STATIC INLINE SBIT32 GetThreadId( VOID )
			{
#ifdef ASSEMBLY_X86
#ifdef ENABLE_NON_STANDARD_ASSEMBLY
			__asm
				{
				mov		eax,fs:[PcTeb]				// Load TEB base address.
				mov		eax,dword ptr[eax+IDTeb]	// Load thread ID.
				}
#else
			return ((SBIT32) GetCurrentThreadId());
#endif
#else
			return ((SBIT32) GetCurrentThreadId());
#endif
			}

		STATIC INLINE VOID PrefetchL1( VOID *Address )
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		eax,Address					// Load the address.
#ifdef ASSEMBLY_PREFETCH_SUPPORT
				prefetcht0	[eax]					// Prefetch into the L1.
#else
				prefetcht0							// Prefetch into the L1.
#endif
				}
#endif
			}

		STATIC INLINE VOID PrefetchL2( VOID *Address )
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		eax,Address					// Load the address.
#ifdef ASSEMBLY_PREFETCH_SUPPORT
				prefetcht1	[eax]					// Prefetch into the L2.
#else
				prefetcht1							// Prefetch into the L2.
#endif
				}
#endif
			}

		STATIC INLINE VOID PrefetchL3( VOID *Address )
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		eax,Address					// Load the address.
#ifdef ASSEMBLY_PREFETCH_SUPPORT
				prefetcht2	[eax]					// Prefetch into the L3.
#else
				prefetcht2							// Prefetch into the L3.
#endif
				}
#endif
			}

		STATIC INLINE VOID PrefetchNta( VOID *Address )
			{
#ifdef ASSEMBLY_X86
			__asm
				{
				mov		eax,Address					// Load the address.
#ifdef ASSEMBLY_PREFETCH_SUPPORT
				prefetchnta	[eax]					// Prefetch into the L1.
#else
				prefetchnta							// Prefetch into the L1.
#endif
				}
#endif
			}

#ifdef ASSEMBLY_X86
#ifdef ENABLE_NON_STANDARD_ASSEMBLY
		STATIC INLINE VOID *GetTlsAddress( SBIT32 TlsOffset )
			{
			__asm
				{
				mov		eax,TlsOffset				// Load the TLS offset.
				add		eax,fs:[PcTeb]				// Add TEB base address.
				}
			}
#endif
#endif

		STATIC INLINE VOID *GetTlsValue
				( 
				SBIT32				  TlsIndex,
				SBIT32				  TlsOffset
				)
			{
#ifdef ASSEMBLY_X86
#ifdef ENABLE_NON_STANDARD_ASSEMBLY
			__asm
				{
				mov		edx,TlsOffset				// Load the TLS offset.
				add		edx,fs:[PcTeb]				// Add TEB base address.
				mov		eax,[edx]					// Load TLS value.
				}
#else
			return (TlsGetValue( ((DWORD) TlsIndex) ));
#endif
#else
			return (TlsGetValue( ((DWORD) TlsIndex) ));
#endif
			}

		STATIC INLINE VOID SetTlsValue
				( 
				SBIT32				  TlsIndex,
				SBIT32				  TlsOffset,
				VOID				  *NewPointer 
				)
			{
#ifdef ASSEMBLY_X86
#ifdef ENABLE_NON_STANDARD_ASSEMBLY
			__asm
				{
				mov		edx,TlsOffset				// Load the TLS offset.
				add		edx,fs:[PcTeb]				// Add TEB base address.
				mov		ecx,NewPointer				// Load new TLS value.
				mov		[edx],ecx					// Store new TLS value.
				}
#else
			(VOID) TlsSetValue( ((DWORD) TlsIndex),NewPointer );
#endif
#else
			(VOID) TlsSetValue( ((DWORD) TlsIndex),NewPointer );
#endif
			}

		~ASSEMBLY( VOID )
			{ /* void */ }

	private:
        //
        //   Disabled operations.
        //
        ASSEMBLY( CONST ASSEMBLY & Copy );

        VOID operator=( CONST ASSEMBLY & Copy );
    };

#pragma warning( default : 4035 )
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\CallStack.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#ifndef DISABLE_DEBUG_HELP
#include <dbghelp.h>
#endif
#include "CallStack.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Compiler options.                                              */
    /*                                                                  */
    /*   Ensure that the last function call(s) before 'StackWalk'       */
    /*   are not FPO-optimized.                                         */
    /*                                                                  */
    /********************************************************************/

#pragma optimize("y", off)

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control the debug buffer size.     */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MaxBufferSize			  = 512;
CONST SBIT32 SymbolNameLength		  = 512;

    /********************************************************************/
    /*                                                                  */
    /*   Static member initialization.                                  */
    /*                                                                  */
    /*   Static member initialization sets the initial value for all    */
    /*   static members.                                                */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CALL_STACK::Active = False;
SBIT32 CALL_STACK::Activations = 0;
HANDLE CALL_STACK::Process = NULL;
SPINLOCK CALL_STACK::Spinlock = NULL;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a call stack class and initialize it.  This call is     */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

CALL_STACK::CALL_STACK( VOID )
    {
	//
	//   Claim a lock to prevent multiple threads
	//   from using the symbol lookup mechanism.
	//
	Spinlock.ClaimLock();

#ifndef DISABLE_DEBUG_HELP
	//
	//   We will activate the symbols if they are
	//   not already available.
	//
	if ( ! Active )
		{
		//
		//   Setup the process handle, load image help  
		//   and then load any available symbols.
		//
		Process = GetCurrentProcess();

		//
		//   Setup the image help library.
		//
		if ( ! (Active = ((BOOLEAN) SymInitialize( Process,NULL,TRUE ))) )
			{
			//
			//   We only issue the warning message once
			//   when we fail to load the symbols.
			//
			if ( Activations == 0 )
				{
				//
				//   Format the error message and output it
				//   to the debug stream.
				//
				DebugPrint
					(
					"Missing or mismatched symbols files: %x\n",
					HRESULT_FROM_WIN32( GetLastError() )
					);
				}
			}
		}

	//
	//   We keep track of the number of activations
	//   so we can delete the symbols at the
	//   required point.
	//
	Activations ++;

#endif
	//
	//   Release the lock.
	//
	Spinlock.ReleaseLock();

	//
	//   Update the available symbols.
	//
	UpdateSymbols();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Extract the current call stack.                                */
    /*                                                                  */
    /*   Extract the current call stack and return it to the caller     */
    /*   so it can be used later.                                       */
    /*                                                                  */
    /********************************************************************/

SBIT32 CALL_STACK::GetCallStack
		(
		VOID						  *Frames[],
        SBIT32						  MaxFrames,
        SBIT32						  SkipFrames
		)
    {
	REGISTER SBIT32 Count = 0;

#ifndef DISABLE_DEBUG_HELP
	//
	//   We can only examine the symbol information if
	//   we were able to load image help.
	//
	if ( Active )
		{
		REGISTER CONTEXT Context;
		REGISTER HANDLE Thread;
		REGISTER SBIT32 MachineType;
		REGISTER STACKFRAME StackFrame;

		//
		//   Zero all the data structures to make
		//   sure they are clean.
		//
		ZeroMemory( & Context,sizeof(CONTEXT) );
		ZeroMemory( & StackFrame,sizeof(STACKFRAME) );

		//
		//   Setup the necessary flags and extract
		//   the thread context.
		//
		Context.ContextFlags = CONTEXT_FULL;
		MachineType = IMAGE_FILE_MACHINE_I386;
		Thread = GetCurrentThread();

		GetThreadContext( Thread,& Context );

		//
		//   Extract the details of the current
		//   stack frame.
		//
		_asm
			{
				mov StackFrame.AddrStack.Offset, esp
				mov StackFrame.AddrFrame.Offset, ebp
				mov StackFrame.AddrPC.Offset, offset DummyLabel
			DummyLabel:
			}

		StackFrame.AddrPC.Mode = AddrModeFlat;
		StackFrame.AddrStack.Mode = AddrModeFlat;
		StackFrame.AddrFrame.Mode = AddrModeFlat;

		//
		//   Claim a lock to prevent multiple threads
		//   from using the symbol lookup mechanism.
		//
		Spinlock.ClaimLock();

		//
		//   Walk the stack frames extracting the
		//   details from each frame examined.
		//
		while ( Count < MaxFrames )
			{
			//
			//   Walk the each stack frame.
			//
			if 
					(
					StackWalk
						(
						MachineType,		   
						Process,		   
						Thread,		   
						& StackFrame,
						& Context,
						NULL,
						SymFunctionTableAccess,
						SymGetModuleBase,
						NULL
						)
					)
				{
				//
				//   Examine and process the current 
				//   stack frame.
				//
				if ( SkipFrames <= 0 )
					{ 
					//
					//   Collect the current function
					//   address and store it.
					//
					Frames[ (Count ++) ] = 
						((VOID*) StackFrame.AddrPC.Offset); 
					}
				else
					{ SkipFrames --; }
				}
			else
				{ break; }
			}

		//
		//   Release the lock.
		//
		Spinlock.ReleaseLock();
		}

#endif
	return Count;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Format a call stack.                                           */
    /*                                                                  */
    /*   We format an entire call stack into a single string ready      */
    /*   for output.                                                    */
    /*                                                                  */
    /********************************************************************/

VOID CALL_STACK::FormatCallStack
		(
		CHAR						  *Buffer, 
		VOID						  *Frames[], 
		SBIT32						  MaxBuffer, 
		SBIT32						  MaxFrames 
		)
    {
#ifndef DISABLE_DEBUG_HELP
	//
	//   We can only examine the symbol information if
	//   we were able to load image help.
	//
	if ( Active )
		{
		REGISTER SBIT32 Count;

		//
		//   Delete any existing string.
		//
		strcpy( Buffer,"" );

		//
		//   Format each frame and then update the
		//   main buffer.
		//
		for ( Count=0;Count < MaxFrames;Count ++ )
			{
			AUTO CHAR NewSymbol[ MaxBufferSize ];
			REGISTER SBIT32 Size;

			//
			//   Format the symbol.
			//
			FormatSymbol( Frames[ Count ],NewSymbol,MaxBufferSize );

			//
			//   Make sure there is enough space in the
			//   output buffer.
			//
			if ( ((Size = strlen( NewSymbol )) + 1) < MaxBuffer)
				{
				//
				//   Copy the symbol into the buffer.
				//
				strcpy( Buffer,NewSymbol );
				Buffer += Size;

				strcpy( Buffer ++,"\n" );

				MaxBuffer -= (Size + 1);
				}
			else
				{ break; }
			}
		}
	else
		{ strcpy( Buffer,"" ); }
#else
	strcpy( Buffer,"" );
#endif
    }
#ifndef DISABLE_DEBUG_HELP

    /********************************************************************/
    /*                                                                  */
    /*   Format a single symbol.                                        */
    /*                                                                  */
    /*   We format a single simple converting it from an address to     */
    /*   a text string.                                                 */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CALL_STACK::FormatSymbol
		(
		VOID						  *Address,
        CHAR						  *Buffer,
        SBIT32						  MaxBuffer
		)
    {
    AUTO CHAR SymbolBuffer[ (sizeof(IMAGEHLP_SYMBOL) + SymbolNameLength) ];
    AUTO IMAGEHLP_MODULE Module = { 0 };
    REGISTER BOOLEAN Result = True;
    REGISTER PIMAGEHLP_SYMBOL Symbol = ((PIMAGEHLP_SYMBOL) SymbolBuffer);   

	//
	//   Setup values ready for main symbol
	//   extraction function body.
	//
    Module.SizeOfStruct = sizeof(IMAGEHLP_MODULE);

    ZeroMemory( Symbol,(sizeof(IMAGEHLP_SYMBOL) + SymbolNameLength) );

    Symbol -> SizeOfStruct = sizeof(IMAGEHLP_SYMBOL);
    Symbol -> MaxNameLength = SymbolNameLength;

	//
	//   Claim a lock to prevent multiple threads
	//   from using the symbol lookup mechanism.
	//
	Spinlock.ClaimLock();

	//
	//   Extract the module information for the
	//   symbol and format it.
	//
    if ( SymGetModuleInfo( Process,((DWORD) Address),& Module ) )
		{
		REGISTER SBIT32 Size;

		//
		//   Make sure there is enough space in the
		//   output buffer.
		//
        if ( ((Size = strlen( Module.ModuleName )) + 1) < MaxBuffer)
			{
			//
			//   Copy the module name into the buffer.
			//
            strcpy( Buffer,Module.ModuleName );
			Buffer += Size;

            strcpy( Buffer ++,"!" );

			MaxBuffer -= (Size + 1);
			}
		}
    else
		{
		REGISTER SBIT32 Size;

		//
		//   Make sure there is enough space in the
		//   output buffer.
		//
        if ( (Size = strlen( "None!" )) < MaxBuffer)
			{
			//
			//   Copy the module name into the buffer.
			//
            strcpy( Buffer,"None!" );
			Buffer += Size;
			MaxBuffer -= Size;
			}

		//
		//  We failed to extract the module name.
		//
		Result = False;
		}

	//
	//   We will not even bother to try to decode
	//   the symbol if we can't decode the module.
	//
    if ( Result )
		{
		AUTO CHAR SymbolName[ SymbolNameLength ];
		AUTO DWORD Offset = 0;

		//
		//   Try to convert the symbol from an
		//   address to a name.
		//
        if
				(
				SymGetSymFromAddr
					(
					Process,
					((DWORD) Address),
					& Offset,
					Symbol
					)
				)
	        {
			REGISTER SBIT32 Size;

			//
			//   Try to undecorate the name.  If
			//   this fails just use the decorated
			//   name is it is better than nothing.
			//
            if ( ! SymUnDName( Symbol,SymbolName,sizeof(SymbolName) ) )
				{ lstrcpynA( SymbolName,& Symbol->Name[1],sizeof(SymbolName) ); }

			//
			//   Make sure there is enough space in the
			//   output buffer.
			//
			if ( (Size = strlen( SymbolName )) < MaxBuffer)
				{
				//
				//   Copy the symbol name into the buffer.
				//
				strcpy( Buffer,SymbolName );
				Buffer += Size;
				MaxBuffer -= Size;
	            }
			
			//
			//   Format the offset if is is non-zero.
			//
			if ( Offset != 0 )
				{
				//
				//   Format the symbol offset.
				//
				sprintf( SymbolName,"+0x%x",Offset );

				//
				//   Make sure there is enough space in the
				//   output buffer.
				//
				if ( (Size = strlen( SymbolName )) < MaxBuffer)
					{
					//
					//   Copy the symbol name into the buffer.
					//
					strcpy( Buffer,SymbolName );
					Buffer += Size;
					MaxBuffer -= Size;
					}
				}
	        }
        else
	        {
			REGISTER SBIT32 Size;

			//
			//   Format the symbol address.
			//
            sprintf( SymbolName,"0x%p",Address );

			//
			//   Make sure there is enough space in the
			//   output buffer.
			//
			if ( (Size = strlen( SymbolName )) < MaxBuffer)
				{
				//
				//   Copy the symbol name into the buffer.
				//
				strcpy( Buffer,SymbolName );
				Buffer += Size;
				MaxBuffer -= Size;
	            }

 			//
			//  We failed to extract the symbol name.
			//
           Result = False;
	       }
		}
    else
		{
		AUTO CHAR SymbolName[ SymbolNameLength ];
		REGISTER SBIT32 Size;

		//
		//   Format the symbol address.
		//
        sprintf( SymbolName,"0x%p",Address );

		//
		//   Make sure there is enough space in the
		//   output buffer.
		//
		if ( (Size = strlen( SymbolName )) < MaxBuffer)
			{
			//
			//   Copy the symbol name into the buffer.
			//
			strcpy( Buffer,SymbolName );
			Buffer += Size;
			MaxBuffer -= Size;
	        }
		}

	//
	//   Release the lock.
	//
	Spinlock.ReleaseLock();

    return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Load symbols callback.                                         */
    /*                                                                  */
    /*   When we load the symbols we get a callback for every module    */
    /*   that is currently loaded into the application.                 */
    /*                                                                  */
    /********************************************************************/

BOOL STDCALL CALL_STACK::UpdateSymbolCallback
		(
		PSTR						  Module,
        ULONG_PTR					  BaseOfDLL,
        ULONG						  SizeOfDLL,
        VOID						  *Context
		)
    {
	if ( SymGetModuleBase( Process,BaseOfDLL ) == 0 )
		{ SymLoadModule( Process,NULL,Module,NULL,BaseOfDLL,SizeOfDLL ); }

	return TRUE;
    }
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Load the symbols.                                              */
    /*                                                                  */
    /*   Load the symbols for the current process so we can translate   */
    /*   code addresses into names.                                     */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CALL_STACK::UpdateSymbols( VOID )
    {
	REGISTER BOOLEAN Result = True;
#ifndef DISABLE_DEBUG_HELP
	//
	//   We can only examine the symbol information if
	//   we were able to load image help.
	//
	if ( Active )
		{
		//
		//   Claim a lock to prevent multiple threads
		//   from using the symbol lookup mechanism.
		//
		Spinlock.ClaimLock();

		//
		//   Enumaerate all of the loaded modules and
		//   cascade load all of the symbols.
		//
		if ( ! EnumerateLoadedModules( Process,UpdateSymbolCallback,NULL ) )
			{
			//
			//   Format the error message and output it
			//   to the debug window.
			//
			DebugPrint
				(
				"EnumerateLoadedModules returned: %x\n",
				HRESULT_FROM_WIN32( GetLastError() )
				);

			Result = False;
			}

		//
		//   Release the lock.
		//
		Spinlock.ReleaseLock();
		}
#endif

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the call stack.  This call is not thread safe and      */
    /*   should only be made in a single thread environment.            */
    /*                                                                  */
    /********************************************************************/

CALL_STACK::~CALL_STACK( VOID )
	{ 
	//
	//   Claim a lock to prevent multiple threads
	//   from using the symbol lookup mechanism.
	//
	Spinlock.ClaimLock();

#ifndef DISABLE_DEBUG_HELP
	//
	//   Cleanup the symbol library.
	//
	if ( ((-- Activations) == 0) && (Active) )
		{
		Active = False;

		//
		//   I don't understand why this does not work at
		//   the moment so I will fix it later.
		//
		// SymCleanup( Process ); 

		//
		//   Just to be neat lets zero everything.
		//
		Process = NULL;
		}

#endif
	//
	//   Release the lock.
	//
	Spinlock.ReleaseLock();
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\CallStack.hpp ===
#ifndef _CALL_STACK_HPP_
#define _CALL_STACK_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A call stack trace.                                            */
    /*                                                                  */
    /*   The call stack trace class supports the extraction, storage    */
    /*   and formatting of call stack function traces.                  */
    /*                                                                  */
    /********************************************************************/

class CALL_STACK
    {
        //
        //   Static private data.
        //
 		STATIC BOOLEAN				  Active;
 		STATIC SBIT32				  Activations;
	    STATIC HANDLE			      Process;
        STATIC SPINLOCK               Spinlock;

    public:
        //
        //   Public functions.
        //
        CALL_STACK( VOID );

		SBIT32 GetCallStack
			( 
			VOID					  *Frames[], 
			SBIT32					  MaxFrames, 
			SBIT32					  SkipFrames = 1
			);

		VOID FormatCallStack
			(
			CHAR					  *Buffer, 
			VOID					  *Frames[], 
			SBIT32					  MaxBuffer, 
			SBIT32					  MaxFrames 
			);

		BOOLEAN UpdateSymbols( VOID );

        ~CALL_STACK( VOID );

	private:
#ifndef DISABLE_DEBUG_HELP
		//
		//   Private functions.
		//
		BOOLEAN FormatSymbol
			(
			VOID					  *Address,
			CHAR					  *Buffer,
			SBIT32					  MaxBuffer
			);

		//
		//   Static provate functions.
		//
		STATIC BOOL STDCALL UpdateSymbolCallback
			(
			PSTR					  Module,
			ULONG_PTR				  BaseOfDLL,
			ULONG					  SizeOfDLL,
			VOID					  *Context
			);

#endif
        //
        //   Disabled operations.
        //
        CALL_STACK( CONST CALL_STACK & Copy );

        VOID operator=( CONST CALL_STACK & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\autolock.hpp ===
#ifndef _AUTOLOCK_HPP_
#define _AUTOLOCK_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Sharelock.hpp"
#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Automatic sharelock control.                                   */
    /*                                                                  */
    /*   We can simplify quite a bit of code using this class when we   */
    /*   only need to hold a share lock for the duration of a block     */
    /*   or a function.                                                 */
    /*                                                                  */
    /********************************************************************/

class AUTO_EXCLUSIVE_LOCK
    {
		//
		//   Private data.
		//
		SHARELOCK					  *Sharelock;

    public:
        //
        //   Public inline functions.
        //
        AUTO_EXCLUSIVE_LOCK( SHARELOCK *NewSharelock,SBIT32 Sleep = INFINITE )
			{ (Sharelock = NewSharelock) -> ClaimExclusiveLock( Sleep ); }

        ~AUTO_EXCLUSIVE_LOCK( VOID )
			{ Sharelock -> ReleaseExclusiveLock(); }

	private:
        //
        //   Disabled operations.
        //
        AUTO_EXCLUSIVE_LOCK( CONST AUTO_EXCLUSIVE_LOCK & Copy );

        VOID operator=( CONST AUTO_EXCLUSIVE_LOCK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Automatic sharelock control.                                   */
    /*                                                                  */
    /*   We can simplify quite a bit of code using this class when we   */
    /*   only need to hold a share lock for the duration of a block     */
    /*   or a function.                                                 */
    /*                                                                  */
    /********************************************************************/

class AUTO_SHARE_LOCK
    {
		//
		//   Private data.
		//
		SHARELOCK					  *Sharelock;

    public:
        //
        //   Public inline functions.
        //
        AUTO_SHARE_LOCK( SHARELOCK *NewSharelock,SBIT32 Sleep = INFINITE )
			{ (Sharelock = NewSharelock) -> ClaimShareLock( Sleep ); }

        ~AUTO_SHARE_LOCK( VOID )
			{ Sharelock -> ReleaseShareLock(); }

	private:
        //
        //   Disabled operations.
        //
        AUTO_SHARE_LOCK( CONST AUTO_SHARE_LOCK & Copy );

        VOID operator=( CONST AUTO_SHARE_LOCK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Automatic spinlock control.                                    */
    /*                                                                  */
    /*   We can simplify quite a bit of code using this class when we   */
    /*   only need to hold a spin lock for the duration of a block      */
    /*   or a function.                                                 */
    /*                                                                  */
    /********************************************************************/

class AUTO_SPIN_LOCK
    {
		//
		//   Private data.
		//
		SPINLOCK					  *Spinlock;

    public:
        //
        //   Public inline functions.
        //
        AUTO_SPIN_LOCK( SPINLOCK *NewSpinlock,SBIT32 Sleep = INFINITE )
			{ (Spinlock = NewSpinlock) -> ClaimLock( Sleep ); }

        ~AUTO_SPIN_LOCK( VOID )
			{ Spinlock -> ReleaseLock(); }

	private:
        //
        //   Disabled operations.
        //
        AUTO_SPIN_LOCK( CONST AUTO_SPIN_LOCK & Copy );

        VOID operator=( CONST AUTO_SPIN_LOCK & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\barrier.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Barrier.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new barrier and initialize it.  This call is not      */
    /*   thread safe and should only be made in a single thread         */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

BARRIER::BARRIER( VOID )
    {
    Waiting = 0;

    if ( (Semaphore = CreateSemaphore( NULL,0,MaxCpus,NULL )) == NULL)
        { Failure( "Create semaphore in constructor for BARRIER" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Synchronize Threads.                                           */
    /*                                                                  */
    /*   Synchronize a collection of threads.                           */
    /*                                                                  */
    /********************************************************************/

VOID BARRIER::Synchronize( SBIT32 Expecting )
    {
	//
	//   We make sure we are expecting at least two threads.
	//   If not then do nothing.
	//
	if ( Expecting > 1 )
		{
		//
		//   Cliam the lock.
		//
		Spinlock.ClaimLock();

		//
		//   We see if the required number of threads has
		//   arrived.
		//
		if ( Expecting > (++ Waiting) )
			{
			//
			//   We are about to sleep so drop the lock.
			//
			Spinlock.ReleaseLock();

			//
			//   The threads sleep here waiting for everyone 
			//   else to arrive.
			//
			if 
					( 
					WaitForSingleObject( Semaphore,INFINITE ) 
						!= 
					WAIT_OBJECT_0 
					)
				{ Failure( "Sleep failed in Synchronize()" ); }
			}
		else
			{
			REGISTER SBIT32 Wakeup = (Expecting-1);

			//
			//   The count of threads that have arrived is
			//   updated and the number of threads that are
			//   about to leave is updated.
			//
			Waiting -= Expecting;

			//
			//   We are about to wake up all the sleepers so 
			//   drop the lock.
			//
			Spinlock.ReleaseLock();

			//
			//   Wakeup any sleeping threads and exit.
			//
			if ( Wakeup > 0 )
				{
				if ( ! ReleaseSemaphore( Semaphore,Wakeup,NULL ) )
					{ Failure( "Wakeup failed in Synchronize()" ); }
				}
			}
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a barrier.  This call is not thread safe and should    */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

BARRIER::~BARRIER( VOID )
    {
    if ( ! CloseHandle( Semaphore ) )
        { Failure( "Close semaphore in destructor for BARRIER" ); }
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\common.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Common.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Convert a divisor to a shift.                                  */
    /*                                                                  */
    /*   We know that we can convert any divide operation into a        */
    /*   shift when the divisor is a power of two.  This function       */
    /*   figures out whether we can do this and what the how far        */
    /*   we would need to shift.                               .        */
    /*                                                                  */
    /********************************************************************/

BOOLEAN COMMON::ConvertDivideToShift( SBIT32 Divisor,SBIT32 *Shift )
	{
	if ( Divisor > 0 )
		{
		REGISTER SBIT32 Count;

		for ( Count=0;(Divisor & 1) == 0;Count ++ )
			{ Divisor >>= 1; }

		if (Divisor == 1)
			{
			(*Shift) = Count;

			return True;
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Force to the next power of two.                                */
    /*                                                                  */
    /*   We know that we can do certain optimizations if certain        */
    /*   values are a power of two.  Here we force the issue by         */
    /*   rounding up the value to the next power of two.                */
    /*                                                                  */
    /********************************************************************/

SBIT32 COMMON::ForceToPowerOfTwo( SBIT32 Value )
	{
	//
	//   We ensure the value is positive if not we 
	//   simply return the identity value.
	//
	if ( Value > 1 )
		{
		//
		//   We only have to compute the next power of
		//   two if the value is not already a power
		//   of two.
		//
		if ( ! PowerOfTwo( Value ) )
			{
			REGISTER SBIT32 Count;

			for ( Count=0;Value > 0;Count ++ )
				{ Value >>= 1; }

			return (1 << Count);
			}
		else
			{ return Value; }
		}
	else
		{ return 1; }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Convert to lower case.                                         */
    /*                                                                  */
    /*   Convert all characters to lower case until we find the         */
    /*   end of the string.                                             */
    /*                                                                  */
    /********************************************************************/

CHAR *COMMON::LowerCase( CHAR *Text )
	{
	REGISTER CHAR *Current = Text;

	for ( /* void */;(*Current) != '\0';Current ++ )
		{
		if ( isupper( (*Current) ) )
			{ (*Current) = ((CHAR) tolower( (*Current) )); }
		}

	return Text;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Convert to lower case.                                         */
    /*                                                                  */
    /*   Convert a fixed number of characters to lower case.            */
    /*                                                                  */
    /********************************************************************/

CHAR *COMMON::LowerCase( CHAR *Text,SBIT32 Size )
	{
	REGISTER CHAR *Current = Text;

	for ( /* void */;Size > 0;Current ++, Size -- )
		{
		if ( isupper( (*Current) ) )
			{ (*Current) = ((CHAR) tolower( (*Current) )); }
		}

	return Text;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Ensure value is a power of two.                                */
    /*                                                                  */
    /*   We need to ensure that certain values are an exact power       */
    /*   of two.  If this is true then the value will be positive       */
    /*   and only 1 bit will be set.  So we shift right until we        */
    /*   find the first bit on and then the value should be one.        */
    /*                                                                  */
    /********************************************************************/

BOOLEAN COMMON::PowerOfTwo( SBIT32 Value )
	{ return ((Value & (Value-1)) == 0); }
#ifndef DISABLE_ATOMIC_FLAGS

    /********************************************************************/
    /*                                                                  */
    /*   Atomically set flags.                                          */
    /*                                                                  */
    /*   We need to atomically set some flags to prevent them being     */
    /*   corrupted by concurrent updates.                               */
    /*                                                                  */
    /********************************************************************/

VOID COMMON::SetFlags( SBIT32 *CurrentFlags,SBIT32 NewFlags )
	{
	REGISTER SBIT32 StartFlags;
	REGISTER SBIT32 ResultFlags;

	do
		{ 
		StartFlags = (*CurrentFlags);
		
		ResultFlags =
			(
			AtomicCompareExchange
				(
				CurrentFlags,
				(StartFlags |= NewFlags), 
				StartFlags
				)
			);
		}
	while ( StartFlags != ResultFlags );
	}

    /********************************************************************/
    /*                                                                  */
    /*   Atomically unset flags.                                        */
    /*                                                                  */
    /*   We need to atomically unset some flags to prevent them being   */
    /*   corrupted by concurrent updates.                               */
    /*                                                                  */
    /********************************************************************/

VOID COMMON::UnsetFlags( SBIT32 *CurrentFlags,SBIT32 NewFlags )
	{
	REGISTER SBIT32 StartFlags;
	REGISTER SBIT32 ResultFlags;

	do
		{ 
		StartFlags = (*CurrentFlags);
		
		ResultFlags =
			(
			AtomicCompareExchange
				(
				CurrentFlags,
				(StartFlags &= ~NewFlags), 
				StartFlags
				)
			);
		}
	while ( StartFlags != ResultFlags );
	}

    /********************************************************************/
    /*                                                                  */
    /*   Convert to upper case.                                         */
    /*                                                                  */
    /*   Convert all characters to upper case until we find the         */
    /*   end of the string.                                             */
    /*                                                                  */
    /********************************************************************/

CHAR *COMMON::UpperCase( CHAR *Text )
	{
	REGISTER CHAR *Current = Text;

	for ( /* void */;(*Current) != '\0';Current ++ )
		{
		if ( islower( (*Current) ) )
			{ (*Current) = ((CHAR) toupper( (*Current) )); }
		}

	return Text;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Convert to upper case.                                         */
    /*                                                                  */
    /*   Convert a fixed number of characters to upper case.            */
    /*                                                                  */
    /********************************************************************/

CHAR *COMMON::UpperCase( CHAR *Text,SBIT32 Size )
	{
	REGISTER CHAR *Current = Text;

	for ( /* void */;Size > 0;Current ++, Size -- )
		{
		if ( islower( (*Current) ) )
			{ (*Current) = ((CHAR) toupper( (*Current) )); }
		}

	return Text;
	}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\common.hpp ===
#ifndef _COMMON_HPP_
#define _COMMON_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Assembly.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A collection of common functions.                              */
    /*                                                                  */
    /*   This class contains common functions that are needed           */
    /*   throughout the application.                                    */
    /*                                                                  */
    /********************************************************************/

class COMMON : public ASSEMBLY
    {
    public:
        //
        //   Public functions.
        //
		COMMON( VOID )
			{ /* void */ }

		STATIC BOOLEAN ConvertDivideToShift( SBIT32 Divisor,SBIT32 *Shift );

		STATIC SBIT32 ForceToPowerOfTwo( SBIT32 Value );

		STATIC CHAR *LowerCase( CHAR *Text );

		STATIC CHAR *LowerCase( CHAR *Text,SBIT32 Size );

		STATIC BOOLEAN PowerOfTwo( SBIT32 Value );
#ifndef DISABLE_ATOMIC_FLAGS

		STATIC VOID SetFlags( SBIT32 *CurrentFlags,SBIT32 NewFlags );

		STATIC VOID UnsetFlags( SBIT32 *CurrentFlags,SBIT32 NewFlags );

		STATIC CHAR *UpperCase( CHAR *Text );

		STATIC CHAR *UpperCase( CHAR *Text,SBIT32 Size );
#endif

		~COMMON( VOID )
			{ /* void */ }

	private:
        //
        //   Disabled operations.
        //
        COMMON( CONST COMMON & Copy );

        VOID operator=( CONST COMMON & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\barrier.hpp ===
#ifndef _BARRIER_HPP_
#define _BARRIER_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A control barrier.                                             */
    /*                                                                  */
    /*   This class synchronizs a collection of threads.                */
    /*                                                                  */
    /********************************************************************/

class BARRIER
    {
        //
        //   Private data.
        //
        HANDLE                        Semaphore;
	    SPINLOCK					  Spinlock;
        VOLATILE LONG                 Waiting;

    public:
        //
        //   Public functions.
        //
        BARRIER( VOID );

        VOID Synchronize( SBIT32 Expecting );

        ~BARRIER( VOID );

	private:
        //
        //   Disabled operations.
        //
        BARRIER( CONST BARRIER & Copy );

        VOID operator=( CONST BARRIER & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\Dll.hpp ===
#ifndef _DLL_HPP_
#define _DLL_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "List.hpp"
#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A monitor class for DLLs.                                      */
    /*                                                                  */
    /*   When a process or thread attaches or dettaches from a DLL      */
    /*   the notification is passed along to all interested parties.    */
    /*                                                                  */
    /********************************************************************/

class DLL : public LIST
    {
		//
		//   Private type definitions.
		//
		typedef VOID (*FUNCTION)( void *Parameter, int Reason );

        //
        //   Private data.
        //
		FUNCTION					  Function;
		VOID						  *Parameter;

        //
        //   Static private data.
        //
        STATIC LIST					  ActiveClasses;
        STATIC SPINLOCK				  Spinlock;

    public:
        //
        //   Public functions.
        //
        DLL( FUNCTION NewFunction = NULL,VOID *NewParameter = NULL );

		VIRTUAL VOID ProcessAttach( VOID );

		VIRTUAL VOID ProcessDetach( VOID );

		VIRTUAL VOID ThreadAttach( VOID );

		VIRTUAL VOID ThreadDetach( VOID );

        ~DLL( VOID );

		//
		//   Static public functions.
		//
		STATIC VOID ClaimLock( VOID )
			{ Spinlock.ClaimLock(); }

		STATIC DLL *GetActiveClasses( VOID )
			{ return ((DLL*) ActiveClasses.First()); }

		STATIC VOID ReleaseLock( VOID )
			{ Spinlock.ReleaseLock(); }

	private:
        //
        //   Disabled operations.
        //
        DLL( CONST DLL & Copy );

        VOID operator=( CONST DLL & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\delay.hpp ===
#ifndef _DELAY_HPP_
#define _DELAY_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Lock.hpp"
#include "Vector.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The delay constants specify the initial size of the array      */
    /*   containing the list of allocations to be deleted.              */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 BlockSize				  = 128;

    /********************************************************************/
    /*                                                                  */
    /*   Delayed memory deletion.                                       */
    /*                                                                  */
    /*   This class provides general purpose memory delayed memory      */
    /*   deletion mechanism.                                            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK=NO_LOCK> class DELAY : public LOCK
    {
        //
        //   Private data.
        //
        SBIT32                        MaxSize;
        SBIT32                        Used;

        TYPE                          **Block;

    public:
        //
        //   Public functions.
        //
        DELAY( SBIT32 NewMaxSize = BlockSize );

        VOID DeferedDelete( TYPE *Memory );

        ~DELAY( VOID );

		//
		//   Public inline functions.
		//
        INLINE CONST TYPE **AllocationList( VOID )
			{ return ((CONST TYPE**) Block); };

        INLINE SBIT32 SizeOfBlock( VOID ) 
			{ return Used; }

    private:
        //
        //   Disabled operations.
        //
        DELAY( CONST DELAY & Copy );

        VOID operator=( CONST DELAY & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new block and prepare it for use.  This call is       */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> DELAY<TYPE,LOCK>::DELAY( SBIT32 NewMaxSize ) 
    {
#ifdef DEBUGGING
    if ( NewMaxSize > 0 )
        {
#endif
        MaxSize = NewMaxSize;
        Used = 0;

        Block = new TYPE* [ NewMaxSize ];
#ifdef DEBUGGING
        }
    else
        { Failure( "Max size in constructor for DELAY" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Defered delete for an allocated memory block.                  */
    /*                                                                  */
    /*   An allocated memory block is registered for deletion by        */
    /*   the class destructor.                                          */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID DELAY<TYPE,LOCK>::DeferedDelete
		( 
		TYPE						  *Memory 
		)
    {
	//
	//   Claim an exclusive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   Make sure we have enough space to register this memory 
	//   block for later deletion.  If not allocate more space 
	//   and copy the existing data into the enlarged space.
	//
    if ( Used >= MaxSize )
        {
        REGISTER SBIT32 Count;
        REGISTER TYPE **NewBlock = new TYPE* [ (MaxSize *= ExpandStore) ];

        for ( Count=0;Count < Used;Count ++ )
            { NewBlock[ Count ] = Block[ Count ]; }

        delete [] Block;

        Block = NewBlock;
        }

	//
	//   Register the allocated memory block.
	//
    Block[ Used ++ ] = Memory;

	//
	//   Release any lock claimed earlier.
	//
	ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory an allocation.  This call is not thread safe and       */
    /*   should only be made in a single thread environment.            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> DELAY<TYPE,LOCK>::~DELAY( VOID )
    {
    REGISTER SBIT32 Count;

	//
	//   Delete the allocated memory blocks.
	//
    for ( Count = (Used - 1);Count >= 0;Count -- )
        { delete Block[ Count ]; }

    delete [] Block;
    }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\features.hpp ===
#ifndef _FEATURES_HPP_
#define _FEATURES_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Standard.hpp"
#include "System.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Active project list.	 							            */
    /*                                                                  */
    /*   The active project list contains all of the projects that      */
    /*   are currently selected.                                        */
    /*                                                                  */
    /********************************************************************/

//#define COMPILING_PIPELINE_SERVER	  1
#define COMPILING_ROCKALL_III		  1
//#define COMPILING_WEB_SERVER		  1

    /********************************************************************/
    /*                                                                  */
    /*   Active fetaure lists.	 							            */
    /*                                                                  */
    /*   The active features list contain all of the features that      */
    /*   are currently selected for each project.                       */
    /*                                                                  */
    /********************************************************************/

#ifdef COMPILING_PIPELINE_SERVER
#ifdef DEBUGGING
#define COMPILING_ROCKALL_LIBRARY	  1			// Enable for testing.
//#define DISABLE_MULTIPLE_PROCESSORS	  1		// Disable for testing.
#define ENABLE_LOCK_STATISTICS		  1			// Enable for testing.
#endif
#define DISABLE_PRECOMPILED_HEADERS	  1		// Disable for testing.
#define DISABLE_STRUCTURED_EXCEPTIONS 1			// Disable for product groups.
#define ENABLE_DEBUG_FILE             1			// Enable for testing.
#define ENABLE_GLOBAL_ROCKALL		  1			// Enable for pure speed.
#define ENABLE_NON_STANDARD_ASSEMBLY  1			// Enable for pure speed.
//#define PRINT_ACTIVE_PACKETS		  1			// Enable for testing.
#endif

#ifdef COMPILING_ROCKALL_III
#ifdef DEBUGGING
#define ENABLE_HEAP_STATISTICS        1			// Enable stats in debug build.
#endif
#define DISABLE_ATOMIC_FLAGS		  1			// Disable for product groups.
//#define DISABLE_DEBUG_HELP			  1
#define DISABLE_ENVIRONMENT_VARIABLES 1			// Disable for product groups.
#define DISABLE_GLOBAL_NEW			  1			// Disable for product groups.
//#define DISABLE_MULTIPLE_PROCESSORS	  1		// Disable for testing.
//#define DISABLE_PRECOMPILED_HEADERS	  1			// Disable for testing.
//#define DISABLE_STRUCTURED_EXCEPTIONS 1			// Disable for product groups.
#define ENABLE_DEBUG_FILE             1			// Create a debug file.
//#define ENABLE_NON_STANDARD_ASSEMBLY  1			// Enable for pure speed.
//#define ENABLE_RECURSIVE_LOCKS		  1		// Enable to save lost of TLS.
#endif

#ifdef COMPILING_WEB_SERVER
#ifdef DEBUGGING
#define ENABLE_LOCK_STATISTICS		  1			// Enable for testing.
#define PRINT_ACTIVE_PACKETS		  1			// Enable for testing.
#endif
#define ENABLE_DEBUG_FILE             1			// Create a debug file.
#define ENABLE_NON_STANDARD_ASSEMBLY  1			// Enable for pure speed.
#endif

    /********************************************************************/
    /*                                                                  */
    /*   The complete feature list.							            */
    /*                                                                  */
    /*   The code supports a significant number of optional features    */
    /*   which are listed in this file.  Any feature can be activated   */
    /*   by copying the approriate setting.  Please be sure to keep     */
    /*   all the flags up to date and leave at list one copy of each    */
    /*   flag below.                                                    */
    /*                                                                  */
    /********************************************************************/

#ifdef ACTIVATE_ALL_OPTIONS
	//
	//   Standard options for all code.
	//
#define ASSEMBLY_X86				  1
#define DEBUGGING                     1

#define DISABLE_GLOBAL_NEW			  1
#define DISABLE_PRECOMPILED_HEADERS	  1
#define DISABLE_STRUCTURED_EXCEPTIONS 1

	//
	//   Standard options for the library code.
	//
#define ENABLE_DEBUG_FILE             1
#define ENABLE_GLOBAL_ROCKALL		  1
#define ENABLE_LOCK_STATISTICS		  1
#define ENABLE_NON_STANDARD_ASSEMBLY  1
#define ENABLE_RECURSIVE_LOCKS		  1

#define DISABLE_ATOMIC_FLAGS		  1
#define DISABLE_DEBUG_HELP			  1
#define DISABLE_ENVIRONMENT_VARIABLES 1
#define DISABLE_MULTIPLE_PROCESSORS	  1
#define DISABLE_STRING_LOCKS		  1

	//
	//   Rockall specific options.
	//
#define COMPILING_ROCKALL_DLL		  1
#define COMPILING_ROCKALL_LIBRARY	  1
#define ENABLE_ALLOCATION_STATISTICS  1
#define ENABLE_HEAP_STATISTICS        1
#define NO_DEFAULT_HEAP				  1

	//
	//   Pipeline Server specific options.
	//
#define ENABLE_BUFFER_LOCK			  1
#define ENABLE_ZERO_WRITE_BUFFER	  1

#define PRINT_ACTIVE_PACKETS		  1

	//
	//   Pipeline Server demo specific options.
	//
#define ENABLE_DATABASE				  1
#define ENABLE_READING				  1
#define ENABLE_TRANSACTIONS			  1
#define ENABLE_WRITING				  1

	//
	//   Web Server specific options.
	//
#define DISABLE_ASYNC_IO			  1
#define DISABLE_BUFFER_COPY			  1
#define DISABLE_WEB_LOCKS			  1
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\environment.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Environment.hpp"
#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The enviroment class slaves various information to speed       */
    /*   up access to it.                                               */
    /*                                                                  */
    /********************************************************************/

CONST SBIT16 EnvironmentCacheSize	  = 16;
CONST SBIT32 SizeOfName				  = 256;

    /********************************************************************/
    /*                                                                  */
    /*   Static member initialization.                                  */
    /*                                                                  */
    /*   Static member initialization sets the initial value for all    */
    /*   static members.                                                */
    /*                                                                  */
    /********************************************************************/

#pragma init_seg(lib)
SBIT32 ENVIRONMENT::Activations = 0;
SBIT32 ENVIRONMENT::AllocationGranularity = 0;
SBIT16 ENVIRONMENT::NumberOfProcessors = 0;
SBIT32 ENVIRONMENT::SizeOfMemory = 0;
SBIT32 ENVIRONMENT::SizeOfPage = 0;
#ifndef DISABLE_ENVIRONMENT_VARIABLES
CHAR *ENVIRONMENT::ProgramName = NULL;
CHAR *ENVIRONMENT::ProgramPath = NULL;
SBIT32 ENVIRONMENT::MaxVariables = 0;
SBIT32 ENVIRONMENT::VariablesUsed = 0;
ENVIRONMENT::VARIABLE *ENVIRONMENT::Variables = NULL;
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new environment and initialize it if needed.  This    */
    /*   call is not thread safe and should only be made in a single    */
    /*   thread environment.                                            */
    /*                                                                  */
    /********************************************************************/

ENVIRONMENT::ENVIRONMENT( VOID )
    {
	//
	//   We only actvate the environment once regardless 
	//   of the number of instances as it is a static class.
	//
    if ( AtomicIncrement( & Activations ) == 1 )
        {
#ifndef DISABLE_ENVIRONMENT_VARIABLES
#ifndef ENABLE_GLOBAL_ROCKALL
		AUTO CHAR ProgramFullName[ SizeOfName ];
#endif
#endif
		AUTO MEMORYSTATUS MemoryStatus;
		AUTO SYSTEM_INFO SystemInformation;

		//
		//   Initialize the class members to reasonable 
		//   default values.
		//
		GetSystemInfo( & SystemInformation );

		GlobalMemoryStatus( & MemoryStatus );

		AllocationGranularity = 
			((SBIT32) SystemInformation.dwAllocationGranularity);
		NumberOfProcessors = 
			((SBIT16) SystemInformation.dwNumberOfProcessors);
		SizeOfMemory = 
			((SBIT32) MemoryStatus.dwTotalPhys);
		SizeOfPage = 
			((SBIT32) SystemInformation.dwPageSize);
#ifndef DISABLE_ENVIRONMENT_VARIABLES
#ifndef ENABLE_GLOBAL_ROCKALL

		//
		//   Slave interesting values like the program name 
		//   and path variable.
		//
		ProgramName = NULL;
		ProgramPath = NULL;

		MaxVariables = 0;
		VariablesUsed = 0;
		Variables = NULL;

		//
		//   Get the complete file name for the current program.
		//
		if ( GetModuleFileName( NULL,ProgramFullName,SizeOfName ) > 0 )
			{
			REGISTER SBIT16 Count = (SBIT16) strlen( (char*) ProgramFullName );
			REGISTER CHAR *Characters = & ProgramFullName[ Count ];

			//
			//   Scan backwards looking for the first directory   
			//   seperator.  There is guaranteed to be at least 
			//   one.
			//
			for 
				( 
				/* void */;
				((Count > 0) && ((*Characters) != (*DirectorySeperator())));
				Count --, Characters -- 
				);

			(*(Characters ++)) = '\0';

			//
			//   Allocate space for the directory path and copy   
			//   the path into the newly allocated area.
			//
			ProgramPath = new CHAR [ (strlen( ((char*) ProgramFullName) )+1) ];

			if ( ProgramPath != NULL )
				{
				(VOID) strcpy
					( 
					((char*) ProgramPath),
					((char*) ProgramFullName)
					); 
				}

			//
			//   Scan the program name backwards looking for a '.'.
			//
			for 
				( 
				Count = (SBIT16) strlen( (char*) Characters );
				((Count > 0) && (Characters[ Count ] != '.'));
				Count -- 
				);

			//
			//   Remove any trailing suffix from the program name 
			//   (i.e. '*.EXE').
			//
			if ( Count > 0 )
				{ Characters[ Count ] = '\0'; }

			//
			//   Allocate space for the program name and copy  
			//   the name into the newly allocated area.
			//
			ProgramName = new CHAR [ (strlen( ((char*) Characters) )+1) ];

			if ( ProgramName != NULL )
				{
				(void) strcpy
					( 
					((char*) ProgramName),
					((char*) Characters) 
					);
				}
			}
#endif
#endif
		}
	}
#ifndef DISABLE_ENVIRONMENT_VARIABLES
#ifndef ENABLE_GLOBAL_ROCKALL

    /********************************************************************/
    /*                                                                  */
    /*   Read an environment variable.                                  */
    /*                                                                  */
    /*   When we read an environment value we want to make sure that    */
    /*   it never changes and gets slaved in memory.  This routine      */
    /*   implements this functionality.                                 */
    /*                                                                  */
    /********************************************************************/

CONST CHAR *ENVIRONMENT::ReadEnvironmentVariable( CONST CHAR *Name )
	{
	if ( Activations > 0 )
		{
		REGISTER SBIT32 Count;
		REGISTER SBIT32 SizeOfName = (SBIT32) strlen( (char*) Name );
		REGISTER VARIABLE *Variable;
		STATIC SPINLOCK Spinlock;

		//
		//   The environment variables can only be scanned by  
		//   one CPU at a time because a second CPU might reallocate  
		//   the storage and cause the first CPU to fail.
		//
		Spinlock.ClaimLock();

		//
		//   Examine all existing environment variables looking for a 
		//   match. If a match is found return it to the caller.
		//
		for 
				( 
				Count = VariablesUsed, Variable = Variables;
				Count > 0; 
				Count --, Variable ++ 
				)
			{
			if 
					( 
					(SizeOfName == Variable -> SizeOfName) 
						&& 
					(strcmp( (char*) Name,(char*) Variable -> Name ) == 0) 
					)
				{
				Spinlock.ReleaseLock();

				return (Variable -> Value);
				}
			}

		//
		//  If we have filled up our array so we need to make it bigger.
		//  So lets check for this now.
		//
		if ( VariablesUsed >= MaxVariables )
			{
			REGISTER VARIABLE *PreviousAllocation = Variables;

			if ( MaxVariables > 0 )
				{
				Variables = 
					(
					(VARIABLE*) realloc
						( 
						(VOID*) Variables,
						((MaxVariables *= ExpandStore) * sizeof(VARIABLE)) 
						)
					);
				}
			else
				{ Variables = new VARIABLE [ EnvironmentCacheSize ]; }

			//
			//   Lets make sure we were successful.  If not we restore 
			//   the previous pointer as it is still valid.
			//
			if ( Variables == NULL )
				{
				Variables = PreviousAllocation;

				Failure( "Expand memory in ReadEnvironmentVariable" );
				}
			}

		//
		//  We know that we have enough memory to allocate another element and 
		//  that we are the only CPU in this section of code so just add the 
		//  new variable.
		//
		Variable = & Variables[ VariablesUsed ++ ];

		Variable -> SizeOfName = 
			(SBIT32) strlen( (char*) Name );
		Variable -> SizeOfValue = 
			(SBIT32) GetEnvironmentVariable( (char*) Name,"",0 );

		Variable -> Name = new CHAR [ (Variable -> SizeOfName + 1) ];
		(VOID) strcpy( (char*) Variable -> Name,(char*) Name );

		if ( Variable -> SizeOfValue > 0 )
			{
			Variable -> Value = new CHAR [ (Variable -> SizeOfValue + 1) ];

			(VOID) GetEnvironmentVariable
				( 
				(char*) Name,
				(char*) Variable -> Value,
				(int) (Variable -> SizeOfValue + 1)
				);
			}
		else
			{ Variable -> Value = NULL; }

		Spinlock.ReleaseLock();

		return (Variable -> Value);
		}
	else
		{ return NULL; }
	}
#endif
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory an environment.  This call is not thread safe and      */
    /*   should only be made in a single thread environment.            */
    /*                                                                  */
    /********************************************************************/

ENVIRONMENT::~ENVIRONMENT( VOID )
	{
	//
	//   We only destroy the environment once regardless 
	//   of the number of instances as it is a static class.
	//
    if ( AtomicDecrement( & Activations ) == 0 )
		{
#ifndef DISABLE_ENVIRONMENT_VARIABLES
#ifndef ENABLE_GLOBAL_ROCKALL
		REGISTER SBIT32 Count;

		//
		//   Delete all of the environment variable names
		//   and values.
		//
		for ( Count = 0;Count < VariablesUsed;Count ++ )
			{
			REGISTER VARIABLE *Variable = & Variables[ Count ];

			delete [] Variable -> Name;

			if ( Variable -> Value != NULL )
				{ delete [] Variable -> Value; }
			}


		//
		//   Delete the environment array.
		//
		delete [] Variables;
		Variables = NULL;

		//
		//   Delete the program name and path.
		//
		if ( ProgramPath != NULL )
			{
			delete [] ProgramPath;
			ProgramPath = NULL;
			}

		if ( ProgramName != NULL )
			{
			delete [] ProgramName;
			ProgramName = NULL;
			}
#endif
#endif
		}
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\global.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Global.hpp"
#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control various debug settings.    */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MaxDebugFileName		  = 128;
CONST SBIT32 DebugBufferSize		  = 512;
#ifdef ENABLE_DEBUG_FILE

    /********************************************************************/
    /*                                                                  */
    /*   Static member initialization.                                  */
    /*                                                                  */
    /*   Static member initialization sets the initial value for all    */
    /*   static members.                                                */
    /*                                                                  */
    /********************************************************************/

STATIC CHAR DebugModuleName[ MaxDebugFileName ] = "";
STATIC SPINLOCK Spinlock;

    /********************************************************************/
    /*                                                                  */
    /*   Debug file name.                                               */
    /*                                                                  */
    /*   We sometimes want to change the debug file name to prevent     */
    /*   the debug file being overwritten by a DLLs output or a later   */
    /*   run of the same application.                                   */
    /*                                                                  */
    /********************************************************************/

HANDLE DebugFileHandle( VOID )
	{
	AUTO CHAR FileName[ MaxDebugFileName ];
	STATIC HANDLE DebugFile = INVALID_HANDLE_VALUE;

	//
	//   We will open the debug file if it is not 
	//   already open.
	//
	if ( DebugFile == INVALID_HANDLE_VALUE )
		{
		//
		//   Construct the full file name.
		//
		sprintf
			( 
			FileName,
			"C:\\Temp\\DebugTrace%s.log",
			DebugModuleName 
			);

		//
		//   Now lets try to open the file.
		//
		DebugFile =
			(
			CreateFile
				(
				((LPCTSTR) FileName),
				(GENERIC_READ | GENERIC_WRITE),
				FILE_SHARE_READ, 
				NULL,
				CREATE_ALWAYS,
				NULL,
				NULL
				)
			);

		//
		//   When the file will not open for some reason
		//   we try an alternative path.
		//
		if ( DebugFile == INVALID_HANDLE_VALUE )
			{ 
			//
			//   Construct the alternate file name.
			//
			sprintf
				( 
				FileName,
				"C:\\DebugTrace%s.log",
				DebugModuleName 
				);

			//
			//   Try again using an alternative name.
			//
			DebugFile =
				(
				CreateFile
					(
					((LPCTSTR) FileName),
					(GENERIC_READ | GENERIC_WRITE),
					FILE_SHARE_READ, 
					NULL,
					CREATE_ALWAYS,
					NULL,
					NULL
					)
				);
			}
		}

	return DebugFile;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Debug file name.                                               */
    /*                                                                  */
    /*   We sometimes want to change the debug file name to prevent     */
    /*   the debug file being overwritten by a DLLs output or a later   */
    /*   run of the same application.                                   */
    /*                                                                  */
    /********************************************************************/

VOID DebugFileName( CONST CHAR *FileName )
	{
	AUTO CHAR EditBuffer[ MaxDebugFileName ];
	REGISTER CHAR *Current;

	//
	//   Copy the file name into an edit buffer
	//   so we can remove any directories or
	//   trailing names.
	//
	strncpy( EditBuffer,FileName,MaxDebugFileName );

	EditBuffer[ (MaxDebugFileName-1) ] = '\0';

	//
	//   Scan backwards to remove any suffix.
	//
	for
		(
		Current = & EditBuffer[ (strlen( EditBuffer )-1) ];
		(Current > EditBuffer) && ((*Current) != '.') && ((*Current) != '\\');
		Current --
		);

	if ( (Current > EditBuffer) && (*Current) == '.' )
		{ (*Current) = '\0'; }

	//
	//   Scan backwards to the first directory name.
	//
	for
		(
		Current = & EditBuffer[ (strlen( EditBuffer )-1) ];
		(Current > EditBuffer) && ((*Current) != '\\');
		Current --
		);

	if ( (*Current) == '\\' )
		{ Current ++; }

	//
	//   Copy the edited file name.
	//
	DebugModuleName[0] = '-';

	strncpy( & DebugModuleName[1],Current,(MaxDebugFileName-1) );
	}
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Debug printing.                                                */
    /*                                                                  */
    /*   We sometimes need to print message during debugging. We        */
    /*   do this using the following 'printf' like function.            */
    /*                                                                  */
    /********************************************************************/

VOID DebugPrint( CONST CHAR *Format,... )
	{
	AUTO CHAR Buffer[ DebugBufferSize ];

	//
	//   Start of variable arguments.
	//
	va_list Arguments;

	va_start(Arguments, Format);

	//
	//   Format the string to be printed.
	//
	_vsnprintf
		( 
		Buffer,
		(DebugBufferSize-1),
		Format,
		Arguments 
		);

	//
	//   Force null termination.
	//
	Buffer[ (DebugBufferSize-1) ] = '\0';

#ifdef ENABLE_DEBUG_FILE
	//
	//   Claim a spinlock to prevent multiple
	//   threads executing overlapping writes.
	//
	Spinlock.ClaimLock();

	//
	//   We will write to the debug file if there
	//   is a valid handle.
	//
	if ( DebugFileHandle() != INVALID_HANDLE_VALUE )
		{
		REGISTER CHAR *Current = Buffer;
		REGISTER SBIT32 Length;

		//
		//   A number of windows applications are too
		//   stupid to understand a simple '\n'.  So
		//   here we convert all "\n" to "\r\n".
		//
		for ( /* void */;(*Current) != '\0';Current += Length )
			{
			STATIC DWORD Written;

			//
			//   Count the characters until the next
			//   newline or end of string.
			//
			for
				(
				Length=0;
				((Current[ Length ] != '\n') && (Current[ Length ] != '\0'));
				Length ++
				);

			//
			//   Write the string and then add a return
			//   newline sequence.
			//
			WriteFile
				(
				DebugFileHandle(),
				((LPCVOID) Current),
				((DWORD) Length),
				& Written,
				NULL
				);

			//
			//   Generate a newline (if needed).
			//
			if ( Current[ Length ] == '\n' )
				{ 
				WriteFile
					(
					DebugFileHandle(),
					((LPCVOID) "\r\n"),
					((DWORD) (sizeof("\r\n") - 1)),
					& Written,
					NULL
					);

				Length ++; 
				}
			}

		//
		//   Flush the file buffers.
		//
		FlushFileBuffers( DebugFileHandle() );
		}

	//
	//   Release any lock claimed earlier.
	//
	Spinlock.ReleaseLock();
#else
	//
	//   Write to the debug window.
	//
	OutputDebugString( Buffer );
#endif

	//
	//   End of variable arguments.
	//
	va_end( Arguments );
	}

    /********************************************************************/
    /*                                                                  */
    /*   Software failure.                                              */
    /*                                                                  */
    /*   We know that when this function is called the application      */
    /*   has failed so we simply try to cleanly exit in the vain        */
    /*   hope that the failure can be caught and corrected.             */
    /*                                                                  */
    /********************************************************************/

VOID Failure( char *Message,BOOLEAN Report )
	{
	//
	//   Report the fault to the debug stream
	//   (if required).
	//
	if ( Report )
		{ DebugPrint( "*** Software Failure: %s ***\n",Message ); }

	//
	//   Raise an exception.
	//
#ifdef DISABLE_STRUCTURED_EXCEPTIONS
	throw ((FAULT) Message);
#else
	RaiseException( 1,0,1,((CONST DWORD*) Message) );
#endif
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\global.hpp ===
#ifndef _GLOBAL_HPP_
#define _GLOBAL_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

#pragma warning( disable : 4995)

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Features.hpp"
#include "Standard.hpp"
#include "System.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The standard macros.                                           */
    /*                                                                  */
    /*   The following are standard macros used by various              */
    /*   classes in this program.                                       */
    /*                                                                  */
    /********************************************************************/

#define FIELDOFFSET( Type,Field )	  ((SBIT16) & (((Type *)0) -> Field))
#define TO_DO( Message ) message ( "---- To do ---->>>> " Message )

#ifdef DISABLE_STRUCTURED_EXCEPTIONS
#define TRY							  try
#else
#define TRY							  __try
#endif

    /********************************************************************/
    /*                                                                  */
    /*   The standard constants.                                        */
    /*                                                                  */
    /*   The following are standard constants used by various           */
    /*   classes in this program.                                       */
    /*                                                                  */
    /********************************************************************/

	//
	//   The hardware cache line size.
	//
CONST SBIT32 CacheLineSize			  = 32;
CONST SBIT32 CacheLineMask			  = (CacheLineSize - 1);
CONST SBIT32 NoAlignment			  = 1;

	//
	//   The end of a linked list.
	//
CONST INT EndOfList					  = -1;

	//
	//   The boolean constants.
	//
CONST BOOLEAN False					  = 0;
CONST BOOLEAN True					  = 1;

	//
	//   Various misc constants.
	//
CONST INT ExpandStore				  = 2;
CONST INT MaxCpus					  = 32;
CONST INT NoFlags					  = 0;

    /********************************************************************/
    /*                                                                  */
    /*   The standard functions.                                        */
    /*                                                                  */
    /*   The following are standard functions used by various           */
    /*   classes in multiple applications.                              */
    /*                                                                  */
    /********************************************************************/
#ifdef ENABLE_DEBUG_FILE

HANDLE DebugFileHandle( VOID );

VOID DebugFileName( CONST CHAR *FileName );
#endif

VOID DebugPrint( CONST CHAR *Format,... );

VOID Failure( char *Message,BOOLEAN Report = True );
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\Dll.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Dll.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control various debug settings.    */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MaxDebugFileName		  = 128;

    /********************************************************************/
    /*                                                                  */
    /*   Static member initialization.                                  */
    /*                                                                  */
    /*   Static member initialization sets the initial value for all    */
    /*   static members.                                                */
    /*                                                                  */
    /********************************************************************/

#pragma init_seg(lib)
LIST DLL::ActiveClasses;
SPINLOCK DLL::Spinlock;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new entry so we can notify the class when a DLL       */
    /*   event occurs.                                                  */
    /*                                                                  */
    /********************************************************************/

DLL::DLL( FUNCTION NewFunction,VOID *NewParameter )
    {
	//
	//  Setup class values.
	//
	Function = NewFunction;
	Parameter = NewParameter;

	//
	//   Claim a lock to ensure the list does
	//   not become corrupt.
	//
	Spinlock.ClaimLock();

	//
	//   Add the current instance into the active 
	//   list so it will be notified of all future
	//   events.
	//
	Insert( & ActiveClasses );

	//
	//   Release the lock.
	//
	Spinlock.ReleaseLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Standard DLL processing.                                       */
    /*                                                                  */
    /*   Automatically delete the private per thread heap on thread     */
    /*   exit when Rockall is compiled as a DLL.                        */
    /*                                                                  */
    /********************************************************************/

BOOL WINAPI DllMain
		(
		HINSTANCE					  Module,
		DWORD						  Reason,
		LPVOID						  Reserved 
		)
	{
	REGISTER DLL *Current;

	//
	//   Claim a lock to ensure the list does
	//   not become corrupt.
	//
	DLL::ClaimLock();

	//
	//   When Rockall is built for a DLL we use the 
	//   detach notification to delete the private
	//   per thread heap.
	//
	switch( Reason ) 
		{ 
		case DLL_PROCESS_ATTACH:
			{
#ifdef ENABLE_DEBUG_FILE
			AUTO CHAR FileName[ MaxDebugFileName ];

			//
			//   We will register the DLL name with the 
			//   debug trace code just in case any messages
			//   are generated.
			//
			if ( GetModuleFileNameA( Module,FileName,MaxDebugFileName ) != 0 )
			{ 
				FileName[ MaxDebugFileName - 1 ] = '\0';
				DebugFileName( FileName ); 
			}

#endif
			//
			//   Notify all interested parties that
			//   a process has attached.
			//
			for 
					( 
					Current = ((DLL*) DLL::GetActiveClasses());
					Current != NULL;
					Current = ((DLL*) Current -> Next())
					)
				{ Current -> ProcessAttach(); }

			break;
			}

		case DLL_THREAD_ATTACH:
			{
			//
			//   Notify all interested parties that
			//   a thread has attached.
			//
			for 
					( 
					Current = ((DLL*) DLL::GetActiveClasses());
					Current != NULL;
					Current = ((DLL*) Current -> Next())
					)
				{ Current -> ThreadAttach(); }

			break;
			}

		case DLL_THREAD_DETACH:
			{
			//
			//   Notify all interested parties that
			//   a thread has dettached.
			//
			for 
					( 
					Current = ((DLL*) DLL::GetActiveClasses());
					Current != NULL;
					Current = ((DLL*) Current -> Next())
					)
				{ Current -> ThreadDetach(); }

			break;
			}

		case DLL_PROCESS_DETACH:
			{
			//
			//   Notify all interested parties that
			//   a process has dettached.
			//
			for 
					( 
					Current = ((DLL*) DLL::GetActiveClasses());
					Current != NULL;
					Current = ((DLL*) Current -> Next())
					)
				{ Current -> ProcessDetach(); }

			break;
			}
		}

	//
	//   Release the lock.
	//
	DLL::ReleaseLock();

	return TRUE;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Process attach callback.                                       */
    /*                                                                  */
    /*   When a process attach occurs the following callback is         */
    /*   executed.                                                      */
    /*                                                                  */
    /********************************************************************/

VOID DLL::ProcessAttach( VOID )
	{
	if ( Function != NULL )
		{ Function( Parameter,DLL_PROCESS_ATTACH ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Thread attach callback.                                        */
    /*                                                                  */
    /*   When a thread attach occurs the following callback is          */
    /*   executed.                                                      */
    /*                                                                  */
    /********************************************************************/

VOID DLL::ThreadAttach( VOID )
	{
	if ( Function != NULL )
		{ Function( Parameter,DLL_THREAD_ATTACH ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Thread dettach callback.                                       */
    /*                                                                  */
    /*   When a thread dettach occurs the following callback is         */
    /*   executed.                                                      */
    /*                                                                  */
    /********************************************************************/

VOID DLL::ThreadDetach( VOID )
	{
	if ( Function != NULL )
		{ Function( Parameter,DLL_THREAD_DETACH ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Process dettach callback.                                      */
    /*                                                                  */
    /*   When a process dettach occurs the following callback is        */
    /*   executed.                                                      */
    /*                                                                  */
    /********************************************************************/

VOID DLL::ProcessDetach( VOID )
	{
	if ( Function != NULL )
		{ Function( Parameter,DLL_PROCESS_DETACH ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a DLL.  This call is not thread safe and should        */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

DLL::~DLL( VOID )
    {
	//
	//   Claim a lock to ensure the list does
	//   not become corrupt.
	//
	Spinlock.ClaimLock();

	//
	//   Delete the current instance from the active 
	//   list so it will not be notified of future
	//   events.
	//
	Delete( & ActiveClasses );

	//
	//   Release the lock.
	//
	Spinlock.ReleaseLock();

	//
	//   Delete class values.
	//
	Parameter = NULL;
	Function = NULL;
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\librarypch.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\environment.hpp ===
#ifndef _ENVIRONMENT_HPP_
#define _ENVIRONMENT_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Assembly.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Environment configuration values.                              */
    /*                                                                  */
    /*   This class provides a information about the environment.       */
    /*   The information can be accessed repeatedly with very little    */
    /*   cost as the data is slaved in static memory.                   */
    /*                                                                  */
    /********************************************************************/

class ENVIRONMENT : public ASSEMBLY
    {
#ifndef DISABLE_ENVIRONMENT_VARIABLES
		//
		//   Private structures.
		//
		typedef struct
			{
			CHAR					  *Name;
			SBIT32                    SizeOfName;
			CHAR                      *Value;
			SBIT32                    SizeOfValue;
			} 
		VARIABLE;

#endif
        //
        //   Private data.
        //
        STATIC SBIT32		          Activations;

		STATIC SBIT32                 AllocationGranularity;
        STATIC SBIT16                 NumberOfProcessors;
#ifndef DISABLE_ENVIRONMENT_VARIABLES
		STATIC CHAR                   *ProgramName;
		STATIC CHAR                   *ProgramPath;
#endif
		STATIC SBIT32                 SizeOfMemory;
		STATIC SBIT32                 SizeOfPage;
#ifndef DISABLE_ENVIRONMENT_VARIABLES

		STATIC SBIT32                 MaxVariables;
		STATIC SBIT32                 VariablesUsed;
		STATIC VARIABLE               *Variables;
#endif

    public:
        //
        //   Public functions.
        //
        ENVIRONMENT( VOID );
#ifndef DISABLE_ENVIRONMENT_VARIABLES

		STATIC CONST CHAR *ReadEnvironmentVariable( CONST CHAR *Name );
#endif

        ~ENVIRONMENT( VOID );

		//
		//   Public inline functions.
		//
		STATIC INLINE  SBIT32 AllocationSize(VOID ) 
			{ return AllocationGranularity; };
	
		STATIC INLINE SBIT32 CacheAlignSize( SBIT32 Size )
			{ return ((Size + CacheLineMask) & ~CacheLineMask); }

		STATIC INLINE CONST CHAR *DirectorySeperator( VOID ) 
			{ return "\\"; };

#ifndef DISABLE_MULTIPLE_PROCESSORS
        STATIC INLINE SBIT16 NumberOfCpus( VOID ) 
			{ return NumberOfProcessors; }
#else
        STATIC INLINE SBIT16 NumberOfCpus( VOID ) 
			{ return 1; }
#endif

		STATIC INLINE SBIT32 MemorySize( VOID ) 
			{ return SizeOfMemory; };

		STATIC INLINE SBIT32 PageSize( VOID ) 
			{ return SizeOfPage; };
#ifndef DISABLE_ENVIRONMENT_VARIABLES

		STATIC INLINE CONST CHAR *ProgramFileName( VOID ) 
			{ return ((CONST CHAR*) ProgramName); };

		STATIC INLINE CONST CHAR *ProgramFilePath( VOID ) 
			{ return ((CONST CHAR*) ProgramPath); };
#endif

	private:
        //
        //   Disabled operations.
        //
        ENVIRONMENT( CONST ENVIRONMENT & Copy );

        VOID operator=( CONST ENVIRONMENT & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\Globallock.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Globallock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new lock and initialize it.  This call is not         */
    /*   thread safe and should only be made in a single thread         */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

GLOBALLOCK::GLOBALLOCK( CHAR *Name,SBIT32 NewMaxUsers )
    {
	//
	//   Set the initial state.
	//
	if ( (Semaphore = CreateSemaphore( NULL,1,NewMaxUsers,Name )) == NULL )
		{ Failure( "Global semaphore rejected by OS" ); } 
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Zero the lock statistics.
	//
    TotalLocks = 0;
    TotalTimeouts = 0;
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Claim the Globallock.                                          */
    /*                                                                  */
    /*   Claim the lock if available else wait or exit.                 */
    /*                                                                  */
    /********************************************************************/

BOOLEAN GLOBALLOCK::ClaimLock( SBIT32 Sleep )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	REGISTER SBIT32 ThreadId = GetThreadId();

	//
	//   We may already own the spin lock.  If so
	//   we increment the recursive count.  If not 
	//   we have to wait.
	//
	if ( Owner != ThreadId )
		{
#endif
		//
		//   Wait for the global lock.
		//
		if 
				( 
				WaitForSingleObject( Semaphore,Sleep ) 
					!= 
				WAIT_OBJECT_0 
				)
			{
			//
			//   We failed to claim the lock due to
			//   a timeout.
			//
#ifdef ENABLE_LOCK_STATISTICS
			(VOID) AtomicIncrement( & TotalTimeouts );

#endif
			return False;
			}
#ifdef ENABLE_RECURSIVE_LOCKS

		//
		//   Register the new owner of the lock.
		//
		NewExclusiveOwner( ThreadId );
		}
	else
		{ Recursive ++; }
#endif
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
	(VOID) AtomicIncrement( & TotalLocks );
#endif

    return True;
    }
#ifdef ENABLE_RECURSIVE_LOCKS

    /********************************************************************/
    /*                                                                  */
    /*   New exclusive owner.                                           */
    /*                                                                  */
    /*   Delete the exclusive lock owner information.                   */
    /*                                                                  */
    /********************************************************************/

VOID GLOBALLOCK::DeleteExclusiveOwner( VOID )
    {
#ifdef DEBUGGING
	if ( Owner != NULL )
		{ 
#endif
		Owner = NULL; 
#ifdef DEBUGGING
		}
	else
		{ Failure( "Globallock has no owner in DeleteExclusiveOwner" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   New exclusive owner.                                           */
    /*                                                                  */
    /*   Register new exclusive lock owner information.                 */
    /*                                                                  */
    /********************************************************************/

VOID GLOBALLOCK::NewExclusiveOwner( SBIT32 NewOwner )
    {
#ifdef DEBUGGING
	if ( Owner == NULL )
		{ 
#endif
		Owner = NewOwner; 
#ifdef DEBUGGING
		}
	else
		{ Failure( "Already exclusive in NewExclusiveOwner" ); }
#endif
    }
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Release the spinlock.                                          */
    /*                                                                  */
    /*   Release the lock and if needed wakeup any sleepers.            */
    /*                                                                  */
    /********************************************************************/

VOID GLOBALLOCK::ReleaseLock( VOID )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	//
	//   When we have recursive lock calls we do not 
	//   release the lock until we have exited to the 
	//   top level.
	//
	if ( Recursive <= 0 )
		{
		//
		//   Delete the exclusive owner information.
		//
		DeleteExclusiveOwner();
#endif
		//
		//   Release the global lock.
		//
		ReleaseSemaphore( Semaphore,1,NULL );
#ifdef ENABLE_RECURSIVE_LOCKS
		}
	else
		{ Recursive --; }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a lock.  This call is not thread safe and should       */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

GLOBALLOCK::~GLOBALLOCK( VOID )
    {
#ifdef ENABLE_LOCK_STATISTICS
	//
	//   Print the lock statistics.
	//
	DebugPrint
		(
		"Globallock : %d locks, %d timeouts.\n"
		TotalLocks,
		TotalTimeouts
		);

#endif
	//
	//   Close the semaphore handle.
	//
    if ( ! CloseHandle( Semaphore ) )
        { Failure( "Close semaphore in destructor for GLOBALLOCK" ); }

	//
	//   Just to be tidy.
	//
	Semaphore = NULL;
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\list.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "List.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new linked list element.                              */
    /*                                                                  */
    /********************************************************************/

LIST::LIST( VOID )
    {
	Forward = NULL;
	Backward = NULL;
#ifdef DEBUGGING
	Head = NULL;
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Delete an element.                                             */
    /*                                                                  */
    /*   Delete the current element.                                    */
    /*                                                                  */
    /********************************************************************/

VOID LIST::Delete( LIST *HeadOfList )
	{
#ifdef DEBUGGING
	if ( Head == HeadOfList )
		{
#endif
		//
		//   Relink the forward chain.
		//
		if ( Forward != NULL )
			{ Forward -> Backward = Backward; }
		else
			{ HeadOfList -> Backward = Backward; }

		//
		//   Relink the backward chain.
		//
		if ( Backward != NULL )
			{ Backward -> Forward = Forward; }
		else
			{ HeadOfList -> Forward = Forward; }

		//
		//   Reset the list elements.
		//
		Forward = NULL;
		Backward = NULL;
#ifdef DEBUGGING
		Head = NULL;
		}
	else
		{ Failure( "No active linked list element in Delete" ); }
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Insert a list element.                                         */
    /*                                                                  */
    /*   Insert a list element at the head of the list.                 */
    /*                                                                  */
    /********************************************************************/

VOID LIST::Insert( LIST *HeadOfList )
	{
#ifdef DEBUGGING
	if ( Head == NULL )
		{
#endif
		//
		//   Insert the new element at the front of the list.
		//
		if ( (Forward = HeadOfList -> Forward) == NULL )
			{ 
			HeadOfList -> Forward = this;
			HeadOfList -> Backward = this; 
			}
		else
			{ 
			HeadOfList -> Forward -> Backward = this; 
			HeadOfList -> Forward = this;
			}

		//
		//   Set the other pointers as needed.
		//
		Backward = NULL;
#ifdef DEBUGGING
		Head = HeadOfList;
		}
	else
		{ Failure( "List element already in use in Insert" ); }
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Insert a list element.                                         */
    /*                                                                  */
    /*   Insert a new list element before the current element.          */
    /*                                                                  */
    /********************************************************************/

VOID LIST::InsertBefore( LIST *HeadOfList,LIST *NewList )
	{
#ifdef DEBUGGING
	if ( NewList -> Head == NULL )
		{
#endif
		if ( HeadOfList -> Forward == NULL )
			{
			//
			//   When the list is empty then add the 
			//   new element at the start of the list.
			//
			HeadOfList -> Forward = NewList;
			HeadOfList -> Backward = NewList;

			NewList -> Forward = NULL;
			NewList -> Backward = NULL;
#ifdef DEBUGGING
			NewList -> Head = HeadOfList;
#endif
			}
		else
			{
#ifdef DEBUGGING
			//
			//   We want to be sure that we consistently 
			//   get the same list head otherwise the list 
			//   may become corrupted.
			//
			if ( Head == HeadOfList )
				{
#endif
				//
				//   If there is a previous element we must
				//   make it point at the new element.  If
				//   not we are the first element in the 
				//   list so update the head.
				//
				if ( Backward != NULL )
					{ Backward -> Forward = NewList; }
				else
					{ HeadOfList -> Forward = NewList; }

				//
				//   Link the new element into the list and
				//   update the current element to point to
				//   it.
				//
				NewList -> Backward = Backward;
				NewList -> Forward = this;
#ifdef DEBUGGING
				NewList -> Head = HeadOfList;
#endif

				Backward = NewList;
				}
#ifdef DEBUGGING
			else
				{ Failure( "No active linked list element in InsertBefore" ); }
			}
		}
	else
		{ Failure( "List element already in use in InsertBefore" ); }
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Insert an element.                                             */
    /*                                                                  */
    /*   Insert a new list element after the current element.           */
    /*                                                                  */
    /********************************************************************/

VOID LIST::InsertAfter( LIST *HeadOfList,LIST *NewList )
	{
#ifdef DEBUGGING
	if ( NewList -> Head == NULL )
		{
#endif
		if ( HeadOfList -> Forward == NULL )
			{
			//
			//   When the list is empty then add the 
			//   new element at the start of the list.
			//
			HeadOfList -> Forward = NewList;
			HeadOfList -> Backward = NewList;

			NewList -> Forward = NULL;
			NewList -> Backward = NULL;
#ifdef DEBUGGING
			NewList -> Head = HeadOfList;
#endif
			}
		else
			{
#ifdef DEBUGGING
			//
			//   We want to be sure that we consistently 
			//   get the same list head otherwise the list 
			//   may become corrupted.
			//
			if ( Head == HeadOfList )
				{
#endif
				//
				//   If there is a next element we must
				//   make it point at the new element.  If
				//   not we are the last element in the 
				//   list so update the head.
				//
				if ( Forward != NULL )
					{ Forward -> Backward = NewList; }
				else
					{ HeadOfList -> Backward = NewList; }

				//
				//   Link the new element into the list and
				//   update the current element to point to
				//   it.
				//
				NewList -> Forward = Forward;
				NewList -> Backward = this;
#ifdef DEBUGGING
				NewList -> Head = HeadOfList;
#endif

				Forward = NewList;
				}
#ifdef DEBUGGING
			else
				{ Failure( "No active linked list element in InsertAfter" ); }
			}
		}
	else
		{ Failure( "List element already in use in InsertAfter" ); }
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Reset a list element.                                          */
    /*                                                                  */
    /*   Reset a list element without any questions.                    */
    /*                                                                  */
    /********************************************************************/

VOID LIST::Reset( VOID )
    {
	Forward = NULL;
	Backward = NULL;
#ifdef DEBUGGING
	Head = NULL;
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a linked list element.                                 */
    /*                                                                  */
    /********************************************************************/

LIST::~LIST( VOID )
    {
	Forward = NULL;
	Backward = NULL;
#ifdef DEBUGGING
	Head = NULL;
#endif
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\lock.hpp ===
#ifndef _LOCKS_HPP_
#define _LOCKS_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Sharelock.hpp"
#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Full lock structure.                                           */
    /*                                                                  */
    /*   This class provides an full locking mechanism for a            */
    /*   collection of higher level classes.                            */
    /*                                                                  */
    /********************************************************************/

class FULL_LOCK
    {
        //
        //   Private data.
        //
		SHARELOCK                     ShareLock;

    public:
        //
        //   Public inline functions.
        //
        FULL_LOCK( VOID )
			{ /* void */ }

        INLINE VOID ClaimExclusiveLock( VOID )
			{ (VOID) ShareLock.ClaimExclusiveLock(); }

        INLINE VOID ClaimSharedLock( VOID )
			{ (VOID) ShareLock.ClaimShareLock(); }

        INLINE VOID ReleaseExclusiveLock( VOID )
			{ (VOID) ShareLock.ReleaseExclusiveLock(); }

		INLINE VOID ReleaseSharedLock( VOID )
			{ (VOID) ShareLock.ReleaseShareLock(); }

        ~FULL_LOCK( VOID )
			{ /* void */ }

	private:
        //
        //   Disabled operations.
        //
        FULL_LOCK( CONST FULL_LOCK & Copy );

        VOID operator=( CONST FULL_LOCK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   No lock structure.                                             */
    /*                                                                  */
    /*   This class provides a default locking mechanism for a          */
    /*   collection of higher level classes.                            */
    /*                                                                  */
    /********************************************************************/

class NO_LOCK
    {
    public:
        //
        //   Public inline functions.
        //
        NO_LOCK( VOID )
			{ /* void */ }

        INLINE VOID ClaimExclusiveLock( VOID )
			{ /* void */ }

        INLINE VOID ClaimSharedLock( VOID )
			{ /* void */ }

        INLINE VOID ReleaseExclusiveLock( VOID )
			{ /* void */ }

		INLINE VOID ReleaseSharedLock( VOID )
 			{ /* void */ }

        ~NO_LOCK( VOID )
			{ /* void */ }

	private:
        //
        //   Disabled operations.
        //
        NO_LOCK( CONST NO_LOCK & Copy );

        VOID operator=( CONST NO_LOCK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Partial lock structure.                                        */
    /*                                                                  */
    /*   This class provides a partial locking mechanism for a          */
    /*   collection of higher level classes.                            */
    /*                                                                  */
    /********************************************************************/

class PARTIAL_LOCK
    {
        //
        // Private structures.
        //
		SPINLOCK                      Spinlock;

    public:
        //
        //   Public inline functions.
        //
        PARTIAL_LOCK( VOID )
			{ /* void */ }

        INLINE VOID ClaimExclusiveLock( VOID )
			{ (VOID) Spinlock.ClaimLock(); }

        INLINE VOID ClaimSharedLock( VOID )
			{ (VOID) Spinlock.ClaimLock(); }

        INLINE VOID ReleaseExclusiveLock( VOID )
			{ (VOID) Spinlock.ReleaseLock(); }

		INLINE VOID ReleaseSharedLock( VOID )
			{ (VOID) Spinlock.ReleaseLock(); }

        ~PARTIAL_LOCK( VOID )
			{ /* void */ }

	private:
        //
        //   Disabled operations.
        //
        PARTIAL_LOCK( CONST PARTIAL_LOCK & Copy );

        VOID operator=( CONST PARTIAL_LOCK & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\hash.hpp ===
#ifndef _HASH_HPP_
#define _HASH_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Include files for inherited classes.                           */
    /*                                                                  */
    /*   The include files for inherited classes are required in the    */
    /*   specification of this class.                                   */
    /*                                                                  */
    /********************************************************************/

#include "Common.hpp"
#include "Lock.hpp"
#include "Stack.hpp"
#include "Vector.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Macros exported from this class.                               */
    /*                                                                  */
    /*   This class has three template parameters so to make it more    */
    /*   readable a macro is specified here to simplify the code.       */
    /*                                                                  */
    /********************************************************************/

#define HASH_TEMPLATE				  class KEY,class TYPE,class LOCK 

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The stack constants specify the initial size of the map.       */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 HashSize				  = 1024;
CONST SBIT32 MinHashFree			  = (100/25);
CONST SBIT32 ValueSize				  = 256;

    /********************************************************************/
    /*                                                                  */
    /*   Hash table.                                                    */
    /*                                                                  */
    /*   This class provides general purpose hash table functions to    */
    /*   safely map sparse integer keys into some pointer or value.     */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE=NO_LOCK> class HASH : public LOCK
    {
        //
        //   Private structures.
        //
        typedef struct
            {
            KEY                       Key;
            SBIT32                    Next;
            TYPE                      Value;
            }
        VALUE;

        //
        //   Private data.
        //
        SBIT32                        MaxHash;
        SBIT32                        MaxValues;
        SBIT32                        ValuesUsed;

		SBIT32						  Active;
        VECTOR<SBIT32>                Hash;
		SBIT32						  HashMask;
		SBIT32						  HashShift;
        STACK<SBIT32>                 FreeStack;
        VECTOR<VALUE>                 Values;

    public:
        //
        //   Public functions.
        //
        HASH
			( 
			SBIT32                    NewMaxHash = HashSize, 
			SBIT32                    NewMaxValues = ValueSize, 
			SBIT32                    Alignment = 1 
			);

        VOID AddToHash( CONST KEY & Key, CONST TYPE & Value );

        VIRTUAL SBIT32 ComputeHashKey( CONST KEY & Key );

		BOOLEAN FindInHash( CONST KEY & Key, TYPE *Value );

		VIRTUAL BOOLEAN MatchingKeys( CONST KEY & Key1, CONST KEY & Key2 );

        VOID RemoveFromHash( CONST KEY & Key );

        ~HASH( VOID );

	private:
        //
        //   Private functions.
        //
		BOOLEAN FindHashKeyValue( CONST KEY & Key, SBIT32 **HashIndex );

		VOID Resize( VOID );

        //
        //   Disabled operations.
        //
        HASH( CONST HASH & Copy );

        VOID operator=( CONST HASH & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new hash and prepare it for use.  This call is        */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> HASH<KEY,TYPE,LOCK>::HASH
		( 
		SBIT32						  NewMaxHash,
		SBIT32                        NewMaxValues,
		SBIT32                        Alignment
		) :
		//
		//   Call the constructors for the contained classes.
		//
		Hash( (COMMON::ForceToPowerOfTwo( NewMaxHash )),1,CacheLineSize ),
		FreeStack( (NewMaxValues / 2) ),
		Values( NewMaxValues,Alignment,CacheLineSize )
    {
    if 
			( 
			(NewMaxHash > 0) 
				&& 
			(
			COMMON::ConvertDivideToShift
				( 
				(COMMON::ForceToPowerOfTwo( NewMaxHash )),
				& HashMask 
				)
			)
				&&
			(NewMaxValues > 0) 
			)
        {
		REGISTER SBIT32 Count;

		//
		//   Setup the hash table size information.
		//
        MaxHash = (COMMON::ForceToPowerOfTwo( NewMaxHash ));
        MaxValues = NewMaxValues;
        ValuesUsed = 0;

		//
		//   Zero the control values compute the
		//   hash table shift values.
		//
		Active = 0;
		HashShift = (32-HashMask);
		HashMask = ((1 << HashMask)-1);

		for( Count=0;Count < MaxHash;Count ++ )
			{ Hash[ Count ] = EndOfList; }
        }
    else
        { Failure( "Max sizes in constructor for HASH" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Add to the hash table.                                         */
    /*                                                                  */
    /*   We add an key to the hash table if it does not already exist.  */
    /*   Then we add (or update) the current value.  If the is not      */
    /*   space we expand the size of the 'Values' table.                */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> VOID HASH<KEY,TYPE,LOCK>::AddToHash
        (
		CONST KEY					  & Key,
        CONST TYPE					  & Value 
        )
    {
	AUTO SBIT32 *HashIndex;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	if ( ! FindHashKeyValue( Key, & HashIndex ) )
		{
		AUTO SBIT32 NewIndex;
		REGISTER VALUE *NewValue;

		//
		//   Extract a free element from the stack.
		//   If the stack is empty then allocated one
		//   from the array.
		//
		if ( ! FreeStack.PopStack( & NewIndex ) )
			{
			//
			//   If the array is full then resize it.
			//   We need to be careful here as a resize
			//   can change the address of the 'Values'
			//   array.
			//
			if ( (NewIndex = ValuesUsed ++) >= MaxValues  )
				{ Values.Resize( (MaxValues *= ExpandStore) ); }
			}

		//
		//   Add the new element into the hash table
		//   and link it into any overflow chains.
		//
		NewValue = & Values[ NewIndex ];

		Active ++;

		//
		//   Link in the new element.
		//
		NewValue -> Key = Key;
		NewValue -> Next = (*HashIndex);
		(*HashIndex) = NewIndex;
		NewValue -> Value = Value;
		}
	else
		{ Values[ (*HashIndex) ].Value = Value; }

	//
	//   If the hash table has grown too big we
	//   resize it.
	//
	if ( (Active + (MaxHash / MinHashFree)) > MaxHash )
		{ Resize(); }

	//
	//   Release any lock we got earlier.
	//
	ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the hash key.                                          */
    /*                                                                  */
    /*   Compute a hash value from the supplied key.                    */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> SBIT32 HASH<KEY,TYPE,LOCK>::ComputeHashKey
        (
		CONST KEY					  & Key
        )
	{
	//
	//   When the key is larger than an integer the we need 
	//   to do a bit more work.
	//
	//if ( sizeof(KEY) > sizeof(SBIT32) )
	//	{
	//	REGISTER SBIT32 HighWord = ((SBIT32) (Key >> 32));
	//	REGISTER SBIT32 LowWord = ((SBIT32) Key);

	//	//
	//	//   We compute the hash key using both the high
	//	//   and low order words.
	//	//
	//	return
	//		(
	//		(HighWord * 2964557531)
	//			+
	//		(LowWord * 2964557531)
	//			+
	//		(HighWord + LowWord)
	//		);
	//	}
	//else
		{ return ((((SBIT32) Key) * 2964557531) + ((SBIT32) Key)); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find a key in the hash table.                                  */
    /*                                                                  */
    /*   Find a key in the hash table and return the associated value.  */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> BOOLEAN HASH<KEY,TYPE,LOCK>::FindInHash
        (
		CONST KEY					  & Key,
        TYPE						  *Value 
        )
    {
	AUTO SBIT32 *Index;
	REGISTER BOOLEAN Result;

	//
	//   Claim an shared lock (if enabled).
	//
    ClaimSharedLock();

	//
	//   Find the key in the hash table.
	//
	if ( (Result = FindHashKeyValue( Key,& Index )) )
		{ (*Value) = Values[ (*Index) ].Value; }

	//
	//   Release any lock we got earlier.
	//
	ReleaseSharedLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Find the hash key value.                                       */
    /*                                                                  */
    /*   Find the value associated with the supplied hash key.          */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> BOOLEAN HASH<KEY,TYPE,LOCK>::FindHashKeyValue
        (
		CONST KEY					  & Key,
		SBIT32                        **Index
        )
	{
	REGISTER SBIT32 *Current;
	REGISTER VALUE *List;

	//
	//   Find the bucket in the hash table that should
	//   contain this key.
	//
	(*Index) = & Hash[ ((ComputeHashKey( Key ) >> HashShift) & HashMask) ];

	//
	//   Walk the overflow chain and look for the key.
	//
	for ( Current = (*Index);(*Current) != EndOfList;Current = & List -> Next )
		{
		List = & Values[ (*Current) ];

		//
		//   If the keys match we are out of here.
		//
		if ( MatchingKeys( Key,List -> Key ) )
			{
			(*Index) = Current;

			return True;
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compare two hask keys.       .                                 */
    /*                                                                  */
    /*   Compare two hash keys to see if they match.                    */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> BOOLEAN HASH<KEY,TYPE,LOCK>::MatchingKeys
        (
		CONST KEY					  & Key1,
		CONST KEY					  & Key2
        )
	{ return (Key1 == Key2); }

    /********************************************************************/
    /*                                                                  */
    /*   Remove a key from the hash table.                              */
    /*                                                                  */
    /*   The supplied key is removed from the hash table (if it exists) */
    /*   and the associated value is deleted.                           */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> VOID HASH<KEY,TYPE,LOCK>::RemoveFromHash
        (
		CONST KEY					  & Key
        )
    {
	AUTO SBIT32 *Index;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   Find the key in the hash table..  If it 
	//   exists then delete it.
	//
	if ( FindHashKeyValue( Key,& Index ) )
		{
		Active --;

		FreeStack.PushStack( (*Index) );

		(*Index) = Values[ (*Index) ].Next;
		}

	//
	//   Release any lock we got earlier.
	//
	ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Resize the hash table.                                         */
    /*                                                                  */
    /*   The hash table is resized if it becomes more than 75% full     */
    /*   and all the keys are rehashed.                                 */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> VOID HASH<KEY,TYPE,LOCK>::Resize( VOID )
    {
	REGISTER SBIT32 Count;
	REGISTER SBIT32 List = EndOfList;

	//
	//   Walk the hash table and link all the active
	//   values into a single linked list.
	//
	for ( Count=0;Count < MaxHash;Count ++ )
		{
		REGISTER SBIT32 Start = Hash[ Count ];

		//
		//   We know that some of the hash buckets may
		//   be empty so we skip these.
		//
		if ( Start != EndOfList )
			{
			REGISTER SBIT32 Last = Start;

			//
			//   Walk along the overflow chain until
			//   we find the end.
			//
			while ( Values[ Last ].Next != EndOfList )
				{ Last = Values[ Last ].Next; }
			
			//
			//   Add the list on the front of the new
			//   global list.
			//   
			Values[ Last ].Next = List;
			List = Start;
			}
		}

	//
	//   Resize the hash table.
	//
	Hash.Resize( (MaxHash *= ExpandStore) );

        if ( COMMON::ConvertDivideToShift( MaxHash,& HashMask ) )
        {
		//
		//   Update the shift values.
		//
		HashShift = (32-HashMask);
		HashMask = ((1 << HashMask)-1);

		//
		//   Zero the resized table.
		//  
		for ( Count=0;Count < MaxHash;Count ++ )
			{ Hash[ Count ] = EndOfList; }
		}
	else
		{ Failure( "Hash size in Resize" ); }

	//
	//   Rehash all the existing values.
	//
	while ( List != EndOfList )
        {
		AUTO SBIT32 *Index;
		REGISTER VALUE *Current = & Values[ List ];
		REGISTER SBIT32 Next = Current -> Next;

		if ( ! FindHashKeyValue( Current -> Key,& Index ) )
			{
			Current -> Next = (*Index);
			(*Index) = List;
			List = Next;
			}
		else
			{ Failure( "Duplicate hash key in Risize" ); }
        }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the hash.  This call is not thread safe and should     */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

template <HASH_TEMPLATE> HASH<KEY,TYPE,LOCK>::~HASH( VOID )
    { /* void */ }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\Globallock.hpp ===
#ifndef _GLOBALLOCK_HPP_
#define _GLOBALLOCK_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Environment.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Global locking.                                                */
    /*                                                                  */
    /*   This class provides a very conservative locking scheme.        */
    /*   The lock claimed is a system-wide global lock shared           */
    /*   between all classes, DLLs and proceses.                        */
    /*                                                                  */
    /********************************************************************/

class GLOBALLOCK : public ENVIRONMENT
    {
        //
        //   Private data.
        //
#ifdef ENABLE_RECURSIVE_LOCKS
		SBIT32						  Owner;
		SBIT32						  Recursive;
#endif
        HANDLE                        Semaphore;
#ifdef ENABLE_LOCK_STATISTICS

        //
        //   Counters for debugging builds.
        //
        VOLATILE SBIT32               TotalLocks;
        VOLATILE SBIT32               TotalTimeouts;
#endif

    public:
        //
        //   Public functions.
        //
        GLOBALLOCK( CHAR *Name = "GlobalLock", SBIT32 NewMaxUsers = 256 );

        BOOLEAN ClaimLock( SBIT32 Sleep = INFINITE );

        VOID ReleaseLock( VOID );

        ~GLOBALLOCK( VOID );

    private:
        //
        //   Private functions.
        //
		VOID DeleteExclusiveOwner( VOID );

		VOID NewExclusiveOwner( SBIT32 NewOwner );
        //
        //   Disabled operations.
        //
        GLOBALLOCK( CONST GLOBALLOCK & Copy );

        VOID operator=( CONST GLOBALLOCK & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\librarypch.hpp ===
#ifndef _LIBRARY_PCH_HPP_
#define _LIBRARY_PCH_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#ifndef DISABLE_PRECOMPILED_HEADERS
#include "Align.hpp"
#include "Assembly.hpp"
#include "Autolock.hpp"
#include "Barrier.hpp"
#include "CallStack.hpp"
#include "Common.hpp"
#include "Delay.hpp"
#include "Dll.hpp"
#include "Environment.hpp"
#include "Global.hpp"
#include "Globallock.hpp"
#include "Hash.hpp"
#include "List.hpp"
#include "Lock.hpp"
#include "Map.hpp"
#include "New.hpp"
#include "Pool.hpp"
#include "Prefetch.hpp"
#include "Queue.hpp"
#include "Sharelock.hpp"
#include "Spinlock.hpp"
#include "Stack.hpp"
#include "Standard.hpp"
#include "String.hpp"
#include "System.hpp"
#include "Thread.hpp"
#include "Tls.hpp"
#include "Unique.hpp"
#include "Vector.hpp"
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\new.hpp ===
#ifndef _NEW_HPP_
#define _NEW_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"
#ifdef ENABLE_GLOBAL_ROCKALL

#include "DefaultHeap.hpp"
#endif

    /********************************************************************/
    /*                                                                  */
    /*   The placement new and delete macros.                           */
    /*                                                                  */
    /*   The placement new and delete macros allow the constructor      */
    /*   and destructos of a type to be called as needed.               */
    /*                                                                  */
    /********************************************************************/

#define PLACEMENT_NEW( Address,Type )		new( Address ) Type
#define PLACEMENT_DELETE( Address,Type )	(((Type*) Address) -> ~Type())
#ifndef DISABLE_GLOBAL_NEW

    /********************************************************************/
    /*                                                                  */
    /*   The memory allocation operator.                                */
    /*                                                                  */
    /*   The memory allocation operator 'new' is overloaded to          */
    /*   provide a consistent interface.                                */
    /*                                                                  */
    /********************************************************************/

INLINE VOID *operator new( size_t Size )
    {
#ifdef ENABLE_GLOBAL_ROCKALL
    REGISTER VOID *Store = DefaultHeap.New( Size );
#else
    REGISTER VOID *Store = malloc( Size );
#endif

    if ( Store == NULL )
        { Failure( "Out of system memory" ); }

    return Store;
    }

    /********************************************************************/
    /*                                                                  */
    /*   The memory deallocation operator.                              */
    /*                                                                  */
    /*   The memory deallocation operator releases allocated memory.    */
    /*                                                                  */
    /********************************************************************/

INLINE VOID operator delete( VOID *Store )
	{
#ifdef ENABLE_GLOBAL_ROCKALL
    DefaultHeap.Delete( Store );
#else
    free( Store );
#endif
	}
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\list.hpp ===
#ifndef _LIST_HPP_
#define _LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A generic linked list.                                         */
    /*                                                                  */
    /*   There are a significant number of situations where objects     */
    /*   need to be linked together.  The objects may be of the same    */
    /*   or diffrent types so the class specified here is intended      */
    /*   to be used as base class so as to make supporting this easy.   */
    /*                                                                  */
    /********************************************************************/

class LIST
    {
		//
		//   Private data.
		//
 		LIST						  *Backward;
 		LIST						  *Forward;
#ifdef DEBUGGING
		LIST						  *Head;
#endif

   public:
        //
        //   Public functions.
        //
        LIST( VOID );

		VOID Delete( LIST *HeadOfList );

		VOID Insert( LIST *HeadOfList );

		VOID InsertBefore( LIST *HeadOfList,LIST *NewList );

		VOID InsertAfter( LIST *HeadOfList,LIST *NewList );

		VOID Reset( VOID );

        ~LIST( VOID );

		//
		//   Public line functions.
		//
		INLINE BOOLEAN StartOfList( VOID )
			{ return (Backward == NULL); }

		INLINE LIST *First( VOID )
			{ return Forward; }

		INLINE LIST *Last( VOID )
			{ return Backward; }

		INLINE LIST *Next( VOID )
			{ return Forward; }

		INLINE LIST *Previous( VOID )
			{ return Backward; }

		INLINE BOOLEAN EndOfList( VOID )
			{ return (Forward == NULL); }

	private:
        //
        //   Disabled operations.
        //
        LIST( CONST LIST & Copy );

        VOID operator=( CONST LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\map.hpp ===
#ifndef _MAP_HPP_
#define _MAP_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Lock.hpp"
#include "Stack.hpp"
#include "Vector.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The map constants specify the initial size of the map.         */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MapSize				  = 128;

    /********************************************************************/
    /*                                                                  */
    /*   Maps and map management.                                       */
    /*                                                                  */
    /*   This class provides general purpose mapping functions to       */
    /*   safely convert handles into some pointer or value.             */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK=NO_LOCK> class MAP : public LOCK
    {
        //
        //   Private structures.
        //
        typedef struct
            {
            BOOLEAN                   Available;
            TYPE                      Value;
            }
        VALUE;

        //
        //   Private data.
        //
        SBIT32                        MaxMap;
        SBIT32                        MapUsed;

        STACK<SBIT32>                 FreeStack;
        VECTOR<VALUE>                 Map;

    public:
        //
        //   Public functions.
        //
        MAP( SBIT32 NewMaxMap = MapSize, SBIT32 Alignment = 1 );

        SBIT32 NewHandle( CONST TYPE & Value );

		BOOLEAN FindHandle
			( 
			SBIT32                        Handle, 
			TYPE                          *Value 
			);

		VOID DeleteHandle( SBIT32 Handle );

        ~MAP( VOID );

		//
		//   Public inline functions.
		//
        INLINE SBIT32 MaxHandles( VOID )
			{ return MapUsed; }

	private:
        //
        //   Disabled operations.
        //
        MAP( CONST MAP & Copy );

        VOID operator=( CONST MAP & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new map and prepare it for use.  This call is         */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> MAP<TYPE,LOCK>::MAP
		( 
		SBIT32						  NewMaxMap,
		SBIT32						  Alignment 
		) :
		//
		//   Call the constructors for the contained classes.
		//
		FreeStack( NewMaxMap ), 
		Map( NewMaxMap,Alignment,CacheLineSize )
    {
#ifdef DEBUGGING
    if ( NewMaxMap > 0 )
        {
#endif
        MaxMap = NewMaxMap;
        MapUsed = 0;
#ifdef DEBUGGING
        }
    else
        { Failure( "Max map size in constructor for MAP" ); }
#endif
    }

	/********************************************************************/
    /*                                                                  */
    /*   Create a new handle.                                           */
    /*                                                                  */
    /*   We create a new handle for the supplied value.                 */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> SBIT32 MAP<TYPE,LOCK>::NewHandle
		( 
		CONST TYPE					  & Value 
		)
    {
	AUTO SBIT32 Handle;
	REGISTER VALUE *NewValue;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   Expand the mapping table if it is too
	//   small be resizing it.
	//
	if ( ! FreeStack.PopStack( & Handle ) )
		{
		if ( (Handle = MapUsed ++) >= MaxMap )
			{ Map.Resize( (MaxMap *= ExpandStore) ); }
		}

	//
	//   Link in the new mapping.
	//
	NewValue = & Map[ Handle ];

	NewValue -> Available = True;
	NewValue -> Value = Value;

	//
	//   Release any lock claimed earlier.
	//
	ReleaseExclusiveLock();

	return Handle;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Find the value associated with a handle.                       */
    /*                                                                  */
    /*   We find the value associated with the supplied handle.         */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN MAP<TYPE,LOCK>::FindHandle
        ( 
        SBIT32                        Handle, 
        TYPE                          *Value 
        )
    {
	REGISTER BOOLEAN Result;

	//
	//   Claim a shared lock (if enabled).
	//
    ClaimSharedLock();

	//
	//   Find the handle and return the associated value.
	//
	Result = 
		( 
		((Handle >= 0) && (Handle < MaxMap))
			&& 
		(Map[ Handle ].Available) 
		);

	if ( Result )
		{ (*Value) = Map[ Handle ].Value; }

	//
	//   Release any lock claimed earlier.
	//
	ReleaseSharedLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Delete a handle.                                               */
    /*                                                                  */
    /*   We delete the supplied handle and the associated value.        */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID MAP<TYPE,LOCK>::DeleteHandle
		( 
        SBIT32                        Handle
		)
    {
	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   If the handle is valid then delete any
	//   associated value.
	//
	if ( (Handle >= 0) && (Handle < MaxMap) && (Map[ Handle ].Available) )
		{
		Map[ Handle ].Available = False;
		FreeStack.PushStack( Handle );
		}
	else
		{ Failure( "No mapping in DeleteMapHandle()" ); } 

	//
	//   Release any lock claimed earlier.
	//
	ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the map.  This call is not thread safe and should      */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> MAP<TYPE,LOCK>::~MAP( VOID )
    { /* void */ }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\prefetch.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Prefetch.hpp"
#ifdef ASSEMBLY_X86

    /********************************************************************/
    /*                                                                  */
    /*   Static member initialization.                                  */
    /*                                                                  */
    /*   Static member initialization sets the initial value for all    */
    /*   static members.                                                */
    /*                                                                  */
    /********************************************************************/

#pragma init_seg(lib)
BOOLEAN PREFETCH::Active =
	(
	(BOOLEAN) IsProcessorFeaturePresent
		( 
		PF_XMMI_INSTRUCTIONS_AVAILABLE
		)
	);
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\prefetch.hpp ===
#ifndef _PREFETCH_HPP_
#define _PREFETCH_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Assembly.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Prefetch a cache line.				                            */
    /*                                                                  */
    /*   Support of data prefetch on the Pentium III or better.         */
    /*                                                                  */
    /********************************************************************/

class PREFETCH : public ASSEMBLY
    {
#ifdef ASSEMBLY_X86
        //
        //   Static private data.
        //
        STATIC BOOLEAN		          Active;

#endif
    public:
        //
        //   Public inline functions.
        //
        PREFETCH( VOID )
			{ /* void */ }

		STATIC INLINE VOID L1( CHAR *Address,SBIT32 Size );

		STATIC INLINE VOID L2( CHAR *Address,SBIT32 Size );

		STATIC INLINE VOID L3( CHAR *Address,SBIT32 Size );

		STATIC INLINE VOID Nta( CHAR *Address,SBIT32 Size );

        ~PREFETCH( VOID )
			{ /* void */ }

	private:
        //
        //   Disabled operations.
        //
        PREFETCH( CONST PREFETCH & Copy );

        VOID operator=( CONST PREFETCH & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Prefetch to the L1.                                            */
    /*                                                                  */
    /*   Prefetch an area of memory to the L1 cache if the processor    */
    /*   supports this feature.                                         */
    /*                                                                  */
    /********************************************************************/

VOID PREFETCH::L1( CHAR *Address,SBIT32 Size )
	{
#ifdef ASSEMBLY_X86
	//
	//   We ensure the processor has prefetch functionality
	//   otherwise the instruction will fail.
	//
	if ( Active )
		{
		//
		//   We execute a prefetch for each cache line
		//   (which assumes things are alignment).
		//
		for 
				( 
				/* void */;
				Size > 0;
				Address += CacheLineSize, Size -= CacheLineSize 
				)
			{ PrefetchL1( Address ); }
		}
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Prefetch to the L2.                                            */
    /*                                                                  */
    /*   Prefetch an area of memory to the L2 cache if the processor    */
    /*   supports this feature.                                         */
    /*                                                                  */
    /********************************************************************/

VOID PREFETCH::L2( CHAR *Address,SBIT32 Size )
	{
#ifdef ASSEMBLY_X86
	//
	//   We ensure the processor has prefetch functionality
	//   otherwise the instruction will fail.
	//
	if ( Active )
		{
		//
		//   We execute a prefetch for each cache line
		//   (which assumes things are alignment).
		//
		for 
				( 
				/* void */;
				Size > 0;
				Address += CacheLineSize, Size -= CacheLineSize 
				)
			{ PrefetchL2( Address ); }
		}
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Prefetch to the L3.                                            */
    /*                                                                  */
    /*   Prefetch an area of memory to the L3 cache if the processor    */
    /*   supports this feature.                                         */
    /*                                                                  */
    /********************************************************************/

VOID PREFETCH::L3( CHAR *Address,SBIT32 Size )
	{
#ifdef ASSEMBLY_X86
	//
	//   We ensure the processor has prefetch functionality
	//   otherwise the instruction will fail.
	//
	if ( Active )
		{
		//
		//   We execute a prefetch for each cache line
		//   (which assumes things are alignment).
		//
		for 
				( 
				/* void */;
				Size > 0;
				Address += CacheLineSize, Size -= CacheLineSize 
				)
			{ PrefetchL3( Address ); }
		}
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Prefetch to the L1.                                            */
    /*                                                                  */
    /*   Prefetch an area of memory to the L1 cache if the processor    */
    /*   supports this feature.                                         */
    /*                                                                  */
    /********************************************************************/

VOID PREFETCH::Nta( CHAR *Address,SBIT32 Size )
	{
#ifdef ASSEMBLY_X86
	//
	//   We ensure the processor has prefetch functionality
	//   otherwise the instruction will fail.
	//
	if ( Active )
		{
		//
		//   We execute a prefetch for each cache line
		//   (which assumes things are alignment).
		//
		for 
				( 
				/* void */;
				Size > 0;
				Address += CacheLineSize, Size -= CacheLineSize 
				)
			{ PrefetchNta( Address ); }
		}
#endif
	}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\pool.hpp ===
#ifndef _POOL_HPP_
#define _POOL_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Delay.hpp"
#include "Lock.hpp"
#include "New.hpp"
#include "Stack.hpp"
#include "Vector.hpp"
  
    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The server constants specify the size of the server queue      */
    /*   per processor stacks.                                          */
    /*                                                                  */
    /********************************************************************/

CONST SBIT16 MinPoolSize			  = 64;
CONST SBIT16 PoolStackSize			  = 32;

    /********************************************************************/
    /*                                                                  */
    /*   Pools and pool management.                                     */
    /*                                                                  */
    /*   This class provides general purpose memory pool along with     */
    /*   basic management.  The pools are optimized for very high       */
    /*   performance on SMP systems (although this calls does not       */
    /*   perform the actual locking.  Whenever possible multiple        */
    /*   items should allocated and deallocated at the same time.       */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK=NO_LOCK> class POOL : public LOCK
    {
		//
		//   Private type definitions.
		//
		typedef struct { CHAR TypeSize[sizeof(TYPE)]; } TYPE_SIZE;

        //
        //   Private data.
        //
		SBIT32                        MaxSize;
		SBIT32                        MinSize;

        DELAY< VECTOR<TYPE_SIZE> >    Delay;
		STACK<POINTER>				  Stack;

    public:
        //
        //   Public functions.
        //
        POOL( SBIT32 NewMinSize = MinPoolSize );

        TYPE **MultiplePopPool
            ( 
            SBIT32                        Requested, 
            SBIT32                        *Size 
            );

        VOID MultiplePushPool
            ( 
            CONST TYPE					  *Type[], 
            CONST SBIT32				  Size 
            );

        TYPE *PopPool( VOID );

        VOID PushPool( CONST TYPE *Type );

        ~POOL( VOID );

	private:
		//
		//   Private functions.
		//
		VOID ExpandSize( SBIT32 MaxSize );

        //
        //   Disabled operations.
        //
        POOL( CONST POOL & Copy );

        VOID operator=( CONST POOL & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new pool and prepare it for use.  This call is        */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> POOL<TYPE,LOCK>::POOL( SBIT32 NewMinSize ) : 
		//
		//   Call the constructors for the contained classes.
		//
		Stack( NewMinSize )
    {
#ifdef DEBUGGING
    if ( NewMinSize > 0 )
        {
#endif
		//
		//   We need to keep a note of the amount of elements 
		//   we have allocated so far.
		//
        MaxSize = 0;
        MinSize = NewMinSize;
#ifdef DEBUGGING
        }
    else
        { Failure( "Min size in constructor for POOL" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Expand size.                                                   */
    /*                                                                  */
    /*   Expand the current memory allocation.  This call is not        */
    /*   thread safe and should only be made in a single thread         */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID POOL<TYPE,LOCK>::ExpandSize
		( 
		SBIT32						  NewSize 
		)
    {
	REGISTER SBIT32 Count1;
	REGISTER SBIT32 Count2;
	REGISTER SBIT32 ActualSize =
		((NewSize <= MinSize) ? MinSize : NewSize);
	REGISTER VECTOR<TYPE> *NewBlock =
		(
		(VECTOR<TYPE>*) new VECTOR<TYPE_SIZE>
			( 
			ActualSize, 
			CacheLineSize,
			CacheLineSize
			)
		);

	//
	//   We need to keep a note of the number of elements 
	//   we have allocated thus far.
	//
    MaxSize += ActualSize;

	//
	//   We put the address of each element we allocate on
	//   a stack to enable high speed allocation and 
	//   deallocation.
	//
    for 
			( 
			Count1 = 0;
			Count1 < ActualSize;
			Count1 += PoolStackSize 
			)
        {
		AUTO POINTER NewCalls[ PoolStackSize ];

		//
		//   We add elements to the stack in blocks
		//   to reduce the number of call to the
		//   stack code.
		//
        for 
				( 
				Count2 = 0;
				((Count1 + Count2) < ActualSize)
					&&
				(Count2 < PoolStackSize);
				Count2 ++ 
				)
            {
			REGISTER TYPE *NewCall =
				(
                & (*NewBlock)[ (Count1 + Count2) ]
				);
                 
            NewCalls[ Count2 ] = (POINTER) NewCall;
            }

		//
		//   Add the next block for free work packets to
		//   the global free stack.
		//
        Stack.MultiplePushStack
            ( 
            NewCalls,
            Count2 
            );
        }

    //
    //   Add the newly allocated block to the list of
    //   things to be deleted when this class is deleted.
    //
    Delay.DeferedDelete( ((VECTOR<TYPE_SIZE>*) NewBlock) );
    }

    /********************************************************************/
    /*                                                                  */
    /*   Remove multiple items from the pool.                           */
    /*                                                                  */
    /*   We allocate a multiple elements from the allocation pool.      */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> INLINE TYPE **POOL<TYPE,LOCK>::MultiplePopPool
        ( 
        SBIT32                        Requested, 
        SBIT32                        *Size 
        )
    {
	AUTO TYPE *Type[ PoolStackSize ];
	REGISTER SBIT32 Count;

	//
	//   Compute the actual request size.
	//
	Requested = ((Requested <= PoolStackSize) ? Requested : PoolStackSize);

	//
	//   Claim an exclisive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   Extract as may elements from the stack as possible.
	//   If the stack is empty then allocate more.
	//
	while ( ! Stack.MultiplePopStack( Requested,(POINTER*) Type,Size ) )
		{ ExpandSize( MaxSize ); }

	//
	//   Release and lock we claimed earlier.
	//
    ReleaseExclusiveLock();

	//
	//   Call the constructors.
	//
	for ( Count=0;Count < (*Size); Count ++ )
		{ (VOID) PLACEMENT_NEW( NewPool[ Count ], TYPE ); }

	return Type;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Add multiple items to the pool.                                */
    /*                                                                  */
    /*   We push multiple existing elements into the pool for reuse.    */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> INLINE VOID POOL<TYPE,LOCK>::MultiplePushPool
        ( 
        CONST TYPE					  *Type[],
        CONST SBIT32				  Size 
        )
	{
	REGISTER SBIT32 Count;
	
	//
	//   Call the destructors.
	//
	for ( Count=(Size - 1);Count >= 0; Count -- )
		{ PLACEMENT_DELETE( Type[ Count ],TYPE ); }


	//
	//   Claim an exclisive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   Push the elements back onto the free stack.
	//
	Stack.MultiplePushStack( (POINTER*) Type,Size ); 

	//
	//   Release and lock we claimed earlier.
	//
    ReleaseExclusiveLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   Remove a single item from the pool.                            */
    /*                                                                  */
    /*   We allocate a new element from the allocation pool.            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> INLINE TYPE *POOL<TYPE,LOCK>::PopPool( VOID )
    {
	AUTO TYPE *Type;

	//
	//   Claim an exclisive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   We pop an element off the stack if the
	//   stack is empty we create more elements.
	//
	while ( ! Stack.PopStack( (POINTER*) & Type ) )
		{ ExpandSize( MaxSize ); }

	//
	//   Release and lock we claimed earlier.
	//
    ReleaseExclusiveLock();

	//
	//   Call the constructor.
	//
	(VOID) PLACEMENT_NEW( Type, TYPE );

	return Type;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Add a single item to the pool.                                 */
    /*                                                                  */
    /*   We push an existing element into the pool for reuse.           */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> INLINE VOID POOL<TYPE,LOCK>::PushPool
		( 
		CONST TYPE					  *Type 
		)
	{
	//
	//   Call the destructor.
	//
	PLACEMENT_DELETE( Type,TYPE );

	//
	//   Claim an exclisive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   Push the element back onto the free stack.
	//
	Stack.PushStack( (POINTER) Type );

	//
	//   Release and lock we claimed earlier.
	//
    ReleaseExclusiveLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the stack.  This call is not thread safe and should    */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> POOL<TYPE,LOCK>::~POOL( VOID )
    { /* void */ }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\queue.hpp ===
#ifndef _QUEUE_HPP_
#define _QUEUE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Common.hpp"
#include "Lock.hpp"
#include "Vector.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The queue constants specify the initial size of the queue.     */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 QueueSize				  = 1024;

    /********************************************************************/
    /*                                                                  */
    /*   Queues and queue management.                                   */
    /*                                                                  */
    /*   This class provides general purpose queues along with some     */
    /*   basic management.  The queues are optimized for very high      */
    /*   performance on SMP systems.  Whenever possible multiple        */
    /*   items should added and removed from a queue at the same time.  */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK=NO_LOCK> class QUEUE : public COMMON, public LOCK
    {
        //
        //   Private data.
        //
        SBIT32						  MaxSize;

		BOOLEAN						  Align;
        SBIT32						  Mask;

        SBIT32						  Back;
        SBIT32						  Front;

        VECTOR<TYPE>                  Queue;

    public:
        //
        //   Public functions.
        //
        QUEUE( SBIT32 NewMaxSize = QueueSize,BOOLEAN NewAlign = True );

        BOOLEAN MultiplePopBackOfQueue
            ( 
            SBIT32					  Requested, 
            TYPE					  Data[], 
            SBIT32					  *Size 
            );

        BOOLEAN MultiplePopFrontOfQueue
            ( 
            SBIT32					  Requested, 
            TYPE					  Data[], 
            SBIT32					  *Size 
            );

        VOID MultiplePushBackOfQueue
            ( 
            CONST TYPE				  Data[], 
            CONST SBIT32			  Size 
            );

        VOID MultiplePushFrontOfQueue
            ( 
            CONST TYPE				  Data[], 
            CONST SBIT32			  Size 
            );

        BOOLEAN PeekBackOfQueue( TYPE *Data );

        BOOLEAN PeekFrontOfQueue( TYPE *Data );

        BOOLEAN PopBackOfQueue( TYPE *Data );

        BOOLEAN PopFrontOfQueue( TYPE *Data );

        VOID PushBackOfQueue( CONST TYPE & Data );

        VOID PushFrontOfQueue( CONST TYPE & Data );

		SBIT32 SizeOfQueue( VOID );

        ~QUEUE( VOID );

		//
		//   Public inline functions.
		//
        INLINE BOOLEAN MultiplePopQueue
				( 
				SBIT32				  Requested, 
				TYPE				  Data[], 
				SBIT32				  *Size 
				)
			{ return MultiplePopFrontOfQueue( Requested,Data,Size ); }

        INLINE VOID MultiplePushQueue
				( 
				CONST TYPE			  Data[], 
				CONST SBIT32		  Size 
				)
			{ MultiplePushBackOfQueue( Data,Size ); }

        INLINE BOOLEAN PeekQueue( TYPE *Data )
			{ return PeekFrontOfQueue( Data ); }

        INLINE BOOLEAN PopQueue( TYPE *Data )
			{ return PopFrontOfQueue( Data ); }

        INLINE VOID PushQueue( CONST TYPE & Data )
			{ PushBackOfQueue( Data ); }

	private:
		//
		//   Private functions.
		//
		VOID ExpandQueue( VOID );

        //
        //   Disabled operations.
        //
        QUEUE( CONST QUEUE & Copy );

        VOID operator=( CONST QUEUE & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new queue and prepare it for use.  This call is       */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> QUEUE<TYPE,LOCK>::QUEUE
		( 
		SBIT32						  NewMaxSize,
		BOOLEAN						  NewAlign 
		) : 
		//
		//   Call the constructors for the contained classes.
		//
		Queue( NewMaxSize,1,CacheLineSize )
    {
#ifdef DEBUGGING
    if ( NewMaxSize > 0 )
        {
#endif
		//
		//   Setup the control information.
		//
        MaxSize = NewMaxSize;

		Align = NewAlign;
        Mask = 0x7fffffff;

		//
		//   Setup the queue so it is empty.
		//
        Back = 0;
        Front = 0;

		//
		//   Compute the alignment mask.
		//
		if 
				(
				((sizeof(TYPE) > 0) && (sizeof(TYPE) <= CacheLineSize))
					&&
				(PowerOfTwo( sizeof(TYPE) ))
				)
			{ Mask = ((CacheLineSize / sizeof(TYPE))-1); }
#ifdef DEBUGGING
        }
    else
        { Failure( "Size in constructor for QUEUE" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Expand a queue.                                                */
    /*                                                                  */
    /*   When a queue becomes full we need to expand it and to copy     */
    /*   the tail end of the queue into the correct place.              */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID QUEUE<TYPE,LOCK>::ExpandQueue( VOID )
    {
    REGISTER SBIT32 Count;
    REGISTER SBIT32 NewSize = (MaxSize * ExpandStore);

	//
	//   Expand the queue (it will be at least doubled).
	//
    Queue.Resize( NewSize );

	//
	//   Copy the tail end of the queue to the correct
	//   place in the expanded queue.
	//
    for ( Count = 0;Count < Back;Count ++ )
        { Queue[ (MaxSize + Count) ] = Queue[ Count ]; }

	//
	//   Update the control information.
	//
    Back += MaxSize;
    MaxSize = NewSize;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Pop multiple items from the back of the queue.                 */
    /*                                                                  */
    /*   We remove multiple items from a queue and check to make sure   */
    /*   that the queue has not wrapped.                                */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN QUEUE<TYPE,LOCK>::MultiplePopBackOfQueue
        ( 
        SBIT32                        Requested, 
        TYPE                          Data[], 
        SBIT32                        *Size 
        )
    {
    REGISTER BOOLEAN Result;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

    //
    //   When running on SMP hardware it is very important 
	//   to prevent multiple CPU fighting over the same memory.  
	//   Most systems prevent multiple CPUs accessing a cache  
	//   line at the same time.  Here we modify the request  
	//   to pop exactly the correct number of items to leave  
	//   us on a cache line boundary. 
    //
    if ( Align )
        {
        REGISTER SBIT32 Spare = (Back & Mask);

		if ( Requested > Spare )
			{
			Requested -= Spare;
			Requested &= ~Mask;
			Requested += Spare;
			}
        }

	//
	//   If there is enough elements in the current queue
	//   to extract without wrapping then just do a straight 
	//   copy.
	//
    if 
            ( 
            ((Front <= Back) && (Front <= (Back - Requested))) 
                || 
            ((Front > Back) && ((Back - Requested) >= 0)) 
            )
        {
        REGISTER SBIT32 Count;

        //
        //   We have verified that it is safe to remove all  
        //   the requested elements with a straight copy.
        //
        for ( Count = 0;Count < Requested;Count ++ )
            { Data[ Count ] = Queue[ -- Back ]; }

        (*Size) = Requested;

		Result = True;
		}
    else
        {
        REGISTER SBIT32 Count;

        //
        //   It is not safe to remove all the elements from 
        //   the array.  Hence, I must remove them one at a 
		//   time.  This is tedious but should only happen 
		//   occasionally.
        //
        for ( Count=0,(*Size)=0;Count < Requested;Count ++,(*Size) ++ )
            {
            if ( Front != Back )
                {
                //
                //   We have found an element so return it 
				//   to the caller.  However, lets we need  
				//   to be careful about wrapping.
                //
				 if ( Back <= 0 )
					{ Back = MaxSize; }

                Data[ Count ] = Queue[ -- Back ];
                }
            else
                {
                //
                //  We are out of queue elements so lets exit.  
				//  However, we only return 'False' if we didn't 
				//  find any elements at all.
                //
				Result = (Count != 0);

                break;
                }
            }
        }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

    return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Pop multiple items from the front of the queue.                */
    /*                                                                  */
    /*   We remove multiple items from a queue and check to make sure   */
    /*   that the queue has not wrapped.                                */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN QUEUE<TYPE,LOCK>::MultiplePopFrontOfQueue
        ( 
        SBIT32                        Requested, 
        TYPE                          Data[], 
        SBIT32                        *Size 
        )
    {
    REGISTER BOOLEAN Result;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

    //
    //   When running on SMP hardware it is very important 
	//   to prevent multiple CPU fighting over the same memory.  
	//   Most systems prevent multiple CPUs accessing cache  
	//   lines at the same time.  Here we modify the request  
	//   to access exactly the correct number of items to leave  
	//   us on a cache line boundary. 
    //
    if ( Align )
        {
        REGISTER SBIT32 Spare = ((Mask + 1) - (Front & Mask));

		if ( Requested > Spare )
			{
			Requested -= Spare;
			Requested &= ~Mask;
			Requested += Spare;
			}
        }

	//
	//   If there is enough elements in the current queue
	//   to extract without wrapping then just do a straight 
	//   copy.
	//
    if 
            ( 
            ((Front <= Back) && ((Front + Requested) <= Back)) 
                || 
            ((Front > Back) && ((Front + Requested) < MaxSize)) 
            )
        {
        REGISTER SBIT32 Count;

        //
        //   We have verified that it is safe to remove all  
        //   the requested elements with a straight copy.
        //
        for ( Count = 0;Count < Requested;Count ++ )
            { Data[ Count ] = Queue[ Front ++ ]; }

        (*Size) = Requested;

		Result = True;
		}
    else
        {
        REGISTER SBIT32 Count;
        //
        //   It is not safe to remove all the elements from 
        //   the array.  Hence, I must remove them one at a 
		//   time.  This is tedious but should only happen 
		//   occasionally.
        //
        for ( Count=0,(*Size)=0;Count < Requested;Count ++,(*Size) ++ )
            {
            if ( Front != Back )
                {
                //
                //   We have found an element so return it 
				//   to the caller.  However, lets we need  
				//   to be careful about wrapping.
                //
                Data[ Count ] = Queue[ Front ++ ];

                if ( Front >= MaxSize )
                    { Front = 0; }
                }
            else
                {
                //
                //  We are out of queue elements so lets exit.  
				//  However, we only return 'False' if we didn't 
				//  find any elements at all.
                //
				Result = (Count != 0);

                break;
                }
            }
        }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

    return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Push multiple items onto the back of the queue.                */
    /*                                                                  */
    /*   We add multiple items to a queue and check to make sure that   */
    /*   the queue has not overflowed.  If the queue has overflowed     */
    /*   we double its size.                                            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID QUEUE<TYPE,LOCK>::MultiplePushBackOfQueue
        ( 
        CONST TYPE					  Data[],
        CONST SBIT32				  Size 
        )
    {
	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   If there is enough space in the current queue
	//   for the new elements without wrapping then
	//   just do a straight copy.
	//
    if 
            ( 
            ((Front <= Back) && ((Back + Size) < MaxSize)) 
                || 
            ((Front > Back) && (Front > (Back + Size))) 
            )
        {
        REGISTER SBIT32 Count;

        //
        //   We have verified that it is safe to copy 
        //   all the new elements on to the end of the 
		//   array.  So lets do it and then we can exit. 
        //
        for ( Count = 0;Count < Size;Count ++ )
            { Queue[ Back ++ ] = Data[ Count ]; }
        }
    else
        {
        REGISTER SBIT32 Count;

        //
        //   It is not safe to add the new elements to 
		//   the end of the array so add them one at a 
		//   time.  This is tedious but should only happen 
		//   occasionally.
        //
        for ( Count=0;Count < Size;Count ++ )
            {
            //
            //   Add element to the queue.  If necessary  
            //   wrap round to the front of the array.
            //
            Queue[ Back ++ ] = Data[ Count ];

             if ( Back >= MaxSize )
                { Back = 0; }

            //
            //   Verify that the queue is not full.  If 
			//   it is full then double its size and  
			//   copy wrapped data to the correct position 
			//   in the new array.
            //
            if ( Front == Back )
				{ ExpandQueue(); }
            }
        }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Push multiple items onto the front of the queue.               */
    /*                                                                  */
    /*   We add multiple items to a queue and check to make sure that   */
    /*   the queue has not overflowed.  If the queue has overflowed     */
    /*   we double its size.                                            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID QUEUE<TYPE,LOCK>::MultiplePushFrontOfQueue
        ( 
        CONST TYPE					  Data[],
        CONST SBIT32				  Size 
        )
    {
	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   If there is enough space in the current queue
	//   for the new elements without wrapping then
	//   just do a straight copy.
	//
    if 
            ( 
            ((Front <= Back) && ((Front - Size) >= 0)) 
                || 
            ((Front > Back) && ((Front - Size) > Back)) 
            )
        {
        REGISTER SBIT32 Count;

        //
        //   We have verified that it is safe to copy 
        //   all the new elements on to the end of the 
		//   array.  So lets do it and then we can exit. 
        //
        for ( Count = 0;Count < Size;Count ++ )
            { Queue[ -- Front ] = Data[ Count ]; }
        }
    else
        {
        REGISTER SBIT32 Count;

        //
        //   It is not safe to add the new elements to 
		//   the end of the array so add them one at a 
		//   time.  This is tedious but should only happen 
		//   occasionally.
        //
        for ( Count = 0;Count < Size;Count ++ )
            {
            //
            //   Add element to the queue.  If necessary  
            //   wrap round to the back of the array.
            //
			 if ( Front <= 0 )
				{ Front = MaxSize; }

			Queue[ -- Front ] = Data[ Count ];

            //
            //   Verify that the queue is not full.  If 
			//   it is full then double its size and  
			//   copy wrapped data to the correct position 
			//   in the new array.
            //
            if ( Front == Back )
				{ ExpandQueue(); }
            }
        }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Peek the back of the queue.                                    */
    /*                                                                  */
    /*   We return the end of the queue but check to make sure          */
    /*   that the queue is not empty.                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN QUEUE<TYPE,LOCK>::PeekBackOfQueue
		( 
		TYPE						  *Data 
		)
    {
    REGISTER BOOLEAN Result;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   If the queue contains at least one element then
	//   return a copy of the last element.
	//
    if ( Front != Back )
		{
		//
		//   The 'Back' index points at the next free cell.
		//   So the last element is 'Back - 1'.  However,
		//   when 'Back' is zero we need to wrap.
		//
		if ( Back > 0 )
			{ (*Data) = Queue[ (Back - 1) ]; }
		else
			{ (*Data) = Queue[ (MaxSize - 1) ]; }
	
		Result = True;
		}
    else
        { Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

    return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Peek the front of the queue.                                   */
    /*                                                                  */
    /*   We return the front of the queue but check to make sure        */
    /*   that the queue is not empty.                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN QUEUE<TYPE,LOCK>::PeekFrontOfQueue
		( 
		TYPE						  *Data 
		)
    {
    REGISTER BOOLEAN Result;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   If the queue contains at least one element then
	//   return a copy of the first element.
	//
    if ( Front != Back )
		{ 
		(*Data) = Queue[ Front ];
		
		Result = True;
		}
    else
        { Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

    return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Pop an item from the back of the queue.                        */
    /*                                                                  */
    /*   We remove a single item from a queue and check to make sure    */
    /*   that the queue has not wrapped.                                */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN QUEUE<TYPE,LOCK>::PopBackOfQueue
		( 
		TYPE						  *Data 
		)
    {
    REGISTER BOOLEAN Result;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   We make sure the queue is not empty.
	//
    if ( Front != Back )
        {
        //
        //   We have found an element so return it to 
		//   the caller.  If we walk off the end of the 
		//   queue then wrap to the other end.
        //
         if ( Back <= 0 )
            { Back = MaxSize; }

       (*Data) = Queue[ -- Back ];

		Result = True;
        }
    else
        { Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

    return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Pop an item from the front of the queue.                       */
    /*                                                                  */
    /*   We remove a single item from a queue and check to make sure    */
    /*   that the queue has not wrapped.                                */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN QUEUE<TYPE,LOCK>::PopFrontOfQueue
		( 
		TYPE						  *Data 
		)
    {
    REGISTER BOOLEAN Result;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   We make sure the queue is not empty.
	//
    if ( Front != Back )
        {
        //
        //   We have found an element so return it to 
		//   the caller.  If we walk off the end of the 
		//   queue then wrap to the other end.
        //
        (*Data) = Queue[ Front ++ ];

        if ( Front >= MaxSize )
            { Front = 0; }

		Result = True;
        }
    else
        { Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

    return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Push an item onto the back of the queue.                       */
    /*                                                                  */
    /*   We add a single item to a queue and check to make sure that    */
    /*   the queue has not overflowed.  If the queue has overflowed     */
    /*   we double its size.                                            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID QUEUE<TYPE,LOCK>::PushBackOfQueue
		( 
		CONST TYPE					  & Data 
		)
    {
	//
	//   Claim an exclisive lock (if enabled).
	//
    ClaimExclusiveLock();

    //
    //   Add element to the queue.  If necessary wrap round 
    //   to the front of the array.
    //
    Queue[ Back ++ ] = Data;

     if ( Back >= MaxSize )
        { Back = 0; }

    //
    //   Verify that the queue is not full.  If it is full then 
    //   double its size and copy wrapped data to the correct
    //   position in the new array.
    //
    if ( Front == Back )
		{ ExpandQueue(); }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Push an item onto the front of the queue.                      */
    /*                                                                  */
    /*   We add a single item to a queue and check to make sure that    */
    /*   the queue has not overflowed.  If the queue has overflowed     */
    /*   we double its size.                                            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID QUEUE<TYPE,LOCK>::PushFrontOfQueue
		( 
		CONST TYPE					  & Data 
		)
    {
	//
	//   Claim an exclisive lock (if enabled).
	//
    ClaimExclusiveLock();

    //
    //   Add element to the queue.  If necessary wrap round 
    //   to the back of the array.
    //
     if ( Front <= 0 )
        { Front = MaxSize; }

    Queue[ -- Front ] = Data;

    //
    //   Verify that the queue is not full.  If it is full then 
    //   double its size and copy wrapped data to the correct
    //   position in the new array.
    //
    if ( Front == Back )
		{ ExpandQueue(); }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Calculate the size of the queue.                               */
    /*                                                                  */
    /*   Calculate the size of the queue and return it to the caller.   */
    /*   This is only used when the size is needed in all other cases   */
    /*   we just try to remove the elements in the queue.               */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> SBIT32 QUEUE<TYPE,LOCK>::SizeOfQueue( VOID )
    {
    REGISTER SBIT32 Size;

	//
	//   Claim a shared lock (if enabled).
	//
    ClaimSharedLock();

	//
	//   Compute the size of the queue.
	//
	Size = (Back - Front);

	if ( Size < 0 )
		{ Size += MaxSize; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseSharedLock();

    return Size;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a queue.  This call is not thread safe and should      */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> QUEUE<TYPE,LOCK>::~QUEUE( VOID )
    { /* void */ }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\sharelock.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Sharelock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The Windows NT kernel requires a maximum wakeup count when     */
    /*   creating a semaphore.                                          */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MaxShareLockUsers		  = 256;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new lock and initialize it.  This call is not         */
    /*   thread safe and should only be made in a single thread         */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

SHARELOCK::SHARELOCK( SBIT32 NewMaxSpins, SBIT32 NewMaxUsers )
    {
	//
	//   Set the initial state.
	//
	ExclusiveUsers = 0;
	TotalUsers = 0;

	NormalSemaphore = NULL;
    NormalWaiting = 0;
	PrioritySemaphore = NULL;
    PriorityWaiting = 0;

#ifdef ENABLE_RECURSIVE_LOCKS
	Owner = NULL;
	Recursive = 0;

#endif
	//
	//   Check the configurable values.
	//
	if ( NewMaxSpins > 0 )
		{ MaxSpins = NewMaxSpins; }
	else
		{ Failure( "Maximum spins invalid in constructor for SHARELOCK" ); }

	if ( (NewMaxUsers > 0) && (NewMaxUsers <= MaxShareLockUsers) )
		{ MaxUsers = NewMaxUsers; }
	else
		{ Failure( "Maximum share invalid in constructor for SHARELOCK" ); }
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Zero the statistics.
	//
    TotalExclusiveLocks = 0;
    TotalShareLocks = 0;
    TotalSleeps = 0;
    TotalSpins = 0;
    TotalTimeouts = 0;
    TotalWaits = 0;
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Sleep waiting for the lock.                                    */
    /*                                                                  */
    /*   We have decided it is time to sleep waiting for the lock       */
    /*   to become free.                                                */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SHARELOCK::SleepWaitingForLock
		( 
		HANDLE						  *Semaphore,
		SBIT32						  Sleep,
		VOLATILE SBIT32				  *Waiting 
		)
    {
	//
	//   We do not create the semaphore until somebody tries
	//   to sleep on it for the first time.  We would normally
	//   hope to find a semaphore avaiable ready for a sleep
	//   but the OS may decline the request.  If this is the 
	//   case we exit without sleeping.
	//
	if ( ((*Semaphore) != NULL) || (UpdateSemaphore( Semaphore )) )
		{
		//
		//   We have been spinning waiting for the lock but it
		//   has not become free.  Hence, it is now time to 
		//   give up and sleep for a while.
		//
		(VOID) AtomicIncrement( Waiting );

		//
		//   Just before we go to sleep we do one final check
		//   to make sure that the lock is still busy and that
		//   there is someone to wake us up when it becomes 
		//   free.
		//
		if ( TotalUsers > 0 )
			{
#ifdef ENABLE_LOCK_STATISTICS
			//
			//   Count the number of times we have slept on 
			//   this lock.
			//
			(VOID) AtomicIncrement( & TotalSleeps );

#endif
			//
			//   When we sleep we awoken when the lock  
			//   becomes free or when we timeout.  If we  
			//   timeout we simply exit after decrementing 
			//   various counters.
			//
			if 
					( 
					WaitForSingleObject( (*Semaphore), Sleep ) 
						!= 
					WAIT_OBJECT_0 
					)
				{ 
#ifdef ENABLE_LOCK_STATISTICS
				//
				//   Count the number of times we have timed  
				//   out on this lock.
				//
				(VOID) AtomicIncrement( & TotalTimeouts );

#endif
				return False; 
				}
			}
		else
			{
			//
			//   Lucky - the lock was just freed so lets
			//   decrement the sleep count and exit without
			//   sleeping.
			// 
			(VOID) AtomicDecrement( Waiting );
			}
		}
	
	return True;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Update the spin limit.                                         */
    /*                                                                  */
    /*   Update the maximum number of spins while waiting for the lock. */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SHARELOCK::UpdateMaxSpins( SBIT32 NewMaxSpins )
    {
	if ( NewMaxSpins > 0 )
		{ 
		MaxSpins = NewMaxSpins; 

		return True;
		}
	else
		{ return False; }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Update the sharing limit.                                      */
    /*                                                                  */
    /*   Update the maximum number of users that can share the lock.    */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SHARELOCK::UpdateMaxUsers( SBIT32 NewMaxUsers )
    {
	//
	//   We need to verify the new value makes sense.
	//
	if ( (NewMaxUsers > 0) && (NewMaxUsers <= MaxShareLockUsers) )
		{
		ClaimExclusiveLock();

		//
		//   Update the maximum number of users.
		//
		MaxUsers = NewMaxUsers;
		
		ReleaseExclusiveLock();

		return True;
		}
	else
		{ return False; }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Update the semahore.                                           */
    /*                                                                  */
    /*   We only create the semaphore on first use.  So when we need    */
    /*   need to create a new semaphore any thread that is trying       */
    /*   to sleep on it comes here.                                     */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SHARELOCK::UpdateSemaphore( HANDLE *Semaphore )
    {
	STATIC SBIT32 Active = 0;

	//
	//   We verify that there is still no semaphore
	//   otherwise we exit.
	//
	while ( (*Semaphore) == NULL )
		{
		//
		//   We increment the active count and if we
		//   are first we are selected for special duty.
		//
		if ( (AtomicIncrement( & Active ) == 1) && ((*Semaphore) == NULL) )
			{
			//
			//   We try to create a new semaphore.  If
			//   we fail we still exit.
			//   
			(*Semaphore) = CreateSemaphore( NULL,0,MaxShareLockUsers,NULL );

			//
			//  Decrement the active count and exit.
			//
			AtomicDecrement( & Active );

			return ((*Semaphore) != NULL);
			}
		else
			{ 
			//
			//  Decrement the active count and exit.
			//
			AtomicDecrement( & Active );

			Sleep( 1 ); 
			}
		}

	return True;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Wait for an exclusive lock.                                    */
    /*                                                                  */
    /*   Wait for the spinlock to become free and then claim it.        */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SHARELOCK::WaitForExclusiveLock( SBIT32 Sleep )
    {
	REGISTER LONG Cpus = ((LONG) NumberOfCpus());
#ifdef ENABLE_LOCK_STATISTICS
	REGISTER SBIT32 Spins = 0;
	REGISTER SBIT32 Waits = 0;

#endif
	//
	//   We will loop round in this function until the
	//   following condition becomes false.
	//
	while ( TotalUsers != 1 )
		{
		//
		//   The lock is busy so release it and spin waiting
		//   for it to become free.
		//
		(VOID) AtomicDecrement( & TotalUsers );
    
		//
		//   We will only try spinning and sleeping if we
		//   are permitted to do so by the parameters.
		//   
		if ( Sleep != 0 )
			{
			REGISTER SBIT32 Count;
    
			//
			//   If there are already more threads waiting 
			//   than the number of CPUs then the odds of 
			//   getting the lock by spinning are slim, when 
			//   there is only one CPU the chance is zero, so 
			//   just bypass this step.
			//
			if ( (Cpus > 1) && (Cpus > PriorityWaiting) )
				{
				//
				//   Wait by spinning and repeatedly testing 
				//   the spinlock.  We exit when the lock  
				//   becomes free or the spin limit is exceeded.
				//
				for 
					( 
						Count = MaxSpins;
						(Count > 0) && (TotalUsers > 0);
						Count -- 
					);
#ifdef ENABLE_LOCK_STATISTICS

				//
				//   Update the statistics.
				//
				Spins += (MaxSpins - Count);
				Waits ++;
#endif
				}
			else
				{ Count = 0; }

			//
			//   We have exhusted our spin count so it is 
			//   time to sleep waiting for the lock to clear.
			//
			if ( Count == 0 )
				{
				//
				//   We have decide that we need to sleep but are
				//   still holding an exclusive lock so lets drop it
				//   before sleeping.
				//
				(VOID) AtomicDecrement( & ExclusiveUsers );

				//
				//   We have decied that it is time to go to sleep
				//   when we wake up the lock should be available
				//   (or just aquired) unless we have timed out in
				//   wich case we exit.
				//
				if 
						( 
						! SleepWaitingForLock
							( 
							& PrioritySemaphore,
							Sleep,
							& PriorityWaiting 
							) 
						)
					{ return False; }

				//
				//   We have woken up again so lets reclaim the
				//   exclusive lock we had earlier.
				//
				(VOID) AtomicIncrement( & ExclusiveUsers );
				}
			}
		else
			{ 
			//
			//   We have decide that we need to exit but are 
			//   still holding an exclusive lock.  so lets drop 
			//   it and leave.
			//
			(VOID) AtomicDecrement( & ExclusiveUsers );

			return False; 
			} 
		//
		//   Lets test the lock again.
		//
		(VOID) AtomicIncrement( & TotalUsers );
		}

#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
	(VOID) AtomicAdd( & TotalSpins, Spins );
	(VOID) AtomicAdd( & TotalWaits, Waits );
#endif

	return True;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Wait for a shared lock.                                        */
    /*                                                                  */
    /*   Wait for the lock to become free and then claim it.            */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SHARELOCK::WaitForShareLock( SBIT32 Sleep )
    {
	REGISTER LONG Cpus = ((LONG) NumberOfCpus());
#ifdef ENABLE_LOCK_STATISTICS
	REGISTER SBIT32 Spins = 0;
	REGISTER SBIT32 Waits = 0;

#endif
	//
	//   We will loop round in this function until the
	//   following condition becomes false.
	//
	while ( (ExclusiveUsers > 0) || (TotalUsers > MaxUsers) )
		{
		//
		//   The lock is busy so release it and spin waiting
		//   for it to become free.
		//
		(VOID) AtomicDecrement( & TotalUsers );

		//
		//   We will only try spinning and sleeping if we
		//   are permitted to do so by the parameters.
		//   
		if ( Sleep != 0 )
			{
			REGISTER SBIT32 Count;
    
			//
			//   If there are already more threads waiting 
			//   than the number of CPUs then the odds of 
			//   getting the lock by spinning are slim, when 
			//   there is only one CPU the chance is zero, so 
			//   just bypass this step.
			//
			if ( (Cpus > 1) && (Cpus > (PriorityWaiting + NormalWaiting)) )
				{
				//
				//   Wait by spinning and repeatedly testing 
				//   the spinlock.  We exit when the lock  
				//   becomes free or the spin limit is exceeded.
				//
				for 
					( 
						Count = MaxSpins;
						(Count > 0) 
							&& 
						((ExclusiveUsers > 0) || (TotalUsers >= MaxUsers));
						Count -- 
					);
#ifdef ENABLE_LOCK_STATISTICS

				//
				//   Update the statistics.
				//
				Spins += (MaxSpins - Count);
				Waits ++;
#endif
				}
			else
				{ Count = 0; }

			//
			//   We have exhusted our spin count so it is 
			//   time to sleep waiting for the lock to clear.
			//
			if ( Count == 0 )
				{
				//
				//   We have decied that it is time to go to sleep
				//   when we wake up the lock should be available
				//   (or just aquired) unless we have timed out in
				//   wich case we exit.
				//
				if 
						( 
						! SleepWaitingForLock
							( 
							& NormalSemaphore,
							Sleep,
							& NormalWaiting 
							) 
						)
					{ return False; }
				}
			}
		else
			{ return False; }

		//
		//   Lets test the lock again.
		//
		(VOID) AtomicIncrement( & TotalUsers );
		}
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
	(VOID) AtomicAdd( & TotalSpins, Spins );
	(VOID) AtomicAdd( & TotalWaits, Waits );
#endif

	return True;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Wake all sleepers.                                             */
    /*                                                                  */
    /*   Wake all the sleepers who are waiting for the spinlock.        */
    /*   All sleepers are woken because this is much more efficent      */
    /*   and it is known that the lock latency is typically short.      */
    /*                                                                  */
    /********************************************************************/

VOID SHARELOCK::WakeAllSleepers( VOID )
    {
    REGISTER SBIT32 PriorityWakeup = AtomicExchange( & PriorityWaiting, 0 );

	//
	//   We try to wake any priority sleepers before
	//   waking any normal sleepers.
	//
    if ( PriorityWakeup > 0 )
        {
		REGISTER SBIT32 Cpus = ((LONG) NumberOfCpus());

		//
		//   We will only wake enough threads to ensure that 
		//   there is one active thread per CPU.  So if an 
		//   application has hundreds of threads we will try 
		//   prevent the system from becoming swampped.
		//
		if ( PriorityWakeup > Cpus )
			{
			(VOID) AtomicAdd( & PriorityWaiting,(PriorityWakeup - Cpus) );
			PriorityWakeup = Cpus; 
			}

        //
        //   Wake some sleepers as the lock has just been freed.
        //   It is a straight race to decide who gets the lock next.
        //
        if ( ! ReleaseSemaphore( PrioritySemaphore, PriorityWakeup, NULL ) )
            { Failure( "Priority wakeup failed in WakeAllSleepers()" ); }
        }
    else
        {
		REGISTER SBIT32 NormalWakeup = AtomicExchange( & NormalWaiting, 0 );

		//
		//   Well as there are no priority sleepers lets  
		//   wake some of the normal sleepers.
		//
		if ( NormalWakeup > 0 )
			{
			REGISTER SBIT32 Cpus = ((LONG) NumberOfCpus());

			//
			//   We will only wake enough threads to ensure that 
			//   there is one active thread per CPU.  So if an 
			//   application has hundreds of threads we will try 
			//   prevent the system from becoming swampped.
			//
			if ( NormalWakeup > Cpus )
				{
				(VOID) AtomicAdd( & NormalWaiting,(NormalWakeup - Cpus) );
				NormalWakeup = Cpus; 
				}

			//
			//   Wake some sleepers as the lock has just been freed.
			//   It is a straight race to decide who gets the lock next.
			//
			if ( ! ReleaseSemaphore( NormalSemaphore, NormalWakeup, NULL ) )
				{ Failure( "Normal wakeup failed in WakeAllSleepers()" ); }
			}
		else
			{
			//
			//   When multiple threads pass through the critical  
			//   section it is possible for the waiting count  
			//   to become negative.  This should be very rare but 
			//   such a negative value needs to be preserved. 
			//
			if ( NormalWakeup < 0 )
				{ (VOID) AtomicAdd( & NormalWaiting, NormalWakeup ); }
			}

        //
        //   When multiple threads pass through the critical  
        //   section it is possible for the waiting count  
		//   to become negative.  This should be very rare but 
		//   such a negative value needs to be preserved. 
        //
		if ( PriorityWakeup < 0 )
			{ (VOID) AtomicAdd( & PriorityWaiting, PriorityWakeup ); }
        }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a lock.  This call is not thread safe and should       */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

SHARELOCK::~SHARELOCK( VOID )
    {
#ifdef ENABLE_LOCK_STATISTICS
	//
	//   Print the lock statistics.
	//
	DebugPrint
		(
		"Sharelock: %d exclusive, %d shared, %d timeouts, " 
		"%d locks per wait, %d spins per wait, %d waits per sleep.\n",
		TotalExclusiveLocks,
		TotalShareLocks,
		TotalTimeouts,
		((TotalExclusiveLocks + TotalShareLocks) / ((TotalWaits <= 0) ? 1 : TotalWaits)),
		(TotalSpins / ((TotalWaits <= 0) ? 1 : TotalWaits)),
		(TotalWaits / ((TotalSleeps <= 0) ? 1 : TotalSleeps))
		);
#endif
	//
	//   Close the semaphores handle.
	//
    if ( (PrioritySemaphore != NULL) && (! CloseHandle( PrioritySemaphore )) )
        { Failure( "Close semaphore in destructor for SHARELOCK" ); }

    if ( (NormalSemaphore != NULL) && (! CloseHandle( NormalSemaphore )) )
        { Failure( "Close semaphore in destructor for SHARELOCK" ); }
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\slist.hpp ===
#ifndef _SLIST_HPP_
#define _SLIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Assembly.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A lockless list.                                               */
    /*                                                                  */
    /*   An SList is a lockless list suitable for high contention       */
    /*   SMP access.                                                    */
    /*                                                                  */
    /********************************************************************/

class SLIST : public ASSEMBLY
    {
		//
		//   Private type definitions.
		//
		typedef struct
			{
	        SLIST                     *Address;
	        SBIT16                    Size;
	        SBIT16                    Version;
			}
		SLIST_HEADER;

        //
        //   Private data.
        //
        VOLATILE SBIT64	              Header;

    public:
        //
        //   Public functions.
        //
        SLIST( VOID );

		BOOLEAN Pop( SLIST **Element );

		VOID PopAll( SLIST **List );

		VOID Push( SLIST *Element );

        ~SLIST( VOID );

		//
		//   Public inline functions.
		//
		INLINE SBIT32 Size( VOID )
			{ return (((SLIST_HEADER*) & Header) -> Size); }

	private:
        //
        //   Disabled operations.
        //
        SLIST( CONST SLIST & Copy );

        VOID operator=( CONST SLIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\sharelock.hpp ===
#ifndef _SHARELOCK_HPP_
#define _SHARELOCK_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Environment.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Sharelock and Semaphore locking.                               */
    /*                                                                  */
    /*   This class provides a very conservative locking scheme.        */
    /*   The assumption behind the code is that locks will be           */
    /*   held for a very short time.  A lock can be obtained in         */
    /*   either exclusive mode or shared mode.  If the lock is not      */
    /*   available the caller waits by spinning or if that fails        */
    /*   by sleeping.                                                   */
    /*                                                                  */
    /********************************************************************/

class SHARELOCK : public ENVIRONMENT
    {
        //
        //   Private data.
        //
		SBIT32                        MaxSpins;
		SBIT32                        MaxUsers;

        VOLATILE SBIT32               ExclusiveUsers;
        VOLATILE SBIT32               TotalUsers;

        HANDLE                        NormalSemaphore;
        VOLATILE SBIT32               NormalWaiting;
        HANDLE                        PrioritySemaphore;
        VOLATILE SBIT32               PriorityWaiting;

#ifdef ENABLE_RECURSIVE_LOCKS
		SBIT32						  Owner;
		SBIT32						  Recursive;

#endif
#ifdef ENABLE_LOCK_STATISTICS
        //
        //   Counters for debugging builds.
        //
        VOLATILE SBIT32               TotalExclusiveLocks;
        VOLATILE SBIT32               TotalShareLocks;
        VOLATILE SBIT32               TotalSleeps;
        VOLATILE SBIT32               TotalSpins;
        VOLATILE SBIT32               TotalTimeouts;
        VOLATILE SBIT32               TotalWaits;
#endif

    public:
        //
        //   Public functions.
        //
        SHARELOCK( SBIT32 NewMaxSpins = 4096, SBIT32 NewMaxUsers = 256 );

        INLINE VOID ChangeExclusiveLockToSharedLock( VOID );

        INLINE BOOLEAN ChangeSharedLockToExclusiveLock( SBIT32 Sleep = INFINITE );

        INLINE BOOLEAN ClaimExclusiveLock( SBIT32 Sleep = INFINITE );

        INLINE BOOLEAN ClaimShareLock( SBIT32 Sleep = INFINITE );

        INLINE VOID ReleaseExclusiveLock( VOID );

        INLINE VOID ReleaseShareLock( VOID );

        BOOLEAN UpdateMaxSpins( SBIT32 NewMaxSpins );

        BOOLEAN UpdateMaxUsers( SBIT32 NewMaxUsers );

        ~SHARELOCK( VOID );

		//
		//   Public inline functions.
		//
        INLINE SBIT32 ActiveUsers( VOID ) 
			{ return (SBIT32) TotalUsers; }

    private:
        //
        //   Private functions.
        //
		INLINE VOID DeleteExclusiveOwner( VOID );

		INLINE VOID NewExclusiveOwner( SBIT32 NewOwner );

        BOOLEAN SleepWaitingForLock
			( 
			HANDLE					  *Semaphore,
			SBIT32					  Sleep,
			VOLATILE SBIT32			  *Waiting 
			);

		BOOLEAN UpdateSemaphore( HANDLE *Semaphore );

        BOOLEAN WaitForExclusiveLock( SBIT32 Sleep );

        BOOLEAN WaitForShareLock( SBIT32 Sleep );

        VOID WakeAllSleepers( VOID );

        //
        //   Disabled operations.
        //
        SHARELOCK( CONST SHARELOCK & Copy );

        VOID operator=( CONST SHARELOCK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Change an exclusive lock to a shared lock.                     */
    /*                                                                  */
    /*   Downgrade the existing exclusive lock to a shared lock.        */
    /*                                                                  */
    /********************************************************************/

INLINE VOID SHARELOCK::ChangeExclusiveLockToSharedLock( VOID )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	//
	//   When we have recursive lock calls we do not 
	//   release the lock until we have exited to the 
	//   top level.
	//
	if ( Recursive <= 0 )
		{
		//
		//   Delete the exclusive owner information.
		//
		DeleteExclusiveOwner();

#endif
		//
		//   Simply decrement the exclusive count.
		//   This allows the lock to be shared.
		//
		(VOID) AtomicDecrement( & ExclusiveUsers );
#ifdef ENABLE_RECURSIVE_LOCKS
		}
#endif
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
	(VOID) AtomicIncrement( & TotalShareLocks );
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Change a shared lock to an exclusive lock.                     */
    /*                                                                  */
    /*   Upgrade the existing shared lock to an exclusive lock.         */
    /*                                                                  */
    /********************************************************************/

INLINE BOOLEAN SHARELOCK::ChangeSharedLockToExclusiveLock( SBIT32 Sleep )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	REGISTER SBIT32 ThreadId = GetThreadId();

	//
	//   We may already own an exclusive lock. If so 
	//   we increment the recursive count otherwise 
	//   we have to wait.
	//
	if ( Owner != ThreadId )
		{
#endif		
		//
		//   We need to increment the exclusive count
		//   to prevent the lock from being shared.
		//
		(VOID) AtomicIncrement( & ExclusiveUsers );

		//
		//   If the total number of users is one then
		//   we have the lock exclusively otherwise we
		//   may need to wait.
		//
		if ( TotalUsers != 1 )
			{
			//
			//   We have to wait.  If we are not allowed 
			//   to sleep or we have timed out then exit.
			//
			if ( ! WaitForExclusiveLock( Sleep ) )
				{ return False; }
			}
#ifdef ENABLE_RECURSIVE_LOCKS

		//
		//   Register the new exclusive owner
		//   of the lock.
		//
		NewExclusiveOwner( ThreadId );
		}
#endif
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
	(VOID) AtomicIncrement( & TotalExclusiveLocks );
#endif

    return True;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Claim an exclusive lock.                                       */
    /*                                                                  */
    /*   Claim an exclusive lock if available else wait or exit.        */
    /*                                                                  */
    /********************************************************************/

INLINE BOOLEAN SHARELOCK::ClaimExclusiveLock( SBIT32 Sleep )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	REGISTER SBIT32 ThreadId = GetThreadId();

	//
	//   We may already own an exclusive lock. If so 
	//   we increment the recursive count otherwise 
	//   we have to wait.
	//
	if ( Owner != ThreadId )
		{
#endif
		//
		//   We need to increment the exclusive count
		//   to prevent the lock from being shared and
		//   the total number of users count.  We need
		//   update the total number of users first to
		//   avoid a deadlock when real-time priorites
		//   are being used.  If not then an interupt
		//   can occur after the update of the 
		//   'ExclusiveUsers' count but before the 
		//   'TotalUsers' count that will prevent
		//   another thread from getting the lock or
		//   sleeping (i.e. a live lock).
		//
		(VOID) AtomicIncrement( & TotalUsers );
		(VOID) AtomicIncrement( & ExclusiveUsers );

		if ( TotalUsers != 1 )
			{
			//
			//   We have to wait.  If we are not allowed 
			//   to sleep or we have timed out then exit.
			//
			if ( ! WaitForExclusiveLock( Sleep ) )
				{ return False; }
			}
#ifdef ENABLE_RECURSIVE_LOCKS

		//
		//   Register the new exclusive owner
		//   of the lock.
		//
		NewExclusiveOwner( ThreadId );
		}
	else
		{ Recursive ++; }
#endif
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
	(VOID) AtomicIncrement( & TotalExclusiveLocks );
#endif

    return True;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Claim a shared lock.                                           */
    /*                                                                  */
    /*   Claim a shared lock if available else wait or exit.            */
    /*                                                                  */
    /********************************************************************/

INLINE BOOLEAN SHARELOCK::ClaimShareLock( SBIT32 Sleep )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	REGISTER SBIT32 ThreadId = GetThreadId();

	//
	//   We may already own an exclusive lock. If so 
	//   we increment the recursive count otherwise 
	//   we have to wait.
	//
	if ( Owner != ThreadId )
		{
#endif
		//
		//   We need to increment the total number of 
		//   users count to prevent the lock from being 
		//   claimed for exclusive use.
		//
		(VOID) AtomicIncrement( & TotalUsers );

		if ( (ExclusiveUsers > 0) || (TotalUsers > MaxUsers) )
			{
			//
			//   We have to wait.  If we are not allowed 
			//   to sleep or we have timed out then exit.
			//
			if ( ! WaitForShareLock( Sleep ) )
				{ return False; }
			}
#ifdef ENABLE_RECURSIVE_LOCKS
		}
	else
		{ Recursive ++; }
#endif
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
	(VOID) AtomicIncrement( & TotalShareLocks );
#endif

	return True;
    }
#ifdef ENABLE_RECURSIVE_LOCKS

    /********************************************************************/
    /*                                                                  */
    /*   New exclusive owner.                                           */
    /*                                                                  */
    /*   Delete the exclusive lock owner information.                   */
    /*                                                                  */
    /********************************************************************/

INLINE VOID SHARELOCK::DeleteExclusiveOwner( VOID )
    {
#ifdef DEBUGGING
	if ( Owner != NULL )
		{ 
#endif
		Owner = NULL; 
#ifdef DEBUGGING
		}
	else
		{ Failure( "Sharelock has no owner in DeleteExclusiveOwner" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   New exclusive owner.                                           */
    /*                                                                  */
    /*   Register new exclusive lock owner information.                 */
    /*                                                                  */
    /********************************************************************/

INLINE VOID SHARELOCK::NewExclusiveOwner( SBIT32 NewOwner )
    {
#ifdef DEBUGGING
	if ( Owner == NULL )
		{ 
#endif
		Owner = NewOwner; 
#ifdef DEBUGGING
		}
	else
		{ Failure( "Already exclusive in NewExclusiveOwner" ); }
#endif
    }
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Release an exclusive lock.                                     */
    /*                                                                  */
    /*   Release an exclusive lock and if needed wakeup any sleepers.   */
    /*                                                                  */
    /********************************************************************/

INLINE VOID SHARELOCK::ReleaseExclusiveLock( VOID )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	//
	//   When we have recursive lock calls we do not 
	//   release the lock until we have exited to the 
	//   top level.
	//
	if ( Recursive <= 0 )
		{
		//
		//   Delete the exclusive owner information.
		//
		DeleteExclusiveOwner();

#endif
		//
		//   Release an exclusive lock.
		//
#ifdef DEBUGGING
		if
				(
				(AtomicDecrement( & ExclusiveUsers ) < 0)
					||
				(AtomicDecrement( & TotalUsers ) < 0)
				)
			{ Failure( "Negative lock count in ReleaseExclusiveLock" ); }
#else
		AtomicDecrement( & ExclusiveUsers );
		AtomicDecrement( & TotalUsers );
#endif

		//
		//   Wakeup anyone who is asleep waiting.  We
		//   need to be vaery careful here as in very
		//   rare situations the waiting counts can
		//   be negative for very breif periods.
		//
		if ( (PriorityWaiting > 0) || (NormalWaiting > 0) )
			{ WakeAllSleepers(); }
#ifdef ENABLE_RECURSIVE_LOCKS
		}
	else
		{ Recursive --; }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Release a shared lock.                                         */
    /*                                                                  */
    /*   Release a shared lock and if needed wakeup any sleepers.       */
    /*                                                                  */
    /********************************************************************/

INLINE VOID SHARELOCK::ReleaseShareLock( VOID )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	//
	//   When we have recursive lock calls we do not 
	//   release the lock until we have exited to the 
	//   top level.
	//
	if ( Recursive <= 0 )
		{
#endif
#ifdef DEBUGGING
		//
		//   Release a shared lock.
		//
		if ( AtomicDecrement( & TotalUsers ) < 0 )
			{ Failure( "Negative lock count in ReleaseShareLock" ); }
#else
		AtomicDecrement( & TotalUsers );
#endif

		//
		//   Wakeup anyone who is asleep waiting.  We
		//   need to be vaery careful here as in very
		//   rare situations the waiting counts can
		//   be negative for very breif periods.
		//
		if ( (PriorityWaiting > 0) || (NormalWaiting > 0) )
			{ WakeAllSleepers(); }
#ifdef ENABLE_RECURSIVE_LOCKS
		}
	else
		{ Recursive --; }
#endif
    }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\slist.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "SList.hpp"
#ifdef ASSEMBLY_X86

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new slist and initialize it.  This call is not        */
    /*   thread safe and should only be made in a single thread         */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

SLIST::SLIST( VOID )
    {
	//
	//   Zero the list head.
	//
	Header = 0;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Pop an element.                                                */
    /*                                                                  */
    /*   Pop an element from the list.                                  */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SLIST::Pop( SLIST **Element )
    {
	AUTO SBIT64 Original;
	AUTO SBIT64 Update;
	REGISTER SLIST_HEADER *NewElement;
	REGISTER SLIST_HEADER *NewHeader = ((SLIST_HEADER*) & Update);

	//
	//   We repeatedly try to update the list until
	//   we are sucessful.
	//
	do 
		{
		//
		//   Clone the current head of the list.
		//
		Original = Header;
		Update = Original;

		//
		//   We need to be sure that there is an element
		//   to extract.  If not we exit.
		//
		if ( (NewElement = ((SLIST_HEADER*) NewHeader -> Address)) != NULL )
			{
			//
			//   Create a new list head.
			//
			NewHeader -> Address = NewElement -> Address;
			NewHeader -> Size --;
			NewHeader -> Version ++;
			}
		else
			{ return False; }
		}
	while 
		( AtomicCompareExchange64( & Header,Update,Original ) != Original );

	//
	//   Update the parameter and exit.
	//
	(*Element) = ((SLIST*) NewElement);

	return True;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Pop all elements.                                              */
    /*                                                                  */
    /*   Pop all the elements from the list.                            */
    /*                                                                  */
    /********************************************************************/

VOID SLIST::PopAll( SLIST **List )
    {
	AUTO SBIT64 Original;
	AUTO SBIT64 Update = NULL;
	REGISTER SLIST_HEADER *OldHeader = ((SLIST_HEADER*) & Original);

	//
	//   We repeatedly try to update the list until
	//   we are sucessful.
	//
	do 
		{
		//
		//   Clone the current head of the list.
		//
		Original = Header;
		}
	while 
		( AtomicCompareExchange64( & Header,Update,Original ) != Original );

	//
	//   Update the parameter and exit.
	//
	(*List) = ((SLIST*) OldHeader -> Address);
    }

    /********************************************************************/
    /*                                                                  */
    /*   Push an element.                                               */
    /*                                                                  */
    /*   Push an element onto the list.                                 */
    /*                                                                  */
    /********************************************************************/

VOID SLIST::Push( SLIST *Element )
    {
	AUTO SBIT64 Original;
	AUTO SBIT64 Update;
	REGISTER SLIST_HEADER *NewElement = ((SLIST_HEADER*) Element);
	REGISTER SLIST_HEADER *NewHeader = ((SLIST_HEADER*) & Update);

	//
	//   We repeatedly try to update the list until
	//   we are sucessful.
	//
	do 
		{
		//
		//   Clone the current head of the list.
		//
		Original = Header;
		Update = Original;

		//
		//   The current list head is copied to 
		//   the new element pointer.
		//
		NewElement -> Address = NewHeader -> Address;

		//
		//   Update the list head.
		//
		NewHeader -> Address = Element;
		NewHeader -> Size ++;
		NewHeader -> Version ++;
		}
	while 
		( AtomicCompareExchange64( & Header,Update,Original ) != Original );
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a SList.  This call is not thread safe and should      */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

SLIST::~SLIST( VOID )
    {
	//
	//   The list should be empty.
	//
    if ( Header != 0 )
		{ Failure( "Non-empty list in destructor for SLIST" ); }
    }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\smpool.hpp ===
#ifndef _SMPOOL_HPP_
#define _SMPOOL_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Block.hpp"
#include "Exclusive.hpp"
#include "Queue.hpp"
#include "Spinlock.hpp"
#include "Stack.hpp"
#include "Vector.hpp"
  
    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The server constants specify the size of the server queue      */
    /*   per processor stacks.                                          */
    /*                                                                  */
    /********************************************************************/

CONST SBIT16 MinSMPoolSize			  = 128;
CONST SBIT16 SMPoolStackSize		  = 32;

    /********************************************************************/
    /*                                                                  */
    /*   Pools and pool management.                                     */
    /*                                                                  */
    /*   This class provides general purpose memory pool along with     */
    /*   basic management.  The pools are optimized for very high       */
    /*   performance on SMP systems (although this calls does not       */
    /*   perform the actual locking.  Whenever possible multiple        */
    /*   items should allocated and deallocated at the same time.       */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> class SMPOOL
    {
		//
		//   Private structures.
		//
		typedef EXCLUSIVE< QUEUE<POINTER> > LOCKED_QUEUE;
		typedef struct { CHAR TypeSize[sizeof(TYPE)]; } TYPE_SIZE;

        //
        //   Private data.
        //
		SBIT32                        MaxSize;
		SBIT32                        MinSize;

        BLOCK< VECTOR<TYPE_SIZE> >    Block;
        LOCKED_QUEUE                  FreeQueue;
		VECTOR< STACK<POINTER> >      Stacks;

    public:
        //
        //   Public functions.
        //
        SMPOOL( SBIT32 MinSize = MinSMPoolSize );

        TYPE *PopPool( SBIT16 Cpu );

        TYPE **MultiplePopPool
            ( 
            SBIT16                        Cpu, 
            SBIT32                        Requested, 
            SBIT32                        *Size 
            );

        VOID PushPool( SBIT16 Cpu, TYPE *Pool );

        VOID MultiplePushPool
            ( 
            SBIT16                        Cpu, 
            TYPE                          *Pool[], 
            SBIT32                        Size 
            );

        ~SMPOOL( VOID );

	private:
		//
		//   Private functions.
		//
		VOID ExpandSize( SBIT32 NewSize );

        //
        //   Disabled operations.
        //
        SMPOOL( CONST SMPOOL & Copy );

        VOID operator=( CONST SMPOOL & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new pool and prepare it for use.  This call is        */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> SMPOOL<TYPE>::SMPOOL( SBIT32 MinSize ) : 
		//
		//   Call the constructors for the contained classes.
		//
		FreeQueue( MinSize ), 
		Stacks( NumberOfCpus(), CacheLineSize )
    {
#ifdef DEBUGGING
    if ( MinSize > 0 )
        {
#endif
		//
		//   We need to keep a note of the amount of elements 
		//   we have allocated so far.
		//
        this -> MaxSize = 0;
        this -> MinSize = MinSize;
#ifdef DEBUGGING
        }
    else
        { Failure( "MinSize in constructor for SMPOOL" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Expand size.                                                   */
    /*                                                                  */
    /*   Expand the current memory allocation if the free queue is      */
    /*   empty.                                                         */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VOID SMPOOL<TYPE>::ExpandSize( SBIT32 NewSize )
    {
	REGISTER SBIT32 Count1;
	REGISTER SBIT32 Count2;
	STATIC SPINLOCK Spinlock;

	Spinlock.ClaimLock();

	if ( FreeQueue.SizeOfQueue() <= 0 )
		{
		REGISTER SBIT32 ActualSize =
			(NewSize <= MinSize) ? MinSize : NewSize;
		REGISTER VECTOR<TYPE> *NewBlock =
			(
			(VECTOR<TYPE>*) new VECTOR<TYPE_SIZE>
				( 
				ActualSize, 
				CacheLineSize 
				)
			);

		//
		//   We need to keep a note of the number of elements 
		//   we have allocated thus far.
		//
		MaxSize += ActualSize;

		//
		//   We put the address of each element we allocate on
		//   a stack to enable high speed allocation and 
		//   deallocation.
		//
		for 
				( 
				Count1 = 0;
				Count1 < ActualSize;
				Count1 += SMPoolStackSize 
				)
			{
			AUTO POINTER NewCalls[ SMPoolStackSize ];

			//
			//   We add elements to the stack in blocks
			//   to reduce the number of call to the
			//   stack code.
			//
			for 
					( 
					Count2 = 0;
					((Count1 + Count2) < ActualSize)
						&&
					(Count2 < SMPoolStackSize);
					Count2 ++ 
					)
				{
				REGISTER TYPE *NewCall =
					(
					& (*NewBlock)[ (Count1 + Count2) ]
					);
                 
				NewCalls[ Count2 ] = (POINTER) NewCall;
				}

			//
			//   Add the next block for free work packets to
			//   the global free queue.
			//
			Stack.MultiplePushStack
				( 
				NewCalls,
				Count2 
				);
			}

		//
		//   Add the newly allocated block to the list of
		//   things to be deleted when this class is deleted.
		//
		Block.DeferedDelete( (VECTOR<TYPE_SIZE>*) NewBlock );
		}
	
	Spinlock.ReleaseLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Remove a single item from the pool.                            */
    /*                                                                  */
    /*   We remove a single item from the pool.  This call assumes      */
    /*   all calls with the same 'Cpu' value are executed serially      */
    /*   and that only one such call can be executing at any given      */
    /*   time.                                                          */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> TYPE *SMPOOL<TYPE>::PopPool( SBIT16 Cpu )
    {
	REGISTER STACK<POINTER> *Stack = & Stacks[ Cpu ];
	STATIC TYPE *NewPool;

	while ( ! Stack -> PopStack( (POINTER*) & NewPool ) )
        {
        AUTO POINTER Store[ SMPoolStackSize ];
        AUTO SBIT32 Size;

        FreeQueue.RemoveMultipleFromQueue
            ( 
            SMPoolStackSize, 
            Store, 
            & Size 
            );

        if ( Size > 0 )
            { Stack -> MultiplePushStack( Store, Size ); }
		else
			{ ExpandSize( MaxSize ); }
		}

	(VOID) PLACEMENT_NEW( NewPool, TYPE );

	return NewPool;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Remove multiple items from the pool.                           */
    /*                                                                  */
    /*   We remove multiple items from the pool.  This call assumes     */
    /*   all calls with the same 'Cpu' value are executed serially      */
    /*   and that only one such call can be executing at any given      */
    /*   time.                                                          */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> TYPE **SMPOOL<TYPE>::MultiplePopPool
        ( 
        SBIT16                        Cpu, 
        SBIT32                        Requested, 
        SBIT32                        *Size 
        )
    {
	REGISTER SBIT32 Count;
	REGISTER STACK<POINTER> *Stack = & Stacks[ Cpu ];
	STATIC TYPE *NewPool[ SMPoolStackSize ];

	Requested = (Requested <= SMPoolStackSize) ? Requested : SMPoolStackSize;

	while ( ! Stack -> MultiplePopStack( Requested,(POINTER*) NewPool,Size ) )
        {
        AUTO POINTER Store[ SMPoolStackSize ];
        AUTO SBIT32 Size;

        FreeQueue.RemoveMultipleFromQueue
            ( 
            SMPoolStackSize, 
            Store, 
            & Size 
            );

        if ( Size > 0 )
            { Stack -> MultiplePushStack( Store, Size ); }
		else
			{ ExpandSize( MaxSize ); }
		}

	for ( Count=0;Count < (*Size); Count ++ )
		{ (VOID) PLACEMENT_NEW( NewPool[ Count ], TYPE ); }

	return NewPool;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Add a single item to the pool.                                 */
    /*                                                                  */
    /*   We add a single item to the pool.  This call assumes           */
    /*   all calls with the same 'Cpu' value are executed serially      */
    /*   and that only one such call can be executing at any given      */
    /*   time.                                                          */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VOID SMPOOL<TYPE>::PushPool
        ( 
        SBIT16                        Cpu,
        TYPE                          *Pool
        )
    {
	REGISTER STACK<POINTER> *Stack = & Stacks[ Cpu ];

	PLACEMENT_DELETE( Pool, TYPE );

	Stack -> PushStack( (POINTER) Pool );

	while ( Stack -> SizeOfStack() > (SMPoolStackSize * 2) )
		{
		AUTO POINTER Store[ SMPoolStackSize ];
		AUTO SBIT32 Size;

		Stack -> MultiplePopStack
			( 
			SMPoolStackSize, 
			Store, 
			& Size 
			);

		FreeQueue.AddMultipleToQueue( Store, Size );
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Add multiple items to the pool.                                */
    /*                                                                  */
    /*   We add a multiple items to the pool.  This call assumes        */
    /*   all calls with the same 'Cpu' value are executed serially      */
    /*   and that only one such call can be executing at any given      */
    /*   time.                                                          */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VOID SMPOOL<TYPE>::MultiplePushPool
        ( 
        SBIT16                        Cpu,
        TYPE                          *Pool[],
        SBIT32                        Size 
        )
    {
	REGISTER SBIT32 Count;
	REGISTER STACK<POINTER> *Stack = & Stacks[ Cpu ];
	
	for ( Count=(Size - 1);Count >= 0; Count -- )
		{ PLACEMENT_DELETE( Pool[ Count ], TYPE ); }

	Stack -> MultiplePushStack( (POINTER*) Pool,Size );

	while ( Stack -> SizeOfStack() > (SMPoolStackSize * 2) )
		{
		AUTO POINTER Store[ SMPoolStackSize ];
		AUTO SBIT32 Size;

		Stack -> MultiplePopStack
			( 
			SMPoolStackSize, 
			Store, 
			& Size 
			);

		FreeQueue.AddMultipleToQueue( Store, Size );
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the stack.  This call is not thread safe and should    */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> SMPOOL<TYPE>::~SMPOOL( VOID )
    { /* void */ }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\stack.hpp ===
#ifndef _STACK_HPP_
#define _STACK_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Lock.hpp"
#include "Vector.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The stack constants specify the initial size of the stack.     */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 StackSize				  = 1024;

    /********************************************************************/
    /*                                                                  */
    /*   Stacks and stack management.                                   */
    /*                                                                  */
    /*   This class provides general purpose stacks along with some     */
    /*   basic management.  The stacks are optimized for very high      */
    /*   performance on SMP systems.  Whenever possible multiple        */
    /*   items should added and removed from a stack at the same time.  */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK=NO_LOCK> class STACK : public LOCK
    {
        //
        //   Private data.
        //
        SBIT32                        MaxSize;
        SBIT32                        Top;

        VECTOR<TYPE>                  Stack;

    public:
        //
        //   Public functions.
        //
        STACK( SBIT32 NewMaxSize = StackSize );

        BOOLEAN MultiplePopStack
            ( 
            SBIT32                        Requested, 
            TYPE                          Data[], 
            SBIT32                        *Size 
            );

        BOOLEAN MultiplePopStackReversed
            ( 
            SBIT32                        Requested, 
            TYPE                          Data[], 
            SBIT32                        *Size 
            );

        VOID MultiplePushStack
            ( 
            CONST TYPE					  Data[], 
            CONST SBIT32				  Size 
            );

        VOID MultiplePushStackReversed
            ( 
            CONST TYPE					  Data[], 
            CONST SBIT32				  Size 
            );

        BOOLEAN PeekStack( TYPE *Data );

        BOOLEAN PopStack( TYPE *Data );

        VOID PushStack( CONST TYPE & Data );

        BOOLEAN ReadStack( SBIT32 Index, TYPE *Data );

        VOID ReverseStack( VOID );

        BOOLEAN UpdateStack
            ( 
            CONST SBIT32				  Index, 
            CONST TYPE					  & Data 
            );

        ~STACK( VOID );

		//
		//   Public inline functions.
		//
        INLINE SBIT32 SizeOfStack( VOID ) 
			{ return Top; }

	private:
        //
        //   Disabled operations.
        //
        STACK( CONST STACK & Copy );

        VOID operator=( CONST STACK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new stack and prepare it for use.  This call is       */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> STACK<TYPE,LOCK>::STACK( SBIT32 NewMaxSize ) : 
		//
		//   Call the constructors for the contained classes.
		//
		Stack( NewMaxSize,1,CacheLineSize )
    {
#ifdef DEBUGGING
    if ( NewMaxSize > 0 )
        {
#endif
        MaxSize = NewMaxSize;
        Top = 0;
#ifdef DEBUGGING
        }
    else
        { Failure( "Size in constructor for STACK" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Remove multiple items from a stack.                            */
    /*                                                                  */
    /*   We remove multiple items from a stack and check to make sure   */
    /*   that the stack is not empty.                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN STACK<TYPE,LOCK>::MultiplePopStack
        ( 
        SBIT32                        Requested, 
        TYPE                          Data[], 
        SBIT32                        *Size 
        )
    {
	REGISTER BOOLEAN Result;

	//
	//   Claim an exclisive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   If the stack is not empty return the 
	//   top elements.
    if ( Top > 0 )
        {
        REGISTER SBIT32 Count;

        (*Size) = (Top >= Requested) ? Requested : Top;

        for ( Count = ((*Size) - 1);Count >= 0;Count -- )
            { Data[ Count ] = Stack[ -- Top ]; }

		Result = True;
        }
    else
		{ Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
	ReleaseExclusiveLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Remove multiple items from a stack in reverse order.           */
    /*                                                                  */
    /*   We remove multiple items from a stack in reverse order and     */
    /*   check to make sure that the stack is not empty.                */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN STACK<TYPE,LOCK>::MultiplePopStackReversed
        ( 
        SBIT32                        Requested, 
        TYPE                          Data[], 
        SBIT32                        *Size 
        )
    {
	REGISTER BOOLEAN Result;

	//
	//   Claim an exclisive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   If the stack is not empty return the 
	//   top elements.
    if ( Top > 0 )
        {
        REGISTER SBIT32 Count;

        (*Size) = (Top >= Requested) ? Requested : Top;

        for ( Count = 0;Count < (*Size);Count ++ )
            { Data[ Count ] = Stack[ -- Top ]; }

		Result = True;
        }
    else
		{ Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
	ReleaseExclusiveLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Add multiple items to a stack.                                 */
    /*                                                                  */
    /*   We add multiple items to a stack and check to make sure that   */
    /*   the stack has not overflowed.  If the stack has overflowed     */
    /*   we double its size.                                            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID STACK<TYPE,LOCK>::MultiplePushStack
        ( 
        CONST TYPE					  Data[],
        CONST SBIT32				  Size 
        )
    {
    REGISTER SBIT32 Count;

	//
	//   Claim an exclisive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   If the stack will overflow then expand it.
	//
    while ( (Top + Size) >= MaxSize )
        { Stack.Resize( (MaxSize *= ExpandStore) ); }

	//
	//   Push the new elements.
	//
    for ( Count = 0;Count < Size;Count ++ )
        { Stack[ Top ++ ] = Data[ Count ]; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Add multiple items to a stack in reverse order.                */
    /*                                                                  */
    /*   We add multiple items to a stack in reverse order and check    */
    /*   to make sure that the stack has not overflowed.  If the stack  */
    /*   has overflowed we double its size.                             */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID STACK<TYPE,LOCK>::MultiplePushStackReversed
        ( 
        CONST TYPE					  Data[],
        CONST SBIT32				  Size 
        )
    {
    REGISTER SBIT32 Count;

	//
	//   Claim an exclisive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   If the stack will overflow then expand it.
	//
    while ( (Top + Size) >= MaxSize )
        { Stack.Resize( (MaxSize *= ExpandStore) ); }

	//
	//   Push the new elements in reverse order.
	//
    for ( Count = (Size-1);Count >= 0;Count -- )
        { Stack[ Top ++ ] = Data[ Count ]; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Peek at the top of stack.                                      */
    /*                                                                  */
    /*   We return the top of stack with a pop but check to make sure   */
    /*   that the stack is not empty.                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN STACK<TYPE,LOCK>::PeekStack
		( 
		TYPE						  *Data 
		)
    {
    REGISTER BOOLEAN Result;

	//
	//   Claim an shared lock (if enabled).
	//
    ClaimSharedLock();

	//
	//   If the stack is not empty return a copy
	//   of the top element.
	//
    if ( Top > 0 )
		{ 
		(*Data) = Stack[ (Top - 1) ];

		Result = True;
		}
	else
		{ Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
	ReleaseSharedLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Remove a single item from a stack.                             */
    /*                                                                  */
    /*   We remove a single item from a stack and check to make sure    */
    /*   that the stack is not empty.                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN STACK<TYPE,LOCK>::PopStack
		( 
		TYPE						  *Data 
		)
    {
    REGISTER BOOLEAN Result;

    //
	//   Claim an exclisive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   If the stack is not empty return the
	//   top element.
	//
    if ( Top > 0 )
		{ 
		(*Data) = Stack[ -- Top ];
		
		Result = True;
		}
	else
		{ Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
	ReleaseExclusiveLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Add a single item to a stack.                                  */
    /*                                                                  */
    /*   We add a single item to a stack and check to make sure that    */
    /*   the stack has not overflowed.  If the stack has overflowed     */
    /*   we double its size.                                            */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID STACK<TYPE,LOCK>::PushStack
		( 
		CONST TYPE					  & Data
		)
    {    
	//
	//   Claim an exclisive lock (if enabled).
	//
	ClaimExclusiveLock();

	//
	//   If the stack is full then expand it.
	//
    while ( Top >= MaxSize )
        { Stack.Resize( (MaxSize *= ExpandStore) ); }

	//
	//   Push a new element.
	//
    Stack[ Top ++ ] = Data;

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   Read a stack value.                                            */
    /*                                                                  */
    /*   We return a single item from the stack but check to make       */
    /*   sure that it exists.            .                              */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN STACK<TYPE,LOCK>::ReadStack
        ( 
        SBIT32                        Index, 
        TYPE                          *Data 
        )
    {
	REGISTER BOOLEAN Result;

	//
	//   Claim an shared lock (if enabled).
	//
    ClaimSharedLock();

	//
	//   If the element exists then return a copy of
	//   it to the caller.
	//
    if ( Index < Top )
		{ 
		(*Data) = Stack[ Index ];
		
		Result = True;
		}
	else
		{ Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
	ReleaseSharedLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Reverse the stack.                                             */
    /*                                                                  */
    /*   We reverse the order of the stack to make effectively          */
    /*   make it a queue.                .                              */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> VOID STACK<TYPE,LOCK>::ReverseStack( VOID )
    {
	REGISTER SBIT32 Count;
	REGISTER SBIT32 MidPoint = (Top / 2);

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   Swap all elements around the mid point.
	//
	for ( Count=0;Count < MidPoint;Count ++ )
		{
		REGISTER TYPE *Low = & Stack[ Count ];
		REGISTER TYPE *High = & Stack[ (Top - Count - 1) ];
		REGISTER TYPE Temp = (*Low);

		(*Low) = (*High);
		(*High) = Temp;
		}

	//
	//   Release any lock we claimed earlier.
	//
	ReleaseExclusiveLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Update a stack value.                                          */
    /*                                                                  */
    /*   We update a single item on the stack but check to make         */
    /*   sure that it exists.            .                              */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN STACK<TYPE,LOCK>::UpdateStack
        ( 
        CONST SBIT32				  Index, 
        CONST TYPE					  & Data 
        )
    {
	REGISTER BOOLEAN Result;

	//
	//   Claim an exclisive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   If the element exists then update it.
	//
    if ( Index < Top )
		{ 
		Stack[ Index ] = Data;

		Result = True;
		}
	else
		{ Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
	ReleaseExclusiveLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the stack.  This call is not thread safe and should    */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> STACK<TYPE,LOCK>::~STACK( VOID )
    { /* void */ }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\standard.hpp ===
#ifndef _STANDARD_HPP_
#define _STANDARD_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard data types.                                       */
    /*                                                                  */
    /*   The standard data types should be used in preference to the    */
    /*   data types defined in the C++ language.  This is to allow      */
    /*   for easier porting.  If no suitable standard type exists       */
    /*   then one should be created and documented here.                */
    /*                                                                  */
    /********************************************************************/

#define AUTO                          auto
#define CONST						  const
#define CONSTANT                      const
#define EXTERN                        extern
#define GLOBAL                        extern
#define INLINE                        __forceinline
#define LOCAL                         auto
#define REGISTER                      register
#define STATIC                        static
#define VIRTUAL                       virtual
#define VOLATILE                      volatile

    /********************************************************************/
    /*                                                                  */
    /*   The standard C++ types.                                        */
    /*                                                                  */
    /*   The C++ standard reserves various lower case keywords.  This   */
    /*   system uses a similar standard.  All upper case words are      */
    /*   either constants or types.  All words begining with a single   */
    /*   upper case letter are variables.                               */
    /*                                                                  */
    /********************************************************************/

typedef unsigned char                 BOOLEAN;

typedef char                          CHAR;
typedef short int                     SHORT;
typedef int                           INT;
typedef long int                      LONG;

typedef signed char                   SCHAR;
typedef signed short int              SSHORT;
typedef signed int                    SINT;
typedef signed long int               SLONG;

typedef unsigned char                 UCHAR;
typedef unsigned short int            USHORT;
typedef unsigned int                  UINT;
typedef unsigned long int             ULONG;

typedef unsigned char                 *FAULT;
typedef void                          *POINTER;

    /********************************************************************/
    /*                                                                  */
    /*   The optional standard types.                                   */
    /*                                                                  */
    /*   Some of the standard types are specified in other headers.     */
    /*   We need to be careful not to redefine these specifications     */
    /*   if they already exist.                                         */
    /*                                                                  */
    /********************************************************************/

#ifndef CDECL
#define	CDECL						  _cdecl
#endif

#ifndef DLL_EXPORT
#define	DLL_EXPORT					  _declspec(dllexport)
#endif

#ifndef DLL_IMPORT
#define	DLL_IMPORT					  _declspec(dllimport)
#endif

#ifndef STDCALL
#define	STDCALL						  _stdcall
#endif

#ifndef VOID
#define	VOID						  void
#endif

    /********************************************************************/
    /*                                                                  */
    /*   The fixed length types.                                        */
    /*                                                                  */
    /*   The above types are intended to shadow the standard C++ types  */
    /*   built into the language.  However, these types don't assure    */
    /*   any level of accuracy.  Each of following types is defined     */
    /*   to provide a minimum level of precision.                       */
    /*                                                                  */
    /********************************************************************/

typedef unsigned __int8               BIT8;
typedef unsigned __int16              BIT16;
typedef unsigned __int32              BIT32;
typedef unsigned __int64              BIT64;

typedef signed __int8                 SBIT8;
typedef signed __int16                SBIT16;
typedef signed __int32                SBIT32;
typedef signed __int64                SBIT64;
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\spinlock.hpp ===
#ifndef _SPINLOCK_HPP_
#define _SPINLOCK_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Environment.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The spinlock constants indicate when the lock is open and      */
    /*   when it is closed.                                             */
    /*                                                                  */
    /********************************************************************/

CONST LONG LockClosed				  = 1;
CONST LONG LockOpen					  = 0;

    /********************************************************************/
    /*                                                                  */
    /*   Spinlock and Semaphore locking.                                */
    /*                                                                  */
    /*   This class provides a very conservative locking scheme.        */
    /*   The assumption behind the code is that locks will be           */
    /*   held for a very short time.  When a lock is taken a memory     */
    /*   location is exchanged.  All other threads that want this       */
    /*   lock wait by spinning and sometimes sleeping on a semaphore    */
    /*   until it becomes free again.  The only other choice is not     */
    /*   to wait at all and move on to do something else.  This         */
    /*   module should normally be used in conjunction with cache       */
    /*   aligned memory in minimize cache line misses.                  */
    /*                                                                  */
    /********************************************************************/

class SPINLOCK : public ENVIRONMENT
    {
        //
        //   Private data.
        //
		SBIT32						  MaxSpins;
		SBIT32						  MaxUsers;
#ifdef ENABLE_RECURSIVE_LOCKS
		SBIT32						  Owner;
		SBIT32						  Recursive;
#endif
        HANDLE                        Semaphore;
        VOLATILE SBIT32               Spinlock;
        VOLATILE SBIT32               Waiting;
#ifdef ENABLE_LOCK_STATISTICS

        //
        //   Counters for debugging builds.
        //
        VOLATILE SBIT32               TotalLocks;
        VOLATILE SBIT32               TotalSleeps;
        VOLATILE SBIT32               TotalSpins;
        VOLATILE SBIT32               TotalTimeouts;
        VOLATILE SBIT32               TotalWaits;
#endif

    public:
        //
        //   Public functions.
        //
        SPINLOCK( SBIT32 NewMaxSpins = 4096, SBIT32 NewMaxUsers = 256 );

        INLINE BOOLEAN ClaimLock( SBIT32 Sleep = INFINITE );

        INLINE VOID ReleaseLock( VOID );

        ~SPINLOCK( VOID );

    private:
        //
        //   Private functions.
        //
        INLINE BOOLEAN ClaimSpinlock( VOLATILE SBIT32 *Spinlock );

		INLINE VOID DeleteExclusiveOwner( VOID );

		INLINE VOID NewExclusiveOwner( SBIT32 NewOwner );

		BOOLEAN UpdateSemaphore( VOID );

        BOOLEAN WaitForLock( SBIT32 Sleep );

        VOID WakeAllSleepers( VOID );

        //
        //   Disabled operations.
        //
        SPINLOCK( CONST SPINLOCK & Copy );

        VOID operator=( CONST SPINLOCK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   A guaranteed atomic exchange.                                  */
    /*                                                                  */
    /*   An attempt is made to claim the spinlock.  This action is      */
    /*   guaranteed to be atomic.                                       */
    /*                                                                  */
    /********************************************************************/

INLINE BOOLEAN SPINLOCK::ClaimSpinlock( VOLATILE SBIT32 *Spinlock )
    {
    return 
		(
		AtomicCompareExchange( Spinlock,LockClosed,LockOpen ) 
			== 
		LockOpen
		); 
    }

    /********************************************************************/
    /*                                                                  */
    /*   Claim the spinlock.                                            */
    /*                                                                  */
    /*   Claim the lock if available else wait or exit.                 */
    /*                                                                  */
    /********************************************************************/

INLINE BOOLEAN SPINLOCK::ClaimLock( SBIT32 Sleep )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	REGISTER SBIT32 ThreadId = GetThreadId();

	//
	//   We may already own the spin lock.  If so
	//   we increment the recursive count.  If not 
	//   we have to wait.
	//
	if ( Owner != ThreadId )
		{
#endif
		//
		//   Claim the spinlock.
		//
		if ( ! ClaimSpinlock( & Spinlock ) )
			{
			//
			//   We have to wait.  If we are not 
			//   allowed to sleep or we have timed
			//   out then exit.
			//
			if ( (Sleep == 0) || (! WaitForLock( Sleep )) )
				{ return False; }
			}
#ifdef ENABLE_RECURSIVE_LOCKS

		//
		//   Register the new owner of the lock.
		//
		NewExclusiveOwner( ThreadId );
		}
	else
		{ Recursive ++; }
#endif
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
	(VOID) AtomicIncrement( & TotalLocks );
#endif

    return True;
    }
#ifdef ENABLE_RECURSIVE_LOCKS

    /********************************************************************/
    /*                                                                  */
    /*   New exclusive owner.                                           */
    /*                                                                  */
    /*   Delete the exclusive lock owner information.                   */
    /*                                                                  */
    /********************************************************************/

INLINE VOID SPINLOCK::DeleteExclusiveOwner( VOID )
    {
#ifdef DEBUGGING
	if ( Owner != NULL )
		{ 
#endif
		Owner = NULL; 
#ifdef DEBUGGING
		}
	else
		{ Failure( "Sharelock has no owner in DeleteExclusiveOwner" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   New exclusive owner.                                           */
    /*                                                                  */
    /*   Register new exclusive lock owner information.                 */
    /*                                                                  */
    /********************************************************************/

INLINE VOID SPINLOCK::NewExclusiveOwner( SBIT32 NewOwner )
    {
#ifdef DEBUGGING
	if ( Owner == NULL )
		{ 
#endif
		Owner = NewOwner; 
#ifdef DEBUGGING
		}
	else
		{ Failure( "Already exclusive in NewExclusiveOwner" ); }
#endif
    }
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Release the spinlock.                                          */
    /*                                                                  */
    /*   Release the lock and if needed wakeup any sleepers.            */
    /*                                                                  */
    /********************************************************************/

INLINE VOID SPINLOCK::ReleaseLock( VOID )
    {
#ifdef ENABLE_RECURSIVE_LOCKS
	//
	//   When we have recursive lock calls we do not 
	//   release the lock until we have exited to the 
	//   top level.
	//
	if ( Recursive <= 0 )
		{
		//
		//   Delete the exclusive owner information.
		//
		DeleteExclusiveOwner();
#endif
#ifdef DEBUGGING

		//
		//   Release the spinlock.
		//
		if ( AtomicExchange( & Spinlock, LockOpen ) == LockClosed )
			{
#else
			(VOID) AtomicExchange( & Spinlock, LockOpen );
#endif

			//
			//   Wakeup anyone who is asleep waiting.
			//
			if ( Waiting > 0 )
				{ WakeAllSleepers(); }
#ifdef DEBUGGING
			}
		else
			{ Failure( "Spinlock released by not held in ReleaseLock" ); } 
#endif
#ifdef ENABLE_RECURSIVE_LOCKS
		}
	else
		{ Recursive --; }
#endif
    }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\spinlock.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new lock and initialize it.  This call is not         */
    /*   thread safe and should only be made in a single thread         */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

SPINLOCK::SPINLOCK( SBIT32 NewMaxSpins,SBIT32 NewMaxUsers )
    {
	//
	//   Set the initial state.
	//
	MaxSpins = NewMaxSpins;
	MaxUsers = NewMaxUsers;
#ifdef ENABLE_RECURSIVE_LOCKS
	Owner = NULL;
	Recursive = 0;
#endif
    Spinlock = LockOpen;
	Semaphore = NULL;
    Waiting = 0;
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Zero the lock statistics.
	//
    TotalLocks = 0;
    TotalSleeps = 0;
    TotalSpins = 0;
    TotalTimeouts = 0;
    TotalWaits = 0;
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Update the semahore.                                           */
    /*                                                                  */
    /*   We only create the semaphore on first use.  So when we need    */
    /*   need to create a new semaphore any thread that is trying       */
    /*   to sleep on it comes here.                                     */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SPINLOCK::UpdateSemaphore( VOID )
    {
	STATIC SBIT32 Active = 0;

	//
	//   We verify that there is still no semaphore
	//   otherwise we exit.
	//
	while ( Semaphore == NULL )
		{
		//
		//   We increment the active count and if we
		//   are first we are selected for special duty.
		//
		if ( (AtomicIncrement( & Active ) == 1) && (Semaphore == NULL) )
			{
			//
			//   We try to create a new semaphore.  If
			//   we fail we still exit.
			//   
			Semaphore = CreateSemaphore( NULL,0,MaxUsers,NULL );

			//
			//  Decrement the active count and exit.
			//
			AtomicDecrement( & Active );

			return (Semaphore != NULL);
			}
		else
			{ 
			//
			//  Decrement the active count and exit.
			//
			AtomicDecrement( & Active );

			Sleep( 1 ); 
			}
		}

	return True;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Wait for the spinlock.                                         */
    /*                                                                  */
    /*   Wait for the spinlock to become free and then claim it.        */
    /*                                                                  */
    /********************************************************************/

BOOLEAN SPINLOCK::WaitForLock( SBIT32 Sleep )
    {
	REGISTER LONG Cpus = ((LONG) NumberOfCpus());
#ifdef ENABLE_LOCK_STATISTICS
    REGISTER SBIT32 Sleeps = 0;
    REGISTER SBIT32 Spins = 0;
    REGISTER SBIT32 Waits = 0;

#endif
    do
        {
        REGISTER SBIT32 Count;
        
		//
		//   If there are already more threads waiting 
		//   than the number of CPUs then the odds of 
		//   getting the lock by spinning are slim, when 
		//   there is only one CPU the chance is zero, so 
		//   just bypass this step.
		//
		if ( (Cpus > 1) && (Cpus > Waiting) )
			{
			//
			//   Wait by spinning and repeatedly testing the
			//   spinlock.  We exit when the lock becomes free 
			//   or the spin limit is exceeded.
			//
			for 
				( 
					Count = MaxSpins;
					(Count > 0) && (Spinlock != LockOpen);
					Count -- 
				);
#ifdef ENABLE_LOCK_STATISTICS

			//
			//   Update the statistics.
			//
			Spins += (MaxSpins - Count);
			Waits ++;
#endif
			}
		else
			{ Count = 0; }

		//
		//   We have exhusted our spin count so it is time to
		//   sleep waiting for the lock to clear.
		//
        if ( Count == 0 )
            {
			//
			//   We do not create the semaphore until  
			//   somebody tries to sleep on it for the 
			//   first time.  We would normally hope
			//   to find a semaphore avaiable ready
			//   for a sleep but the OS may decline the 
			//   request.  If this is the case try the
			//   lock again.
			//
			if ( (Semaphore != NULL) || (UpdateSemaphore()) )
				{
				//
				//   The lock is still closed so lets go to sleep on 
				//   a semaphore.  However, we must first increment
				//   the waiting count and test the lock one last time
				//   to make sure it is still busy and there is someone
				//   to wake us up later.
				//
				(VOID) AtomicIncrement( & Waiting );

				if ( ! ClaimSpinlock( & Spinlock ) )
					{
					if 
							( 
							WaitForSingleObject( Semaphore, Sleep ) 
								!= 
							WAIT_OBJECT_0 
							)
						{
#ifdef ENABLE_LOCK_STATISTICS
						//
						//   Count the number of times we have  
						//   timed out on this lock.
						//
						(VOID) AtomicIncrement( & TotalTimeouts );

#endif
						return False; 
						}
#ifdef ENABLE_LOCK_STATISTICS

					//
					//   Update the statistics.
					//
					Sleeps ++;
#endif
					}
				else
					{
					//
					//   Lucky - got the lock on the last attempt.
					//   Hence, lets decrement the sleep count and
					//   exit.
					// 
					(VOID) AtomicDecrement( & Waiting );
                
					break; 
					}
				}
            }
        }
    while ( ! ClaimSpinlock( & Spinlock ) );
#ifdef ENABLE_LOCK_STATISTICS

	//
	//   Update the statistics.
	//
    TotalSleeps += Sleeps;
    TotalSpins += Spins;
    TotalWaits += Waits;
#endif

    return True;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Wake all sleepers.                                             */
    /*                                                                  */
    /*   Wake all the sleepers who are waiting for the spinlock.        */
    /*   All sleepers are woken because this is much more efficent      */
    /*   and it is known that the lock latency is short.                */
    /*                                                                  */
    /********************************************************************/

VOID SPINLOCK::WakeAllSleepers( VOID )
    {
    REGISTER SBIT32 Wakeup = AtomicExchange( & Waiting, 0 );

	//
	//   We make sure there is still someone to be woken 
	//   up if not we check that the count has not become
	//   negative.
	//
    if ( Wakeup > 0 )
        {
		REGISTER SBIT32 Cpus = ((LONG) NumberOfCpus());

		//
		//   We will only wake enough threads to ensure that 
		//   there is one active thread per CPU.  So if an 
		//   application has hundreds of threads we will try 
		//   prevent the system from becoming swampped.
		//
		if ( Wakeup > Cpus )
			{
			(VOID) AtomicAdd( & Waiting,(Wakeup - Cpus) );
			Wakeup = Cpus; 
			}

        //
        //   Wake some sleepers as the lock has just been freed.
        //   It is a straight race to decide who gets the lock next.
        //
        if ( ! ReleaseSemaphore( Semaphore, Wakeup, NULL ) )
            { Failure( "Wakeup failed in WakeAllSleepers()" ); }
        }
    else
        {
        //
        //   When multiple threads pass through the critical  
        //   section it is possible for the 'Waiting' count  
		//   to become negative.  This should be very rare but 
		//   such a negative value needs to be preserved. 
        //
		if ( Wakeup < 0 )
			{ (VOID) AtomicAdd( & Waiting, Wakeup ); }
        }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a lock.  This call is not thread safe and should       */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

SPINLOCK::~SPINLOCK( VOID )
    {
#ifdef ENABLE_LOCK_STATISTICS
	//
	//   Print the lock statistics.
	//
	DebugPrint
		(
		"Spinlock: %d locks, %d timeouts, %d locks per wait, "
		"%d spins per wait, %d waits per sleep.\n",
		TotalLocks,
		TotalTimeouts,
		(TotalLocks / ((TotalWaits <= 0) ? 1 : TotalWaits)),
		(TotalSpins / ((TotalWaits <= 0) ? 1 : TotalWaits)),
		(TotalWaits / ((TotalSleeps <= 0) ? 1 : TotalSleeps))
		);

#endif
	//
	//   Close the semaphore handle.
	//
    if ( (Semaphore != NULL) && (! CloseHandle( Semaphore )) )
        { Failure( "Close semaphore in destructor for SPINLOCK" ); }
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\string.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Delay.hpp"
#include "String.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Static member initialization.                                  */
    /*                                                                  */
    /*   Static member initialization sets the initial value for all    */
    /*   static members.                                                */
    /*                                                                  */
    /********************************************************************/

#pragma init_seg(lib)
#ifdef DISABLE_STRING_LOCKS
UNIQUE<NO_LOCK> *STRING::Unique;
#else
SPINLOCK STRING::Spinlock;
UNIQUE<FULL_LOCK> *STRING::Unique = NULL;
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Create the string table.                                       */
    /*                                                                  */
    /*   We create the string table on first use.  This is tricky as    */
    /*   we may have created multiple threads so we must be careful     */
    /*   to avoid race conditions.  We also arrang for the string table */
    /*   to be deleted at the end of the run unit.                      */
    /*                                                                  */
    /********************************************************************/

VOID STRING::CreateStringTable( VOID )
	{
#ifdef DISABLE_STRING_LOCKS
	STATIC DELAY<UNIQUE<NO_LOCK>> Delay;

	//
	//   Create the new string table.
	//
	Unique = new UNIQUE<NO_LOCK>;

	//
	//   Register the string table for deletion at
	//   at the end of the run unit.
	//
	Delay.DeferedDelete( Unique );
#else
	//
	//   Claim a lock to avoid race conditions.
	//
	Spinlock.ClaimLock();

	//
	//   If the string table still does not exist
	//   then create it.
	//
	if ( Unique == NULL )
		{
		STATIC DELAY< UNIQUE<FULL_LOCK> > Delay;

		//
		//   Create the new string table.
		//
		Unique = new UNIQUE<FULL_LOCK>;

		//
		//   Register the string table for deletion at
		//   at the end of the run unit.
		//
		Delay.DeferedDelete( Unique );
		}

	//
	//   Release the lock.
	//
	Spinlock.ReleaseLock();
#endif
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\system.hpp ===
#ifndef _SYSTEM_HPP_
#define _SYSTEM_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard system include files.                             */
    /*                                                                  */
    /*   The standard system include files contain various definitions  */
    /*   used throughout the system.                                    */
    /*                                                                  */
    /********************************************************************/

#include <conio.h>
#include <iostream>
#include <stdarg.h>
#include <stddef.h>
#include <stdio.h>
#include <stdlib.h>
#include <malloc.h>
#include <new.h>
#include <process.h>
#include <time.h>
#include <winsock2.h>
#include <windows.h>

    /********************************************************************/
    /*                                                                  */
    /*   Automatically set the debugging flag if needed.                */
    /*                                                                  */
    /*   There are various standards for enabling dedugging code.       */
    /*   Here we translate on to the standard used in this              */
    /*   application.                                                   */
    /*                                                                  */
    /********************************************************************/

#ifdef _M_IX86
#define ASSEMBLY_X86				  1
#endif

#ifdef _DEBUG
#define DEBUGGING                     1
#endif

#ifdef UNICODE
#undef CreateSemaphore
#undef OutputDebugString

#define CreateSemaphore				  CreateSemaphoreA
#define OutputDebugString			  OutputDebugStringA
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Automatically disable anoying warnings.                        */
    /*                                                                  */
    /*   Some of the VC compiler warning are not very helpful so        */
    /*   we disable them here.                                          */
    /*                                                                  */
    /********************************************************************/

#ifndef ALL_COMPLAINTS
#pragma warning( disable : 4073 )
#pragma warning( disable : 4074 )
#pragma warning( disable : 4097 )
#pragma warning( disable : 4100 )
#pragma warning( disable : 4121 )
#pragma warning( disable : 4127 )
#pragma warning( disable : 4291 )
#pragma warning( disable : 4509 )
#pragma warning( disable : 4511 )
#pragma warning( disable : 4512 )
#pragma warning( disable : 4514 )
#pragma warning( disable : 4701 )
#pragma warning( disable : 4702 )
#pragma warning( disable : 4706 )
#pragma warning( disable : 4710 )
#pragma warning( disable : 4711 )
#pragma warning( disable : 4800 )
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\string.hpp ===
#ifndef _STRING_HPP_
#define _STRING_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Lock.hpp"
#include "Spinlock.hpp"
#include "Unique.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A string class.                                                */
    /*                                                                  */
    /*   A typical string class manages variable length text strings.   */
    /*   Although we support the same in this class we ensure that      */
    /*   there is only one copy of every unique string.  There is a     */
    /*   cost associated with this at string creation time but a big    */
    /*   win when the strings are heavily compared, copied or           */
    /*   replicated.                                                    */
    /*                                                                  */
    /********************************************************************/

class STRING
    {
        //
        //   Private data.
        //
        DETAIL						  *Detail;

        //
        //   Static private data.
        //
#ifdef DISABLE_STRING_LOCKS
		STATIC UNIQUE<NO_LOCK>		  *Unique;
#else
		STATIC SPINLOCK				  Spinlock;
		STATIC UNIQUE<FULL_LOCK>	  *Unique;
#endif

    public:
		//
		//   Public inline functions.
		//
        STRING( VOID )
			{ DefaultString(); }

        STRING( CHAR *String )
			{ CreateString( String,strlen( String ) ); }

        STRING( CHAR *String,SBIT32 Size )
			{ CreateString( String,Size ); }

        STRING( CONST STRING & Update )
			{ Detail = Unique -> CopyString( DefaultString(),Update.Detail ); }

        INLINE VOID operator=( CONST STRING & Update )
			{ Detail = Unique -> CopyString( Detail,Update.Detail ); }

        INLINE BOOLEAN operator==( CONST STRING & String )
			{ return (Detail == String.Detail); }

        INLINE BOOLEAN operator!=( CONST STRING & String )
			{ return (Detail != String.Detail); }

        INLINE BOOLEAN operator<( CONST STRING & String )
			{ return (Unique -> CompareStrings( Detail,String.Detail ) < 0); }

        INLINE BOOLEAN operator<=( CONST STRING & String )
			{ return (Unique -> CompareStrings( Detail,String.Detail ) <= 0); }

        INLINE BOOLEAN operator>( CONST STRING & String )
			{ return (Unique -> CompareStrings( Detail,String.Detail ) > 0); }

        INLINE BOOLEAN operator>=( CONST STRING & String )
			{ return (Unique -> CompareStrings( Detail,String.Detail ) >= 0); }

		INLINE SBIT32 Size( VOID )
			{ return Unique -> Size( Detail ); }

		INLINE CHAR *Value( VOID )
			{ return Unique -> Value( Detail ); }

		INLINE SBIT32 ValueID( VOID )
			{ return ((SBIT32) Detail); }

        ~STRING( VOID )
			{ DeleteString(); }

	private:
		//
		//   Private functions.
		//
		VOID CreateStringTable( VOID );

		//
		//   Private inline functions.
		//
		DETAIL *CreateString( CHAR *String,SBIT32 Size )
			{
			VerifyStringTable();

			return (Detail = Unique -> CreateString( String,Size ));
			}

        DETAIL *DefaultString( VOID )
			{
			VerifyStringTable();

			return (Detail = Unique -> DefaultString()); 
			}

        VOID DeleteString( VOID )
			{
			if ( Unique != NULL )
				{ Unique -> DeleteString( Detail ); }
			}

		VOID VerifyStringTable( VOID )
			{
			if ( Unique == NULL )
				{ CreateStringTable(); }
			}
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\thread.hpp ===
#ifndef _THREAD_HPP_
#define _THREAD_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Environment.hpp"
#include "Spinlock.hpp"
#include "Vector.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Data structures exported from the class.                       */
    /*                                                                  */
    /*   A thread started by this class should conform to the type      */
    /*   specification given here.                                      */
    /*                                                                  */
    /********************************************************************/

typedef VOID (*NEW_THREAD)( VOID *Parameter );

    /********************************************************************/
    /*                                                                  */
    /*   Thread synchronization.                                        */
    /*                                                                  */
    /*   This class privides a method for synchronizing a number        */
    /*   of worker threads with a master thread.  Each time the         */
    /*   master thread calls 'StartThread()' a new thread is created.   */
    /*   When a thread calls 'EndThread()' the thread is terminated.    */
    /*   At any point the master thread can enquire about the number    */
    /*   of active threads or wait for them to complete.                */
    /*                                                                  */
    /********************************************************************/

class THREAD : public ENVIRONMENT
    {
    public:
		//
		//   Public data.
		//
		BOOLEAN						  Active;

        SBIT32						  ActiveThreads;
        SBIT32						  MaxThreads;
        VECTOR<HANDLE>				  Threads;

        BOOLEAN                       Affinity;
        VOLATILE SBIT16               Cpu;
        BOOLEAN                       Priority;
        LONG                          Stack;

        HANDLE                        Completed;
        HANDLE                        Running;
        HANDLE                        Started;

		SPINLOCK					  Spinlock;

		NEW_THREAD					  ThreadFunction;
	    VOID						  *ThreadParameter;
		BOOLEAN						  ThreadWait;

        //
        //   Public functions.
        //
        THREAD( VOID );

        VOID EndThread( VOID );

		VOID RegisterThread( VOID );

        VOID SetThreadStackSize( LONG Stack = 0 );

        BOOLEAN StartThread
			( 
			NEW_THREAD                Function, 
			VOID                      *Parameter = NULL, 
			BOOLEAN                   Wait = True 
			);

        BOOLEAN WaitForThreads( LONG WaitTime = INFINITE );

        ~THREAD( VOID );

		//
		//   Public inline functions.
		//
        VOID SetThreadAffinity( BOOLEAN NewAffinity = True )
			{ Affinity = NewAffinity; }

        VOID SetThreadPriority( BOOLEAN NewPriority = True )
			{ Priority = NewPriority; }

	private:
        //
        //   Disabled operations.
        //
        THREAD( CONST THREAD & Copy );

        VOID operator=( CONST THREAD & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\thread.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Thread.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The thread class keeps track of active threads.                */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 ThreadsSize			  = 16;

    /********************************************************************/
    /*                                                                  */
    /*   Static functions local to the class.                           */
    /*                                                                  */
    /*   The static functions used by this class are declared here.     */
    /*                                                                  */
    /********************************************************************/

STATIC VOID CDECL MonitorThread( VOID *Parameter );
STATIC VOID CDECL NewThread( VOID *Parameter );

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a thread class and initialize it.  This call is not     */
    /*   thread safe and should only be made in a single thread         */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

THREAD::THREAD( VOID ) : 
		//
		//   Call the constructors for the contained classes.
		//
		Threads( ThreadsSize,NoAlignment,CacheLineSize )
    {
	//
	//   Setup the initial flags.
	//
	Active = True;

	//
	//   The inital configuration.
	//
	ActiveThreads = 0;
	MaxThreads = ThreadsSize;

    Affinity = False;
    Cpu = 0;
    Priority = False;
    Stack = 0;

	//
	//   This event is signaled when all threads are 
	//   complete.
	//
    if ( (Completed = CreateEvent( NULL, FALSE, FALSE, NULL )) == NULL)
        { Failure( "Create event in constructor for THREAD" ); }

	//
	//   This event is signaled when a thread is 
	//   running.
	//
    if ( (Running = CreateEvent( NULL, FALSE, FALSE, NULL )) == NULL)
        { Failure( "Create event in constructor for THREAD" ); }

	//
	//   This event is signaled when a new thread can 
	//   be started.
	//
    if ( (Started = CreateEvent( NULL, FALSE, TRUE, NULL )) == NULL)
        { Failure( "Create event in constructor for THREAD" ); }

	//
	//   A thread is started whos job in life is to monitor
	//   all the other threads.
	//
	if ( _beginthread( MonitorThread,0,((VOID*) this) ) == NULL )
        { Failure( "Monitor thread in constructor for THREAD" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   End a thread.                                                  */
    /*                                                                  */
    /*   Terminate the current thread.                                  */
    /*                                                                  */
    /********************************************************************/

VOID THREAD::EndThread( VOID )
	{ _endthread(); }

    /********************************************************************/
    /*                                                                  */
    /*   The monitor thread.                                            */
    /*                                                                  */
    /*   The monitor thread simply watches the lifetimes of all the     */
    /*   other threads in the process.                                  */
    /*                                                                  */
    /********************************************************************/

STATIC VOID CDECL MonitorThread( VOID *Parameter )
    {
	AUTO SBIT32 Current = 0;
	REGISTER THREAD *Thread = ((THREAD*) Parameter);

	//
	//   The monitor thread only remains active while 
	//   the class is active.
	//
	while ( Thread -> Active )
		{
		//
		//   There is little point in trying to sleep
		//   on a thread handle if no threads are active.
		//
		if ( Thread -> ActiveThreads > 0 )
			{
			REGISTER DWORD Status = 
				(WaitForSingleObject( Thread -> Threads[ Current ],1 ));

			//
			//   Claim a spinlock so we can update the 
			//   thread table.
			//
			Thread -> Spinlock.ClaimLock();

			//
			//   A wait can terminate in various ways
			//   each of which is dealt with here.
			//
			switch ( Status )
				{
				case WAIT_OBJECT_0:
					{
					REGISTER SBIT32 *ActiveThreads = & Thread -> ActiveThreads;

					//
					//   The thread has terminated so close
					//   the thread handle.
					//
					CloseHandle( Thread -> Threads[ Current ] );

					//
					//   Delete the handle from the table
					//   if it was not the last entry.
					//
					if ( (-- (*ActiveThreads)) > 0 )
						{
						REGISTER SBIT32 Count;

						//
						//   Copy down the remaining 
						//   thread handles.
						//
						for ( Count=Current;Count < (*ActiveThreads);Count ++ )
							{						
							Thread -> Threads[ Count ] =
								Thread -> Threads[ (Count+1) ];
							}

						//
						//   We may need to wrap around to
						//   the start of the array.
						//
						Current %= (*ActiveThreads);
						}
					else
						{ SetEvent( Thread -> Completed ); }

					break;
					}

				case WAIT_TIMEOUT:
					{
					//
					//   The thread is still active so try the
					//   next thread handle.
					//
					Current = ((Current + 1) % Thread -> ActiveThreads);

					break;
					}

				case WAIT_FAILED:
					{ Failure( "Wait fails in MonitorThread" ); }

				default:
					{ Failure( "Missing case in MonitorThread" ); }
				}

			//
			//   We are finished so release the lock.
			//
			Thread -> Spinlock.ReleaseLock();
			}
		else
			{ Sleep( 1 ); }
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Start a new thread.                                            */
    /*                                                                  */
    /*   When a new thread is created it executes a special initial     */
    /*   function which configures it.  When control returns to this    */
    /*   function the thread is terminated.                             */
    /*                                                                  */
    /********************************************************************/

STATIC VOID CDECL NewThread( VOID *Parameter )
    {
	REGISTER THREAD *Thread = ((THREAD*) Parameter);
	REGISTER NEW_THREAD ThreadFunction = Thread -> ThreadFunction;
	REGISTER VOID *ThreadParameter = Thread -> ThreadParameter;

    //
    //   Set the affinity mask to the next processor 
	//   if requested.
    //  
    if ( (Thread -> Affinity) && (Thread -> NumberOfCpus() > 1) )
        {
        REGISTER DWORD AffinityMask;

        if ( (Thread -> Cpu) < (Thread -> NumberOfCpus()) )
            { AffinityMask = (1 << (Thread -> Cpu ++)); }
        else
            {
            AffinityMask = 1;
            Thread -> Cpu = 1;
            }

        if ( SetThreadAffinityMask( GetCurrentThread(),AffinityMask ) == 0 )
            { Failure( "Affinity mask invalid in NewThread()" ); }
        }

    //
    //   Set the priority to 'HIGH' if requested.
    //
    if ( Thread -> Priority )
        { SetThreadPriority( GetCurrentThread(),THREAD_PRIORITY_HIGHEST ); }

	//
	//   The thread is now ready so add it to the table
	//   executiong threads.
	//
	Thread -> RegisterThread();

	//
	//   Wake up anyone who is waiting.
	//
	if ( Thread -> ThreadWait )
		{ SetEvent( Thread -> Running ); }

	SetEvent( Thread -> Started );

    //
    //   Call the thread function.
    //
    ThreadFunction( ThreadParameter );

    //
    //   The thread function has returned so exit.
    //
    Thread -> EndThread();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Register the current thread.                                   */
    /*                                                                  */
    /*   When a thread has created we can add the thread info to        */
    /*   our internal table.                                            */
    /*                                                                  */
    /********************************************************************/

VOID THREAD::RegisterThread( VOID )
    {
	AUTO HANDLE NewHandle;
	REGISTER HANDLE Process = GetCurrentProcess();
	REGISTER HANDLE Thread = GetCurrentThread();

	//
	//   Claim a spinlock so we can update the 
	//   thread table.
	//
	Spinlock.ClaimLock();

	//
	//   We need to duplicate the handle so we get
	//   a real thread handle and not the pretend
	//   ones supplied by NT.
	//
	if
			(
			DuplicateHandle
				(
				Process,
				Thread,
				Process,
				& NewHandle,
				DUPLICATE_SAME_ACCESS,
				False,
				DUPLICATE_SAME_ACCESS
				)
			)
		{
		//
		//   We may need to expand the table if there are
		//   a large number of threads.
		//
		while ( ActiveThreads >= MaxThreads )
			{ Threads.Resize( (MaxThreads *= ExpandStore) ); }

		//
		//   Add the thread handle to the table.
		//
		Threads[ ActiveThreads ++ ] = NewHandle;
		}
	else
		{ Failure( "Failed to duplicate handle in RegisterThread" ); }

	//
	//   We are finished so release the lock.
	//
	Spinlock.ReleaseLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Set thread stack size.                                         */
    /*                                                                  */
    /*   Set thread stack size.  This will cause all new threads to     */
    /*   be created with the selected stack size.                       */
    /*                                                                  */
    /********************************************************************/

VOID THREAD::SetThreadStackSize( LONG Stack ) 
    {
#ifdef DEBUGGING
    if ( Stack >= 0 )
        {
#endif
        this -> Stack = Stack;
#ifdef DEBUGGING
        }
    else
        { Failure( "Stack size in SetThreadStack()" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Start a new thread.                                            */
    /*                                                                  */
    /*   Start a new thread and configure it as requested by the        */
    /*   caller.  If needed we will set the affinity and priority       */
    /*   of this thread later.                                          */
    /*                                                                  */
    /********************************************************************/

BOOLEAN THREAD::StartThread( NEW_THREAD Function,VOID *Parameter,BOOLEAN Wait )
    {
	//
	//   Wait for any pending thread creations to
	//   complete.
	//
    if ( WaitForSingleObject( Started,INFINITE ) == WAIT_OBJECT_0 )
		{
		REGISTER unsigned NewStack = ((unsigned) Stack);

		//
		//   Store the thread function and parameter
		//   so they can be extracted later.
		//
		ThreadFunction = Function;
		ThreadParameter = Parameter;
		ThreadWait = Wait;

		//
		//   Call the operating system to start the thread.
		//
		if ( _beginthread( NewThread,NewStack,((VOID*) this) ) != NULL )
			{
			//
			//   Wait for the thread to initialize if needed.
			//
			return
				(
				(! Wait)
					||
				(WaitForSingleObject( Running,INFINITE ) == WAIT_OBJECT_0)
				);
			}
		else
			{ return False; }
		}
	else
		{ return False; }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Wait for threads.                                              */
    /*                                                                  */
    /*   Wait for all threads to finish and then return.  As this may   */
    /*   take a while an optional timeout may be supplied.              */
    /*                                                                  */
    /********************************************************************/

BOOLEAN THREAD::WaitForThreads( LONG WaitTime )
    {
	REGISTER DWORD Wait = ((DWORD) WaitTime);

	return ( WaitForSingleObject( Completed,Wait ) != WAIT_TIMEOUT );
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the thread class.  This call is not thread safe        */
    /*   and should only be made in a single thread environment.        */
    /*                                                                  */
    /********************************************************************/

THREAD::~THREAD( VOID )
    {
	Active = False;

	if 
			(
			! CloseHandle( Started )
				||
			! CloseHandle( Running )
				||
			! CloseHandle( Completed )
			)
		{ Failure( "Event handles in destructor for THREAD" ); }
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\ticket.hpp ===
#ifndef _TICKET_HPP_
#define _TICKET_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Lock.hpp"
#include "Vector.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The ticket constants specify the initial size of the           */
    /*   ticket array.                                                  */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 TicketSize			  = 128;

    /********************************************************************/
    /*                                                                  */
    /*   Ticketing to maintain ordering.                                */
    /*                                                                  */
    /*   This class provides general purpose event ordering so          */
    /*   that events can arrive in any order but processed in           */
    /*   sequential order with a minimal amount of fuss.                */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK=NO_LOCK> class TICKET : public LOCK
    {
		//
		//   Private data structure.
		//
		typedef struct
			{
			BOOLEAN					  Available;
			TYPE					  Data;
			}
		STUB;

        //
        //   Private data.
        //
        SBIT32						  MaxSize;

        SBIT32						  Back;
        SBIT32						  Front;

        SBIT32						  Base;
        SBIT32						  Stride;

        VECTOR<STUB>				  Ticket;

    public:
        //
        //   Public functions.
        //
        TICKET
			( 
			SBIT32					  Start = 0,
			SBIT32					  NewMaxSize = TicketSize,
			SBIT32					  NewStride = 1  
			);

		BOOLEAN CollectTicket( TYPE *Data,SBIT32 *Ticket );

		SBIT32 NumberOfTickets( VOID );

		SBIT32 NewTicket( VOID );

		BOOLEAN PunchTicket( CONST TYPE & Data,SBIT32 Ticket );

        ~TICKET( VOID );

		//
		//   Public inline functions.
		//
		SBIT32 LowestOutstandingTicket( VOID )
			{ return Base; }

	private:

        //
        //   Disabled operations.
        //
        TICKET( CONST TICKET & Copy );

        VOID operator=( CONST TICKET & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new ticket queue and prepare it for use.  This call   */
    /*   is not thread safe and should only be made in a single thread  */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> TICKET<TYPE,LOCK>::TICKET
		( 
		SBIT32						  Start,
		SBIT32						  NewMaxSize,
		SBIT32						  NewStride
		) : 
		//
		//   Call the constructors for the contained classes.
		//
		Queue( NewMaxSize,1,CacheLineSize )
    {
#ifdef DEBUGGING
    if ( NewMaxSize > 0 )
        {
#endif
		//
		//   Setup the control information.
		//
        MaxSize = NewMaxSize;

		//
		//   Setup the queue so it is empty.
		//
        Back = 0;
        Front = 0;

		//
		//   Set the initial ticket number.
		//
		Base = Start;
		Stride = NewStride;
#ifdef DEBUGGING
        }
    else
        { Failure( "MaxSize in constructor for TICKET" ); }
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Issue a new ticket.                                            */
    /*                                                                  */
    /*   We issue a new ticket and allocate a place in the line.  We    */
    /*   also we reserve space in the ticket queue.                     */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> SBIT32 TICKET<TYPE,LOCK>::NewTicket( VOID )
    {
	REGISTER SBIT32 Result;

	//
	//   Claim an exclisive lock (if enabled).
	//
    ClaimExclusiveLock();

    //
    //   Add element to the queue.  If necessary wrap round 
    //   to the front of the array.
    //
    Ticket[ Back ++ ].Available = False;

     if ( Back >= MaxSize )
        { Back = 0; }

	//
	//   Compute the ticket number.
	//
	Result = (Base + (NumberOfTickets() * Stride));

    //
    //   Verify that the queue is not full.  If it is full then 
    //   double its size and copy wrapped data to the correct
    //   position in the new array.
    //
    if ( Front == Back )
		{
		REGISTER SBIT32 Count;
		REGISTER SBIT32 NewSize = (MaxSize * ExpandStore);

		//
		//   Expand the queue (it will be at least doubled).
		//
		Ticket.Resize( NewSize );

		//
		//   Copy the tail end of the queue to the correct
		//   place in the expanded queue.
		//
		for ( Count = 0;Count < Back;Count ++ )
			{ Ticket[ (MaxSize + Count) ] = Ticket[ Count ]; }

		//
		//   Update the control information.
		//
		Back += MaxSize;
		MaxSize = NewSize;
		}

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Punch a ticket and store any associated data.                  */
    /*                                                                  */
    /*   We punch a ticket so it can be collected and store any         */
    /*   related data.                                                  */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN TICKET<TYPE,LOCK>::PunchTicket
		( 
		CONST TYPE					  & Data,
		SBIT32						  Ticket
		)
    {
    REGISTER BOOLEAN Result;
	REGISTER SBIT32 TicketOffset;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   Compute the offset in the ticket array.
	//
	TicketOffset = ((Ticket - Base) / Stride);

	//
	//   Ensure the ticket refers to and active ticket
	//   that has not already been recycled.
	//
	if ( (TicketOffset >= 0) && (TicketOffset < NumberOfTickets()) )
		{
		REGISTER STUB *Stub = & Ticket[ TicketOffset ];

		//
		//   Ensure the ticket has not already been
		//   punched.
		//
		if ( ! Stub -> Available )
			{
			Stub -> Available = True;
			Stub -> Data = Data;

			Result = True;
			}
		else
			{ Result = False; }
        }
    else
        { Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

    return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Collect the lowest numbered ticket.                            */
    /*                                                                  */
    /*   We try to collect the lowest numbered ticket that has been     */
    /*   issued.  If it is has been punched and is available we         */
    /*   recycle it after returning any associated data to the caller.  */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> BOOLEAN TICKET<TYPE,LOCK>::CollectTicket
		( 
		TYPE						  *Data,
		SBIT32						  *Ticket
		)
    {
    REGISTER BOOLEAN Result;

	//
	//   Claim an exclusive lock (if enabled).
	//
    ClaimExclusiveLock();

	//
	//   We make sure the ticket queue is not empty.
	//
    if ( Front != Back )
        {
		REGISTER STUB *Stub = & Ticket[ Front ];

		//
		//   We can collect the first ticket in the
		//   ticket queue if it has been punched.
		//
		if ( Stub -> Available )
			{
			//
			//   We have an ticket ready so return it to 
			//   the caller.  If we walk off the end of  
			//   the ticket queue then wrap to the other
			//   end.
			//
			(*Data) = Stub -> Data;
			(*Ticket) = (Base += Stride);

			if ( (++ Front) >= MaxSize )
				{ Front = 0; }

			Result = True;
			}
		else
			{ Result = False; }
        }
    else
        { Result = False; }

	//
	//   Release any lock we claimed earlier.
	//
    ReleaseExclusiveLock();

    return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Calculate the size of the reorder queue.                       */
    /*                                                                  */
    /*   Calculate the size of the queue and return it to the caller.   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> SBIT32 TICKET<TYPE,LOCK>::NumberOfTickets( VOID )
    {
    REGISTER SBIT32 Size;

	//
	//   Compute the size of the reorder queue.
	//
	Size = (Back - Front);

	//
	//   If the queue has wrapped then adjust as needed.
	//
	if ( Size < 0 )
		{ Size += MaxSize; }

    return Size;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a queue.  This call is not thread safe and should      */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE,class LOCK> TICKET<TYPE,LOCK>::~TICKET( VOID )
    { /* void */ }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\objd\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_xhash_none_12.4.56.0_none_f51832dadf665cc4
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=xhash
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c.manifest
XP_MANIFEST_PATH=manifests\x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c.cat
XP_CATALOG_PATH=manifests\x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c.cat
XP_PAYLOAD_PATH=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=xhash,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\obj\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_xhash_none_12.4.56.0_none_f51832dadf665cc4
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=xhash
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c.manifest
XP_MANIFEST_PATH=manifests\x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c.cat
XP_CATALOG_PATH=manifests\x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c.cat
XP_PAYLOAD_PATH=x86_xhash_no-public-key_12.4.56.0_x-ww_37c3a93c
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=xhash,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\tlc.hpp ===
#ifndef _TLC_HPP_
#define _TLC_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "List.hpp"
#include "Spinlock.hpp"
#include "Tls.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A thread local class.                                          */
    /*                                                                  */
    /*   A significant number of SMP applications need thread local     */
    /*   data structures.  Here we support the automatic creation       */
    /*   and management of such structures.                             */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> class TLC
    {
        //
        //   Private data.
        //
		LIST						  ActiveList;
		LIST						  FreeList;
	    SPINLOCK					  Spinlock;
		TLS							  Tls;

    public:
        //
        //   Public functions.
        //
        TLC( VOID );

        ~TLC( VOID );

		//
		//   Public inline functions.
		//
		INLINE TYPE *GetPointer( VOID )
			{
			REGISTER LIST *Class = ((LIST*) Tls.GetPointer());

			return ((Class != NULL) ? ((TYPE*) & Class[1]) : CreateClass());
			}

		INLINE VOID Delete( VOID )
			{
			REGISTER LIST *Class = ((LIST*) Tls.GetPointer());

			if ( Class != NULL )
				{ DeleteClass( Class ); }
			}

	private:
		//
		//   Private functions.
		//
		TYPE *CreateClass( VOID );

		VOID DeleteClass( LIST *Class );

        //
        //   Disabled operations.
        //
        TLC( CONST TLC & Copy );

        VOID operator=( CONST TLC & Copy );
    };
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a thread private management class.  This call is        */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> TLC<TYPE>::TLC( VOID )
	{ /* void */ }

    /********************************************************************/
    /*                                                                  */
    /*   Create a new class.                                            */
    /*                                                                  */
    /*   Create a new private class and store a pointer to it in        */
    /*   the thread local store.                                        */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> TYPE *TLC<TYPE>::CreateClass( VOID )
	{
	REGISTER LIST *Class;

	//
	//   Claim a spinlock just in case multiple
	//   threads are active.
	//
	Spinlock.ClaimLock();

	//
	//   We are more than happy to use any existing
	//   memory allocation from the free list if
	//   one is available.
	//
	Class = FreeList.First();

	//
	//   If the free list is empty we create a new
	//   class using the memory allocator.  If it is
	//   not empty we delete the first element from
	//   the list.
	//
	if ( Class == NULL )
		{
		REGISTER SBIT32 TotalSize = (sizeof(LIST) + sizeof(TYPE));

		//
		//   Cache align the size.  This may look
		//   like a waste of time but is worth
		//   30% in some cases when we are correctly
		//   aligned.
		//
		TotalSize = ((TotalSize + CacheLineMask) & ~CacheLineMask);

		Class = ((LIST*) new CHAR [ TotalSize ]); 
		}
	else
		{ Class -> Delete( & FreeList ); }

	PLACEMENT_NEW( & Class[0],LIST );

	//
	//   We need to add the new class to the active
	//   list so we can rememebr to delete it later.
	//
	Class -> Insert( & ActiveList );

	//
	//   Relaese the lock we claimed earlier.
	//
	Spinlock.ReleaseLock();

	//
	//   Finally, update the TLS pointer and call the
	//   class constructor to get everything ready for
	//   use.
	//
	Tls.SetPointer( Class );

	PLACEMENT_NEW( & Class[1],TYPE );

	return ((TYPE*) & Class[1]);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete a class.                                                */
    /*                                                                  */
    /*   We may need to delete a thread local class in some situations  */
    /*   so here we call the destructor and recycle the memory.         */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VOID TLC<TYPE>::DeleteClass( LIST *Class )
	{
	//
	//   Call the destructor for clean up.
	//
	PLACEMENT_DELETE( & Class[1],TYPE );

	//
	//   Claim a spinlock just in case multiple
	//   threads are active.
	//
	Spinlock.Claimlock();

	//
	//   Call the destructor for clean up.
	//
	PLACEMENT_DELETE( & Class[0],LIST );

	//
	//   Move the element from the active list
	//   to the free list.
	//
	Class -> Delete( & ActiveList );

	Class -> Insert( & FreeList );

	//
	//   Relaese the lock we claimed earlier.
	//
	Spinlock.ReleaseLock();

	//
	//   Finally, zero the TLS pointer.
	//
	Tls.SetPointer( NULL );
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destroy a thread private management class.  This call is       */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> TLC<TYPE>::~TLC( VOID )
	{
	REGISTER LIST *Current;

	//
	//   Walk the list of active classes and release
	//   them back to the heap.
	//
	for 
			( 
			Current = ActiveList.First();
			Current != NULL;
			Current = ActiveList.First()
			)
		{
		//
		//   Call the destructor, remove the element
		//   from the active list and free it.
		//
		PLACEMENT_DELETE( (Current + 1),TYPE );

		Current -> Delete( & ActiveList );

		delete [] ((CHAR*) Current);
		}

	//
	//   Walk the list of free classes and release
	//   them back to the heap.
	//
	for 
			( 
			Current = FreeList.First();
			Current != NULL;
			Current = FreeList.First()
			)
		{
		//
		//   Remove the element from the free list  
		//   and free it.
		//
		Current -> Delete( & FreeList );

		delete [] Current;
		}
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\tls.hpp ===
#ifndef _TLS_HPP_
#define _TLS_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Assembly.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The environment constants indicate the state of thread         */
    /*   local store.                                                   */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 NoTLSMemory			  = -1;
CONST SBIT32 NoTLSStructure			  = 0;

#ifdef ENABLE_NON_STANDARD_ASSEMBLY
CONST SBIT32 MaxTlsIndex			  = 64;
#else
CONST SBIT32 MaxTlsIndex			  = 1088;
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Thread local store.                                            */
    /*                                                                  */
    /*   A wide range of applications use threads.  It is often very    */
    /*   valuable to be able to have some private per thread data.      */
    /*   This functionality is supported by the following class.        */
    /*                                                                  */
    /********************************************************************/

class TLS : public ASSEMBLY
    {
        //
        //   Private data.
        //
		BOOLEAN						  Active;

		SBIT32						  TlsIndex;
		SBIT32						  TlsOffset;

    public:
        //
        //   Public functions.
        //
        TLS( VOID )
			{
			Active = ((TlsIndex = TlsAlloc()) != NoTLSMemory);

			if ( (Active) && (TlsIndex < MaxTlsIndex) )
				{ TlsOffset = ((TlsIndex * sizeof(void*)) + TebSlot); }
			else
				{ Failure( "No TLS available" ); }
			}

		INLINE BOOLEAN Available( VOID )
			{ return Active; }
#ifdef ASSEMBLY_X86
#ifdef ENABLE_NON_STANDARD_ASSEMBLY

		INLINE VOID *GetAddress( VOID )
			{ return (GetTlsAddress( TlsOffset )); }
#endif
#endif

		INLINE VOID *GetPointer( VOID )
			{ return (GetTlsValue( TlsIndex,TlsOffset )); }

		INLINE VOID SetPointer( VOID *NewPointer )
			{ SetTlsValue( TlsIndex,TlsOffset,NewPointer ); }

        ~TLS( VOID )
			{
			Active = False;

			if ( TlsIndex != NoTLSMemory )
				{ 
				if ( ! TlsFree( TlsIndex ) )
					{ Failure( "Unable to free TLS memory" ); }
				}
			}

	private:
        //
        //   Disabled operations.
        //
        TLS( CONST TLS & Copy );

        VOID operator=( CONST TLS & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\vector.hpp ===
#ifndef _VECTOR_HPP_
#define _VECTOR_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "New.hpp"
#ifdef DEBUGGING

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The constants specified here control various aspects of the    */
    /*   vector classes debugging operations.                           */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 DebugDisplaySize		  = 8;
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Vector creation, management and use.                           */
    /*                                                                  */
    /*   A vector is esentially an allocated array of data.  However,   */
    /*   vectors also have some special features.  A vector can be      */
    /*   aligned to any binary boundary and each element can also be    */
    /*   aligned to any binary boundary.  This is very helpful in       */
    /*   SMP systems as increased performance can be obtained by        */
    /*   using vectors on selected data structures.                     */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> class VECTOR
    {
        //
        //   Private data.
        //
        SBIT32                        Alignment;
        SBIT32                        Elements;
        SBIT32                        Size;

        CHAR                          *Allocated;
        CHAR                          *Aligned;
#ifdef DEBUGGING
		TYPE                          *Display[DebugDisplaySize];
#endif


    public:
        //
        //   Public functions.
        //
        VECTOR
            ( 
            SBIT32					  NumberOfElements, 
            SBIT32					  AlignSize, 
            SBIT32					  AlignStart
            );

       VECTOR
            ( 
            SBIT32					  One, 
            SBIT32					  NumberOfElements, 
            SBIT32					  AlignSize, 
            SBIT32					  AlignStart
            );

       VECTOR
            ( 
            SBIT32					  One, 
            SBIT32					  Two, 
            SBIT32					  NumberOfElements, 
            SBIT32					  AlignSize, 
            SBIT32					  AlignStart
            );

        VOID Resize( SBIT32 Reallocate );

        ~VECTOR( VOID );

		//
		//   Public inline functions.
		//
        INLINE TYPE & operator[]( SBIT32 Index )
			{
#ifdef DEBUGGING
			if ( (Index < 0) || (Index >= Elements) )
				{ Failure( "Array subscript in VECTOR[]" ); }

#endif
			return (*((TYPE*) & Aligned[ (Index * Size) ]));
			}

        INLINE TYPE *operator&( VOID )
			{ return ((TYPE*) & Aligned[0]); }

		SBIT32 SizeOfVector( VOID ) 
			{ return Elements; }

	private:
		//
		//   Private functions.
		//
        VOID AllocateAndAlignVector
            ( 
            SBIT32                        NumberOfElements, 
            SBIT32                        AlignSize, 
            SBIT32                        AlignStart
            );

		TYPE & ComputeAddressWithMultiply( SBIT32 Index );

		TYPE & ComputeAddressWithShift( SBIT32 Index );

        //
        //   Disabled operations.
        //
        VECTOR( CONST VECTOR & Copy );

        VOID operator=( CONST VECTOR & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Ceate a memory allocation and initialize it.  This call is     */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VECTOR<TYPE>::VECTOR
        ( 
        SBIT32                        NumberOfElements, 
        SBIT32                        AlignSize, 
        SBIT32                        AlignStart 
        )
    {
	REGISTER SBIT32 Count;

	//
	//   Allocate the storage.
	//
	AllocateAndAlignVector( NumberOfElements,AlignSize,AlignStart );

	//
	//   Call the constructors.
	//
	for ( Count = 0;Count < NumberOfElements;Count ++ )
		{ (VOID) PLACEMENT_NEW( & Aligned[ (Count * Size) ], TYPE ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Ceate a memory allocation and initialize it.  This call is     */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VECTOR<TYPE>::VECTOR
        ( 
        SBIT32                        One,
        SBIT32                        NumberOfElements, 
        SBIT32                        AlignSize,
        SBIT32                        AlignStart
        )
    {
	REGISTER SBIT32 Count;

	//
	//   Allocate the storage.
	//
	AllocateAndAlignVector( NumberOfElements,AlignSize,AlignStart );

	//
	//   Call the constructors.
	//
	for ( Count = 0;Count < NumberOfElements;Count ++ )
		{ (VOID) PLACEMENT_NEW( & Aligned[ (Count * Size) ], TYPE( One ) ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Ceate a memory allocation and initialize it.  This call is     */
    /*   not thread safe and should only be made in a single thread     */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VECTOR<TYPE>::VECTOR
        ( 
        SBIT32                        One, 
        SBIT32                        Two, 
        SBIT32                        NumberOfElements, 
        SBIT32                        AlignSize, 
        SBIT32                        AlignStart 
        )
    {
	REGISTER SBIT32 Count;

	//
	//   Allocate the storage.
	//
	AllocateAndAlignVector( NumberOfElements,AlignSize,AlignStart );

	//
	//   Call the constructors.
	//
	for ( Count = 0;Count < NumberOfElements;Count ++ )
		{ (VOID) PLACEMENT_NEW( & Aligned[ (Count * Size) ], TYPE( One,Two ) ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Allocate and align a vector.                                   */
    /*                                                                  */
    /*   We need to allocate some memory and align it as requested      */
    /*   by the user.                                                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VOID VECTOR<TYPE>::AllocateAndAlignVector
        ( 
        SBIT32                        NumberOfElements, 
        SBIT32                        AlignSize, 
        SBIT32                        AlignStart 
        )
    {
    if ( NumberOfElements > 0 )
        {
#ifdef DEBUGGING
		REGISTER SBIT32 Count;

#endif
        //
        //   We need to remember the initial alignment and count of
		//   elements for later.
        //   
        Alignment = AlignStart;
        Elements = NumberOfElements;

        //
        //   Calculate the new element size using the requested alignment
		//   value.
        //
		Size = (AlignSize - (sizeof(TYPE) % AlignSize));
		Size = (Size == AlignSize) ? 0 : Size;
		Size += sizeof(TYPE);

        //
        //   Allocate memory and call constructor for each element.
        //   Calculate the start address for requested alignment.
        //
        Allocated = new CHAR [ (AlignStart + (NumberOfElements * Size)) ];

		Aligned = (CHAR*) (AlignStart - (((LONG) Allocated) % AlignStart));
		Aligned = (((SBIT32) Aligned) == AlignStart) ? 0 : Aligned;
		Aligned += (LONG) Allocated;
#ifdef DEBUGGING

		//
		//   When we are in debug mode calculate the addresses
		//   of the first few elements of the vector.
		//
		for 
				( 
				Count = 0;
				(Count < NumberOfElements) && (Count < DebugDisplaySize);
				Count ++ 
				)
			{ Display[ Count ] = (TYPE*) & Aligned[ (Count * Size) ]; }
#endif
        }
    else
        { Failure( "Allocation size in AllocateAndAlignVector" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Resize a memory allocation.                                    */
    /*                                                                  */
    /*   Resize a memory allocation and initialize the resized area.    */
    /*   This call is not thread safe and should only be made in a      */
    /*   single thread environment.                                     */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VOID VECTOR<TYPE>::Resize( SBIT32 Reallocate )
    {
    if ( Reallocate > 0 )
        {
		REGISTER SBIT32 Count;
		REGISTER CHAR *NewAllocated = new CHAR [ (Alignment + (Reallocate * Size)) ];
		REGISTER CHAR *NewAligned = ((CHAR*) (((LONG) NewAllocated) % Alignment));
		REGISTER SBIT32 Minimum = (Elements < Reallocate) ? Elements : Reallocate;

		//
		//   Ensure we were able to allocate some memory.
		//
		if ( NewAllocated != NULL )
			{
			//
			//   Calculate the new aligned address
			//.
			NewAligned = (CHAR*) (Alignment - ((LONG) NewAligned));
			NewAligned = (((SBIT32) NewAligned) == Alignment) ? 0 : NewAligned;
			NewAligned += (LONG) NewAllocated;

			//
			//   Copy each existing element into the new allocation.
			//
			for ( Count = 0;Count < Minimum;Count ++ )
				{ 
				REGISTER SBIT32 Offset = (Count * Size);

				(*((TYPE*) & NewAligned[ Offset ])) = 
					(*((TYPE*) & Aligned[ Offset ])); 
				}

			//
			//   Call the constructor for each new element.
			//
			for ( Count = Elements;Count < Reallocate;Count ++ )
				{ (VOID) PLACEMENT_NEW( & NewAligned[ (Count * Size) ], TYPE ); }

			//
			//   Call the destructor for each original original element.
			//
			for ( Count = (Elements - 1);Count >= 0;Count -- )
				{ PLACEMENT_DELETE( & Aligned[ (Count * Size) ], TYPE ); }

			//
			//   Delete the original allocation.
			//
			delete [] Allocated;
#ifdef DEBUGGING

			//
			//   When we are in debug mode calculate the addresses
			//   of the first few elements of the vector.
			//
			for 
					( 
					Count = 0;
					(Count < Reallocate) && (Count < DebugDisplaySize);
					Count ++ 
					)
			{ Display[ Count ] = (TYPE*) & NewAligned[ (Count * Size) ]; }
#endif
 
			//
			//   Finally, lets update the information about the new
			//   amended allocation.
			//   
			this -> Elements = Reallocate;
			this -> Allocated = NewAllocated;
			this -> Aligned = NewAligned;
			}
		else
			{ Failure( "No memory available in Resize" ); }
        }
    else
        { Failure( "Rellocation size in Resize" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a vector.  This call is not thread safe and should     */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

template <class TYPE> VECTOR<TYPE>::~VECTOR( VOID )
    {
	REGISTER SBIT32 Count;

	//
	//   Call the destructors.
	//
	for ( Count = (Elements - 1);Count >= 0;Count -- )
		{ PLACEMENT_DELETE( & Aligned[ (Count * Size) ], TYPE ); }

	//
	//   Delete the storage.
	//
    delete [] Allocated;
    }
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\bucketlist.hpp ===
#ifndef _BUCKET_LIST_HPP_
#define _BUCKET_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "List.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class PAGE;

    /********************************************************************/
    /*                                                                  */
    /*   The bucket list.                                               */
    /*                                                                  */
    /*   All allocation buckets have a linked list of pages with        */
    /*   available space in ascending order of address.                 */
    /*                                                                  */
    /********************************************************************/

class BUCKET_LIST
    {
		//
		//   Private data.
		//
 		LIST						  BucketList;

   public:
        //
        //   Public inline functions.
		//
		//   All page descriptions contain four linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
        //
        BUCKET_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromBucketList( LIST *HeadOfList )
			{ BucketList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfBucketList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInBucketList( LIST *HeadOfList )
			{ return ((PAGE*) HeadOfList -> First()); }

		INLINE VOID InsertInBucketList( LIST *HeadOfList )
			{ BucketList.Insert( HeadOfList ); }

		INLINE VOID InsertAfterInBucketList( LIST *HeadOfList,PAGE *Page )
			{ BucketList.InsertAfter( HeadOfList,(LIST*) Page ); }

		INLINE VOID InsertBeforeInBucketList( LIST *HeadOfList,PAGE *Page )
			{ BucketList.InsertBefore( HeadOfList,(LIST*) Page ); }

		STATIC INLINE PAGE *LastInBucketList( LIST *HeadOfList )
			{ return ((PAGE*) HeadOfList -> Last()); }

		INLINE PAGE *NextInBucketList( VOID )
			{ return ((PAGE*) BucketList.Next()); }

		INLINE PAGE *PreviousInBucketList( VOID )
			{ return ((PAGE*) BucketList.Previous()); }

        ~BUCKET_LIST( VOID )
			{ /* void */ };

	private:
        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        BUCKET_LIST( CONST BUCKET_LIST & Copy );

        VOID operator=( CONST BUCKET_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xhash\library\unique.hpp ===
#ifndef _UNIQUE_HPP_
#define _UNIQUE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Hash.hpp"
#include "List.hpp"
#include "Pool.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The constants supplied here control how unique strings         */
    /*   are constructed.                                               */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MinDetails				  = 16;

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> class UNIQUE;

    /********************************************************************/
    /*                                                                  */
    /*   A string description.                                          */
    /*                                                                  */
    /*   All unique strings have a string drescription which is         */
    /*   into either the active or free list.                           */
    /*                                                                  */
    /********************************************************************/

class DETAIL : public LIST
	{
	private:
		//
		//   Friend classes.
		//
		friend class				  UNIQUE<NO_LOCK>;
		friend class				  UNIQUE<PARTIAL_LOCK>;
		friend class				  UNIQUE<FULL_LOCK>;

		//
		//   Private data.
		//
		BOOLEAN						  Active;
		SBIT32						  Size;
		CHAR						  *Text;
		SBIT32						  Uses;
	};

    /********************************************************************/
    /*                                                                  */
    /*   A unique string.                                               */
    /*                                                                  */
    /*   Almost all the other classes in the library offer valuable     */
    /*   free-standing functionality.  However, this class is really    */
    /*   just a support class for the variable length string class.     */
    /*                                                                  */
    /********************************************************************/

template <class LOCK=PARTIAL_LOCK> class UNIQUE : public HASH<SBIT32,POINTER>
    {
		//
		//   Private data.
		//
		LIST						  Active;
		LIST						  Free;

		DETAIL						  *Default;
		POOL<DETAIL>				  Details;
		LOCK						  Sharelock;

    public:
        //
        //   Public functions.
        //
        UNIQUE( VOID );

		DETAIL *CreateString( CHAR *String,SBIT32 Size );

		SBIT32 CompareStrings( DETAIL *Detail1,DETAIL *Detail2 );

		DETAIL *CopyString( DETAIL *Detail1,DETAIL *Detail2 );

		VOID DeleteString( DETAIL *Detail );

        ~UNIQUE( VOID );

		//
		//   Public inline functions.
		//
		INLINE DETAIL *DefaultString( VOID )
			{ return Default; }

		INLINE SBIT32 Size( DETAIL *Detail )
			{ return Detail -> Size; }

		INLINE CHAR *Value( DETAIL *Detail )
			{ return Detail -> Text; }

	private:
		//
		//   Private functions.
		//
		VIRTUAL SBIT32 ComputeHashKey
			( 
			CONST SBIT32			  & Key 
			);

		VIRTUAL BOOLEAN MatchingKeys
			( 
			CONST SBIT32			  & Key1,
			CONST SBIT32			  & Key2 
			);

        //
        //   Disabled operations.
        //
        UNIQUE( CONST UNIQUE & Copy );

        VOID operator=( CONST UNIQUE & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new unique string table.  This call is not thread     */
    /*   safe and should only be made in a single thread environment.   */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> UNIQUE<LOCK>::UNIQUE( VOID )
	{
	//
	//   Create the default string.
	//
	Default = CreateString( "",0 );
	}

    /********************************************************************/
    /*                                                                  */
    /*   Create a new unique string.                                    */
    /*                                                                  */
    /*   When we are handed a new string we need to find out whether    */
    /*   it is unique (and needs to be added to the table) or just a    */
    /*   duplicate of an existing string.                               */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> DETAIL *UNIQUE<LOCK>::CreateString
		( 
		CHAR						  *String,
		SBIT32						  Size 
		)
	{
	AUTO DETAIL *Detail1;
	AUTO DETAIL *Detail2;

	//
	//   Claim an exclusive lock (if enabled).
	//
    Sharelock.ClaimExclusiveLock();

	//
	//   Let us assume that the string is unique and
	//   build an entry to for it.  If we later find
	//   it is not then we just back out the changes.
	//
	if ( Free.EndOfList() )
		{
		REGISTER SBIT32 Count;

		//
		//   Create a several new string descriptions 
		//   and link them into the free list.
		//
		for ( Count=0;Count < MinDetails;Count ++ )
			{
			//
			//   Create a new description and add it 
			//   to the free list.
			//
			Detail1 = new DETAIL;

			Detail1 -> Active = False;

			Detail1 -> Insert( & Free );
			}
		}

	//
	//   We know that the free list must contain 
	//   least one element (if not we would have 
	//   just made some).  We extract the oldest
	//   here.
	//
	if ( (Detail1 = ((DETAIL*) Free.Last())) -> Active )
		{
		//
		//   Delete any existing value when we
		//   recycle an old and unused string
		//   description.  Remember to remove
		//   it from the hash before deleting
		//   the string as the hash uses the
		//   string.
		//
		RemoveFromHash( ((SBIT32) Detail1) );

		delete [] Detail1 -> Text;

		Detail1 -> Active = False;
		}

	//
	//   We now setup the string description for the 
	//   new string.
	//
	Detail1 -> Size = Size;
	Detail1 -> Text = String;
	Detail1 -> Uses = 1;

	//
	//   We are now ready to search the hash table for
	//   a matching string.  We do this by overloading
	//   the hash table key comparision (see later).
	//
	if ( ! FindInHash( ((SBIT32) Detail1),((POINTER*) & Detail2) ) )
		{
		//
		//   We have found a new string so we need to
		//   make the string description active and
		//   insert it in the active list.
		//
		(Detail2 = Detail1) -> Active = True;

		Detail1 -> Delete( & Free );
		Detail1 -> Insert( & Active );

		//
		//   Add the new unique string the the hash 
		//   table so we can find it later.
		//
		AddToHash( ((SBIT32) Detail1),((POINTER) Detail1) );

		//
		//   We know the string is unique so lets
		//   allocate some space for it and copy it 
		//   into the new area.
		//
		Detail1 -> Text = 
			(
			strncpy
				( 
				new CHAR [ (Size + 1) ],
				String,
				Size 
				)
			);

		Detail1 -> Text[ Size ] = '\0';
		}
	else
		{
		//
		//   Increment the use count for an existing
		//   string.
		//
		if ( Detail2 != Default )
			{ 
			//
			//   We may be lucky and find an unused
			//   string.  If so we need to add it to
			//   the active list again.
			//
			if ( (Detail2 -> Uses ++) == 0 )
				{
				//
				//   Add an unused string back to the 
				//   active list again.
				//
				Detail2 -> Delete( & Free );
				Detail2 -> Insert( & Active );
				}
			}
		}

	//
	//   Release any lock we got earlier.
	//
	Sharelock.ReleaseExclusiveLock();

	return Detail2;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compare two strings.                                           */
    /*                                                                  */
    /*   Compare two strings and find the relationship between them.    */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> SBIT32 UNIQUE<LOCK>::CompareStrings
		( 
		DETAIL						  *Detail1,
		DETAIL						  *Detail2
		)
	{
	//
	//   We know that all strings are unique so if the
	//   string pointers match then they must be the 
	//   the same string.
	//
	if ( Detail1 != Detail2 )
		{
		REGISTER SBIT32 Result =
			(
			strncmp
				( 
				Detail1 -> Text,
				Detail2 -> Text,
				(Detail1 -> Size < Detail2 -> Size)
					? Detail1 -> Size
					: Detail2 -> Size
				)
			);

		//
		//   If the strings match pick the longest.
		//
		if ( Result == 0 )
			{ Result = ((Detail1 -> Size < Detail2 -> Size) ? -1 : 1); }

		return Result;
		}
	else
		{ return 0; }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute a hash key.                                            */
    /*                                                                  */
    /*   Compute a hash key for the supplied key.  This hash key        */
    /*   is used to select the hash chain to search.                    */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> SBIT32 UNIQUE<LOCK>::ComputeHashKey
		( 
		CONST SBIT32				  & Key 
		)
	{
	REGISTER SBIT32 Count;
	REGISTER DETAIL *Detail = ((DETAIL*) Key);
	REGISTER SBIT32 HashKey = 2964557531;

	for ( Count=0;Count < Detail -> Size;Count ++ )
		{
		REGISTER SBIT32 Value = ((SBIT32) Detail -> Text[ Count ]);

		HashKey = ((HashKey * Value) + Value); 
		}

	return (HashKey & 0x3fffffff);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Copy a string.                                                 */
    /*                                                                  */
    /*   All strings are unique so there is no need to copy a string.   */
    /*   Nonetheless, we still have to update the use counts.           */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> DETAIL *UNIQUE<LOCK>::CopyString
		( 
		DETAIL						  *Detail1,
		DETAIL						  *Detail2
		)
	{
	//
	//   Claim an exclusive lock (if enabled).
	//
	Sharelock.ClaimExclusiveLock();

	//
	//   Decrement the use count for old string.
	//
	if ( Detail1 != Default )
		{ Detail1 -> Uses --; }

	//
	//   Increment the use count for new string.
	//
	if ( Detail2 != Default )
		{ Detail2 -> Uses ++; }

	//
	//   Release any lock we got earlier.
	//
	Sharelock.ReleaseExclusiveLock();

	return Detail2;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compare two hash keys.                                         */
    /*                                                                  */
    /*   Compare two hash keys to see if they match.                    */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> BOOLEAN UNIQUE<LOCK>::MatchingKeys
		( 
		CONST SBIT32				  & Key1,
		CONST SBIT32				  & Key2 
		)
	{
	REGISTER DETAIL *Detail1 = ((DETAIL*) Key1);
	REGISTER DETAIL *Detail2 = ((DETAIL*) Key2);

	return
		(
		(Detail1 -> Size == Detail2 -> Size)
			&&
		(strncmp( Detail1 -> Text,Detail2 -> Text,Detail1 -> Size ) == 0)
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete a string.                                               */
    /*                                                                  */
    /*   Delete a text string.                                          */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> VOID UNIQUE<LOCK>::DeleteString( DETAIL *Detail )
	{
	//
	//   Claim an exclusive lock (if enabled).
	//
	Sharelock.ClaimExclusiveLock();

	//
	//   Decrement the use count for the string.
	//
	if ( Detail != Default )
		{
		//
		//   Decrement the use count and ensure that
		//   this is not the last use of the string.
		//
		if ( (-- Detail -> Uses) == 0 )
			{
			//
			//   When we delete the last use of
			//   a string we add it to the free 
			//   list.  The string can be reclaimed
			//   if it is recreated before it is
			//   deleted.
			//
			Detail -> Delete( & Active );
			Detail -> Insert( & Free );
			}
		}

	//
	//   Release any lock we got earlier.
	//
	Sharelock.ReleaseExclusiveLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the unique string table.  This call is not thread      */
    /*   safe and should only be made in a single thread environment.   */
    /*                                                                  */
    /********************************************************************/

template <class LOCK> UNIQUE<LOCK>::~UNIQUE( VOID )
	{ 
	//
	//   Delete all active strings.
	//
	while ( ! Active.EndOfList() )
		{
		REGISTER DETAIL *Detail = ((DETAIL*) Active.First());

		//
		//   Delete from the list and add to the free
		//   pool just to be tidy.
		//
		Detail -> Delete( & Active );

		//
		//   The string description may be contain an 
		//   previous value and require some cleanup.
		//
		if ( Detail -> Active )
			{
			//
			//   Delete any existing value.  Remember
			//   to remove it from the hash before
			//   deleting the string as the hash uses
			//   the string.
			//
			RemoveFromHash( ((SBIT32) Detail) );

			delete [] Detail -> Text;

			Detail -> Active = False;
			}

		//
		//   Push back into the pool.
		//
		Details.PushPool( Detail );
		}

	//
	//   Delete all free strings.
	//
	while ( ! Free.EndOfList() )
		{
		REGISTER DETAIL *Detail = ((DETAIL*) Free.First());

		//
		//   Delete from the list and add to the free
		//   pool just to be tidy.
		//
		Detail -> Delete( & Free );

		//
		//   The string description may be contain an 
		//   previous value and require some cleanup.
		//
		if ( Detail -> Active )
			{
			//
			//   Delete any existing value.  Remember
			//   to remove it from the hash before
			//   deleting the string as the hash uses
			//   the string.
			//
			RemoveFromHash( ((SBIT32) Detail) );

			delete [] Detail -> Text;

			Detail -> Active = False;
			}

		//
		//   Push back into the pool.
		//
		Details.PushPool( Detail );
		}
	}
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\cache.hpp ===
#ifndef _CACHE_HPP_
#define _CACHE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Bucket.hpp"
#include "Find.hpp"
#include "NewPage.hpp"
#include "ThreadSafe.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The allocation cache.                                          */
    /*                                                                  */
    /*   The memory allocation cache consists of two stacks.  The       */
    /*   first stack contains preallocated elements which are           */
    /*   available for use.  The second stack contains elements         */
    /*   which have been deallocated and are about to be recycled.      */
    /*                                                                  */
    /********************************************************************/

class CACHE : public BUCKET
    {
		//
		//   Private data.
		//
		//   A cache sits on top of a bucket and shields 
		//   it from being swamped by calls.  The 'Active'
		//   flag is set when the cache is active.  The
		//   'Stealing' flag indicates that deallocated
		//   memory can be stolen and reallocated.  The
		//   'ThreadSafe' flag indicates that locking is
		//   required.
		//
		BOOLEAN						  Active;
		BOOLEAN						  Stealing;
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   When we are collecting statistics we enable 
		//   the following variables.  The 'CacheFills' 
		//   count keeps track of the number of times
		//   the cache was filled from the bucket.  The
		//   'CacheFlushes' count keeps track of the 
		//   number of times the cache flushed deleted
		//   elements to the bucket.  The 'HighTide' count  
		//   keeps track the the highest number of outstanding
		//   allocations since the last "DeleteAll()'.  The 
		//   'HighWater' count keeps track of the maximum 
		//   number of allocations at any point.  The
		//   'InUse' counts the the current number of outstanding 
		//   allocations.
		//
		SBIT32						  CacheFills;
		SBIT32						  CacheFlushes;
		SBIT32						  HighTide;
		SBIT32						  HighWater;
		SBIT32						  InUse;
#endif

		//
		//   A cache can be controlled by the user.  The
		//   'CacheSize' controls the number of allocations
		//   that can be preallocated or queued for 
		//   deletion.  The 'NumberOfChildren' is a count
		//   of the number of caches that allocate space
		//   from this cache.
		//
		SBIT16						  CacheSize;
		SBIT16						  FillSize;
		SBIT16						  NumberOfChildren;

		//
		//   The cache consists of two stacks.  The
		//   'DeleteStack' contains elements that are 
		//   waiting to be deleted.  The 'NewStack' 
		//   contains elements waiting to be allocated.
		//
		ADDRESS_AND_PAGE			  *DeleteStack;
		VOID						  **NewStack;
		THREAD_SAFE					  *ThreadSafe;

		//
		//   The top of the deleted stack is kept in
		//   'TopOfDeleteStack' and the top of the new
		//   stack is kept in 'TopOfNewStack'.
		//
		SBIT32						  TopOfDeleteStack;
		SBIT32						  TopOfNewStack;

		//
		//   The 'Spinlock' is a fast lock employed to
		//   make the cache multi-threaded if 'ThreadSafe'
		//   is true.
		//   
		SPINLOCK					  Spinlock;

   public:
		//
		//   Public functions.
		//
		//   The cacahe is a subset of the full haep interface
		//   a certain calls simply bypass it.  However, there
		//   are a few additional functions for cases where the
		//   cache needs to be notified of significant heap
		//   events.
		//
        CACHE
			( 
			SBIT32					  NewAllocationSize,
			SBIT32					  NewCacheSize,
			SBIT32					  NewChunkSize,
			SBIT32					  NewPageSize,
			BOOLEAN					  NewStealing,
			THREAD_SAFE				  *NewThreadSafe
			);

		VOID *CreateDataPage( VOID );

		BOOLEAN Delete( VOID *Address,PAGE *Page,SBIT32 Version );

		VOID DeleteAll( VOID );

		BOOLEAN DeleteDataPage( VOID *Address );

		PAGE *FindChildPage( VOID *Address,FIND *Find );

		PAGE *FindParentPage( VOID *Address,FIND *Find );

		BOOLEAN MultipleNew
			( 
			SBIT32					  *Actual,
			VOID					  *Array[],
			SBIT32					  Requested 
			);

		VOID *New( VOID );

		VOID *New( BOOLEAN SubDivided,SBIT32 NewSize = NoSize );

		VOID ReleaseSpace( SBIT32 MaxActivePages );

		BOOLEAN SearchCache( VOID *Address );

		BOOLEAN Truncate( VOID );

		VOID UpdateCache
			( 
			HEAP					  *NewHeap,
			NEW_PAGE				  *NewPages,
			CACHE					  *NewParentCache,
			FIND					  *NewPrivateFind,
			FIND					  *NewPublicFind
			);

        ~CACHE( VOID );

		//
		//   Public inline functions.
		//
		//   A cache just like its parent bucket is closely
		//   coupled to various other classes and provides
		//   then is vital information.
		//
		INLINE VOID ClaimCacheLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Spinlock.ClaimLock(); } 
			}

		INLINE SBIT16 GetCacheSize( VOID )
			{ return CacheSize; }

		INLINE SBIT32 GetNumberOfChildren( VOID )
			{ return NumberOfChildren; }

		INLINE VOID ReleaseCacheLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Spinlock.ReleaseLock(); } 
			}

		INLINE BOOLEAN Walk( SEARCH_PAGE *Details,FIND *Find )
			{ return NewPage -> Walk( Details,Find ); }
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Cache statistics.
		//
		//   A cache has a collection statistics which it
		//   uses to measure how it is doing.  It is possible
		//   to get access to this data for the purpose of
		//   outputing various reports.
		//
		INLINE SBIT32 GetCacheFills( VOID )
			{ return CacheFills; }

		INLINE SBIT32 GetCacheFlushes( VOID )
			{ return CacheFlushes; }

		INLINE SBIT32 GetHighTide( VOID )
			{ return HighTide; }

		INLINE SBIT32 GetHighWater( VOID )
			{ return HighWater; }

		INLINE SBIT32 GetInUse( VOID )
			{ return InUse; }
#endif

	private:
		//
		//   Private functions.
		//
		//   A cache is initially inactive.  If at least one
		//   allocation request is made it will spring into
		//   life, allocate any space needed and prepare itself
		//   for use.
		//
		VOID CreateCacheStacks( VOID );
#ifdef ENABLE_HEAP_STATISTICS

		VOID ComputeHighWater( SBIT32 Size );
#endif

        //
        //   Disabled operations.
 		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        CACHE( CONST CACHE & Copy );

        VOID operator=( CONST CACHE & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\connections.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Connections.hpp"
#include "Cache.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "NewPage.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   There are a variety of connections that need to be made        */
    /*   after all the classes are ready for use.  However, we          */
    /*   initially zero all these connection pointers until we are      */
    /*   ready to link everything.                                      */
    /*                                                                  */
    /********************************************************************/

CONNECTIONS::CONNECTIONS( VOID )
    {
	Active = False;

	Heap = NULL;
	NewPage = NULL;
	ParentCache = NULL;
 	PrivateFind = NULL;
	PublicFind = NULL;
   }

    /********************************************************************/
    /*                                                                  */
    /*   Delete from the find lists.                                    */
    /*                                                                  */
    /*   When we delete a page we need to remove it from the private    */
    /*   and public find tables as needed.                              */
    /*                                                                  */
    /********************************************************************/

VOID CONNECTIONS::DeleteFromFindList( PAGE *Page )
	{
	//
	//   Delete from any active public find table.
	//
	if ( PublicFind != NULL )
		{ PublicFind -> DeleteFromFindList( Page ); }

	//
	//   Delete from any active private find table.
	//
	if ( PrivateFind != NULL )
		{ PrivateFind -> DeleteFromFindList( Page ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Add to the find lists.                                         */
    /*                                                                  */
    /*   When we create a page we need to insert it into the private    */
    /*   and public find tables as needed.                              */
    /*                                                                  */
    /********************************************************************/

VOID CONNECTIONS::InsertInFindList( PAGE *Page )
	{

	//
	//   Insert into any active private find table.
	//
	if ( PrivateFind != NULL )
		{ PrivateFind -> InsertInFindList( Page ); }

	//
	//   Insert into any active public find table.
	//
	if ( PublicFind != NULL )
		{ PublicFind -> InsertInFindList( Page ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Update the connections.                                        */
    /*                                                                  */
    /*   When we create an allocator there is some information that     */
    /*   is not available.  Here we update the connection information   */
    /*   so we can locate the correct instances of various other        */
    /*   classes.                                                       */
    /*                                                                  */
    /********************************************************************/

VOID CONNECTIONS::UpdateConnections
		( 
		HEAP						  *NewHeap,
		NEW_PAGE					  *NewPages,
		CACHE						  *NewParentCache,
		FIND						  *NewPrivateFind,
		FIND						  *NewPublicFind
		)
	{
	//
	//   We typically only need to update the connections once
	//   but in some situations multiple updates can occur.  If
	//   this is the case we carefully check the update is 
	//   consistent with the previous update.
	//
	if ( ! Active )
		{
		//
		//   We now have the information we need to update the 
		//   connections.
		//
		Active = True;
		Heap = NewHeap;
		NewPage = NewPages;
		ParentCache = NewParentCache;
		PrivateFind = NewPrivateFind;
		PublicFind = NewPublicFind;
		}
	else
		{
		//
		//   Nasty, we have already updated the connections once.  
		//   Since we have been called again we know this node 
		//   must be shared between two heaps.  We can deal with  
		//   this as long as selected pointers are the same.
		//
		if 
				(
				(PublicFind != NewPublicFind)
					||
				(NewPage != NewPages)
					||
				(ParentCache != NewParentCache)
				)
			{ Failure( "Sharing violation in UpdateConnections" ); }
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the connections.                                       */
    /*                                                                  */
    /********************************************************************/

CONNECTIONS::~CONNECTIONS( VOID )
    {
	PublicFind = NULL;
	PrivateFind = NULL;
	ParentCache = NULL;
	NewPage = NULL;
	Heap = NULL;

	Active = False;
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\cache.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "Heap.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control the maximum size of        */
    /*   the cache.                                                     */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MaxCacheSize			  = ((2 << 16)-1);

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new allocation cache and prepare it for use.  A       */
    /*   is inactive until the first request is received at which       */
    /*   time it springs into life.                                     */
    /*                                                                  */
    /********************************************************************/

CACHE::CACHE
		( 
		SBIT32						  NewAllocationSize,
		SBIT32						  NewCacheSize,
		SBIT32						  NewChunkSize,
		SBIT32						  NewPageSize,
		BOOLEAN						  NewStealing,
		THREAD_SAFE					  *NewThreadSafe
		) :
		//
		//   Call the constructors for the contained classes.
		//
		BUCKET( NewAllocationSize,NewChunkSize,NewPageSize )
    {
	//
	//   We need to be very careful with the configuration
	//   information as it has come indirectly from the
	//   user and my be bogus.
	//
	if ( (NewCacheSize >= 0) && (NewCacheSize < MaxCacheSize) )
		{
		//
		//   Setup the cache and mark it as inactive.
		//
		Active = False;
		Stealing = NewStealing;
		ThreadSafe = NewThreadSafe;
#ifdef ENABLE_HEAP_STATISTICS

		CacheFills = 0;
		CacheFlushes = 0;
		HighTide = 0;
		HighWater = 0;
		InUse = 0;
#endif

		CacheSize = ((SBIT16) NewCacheSize);
		FillSize = 1;
		NumberOfChildren = 0;

		//
		//   The stacks that may later contain allocations
		//   are set to zero just to be neat.
		//
		DeleteStack = NULL;
		NewStack = NULL;

		TopOfDeleteStack = 0;
		TopOfNewStack = 0;
		}
	else
		{ Failure( "Cache size in constructor for CACHE" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Create the cache stacks.                                       */
    /*                                                                  */
    /*   A cache is created on demand.  We do this when we get the      */
    /*   first allocation or deallocation request.                      */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::CreateCacheStacks( VOID )
	{
	//
	//   We allocate the cache stacks from the internal
	//   new page allocator if we have not done it already.
	//
	if ( DeleteStack == NULL )
		{
		REGISTER SBIT32 Size = (CacheSize * sizeof(ADDRESS_AND_PAGE));

		DeleteStack = 
			((ADDRESS_AND_PAGE*) (NewPage -> NewCacheStack( Size )));
		}

	if ( NewStack == NULL )
		{
		REGISTER SBIT32 Size = (CacheSize * sizeof(VOID*));

		NewStack = 
			((VOID**) (NewPage -> NewCacheStack( Size )));
		}

	//
	//   We can now activate the cache as long as we 
	//   were able to allocate both stacks.
	//
	if ( (NewStack != NULL ) && (DeleteStack != NULL ) )
		{
		//
		//   We have completed creating the cache so set
		//   various flags and zero various counters.
		//
		Active = True;

		//
		//   Setup the fill size.
		//
		FillSize = 1;

		//
		//   Zero the stack tops.
		//
		TopOfDeleteStack = 0;
		TopOfNewStack = 0;
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Create a new data page.                                        */
    /*                                                                  */
    /*   When we create a new page we also need to allocate some        */
    /*   memory to hold the associated data.                            */
    /*                                                                  */
    /********************************************************************/

VOID *CACHE::CreateDataPage( VOID )
	{
	REGISTER VOID *NewMemory;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Create a data page.
	//
	NewMemory = ((BUCKET*) this) -> New( True );

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return NewMemory;
	}
#ifdef ENABLE_HEAP_STATISTICS

    /********************************************************************/
    /*                                                                  */
    /*   Compute high water.                                            */
    /*                                                                  */
    /*   Compute the high water mark for the current cache.             */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::ComputeHighWater( SBIT32 Size )
	{
	//
	//   Update the usage statistics.
	//
	if ( (InUse += Size) > HighTide )
		{ 
		HighTide = InUse;
		
		if ( HighTide > HighWater )
			{ HighWater = HighTide; }
		}
	}
#endif

    /********************************************************************/
    /*                                                                  */
    /*   A memory deallocation cache.                                   */
    /*                                                                  */
    /*   We cache memory deallocation requests to improve performance.  */
    /*   We do this by stacking requests until we have a batch.         */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::Delete( VOID *Address,PAGE *Page,SBIT32 Version )
	{
	REGISTER BOOLEAN Result;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   At various times the cache may be either disabled
	//   or inactive.  Here we ensure that we are able to use
	//   the cache.  If not we bypass it and call the bucket 
	//   directly.
	//
	if ( Active )
		{
		//
		//   If recycling is allowed and the address is
		//   on the current page or a previous page and
		//   there is space on the new stack then put the
		//   element in the new stack for immediate reuse.
		//
		if 
				(
				(Stealing)
					&&
				(Address < GetCurrentPage())
					&&
				(TopOfNewStack < CacheSize)
				)
			{
			//
			//   The address is suitable for immediate
			//   reuse.  So put it on the stack of new
			//   elements.
			//
			NewStack[ (TopOfNewStack ++) ] = Address;

			Result = True;
			}
		else
			{
			REGISTER ADDRESS_AND_PAGE *Current = 
				(& DeleteStack[ TopOfDeleteStack ++ ]);

			//
			//   The address would best be deleted before
			//   being reused.
			//
			Current -> Address = Address;
			Current -> Page = Page;
			Current -> Version = Version;

			//
			//   When the delete stack is full we flush it.
			//
			if ( TopOfDeleteStack >= CacheSize )
				{
				AUTO SBIT32 Deleted;

				//
				//   Flush the delete stack.
				//
				Result = 
					(
					((BUCKET*) this) -> MultipleDelete
						(
						DeleteStack,
						& Deleted,
						TopOfDeleteStack 
						)
					);
#ifdef ENABLE_HEAP_STATISTICS

				//
				//   Update the usage statistics.  There
				//   is a nasty case here where we cache
				//   a delete only to find out later that
				//   it was bogus.   When this occurs we
				//   have to increase the 'InUse' count 
				//   to allow for this situation.
				//
				CacheFlushes ++;
				
				InUse += (TopOfDeleteStack - Deleted);
#endif

				//
				//   Zero the top of the stack.
				//
				TopOfDeleteStack = 0;
				}
			else
				{ Result = True; }
			}
		}
	else
		{
		//
		//   Delete the element.
		//
		Result = 
			(((BUCKET*) this) -> Delete( Address,Page,Version )); 
		}
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Update the usage statistics.
	//
	if ( Result )
		{ InUse --; }
#endif

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete all allocations.                                        */
    /*                                                                  */
    /*   The entire heap is about to be deleted under our feet.  We     */
    /*   need to prepare for this by disabling the cache as its         */
    /*   contents will disappear as well.                               */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::DeleteAll( VOID )
	{
	//
	//   Disable the cache if needed.
	//
	Active = False;
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Zero the statistics.
	//
	HighTide = 0;
	InUse = 0;
#endif

	//
	//   Setup the fill size.
	//
	FillSize = 1;

	//
	//   Zero the top of stacks.
	//
	TopOfDeleteStack = 0;
	TopOfNewStack = 0;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete a data page.                                            */
    /*                                                                  */
    /*   Delete a data page that was associated with a smaller cache    */
    /*   so its space can be reused.                                    */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::DeleteDataPage( VOID *Address )
	{
	AUTO SEARCH_PAGE Details;
	REGISTER BOOLEAN Result;
	REGISTER PAGE *Page;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Find the description of the data page we need to 
	//   delete and make sure it is valid.
	//
	PrivateFind -> ClaimFindShareLock();

	Page = FindParentPage( Address,PrivateFind );

	if ( Page != NULL )
		{ Page = (Page -> FindPage( Address,& Details,PrivateFind,False )); }

	PrivateFind -> ReleaseFindShareLock();

	//
	//   Delete the data page.
	//
	if ( (Result = (Page != NULL)) )
		{ Result = (Page -> Delete( & Details )); }
	else
		{ Failure( "No data page in DeleteDataPage" ); }

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find a child page.                                             */
    /*                                                                  */
    /*   Find a child page in the local heap given an address and       */
    /*   the current memory allocation cache.                           */
    /*                                                                  */
    /********************************************************************/

PAGE *CACHE::FindChildPage( VOID *Address,FIND *Find )
	{
	return 
		(
		Find -> FindPage
			( 
			((VOID*) (((UNATIVE) Address) & ~(GetAllocationSize()-1))),
			(CACHE*) this
			)
		); 
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find a parent page.                                            */
    /*                                                                  */
    /*   Find a parent page in the local heap given an address and      */
    /*   the current memory allocation cache.                           */
    /*                                                                  */
    /********************************************************************/

PAGE *CACHE::FindParentPage( VOID *Address,FIND *Find )
	{
	return 
		(
		Find -> FindPage
			( 
			((VOID*) (((UNATIVE) Address) & ~(GetPageSize()-1))),
			ParentCache
			)
		); 
	}

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory allocations.                                   */
    /*                                                                  */
    /*   The allocation cache contains preallocated memory from the     */
    /*   associated allocation bucket.  The cache will supply these     */
    /*   preallocated elements with the minimum fuss to any caller.     */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::MultipleNew( SBIT32 *Actual,VOID *Array[],SBIT32 Requested )
	{
	REGISTER BOOLEAN Result;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   At various times the cache may be either disabled
	//   or inactive.  Here we ensure that we are able to use
	//   the cache.  If not we bypass it and call the bucket 
	//   directly.
	//
	if ( Active )
		{
		//
		//   We have been asked to allocalte multiple
		//   new elements.  If it appears that we don't  
		//   have enough elements available but stealing 
		//   is allowed we can try raiding the deleted 
		//   stack.
		//
		if ( (Requested > TopOfNewStack) && (Stealing) )
			{
			while ( (TopOfDeleteStack > 0) && (TopOfNewStack < CacheSize) )
				{
				NewStack[ (TopOfNewStack ++) ] = 
					(DeleteStack[ (-- TopOfDeleteStack) ].Address);
				}
			}

		//
		//   We will allocate from the cache if requested 
		//   size is smaller than the number of available 
		//   elements.
		//
		if ( Requested <= TopOfNewStack )
			{
			REGISTER SBIT32 Count;

			//
			//   We need to copy the elements out of the
			//   cache into the callers array.
			//
			for ( Count=0;Count < Requested;Count ++ )
				{ Array[ Count ] = NewStack[ (-- TopOfNewStack) ]; }

			(*Actual) = Requested;

			Result = True;
			}
		else
			{
			REGISTER BUCKET *Bucket = ((BUCKET*) this);

			//
			//   We don't have enough elements in the cache 
			//   so we allocate directly from the bucket.
			//
			Result =
				(
				Bucket -> MultipleNew
					( 
					Actual,
					Array,
					Requested
					)
				);

			//
			//   We fill up the cache so we have a good 
			//   chance of dealing with any following 
			//   requests if it is less than half full.
			//
			if ( TopOfNewStack <= (CacheSize / 2) )
				{
				AUTO SBIT32 NewSize;
				REGISTER SBIT32 MaxSize = (CacheSize - TopOfNewStack);

				//
				//   We slowly increse the fill size
				//   of the cache to make sure we don't
				//   waste too much space.
				//
				if ( FillSize < CacheSize )
					{
					if ( (FillSize *= 2) > CacheSize )
						{ FillSize = CacheSize; }
					}

				//
				//   Bulk load the cache with new
				//   elements.
				//
				Bucket -> MultipleNew
					( 
					& NewSize, 
					& NewStack[ TopOfNewStack ],
					((FillSize < MaxSize) ? FillSize : MaxSize)
					);
#ifdef ENABLE_HEAP_STATISTICS

				CacheFills ++;
#endif
				TopOfNewStack += NewSize;
				}
			}
		}
	else
		{
		//
		//   We may want to enable the cache for next
		//   time so see if this needs to be done.
		//
		if ( CacheSize > 1 )
			{ CreateCacheStacks(); }

		//
		//   The cache is disabled so go directly to the
		//   bucket.
		//
		Result = ((BUCKET*) this) -> MultipleNew
			( 
			Actual,
			Array,
			Requested
			);
		}
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Update the usage statistics.
	//
	ComputeHighWater( (*Actual) );
#endif

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Memory allocation.                                             */
    /*                                                                  */
    /*   The allocation cache contains preallocated memory from the     */
    /*   associated allocation bucket.  The cache will supply these     */
    /*   preallocated elements with the minimum fuss to any caller.     */
    /*                                                                  */
    /********************************************************************/

VOID *CACHE::New( VOID )
	{
	REGISTER VOID *NewMemory;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   At various times the cache may be either disabled
	//   or inactive.  Here we ensure that we are able to use
	//   the cache.  If not we bypass it and call the bucket 
	//   directly.
	//
	if ( Active )
		{
		//
		//   We first try the stack for new allocations
		//   to see if there are any available elements.
		//
		if ( TopOfNewStack > 0 )
			{ NewMemory = (NewStack[ (-- TopOfNewStack) ]); }
		else
			{
			//
			//   When stealing is allowed we will recycle
			//   elements from the top of the deleted stack.
			//
			if ( (TopOfDeleteStack > 0) && (Stealing) )
				{ NewMemory = (DeleteStack[ (-- TopOfDeleteStack) ].Address); }
			else
				{
				//
				//   We slowly increse the fill size
				//   of the cache to make sure we don't
				//   waste too much space.
				//
				if ( FillSize < CacheSize )
					{
					if ( (FillSize *= 2) > CacheSize )
						{ FillSize = CacheSize; }
					}

				//
				//   We need to bulk load some new  
				//   memory from the heap.
				//
				if 
						( 
						((BUCKET*) this) -> MultipleNew
							( 
							& TopOfNewStack,
							NewStack,
							FillSize
							) 
						)
					{
					//
					//   Update the statistics and return
					//   the top element on the stack.
					//
#ifdef ENABLE_HEAP_STATISTICS
					CacheFills ++;
#endif
					NewMemory = NewStack[ (-- TopOfNewStack) ]; 
					}
				else
					{
					//
					//   Update the statistics and fail
					//   the request for memeory.
					//
					NewMemory = ((VOID*) AllocationFailure);
					}
				}
			}
		}
	else
		{ 
		//
		//   We may want to enable the cache for next
		//   time so see if this needs to be done.
		//
		if ( CacheSize > 1 )
			{ CreateCacheStacks(); }

		//
		//   The cache is disabled so go directly to the
		//   bucket.
		//
		NewMemory = ((BUCKET*) this) -> New( False ); 
		}
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Update the usage statistics.
	//
	ComputeHighWater( (NewMemory != ((VOID*) AllocationFailure)) );
#endif

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	//
	//   Prefetch the first cache line if we are running
	//   a Pentium III or better.
	//
	Prefetch.L1( ((CHAR*) NewMemory),1 );

	return NewMemory;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Memory allocation for non-standard sizes.                      */
    /*                                                                  */
    /*   A non standard sized allocation simply by-passes the cache     */
    /*   but it still needs to hold the lock to prevent failure on      */
    /*   SMP systems.                                                   */
    /*                                                                  */
    /********************************************************************/

VOID *CACHE::New( BOOLEAN SubDivided,SBIT32 NewSize )
	{
	REGISTER VOID *NewMemory;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Allocate a non-standard sized block.
	//
	NewMemory = ((BUCKET*) this) -> New( SubDivided,NewSize );
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Update the usage statistics.
	//
	ComputeHighWater( (NewMemory != ((VOID*) AllocationFailure)) );
#endif

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return NewMemory;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release free space.                                            */
    /*                                                                  */
    /*   We sometimes do not release free space from a bucket as        */
    /*   returning it to the operating system and getting it again      */
    /*   later is very expensive.  Here we flush any free space we      */
    /*   have aquired over the user supplied limit.                     */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::ReleaseSpace( SBIT32 MaxActivePages )
	{
	//
	//   When there is a potential for multiple threads 
	//   we claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Release the free space from the backet.
	//
	((BUCKET*) this) -> ReleaseSpace( MaxActivePages );

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   Search the cacahe for an allocation.                           */
    /*                                                                  */
    /*   We sometimes need to search the cache to see if an             */
    /*   allocation is currently in the cacahe awaiting allocation      */
    /*   or release.                                                    */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::SearchCache( VOID *Address )
	{
	REGISTER BOOLEAN Result = False;

	//
	//   We check to see if the cache is active.
	//
	if ( Active )
		{
		//
		//   When there is a potential for multiple 
		//   threads we claim the cache lock.
		//
		ClaimCacheLock();

		//
		//   We check to see if the cache is still 
		//   active.
		//
		if ( Active )
			{
			REGISTER SBIT32 Count;

			//
			//   Search the allocated cache.
			//
			for ( Count=(TopOfNewStack-1);Count >= 0;Count -- )
				{ 
				if ( Address == NewStack[ Count ] )
					{
					Result = True;
					break;
					}
				}

			//
			//   If it has not been found yet then try
			//   the deleted cache.
			//
			if ( ! Result )
				{
				//
				//   Search the deleted cache.
				//
				for ( Count=(TopOfDeleteStack-1);Count >= 0;Count -- )
					{ 
					if ( Address == DeleteStack[ Count ].Address )
						{
						Result = True;
						break;
						}
					}
				}
			}

		//
		//   Release any lock we may have claimed earlier.
		//
		ReleaseCacheLock();
		}

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Truncate the heap.                                             */
    /*                                                                  */
    /*   Flush the cache to release the maximum amount of space back    */
    /*   to the operating system.  This is slow but may be very         */
    /*   valuable in some situations.                                   */
    /*                                                                  */
    /********************************************************************/

BOOLEAN CACHE::Truncate( VOID )
	{
	REGISTER BOOLEAN Result = True;

	//
	//   When there is a potential for multiple threads we
	//   claim the cache lock.
	//
	ClaimCacheLock();

	//
	//   Disable the cache if needed.
	//
	Active = False;

	//
	//   Setup the fill size.
	//
	FillSize = 1;

	//
	//   Flush any elements in the delete cache.
	//   We do this now because we need to use 
	//   the delete cache below.
	//
	if ( TopOfDeleteStack > 0 )
		{
		AUTO SBIT32 Deleted;

		//
		//   Flush the delete stack.
		//
		Result = 
			(
			((BUCKET*) this) -> MultipleDelete
				(
				DeleteStack,
				& Deleted,
				TopOfDeleteStack 
				)
				&&
			(Result)
			);
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Update the usage statistics.  There
		//   is a nasty case here where we cache
		//   a delete only to find out later that
		//   it was bogus.   When this occurs we
		//   have to increase the 'InUse' count 
		//   to allow for this situation.
		//
		CacheFlushes ++;
		
		InUse += (TopOfDeleteStack - Deleted);
#endif
		
		//
		//   Zero the top of the stack.
		//
		TopOfDeleteStack = 0;
		}
	
	//
	//   Flush any elements in the new cache by
	//   copying them over to the delete cache
	//   and adding the additional information
	//   required.
	//
	if ( TopOfNewStack > 0 )
		{
		//
		//   We need to find the data page for each  
		//   allocation we have in the new cache.
		//   Claim the lock here to make things a
		//   little more efficient.
		//
		PrivateFind -> ClaimFindShareLock();

		//
		//   We copy each allocation across and 
		//   add the associated page information.
		//
		for ( TopOfNewStack --;TopOfNewStack >= 0;TopOfNewStack -- )
			{
			REGISTER VOID *Address = 
				(NewStack[ TopOfNewStack ]);
			REGISTER PAGE *Page = 
				(ParentCache -> FindChildPage( Address,PrivateFind ));

			//
			//   You would think that any memory in the
			//   new cache had to be valid.   Well it
			//   does except in the case when we have
			//   'Recycle' set and somebody does a double
			//   delete on a valid heap address.
			//
			if ( Page != NULL )
				{
				REGISTER ADDRESS_AND_PAGE *Current = 
					(& DeleteStack[ TopOfDeleteStack ++ ]);

				//
				//   We need to find the allocation page
				//   where the memory was allocated from
				//   so we can delete it.
				//
				Current -> Address = Address;
				Current -> Page = Page;
				Current -> Version = Page -> GetVersion();
				}
			else
				{ 
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   Update the usage statistics.  There
				//   is a nasty case here where we cache
				//   a delete only to find out later that
				//   it was bogus.   When this occurs we
				//   have to increase the 'InUse' count 
				//   to allow for this situation.
				//
				InUse ++;

#endif
				Result = False; 
				}
			}

		//
		//   Release the lock.
		//
		PrivateFind -> ReleaseFindShareLock();
		}

	//
	//   Flush the delete cache again to delete
	//   any new elements that we added to it
	//   above.
	//
	if ( TopOfDeleteStack > 0 )
		{
		AUTO SBIT32 Deleted;

		//
		//   Flush the delete stack.
		//
		Result = 
			(
			((BUCKET*) this) -> MultipleDelete
				(
				DeleteStack,
				& Deleted,
				TopOfDeleteStack 
				)
				&&
			(Result)
			);
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Update the usage statistics.  There
		//   is a nasty case here where we cache
		//   a delete only to find out later that
		//   it was bogus.   When this occurs we
		//   have to increase the 'InUse' count 
		//   to allow for this situation.
		//
		CacheFlushes ++;
		
		InUse += (TopOfDeleteStack - Deleted);
#endif
		
		//
		//   Zero the top of the stack.
		//
		TopOfDeleteStack = 0;
		}

	//
	//   Release any lock we may have claimed earlier.
	//
	ReleaseCacheLock();

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Update the bucket information.                                 */
    /*                                                                  */
    /*   When we create the bucket there is some information that       */
    /*   is not available.  Here we update the bucket to make sure      */
    /*   it has all the data it needs.                                  */
    /*                                                                  */
    /********************************************************************/

VOID CACHE::UpdateCache
		( 
		HEAP						  *NewHeap,
		NEW_PAGE					  *NewPages,
		CACHE						  *NewParentCache,
		FIND						  *NewPrivateFind,
		FIND						  *NewPublicFind
		)
	{
	//
	//   Notify the parent cache that it has a new
	//   child.
	//
	if ( NewParentCache != ((CACHE*) GlobalRoot) )
		{ NewParentCache -> NumberOfChildren ++; }

	//
	//   Update the allocation bucket.
	//
	UpdateBucket
		( 
		NewHeap,
		NewPages,
		NewParentCache, 
		NewPrivateFind,
		NewPublicFind
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the cache and ensure it is disabled.                   */
    /*                                                                  */
    /********************************************************************/

CACHE::~CACHE( VOID )
	{
	if ( Active )
		{ Failure( "Cache active in destructor for CACHE" ); }
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\find.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "New.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control the size of the hash       */
    /*   table and other related features.                              */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MinHash				  = 1024;
CONST SBIT32 MinHashSpace			  = (100/25);
CONST SBIT32 MinLookAside			  = 128;

CONST UNATIVE NoAddressMask			  = ((BIT32) -1);
CONST SNATIVE NoCacheEntry			  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create the hash table and initialize it ready for use. The     */
    /*   configuration information supplied from the parameters needs   */
    /*   to be carefully checked as it has come indirectly from the     */
    /*   user and may be bogus.                                         */
    /*                                                                  */
    /********************************************************************/

FIND::FIND
		( 
		SBIT32						  NewMaxHash,
		SBIT32						  NewMaxLookAside,
		SBIT32						  NewFindThreshold,
		BOOLEAN						  NewPublic, 
		BOOLEAN						  NewResize, 
		ROCKALL_BACK_END			  *NewRockallBackEnd,
		THREAD_SAFE					  *NewThreadSafe 
		)
    {
	REGISTER SBIT32 AlignMask = (NewRockallBackEnd -> NaturalSize()-1);

	//
	//   We need to make sure that the size of the hash table
	//   makes sense.  The hash table size needs to be a reasonable
	//   size (say 1k or larger) and a power of 2 (so we don't need
	//   to do any divides).
	//   
	if 
			(
			PowerOfTwo( (AlignMask+1) )
				&&
			(NewFindThreshold >= 0 )
				&&
			(NewMaxHash >= MinHash) 
				&&
			(ConvertDivideToShift( NewMaxHash,& HashMask ))
				&& 
			(NewMaxLookAside >= MinLookAside) 
				&& 
			(ConvertDivideToShift( NewMaxLookAside,& LookAsideMask ))
			)
		{
		REGISTER SBIT32 HashSize = (NewMaxHash * sizeof(LIST));
		REGISTER SBIT32 LookAsideSize = (NewMaxLookAside * sizeof(LOOK_ASIDE));
		REGISTER SBIT32 TotalSize = (HashSize + LookAsideSize);

		//
		//   Set up the hash table.
		//
		MaxHash = NewMaxHash;

		HashShift = (32-HashMask);
		HashMask = ((1 << HashMask)-1);
		Public = NewPublic;
		Resize = NewResize;

		//
		//   Set up the lookaside table.
		//
		MaxLookAside = NewMaxLookAside;

		MaxAddressMask = NoAddressMask;
		MinAddressMask = NoAddressMask;

		LookAsideActions = 0;
		LookAsideShift = (32-LookAsideMask);
		LookAsideMask = ((1 << LookAsideMask)-1);
		LookAsideThreshold = NewFindThreshold;

		RockallBackEnd = NewRockallBackEnd;

		ThreadSafe = NewThreadSafe;

		//
		//   Create some space for the find table and the 
		//   look aside table.
		//
		Hash = 
			((LIST*) RockallBackEnd -> NewArea
				( 
				AlignMask,
				TotalSize,
				False 
				)
			);

		LookAside = ((LOOK_ASIDE*) & Hash[ MaxHash ]);

		//
		//   If the memory allocation request for the hash
		//   table fails we are doomed.  If it works we need
		//   to call the constructor for each linked list
		//   head node.
		//
		if ( Hash != ((LIST*) AllocationFailure) )
			{
			REGISTER SBIT32 Count;

			//
			//   Call the constructor for each hash table
			//   linked list header.
			//
			for ( Count=0;Count < NewMaxHash;Count ++ )
				{ PLACEMENT_NEW( & Hash[ Count ],LIST ); }

			//
			//   Zero the look aside structures.  We need
			//   to do this to ensure they do not match a
			//   valid allocation address later.
			//
			for ( Count=0;Count < MaxLookAside;Count ++ )
				{
				REGISTER LOOK_ASIDE *Current = & LookAside[ Count ];

				Current -> Address = ((VOID*) NoCacheEntry);
				Current -> Page = ((PAGE*) NoCacheEntry);
#ifdef DEBUGGING
				Current -> Version = ((SBIT32) NoCacheEntry);
#endif
				}
#ifdef ENABLE_HEAP_STATISTICS

			//
			//   Zero the statistics information.
			//
			Fills = 0;
			Hits = 0;
			MaxPages = 0;
			MaxTests = 0;
			Misses = 0;
			Scans = 0;
			Tests = 0;
#endif
			Used = 0;
			}
		else
			{ Failure( "Create hash fails in constructor for FIND" ); }
		}
	else
		{ Failure( "Hash table size in constructor for FIND" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Delete a memory allocation.                                    */
    /*                                                                  */
    /*   We need to delete a particular memory allocation.  All         */
    /*   we have is an address.  We use this to find the largest        */
    /*   allocation page this address is contained in and then          */
    /*   navigate through the sub-divisions of this page until we       */
    /*   find the allocation we need to delete.                         */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::Delete( VOID *Address,CACHE *ParentCache )
    {
	REGISTER PAGE *Page;
	REGISTER BOOLEAN Update;
	
	//
	//   If we need to be thread safe then claim a sharable lock
	//   on the hash table to stop it being changed under our feet.
	//
	ClaimFindShareLock();

	//
	//   Lets try the lookaside table.  There is a pretty
	//   good chance that we will have the details we need 
	//   already in the cache.  If not we need to find it
	//   the hard way.  During the process we add the mapping
	//   into the lookaside for next time.
	//
	if
			( 
			Update = 
				(
				! FindLookAside
					( 
					((VOID*) (((SNATIVE) Address) & ~MinAddressMask)),
					& Page 
					)
				)
			)
		{
		//
		//   Find the allocation page and get the details of entry.
		//   We do this by finding the parent of the top cache.
		//   We  know that this is the global root and will find
		//   the correct page even if it is on another heap (as
		//   long as the find table is globally shared).
		//
		Page = (ParentCache -> FindParentPage( Address,this ));

		if ( Page != ((PAGE*) NULL) )
			{ Page = (Page -> FindPage( Address,NULL,this,True )); }
		}

	//
	//   We may have failed to find the address.  If so
	//   we simply fail the call.  If not we put the deleted 
	//   element back in the associated cache.
	//
	if ( Page != ((PAGE*) NULL) )
 		{
		REGISTER CACHE *Cache = (Page -> GetCache());
		REGISTER SBIT32 Original = (Page -> GetVersion());

		//
		//   Prefetch the class data if we are running a
		//   Pentium III or better with locks.  We do this
		//   because prefetching hot SMP data structures
		//   really helps.  However, if the structures are
		//   not shared (i.e. no locks) then it is worthless
		//   overhead.
		//
		if ( ThreadSafe )
			{ Prefetch.Nta( ((CHAR*) Cache),sizeof(CACHE) ); }

		//
		//   Release the lock if we claimed it earlier and
		//   update the lookaside if needed.
		//
		if ( Update )
			{ ReleaseFindShareLockAndUpdate( Address,Page,Original ); }
		else
			{ ReleaseFindShareLock(); }

		//
		//   We have found the associated page description
		//   so pass the delete request along to the cache
		//   and get out of here.
		//
		return (Cache -> Delete( Address,Page,Original ));
		}
	else
		{ 
		//
		//   Release the lock if we claimed it earlier.
		//
		ReleaseFindShareLock();

		return False; 
		}
  }

    /********************************************************************/
    /*                                                                  */
    /*   Delete an item from the find table.                            */
    /*                                                                  */
    /*   We need to delete page from the find list.  We expect          */
    /*   this to take quite a while as multiple threads can be          */
    /*   using this class at the same time.                             */
    /*                                                                  */
    /********************************************************************/

VOID FIND::DeleteFromFindList( PAGE *Page )
	{
	REGISTER VOID *Address = (Page -> GetAddress());

	//
	//   Claim an exclusive lock so we can update the 
	//   hash and lookaside as needed.
	//
	ClaimFindExclusiveLock();

	//
	//   Delete the page from the hash table.
	//
	if ( ! Public )
		{ Page -> DeleteFromPrivateFindList( FindHashHead( Address ) ); }
	else
		{ Page -> DeleteFromPublicFindList( FindHashHead( Address ) ); }

	//
	//   When we create very small heaps (i.e. a heap
	//   where only 20-30 allocations are requested)
	//   the various caches become a problem as they
	//   tend to front load work.  So we allow a limit
	//   to be set before which we run with caches 
	//   disabled.
	//   
	if ( LookAsideActions >= LookAsideThreshold )
		{
		REGISTER SBIT32 Count;
		REGISTER CACHE *Cache = (Page -> GetCache());
		REGISTER SBIT32 Stride = (Cache -> GetAllocationSize());

		//
		//   We are about look up various look aside entries
		//   and delete any that are stale.  We need to do
		//   this for every lookaside slot that relates to
		//   the page.  If the allocation size is smaller
		//   than the lookaside slot size we can save some
		//   iterations by increasing the stride size.
		//
		if ( Stride <= ((SBIT32) MinAddressMask) )
			{ Stride = ((SBIT32) (MinAddressMask+1)); }

		//
		//   Whenever we delete an entry from the hash table
		//   the lookaside is potentially corrupt.  So we 
		//   need to delete any look aside entries relating
		//   to this page.
		//
		for ( Count=0;Count < Cache -> GetPageSize();Count += Stride )
			{
			REGISTER VOID *Segment = 
				((VOID*) ((((SNATIVE) Address) + Count) & ~MinAddressMask));
			REGISTER LOOK_ASIDE *Current = 
				(FindLookAsideHead( Segment ));

			//
			//   Delete the look aside entry if it is stale.
			//
			if ( Segment == Current -> Address )
				{
				Current -> Address = ((VOID*) NoCacheEntry);
				Current -> Page = ((PAGE*) NoCacheEntry);
#ifdef DEBUGGING
				Current -> Version = ((SBIT32) NoCacheEntry);
#endif
				}
			}
		}

	//
	//   Update the statistics.
	//
	Used --;

	//
	//   Release the lock if we claimed it earlier.
	//
	ReleaseFindExclusiveLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   Details of a memory allocation.                                */
    /*                                                                  */
    /*   We need to the details of a particular memory allocation.      */
    /*   All we have is an address.  We use this to find the largest    */
    /*   allocation page this address is contained in and then          */
    /*   navigate through the sub-divisions of this page until we       */
    /*   find the allocation.                                           */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::Details
		( 
		VOID						  *Address,
		SEARCH_PAGE					  *Details,
		CACHE						  *ParentCache,
		SBIT32						  *Size 
		)
    {
	REGISTER PAGE *Page;
	REGISTER BOOLEAN Result;
	REGISTER BOOLEAN Update;
	
	//
	//   If we need to be thread safe then claim a sharable lock
	//   on the hash table to stop it being changed under our feet.
	//
	ClaimFindShareLock();

	//
	//   Lets try the lookaside table.  There is a pretty
	//   good chance that we will have the deatils we need 
	//   already in the cache.  If not we need to find it
	//   the hard way.  During the process we add the mapping
	//   into the lookaside for next time.
	//
	if
			( 
			Update = 
				(
				! FindLookAside
					( 
					((VOID*) (((SNATIVE) Address) & ~MinAddressMask)),
					& Page 
					)
				)
			)
		{
		//
		//   Find the allocation page and get the details of entry.
		//   We do this by finding the parent of the top cache.
		//   We  know that this is the global root and will find
		//   the correct page even if it is on another heap (as
		//   long as the find table is globally shared).
		//
		Page = (ParentCache -> FindParentPage( Address,this ));

		if ( Page != ((PAGE*) NULL) )
			{ Page = (Page -> FindPage( Address,Details,this,True )); }
		}
	else
		{
		//
		//   We may need to provide the all the details of the
		//   allocation for some reason.
		//
		if ( Details != NULL )
			{ Page = (Page -> FindPage( Address,Details,this,True )); }
		}

	//
	//   We may have failed to find the address.  If so
	//   we simply fail the call.  If not we extract the 
	//   information we want.
	//
	if ( Result = (Page != ((PAGE*) NULL)) )
 		{
		//
		//   Compute the size.  We would normally expect
		//   this to be the cache size.  However, there
		//   are some weird pages that sometimes have
		//   other sizes.
		//
		(*Size) = (Page -> ActualSize());
		}

	//
	//   Release the lock if we claimed it earlier and 
	//   update the lookaside if needed.
	//
	if ( (Update) && (Result) )
		{ ReleaseFindShareLockAndUpdate( Address,Page,Page -> GetVersion() ); }
	else
		{ ReleaseFindShareLock(); }

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Find in the look aside.                                        */
    /*                                                                  */
    /*   We need to find a particular page in the look aside.  So we    */
    /*   try a simple look up (no lists or chains).                     */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::FindLookAside( VOID *Address,PAGE **Page )
    {
	//
	//   When we create very small heaps (i.e. a heap
	//   where only 20-30 allocations are requested)
	//   the various caches become a problem as they
	//   tend to front load work.  So we allow a limit
	//   to be set before which we run with caches 
	//   disabled.
	//   
	if ( LookAsideActions >= LookAsideThreshold )
		{
		REGISTER LOOK_ASIDE *Current = FindLookAsideHead( Address );

		//
		//   We have hashed to a lookaside slot.  Maybe
		//   it contains what we want or maybe not.
		//
		if ( Address == Current -> Address )
			{
#ifdef DEBUGGING
			if ( Current -> Version == (Current -> Page -> GetVersion()) )
				{
#endif
				//
				//   We hit the lookaside and the 
				//   contents are valid.
				//
				(*Page) = (Current -> Page);
#ifdef ENABLE_HEAP_STATISTICS

				//
				//   Update the statistics.
				//
				Hits ++;
#endif

				return True;
#ifdef DEBUGGING
				}
			else
				{ Failure( "Deleted page in FindLookAside" ); }
#endif
			}
		}
	else
		{
		//
		//   We update number of times we tried to
		//   use the lookaside and it was disabled.  
		//   After a while this will lead to the 
		//   lookaside being enabled.
		//
		LookAsideActions ++; 
		}
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   We missed the lookaside so update the 
	//   statistics to reflect our misfortune.
	//
	Misses ++;
#endif

	return False; 
    }

    /********************************************************************/
    /*                                                                  */
    /*   Find a page.                                                   */
    /*                                                                  */
    /*   We need to find a particular page in the hash table.  So we    */
    /*   scan along the associated linked list looking for a match.     */
    /*                                                                  */
    /********************************************************************/

PAGE *FIND::FindPage( VOID *Address,CACHE *ParentCache )
    {
#ifdef ENABLE_HEAP_STATISTICS
	REGISTER SBIT32 Cycles = 0;
	REGISTER PAGE *Result = NULL;
#endif
	//
	//   There are two find lists.  There is the
	//   private find list and the public find list.
	//   We choose which one to walk along.
	//
	if ( ! Public )
		{
		REGISTER PAGE *Page;

		//
		//   Find the associated hash bucket and then walk
		//   along the linked list for this looking for
		//   the correct page description.
		//
		for 
				( 
				Page = PAGE::FirstInPrivateFindList( FindHashHead( Address ) );
				! Page -> EndOfPrivateFindList();
				Page = Page -> NextInPrivateFindList()
				)
			{
#ifdef ENABLE_HEAP_STATISTICS
			//
			//   Count the number of iterations in when we
			//   are recording statistics so we can calculate
			//   the average chain length.
			//
			Cycles ++;

#endif
			//
			//   We can identify the the target page by two key
			//   characteristics.  These are the start address and
			//   the parent page.   Although we may have sub-divided
			//   a page into various chunks each chunk will have
			//   a different parent (although its start address
			//   may sometimes be the same).
			//
			if 
					( 
					(Address == (Page -> GetAddress())) 
						&& 
					(ParentCache == (Page -> GetParentPage()))
					)
				{
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   We have found the target page.  So return it
				//   to the caller.
				//
				if ( Page -> ValidPage() )
					{
					Result = Page;
					break;
					}
				else
					{ Failure( "Deleted page in FindPage" ); }
#else
				return Page;
#endif
				}
			}
		}
	else
		{
		REGISTER PAGE *Page;

		//
		//   Find the associated hash bucket and then walk
		//   along the linked list for this looking for
		//   the correct page description.
		//
		for 
				( 
				Page = PAGE::FirstInPublicFindList( FindHashHead( Address ) );
				! Page -> EndOfPublicFindList();
				Page = Page -> NextInPublicFindList()
				)
			{
#ifdef ENABLE_HEAP_STATISTICS
			//
			//   Count the number of iterations in when we
			//   are recording statistics so we can calculate
			//   the average chain length.
			//
			Cycles ++;

#endif
			//
			//   We can identify the the target page by two key
			//   characteristics.  These are the start address and
			//   the parent page.   Although we may have sub-divided
			//   a page into various chunks each chunk will have
			//   a different parent (although its start address
			//   may sometimes be the same).
			//
			if 
					( 
					(Address == (Page -> GetAddress())) 
						&& 
					(ParentCache == (Page -> GetParentPage()))
					)
				{
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   We have found the target page.  So return it
				//   to the caller.
				//
				if ( Page -> ValidPage() )
					{
					Result = Page;
					break;
					}
				else
					{ Failure( "Deleted page in FindPage" ); }
#else
				return Page;
#endif
				}
			}
		}

#ifdef ENABLE_HEAP_STATISTICS
	//
	//   When we are in statistics mode we need to update the
	//   information so we can output it at the end of the
	//   run.
	//
	if ( MaxTests < Cycles )
		{ MaxTests = Cycles; }

	Tests += Cycles;

	Scans ++;

	return Result;
#else
	return NULL;
#endif
    }

    /********************************************************************/
    /*                                                                  */
    /*   Insert an item into the find table.                            */
    /*                                                                  */
    /*   We need to insert a new page into the find table.  We expect   */
    /*   this to take quite a while as multiple threads can be using    */
    /*   this class at the same time.                                   */
    /*                                                                  */
    /********************************************************************/

VOID FIND::InsertInFindList( PAGE *Page )
	{
	REGISTER VOID *Address = (Page -> GetAddress());

	//
	//   Claim an exclusive lock so we can update the 
	//   find table and lookaside as needed.
	//
	ClaimFindExclusiveLock();

	//
	//   Insert a new page into the find table.
	//
	if ( ! Public )
		{ Page -> InsertInPrivateFindList( FindHashHead( Address ) ); }
	else
		{ Page -> InsertInPublicFindList( FindHashHead( Address ) ); }

	//
	//   When we create very small heaps (i.e. a heap
	//   where only 20-30 allocations are requested)
	//   the various caches become a problem as they
	//   tend to front load work.  So we allow a limit
	//   to be set before which we run with caches 
	//   disabled.
	//   
	if ( LookAsideActions >= LookAsideThreshold )
		{
		REGISTER SBIT32 Count;
		REGISTER CACHE *Cache = (Page -> GetCache());
		REGISTER SBIT32 Stride = (Cache -> GetAllocationSize());

		//
		//   We are about look up various lookaside entries
		//   and update any that are stale.  We need to do
		//   this for every lookaside slot that relates to
		//   the page.  If the allocation size is smaller
		//   than the lookaside slot size we can save some
		//   iterations by increasing the stride size.
		//
		if ( Stride <= ((SBIT32) MinAddressMask) )
			{ Stride = ((SBIT32) (MinAddressMask+1)); }

		//
		//   Whenever we add an entry from the find table
		//   the lookaside is potentially corrupt.  So we 
		//   need to update any lookaside entries relating
		//   to the page.
		//
		for ( Count=0;Count < Cache -> GetPageSize();Count += Stride )
			{
			REGISTER VOID *Segment = 
				((VOID*) ((((SNATIVE) Address) + Count) & ~MinAddressMask));
			REGISTER LOOK_ASIDE *Current = 
				(FindLookAsideHead( Segment ));

			//
			//   Add the new page to the lookaside as we
			//   expect it to get hit pretty soon one way
			//   or another.
			//
			Current -> Address = Segment;
			Current -> Page = Page;
#ifdef DEBUGGING
			Current -> Version = Page -> GetVersion();
#endif
			}
		}

	//
	//   Update the statistics and resize the find
	//   table if it is over capacity.
	//
	if ( ((++ Used) + (MaxHash / MinHashSpace)) > MaxHash )
		{ ResizeHashTable(); }
#ifdef ENABLE_HEAP_STATISTICS

	if ( Used > MaxPages )
		{ MaxPages = Used; }
#endif

	//
	//   Release the lock if we claimed it earlier.
	//
	ReleaseFindExclusiveLock();
	}

    /********************************************************************/
    /*                                                                  */
    /*   A known area.                                                  */
    /*                                                                  */
    /*   We have an address and don't have a clue which heap            */
    /*   owns the space.  Here we take a look at the address            */
    /*   and figure out if it is known to the current heap.             */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::KnownArea( VOID *Address,CACHE *ParentCache )
    {
	REGISTER PAGE *Page;
	
	//
	//   If we need to be thread safe then claim a sharable lock
	//   on the hash table to stop it being changed under our feet.
	//
	ClaimFindShareLock();

	//
	//   Find out if the address belongs to this heap
	//   or any other heap of which we are aware (i.e.
	//   when single image is active).
	//
	Page = (ParentCache -> FindParentPage( Address,this ));

	//
	//   Release the lock if we claimed it earlier.
	//
	ReleaseFindShareLock();

	return (Page != ((PAGE*) NULL));
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release a shared lock and update.                              */
    /*                                                                  */
    /*   We have been asked to insert a page into the lookaside.        */
    /*   We assume the caller already has a share lock which we         */
    /*   release when we are finished.                                  */
    /*                                                                  */
    /********************************************************************/

VOID FIND::ReleaseFindShareLockAndUpdate
		( 
		VOID						  *Address,
		PAGE						  *Page,
		SBIT32						  Version
		)
    {
	//
	//   When we create very small heaps (i.e. a heap
	//   where only 20-30 allocations are requested)
	//   the various caches become a problem as they
	//   tend to front load work.  So we allow a limit
	//   to be set before which we run with caches 
	//   disabled.
	//   
	if ( LookAsideActions >= LookAsideThreshold )
		{
		//
		//   Claim an exclusive lock so we can update the 
		//   lookaside as needed.
		//
		ChangeToExclusiveLock();

#ifdef DEBUGGING
		if ( Page -> ValidPage() )
			{
#endif
			if ( Version == (Page -> GetVersion()) )
				{
				REGISTER SNATIVE Base = (((SNATIVE) Address) & ~MinAddressMask);
				REGISTER VOID *Segment = ((VOID*) Base);
				REGISTER LOOK_ASIDE *Current = FindLookAsideHead( Segment );

				//
				//   Overwrite any existing information.
				//
				Current -> Address = Segment;
				Current -> Page = Page;
#ifdef DEBUGGING
				Current -> Version = Page -> GetVersion();
#endif
#ifdef ENABLE_HEAP_STATISTICS

				//
				//   Update the statistics.
				//
				Fills ++;
#endif
				}
#ifdef DEBUGGING
			}
		else
			{ Failure( "Deleted page in ReleaseFindShareLockAndUpdate" ); }
#endif

		//
		//   Release the lock if we claimed it earlier.
		//
		ReleaseFindExclusiveLock();
		}
	else
		{ 
		//
		//   Release the lock if we claimed it earlier.
		//
		ReleaseFindShareLock(); 
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Resize the find table.                                         */
    /*                                                                  */
    /*   We need to grow the hash table as it appears to be a little    */
    /*   small given the number of pages that have been created.        */
    /*                                                                  */
    /********************************************************************/

VOID FIND::ResizeHashTable( VOID )
    {
	AUTO SBIT32 NewHashMask;
	AUTO SBIT32 NewLookAsideMask;

	//
	//   When we need to resize the hash table it is a
	//   straight race.  The first thread to claim the
	//   lock gets to do the work.  Everyone else just
	//   exits.
	//
	if ( (Resize) && (Spinlock.ClaimLock(0)) )
		{
		REGISTER SBIT32 AlignMask = (RockallBackEnd -> NaturalSize()-1);
		REGISTER SBIT32 NewMaxHash = (MaxHash * ExpandStore);
		REGISTER SBIT32 NewMaxLookAside = (MaxLookAside * ExpandStore);
		REGISTER SBIT32 NewHashSize = (NewMaxHash * sizeof(LIST));
		REGISTER SBIT32 NewLookAsideSize = (NewMaxLookAside * sizeof(LOOK_ASIDE));
		REGISTER SBIT32 NewTotalSize = (NewHashSize + NewLookAsideSize);
		REGISTER SBIT32 HashSize = (MaxHash * sizeof(LIST));
		REGISTER SBIT32 LookAsideSize = (MaxLookAside * sizeof(LOOK_ASIDE));
		REGISTER SBIT32 TotalSize = (HashSize + LookAsideSize);

		//
		//   It is actually possible for a thread to get
		//   delayed for so long that it thinks the hash 
		//   table still needs to be resized long after the 
		//   work has been completed.  Additionally, we want
		//   to make sure that all the new values are sane.
		//
		if 
				(
				PowerOfTwo( (AlignMask+1) )
					&&
				(NewMaxHash > 0)
					&&
				(ConvertDivideToShift( NewMaxHash,& NewHashMask ))
					&&
				(NewMaxLookAside > 0)
					&& 
				(ConvertDivideToShift( NewMaxLookAside,& NewLookAsideMask ))
					&&
				((Used + (MaxHash / MinHashSpace)) > MaxHash)
				)
			{
			REGISTER LIST *NewHash;
			REGISTER LOOK_ASIDE *NewLookAside;

			//
			//   We have been picked as the victim who
			//   needs to resize the hash table.  We are
			//   going to call the external allocator 
			//   to get more memory.  As we know this is 
			//   likely to to nail us we drop the lock to 
			//   allow other threads to continue.
			//
			ReleaseFindExclusiveLock();

			//
			//   We know that allocating a new table and 
			//   initializing it is going to take ages.
			//   Well at least everyone else gets to carry
			//   on in the mean time.
			//
			NewHash = 
				((LIST*) RockallBackEnd -> NewArea
					( 
					AlignMask,
					NewTotalSize,
					False 
					)
				);

			NewLookAside = 
				((LOOK_ASIDE*) & NewHash[ NewMaxHash ]);

			//
			//   If the memory allocation request for the hash
			//   table fails we exit and try again later. 
			//
			if ( NewHash != ((LIST*) AllocationFailure) )
				{
				REGISTER SBIT32 Count;

				//
				//   Call the constructor for each hash table
				//   linked list header.
				//
				for ( Count=0;Count < NewMaxHash;Count ++ )
					{ PLACEMENT_NEW( & NewHash[ Count ],LIST ); }

				//
				//   Zero the look aside structure.
				//
				for ( Count=0;Count < NewMaxLookAside;Count ++ )
					{
					REGISTER LOOK_ASIDE *Current = & NewLookAside[ Count ];

					Current -> Address = ((VOID*) NoCacheEntry);
					Current -> Page = ((PAGE*) NoCacheEntry);
#ifdef DEBUGGING
					Current -> Version = ((SBIT32) NoCacheEntry);
#endif
					}
				}

			//
			//   Claim an exclusive lock so we can resize  
			//   the hash table.
			//
			ClaimFindExclusiveLock();

			//
			//   If we have allocated the new find table
			//   we can now rehash the existing entries.
			//   If not we are out of here.
			//
			if ( NewHash != ((LIST*) AllocationFailure) )
				{
				REGISTER SBIT32 Count;
				REGISTER SBIT32 MaxOldHash = MaxHash;
				REGISTER LIST *OldHash = Hash;

				//
				//   Update the control information 
				//   for the new hash table.
				//
				MaxHash = NewMaxHash;
				HashShift = (32-NewHashMask);
				HashMask = ((1 << NewHashMask)-1);

				MaxLookAside = NewMaxLookAside;
				LookAsideShift = (32-NewLookAsideMask);
				LookAsideMask = ((1 << NewLookAsideMask)-1);

				Hash = NewHash;
				LookAside = NewLookAside;

				//
				//   Delete all the existing records
				//   from the old hash table and insert
				//   them into the new hash table.
				//
				for ( Count=0;Count < MaxOldHash;Count ++ )
					{
					REGISTER LIST *Current = & OldHash[ Count ];

					//
					//   There are two find lists.  There 
					//   is the private find list and the
					//   public find list.  We choose which
					//   one to walk along.
					//
					if ( ! Public )
						{
						//
						//   Walk along each hash bucket 
						//   deleting the records and inserting
						//   them into the new hash table.
						//
						while ( ! Current -> EndOfList() )
							{
							REGISTER PAGE *Page = 
								(PAGE::FirstInPrivateFindList( Current ));
							REGISTER VOID *Address = 
								(Page -> GetAddress());
							REGISTER LIST *HeadOfList = 
								(FindHashHead( Address ));

							//
							//   Delele from the old find list
							//   and add into the new find
							//   list.
							//
							Page -> DeleteFromPrivateFindList( Current );

							Page -> InsertInPrivateFindList( HeadOfList );
							}
						}
					else
						{
						//
						//   Walk along each hash bucket 
						//   deleting the records and inserting
						//   them into the new hash table.
						//
						while ( ! Current -> EndOfList() )
							{
							REGISTER PAGE *Page = 
								(PAGE::FirstInPublicFindList( Current ));
							REGISTER VOID *Address = 
								(Page -> GetAddress());
							REGISTER LIST *HeadOfList = 
								(FindHashHead( Address ));

							//
							//   Delele from the old find list
							//   and add into the new find
							//   list.
							//
							Page -> DeleteFromPublicFindList( Current );

							Page -> InsertInPublicFindList( HeadOfList );
							}
						}

					}

				//
				//   Time to do more operating system work
				//   so lets drop the lock again.
				//
				ReleaseFindExclusiveLock();

				//
				//   Delete all the list heads and return the
				//   original allocation to the operating system.
				//
				for ( Count=0;Count < MaxOldHash;Count ++ )
					{ PLACEMENT_DELETE( & OldHash[ Count ],LIST ); }

				//
				//   Deallocate the old extent.
				//
				RockallBackEnd -> DeleteArea
					( 
					((VOID*) OldHash),
					TotalSize,
					False 
					);

				//
				//   We are finished so reclaim the lock
				//   so we can exit.
				//
				ClaimFindExclusiveLock();
				}
			else
				{ Resize = False; }
			}

		Spinlock.ReleaseLock();
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Update the find table.                                         */
    /*                                                                  */
    /*   We need to update the find table with certain information      */
    /*   to ensure it is used correctly and consistently.               */
    /*                                                                  */
    /********************************************************************/

VOID FIND::UpdateFind( BIT32 NewMaxAddressMask,BIT32 NewMinAddressMask )
    {
	//
	//   When we have a single heap image all the 'TopCache' sizes
	//   must be the same.
	//
	if 
			( 
			(MaxAddressMask == NoAddressMask) 
				|| 
			(MaxAddressMask == NewMaxAddressMask) 
			)
		{
		//
		//   If we need to be thread safe then claim a sharable lock
		//   on the hash table to stop it being changed under our feet.
		//
		ClaimFindExclusiveLock();

		//
		//   Update the max address mask if it is not the current
		//   value but yet consistent.
		//
		MaxAddressMask = NewMaxAddressMask;

		//
		//   Update the address mask is the new heap has a smaller
		//   parent than all of the other heaps.
		//
		if ( MinAddressMask > NewMinAddressMask )
			{ MinAddressMask = NewMinAddressMask; }

		//
		//   Release the lock if we claimed it earlier.
		//
		ReleaseFindExclusiveLock();
		}
	else
		{ Failure( "Different 'TopCache' sizes with 'SingleImage'" ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Walk the heap.                                                 */
    /*                                                                  */
    /*   We have been asked to walk the heap.  It is hard to know       */
    /*   whay anybody might want to do this given the rest of the       */
    /*   functionality available.  Nonetheless, we just do what is      */
    /*   required to keep everyone happy.                               */
    /*                                                                  */
    /********************************************************************/

BOOLEAN FIND::Walk
		( 
		BOOLEAN						  *Active,
		VOID						  **Address,
		CACHE						  *ParentCache,
		SBIT32						  *Size 
		)
    {
	REGISTER VOID *Memory = (*Address);
	REGISTER BOOLEAN Result;
	REGISTER BOOLEAN Update;
	REGISTER PAGE *Page;
	
	//
	//   If we need to be thread safe then claim a sharable lock
	//   on the hash table to stop it being changed under our feet.
	//
	ClaimFindShareLock();

	//
	//   When the address is null we need to set up the heap
	//   walk.  In all other cases we just extract the next
	//   allocation in the list.
	//
	if ( Memory != NULL )
		{
		AUTO SEARCH_PAGE Details;

		//
		//   Lets try the lookaside table.  There is a pretty
		//   good chance that we will have the details we need 
		//   already in the cache.  If not we need to find it
		//   the hard way.  During the process we add the mapping
		//   into the lookaside for next time.
		//
		if
				(
				Update =
					( 
					! FindLookAside
						( 
						((VOID*) (((SNATIVE) Memory) & ~MinAddressMask)),
						& Page 
						) 
					)
				)
			{
			//
			//   Find the allocation page and get the details of entry.
			//   We do this by finding the parent of the top cache.
			//   We  know that this is the global root and will find
			//   the correct page even if it is on another heap (as
			//   long as the find table is globally shared).
			//
			Page = (ParentCache -> FindParentPage( Memory,this ));
			}

		//
		//   We now compute all the details relating to the address
		//   so we can find any subsequent allocation.
		//
		if ( Page != ((PAGE*) NULL) )
			{ Page = (Page -> FindPage( Memory,& Details,this,True )); }

		//
		//   We may have failed to find the address  .If so
		//   we simply fail the call.  If not we find the next
		//   allocation in the heap.
		//
		if ( Result = ((Page != ((PAGE*) NULL)) && (Details.Found)) )
 			{
			//
			//   We need to walk the heap to get te details
			//   of the next allocation.
			//
			if ( Result = (Page -> Walk( & Details,this )) )
				{
				REGISTER BIT32 AllocationBit =
					((*Details.VectorWord) & Details.AllocationMask);

				(*Active) = (AllocationBit != 0);
				(*Address) = Details.Address;
				(*Size) = (Details.Page -> ActualSize());

				//
				//   If we are considering putting something
				//   in the lookaside lets make sure that
				//   we will get to hit the cache entry at
				//   least once.  If not lets forget putting
				//   it in the cache.
				//
				if ( Update )
					{
					Update =
						(
						(((SNATIVE) Memory) & ~MinAddressMask)
							==
						(((SNATIVE) Details.Address) & ~MinAddressMask)
						);
					}
				}
			}
		}
	else
		{
		AUTO SEARCH_PAGE Details;

		//
		//   We start a heap walk by setting the initial 
		//   address to the value null.
		//
		Details.Address = NULL;
		Details.Cache = ParentCache;
		Details.Page = NULL;

		Page = NULL;
		Update = False;

		//
		//   We walk the heap to get te details of the
		//   first heap allocation.
		//
		if ( Result = (Page -> Walk( & Details,this )) )
			{
			REGISTER BIT32 AllocationBit =
				((*Details.VectorWord) & Details.AllocationMask);

			(*Active) = (AllocationBit != 0);
			(*Address) = Details.Address;
			(*Size) = (Details.Page -> ActualSize());
			}
		}

	//
	//   Release the lock if we claimed it earlier and
	//   update the lookaside if needed.
	//
	if ( (Update) && (Result) )
		{ ReleaseFindShareLockAndUpdate( Memory,Page,Page -> GetVersion() ); }
	else
		{ ReleaseFindShareLock(); }

	return Result;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Delete the hash table and release all the associated memory.   */
    /*                                                                  */
    /********************************************************************/

FIND::~FIND( VOID )
    {
	REGISTER SBIT32 Count;
	REGISTER SBIT32 HashSize = (MaxHash * sizeof(LIST));
	REGISTER SBIT32 LookAsideSize = (MaxLookAside * sizeof(LOOK_ASIDE));
	REGISTER SBIT32 TotalSize = (HashSize + LookAsideSize);

	//
	//   Call the destructor for each hash table
	//   linked list header.
	//
	for ( Count=0;Count < MaxHash;Count ++ )
		{ PLACEMENT_DELETE( & Hash[ Count ],LIST ); }

	//
	//   Deallocate the area.
	//
	RockallBackEnd -> DeleteArea
		( 
		((VOID*) Hash),
		TotalSize,
		False 
		);
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\heappch.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\find.hpp ===
#ifndef _FIND_HPP_
#define _FIND_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Common.hpp"
#include "Environment.hpp"
#include "List.hpp"
#include "Page.hpp"
#include "Prefetch.hpp"
#include "RockallBackEnd.hpp"
#include "Sharelock.hpp"
#include "Spinlock.hpp"
#include "ThreadSafe.hpp"
  
    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   At the top level the parent of all caches is a constant        */
    /*   called 'GlobalRoot'.                                           */
    /*                                                                  */
    /********************************************************************/

CONST UNATIVE FindHashValue			  = 2964557531;

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;
class HEAP;

    /********************************************************************/
    /*                                                                  */
    /*   Find a memory allocation.                                      */
    /*                                                                  */
    /*   When a memory allocation is released all we are given is .     */
    /*   the allocation address.  This is not very helpful as the       */
    /*   allocation information is not stored relative to this          */
    /*   address.  Instead we use a hash table to map the allocation    */
    /*   address to the allocation information.                         */
    /*                                                                  */
    /********************************************************************/

class FIND : public ENVIRONMENT, public COMMON
    {
		//
		//   Private type specifications.
		//
		//   We need to do a recursive search in the find 
		//   table in order to locate the associated page
		//   from an address.  As this is expensive there
		//   is also a cache that slaves common translations
		//   to improve performance.
		//
		typedef struct
			{
			VOID					  *Address;
			PAGE					  *Page;
#ifdef DEBUGGING
			SBIT32					  Version;
#endif
			}
		LOOK_ASIDE;

		//
		//   Private data.
		//
		//   All the page descriptions are stored in the 
		//   hash table so they can be quickly found.  The
		//   key is the address of the first byte on the
		//   page.  The 'MaxHash' is the number of elements
		//   in the hash table and is always a power of two.
		//   The 'HashMask' is a bit mask to remove any 
		//   unwanted part of the hash key.  The 'HashShift'
		//   is the number of bits required to shift and is
		//   as a substitute for divide.  The 'Resize' flag
		//   indicates whether the hash table is permitted 
		//   to grow.
		//
		SBIT32						  MaxHash;

		SBIT32						  HashMask;
		SBIT32						  HashShift;
		BOOLEAN						  Public;
		BOOLEAN						  Resize;

		//
		//   The hash table allows addresses to be mapped to
		//   page descriptions quickly.  Nonetheless, it is 
		//   not fast enough.  To enhance performance a look
		//   aside cache slaves the hottest translations.  The
		//   'MaxLookAside' is the number of elements in the
		//   cache.  The 'MaxAddressMask' is a mask that removes 
		//   low order bits of an address and represents the
		//   span of each cache entry.  The 'LookAsideActions'
		//   is a simple count of requests to the cache.  The
		//   'LookAsideMask' and 'LookAsideShift' parallel the
		//   fields above in the hash table.  The 'LookAsideThreshold'
		//   determines at what point the cache will become 
		//   active.  
		//
		SBIT32						  MaxLookAside;

		UNATIVE						  MaxAddressMask;
		UNATIVE						  MinAddressMask;

		SBIT32						  LookAsideActions;
		SBIT32						  LookAsideMask;
		SBIT32						  LookAsideShift;
		SBIT32						  LookAsideThreshold;

		//
		//   When a request is made to translate an address to
		//   a page description the cache is the first port of
		//   call.  If the translation is not found then the
		//   hash table is tried.  The 'Hash' points to the hash
		//   table.  The 'LookAside' points to the lookaside
		//   hash table.  The 'Services' points to the external API
		//   to give access to the low level external allocation
		//   functions.  The 'ThreadSafe' class indicates whether
		//   locking is required.  
		//
		LIST						  *Hash;
		LOOK_ASIDE					  *LookAside;
		ROCKALL_BACK_END			  *RockallBackEnd;
		THREAD_SAFE					  *ThreadSafe;

		//
		//   The translation of addresses to page descriptions
		//   is very common.  So care has been taken to ensure
		//   it is not a bottleneck when locking is enabled.  The
		//   'Sharelock' is a fast reader/writer lock and is used
		//   almost all the time.  The 'Spinlock' is an exclusive
		//   lock and is only used when the 'Hash' and 'LookAside'
		//   tables are resized.
		//
		PREFETCH					  Prefetch;
		SHARELOCK					  Sharelock;
		SPINLOCK					  Spinlock;
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Statistics data.
		//
		//   There is a concern with any hash table about
		//   poor hashing keys and poor performance.  The
		//   statistics monitor various data so as to allow
		//   the performance metrics to be monitored.  The
		//   'Fills' counter keeps track of the number of
		//   cache fills.  The 'Hits' counter monitors the
		//   number of cache hits.  The 'MaxPages' counter
		//   is the high water mark of hash table entries.
		//   The 'MaxTests' is the max number of compares 
		//   done while searching an entry.  The 'Misses' 
		//   counter keeps track of the number of cache misses.
		//   The 'Scans' counter monitors the number of hash
		//   table searches.  The 'Tests' counter is the 
		//   total number of tests performed while searching
		//   for entries.
		//
		SBIT32						  Fills;
		SBIT32						  Hits;
		SBIT32						  MaxPages;
		SBIT32						  MaxTests;
		SBIT32						  Misses;
		SBIT32						  Scans;
		SBIT32						  Tests;
#endif
		SBIT32						  Used;

   public:
		//
		//   Public functions.
		//
		//   The translation functionality supplied by this
		//   class is only applicable after an allocation
		//   has been made.  Hence, all of the APIs supported
		//   relate to the need to translate an allocation
		//   address to the host page description.
		//
        FIND
			( 
			SBIT32					  NewMaxHash,
			SBIT32					  NewMaxLookAside,
			SBIT32					  NewFindThreshold,
			BOOLEAN					  NewPublic,
			BOOLEAN					  NewResize,
			ROCKALL_BACK_END		  *NewRockallBackEnd,
			THREAD_SAFE				  *NewThreadSafe 
			);

		BOOLEAN Delete( VOID *Address,CACHE *ParentCache );

		VOID DeleteFromFindList( PAGE *Page );

		BOOLEAN Details
			( 
			VOID					  *Address,
			SEARCH_PAGE				  *Details,
			CACHE					  *ParentCache,
			SBIT32					  *Size 
			);

		PAGE *FindPage( VOID *Address,CACHE *ParentCache );

		VOID InsertInFindList( PAGE *Page );

		BOOLEAN KnownArea( VOID *Address,CACHE *ParentCache );

		VOID ReleaseFindShareLockAndUpdate
			( 
			VOID					  *Address,
			PAGE					  *Page,
			SBIT32					  Version 
			);

		BOOLEAN Walk
			( 
			BOOLEAN					  *Active,
			VOID					  **Address,
			CACHE					  *ParentCache,
			SBIT32					  *Size 
			);

		VOID UpdateFind
			( 
			BIT32					  NewMaxAddressMask,
			BIT32					  NewMinAddressMask
			);

        ~FIND( VOID );

		//
		//   Public inline functions.
		//
		//   Although this class is perhaps the most self
		//   contained.  Nonetheless, there is still lots
		//   of situations when other classes need to 
		//   interact and get information about the current
		//   situation.
		//
		INLINE VOID ClaimFindExclusiveLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ClaimExclusiveLock(); } 
			}

		INLINE VOID ClaimFindShareLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ClaimShareLock(); } 
			}

		INLINE VOID DeleteAll( VOID )
			{ LookAsideActions = 0; }

		INLINE VOID ReleaseFindExclusiveLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ReleaseExclusiveLock(); } 
			}

		INLINE VOID ReleaseFindShareLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ReleaseShareLock(); } 
			}
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Public inline statistic functions.
		//
		//   The statistics are typically provided in 
		//   debug builds to provide good information  
		//   about allocation patterns.  
		//
		INLINE SBIT32 AverageHashLength( VOID )
			{ return (Tests / ((Scans > 0) ? Scans : 1)); }

		INLINE SBIT32 CacheFills( VOID )
			{ return Fills; }

		INLINE SBIT32 CacheHits( VOID )
			{ return Hits; }

		INLINE SBIT32 CacheMisses( VOID )
			{ return Misses; }

		INLINE SBIT32 MaxHashLength( VOID )
			{ return MaxTests; }

		INLINE SBIT32 MaxHashSize( VOID )
			{ return MaxHash; }

		INLINE SBIT32 MaxLookAsideSize( VOID )
			{ return MaxLookAside; }

		INLINE SBIT32 MaxUsage( VOID )
			{ return ((MaxPages * 100) / MaxHash); }

		INLINE SBIT32 TotalScans( VOID )
			{ return Scans; }
#endif

	private:
		//
		//   Private functions.
		//
		//   Although the hashed lookup functionality is 
		//   externally visable the look aside cache is 
		//   hidden from view along with the ability to
		//   resize the hash table.
		//
		BOOLEAN FindLookAside( VOID *Address,PAGE **Page );

		VOID ResizeHashTable( VOID );

		//
		//   Private inline functions.
		//
		//   Although I am not keen on code in the headers
		//   certain functions are so small or so hot that
		//   I have to submit to the desire to do it. 
		//
		INLINE VOID ChangeToExclusiveLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Sharelock.ChangeSharedLockToExclusiveLock(); } 
			}

		INLINE LIST *FindHashHead( VOID *Address )
			{
			REGISTER UNATIVE Value = (((UNATIVE) Address) * FindHashValue);

			return (& Hash[ ((Value >> HashShift) & HashMask) ]); 
			}

		INLINE LOOK_ASIDE *FindLookAsideHead( VOID *Address )
			{
			REGISTER UNATIVE Value = (((UNATIVE) Address) * FindHashValue);

			return (& LookAside[ ((Value >> LookAsideShift) & LookAsideMask) ]); 
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        FIND( CONST FIND & Copy );

        VOID operator=( CONST FIND & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\bucket.hpp ===
#ifndef _BUCKET_HPP_
#define _BUCKET_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Connections.hpp"
#include "Page.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;
class HEAP;

    /********************************************************************/
    /*                                                                  */
    /*   A collection of pages.                                         */
    /*                                                                  */
    /*   A bucket is a collection of pages capable of allocating        */
    /*   fixed sized memory elements.  The pages are allocated from     */
    /*   from larger buckets and are stored in a linked list in         */
    /*   order of ascending of page addresses.                          */
    /*                                                                  */
    /********************************************************************/

class BUCKET : public CONNECTIONS
    {
		//
		//   Private type definitions.
		//
		//   All allocations are registered in bit vectors.
		//   Here we have some prototypes for seriously  
		//   optimized functions to do address to bit 
		//   vector computations.
		//
		typedef VOID *(BUCKET::*COMPUTE_ADDRESS)
			( 
			CHAR					  *Address,
			SBIT32					  Offset 
			);

		typedef SBIT32 (BUCKET::*COMPUTE_OFFSET)
			( 
			SBIT32					  Displacement,
			BOOLEAN					  *Found 
			);

		//
		//   Private data.
		//
		//   A bucket owns all the memory of a given size
		//   and manages it.  Above it is a cache to 
		//   protect it from huge number of calls and
		//   below it are the connections to various 
		//   other classes.  The 'AllocationSize' is the
		//   buckets allocation size.  The 'ChunkSize' is
		//   chunking size which is typically half way
		//   between the 'AllocationSize' and the 'PageSize'.
		//   The 'PageSize' is the size of the bucket
		//   where this bucket gets its space.
		//   
		//
		SBIT32                        AllocationSize;
		SBIT32						  ChunkSize;
		SBIT32						  PageSize;

		//
		//   It is the job of the bucket to keep track of
		//   all the information relating to allocations
		//   of a given 'AllocationSize'.  The 'ActivePages'
		//   keeps track of the number of available pages
		//   in the 'BucketList'.  The 'BucketList' is a
		//   linked list of pages that have available space.
		//   The 'CurrentPage' contains the highest address
		//   of the first page in the 'BucketList'.
		//
		SBIT32						  ActivePages;
		LIST						  BucketList;
		VOID						  *CurrentPage;

		//
		//   A bucket needs to be able to quickly convert
		//   bit vector offsets to addresses (and vice versa).
		//   The 'AllocationShift' is set when the 
		//   'AllocationSize' is a power of two to avoid 
		//   any divides.  The 'ChunkShift' is set when the
		//   'ChunckSize' is a power of two to avoid some
		//   divides.  The 'ComputeAddressFunction' and
		//   'ComputeOffsetFunction' point to optimized
		//   functions to do conversions that are selected
		//   by the constructor.
		//
		SBIT32						  AllocationShift;
		SBIT32						  ChunkShift;
		COMPUTE_ADDRESS				  ComputeAddressFunction;
		COMPUTE_OFFSET				  ComputeOffsetFunction;

		//
		//   A bucket typically contains a collection of
		//   pages.  As all pages are the same data that
		//   should really be stored in page descriptions
		//   is instead stored in the bucket to save space.
		//   The 'NumberOfElements' contains the number of
		//   elements in each pages bit vector.  The 
		//   'SizeOfChunks' contains the pre-computed chunk
		//   size.  The 'SizeOfElements' contains the number
		//   of words in the pages bit vector.  The 'SizeKey'
		//   contains an index which selects the size of the
		//   bit vector when a new page is created.
		//
		SBIT16						  NumberOfElements;
		SBIT16						  SizeOfChunks;
		SBIT16						  SizeOfElements;
		SBIT16						  SizeKey;

   public:
		//
		//   Public functions.
		//
		//   The functionality provided by this class pretty
		//   much matches the external API.  Nonetheless, these
		//   APIs are protected from excessive calls by a fast
		//   cache that is derived from this class.
		//
        BUCKET
			( 
			SBIT32					  NewAllocationSize,
			SBIT32					  NewChunkSize,
			SBIT32					  NewPageSize 
			);

		BOOLEAN Delete( VOID *Address,PAGE *Page,SBIT32 Version );

		VOID DeleteFromBucketList( PAGE *Page );

		VOID InsertInBucketList( PAGE *Page );

		BOOLEAN MultipleDelete
			( 
			ADDRESS_AND_PAGE		  *Array,
			SBIT32					  *Deleted,
			SBIT32					  Size 
			);

		BOOLEAN MultipleNew
			( 
			SBIT32					  *Actual,
			VOID					  *Array[],
			SBIT32					  Requested 
			);

		VOID *New( BOOLEAN SubDivided,SBIT32 NewSize = NoSize );

		VOID ReleaseSpace( SBIT32 MaxActivePages );

		VOID UpdateBucket
			( 
			HEAP					  *NewHeap,
			NEW_PAGE				  *NewPages,
			CACHE					  *NewParentCache,
			FIND					  *NewPrivateFind,
			FIND					  *NewPublicFind
			);

        ~BUCKET( VOID );

		//
		//   Public inline functions.
		//
		//   It saves a significant amount of space by putting
		//   common information in the bucket instead of a 
		//   separate copy in each page description.  Nonetheless,
		//   it means that both classes are very much dependent
		//   upon each other.
		//
		INLINE VOID *ComputeAddress( CHAR *Address,SBIT32 Offset )
			{ return (this ->* ComputeAddressFunction)( Address,Offset ); }

		INLINE SBIT32 ComputeOffset( SBIT32 Displacement,BOOLEAN *Found )
			{ return (this ->* ComputeOffsetFunction)( Displacement,Found ); }

		INLINE SBIT32 GetAllocationSize( VOID )
			{ return AllocationSize; }

		INLINE SBIT32 GetChunkSize( VOID )
			{ return ChunkSize; }

		VOID *GetCurrentPage( VOID )
			{ return CurrentPage; }

		INLINE SBIT16 GetNumberOfElements( VOID )
			{ return NumberOfElements; }

		INLINE SBIT32 GetPageSize( VOID )
			{ return PageSize; }

		INLINE SBIT16 GetSizeOfChunks( VOID )
			{ return SizeOfChunks; }

		INLINE SBIT16 GetSizeOfElements( VOID )
			{ return SizeOfElements; }

		INLINE SBIT16 GetSizeKey( VOID )
			{ return SizeKey; }

	private:
		//
		//   Private functions.
		//
		//   When we need to convert an address to a bit 
		//   offset (or vice versa) we use one of the following 
		//   functions.
		//
		VOID *ComputeAddressBestCase( CHAR *Address,SBIT32 Offset );
		VOID *ComputeAddressGoodCase( CHAR *Address,SBIT32 Offset );
		VOID *ComputeAddressPoorCase( CHAR *Address,SBIT32 Offset );
		VOID *ComputeAddressWorstCase( CHAR *Address,SBIT32 Offset );

		SBIT32 ComputeOffsetBestCase( SBIT32 Displacement,BOOLEAN *Found );
		SBIT32 ComputeOffsetGoodCase( SBIT32 Displacement,BOOLEAN *Found );
		SBIT32 ComputeOffsetPoorCase( SBIT32 Displacement,BOOLEAN *Found );
		SBIT32 ComputeOffsetWorstCase( SBIT32 Displacement,BOOLEAN *Found );

        //
        //   Disabled operations.
 		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
		//
        BUCKET( CONST BUCKET & Copy );

        VOID operator=( CONST BUCKET & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\bucket.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Bucket.hpp"
#include "Cache.hpp"
#include "Heap.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here relate the compuation of the       */
    /*   current active page address range.                             */
    /*                                                                  */
    /********************************************************************/

CONST SNATIVE HighestAddress		  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new allocation bucket and prepare it for use.         */
    /*   We need to be sure to carefully check everything we have       */
    /*   been supplied as it has come indirectly from the user.         */
    /*                                                                  */
    /********************************************************************/

BUCKET::BUCKET
		( 
		SBIT32						  NewAllocationSize,
		SBIT32						  NewChunkSize,
		SBIT32						  NewPageSize 
		)
    {
	//
	//   We want to make sure that the bucket configuration
	//   appears to make basic sense.  If not we have no 
	//   alternative than to throw an expection.
	//
	if
			(
			(NewAllocationSize > 0)
				&&
			(NewChunkSize >= NewAllocationSize)
				&&
			(NewChunkSize <= NewPageSize)
				&&
			PowerOfTwo( NewPageSize )
			)
		{
		//
		//   Create the bucket and prepare it for use.
		//   Pre-compute any information we can here to
		//   save work later.
		//
		AllocationSize = NewAllocationSize;
		ChunkSize = NewChunkSize;
		PageSize = NewPageSize;

		ActivePages = 0;
		AllocationShift = 0;
		ChunkShift = 0;

		//
		//   Compute the optimization level from the available
		//   bucket information.  The highest level means
		//   everything is a power of two (just shifts - yipee !!).
		//   The next means no chunks (i.e. simple scaling), The
		//   next means simple chunks (i.e. complex scaling).
		//   The final alternative is to horrid to discuss. 
		//   
		if ( ConvertDivideToShift( AllocationSize,& AllocationShift ) )
			{
			//
			//   If we are not using chunking we can skip the
			//   extra compuation that is needed.  We can tell
			//   this is the case if the chunk size and the page
			//   size match or if the chunk size is a multiple
			//   of the allocation size.
			//
			if 
					( 
					(ChunkSize == PageSize)
						||
					((ChunkSize % AllocationSize) == 0)
					)
				{
				//
				//   The best case is when we can use shifts
				//   instead of multiply and divide.
				//
				ComputeAddressFunction = & BUCKET::ComputeAddressBestCase;
				ComputeOffsetFunction = & BUCKET::ComputeOffsetBestCase;
				}
			else
				{
				//
				//   When we have chunks we have to do more 
				//   work invloving additional multiples and
				//   divides.  Nonetheless, we try to minimize
				//   these as far as possible.
				// 
				if ( ConvertDivideToShift( ChunkSize,& ChunkShift ) )
					{
					//
					//   We have managed to replace some of the
					//   multiplies and divides with shifts.
					//
					ComputeAddressFunction = & BUCKET::ComputeAddressPoorCase;
					ComputeOffsetFunction = & BUCKET::ComputeOffsetPoorCase;
					}
				else
					{
					//
					//   We are unable to optimize this case.
					//   These calls will really hurt.
					//
					ComputeAddressFunction = & BUCKET::ComputeAddressWorstCase;
					ComputeOffsetFunction = & BUCKET::ComputeOffsetWorstCase;
					}
				}
			}
		else
			{
			//
			//   If we are not using chunking we can skip the
			//   extra compuation that is needed.  We can tell
			//   this is the case if the chunk size and the page
			//   size match or if the chunk size is a multiple
			//   of the allocation size.
			//
			if 
					( 
					(ChunkSize == PageSize)
						||
					((ChunkSize % AllocationSize) == 0)
					)
				{ 
				//
				//   A good case is when we can use a few
				//   simple multiplies and divides to do simple
				//   scaling.
				//
				ComputeAddressFunction = & BUCKET::ComputeAddressGoodCase;
				ComputeOffsetFunction = & BUCKET::ComputeOffsetGoodCase;
				}
			else
				{ 
				//
				//   When we have chunks we have to do more 
				//   work invloving additional multiples and
				//   divides.  Nonetheless, we try to minimize
				//   these as far as possible.
				// 
				if ( ConvertDivideToShift( ChunkSize,& ChunkShift ) )
					{
					//
					//   We have managed to replace some of the
					//   multiplies and divides with shifts.
					//
					ComputeAddressFunction = & BUCKET::ComputeAddressPoorCase;
					ComputeOffsetFunction = & BUCKET::ComputeOffsetPoorCase;
					}
				else
					{
					//
					//   We are unable to optimize this case.
					//   These calls will really hurt.
					//
					ComputeAddressFunction = & BUCKET::ComputeAddressWorstCase;
					ComputeOffsetFunction = & BUCKET::ComputeOffsetWorstCase;
					}
				}
			}

		//
		//   Compute all the information that will be
		//   needed later to describe the allocation
		//   pages.
		//
		NumberOfElements = 
			((SBIT16) ((PageSize / ChunkSize) * (ChunkSize / AllocationSize)));
		SizeOfChunks = (SBIT16)
			((SBIT16) (ChunkSize / AllocationSize));
		SizeOfElements = (SBIT16)
			((SBIT16) (((NumberOfElements-1) / OverheadBitsPerWord) + 1));
		SizeKey = NoSizeKey;
		}
	else
		{ Failure( "Configuration in constructor for BUCKET" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the allocation address.                                */
    /*                                                                  */
    /*   Compute the allocation address given the page address and      */
    /*   the vector offset in the page.                                 */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::ComputeAddressBestCase( CHAR *Address,SBIT32 Offset )
	{ return ((VOID*) (Address + (Offset << AllocationShift))); }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the allocation address.                                */
    /*                                                                  */
    /*   Compute the allocation address given the page address and      */
    /*   the vector offset in the page.                                 */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::ComputeAddressGoodCase( CHAR *Address,SBIT32 Offset )
	{ return ((VOID*) (Address + (Offset * AllocationSize))); }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the allocation address.                                */
    /*                                                                  */
    /*   Compute the allocation address given the page address and      */
    /*   the vector offset in the page.                                 */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::ComputeAddressPoorCase( CHAR *Address,SBIT32 Offset )
	{
	REGISTER SBIT32 ChunkNumber = (Offset / SizeOfChunks);
	REGISTER SBIT32 ChunkOffset = (ChunkNumber * SizeOfChunks);
	REGISTER SBIT32 AllocationNumber = (Offset - ChunkOffset);

	return
		((VOID*)
			(
			Address 
				+
			(ChunkNumber << ChunkShift)
				+
			(AllocationNumber * AllocationSize)
			)
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the allocation address.                                */
    /*                                                                  */
    /*   Compute the allocation address given the page address and      */
    /*   the vector offset in the page.                                 */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::ComputeAddressWorstCase( CHAR *Address,SBIT32 Offset )
	{
	REGISTER SBIT32 ChunkNumber = (Offset / SizeOfChunks);
	REGISTER SBIT32 ChunkOffset = (ChunkNumber * SizeOfChunks);
	REGISTER SBIT32 AllocationNumber = (Offset - ChunkOffset);

	return
		((VOID*)
			(
			Address 
				+
			(ChunkNumber * ChunkSize)
				+
			(AllocationNumber * AllocationSize)
			)
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the bit vector offset.                                 */
    /*                                                                  */
    /*   Compute the bit vector offset given the address of the         */
    /*   memory allocation in the page.                                 */
    /*                                                                  */
    /********************************************************************/

SBIT32 BUCKET::ComputeOffsetBestCase( SBIT32 Displacement,BOOLEAN *Found )
	{
	REGISTER SBIT32 ArrayOffset = (Displacement >> AllocationShift);

	(*Found) = (Displacement == (ArrayOffset << AllocationShift));
#ifdef DEBUGGING

	if ( ArrayOffset >= NumberOfElements )
		{ Failure( "Array offset in ComputeOffsetBestCase" ); }
#endif

	return ArrayOffset;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the bit vector offset.                                 */
    /*                                                                  */
    /*   Compute the bit vector offset given the address of the         */
    /*   memory allocation in the page.                                 */
    /*                                                                  */
    /********************************************************************/

SBIT32 BUCKET::ComputeOffsetGoodCase( SBIT32 Displacement,BOOLEAN *Found )
	{
	REGISTER SBIT32 ArrayOffset = (Displacement / AllocationSize);

	(*Found) = (Displacement == (ArrayOffset * AllocationSize));
#ifdef DEBUGGING

	if ( ArrayOffset >= NumberOfElements )
		{ Failure( "Array offset in ComputeOffsetGoodCase" ); }
#endif

	return ArrayOffset;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the bit vector offset.                                 */
    /*                                                                  */
    /*   Compute the bit vector offset given the address of the         */
    /*   memory allocation in the page.                                 */
    /*                                                                  */
    /********************************************************************/

SBIT32 BUCKET::ComputeOffsetPoorCase( SBIT32 Displacement,BOOLEAN *Found )
	{
	REGISTER SBIT32 ArrayOffset;
	REGISTER SBIT32 ChunkNumber = (Displacement >> ChunkShift);
	REGISTER SBIT32 ChunkAddress = (ChunkNumber << ChunkShift);
	REGISTER SBIT32 ChunkOffset = (Displacement - ChunkAddress);
	REGISTER SBIT32 AllocationNumber = (ChunkOffset / AllocationSize);

	ArrayOffset = ((ChunkNumber * SizeOfChunks) + AllocationNumber);

	(*Found) = 
		(
		(Displacement) 
			== 
		(ChunkAddress + (AllocationNumber * AllocationSize))
		);
#ifdef DEBUGGING

	if ( ArrayOffset >= NumberOfElements )
		{ Failure( "Array offset in ComputeOffsetPoorCase" ); }
#endif

	return ArrayOffset;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Compute the bit vector offset.                                 */
    /*                                                                  */
    /*   Compute the bit vector offset given the address of the         */
    /*   memory allocation in the page.                                 */
    /*                                                                  */
    /********************************************************************/

SBIT32 BUCKET::ComputeOffsetWorstCase( SBIT32 Displacement,BOOLEAN *Found )
	{
	REGISTER SBIT32 ArrayOffset;
	REGISTER SBIT32 ChunkNumber = (Displacement / ChunkSize);
	REGISTER SBIT32 ChunkAddress = (ChunkNumber * ChunkSize);
	REGISTER SBIT32 ChunkOffset = (Displacement - ChunkAddress);
	REGISTER SBIT32 AllocationNumber = (ChunkOffset / AllocationSize);

	ArrayOffset = ((ChunkNumber * SizeOfChunks) + AllocationNumber);

	(*Found) = 
		(
		(Displacement) 
			== 
		(ChunkAddress + (AllocationNumber * AllocationSize))
		);
#ifdef DEBUGGING

	if ( ArrayOffset >= NumberOfElements )
		{ Failure( "Array offset in ComputeOffsetWorstCase" ); }
#endif

	return ArrayOffset;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete a memory allocation.                                    */
    /*                                                                  */
    /*   We need to delete a single memory allocation from a bucket.    */
    /*   We do this by passing the request on to the page.              */
    /*                                                                  */
    /********************************************************************/

BOOLEAN BUCKET::Delete( VOID *Address,PAGE *Page,SBIT32 Version )
	{
	AUTO SEARCH_PAGE Details;

	//
	//   When we delete an allocation we need to ensure 
	//   the page has not radically changed since we found
	//   it.  Hence, we compare the current page version  
	//   number with the one we found earlier.  If all is 
	//   well we get the details relating to the allocation
	//   and then delete it.
	//
	return
		(
		((Page -> GetVersion()) == Version)
			&&
		(Page -> FindPage( Address,& Details,PrivateFind,False ) != NULL)
			&&
		(Page -> Delete( & Details ))
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete a page from the bucket list.                            */
    /*                                                                  */
    /*   When a page becomes full it is removed from the bucket list    */
    /*   so it will be no longer inspected when looking for free space. */
    /*                                                                  */
    /********************************************************************/

VOID BUCKET::DeleteFromBucketList( PAGE *Page )
	{
	//
	//   We keep track of the number of active pages on the 
	//   bucket list.  This helps us when we need to scan the
	//   bucket list for some reason later.
	//
	if ( (-- ActivePages) >= 0 )
		{
		//
		//   Delete the page from the bucket list as it is 
		//   no longer needed.  There are two cases when this 
		//   happens.  When the page is full and when the page 
		//   is about to be deleted.
		//
		Page -> DeleteFromBucketList( & BucketList );

		//
		//   Compute the highest address on the first page.  We 
		//   use this information to figure out whether to 
		//   recycle an allocation or pass it along for deletion
		//   in the cache.
		//
		Page = (PAGE::FirstInBucketList( & BucketList ));
		
		if ( ! Page -> EndOfBucketList() )
			{
			CurrentPage =
				(
				((VOID*) (((SNATIVE) Page -> GetAddress()) + (PageSize - 1)))
				);
			}
		else
			{ CurrentPage = ((VOID*) HighestAddress); }
		}
	else
		{ Failure( "Active page count in DeleteFromBucketList" ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Insert a page into the bucket list.                            */
    /*                                                                  */
    /*   When a page is created or when it changes from being full      */
    /*   to having at least one free slot it is added to the bucket     */
    /*   list so that it can be used to allocate space.                 */
    /*                                                                  */
    /********************************************************************/

VOID BUCKET::InsertInBucketList( PAGE *Page )
	{
	//
	//   We keep track of the number of active pages on the 
	//   bucket list.  This helps us when we need to scan the
	//   bucket list for some reason later.
	//
	ActivePages ++;

	//
	//   We insert pages into the list in ascending address
	//   order.  This ensures that we always allocate the 
	//   lowest addresses first.  This is done to try to keep 
	//   the working set small and compact.
	//
	if ( ! BucketList.EndOfList() )
		{
		REGISTER VOID *Address = (Page -> GetAddress());
		REGISTER PAGE *Last = (Page -> LastInBucketList( & BucketList ));

		//
		//   We are about to walk the entire page list
		//   trying to find where to insert this page.
		//   Lets see if the page needs to be inserted
		//   at the end of the list.  If so have saved
		//   ourseleves a lot of work and we can exit 
		//   early.
		//   
		if ( Address < (Last -> GetAddress()) )
			{
			REGISTER PAGE *Current;

			//
			//   Well it looks like we need to walk along 
			//   the entire page list to find the correct 
			//   place to insert this element.
			//
			for 
					( 
					Current = (Page -> FirstInBucketList( & BucketList ));
					! Current -> EndOfBucketList();
					Current = Current -> NextInBucketList() 
					)
				{
				//
				//   While the current address is lower 
				//   than ours we need to keep on walking.
				//
				if ( Address < (Current -> GetAddress()) )
					{
					//
					//   We have found the spot so insert 
					//   the bucket just before the current 
					//   bucket.
					//
					Current -> InsertBeforeInBucketList( & BucketList,Page );

					break;
					}
				}
			}
		else
			{
			//
			//   The page has the highest address so insert
			//   it at the end of the list.
			//
			Last -> InsertAfterInBucketList( & BucketList,Page );
			}
		}
	else
		{ Page -> InsertInBucketList( & BucketList ); }

	//
	//   Compute the highest address on the first page.  We can
	//   use this information to figure out whether to recycle an
	//   allocation or pass it along for deletion in the cache.
	//
	Page = (PAGE::FirstInBucketList( & BucketList ));
	
	CurrentPage =
		(
		((VOID*) (((SNATIVE) Page -> GetAddress()) + (PageSize - 1)))
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory deallocations.                                 */
    /*                                                                  */
    /*   When the delete cache becomes full we complete any pending     */
    /*   delete requests.  We also flush the delete cache when if       */
    /*   we need to allocate additional memory unless recycling is      */
    /*   enabled in which case we just steal it directly from the       */
    /*   delete cache.                                                  */
    /*                                                                  */
    /********************************************************************/

BOOLEAN BUCKET::MultipleDelete
		( 
		ADDRESS_AND_PAGE			  *Array,
		SBIT32						  *Deleted,
		SBIT32						  Size 
		)
	{
	AUTO SEARCH_PAGE Details;
	REGISTER SBIT32 Count;

	//
	//   Zero the count of deleted items.
	//
	(*Deleted) = 0;

	//
	//   Delete each element one at a time.  We would love to
	//   delete them all at once but we haven't got a clue where
	//   they have come from so we have to do it one at a time. 
	//   
	for ( Count=0;Count < Size;Count ++ )
		{
		REGISTER ADDRESS_AND_PAGE *Current = & Array[ Count ];
		REGISTER VOID *Address = Current -> Address;
		REGISTER PAGE *Page = Current -> Page;

		//
		//   It may see like a waste of time to batch up all
		//   the deletions.  Why not do them as they arrive.
		//   There are a number of reasons.  The deletes can
		//   be recycled, batchs of deletes is faster than
		//   single deletes (due to cache effects) and so on.
		//
		if
				(
				(Current -> Version == Page -> GetVersion())
					&&
				(Page -> FindPage( Address,& Details,PrivateFind,False ) != NULL)
					&&
				(Page -> Delete( & Details ))
				)
			{ (*Deleted) ++; }
		}

	return ((*Deleted) == Size);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory allocations.                                   */
    /*                                                                  */
    /*   We need to make a multiple memory allocation from this			*/
    /*   bucket so walk the bucket list allocating any available        */
    /*   space and return it to the caller.                             */
    /*                                                                  */
    /********************************************************************/

BOOLEAN BUCKET::MultipleNew
		( 
		SBIT32						  *Actual,
		VOID						  *Array[],
		SBIT32						  Requested 
		)
    {
	//
	//   Zero the count of allocated elements.
	//
	(*Actual) = 0;

	//
	//   We walk the sorted list of pages with available
	//   allocations searching for elements to allocate.
	//
	do
		{
		REGISTER PAGE *Page;
		REGISTER PAGE *NextPage;

		//
		//   Walk the bucket list looking for any available
		//   free space.
		//
		for 
				( 
				Page = (PAGE::FirstInBucketList( & BucketList ));
				! Page -> EndOfBucketList();
				Page = NextPage
				)
			{
			REGISTER SBIT32 ActualSize = (Page -> GetPageSize());

			//
			//   Lets find the next page now as the current 
			//   bucket may be removed from the bucket list
			//   by the following allocation call.
			//
			NextPage = Page -> NextInBucketList();

			//
			//   We allow the page size to be dynamically
			//   modified to support a variety of wierd
			//   data layouts for BBT.   If the current page
			//   is not the standard size then skip it.
			//
			if ( (ActualSize == NoSize) || (ActualSize == PageSize) )
				{
				//
				//   We try allocate all the space we need 
				//   from each page in the bucket list.  If 
				//   the page has enough space we can exit 
				//   early if not we go round the loop and
				//   try the next page.
				//
				if ( Page -> MultipleNew( Actual,Array,Requested ) )
					{ return True; }
				}
			}
		}
	while 
		( 
		NewPage -> CreatePage( (CACHE*) this )
			!= 
		((PAGE*) AllocationFailure) 
		);

	//
	//   We see if we managed to allocate all the elements
	//   we wanted.  If so we are happy and we can get out 
	//   of here.
	//
	if ( (*Actual) < Requested )
		{
		//
		//   We see if we managed to allocate any elements 
		//   at all.  If not we fail the request.
		//
		if ( (*Actual) > 0 )
			{
			REGISTER SBIT32 Count;
			REGISTER SBIT32 Delta = ((Requested) - (*Actual));

			//
			//   We are very naughty when we allocate multiple
			//   elements in that we put them in the array in
			//   reverse order.  The logic is that this is just
			//   what we want when we allocate out of the cache.
			//   However, if we are unable to allocate all the
			//   elements we needed then we have to move the 
			//   pointers down to the base of the array.
			//
			for ( Count=0;Count < (*Actual);Count ++ )
				{ Array[ Count ] = Array[ (Count + Delta) ]; }
			}
		else
			{ return False; }
		}

	return True;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Memory allocation.                                             */
    /*                                                                  */
    /*   We need to make a new memory allocation from this bucket       */
    /*   so search the page list of available space and return a        */
    /*   free element.                                                  */
    /*                                                                  */
    /********************************************************************/

VOID *BUCKET::New( BOOLEAN SubDivided,SBIT32 NewSize )
    {
	do
		{
		REGISTER PAGE *Page;

		//
		//   Walk the bucket list looking for any available
		//   free space.
		//
		for 
				( 
				Page = (PAGE::FirstInBucketList( & BucketList ));
				! Page -> EndOfBucketList();
				Page = Page -> NextInBucketList()
				)
			{
			REGISTER SBIT32 ActualSize = (Page -> GetPageSize());

			//
			//   We allow the page size to be dynamically
			//   modified to support a variety of wierd
			//   data layouts for BBT.   If the current page
			//   is not the correct size then skip it.
			//
			if 
					( 
					(ActualSize == NoSize) 
						|| 
					(ActualSize == ((NewSize == NoSize) ? PageSize : NewSize))
					)
				{
				//
				//   We know that any page that appears in 
				//   the bucket list will have at least one 
				//   free element available.  So if we find
				//   that the bucket list a suitable page 
				//   then we know that we can allocate something.
				//
				return (Page -> New( SubDivided ));
				}
			}
		}
	while 
		( 
		NewPage -> CreatePage( ((CACHE*) this),NewSize ) 
			!= 
		((PAGE*) AllocationFailure) 
		);

	//
	//   We were unable to find anything we could allocate
	//   so fail the request.
	//
	return ((VOID*) AllocationFailure);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release free space.                                            */
    /*                                                                  */
    /*   We sometimes do not release free space from a bucket as        */
    /*   returning it to the operating system and getting it again      */
    /*   later is very expensive.  Here we flush any free space we      */
    /*   have aquired over the user supplied limit.                     */
    /*                                                                  */
    /********************************************************************/

VOID BUCKET::ReleaseSpace( SBIT32 MaxActivePages )
    {
	REGISTER SBIT32 Current = ActivePages;

	//
	//   We only bother to try to trim the number of
	//   active pages if we are over the limit.
	//
	if ( Current > MaxActivePages )
		{
		REGISTER PAGE *NextPage;
		REGISTER PAGE *Page;

		//
		//   Walk the backwards along the bucket list 
		//   and delete the highest addressed free pages
		//   if we are over the limit.
		//
		for 
				( 
				Page = (PAGE::LastInBucketList( & BucketList ));
				(Current > MaxActivePages) 
					&& 
				(! Page -> EndOfBucketList());
				Page = NextPage
				)
			{
			//
			//   We are walking backwards down the bucket
			//   list looking for empty pages to delete.
			//   However, if we find a page we can remove
			//   it will be automatically removed from the
			//   list so we need to get the next pointer
			//   before this happens.
			//
			NextPage = Page -> PreviousInBucketList();

			//
			//   We can only release a page if it is empty
			//   if not we must skip it.
			//
			if ( Page -> Empty() )
				{
				Current --;

				DeletePage( Page ); 
				}
			}
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Update the bucket information.                                 */
    /*                                                                  */
    /*   When we create the bucket there is some information that       */
    /*   is not available.  Here we update the bucket to make sure      */
    /*   it has all the data we need.                                   */
    /*                                                                  */
    /********************************************************************/

VOID BUCKET::UpdateBucket
		( 
		HEAP						  *NewHeap,
		NEW_PAGE					  *NewPages,
		CACHE						  *NewParentCache,
		FIND						  *NewPrivateFind,
		FIND						  *NewPublicFind
		)
	{
	REGISTER SBIT16 NewSizeKey = (NewPages -> FindSizeKey( NumberOfElements ));

	//
	//   We compute and verify the size key to make sure
	//   it is suitable for all the pages that we will
	//   create after the heap constructor is completed.
	//
	if ( NewSizeKey != NoSizeKey )
		{
		//
		//   Update the size key and the connections.
		//
		SizeKey = NewSizeKey;

		UpdateConnections
			( 
			NewHeap,
			NewPages,
			NewParentCache, 
			NewPrivateFind,
			NewPublicFind
			);
		}
	else
		{ Failure( "Bucket can't get a size key in UpdateBucket" ); }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory the allocation bucket.                                 */
    /*                                                                  */
    /********************************************************************/

BUCKET::~BUCKET( VOID )
	{ /* void */ }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\connections.hpp ===
#ifndef _CONNECTIONS_HPP_
#define _CONNECTIONS_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Environment.hpp"
#include "Common.hpp"
#include "Find.hpp"
#include "NewPage.hpp"
#include "Prefetch.hpp"
  
    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   At the top level the parent of all caches is a constant        */
    /*   called 'GlobalRoot'.                                           */
    /*                                                                  */
    /********************************************************************/

CONST SNATIVE GlobalRoot			  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;
class HEAP;
class PAGE;

    /********************************************************************/
    /*                                                                  */
    /*   Data structures exported from the class.                       */
    /*                                                                  */
    /*   We communicate between a page and the associated cache         */
    /*   using an address pointer, page pointer and version triple.     */
    /*                                                                  */
    /********************************************************************/

typedef struct
	{
	VOID							  *Address;
	PAGE							  *Page;
	SBIT32							  Version;
	}
ADDRESS_AND_PAGE;

    /********************************************************************/
    /*                                                                  */
    /*   Connections to other classes.                                  */
    /*                                                                  */
    /*   The connections between the various classes in the memory      */
    /*   allocator is a twisted mess.  The root cause is that at a      */
    /*   fundamental level.  Every part depends on every other part.    */
    /*   Nonetheless, a significant effort has been made to seperate    */
    /*   the parts as best as possible.  The various classes are        */
    /*   linked here so every part can find the correct instance of     */
    /*   every other part.                                              */
    /*                                                                  */
    /********************************************************************/

class CONNECTIONS : public ENVIRONMENT, public COMMON
    {
		//
		//   Private data.
		//
		BOOLEAN						  Active;

   public:
		//
		//   Public data.
		//
		//   All the classes that inherit this class get
		//   pointers to related classes they need to call
		//   from time to time. 
		//
		HEAP                          *Heap;
		NEW_PAGE					  *NewPage;
		CACHE						  *ParentCache;
		FIND                          *PrivateFind;
		FIND                          *PublicFind;

		//
		//   The 'Prefetch' is a class that will trigger
		//   a cache fetch if the CPU supports it.
		//   
		PREFETCH					  Prefetch;

        //
        //   Public functions.
		//
		//   The sole job of this class is to provide 
		//   pointers to related classes.  These pointers
		//   are unknown until after the heap has been
		//   created and this need to be dynamically
		//   linked during the execution of the top 
		//   level heap constructor.
        //
        CONNECTIONS( VOID );

		VOID DeleteFromFindList( PAGE *Page );

		VOID InsertInFindList( PAGE *Page );

		VOID UpdateConnections
			( 
			HEAP					  *NewHeap,
			NEW_PAGE				  *NewPages,
			CACHE					  *NewParentCache,
			FIND					  *NewPrivateFind,
			FIND					  *NewPublicFind
			);

        ~CONNECTIONS( VOID );

		//
		//   Public inline functions.
		//
		//   The complex linkages in the heap sometimes 
		//   lead to the case where a class has a pointer
		//   to it's cache but not to the class it needs
		//   to call.  Thus, to avoid replicating large
		//   numbers of pointers we export call interfaces
		//   from here to allow the required calls to be
		//   made indirectly.
		//
		INLINE VOID DeletePage( PAGE *Page )
			{ NewPage -> DeletePage( Page ); }

		INLINE HEAP *GetHeap( VOID )
			{ return Heap; }

		INLINE CACHE *GetParentCache( VOID )
			{ return ParentCache; }

		INLINE BOOLEAN TopCache( VOID )
			{ return (ParentCache == ((CACHE*) GlobalRoot)); }

	private:
        //
        //   Disabled operations.
        //
        CONNECTIONS( CONST CONNECTIONS & Copy );

        VOID operator=( CONST CONNECTIONS & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\heappch.hpp ===
#ifndef _HEAP_PCH_HPP_
#define _HEAP_PCH_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#ifndef DISABLE_PRECOMPILED_HEADERS
#include "Bucket.hpp"
#include "BucketList.hpp"
#include "Cache.hpp"
#include "Connections.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "NewPage.hpp"
#include "NewPageList.hpp"
#include "Page.hpp"
#include "PrivateFindList.hpp"
#include "PublicFindList.hpp"
#include "RockallFrontEnd.hpp"
#include "ThreadSafe.hpp"

#include "LibraryPCH.hpp"
#endif
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\newpagelist.hpp ===
#ifndef _NEW_PAGE_LIST_HPP_
#define _NEW_PAGE_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "BucketList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The new page list.                                             */
    /*                                                                  */
    /*   The new page list links all the memory allocated by the low    */
    /*   level external allocator, or sub-divided pages or free pages   */
    /*   so they can be quickly found.                                  */
    /*                                                                  */
    /********************************************************************/

class NEW_PAGE_LIST : public BUCKET_LIST
    {
		//
		//   Private data.
		//
 		LIST						  NewPageList;

   public:
		//
		//   Public inline functions.
		//
		//   All page descriptions contain four linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
		//
        NEW_PAGE_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromNewPageList( LIST *HeadOfList )
			{ NewPageList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfNewPageList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInNewPageList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> First()) ); }

		INLINE VOID InsertInNewPageList( LIST *HeadOfList )
			{ NewPageList.Insert( HeadOfList ); }

		STATIC INLINE PAGE *LastInNewPageList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> Last()) ); }

		INLINE PAGE *NextInNewPageList( VOID )
			{ return ComputePageAddress( ((CHAR*) NewPageList.Next()) ); }

        ~NEW_PAGE_LIST( VOID )
			{ /* void */ };

	private:
		//
		//   Private functions.
		//
		//   Compute the actual start address of the page
		//   and return it to allow the linked list to
		//   be correctly walked.
		//
		STATIC INLINE PAGE *ComputePageAddress( CHAR *Address )
			{
			if ( Address != NULL )
				{ return ((PAGE*) (Address - sizeof(BUCKET_LIST))); }
			else
				{ return ((PAGE*) NULL); }
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        NEW_PAGE_LIST( CONST NEW_PAGE_LIST & Copy );

        VOID operator=( CONST NEW_PAGE_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\heap.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "Find.hpp"
#include "Globallock.hpp"
#include "Heap.hpp"
#include "RockallBackEnd.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control minimum size of an         */
    /*   allocation bucket.                                             */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MinParentSize			  = 32;
CONST SBIT32 MaxSummaryColumns		  = 2;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a heap and prepare it for use.  Additionally, make      */
    /*   sure that the heap configuration makes sense.  This is         */
    /*   tricky as the whole structure of the heap can be changed       */
    /*   by the external configuration information.                     */
    /*                                                                  */
    /********************************************************************/

HEAP::HEAP
		(
		CACHE						  *Caches1[],
		CACHE						  *Caches2[],
		SBIT32						  MaxFreeSpace,
		NEW_PAGE					  *NewPages,
		FIND						  *NewPrivateFind,
		FIND						  *NewPublicFind,
		ROCKALL_BACK_END			  *NewRockallBackEnd,
		SBIT32						  Size1,
		SBIT32						  Size2,
		SBIT32						  Stride1,
		SBIT32						  Stride2,
		THREAD_SAFE					  *NewThreadSafe
		)
    {
	//
	//   The top three buckets are special and a user can not 
	//   allocate memory from two of them.  Thus, unless we have  
	//   at least four buckets the memory allocator is not going 
	//   to be very useful. 
	//
	if ( (Size1 >= 1) && (Size2 >= 3) )
		{
		REGISTER CACHE *FirstCache = Caches1[0];
		REGISTER CACHE *MiddleCache = Caches2[0];
		REGISTER CACHE *LastCache = Caches2[ (Size2-3) ];

		//
		//   Calculate the minimum and maximum allocation sizes.
		//   All allocations outside of this range will be passed
		//   directly to the external allocator.
		//
		CachesSize = (Size1 + Size2);
		MinCacheSize = FirstCache -> GetAllocationSize();
		MidCacheSize = MiddleCache -> GetAllocationSize();
		MaxCacheSize = LastCache -> GetAllocationSize();

		//
		//   Calculate and save various useful pointers needed
		//   during the course of execution.
		//
		Caches = Caches1;
		ExternalCache = (Caches2[ (Size2-1) ]);
		NewPage = NewPages;
		PrivateFind = NewPrivateFind;
		PublicFind = NewPublicFind;
		RockallBackEnd = NewRockallBackEnd;
		TopCache = (Caches2[ (Size2-2) ]);
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Zero the heap statistics.
		//
		CopyMisses = 0;
		MaxCopySize = 0;
		MaxNewSize = 0;
		NewMisses = 0;
		Reallocations = 0;
		TotalCopySize = 0;
		TotalNewSize = 0;
#endif

		//
		//   The external allocation size must be reasonable.
		//   All allocation sizes must be a multiple of the
		//   minimum allocation size.  The minimum allocation
		//   size and the middle allocation size must be a 
		//   power of two.
		//   
		if 
				( 
				(ExternalCache -> GetPageSize() == TopCache -> GetPageSize())
					&& 
				(PowerOfTwo( RockallBackEnd -> NaturalSize() ))
					&&
				(RockallBackEnd -> NaturalSize() >= PageSize())
					&&
				(TopCache -> GetPageSize() >= PageSize())
					&&
				(PowerOfTwo( TopCache -> GetPageSize() ))
					&&
				((Stride1 > 0) && (PowerOfTwo( Stride1 )))
					&&
				((Stride2 >= Stride1) && (PowerOfTwo( Stride2 )))
					&&
				(ConvertDivideToShift( Stride1,& ShiftSize1 ))
					&&
				(ConvertDivideToShift( Stride2,& ShiftSize2 ))
				)
			{
			REGISTER SBIT32 Count1;
			REGISTER SBIT32 TopCacheSize = (TopCache -> GetPageSize());
			REGISTER SBIT32 MaxSize1 = (MidCacheSize / Stride1);
			REGISTER SBIT32 MaxSize2 = (TopCacheSize / Stride2);

			//
			//   Calculate the maximum number of free pages 
			//   that can be kept.  Also set the smallest parent
			//   mask to the maximum value.
			//
			MaxFreePages = (MaxFreeSpace / (TopCache -> GetAllocationSize()));
			SmallestParentMask = ((TopCache -> GetAllocationSize())-1);
			ThreadSafe = NewThreadSafe;

			//
			//   Calculate the sizes of the arrays that map 
			//   sizes to caches.
			//
			MaxTable1 = (MaxSize1 * sizeof(CACHE*));
			MaxTable2 = (MaxSize2 * sizeof(CACHE*));

			//
			//   The heap pages must be specified in asceding
			//   order of size and be an exact multiple of the
			//   minimum allocation size.
			//
			for ( Count1=0;Count1 < Size1;Count1 ++ )
				{
				REGISTER CACHE *Current = Caches1[ Count1 ];
				REGISTER CACHE *Next = Caches1[ (Count1+1) ];
				REGISTER SBIT32 AllocationSize = Current -> GetAllocationSize();
				REGISTER SBIT32 ChunkSize = Current -> GetChunkSize();
				REGISTER SBIT32 PageSize = Current -> GetPageSize();

				//
				//   Ensure each cache specification meets the
				//   requirements of the heap.  If not fail
				//   the heap entire heap creation.
				//
				if ( (AllocationSize % Stride1) != 0 )
					{ Failure( "Cache size not multiple of stride" ); }

				if ( AllocationSize >= Next -> GetAllocationSize() )
					{ Failure( "Cache sizes not in ascending order" ); }

				if ( (AllocationSize > ChunkSize) || (ChunkSize > PageSize) )
					{ Failure( "Chunk size not suitable for cache" ); }

				if ( AllocationSize >= PageSize )
					{ Failure( "Cache size larger than parent size" ); }

				if ( PageSize > TopCacheSize )
					{ Failure( "Parent size exceeds 'TopCache' size" ); }
				}

			//
			//   The heap pages must be specified in asceding
			//   order of size and be an exact multiple of the
			//   minimum allocation size.
			//
			for ( Count1=0;Count1 < (Size2-2);Count1 ++ )
				{
				REGISTER CACHE *Current = Caches2[ Count1 ];
				REGISTER CACHE *Next = Caches2[ (Count1+1) ];
				REGISTER SBIT32 AllocationSize = Current -> GetAllocationSize();
				REGISTER SBIT32 ChunkSize = Current -> GetChunkSize();
				REGISTER SBIT32 PageSize = Current -> GetPageSize();

				//
				//   Ensure each cache specification meets the
				//   requirements of the heap.  If not fail
				//   the heap entire heap creation.
				//
				if ( (AllocationSize % Stride2) != 0 )
					{ Failure( "Cache size not multiple of stride" ); }

				if ( AllocationSize >= Next -> GetAllocationSize() )
					{ Failure( "Cache sizes not in ascending order" ); }

				if ( (AllocationSize > ChunkSize) || (ChunkSize > PageSize) )
					{ Failure( "Chunk size not suitable for cache" ); }

				if ( AllocationSize >= PageSize )
					{ Failure( "Cache size larger than parent size" ); }

				if ( PageSize > TopCacheSize )
					{ Failure( "Parent size exceeds 'TopCache' size" ); }
				}

			//
			//   The external and top caches have special rules
			//   which must be checked to ensure these caches
			//   are valid.
			//
			for ( Count1=(Size2-2);Count1 < Size2;Count1 ++ )
				{
				REGISTER CACHE *Current = Caches2[ Count1 ];
				REGISTER SBIT32 AllocationSize = Current -> GetAllocationSize();

				//
				//   Ensure each cache specification meets the
				//   requirements of the heap.  If not fail
				//   the heap entire heap creation.
				//
				if ( (AllocationSize % Stride2) != 0 )
					{ Failure( "Top cache size not multiple of minimum" ); }

				if ( AllocationSize != Current -> GetChunkSize() )
					{ Failure( "Chunk size not suitable for top cache" ); }

				if ( AllocationSize != Current -> GetPageSize() )
					{ Failure( "Page size not suitable for top cache" ); }

				if ( Current -> GetCacheSize() != 0 )
					{ Failure( "Cache size not zero for top cache" ); }
				}

			//
			//   We need to allocate two arrays to enable requested
			//   sizes to be quickly mapped to allocation caches.
			//   Here we allocate the tables and later fill in all
			//   the necessary mapping information.
			//
			SizeToCache1 = (CACHE**) 
				(
				RockallBackEnd -> NewArea
					(
					(RockallBackEnd -> NaturalSize() - 1),
					(MaxTable1 + MaxTable2),
					False
					)
				);
#ifdef ENABLE_HEAP_STATISTICS

			//
			//   When we are compiled for statistics we keep
			//   information on all the allocations we see.
			//
			Statistics = (SBIT32*)
				(
				RockallBackEnd -> NewArea
					(
					(RockallBackEnd -> NaturalSize() - 1),
					(MaxCacheSize * sizeof(SBIT32)),
					False
					)
				);
#endif

			//
			//   We make sure that the allocations we made 
			//   did not fail.  If not we have to fail the 
			//   creation of the whole heap.
			//
			if 
					( 
					(SizeToCache1 != ((CACHE**) AllocationFailure))
#ifdef ENABLE_HEAP_STATISTICS
						&&
					(Statistics != ((SBIT32*) AllocationFailure))
#endif
					) 
				{
				REGISTER SBIT32 Count2;

				//
				//   Cycle through the first segment of the 
				//   mapping table creating approriate 
				//   translations.
				//
				for ( Count1=0,Count2=0;Count1 < MaxSize1;Count1 ++ )
					{
					//
					//   We make sure that the current allocation
					//   page is large enough to hold an element
					//   of some given size.  If not we move on to
					//   the next allocation page.
					//
					if 
							( 
							((Count1 + 1) * Stride1)
								> 
							(Caches1[ Count2 ] -> GetAllocationSize()) 
							)
						{ Count2 ++; }

					//
					//   Store a pointer so that a request for
					//   this size of allocation goes directly
					//   to the correct page.
					//
					SizeToCache1[ Count1 ] = Caches1[ Count2 ];
					}

				//
				//   Compute the start address for the second
				//   segment of the table.
				//
				SizeToCache2 = 
					((CACHE**) & ((CHAR*) SizeToCache1)[ MaxTable1 ]);

				//
				//   Cycle through the second segment of the 
				//   mapping table creating approriate 
				//   translations.
				//
				for ( Count1=0,Count2=0;Count1 < MaxSize2;Count1 ++ )
					{
					//
					//   We make sure that the current allocation
					//   page is large enough to hold an element
					//   of some given size.  If not we move on to
					//   the next allocation page.
					//
					if 
							( 
							((Count1 + 1) * Stride2)
								> 
							(Caches2[ Count2 ] -> GetAllocationSize()) 
							)
						{ Count2 ++; }

					//
					//   Store a pointer so that a request for
					//   this size of allocation goes directly
					//   to the correct page.
					//
					SizeToCache2[ Count1 ] = Caches2[ Count2 ];
					}

				//
				//   Now that we have created the size to cache 
				//   mappings lets use them to link each cache to  
				//   the cache it uses to allocate additional 
				//   memory.
				//
				for ( Count1=0;Count1 < (CachesSize-1);Count1 ++ )
					{
					REGISTER CACHE *CurrentCache = Caches[ Count1 ];
					REGISTER SBIT32 PageSize = CurrentCache -> GetPageSize();
					REGISTER CACHE *ParentCache = FindCache( PageSize );
					REGISTER BOOLEAN Top = (CurrentCache == ParentCache);

					//
					//   Ensure that the parent cache is suitable
					//   and in line with what we were expecting. 
					//
					if 
							(
							(PowerOfTwo( PageSize ))
								&&
							(PageSize >= MinParentSize)
								&&
							(PageSize == (ParentCache -> GetAllocationSize()))
							)
						{
						//
						//   We keep track of the smallest
						//   cache that is a parent.  We can
						//   use this to improve the performance
						//   of the find hash table.
						//
						if ( ((BIT32) PageSize) < SmallestParentMask )
							{ SmallestParentMask = (PageSize-1); }

						//
						//   Update the current cache with  
						//   information about it's parent 
						//   cache.
						//
						CurrentCache -> UpdateCache
							(
							this,
							NewPages,
							((Top) ? ((CACHE*) GlobalRoot) : ParentCache),
							PrivateFind,
							PublicFind
							); 
						} 
					else
						{ Failure( "Parent bucket is invalid" ); }
					}
#ifdef ENABLE_HEAP_STATISTICS

				//
				//   It is probably a good idea to zero the 
				//   statistics area.
				//
				ZeroMemory( Statistics,(MaxCacheSize * sizeof(SBIT32)) );
#endif

				//
				//   The external cache is an exact duplicate
				//   of the top cache and is used to hold all
				//   memory allocations that are too large for
				//   any bucket.  Nonetheless, its parent is
				//   still the top cache.
				//
				ExternalCache -> UpdateCache
					(
					this,
					NewPages,
					TopCache,
					PrivateFind,
					PublicFind
					);

				//
				//   Update the new page structure with the 
				//   details of the top cache.
				//
				NewPage -> UpdateNewPage( TopCache );

				//
				//   Update the hash table with the minimum
				//   parent size for this heap.
				//
				PrivateFind -> UpdateFind
					(
					(TopCache -> GetAllocationSize()-1),
					SmallestParentMask 
					);

				//
				//   If there is a public find table then
				//   update the hash table with the minimum
				//   parent size for this heap.
				//
				if ( PublicFind != NULL )
					{
					PublicFind -> UpdateFind
						(
						(TopCache -> GetAllocationSize()-1),
						SmallestParentMask 
						);
					}

				//
				//   Activate the heap.
				//
				Active = True;
				}
			else
				{ Failure( "Mapping table in constructor for HEAP" ); }
			}
		else
			{ Failure( "The allocation sizes in constructor for HEAP" ); }
		}
	else
		{ Failure( "A heap size in constructor for HEAP" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Memory deallocation.                                           */
    /*                                                                  */
    /*   We need to release some memory.  First we try to slave the     */
    /*   request in the free cache so we can do a batch of releases     */
    /*   later.  If not we are forced to do it at once.                 */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Delete( VOID *Address,SBIT32 Size )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   When the caller gives us the size of the 
		//   allocation we can short cut the deallocation 
		//   process by skipping directly to the correct 
		//   cache.  However, if the user supplies us
		//   with bogus data we will retry using the
		//   the full deallocation process.
		//
		if ( (Size > 0) && (Size <= MaxCacheSize) )
			{
			REGISTER CACHE *Cache = (FindCache( Size ));

			if ( PrivateFind -> Delete( Address,Cache ) )
				{ return True; }
			}

		//
		//   It looks like all we have is the address so 
		//   deallocate using the long path.
		//
		if ( PrivateFind -> Delete( Address,TopCache ) )
			{ return True; }
		else
			{
			//
			//   The 'Address' does not belong to this
			//   heap so lets try the public find table.
			//
			if ( PublicFind != NULL )
				{
				//
				//   When the caller gives us the size of the 
				//   allocation we can short cut the deallocation 
				//   process by skipping directly to the correct 
				//   cache.  However, if the user supplies us
				//   with bogus data we will retry using the
				//   the full deallocation process.
				//
				if ( (Size > 0) && (Size <= MaxCacheSize) )
					{
					REGISTER CACHE *Cache = (FindCache( Size ));

					if ( PublicFind -> Delete( Address,Cache ) )
						{ return True; }
					}

				//
				//   It looks like all we have is the address  
				//   so deallocate using the long path.
				//
				return (PublicFind -> Delete( Address,TopCache ));
				}
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete all allocations.                                        */
    /*                                                                  */
    /*   We delete the entire heap and free all existing allocations.   */
    /*   If 'Recycle' is requested we slave the allocated memory as     */
    /*   we expect some new allocations.  If not we return all the      */
    /*   memory to the external allocator.                              */
    /*                                                                  */
    /********************************************************************/

VOID HEAP::DeleteAll( BOOLEAN Recycle )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		REGISTER SBIT32 Count;

		//
		//   We claim all of the heap locks to freeze
		//   all new allocations or deletions.
		//
		LockAll();

		//
		//   Now reset all the caches and the find
		//   hash table statistics.
		//
		PrivateFind -> DeleteAll();

		for ( Count=0;Count < CachesSize;Count ++ )
			{ Caches[ Count ] -> DeleteAll(); }

		//
		//   Delete the heap.
		//
		NewPage -> DeleteAll( Recycle );

		//
		//   Now release all the heap locks we claimed
		//   earlier and unfreeze the heap.
		//
		UnlockAll();

		//
		//   Trim the free space if needed.
		//
		if ( Recycle )
			{ TopCache -> ReleaseSpace( MaxFreePages ); }
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Details of a memory allocation.                                */
    /*                                                                  */
    /*   We need to the details of a particular memory allocation.      */
    /*   All we have is an address.  We use this to find the largest    */
    /*   allocation page this address is contained in and then          */
    /*   navigate through the sub-divisions of this page until we       */
    /*   find the allocation.                                           */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Details
		(
		VOID						  *Address,
		SEARCH_PAGE					  *Details,
		SBIT32						  *Size
		)
    {
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		AUTO SBIT32 Dummy;

		//
		//   We allow the caller to omit the 'Size' parameter.
		//   I can see little reason for this but it is supported
		//   anyway.
		//
		if ( Size == NULL )
			{ Size = & Dummy; }

		//
		//   We may need to try more than one find table
		//   but we always try the the private one
		//   first to minimize shared memory accesses.
		//
		if ( PrivateFind -> Details( Address,Details,TopCache,Size ) )
			{ return True; }
		else
			{
			//
			//   We need to try the public find table
			//   as the private find table could not 
			//   locate the address.
			//
			return
				(
				(PublicFind != NULL)
					&&
				(PublicFind -> Details( Address,Details,TopCache,Size ))
				);
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find a cache.                                                  */
    /*                                                                  */
    /*   Find the allocation cache for the size supplied and return     */
    /*   a pointer to it.                                               */
    /*                                                                  */
    /********************************************************************/

CACHE *HEAP::FindCache( SBIT32 Size )
	{
#ifdef DISABLED_AT_PRESENT
	REGISTER CACHE *Cache;

#endif
	//
	//   Compute the cache address.
	//
	if ( Size < MidCacheSize )
		{ return (SizeToCache1[ ((Size-1) >> ShiftSize1) ]); }
	else
		{ return (SizeToCache2[ ((Size-1) >> ShiftSize2) ]); }
#ifdef DISABLED_AT_PRESENT

	//
	//   Prefetch the class data if we are running a
	//   Pentium III or better with locks.  We do this
	//   because prefetching hot SMP data structures
	//   really helps.  However, if the structures are
	//   not shared (i.e. no locks) then it is worthless
	//   overhead.
	//
	if ( ThreadSafe )
		{ Prefetch.Nta( ((CHAR*) Cache),sizeof(CACHE) ); }

	return Cache;
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   A known area.                                                  */
    /*                                                                  */
    /*   A known area is an address that is understood to be            */
    /*   accessable from the current heap.  If the 'SingleImage'        */
    /*   flag is set it may actually be part of another heap that       */
    /*   the current heap can access.                                   */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::KnownArea( VOID *Address )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We may need to try more than one find table
		//   but we always try the the private one
		//   first to minimize shared memory accesses.
		//
		if ( PrivateFind -> KnownArea( Address,TopCache ) )
			{ return True; }
		else
			{
			//
			//   We need to try the public find table
			//   as the private find table could not 
			//   locate the area.
			//
			if ( PublicFind != NULL )
				{ return (PublicFind -> KnownArea( Address,TopCache )); }
			}
		}

	return False;
	}
    /********************************************************************/
    /*                                                                  */
    /*   Claim a lock on the entire heap.                               */
    /*                                                                  */
    /*   We claim a lock on the heap to improve performance             */
    /*   or prevent others from performing heap operations.             */
    /*                                                                  */
    /********************************************************************/

VOID HEAP::LockAll( VOID )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We claim the locks if we have not already
		//   claimed them earlier.
		//
		if ( ThreadSafe -> ClaimGlobalLock() )
			{
			REGISTER SBIT32 Count;

			//
			//   We claim all of the heap locks to freeze
			//   all new allocations or deletions.
			//
			for ( Count=0;Count < CachesSize;Count ++ )
				{ Caches[ Count ] -> ClaimCacheLock(); }

			//
			//  Although the heap is frozen at this point
			//  we claim the last few locks just to be
			//  tidy.
			//
			PrivateFind -> ClaimFindExclusiveLock();

			NewPage -> ClaimNewPageLock();

			//
			//   Engage the global lock and make it active
			//   to prevent further lock calls on this
			//   thread.
			//
			ThreadSafe -> EngageGlobalLock();
			}
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete multiple allocations.                                   */
    /*                                                                  */
    /*   We need to release multiple memory allocations.  First we try  */
    /*   to slave the requets in the free cache so we can do a batch    */
    /*   of releases later.  If not we are forced to do it immediately. */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::MultipleDelete
		( 
		SBIT32						  Actual,
		VOID						  *Array[],
		SBIT32						  Size 
		)
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		REGISTER SBIT32 Count;
		REGISTER BOOLEAN Result = True;
		REGISTER CACHE *ParentCache = ((CACHE*) GlobalRoot);

		//
		//   When the caller gives us the size of the allocation
		//   we can short cut the deallocation process by skipping
		//   directly to the correct cache.  However, if the user
		//   supplies us with bogus data we will retry using the
		//   the long path.
		//
		if ( (Size > 0) && (Size <= MaxCacheSize) )
			{
			REGISTER CACHE *Cache = (FindCache( Size ));

			//
			//   Compute a pointer to the parent cache
			//   so we can optimize the deletes.
			//
			ParentCache = (Cache -> GetParentCache());

			//
			//   Delete each memory allocation one at a time.
			//   We would like to delete them all at once but
			//   we can't be sure they are all vaild or related.
			//
			for ( Count=0;Count < Actual;Count ++ )
				{
				REGISTER VOID *Address = Array[ Count ];

				//
				//   Lets try to optimize the delete.
				//
				if ( ! PrivateFind -> Delete( Address,ParentCache ) ) 
					{
					//
					//   Lets try a standard full delete.
					//
					if ( ! PrivateFind -> Delete( Address,TopCache ) )
						{
						//
						//   The 'Address' does not belong
						//   to the current heap so lets
						//   try using the global find table
						//   to try a global delete.
						//
						if ( ! PublicFind -> Delete( Address,TopCache ) )
							{ Result = False; }
						}
					}
				}
			}
		else
			{
			//
			//   Delete each memory allocation one at a time.
			//   We would like to delete them all at once but
			//   we can't be sure they are all vaild or related.
			//
			for ( Count=0;Count < Actual;Count ++ )
				{
				REGISTER VOID *Address = Array[ Count ];

				//
				//   Lets try a standard full delete.
				//
				if ( ! PrivateFind -> Delete( Address,TopCache ) )
					{
					//
					//   The 'Address' does not belong to
					//   the current heap so lets try using
					//   the global find table to try a
					//   global delete.
					//
					if ( ! PublicFind -> Delete( Address,TopCache ) )
						{ Result = False; }
					}
				}
			}

		return Result;
		}
	else
		{ return False; }
	}

    /********************************************************************/
    /*                                                                  */
    /*   Multiple memory allocations.                                   */
    /*                                                                  */
    /*   We have been asked to allocate muliple memory blocks.   We     */
    /*   we do this by using the cache and then claiming and addition   */
    /*   space from the heap as needed.                                 */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::MultipleNew
		( 
		SBIT32						  *Actual,
		VOID						  *Array[],
		SBIT32						  Requested,
		SBIT32						  Size,
		SBIT32						  *Space,
		BOOLEAN						  Zero
		)
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		AUTO SBIT32 Dummy;

		//
		//   We allow the caller to omit the 'Actual' parameter.
		//   I can see little reason for this but it is supported
		//   anyway.  Regardless we zero it.
		//
		if ( Actual == NULL )
			{ Actual = & Dummy; }

		(*Actual) = 0;

		//
		//   We need to be sure that the size requested is in the 
		//   range supported by the memory allocator.  If not we
		//   do a series of single allocations from the default
		//   allocator.
		//
		if ( (Size > 0) && (Size <= MaxCacheSize) )
			{
			REGISTER CACHE *Cache = (FindCache( Size ));
			REGISTER SBIT32 NewSize = (Cache -> GetAllocationSize());

			//
			//   Allocate memory from the appropriate 
			//   allocation bucket.
			//
			(VOID) Cache -> MultipleNew( Actual,Array,Requested );

			//
			//   If needed return the actual amount  
			//   of space allocated for each element.
			//
			if ( Space != NULL )
				{ (*Space) = NewSize; }
#ifdef ENABLE_HEAP_STATISTICS

			//
			//   Update the allocation statistics.
			//
			Statistics[ (Size-1) ] += Requested;
#endif

			//
			//   If needed zero each element that is  
			//   allocated.
			//
			if ( Zero )
				{
				REGISTER SBIT32 Count;

				for ( Count=((*Actual)-1);Count >= 0;Count -- )
					{ ZeroMemory( Array[ Count ],NewSize ); }
				}

			return ((*Actual) == Requested);
			}
		else
			{
			//
			//   If the allocation size is greater than
			//   zero we create the allocations.  If not
			//   we fail the request.
			//
			if ( Size > 0 )
				{
				//
				//   We have got a request for an element size
				//   larger than the largest bucket size.  So 
				//   we call the single allocation interface 
				//   as this supports large sizes.
				//
				for 
					( 
					/* void */;
					((*Actual) < Requested)
						&&
					((Array[ (*Actual) ] = New( Size )) != AllocationFailure);
					(*Actual) ++ 
					);

				//
				//   If needed return the actual amount of space 
				//   allocated for each element.
				//
				if ( Space != NULL )
					{ (*Space) = Size; }

				return ((*Actual) == Requested);
				}
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Memory allocation.                                             */
    /*                                                                  */
    /*   We have been asked to allocate some memory.  Hopefully,        */
    /*   we will be able to do this out of the cache.  If not we        */
    /*   will need to pass it along to the appropriate allocation       */
    /*   bucket.                                                        */
    /*                                                                  */
    /********************************************************************/

VOID *HEAP::New( SBIT32 Size,SBIT32 *Space,BOOLEAN Zero )
	{
	REGISTER VOID *NewMemory = ((VOID*) AllocationFailure);

	//
	//   Although normally a class is never called before
	//   its constructor. The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We ensure the allocation size is in
		//   the range supported by the heap.
		//
		if ( (Size > 0) && (Size <= MaxCacheSize) )
			{
			REGISTER CACHE *Cache = (FindCache( Size ));
#ifdef ENABLE_HEAP_STATISTICS

			//
			//   Update the allocation statistics.
			//
			Statistics[ (Size-1) ] ++;
#endif

			//
			//   Allocate memory from the appropriate
			//   cache in the heap.
			//
			NewMemory = (Cache -> New()); 
			Size = (Cache -> GetAllocationSize());
			}
		else
			{ 
			//
			//   If the allocation size is greater than
			//   zero we create the allocation.  If not
			//   we fail the request.
			//
			if ( Size > 0 )
				{
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   Update the allocation statistics.
				//
				if ( Size > MaxNewSize )
					{ MaxNewSize = Size; }

				NewMisses ++;
				TotalNewSize += Size;

#endif
				//
				//   Allocate memory from a special
				//   cache bucket which gets space
				//   externally.
				//
				NewMemory = (ExternalCache -> New( False,Size ));
				}
			else
				{ NewMemory = ((VOID*) AllocationFailure); }
			}

		//
		//   We need to be sure that the allocation 
		//   request did not fail.
		//
		if ( NewMemory != ((VOID*) AllocationFailure) )
			{
			//
			//   If needed return the actual amount of space 
			//   allocated for this request.
			//
			if ( Space != NULL )
				{ (*Space) = Size; }

			//
			//   Zero the memory if the needed.
			//
			if ( Zero )
				{ ZeroMemory( NewMemory,Size ); }
			}
		}

	return NewMemory;
	}
#ifdef ENABLE_HEAP_STATISTICS

    /********************************************************************/
    /*                                                                  */
    /*   Print statistics.                                              */
    /*                                                                  */
    /*   We output the allocation statistics to the debug console.      */
    /*                                                                  */
    /********************************************************************/

VOID HEAP::PrintHeapStatistics( VOID )
	{
	REGISTER SBIT32 Count1;
	REGISTER SBIT32 Count2;
	REGISTER SBIT32 HighWater = 0;
	REGISTER SBIT32 Total = 0;
	STATIC GLOBALLOCK Globallock;

	//
	//   Claim a lock so that multiple threads have
	//   to wait to output any heap statistics.
	//
	Globallock.ClaimLock();

	//
	//
	//   Output the heap details to the debug
	//   console along with an explaination.
	//
	DebugPrint
		(
		"\n"
		"Heap at 0x%x\n"
		"\n"
		"A summary of all the requested sizes, "
		"supplied sizes and associated counts.\n"
		"A brief examination of this summary "
		"should provide a good understanding of\n"
		"an applications overall heap usage"
		"patterns.\n"
		"\n",
		this
		);

	//
	//   Output the titles for the summary table.
	//
	for ( Count1=0;Count1 < MaxSummaryColumns;Count1 ++ )
		{ DebugPrint( "   Actual  Supplied    Total            " ); }

	//
	//   Skip to a new line.
	//
	DebugPrint( "\n" );

	for ( Count1=0;Count1 < MaxSummaryColumns;Count1 ++ )
		{ DebugPrint( "    Size     Size      Calls            " ); }

	//
	//   Skip to a new line.
	//
	DebugPrint( "\n" );

	//
	//   Output the contents of the summary table.
	//
	for ( Count1=0;Count1 < MaxCacheSize;/* void */ )
		{
		//
		//   Output the each non-zero data point.
		//
		for 
				( 
				Count2=0;
				(Count1 < MaxCacheSize) && (Count2 < MaxSummaryColumns);
				Count1 ++ 
				)
			{
			REGISTER SBIT32 Hits = Statistics[ Count1 ];

			//
			//   When the nimber of hits is 
			//   non-zero we output the data.
			//
			if ( Hits > 0 )
				{
				REGISTER CACHE *Cache = FindCache( (Count1+1) );

				//
				//   Output the values.
				//
				DebugPrint
					(
					"%8d  %8d  %8d            ",
					(Count1 + 1),
					Cache -> GetAllocationSize(),
					Hits
					);

				//
				//   Update the column and totals.
				//
				Count2 ++;

				Total += Hits;
				}
			}

		//
		//   Skip to a new line.
		//
		DebugPrint( "\n" );
		}

	//
	//
	//   Output the cache details to the debug
	//   console along with an explaination.
	//
	DebugPrint
		(
		"\n"
		"A summary of the activity of all the "
		"heap caches.  A brief examination of\n"
		"this summary should provide a good "
		"understanding of how the heap dealt\n"
		"with the applications heap usage"
		"patterns.\n"
		);

	//
	//   Output the titles to the debug console.
	//
	DebugPrint
		( 
		"\n"
		"   Actual    Cache     Cache      High      High     Active\n"
		"    Size     Fills    Flushes     Tide      Water    In Use\n"
		);

	//
	//   Output details for every sample size.
	//
	for ( Count1=0;Count1 < CachesSize;Count1 ++ )
		{
		REGISTER CACHE *Cache = Caches[ Count1 ];

		//
		//   Skip this cache if it was not active
		//   as the statistics will be all zeros.
		//
		if ( Cache -> GetHighWater() > 0 )
			{
			//
			//   Output the cache details.
			//
			DebugPrint
				(
				"%8d  %8d  %8d  %8d  %8d  %8d\n",
				Cache -> GetAllocationSize(),
				Cache -> GetCacheFills(),
				Cache -> GetCacheFlushes(),
				Cache -> GetHighTide(),
				Cache -> GetHighWater(),
				Cache -> GetInUse()
				);
			
			//
			//   Compute the space high water mark.
			//
			HighWater += 
				(Cache -> GetHighWater() * Cache -> GetAllocationSize());
			}
		}

	//
	//   Print the private hash table statistics.
	//
	DebugPrint
		(
		"\n"
		"Private Hash Table Statistics\n"
		"-----------------------------\n"
		"\t*** Cache ***\n"
		"\tFills\t\t: %d\n"
		"\tHits\t\t: %d\n"
		"\tMisses\t\t: %d\n"
		"\t*** Table ***\n"
		"\tAverage\t\t: %d\n"
		"\tMax\t\t: %d\n"
		"\tScans\t\t: %d\n"
		"\tMax Hash\t: %d\n"
		"\tMax LookAside\t: %d\n"
		"\tUsage\t\t: %d%%\n",
		PrivateFind -> CacheFills(),
		PrivateFind -> CacheHits(),
		PrivateFind -> CacheMisses(),
		PrivateFind -> AverageHashLength(),
		PrivateFind -> MaxHashLength(),
		PrivateFind -> TotalScans(),
		PrivateFind -> MaxHashSize(),
		PrivateFind -> MaxLookAsideSize(),
		PrivateFind -> MaxUsage()
		);

	
	//
	//   Print the public hash table statistics
	//   (if applicable).
	//
	if ( PublicFind != NULL )
		{
		DebugPrint
			(
			"\n"
			"Public Hash Table Statistics\n"
			"----------------------------\n"
			"\t*** Cache ***\n"
			"\tFills\t\t: %d\n"
			"\tHits\t\t: %d\n"
			"\tMisses\t\t: %d\n"
			"\t*** Table ***\n"
			"\tAverage\t\t: %d\n"
			"\tMax\t\t: %d\n"
			"\tScans\t\t: %d\n"
			"\tMax Hash\t: %d\n"
			"\tMax LookAside\t: %d\n"
			"\tUsage\t\t: %d%%\n",
			PublicFind -> CacheFills(),
			PublicFind -> CacheHits(),
			PublicFind -> CacheMisses(),
			PublicFind -> AverageHashLength(),
			PublicFind -> MaxHashLength(),
			PublicFind -> TotalScans(),
			PublicFind -> MaxHashSize(),
			PublicFind -> MaxLookAsideSize(),
			PublicFind -> MaxUsage()
			);
		}

	//
	//   Print the reallocation statistics.
	//

	DebugPrint
		(
		"\n"
		"Oversize Statistics\n"
		"-------------------\n"
		"\tAverage Size\t: %d\n"
		"\tMax Size\t: %d\n"
		"\tMisses\t\t: %d\n",
		(TotalNewSize / ((NewMisses > 0) ? NewMisses : 1)),
		MaxNewSize,
		NewMisses
		);

	//
	//   Print the reallocation statistics.
	//
	DebugPrint
		(
		"\n"
		"Realloc Statistics\n"
		"------------------\n"
		"\tAverage Copy\t: %d\n"
		"\tCalls\t\t: %d\n"
		"\tMax Copy\t: %d\n"
		"\tTotal Copies\t: %d\n",
		(TotalCopySize / ((CopyMisses > 0) ? CopyMisses : 1)),
		Reallocations,
		MaxCopySize,
		CopyMisses
		);

	//
	//   Print the general statistics.
	//

	DebugPrint
		(
		"\n"
		"Summary Statistics\n"
		"------------------\n"
		"\tMax Heap\t: %d\n"
		"\tTotal Calls\t: %d\n",
		HighWater,
		Total
		);

	//
	//   Relesae the lock.
	//
	Globallock.ReleaseLock();
	}
#endif

    /********************************************************************/
    /*                                                                  */
    /*   Memory reallocation.                                           */
    /*                                                                  */
    /*   We have been asked to reallocate some memory.  Hopefully,      */
    /*   we will be able to do this out of the cache.  If not we        */
    /*   will need to pass it along to the appropriate allocation       */
    /*   bucket, do a copy and free the orginal allocation.             */
    /*                                                                  */
    /********************************************************************/

VOID *HEAP::Resize
		( 
		VOID						  *Address,
		SBIT32						  NewSize,
		SBIT32						  Move,
		SBIT32						  *Space,
		BOOLEAN						  NoDelete,
		BOOLEAN						  Zero
		)
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		AUTO SBIT32 Size;
		AUTO SBIT32 NewSpace;

		//
		//   Find the details of the existing allocation.
		//   If there is no existing allocation then exit.
		//
		if ( Details( Address,NULL,& Size ) )
			{
			REGISTER VOID *NewMemory;
			REGISTER SBIT32 Smallest = ((Size < NewSize) ? Size : NewSize);

			//
			//   Make sure the sizes appear to make sense.
			//
			if ( Smallest > 0 )
				{
#ifdef ENABLE_HEAP_STATISTICS
				//
				//   Update the statistics.
				//
				Reallocations ++;

#endif
				//
				//   When the new allocation allocation is 
				//   standard heap allocation size we check 
				//   for various optimizations.
				//
				if ( NewSize <= MaxCacheSize )
					{
					REGISTER CACHE *Cache = (FindCache( NewSize ));
					REGISTER SBIT32 CacheSize = (Cache -> GetAllocationSize());
					REGISTER SBIT32 Delta = (CacheSize - Size);
					
					//
					//   We only need to reallocate if the new
					//   size is larger than the current bucket
					//   or the new size is smaller and we have 
					//   been given permission to move the 
					//   allocation.
					//
					if ( ResizeTest( Delta,Move ) )
						{
						//
						//   We need to allocate some more
						//   memory and copy the old data.
						//   into the new area.
						//
						NewMemory = (Cache -> New());
						NewSpace = CacheSize;
#ifdef ENABLE_HEAP_STATISTICS

						//
						//   Update the statistics.
						//
						Statistics[ (NewSize-1) ] ++;
#endif
						}
					else
						{
						//
						//   If the new size is unchanged or smaller
						//   then just return the current allocation.
						//   If the new size is larger then we must
						//   fail the call.
						//
						if ( Delta <= 0 )
							{
							//
							//   The amount of memory allocated for  
							//   this request is unchanged so return  
							//   the current size.
							//
							if ( Space != NULL )
								{ (*Space) = Size; }

							return Address; 
							}
						else
							{ return ((VOID*) AllocationFailure); }
						}
					}
				else
					{
					REGISTER SBIT32 Delta = (NewSize - Size);

					//
					//   We only need to reallocate if the new
					//   size is larger than the current bucket
					//   or the new size is smaller and we have 
					//   been given permission to move the 
					//   allocation.
					//
					if ( ResizeTest( Delta,Move ) )
						{
						//
						//   One of the sizes is not within the
						//   allocation range of the heap.  So
						//   I have to punt and reallocate.
						//   
						NewMemory = 
							(
							ExternalCache -> New
								( 
								False,
								(NewSpace = NewSize)
								)
							);
#ifdef ENABLE_HEAP_STATISTICS

						//
						//   Update the allocation statistics.
						//
						if ( NewSize > MaxNewSize )
							{ MaxNewSize = NewSize; }

						NewMisses ++;
						TotalNewSize += NewSize;
#endif
						}
					else
						{
						//
						//   If the new size is unchanged or smaller
						//   then just return the current allocation.
						//   If the new size is larger then we must
						//   fail the call.
						//
						if ( Delta <= 0 )
							{
							//
							//   The amount of memory allocated for  
							//   this request is unchanged so return  
							//   the current size.
							//
							if ( Space != NULL )
								{ (*Space) = Size; }

							return Address; 
							}
						else
							{ return ((VOID*) AllocationFailure); }
						}
					}
				
				//
				//   We need to make sure we were able to allocate
				//   the new memory otherwise the copy will fail.
				//
				if ( NewMemory != ((VOID*) AllocationFailure) )
					{
					//
					//   Copy the contents of the old allocation 
					//   to the new allocation.
					//
					memcpy
						( 
						((void*) NewMemory),
						((void*) Address),
						((int) Smallest) 
						);

					//
					//   If needed return the actual amount of  
					//   space allocated for this request.
					//
					if ( Space != NULL )
						{ (*Space) = NewSpace; }

					//
					//   Delete the old allocation unless we
					//   need to keep it around.
					//
					if ( ! NoDelete )
						{
						//
						//   Delete the old allocation.
						//
						if ( ! Delete( Address,Size ) )
							{ Failure( "Deleting allocation in Resize" ); }
						}

					//
					//   Zero the memory if the needed.
					//
					if ( Zero )
						{
						REGISTER SBIT32 Difference = (NewSpace - Smallest);

						//
						//   If the new size is larger than 
						//   old size then zero the end of the
						//   new allocation.
						//
						if ( Difference > 0 )
							{ 
							REGISTER CHAR *Array = ((CHAR*) NewMemory);

							ZeroMemory( & Array[ Smallest ],Difference ); 
							} 
						}	
#ifdef ENABLE_HEAP_STATISTICS

					//
					//   Update the allocation statistics.
					//
					if ( Smallest > MaxCopySize )
						{ MaxCopySize = Smallest; }

					CopyMisses ++;
					TotalCopySize += Smallest;
#endif
					}

				return NewMemory;
				}
			}
		}

	return ((VOID*) AllocationFailure);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Truncate the heap.                                             */
    /*                                                                  */
    /*   We need to truncate the heap.  This pretty much a do nothing   */
    /*   as we do this automatically anyway.  The only thing we can     */
    /*   do is free any space the user suggested keeping earlier.       */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Truncate( SBIT32 MaxFreeSpace )
	{
	REGISTER BOOLEAN Result = True;

	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		REGISTER SBIT32 Count;

		//
		//   Flush all the caches and to free up
		//   as much space as possible.
		//
		for ( Count=0;Count < CachesSize;Count ++ )
			{
			if ( ! Caches[ Count ] -> Truncate() )
				{ Result = False; }
			}

		//
		//   We slave all available free space in the top
		//   bucket so force it to be released.
		//
		TopCache -> ReleaseSpace
			(
			(MaxFreeSpace / (TopCache -> GetAllocationSize()))
			);
		}

	return Result;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release all the heap locks.                                    */
    /*                                                                  */
    /*   We release the locks so others can use the heap.               */
    /*                                                                  */
    /********************************************************************/

VOID HEAP::UnlockAll( BOOLEAN Partial )
	{
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We release the locks only if we have claimed 
		//   them earlier.
		//
		if ( ThreadSafe -> ReleaseGlobalLock( True ) )
			{
			//
			//   Now release all the heap locks we claimed
			//   earlier and unfreeze the heap.
			//
			NewPage -> ReleaseNewPageLock();

			PrivateFind -> ReleaseFindExclusiveLock();

			//
			//   When we destroy the heap we hold on
			//   to the cache locks to prevent errors.
			//
			if ( ! Partial )
				{
				REGISTER SBIT32 Count;

				//
				//   Now release all the cache locks we claimed
				//   earlier and unfreeze the cache.
				//
				for ( Count=0;Count < CachesSize;Count ++ )
					{ Caches[ Count ] -> ReleaseCacheLock(); }
				}
			}
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Verify of a memory allocation.                                 */
    /*                                                                  */
    /*   We need to verify the details of a memory allocation.          */
    /*   All we have is an address.  We use this to find the largest    */
    /*   allocation page this address is contained in and then          */
    /*   navigate through the sub-divisions of this page until we       */
    /*   find the allocation.  Finally, we check that the element       */
    /*   is not in the cache waiting to be allocated or freed.          */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Verify( VOID *Address,SBIT32 *Size )
    {
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		AUTO SEARCH_PAGE FullDetails;
		AUTO SBIT32 NewSize;

		//
		//   We extract the size of the allocation and  
		//   any associated allocation information.
		//   to see if it is present.
		//
		if ( Details( Address,& FullDetails,& NewSize ) )
			{
			//
			//   We need to be careful to make sure this 
			//   element is actually allocated.
			//
			if ( (*FullDetails.VectorWord) & FullDetails.AllocationMask )
				{
				//
				//   It is possible for a user to give an
				//   address that is in the middle of an
				//   allocation instead of at the beginning.
				//
				if ( FullDetails.Found )
					{
					//
					//   We know that the element appears to be 
					//   allocated but it may be in the cache
					//   somewhere so ensure this is not the case.
					//
					if ( (NewSize > 0) && (NewSize <= MaxCacheSize) )
						{
						if ( FullDetails.Cache -> SearchCache( Address ) )
							{ return False; }
						}

					//
					//   We have shown that the element is active
					//   so return the size if requested.
					//
					if ( Size != NULL )
						{ (*Size) = NewSize; }

					return True;
					}
				}
			}
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Walk the heap.                                                 */
    /*                                                                  */
    /*   We have been asked to walk the heap.  It is hard to know       */
    /*   whay anybody might want to do this given the rest of the       */
    /*   functionality available.  Nonetheless, we just do what is      */
    /*   required to keep everyone happy.                               */
    /*                                                                  */
    /********************************************************************/

BOOLEAN HEAP::Walk
		( 
		BOOLEAN						  *Active,
		VOID						  **Address,
		SBIT32						  *Size 
		)
    {
	//
	//   Although normally a class is never called before
	//   its constructor.  The heap is subject to some strange
	//   behaviour so we check to make sure this is not the
	//   case.
	//
	if ( Active )
		{
		//
		//   We walk the heap and find the next allocation
		//   along with some basic information.
		//
		if ( PrivateFind -> Walk( Active,Address,TopCache,Size ) )
			{
			//
			//   We know that the element appears to be 
			//   allocated but it may be in the cache
			//   somewhere so ensure this is not the case.
			//
			if ( ((*Size) > 0) && ((*Size) <= MaxCacheSize) )
				{
				if ( FindCache( (*Size) ) -> SearchCache( (*Address) ) )
					{ (*Active) = False; }
				}

			return True;
			}
		}

	return False;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   We would like to destroy the heap at the end of the run        */
    /*   just to be tidy.  However, to do this we need to know that     */
    /*   all of the other destructors have been called and that the     */
    /*   application will not request more memory or use any existing   */
    /*   allocations.  We can't know this without help from the         */
    /*   compiler and OS.                                               */
    /*                                                                  */
    /********************************************************************/

HEAP::~HEAP( VOID )
	{
	REGISTER SBIT32 Count;

	//
	//   We mark the heap as inactive.
	//
	Active = False;

	//
	//   We claim all of the heap locks to freeze
	//   all new allocations or deletions.
	//
	LockAll();
#ifdef ENABLE_HEAP_STATISTICS

	//
	//   Deal with heap statistics.
	//
	if ( Statistics != NULL ) 
		{
		//
		//   Print all the statistics.
		//
		PrintHeapStatistics();

		//
		//   Deallocate the area.
		//
		RockallBackEnd -> DeleteArea
			( 
			((VOID*) Statistics),
			(MaxCacheSize * sizeof(SBIT32)),
			False
			); 
		}
#endif

	//
	//   Now reset all the caches.
	//
	for ( Count=0;Count < CachesSize;Count ++ )
		{ Caches[ Count ] -> DeleteAll(); }

	//
	//   Delete the heap.
	//
	NewPage -> DeleteAll( False );

	//
	//   We release any of the shared locks we 
	//   cliamed earlier.
	//
	UnlockAll( True );

	//
	//   Delete the heap mapping tables.
	//
	if ( SizeToCache1 != NULL ) 
		{ 	
		//
		//   Deallocate the area.
		//
		RockallBackEnd -> DeleteArea
			( 
			((VOID*) SizeToCache1),
			(MaxTable1 + MaxTable2),
			False
			); 
		}
	}
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\PrivateFindList.hpp ===
#ifndef _PRIVATE_FIND_LIST_HPP_
#define _PRIVATE_FIND_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "NewPageList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The find list.                                                 */
    /*                                                                  */
    /*   The find list links all the pages in the same hash bucket      */
    /*   together so that the correct page can be found.                */
    /*                                                                  */
    /********************************************************************/

class PRIVATE_FIND_LIST : public NEW_PAGE_LIST
    {
		//
		//   Private data.
		//
 		LIST						  PrivateFindList;

   public:
		//
		//   Public inline functions.
		//
		//   All page descriptions contain four linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
		//
        PRIVATE_FIND_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromPrivateFindList( LIST *HeadOfList )
			{ PrivateFindList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfPrivateFindList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInPrivateFindList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> First()) ); }

		INLINE VOID InsertInPrivateFindList( LIST *HeadOfList )
			{ PrivateFindList.Insert( HeadOfList ); }

		INLINE PAGE *NextInPrivateFindList( VOID )
			{ return ComputePageAddress( ((CHAR*) PrivateFindList.Next()) ); }

        ~PRIVATE_FIND_LIST( VOID )
			{ /* void */ };

	private:
		//
		//   Private functions.
		//
		//   Compute the actual start address of the page
		//   and return it to allow the linked list to
		//   be correctly walked.
		//
		STATIC INLINE PAGE *ComputePageAddress( CHAR *Address )
			{
			if ( Address != NULL )
				{ return ((PAGE*) (Address - sizeof(NEW_PAGE_LIST))); }
			else
				{ return ((PAGE*) NULL); }
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        PRIVATE_FIND_LIST( CONST PRIVATE_FIND_LIST & Copy );

        VOID operator=( CONST PRIVATE_FIND_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\PublicFindList.hpp ===
#ifndef _PUBLIC_FIND_LIST_HPP_
#define _PUBLIC_FIND_LIST_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "PrivateFindList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   The find list.                                                 */
    /*                                                                  */
    /*   The find list links all the pages in the same hash bucket      */
    /*   together so that the correct page can be found.                */
    /*                                                                  */
    /********************************************************************/

class PUBLIC_FIND_LIST : public PRIVATE_FIND_LIST
    {
		//
		//   Private data.
		//
 		LIST						  PublicFindList;

   public:
		//
		//   Public inline functions.
		//
		//   All page descriptions contain four linked lists.
		//   These lists are all derived from a common base
		//   class.  However, this class is unable to support
		//   multiple instances in a single class a wrapper
		//   has been created for each list to make it work
		//   as required.
		//
        PUBLIC_FIND_LIST( VOID )
			{ /* void */ };

		INLINE VOID DeleteFromPublicFindList( LIST *HeadOfList )
			{ PublicFindList.Delete( HeadOfList ); }

		INLINE BOOLEAN EndOfPublicFindList( VOID )
			{ return (this == NULL); }

		STATIC INLINE PAGE *FirstInPublicFindList( LIST *HeadOfList )
			{ return ComputePageAddress( ((CHAR*) HeadOfList -> First()) ); }

		INLINE VOID InsertInPublicFindList( LIST *HeadOfList )
			{ PublicFindList.Insert( HeadOfList ); }

		INLINE PAGE *NextInPublicFindList( VOID )
			{ return ComputePageAddress( ((CHAR*) PublicFindList.Next()) ); }

        ~PUBLIC_FIND_LIST( VOID )
			{ /* void */ };

	private:
		//
		//   Private functions.
		//
		//   Compute the actual start address of the page
		//   and return it to allow the linked list to
		//   be correctly walked.
		//
		STATIC INLINE PAGE *ComputePageAddress( CHAR *Address )
			{
			if ( Address != NULL )
				{ return ((PAGE*) (Address - sizeof(PRIVATE_FIND_LIST))); }
			else
				{ return ((PAGE*) NULL); }
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        PUBLIC_FIND_LIST( CONST PUBLIC_FIND_LIST & Copy );

        VOID operator=( CONST PUBLIC_FIND_LIST & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\ThreadSafe.hpp ===
#ifndef _THREAD_SAFE_HPP_
#define _THREAD_SAFE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Assembly.hpp"
#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Track the need for locks.                                      */
    /*                                                                  */
    /*   Although it may seem simple to know whether to take a lock     */
    /*   there are addition complications such as recursive cases.      */
    /*   We have colected all the messy code into this class.           */
    /*                                                                  */
    /********************************************************************/

class THREAD_SAFE : public ASSEMBLY
    {
		//
		//   Private data.
		//
		//   All the locking information is held here so as
		//   to simplify the code.
		//
		SBIT32						  Claim;
		SBIT32						  Owner;
		SBIT32						  Recursive;
		SPINLOCK					  Spinlock;
		BOOLEAN						  ThreadSafe;

   public:
		//
		//   Public functions.
		//
		//   The translation functionality supplied by this
		//   class is only applicable after an allocation
		//   has been made.  Hence, all of the APIs supported
		//   relate to the need to translate an allocation
		//   address to the host page description.
		//
        THREAD_SAFE( BOOLEAN NewThreadSafe );

		BOOLEAN ClaimGlobalLock( VOID );

		VOID EngageGlobalLock( VOID );

		BOOLEAN ReleaseGlobalLock( BOOLEAN Force = False );

        ~THREAD_SAFE( VOID );

		//
		//   Public inline functions.
		//
		//   Although this class is perhaps the most self
		//   contained.  Nonetheless, there is still lots
		//   of situations when other classes need to 
		//   interact and get information about the current
		//   situation.
		//
		INLINE BOOLEAN ClaimActiveLock( VOID )
			{ return ((ThreadSafe) && (GetThreadId() != Owner)); }

	private:
        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        THREAD_SAFE( CONST THREAD_SAFE & Copy );

        VOID operator=( CONST THREAD_SAFE & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\heap.hpp ===
#ifndef _HEAP_HPP_
#define _HEAP_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Common.hpp"
#include "Environment.hpp"
#include "Find.hpp"
#include "NewPage.hpp"
#include "Prefetch.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class BUCKET;
class CACHE;
class ROCKALL_BACK_END;

    /********************************************************************/
    /*                                                                  */
    /*   The heap interface.                                            */
    /*                                                                  */
    /*   The traditional memory allocation interface only supports      */
    /*   a single allocation heap.  This memory allocator supports      */
    /*   multiple allocation heaps.  However, the interface nicely      */
    /*   hides this so at this point we are back to the traditional     */
    /*   single heap interface.                                         */
    /*                                                                  */
    /********************************************************************/

class HEAP : public ENVIRONMENT, public COMMON
    {
		//
		//   Private data.
		//
		//   The heap is the top level container of all the
		//   functionality in the other classes.  The 'Active'
		//   flag indicates if the heap has been initialized.
		//   The 'MaxFreePages' controls the amount of free
		//   space the heap will slave before it starts to
		//   return it the the external allocator.  The
		//   'SmallestParentMask' is mask that shows which 
		//   parts of an address can be safely masked off
		//   and still ensure a hit in the find lookaside
		//   cache.
		//
		BOOLEAN						  Active;
		SBIT32						  MaxFreePages;
		BIT32						  SmallestParentMask;

		//
		//   A heap is merely a collection of fixed sized
		//   allocation buckets (each with an optional cache).
		//   The 'CachesSize' is the total number of buckets.
		//   The 'MinCacheSize' is the allocation size of the
		//   smallest bucket.  The 'MidCacheSize' is the size
		//   of the bucket where the stride changes.  The
		//   'MaxCacheSize' is the allocation size of the 
		//   largest bucket externally visable.
		//
		SBIT32						  CachesSize;
		SBIT32						  MinCacheSize;
		SBIT32						  MidCacheSize;
		SBIT32						  MaxCacheSize;

		//
		//   A key function of the heap is to convert the
		//   requested allocation size into a pointer to
		//   the appropriate bucket (and cache).  This has
		//   to be very fast and is achieved using a direct
		//   lookup (i.e. an array).  The lookup array 
		//   consists of two sections (i.e. for small sizes
		//   and large sizes) to minimize space.  The 
		//   'MaxTable1' and 'MaxTable2' variables contain 
		//   the size of each section of the array.  The 
		//   'ShiftSize1' and 'ShiftSize2' variables contain
		//   the shift that should be applied to the size to
		//   obtain the appropriate index.  The 'SizeToCache1'
		//   and 'SizeToCache2' pointers refer to the direct
		//   lookup tables.
		//   
		SBIT32						  MaxTable1;
		SBIT32						  MaxTable2;
		SBIT32						  ShiftSize1;
		SBIT32						  ShiftSize2;
		CACHE                         **SizeToCache1;
		CACHE                         **SizeToCache2;

		//
		//   The heap needs to have access to most of the 
		//   other classes.  The 'Caches' class sits on
		//   top of an allocation bucket which owns all
		//   the allocated memory for a given size.  The
		//   'ExternalCache' is a special bucket that 
		//   contains weird sized pages.  The 'Find' class
		//   translates allocation addresses to page 
		//   descriptions.  The 'Services' class is needed
		//   to gain access to the external allocation APIs.
		//   The 'NewPage' class owns all page descriptions
		//   and plays a significant role in whole heap
		//   operations.  The 'TopCache' is the largest 
		//   bucket size and owns almost all the externally
		//   allocated memory.  The 'ThreadSafe' class  
		//   indicates whether locking being used.
		//
		CACHE						  **Caches;
		CACHE						  *ExternalCache;
		NEW_PAGE					  *NewPage;
		PREFETCH					  Prefetch;
		FIND						  *PrivateFind;
		FIND						  *PublicFind;
		ROCKALL_BACK_END			  *RockallBackEnd;
		CACHE						  *TopCache;
		THREAD_SAFE					  *ThreadSafe;
#ifdef ENABLE_HEAP_STATISTICS

		//
		//   Statistics data.
		//
		//   A key feature of this heap is its ability to be
		//   significantly reconfigured at run time.  A great
		//   deal of complexity could have been removed if 
		//   certain static choices had been made.  Although
		//   this flexibility is nice the support of statistics
		//   here allows precise information to be collected so
		//   to enable the value of this to be maximized.
		//   
		//
		SBIT32						  CopyMisses;
		SBIT32						  MaxCopySize;
		SBIT32						  MaxNewSize;
		SBIT32						  NewMisses;
		SBIT32						  Reallocations;
		SBIT32						  *Statistics;
		SBIT32						  TotalCopySize;
		SBIT32						  TotalNewSize;
#endif

   public:
		//
		//   Public functions.
		//
		//   The heap exports the high level interface
		//   out to the world.  Any request a developer
		//   can make must come through one of these
		//   functions.
		//
        HEAP
			(
			CACHE					  *Caches1[],
			CACHE					  *Caches2[],
			SBIT32					  MaxFreeSpace,
			NEW_PAGE				  *NewPages,
			FIND					  *NewPrivateFind,
			FIND					  *NewPublicFind,
			ROCKALL_BACK_END		  *NewRockallBackEnd,
			SBIT32					  Size1,
			SBIT32					  Size2,
			SBIT32					  Stride1,
			SBIT32					  Stride2,
			THREAD_SAFE				  *NewThredSafe
			);

		BOOLEAN Delete( VOID *Address,SBIT32 Size = NoSize );

		VOID DeleteAll( BOOLEAN Recycle = True );

		BOOLEAN Details
			( 
			VOID					  *Address,
			SEARCH_PAGE				  *Details = NULL,
			SBIT32					  *Size = NULL 
			);

		BOOLEAN KnownArea( VOID *Address );

		VOID LockAll( VOID );

		BOOLEAN MultipleDelete
			( 
			SBIT32					  Actual,
			VOID					  *Array[],
			SBIT32					  Size = NoSize
			);

		BOOLEAN MultipleNew
			( 
			SBIT32					  *Actual,
			VOID					  *Array[],
			SBIT32					  Requested,
			SBIT32					  Size,
			SBIT32					  *Space = NULL,
			BOOLEAN					  Zero = False
			);

		VOID *New
			( 
			SBIT32					  Size,
			SBIT32					  *Space = NULL,
			BOOLEAN					  Zero = False
			);

		VOID *Resize
			( 
			VOID					  *Address,
			SBIT32					  NewSize,
			SBIT32					  Move = 1,
			SBIT32					  *Space = NULL,
			BOOLEAN					  NoDelete = False,
			BOOLEAN					  Zero = False
			);

		BOOLEAN Truncate( SBIT32 MaxFreeSpace = 0 );

		VOID UnlockAll( BOOLEAN Partial = False );

		BOOLEAN Verify( VOID *Address,SBIT32 *Size = NULL );

		BOOLEAN Walk
			( 
			BOOLEAN					  *Active,
			VOID					  **Address,
			SBIT32					  *Size 
			);

        ~HEAP( VOID );

		//
		//   Public inline functions.
		//
		//   Although these functions are public they mostly
		//   intended for internal consumption and are not
		//   to be called externally.
		//
		INLINE SBIT32 GetMaxFreePages( VOID )
			{ return MaxFreePages; }

		INLINE VOID *SpecialNew( SBIT32 Size )
			{ return NewPage -> NewCacheStack( Size ); }

	private:
		//
		//   Private functions.
		//
		//   All of the statistical information is 
		//   generated and output when the heaps
		//   destructor executes.
		//
		CACHE *FindCache( SBIT32 Size );

#ifdef ENABLE_HEAP_STATISTICS
		VOID PrintHeapStatistics( VOID );

#endif
		//
		//   Private inline functions.
		//
		//   The notion that resizing an allocation is 
		//   cheap has worked its way into the minds of 
		//   a large number of developers.  As a result
		//   parameter has been added to the function to
		//   allow the actual behavior to be controlled.
		//
		INLINE BOOLEAN ResizeTest( SBIT32 Delta,SBIT32 Move )
			{
			return
				(
				((Move > 0) && ((((Delta >= 0) ? Delta : -Delta) >= Move)))
					||
				((Move < 0) && ((Delta > 0) || (Delta <= Move)))
				);
			}

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        HEAP( CONST HEAP & Copy );

        VOID operator=( CONST HEAP & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\newpage.hpp ===
#ifndef _NEW_PAGE_HPP_
#define _NEW_PAGE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Common.hpp"
#include "Environment.hpp"
#include "Find.hpp"
#include "Page.hpp"
#include "RockallBackEnd.hpp"
#include "RockallFrontEnd.hpp"
#include "Spinlock.hpp"
#include "ThreadSafe.hpp"
 
    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The constants supplied here relate to various failure          */
    /*   conditions or situations where information is unknown.         */
    /*                                                                  */
    /********************************************************************/

CONST SBIT16 NoSizeKey				  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;

    /********************************************************************/
    /*                                                                  */
    /*   Create and delete pages.                                       */
    /*                                                                  */
    /*   We would normally expect a class to manage its own memory.     */
    /*   However, this is quite difficult for the 'PAGE' class as it    */
    /*   is also responsible for managing the memory for the memory     */
    /*   allocator.  So here we remove a potentially nasty chore        */
    /*   and isolate it in a class of its own.                          */
    /*                                                                  */
    /********************************************************************/

class NEW_PAGE : public ENVIRONMENT, public COMMON
    {
		//
		//   Private structures.
		//
		//   All the pages descriptions created by this
		//   class and managed by the memory allocator
		//   are linked in three list.  One of these lists
		//   is managed by this class and is called the
		//   'NewPageList'.  All pages are linked into 
		//   of three sub-lists.  The 'ExternalList' is
		//   a list of pages externally allocated pages.
		//   The 'FullList' is a list of sub-allocated
		//   space from the 'ExternalList' which is 
		//   partially or completely filled with alocations.
		//   Finally, the 'FreeList' is a collection of
		//   empty page descriptions all of the same size.
		//   
		//
		typedef struct
			{
			SBIT32                    Elements;
			LIST					  ExternalList;
			LIST					  FreeList;
			LIST					  FullList;
			SBIT32                    Size;
			}
		NEW_PAGES;
		
		//
		//   Private data.
		//
		//   We manage a collection of data structures in
		//   this class.  The fundamental data structure
		//   is a stack of externally allocated pages that
		//   typically contain page descriptions that are
		//   linked together into linked lists.  The maximum
		//   size of this stack is given by 'MaxStack'. 
		//   A few additional pages are consumed to allocate
		//   stacks for caches in other classes.
		//
		SBIT32						  MaxCacheStack;
		SBIT32						  MaxNewPages;
		SBIT32						  MaxStack;

		//
		//   We keep track of various values to save having
		//   to recompute them.  The 'NaturalSize' is the 
		//   natural allocation size of our host (i.e. the OS).
		//   The 'RootSize' is some multiple of the 
		//   'NaturalSize' that this class uses to consume 
		//   memory.  The 'ThreadSafe' flag indicates whether
		//   we need to use locks.  The "TopOfStack' is the
		//   stack which contains pointers to the externally
		//   allocated space.  The 'Version' is the global
		//   version number that is used to stamp each page
		//   whenever it is allocated or deallocated.  The
		//   version number allows the code to ensure that
		//   a page description has not been changed while
		//   it was not holding the associated lock.
		//   
		SBIT32						  NaturalSize;
		SBIT32						  RootCoreSize;
		SBIT32						  RootStackSize;
		SBIT32						  TopOfStack;
		SBIT32						  Version;

		//
		//   We keep pointers to all the interesting data
		//   structures we may need to update.  The
		//   'CacheStack' points to block of memory that
		//   is being sliced into small stacks for caches
		//   in other classes.  The 'NewPages' points to
		//   an array of linked lists of page descriptions.
		//   Each collection of page descriptions is 
		//   identical except for the size of the assocated
		//   bit vector.
		//
		CHAR						  *CacheStack;
 		NEW_PAGES					  *NewPages;
		VOID                          **Stack;

		//
		//   We sometimes need to interact with some of
		//   the other class.  The 'Find" class is a hash
		//   table of all the currently allocated pages.
		//   The 'RockallBackEnd' class contains the external
		//   API which includes the external memory memory
		//   allocation functions.  The 'TopCache' is the
		//   largest cache we support and contains details
		//   about top level allocations sizes.  The   
		//   'ThreadSafe' class indicates whether locking 
		//   is required. 
		//
		ROCKALL_BACK_END			  *RockallBackEnd;
		CACHE						  *TopCache;
		THREAD_SAFE					  *ThreadSafe;

		SPINLOCK                      Spinlock;

   public:
		//
		//   Public functions.
		//
		//   The public functions provide support for creating
		//   new page descriptions and caches for other 
		//   classes.  Although a lot of the fuinctionality
		//   of the heap is masked from this class various
		//   features such as deleting the entire heap
		//   (i.e. 'DeleteAll') are still visable.
		//
        NEW_PAGE
			(
			SBIT32					  NewPageSizes[],
			ROCKALL_BACK_END		  *NewRockallBackEnd,
			SBIT32					  Size,
			THREAD_SAFE				  *NewThreadSafe 
			);

		PAGE *CreatePage( CACHE *Cache,SBIT32 NewSize = NoSize );

		VOID DeleteAll( BOOLEAN Recycle );

		VOID DeletePage( PAGE *Page );

		SBIT16 FindSizeKey( SBIT16 NumberOfElements );

		VOID *NewCacheStack( SBIT32 Size  );

		VOID ResizeStack( VOID );

		BOOLEAN Walk( SEARCH_PAGE *Details,FIND *Find );

        ~NEW_PAGE( VOID );

		//
		//   Public inline functions.
		//
		//   The public inline functions are typically either
		//   small or highly performance sensitive.  The
		//   functions here mainly relate to locking and
		//   updating various data structures.
		//
		INLINE VOID ClaimNewPageLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Spinlock.ClaimLock(); } 
			}

		INLINE VOID ReleaseNewPageLock( VOID )
			{
			if ( ThreadSafe -> ClaimActiveLock() )
				{ Spinlock.ReleaseLock(); } 
			}

		INLINE VOID UpdateNewPage( CACHE *NewTopCache )
			{ TopCache = NewTopCache; }

	private:
		//
		//   Private functions.
		//
		//   We support the overloading of the external
		//   memory allocation routines.  This is somewhat
		//   unusual and means that we need to verify
		//   that these functions do not supply us with
		//   total rubbish.
		//
		VOID *VerifyNewArea( SBIT32 AlignMask,SBIT32 Size,BOOLEAN User );

        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        NEW_PAGE( CONST NEW_PAGE & Copy );

        VOID operator=( CONST NEW_PAGE & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\newpage.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "New.hpp"
#include "NewPage.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants set overall limits on the number and size of     */
    /*   page descriptions for pages within the memory allocator.       */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MinNewPages			  = 1;
CONST SBIT32 VectorRange			  = ((2 << 15) - 1);

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   A 'PAGE' structure has various fixed fields and a variable     */
    /*   sized allocation bit vector.  When this class is initialized   */
    /*   the user is required to supply us with an array that details   */
    /*   the sizes of allocation bit vectors supported.                 */
    /*                                                                  */
    /********************************************************************/

NEW_PAGE::NEW_PAGE
		(
		SBIT32						  NewPageSizes[],
		ROCKALL_BACK_END			  *NewRockallBackEnd,
		SBIT32						  Size,
		THREAD_SAFE					  *NewThreadSafe 
		)
    {
	REGISTER SBIT32 DefaultRootSize = (NewRockallBackEnd -> NaturalSize());
	REGISTER SBIT32 ReservedBytes = (Size * sizeof(NEW_PAGES));
	REGISTER SBIT32 SpareBytes = (DefaultRootSize - ReservedBytes);
	REGISTER SBIT32 StackSize = (SpareBytes / sizeof(VOID*));

	//
	//   We need to make sure that we appear to have a valid
	//   array of 'NewPageSizes' and that the bit vector sizes
	//   do not exceed the memory addressing range.
	//
	if 
			(
			PowerOfTwo( DefaultRootSize )
				&&
			(DefaultRootSize >= PageSize())
				&&
			(Size >= MinNewPages) 
				&&
			((NewPageSizes[ (Size-1) ] * OverheadBitsPerWord) <= VectorRange)
			)
		{
		REGISTER VOID *NewMemory = 
			(
			NewRockallBackEnd -> NewArea
				( 
				(DefaultRootSize-1),
				DefaultRootSize,
				False
				)
			);

		//
		//   We are in big trouble if we can not allocate space
		//   to store this initial control information.  If the
		//   allocation fails we are forced to exit and the whole  
		//   memory allocator becomes unavailable.
		//
		if ( NewMemory != AllocationFailure )
			{
			REGISTER SBIT32 Count;
			REGISTER SBIT32 LastSize = 0;

			//
			//   We are now ready to setup the configuration
			//   information.
			//
			MaxCacheStack = 0;
			MaxNewPages = Size;
			MaxStack = StackSize;

			NaturalSize = DefaultRootSize;
			RootCoreSize = DefaultRootSize;
			RootStackSize = 0;
			ThreadSafe = NewThreadSafe;
			TopOfStack = 0;
			Version = 0;

			CacheStack = NULL;
			NewPages = ((NEW_PAGES*) NewMemory);
			Stack = ((VOID**) & NewPages[ Size ]);

			RockallBackEnd = NewRockallBackEnd;
			TopCache = NULL;

			//
			//   Create a lists for the various page 
			//   sizes and prepare them for use.
			//
			for ( Count=0;Count < Size;Count ++ )
				{
				REGISTER SBIT32 CurrentSize = NewPageSizes[ Count ];

				if ( CurrentSize > LastSize )
					{
					REGISTER NEW_PAGES *NewPage = & NewPages[ Count ];

					//
					//   Create a list for the current
					//   size and fill in all the related
					//   details.
					//
					NewPage -> Elements = (CurrentSize * OverheadBitsPerWord);
					PLACEMENT_NEW( & NewPage -> ExternalList,LIST );
					PLACEMENT_NEW( & NewPage -> FullList,LIST );
					PLACEMENT_NEW( & NewPage -> FreeList,LIST );
					NewPage -> Size = (CurrentSize * sizeof(BIT32));

					LastSize = CurrentSize;
					}
				else
					{ Failure( "Sizes in constructor for NEW_PAGES" ); }
				}
			}
		else
			{ Failure( "No memory in constructor for NEW_PAGES" ); }
		}
	else
		{ Failure( "Setup of pages in constructor for NEW_PAGES" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Create a new page.                                             */
    /*                                                                  */
    /*   Create a new 'PAGE' structure and prepare it for use.  If      */
    /*   we don't already have any pages of the required size then      */
    /*   allocate memory, create new 'PAGE' structures and link them    */
    /*   into the appropriate free chain.                               */
    /*                                                                  */
    /********************************************************************/

PAGE *NEW_PAGE::CreatePage( CACHE *Cache,SBIT32 NewSize )
    {
	REGISTER PAGE *NewPage = ((PAGE*) AllocationFailure);
	REGISTER SBIT16 SizeKey = (Cache -> GetSizeKey());

	//
	//   All allocations are made from fixed sized
	//   pages.  These pages have a bit vector to
	//   keep track of which elements are allocated
	//   and available.  The 'SizeKey' is an index
	//   into 'NewPages[]' that will supply a page
	//   that has a big enough the bit vector.
	//
#ifdef DEBUGGING
	if ( (SizeKey >= 0) && (SizeKey < MaxNewPages) )
		{
#endif
		REGISTER NEW_PAGES *Current;

		//
		//   When there is a potential for multiple threads 
		//   we claim the lock.
		//
		ClaimNewPageLock();

		//
		//   We allocate 'PAGE' structures as we need them
		//   and link them together in the free list.
		//   If we don't have any structures available we 
		//   allocate some more and add tem to the list.
		//
		if ( (Current = & NewPages[ SizeKey ]) -> FreeList.EndOfList() )
			{
			REGISTER SBIT32 ArrayElements = (Current -> Size - MinVectorSize);
			REGISTER SBIT32 ArraySize = (ArrayElements * sizeof(BIT32));
			REGISTER SBIT32 TotalSize = (sizeof(PAGE) + ArraySize);
			REGISTER SBIT32 FinalSize = CacheAlignSize( TotalSize );
			REGISTER SBIT32 TotalPages = (NaturalSize / FinalSize);

			//
			//   Nasty, we have run out of stack space.  If
			//   we can not grow this table then the heap
			//   will not be able to expand any further.
			//
			if ( TopOfStack >= MaxStack )
				{
				//
				//   Try to grow the stack size.
				//
				ResizeStack();

				//
				//   Update the pointer as the table may
				//   have moved.
				//
				Current = & NewPages[ SizeKey ];
				}

			//
			//   We may find ourseleves in a situation where
			//   the size of the new 'PAGE' structure is larger
			//   than the natural allocation size or the stack
			//   is full so we can't create new pages.  If so we
			//   refuse to create any new pages so any allocation
			//   requests for this size will fail.
			//
			if ( (TotalPages > 0) && (TopOfStack < MaxStack) )
				{
				REGISTER VOID *NewMemory = 
					(VerifyNewArea( (NaturalSize-1),NaturalSize,False ));

				//
				//   We may also find ourselves unable to 
				//   anymore memory.  If so we will fail the
				//   request to create a page.
				//
				if ( NewMemory != ((VOID*) AllocationFailure) )
					{
					REGISTER CHAR *Address;
					REGISTER SBIT32 Count;

					//
					//   Add the new allocation to stack of
					//   outstanding external allocations.
					//
					Stack[ (TopOfStack ++) ] = NewMemory;

					//
					//   Add the new elements to the free list
					//   for the current allocation size.
					//
					for 
							( 
							Count=0, Address = ((CHAR*) NewMemory);
							Count < TotalPages;
							Count ++, (Address += FinalSize)
							)
						{
						REGISTER PAGE *Page = ((PAGE*) Address);

						//
						//   The page has been allocated but not 
						//   initialized so call the constructor
						//   and the destructor to get it into
						//   a sane state.
						//
						PLACEMENT_NEW( Page,PAGE ) 
							(
							NULL,
							Cache,
							0,
							NULL,
							0
							);

						PLACEMENT_DELETE( Page,PAGE );

						//
						//   Finally add the page to the free list
						//   so it can be used.
						//
						Page -> InsertInNewPageList( & Current -> FreeList ); 
						}
					}
				}
			}

		//
		//   We are now ready to create a new allocation
		//   page.  We start by requesting a page from
		//   the parent bucket.  If this works we know that 
		//   we have almost everthing we need to create the 
		//   new page.
		//
		if ( ! Current -> FreeList.EndOfList() )
			{
			REGISTER VOID *NewMemory;
			REGISTER CACHE *ParentPage = (Cache -> GetParentCache());

			NewPage = (PAGE::FirstInNewPageList( & Current -> FreeList ));

			//
			//   We have found a suitable page structure
			//   so remove it from the free list.
			//
			NewPage -> DeleteFromNewPageList( & Current -> FreeList );

			//
			//   Release any lock we might have as another
			//   thread may be waiting to delete a page and
			//   be holding the lock we need in order to
			//   create a page.
			//
			ReleaseNewPageLock();

			//
			//   We need to allocate memory to store the users 
			//   data.  After all we are the memory allocator
			//   and that is our job in life.  Typically, we do
			//   this by making a recursive internal request
			//   from a larger bucket.  Nonetheless, at some point
			//   we will reach the 'TopCache' and will be forced
			//   to request memory from an external source.
			//
			if ( (Cache -> TopCache()) || (NewSize != NoSize) )
				{
				REGISTER int AlignMask = (TopCache -> GetPageSize()-1);

				//
				//   We allocate memory externally in large blocks 
				//   and sub-divide these allocations into smaller
				//   blocks.  The only exception is if the caller 
				//   caller is requesting some weird size in which
				//   case we request memory directly from the
				//   external allocator (usually the OS).
				//
				if ( NewSize == NoSize )
					{ NewSize = (Cache -> GetPageSize()); }

				//
				//   All externally allocated memory belongs
				//   to the global root.  Thus, it will be 
				//   found in the first lookup in the find
				//   table.
				//
				ParentPage = ((CACHE*) GlobalRoot);

				//
				//   Allocate from the external allocator.
				//
				NewMemory = (VerifyNewArea( AlignMask,NewSize,True ));
				}
			else
				{
				//
				//   Allocate memory from a larger cache and then
				//   sub-divide it as needed.
				//
				NewMemory = 
					(Cache -> GetParentCache() -> CreateDataPage()); 
				}

			//
			//   Reclaim any lock we have had earlier so 
			//   we can update the the new page structure.
			//
			ClaimNewPageLock();

			//
			//   Lets make sure we sucessfully allocated the
			//   memory for the data page.
			//
			if ( NewMemory != AllocationFailure )
				{
				//
				//   We now have everything we need so lets
				//   create a new page.
				//
				PLACEMENT_NEW( NewPage,PAGE ) 
					(
					NewMemory,
					Cache,
					NewSize,
					ParentPage,
					(Version += 2)
					);

				//
				//   Finally lets add the new page to the various
				//   lists so we can quickly find it again later.
				//
				Cache -> InsertInBucketList( NewPage );

				Cache -> InsertInFindList( NewPage );

				NewPage -> InsertInNewPageList
					(
					(Cache -> TopCache())
						? & Current -> ExternalList 
						: & Current -> FullList 
					); 
				}
			else
				{
				//
				//   We were unable to allocate any data space
				//   for this new page so lets free the page 
				//   description and exit.
				//
				NewPage -> InsertInNewPageList( & Current -> FreeList );

				NewPage = ((PAGE*) AllocationFailure);
				}
			}

		//
		//   We have finished so release the lock now. 
		//
		ReleaseNewPageLock();
#ifdef DEBUGGING
		}
	else
		{ Failure( "The page size key is out of range" ); }
#endif

	return NewPage;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete all allocations.                                        */
    /*                                                                  */
    /*   Delete an entire heap and return all the memory to the         */
    /*   top level pool or the external allocator (usually the OS).     */
    /*                                                                  */
    /********************************************************************/

VOID NEW_PAGE::DeleteAll( BOOLEAN Recycle )
    {
	REGISTER SBIT32 Count;

	//
	//   Claim the global lock so that the various  
	//   lists can be updated.
	//
	ClaimNewPageLock();

	//
	//   We assume at this point that we have blocked
	//   all memory allocation and dealloction requests.
	//   We are now going to walk through the various lists
	//   and just blow away things.  We are going to
	//   do this in a tidy way just in case the caller
	//   wants to use the heap again later.
	//
	for ( Count=0;Count < MaxNewPages;Count ++ )
		{
		REGISTER NEW_PAGES *Current = & NewPages[ Count ];
		REGISTER PAGE *Page;
		REGISTER PAGE *NextPage;

		//
		//   All allocations that appear in the full list
		//   have been sub-allocated from larger pages in
		//   almost all cases.
		//
		for
				(
				Page = (PAGE::FirstInNewPageList( & Current -> FullList ));
				! Page -> EndOfNewPageList();
				Page = NextPage
				)
			{
			REGISTER VOID *Address = (Page -> GetAddress());
			REGISTER CACHE *Cache = (Page -> GetCache());
			REGISTER SBIT32 PageSize = (Page -> GetPageSize());

			//
			//   We decide here how we will deal with the page.
			//   If it is empty, non-standard or we are not
			//   recycling we will blow it away.  If not we
			//   simply reset it for later use.
			//
			if ( (Page -> Empty()) || (PageSize != NoSize) || (! Recycle) )
				{
				//
				//   We need to release any associated data page.
				//   If this is the top level then release the
				//   memory back to the external allocator.  If 
				//   not we release it back to the parent bucket.
				//
				if ( PageSize == NoSize )
					{
					//
					//   If we are just recycling then we cleanly
					//   delete the page.  If not then we know it
					//   will be blown away later so why bother.
					//
					if ( Recycle )
						{
						REGISTER CACHE *ParentCache = 
							(Cache -> GetParentCache());

						if ( ! (ParentCache -> DeleteDataPage( Address )) )
							{ Failure( "Reset data page in DeleteAll" ); }
						}
					}
				else
					{ RockallBackEnd -> DeleteArea( Address,PageSize,True ); }

				//
				//   We may have been blowing away pages  
				//   randomly and now we are about to destroy 
				//   the current page.  So lets figure out 
				//   what page comes next before we continue.
				//
				NextPage = (Page -> NextInNewPageList());

				//
				//   If the page is not full it will in a 
				//   bucket list somewhere.  We need to remove
				//   it as we are about to delete the page.
				//
				if ( ! Page -> Full() )
					{ Cache -> DeleteFromBucketList( Page ); }

				//
				//   Delete the page from the find list and the
				//   new page list.
				//
				Cache -> DeleteFromFindList( Page );

				Page -> DeleteFromNewPageList( & Current -> FullList );

				//
				//   Delete the page structure.
				//
				PLACEMENT_DELETE( Page,PAGE );

				//
				//   Finally add the page to the free list
				//   so it can be recycled.
				//
				Page -> InsertInNewPageList( & Current -> FreeList );
				}
			else
				{
				//
				//   We know that the current page has at 
				//   least one allocation on it so instead
				//   of deleting it we will mark it as free
				//   (except for any sub-allocations) and
				//   leave it around for next time.  If it
				//   is never used the next top level 
				//   'DeleteAll' will delete it.
				//
				Page -> DeleteAll();

				//
				//   We have now reset the current page so  
				//   lets figure out what page comes next.
				//
				NextPage = (Page -> NextInNewPageList());
				}
			}

		//
		//   We have a choice to make.  If we intend to
		//   use this heap again we keep all top level
		//   allocated memory in a list ready for reuse.
		//   If not we return it to the external allocator
		//   (usually the OS).
		//   
		if ( ! Recycle )
			{
			//
			//   The external allocations list contains an
			//   entry for every externally allocated page
			//   except those allocated for special internal 
			//   use within this class or for weird sized
			//   pages that appeared above in the 'FullList'.
			//
			for
					(
					Page = (PAGE::FirstInNewPageList( & Current -> ExternalList ));
					! Page -> EndOfNewPageList();
					Page = (PAGE::FirstInNewPageList( & Current -> ExternalList ))
					)
				{
				REGISTER VOID *Address = (Page -> GetAddress());
				REGISTER CACHE *Cache = (Page -> GetCache());
				REGISTER SBIT32 PageSize = (Page -> GetPageSize());

				//
				//   We no longer need this top level allocation
				//   so return it to the external allocator.
				//
				RockallBackEnd -> DeleteArea( Address,PageSize,True );

				//
				//   If the page is not full it will in a 
				//   bucket list somewhere.  We need to remove
				//   it as we are about to delete the page.
				//
				if ( ! Page -> Full() )
					{ Cache -> DeleteFromBucketList( Page ); }

				//
				//   Delete the page from the find list and the
				//   new page list.
				//
				Cache -> DeleteFromFindList( Page );

				Page -> DeleteFromNewPageList( & Current -> ExternalList );

				//
				//   Delete the page structure.
				//
				PLACEMENT_DELETE( Page,PAGE );

				//
				//   Finally add the page to the free list
				//   so it can be recycled.
				//
				Page -> InsertInNewPageList( & Current -> FreeList );
				}
			}
		}

	//
	//   We have finished so release the lock now. 
	//
	ReleaseNewPageLock();
    }

    /********************************************************************/
    /*                                                                  */
    /*   Delete a page.                                                 */
    /*                                                                  */
    /*   Delete a page structure, free the associated memory and        */
    /*   unlink it from the various allocation lists.                   */
    /*                                                                  */
    /********************************************************************/

VOID NEW_PAGE::DeletePage( PAGE *Page )
    {
	REGISTER CACHE *Cache = (Page -> GetCache());
	REGISTER SBIT16 SizeKey = (Cache -> GetSizeKey());

	//
	//   All allocations are made from fixed sized
	//   pages.  These pages have a bit vector to
	//   keep track of which elements are allocated
	//   and available.  The 'SizeKey' is an index
	//   into 'NewPages[]' that will supply a page
	//   that has a big enough the bit vector.
	//
#ifdef DEBUGGING
	if ( (SizeKey >= 0) && (SizeKey < MaxNewPages) )
		{
#endif
		REGISTER VOID *Address = (Page -> GetAddress());
		REGISTER NEW_PAGES *Current = & NewPages[ SizeKey ];
		REGISTER SBIT32 Size = (Page -> GetPageSize());

		//
		//   Claim the global lock so that the various  
		//   lists can be updated.
		//
		ClaimNewPageLock();

		//
		//   Remove the page from the lists and delete it.
		//
		Cache -> DeleteFromBucketList( Page );

		Cache -> DeleteFromFindList( Page );

		Page -> DeleteFromNewPageList
			(
			(Cache -> TopCache())
				? & Current -> ExternalList 
				: & Current -> FullList 
			); 

		PLACEMENT_DELETE( Page,PAGE );

		//
		//   Finally add the page to the free list
		//   so it can be recycled.
		//
		Page -> InsertInNewPageList( & Current -> FreeList );

		//
		//   We have finsihed so release the lock.
		//
		ReleaseNewPageLock();

		//
		//   We need to release any associated data page.
		//   If this is the top level then release the
		//   memory back to the external allocator.  If 
		//   not we release it back to the parent bucket.
		//   This must be done after all the linked lists
		//   have been updated otherwise we may get duplicate
		//   entry in the hash table which may cause us to
		//   think the memory is free when it is in use.
		//
		if ( Size == NoSize )
			{ 
			REGISTER CACHE *ParentCache = (Cache -> GetParentCache());

			if ( ! (ParentCache -> DeleteDataPage( Address )) )
				{ Failure( "Deleting data page in DeletePage" ); }
			}
		else
			{ RockallBackEnd -> DeleteArea( Address,Size,True ); }
#ifdef DEBUGGING
		}
	else
		{ Failure( "The page size key out of range in DeletePage" ); }
#endif
	}

    /********************************************************************/
    /*                                                                  */
    /*   Find the correct index in new page.                            */
    /*                                                                  */
    /*   When we come to create a new page we need to make sure the     */
    /*   bit vector is large enough for the page.  We calculate this    */
	/*   here just once to save time later.                             */
    /*                                                                  */
    /********************************************************************/

SBIT16 NEW_PAGE::FindSizeKey( SBIT16 NumberOfElements )
    {
	REGISTER SBIT32 Count;

	//
	//   Search the table of page structures looking for 
	//   elements of a suitable size.  As the table is
	//   known to be in order of increasing size we can
	//   terminate the search as soon as we find something 
	//   large enough.
	//
	for ( Count=0;Count < MaxNewPages;Count ++ )
		{
		REGISTER NEW_PAGES *Current = & NewPages[ Count ];

		if ( NumberOfElements <= Current -> Elements )
			{ return ((SBIT16) Count); }
		}

	//
	//   Nasty, we don't seem to have anything large enough
	//   to store the bit vector.
	//
	return NoSizeKey;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Create a new cache stack.                                      */
    /*                                                                  */
    /*   A cache stack is an array that contains memory allocations     */
    /*   that are waiting to be allocated or released.                  */
    /*                                                                  */
    /********************************************************************/

VOID *NEW_PAGE::NewCacheStack( SBIT32 Size )
    {
	REGISTER VOID *NewStack;

	//
	//   Claim the global lock so that the various  
	//   lists can be updated.
	//
	ClaimNewPageLock();

	//
	//   We ensure that there is enough space to make the
	//   allocation.  If not we request additional space
	//   and prepare it for use.
	//
	if ( (CacheStack == NULL) || ((MaxCacheStack + Size) > NaturalSize) )
		{
		//
		//   Nasty, we have run out of stack space.  If
		//   we can not grow this table then the heap
		//   will not be able to expand any further.
		//
		if ( TopOfStack >= MaxStack )
			{
			//
			//   Try to grow the stack size.
			//
			ResizeStack();
			}

		//
		//   We may find ourseleves in a situation where
		//   the size of the new stack structure is larger
		//   than the natural allocation size or the stack
		//   is full so we can't create new pages.  If so we
		//   refuse to create any new stacks.
		//
		if ( (Size < NaturalSize) && (TopOfStack < MaxStack) )
			{
			REGISTER VOID *NewMemory = 
				((CHAR*) VerifyNewArea( (NaturalSize-1),NaturalSize,False ));

			//
			//   We may also find ourselves unable to get 
			//   anymore memory.  If so we will fail the
			//   request to create a new cache stack.
			//
			if ( NewMemory != ((VOID*) AllocationFailure) )
				{
				//
				//   Add the new allocation to stack of
				//   outstanding external allocations.
				//
				Stack[ (TopOfStack ++) ] = NewMemory;

				//
				//   Prepare the new memory block for use.
				//   
				CacheStack = ((CHAR*) NewMemory);
				MaxCacheStack = 0;
				}
			else
				{ 
				//
				//   We have finished so release the lock now. 
				//
				ReleaseNewPageLock();

				return NULL; 
				}
			}
		else
			{ 
			//
			//   We have finished so release the lock now. 
			//
			ReleaseNewPageLock();

			return NULL; 
			}
		}

	//
	//   We allocate some space for the new cache 
	//   stack and update and align the high water
	//   mark of the space used.
	//
	NewStack = ((VOID*) & CacheStack[ MaxCacheStack ]);

	MaxCacheStack += (Size + CacheLineMask);
	MaxCacheStack &= ~CacheLineMask;

	//
	//   We have finished so release the lock now. 
	//
	ReleaseNewPageLock();

	return NewStack;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Resize the new page stack.                                     */
    /*                                                                  */
    /*   The new page stack holds pointers to all the pages owned       */
    /*   by the heap.  If this stack become full we must expand it      */
	/*   otherwise we can no longer grow the heap.                      */
    /*                                                                  */
    /********************************************************************/

VOID NEW_PAGE::ResizeStack( VOID )
    {
	REGISTER SBIT32 NewSize = 
		(((RootStackSize <= 0) ? NaturalSize : RootStackSize) * 2);

	//
	//   Lets just check that we have really run out
	//   of stack space as expanding it really hurts.
	//
	if ( TopOfStack >= MaxStack )
		{
		REGISTER VOID *NewMemory = 
			(
			RockallBackEnd -> NewArea
				( 
				(NaturalSize-1),
				NewSize,
				False
				)
			);

		//
		//   We need to verify that we were able to allocate
		//   fresh memory for the stack.
		//
		if ( NewMemory != NULL )
			{
			REGISTER BOOLEAN DeleteStack = (RootStackSize > 0);
			REGISTER VOID *OriginalMemory = ((VOID*) Stack);
			REGISTER SBIT32 OriginalSize = (MaxStack * sizeof(VOID*));

			//
			//   All is well as we were able to allocate 
			//   additional space for the stack.  All we 
			//   need to do now is to update the control 
			//   information.
			//
			MaxStack = (NewSize / sizeof(VOID*));

			RootStackSize = NewSize;

			Stack = ((VOID**) NewMemory);

			//
			//   Now lets copy across the existing data. 
			//
			memcpy( NewMemory,OriginalMemory,OriginalSize );

			//
			//   When the heap is created we put the
			//   stack on the root core page.  Later
			//   we may move it if we expand it.  If
			//   this is the case we have to delete  
			//   the previous expansion here.
			//
			if ( DeleteStack )
				{
				//
				//   Deallocate the existing stack if it
				//   is not on the root core page.
				//
				RockallBackEnd -> DeleteArea
					( 
					OriginalMemory,
					OriginalSize,
					False 
					);
				}
			}
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Verify an external allocation.                                 */
    /*                                                                  */
    /*   All memory requests are allocated from the external allocator  */
	/*   at the highest level.  Here we have a wrapper for this         */
    /*   function so we can test the result and make sure it is sane.   */
    /*                                                                  */
    /********************************************************************/

VOID *NEW_PAGE::VerifyNewArea( SBIT32 AlignMask,SBIT32 Size,BOOLEAN User )
	{
#ifdef DEBUGGING
	//
	//   We need to ensure that the alignment of the new
	//   external allocation is a power of two.
	//
	if ( PowerOfTwo( (AlignMask + 1) ) )
		{
#endif
		REGISTER VOID *NewMemory = 
			(RockallBackEnd -> NewArea( AlignMask,Size,User ));

		//
		//   We need to ensure that the external allocation
		//   request is sucessful.  If not it makes no sense
		//   to try and check it.
		//
		if ( NewMemory != ((VOID*) AllocationFailure) )
			{
			//
			//   We require the external memory allocator to always
			//   allocate memory on the requested boundary.  If not 
			//   we are forced to reject the supplied memory.
			//
			if ( (((SNATIVE) NewMemory) & AlignMask) == 0 )
				{ return NewMemory; }
			else
				{ 
				RockallBackEnd -> DeleteArea( NewMemory,Size,User );
				
				Failure( "Alignment of allocation in VerifyNewArea" );
				}
			}
#ifdef DEBUGGING
		}
	else
		{ Failure( "Alignment is not a power of two in VerifyNewArea" ); }
#endif

	return ((VOID*) AllocationFailure);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Walk the heap.                                                 */
    /*                                                                  */
    /*   We have been asked to walk the heap.  It is hard to know       */
    /*   why anybody might want to do this given the rest of the        */
    /*   functionality available.  Nonetheless, we just do what is      */
    /*   required to keep everyone happy.                               */
    /*                                                                  */
    /********************************************************************/

BOOLEAN NEW_PAGE::Walk( SEARCH_PAGE *Details,FIND *Find )
    {
	//
	//   Claim the global lock so that the various  
	//   lists can be updated.
	//
	ClaimNewPageLock();

	//
	//   We examine the current address to see if it
	//   is null.  If so then this is the start of a
	//   heap walk so we need to set it up.
	//
	if ( Details -> Address == NULL )
		{
		REGISTER SBIT32 Count;

		//
		//   Walk through the list of different sized
		//   page descriptions.
		//
		for ( Count=0;Count < MaxNewPages;Count ++ )
			{
			REGISTER NEW_PAGES *Current = & NewPages[ Count ];

			//
			//   Compute a pointer to the first element
			//   of the current size.
			//
			Details -> Page = 
				(PAGE::FirstInNewPageList( & Current -> FullList ));

			//
			//   Examine the current list of full (or 
			//   partially full) pages.  If there is at  
			//   least one page then this is the starting 
			//   point for the heap walk.
			//
			if ( ! Details -> Page -> EndOfNewPageList() )
				{
				//
				//   Compute the starting address of the 
				//   heap walk.
				//
				Details -> Address = 
					(Details -> Page -> GetAddress());

				break;
				}
			}
		}
	else
		{
		REGISTER PAGE *LastPage = Details -> Page;

		//
		//   We have exhusted the current page so walk
		//   the list and find the next page.
		//
		Details -> Page = 
			(Details -> Page -> NextInNewPageList());

		//
		//   We need to ensure that we have not reached
		//   the end of the current list.
		//
		if ( Details -> Page -> EndOfNewPageList() )
			{
			REGISTER SBIT32 Count;
			REGISTER BOOLEAN Found = False;

			//
			//   We need to find a new page description
			//   list to walk so reset the current 
			//   address just in case we don't find 
			//   anything.
			//
			Details -> Address = NULL;

			//
			//   We have reached the end of the current
			//   list and we need to continue with the
			//   start of the next list.  However, we
			//   don't know which list we were using
			//   previously.  So first we identify the
			//   previous list and then select the next
			//   avaibale list.
			//
			for ( Count=0;Count < MaxNewPages;Count ++ )
				{
				REGISTER NEW_PAGES *Current = & NewPages[ Count ];

				//
				//   We search for the original list
				//   we were walking.
				//
				if ( ! Found )
					{
					//
					//   When we find the original list
					//   then we set a flag showing that
					//   the next available list is the
					//   target.
					//
					if 
							( 
							LastPage 
								== 
							(PAGE::LastInNewPageList( & Current -> FullList )) 
							)
						{ Found = True; }
					}
				else
					{
					//
					//   We have found the previous list
					//   so the first element of the next
					//   list seems a good place to continue.
					//
					Details -> Page = 
						(PAGE::FirstInNewPageList( & Current -> FullList ));

					//
					//   We check to make sure that the list
					//   has at least one active page.  If not
					//   it is worthless and we continue looking
					//   for a suitable list.
					//
					if ( ! Details -> Page -> EndOfNewPageList() )
						{
						//
						//   Compute the starting address for 
						//   the next page in the heap walk.
						//
						Details -> Address = 
							(Details -> Page -> GetAddress());

						break;
						}
					}
				}
			}
		else
			{ 
			//
			//   Compute the starting address for 
			//   the next page in the heap walk.
			//
			Details -> Address = 
				(Details -> Page -> GetAddress());
			}
		}

	//
	//   If we find a new heap page to walk we update
	//   the details.  We mark some entry's as exhusted
    //   so as to provoke other code to set them up.
	//
	if ( Details -> Address != NULL )
		{
		//
		//   Compute the new allocation details.
		//
		Details -> Page -> FindPage
			( 
			Details -> Address,
			Details,
			Find,
			False 
			);
		}

	//
	//   We have finished so release the lock now. 
	//
	ReleaseNewPageLock();

	return (Details -> Address != NULL);
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory all the page structures and release any allocated      */
    /*   memory.                                                        */
    /*                                                                  */
    /********************************************************************/

NEW_PAGE::~NEW_PAGE( VOID )
    {
	REGISTER SBIT32 Count;

	//
	//   Delete all active allocations.
	//
	DeleteAll( False );

	//
	//   We are about to delete all of the memory 
	//   allocated by this class so destroy any
	//   internal pointers.
	//
	MaxCacheStack = 0;
	CacheStack = NULL;

	//
	//   We have now deleted all the memory allocated by
	//   this heap except for the memory  allocated directly 
	//   by this class.  Here we finish off the job by 
	//   deleting these allocations and reseting the internal 
	//   data structures.
	//
	for ( Count=0;Count < TopOfStack;Count ++ )
		{
		REGISTER VOID *Current = Stack[ Count ];

		RockallBackEnd -> DeleteArea( Current,NaturalSize,False );
		}

	TopOfStack = 0;

	//
	//   If we were forced to expand the root stack then
	//   release this additional memory now.
	//
	if ( RootStackSize > 0 )
		{
		//
		//   Deallocate root stack which previously 
		//   contained pointers to all the memory
		//   allocated by this class.
		//
		RockallBackEnd -> DeleteArea
			( 
			((VOID*) Stack),
			RootStackSize,
			False 
			);
		}

	//
	//   Delete all the new page list headings just
	//   to be neat
	//
	for ( Count=0;Count < MaxNewPages;Count ++ )
		{
		REGISTER NEW_PAGES *Current = & NewPages[ Count ];

		PLACEMENT_DELETE( & Current -> ExternalList,LIST );
		PLACEMENT_DELETE( & Current -> FullList,LIST );
		PLACEMENT_DELETE( & Current -> FreeList,LIST );
		}

	//
	//   Deallocate root core page which previously 
	//   contained all the new page lists.
	//
	RockallBackEnd -> DeleteArea
		( 
		((VOID*) NewPages),
		RootCoreSize,
		False 
		);
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\objd\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_heap_none_12.4.56.0_none_b4d7eebb1939bdb6
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=heap
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782.manifest
XP_MANIFEST_PATH=manifests\x86_heap_no-public-key_12.4.56.0_x-ww_6728f782.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782.cat
XP_CATALOG_PATH=manifests\x86_heap_no-public-key_12.4.56.0_x-ww_6728f782.cat
XP_PAYLOAD_PATH=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=heap,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\obj\i386\_asmid.inc ===
ASSEMBLY_IDENTITY_KEY_FORM=x86_heap_none_12.4.56.0_none_b4d7eebb1939bdb6
ASSEMBLY_IDENTITY_XP_KEY_FORM=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782
ASSEMBLY_IDENTITY_CULTURE=
ASSEMBLY_IDENTITY_NAME=heap
ASSEMBLY_IDENTITY_PROCESSOR_ARCHITECTURE=x86
ASSEMBLY_IDENTITY_PUBLIC_KEY=
ASSEMBLY_IDENTITY_PUBLIC_KEY_TOKEN=
ASSEMBLY_IDENTITY_TYPE=
ASSEMBLY_IDENTITY_TYPE_NAME=
ASSEMBLY_IDENTITY_VERSION=12.4.56.0
XP_KEY_FORM=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782
XP_MANIFEST_DIRECTORY=manifests
XP_MANIFEST_NAME=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782.manifest
XP_MANIFEST_PATH=manifests\x86_heap_no-public-key_12.4.56.0_x-ww_6728f782.manifest
XP_CATALOG_DIRECTORY=manifests
XP_CATALOG_NAME=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782.cat
XP_CATALOG_PATH=manifests\x86_heap_no-public-key_12.4.56.0_x-ww_6728f782.cat
XP_PAYLOAD_PATH=x86_heap_no-public-key_12.4.56.0_x-ww_6728f782
_DELAY_SIGN=0
!if [set _ASMIDTOATTRIBS_TLBIMP=]
!endif
CODESIGN_TESTKEY=
_TLBIMP_FLAGS=$(_TLBIMP_FLAGS)  /asmversion:12.4.56.0
_ASSEMBLY_IDENTITY=heap,processorArchitecture=x86,version=12.4.56.0,publicKeyToken=neutral
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\ThreadSafe.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "ThreadSafe.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here control the global lock.           */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 NoThread				  = -1;

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a thread safe class and prepare it for use.  This is    */
    /*   pretty small but needs to be done with a bit of thought.       */
    /*                                                                  */
    /********************************************************************/

THREAD_SAFE::THREAD_SAFE( BOOLEAN NewThreadSafe )
    {
	//
	//   Setup the class variables.
	//
	Claim = NoThread;
	Owner = NoThread;
	Recursive = 0;
	ThreadSafe = NewThreadSafe;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Claim a global lock.                                           */
    /*                                                                  */
    /*   When we try to claim the global lock we first need to be       */
    /*   sure we have not already go it.  If not we try to claim it     */
    /*   and register our ownership.                                    */
    /*                                                                  */
    /********************************************************************/

BOOLEAN THREAD_SAFE::ClaimGlobalLock( VOID )
	{
	//
	//   We only need to do something when we have 
	//   locking enabled for this heap.
	//
	if ( ThreadSafe )
		{
		REGISTER SBIT32 CurrentThread = GetThreadId();

		//
		//   We only try to claim the global lock
		//   if we have not already got it.
		//
		if ( CurrentThread != Claim )
			{
			//
			//   Claim the associated spinlock and
			//   and then register our claim to the 
			//   global lock.
			//
			Spinlock.ClaimLock();

			Claim = CurrentThread;

			return True;
			}
		else
			{ Recursive ++; }
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Engage a global lock.                                          */
    /*                                                                  */
    /*   When we have claimed the global lock we can wait for a         */
    /*   while before we engage it.  This gives us time to get the      */
    /*   locks we want before disabling all further lock calls.         */
    /*                                                                  */
    /********************************************************************/

VOID THREAD_SAFE::EngageGlobalLock( VOID )
	{
	//
	//   We only need to do something when we have 
	//   locking enabled for this heap.
	//
	if ( ThreadSafe )
		{
		REGISTER SBIT32 CurrentThread = GetThreadId();

		//
		//   Just for fun lets make sure that the caller
		//   has already claimed the global lock.  If not
		//   then we fail.
		//
		if ( CurrentThread == Claim )
			{
			//
			//   We now engage the global lock so all future
			//   locking calls will be disabled.
			//
			Owner = CurrentThread;
			}
		else
			{ Failure( "No claim before engage in EngageGlobalLock" ); }
		}
	}

    /********************************************************************/
    /*                                                                  */
    /*   Release the global lock.                                       */
    /*                                                                  */
    /*   When we have finished we may release the global lock so        */
    /*   that others may use it.                                        */
    /*                                                                  */
    /********************************************************************/

BOOLEAN THREAD_SAFE::ReleaseGlobalLock( BOOLEAN Force )
	{
	//
	//   We only need to do something when we have 
	//   locking enabled for this heap.
	//
	if ( ThreadSafe )
		{
		REGISTER SBIT32 CurrentThread = GetThreadId();

		//
		//   Just for fun lets make sure that the caller
		//   has already claimed the global lock.  If not
		//   and we have not been told to force the issue
		//   then fail.
		//
		if 
				(
				(CurrentThread == Claim) 
					||
				((Force) && (Claim != NoThread))
				)
			{
			//
			//   We may have had some recursive calls.  If
			//   so then exit these calls before releasing
			//   the global lock.
			//
			if ( Recursive <= 0 )
				{
				//
				//   Delete the ownership information and 
				//   free the associated spinlock.
				//
				Claim = NoThread;
				Owner = NoThread;

				Spinlock.ReleaseLock();

				return True;
				}
			else
				{ Recursive --; }
			}
		else
			{ Failure( "No claim before release in ReleaseGlobalLock" ); }
		}

	return False;
	}

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Delete the thread safe calls and free any associated           */
	/*   resources.                                                     */
    /*                                                                  */
    /********************************************************************/

THREAD_SAFE::~THREAD_SAFE( VOID )
    {
	//
	//   Just for fun lets just check that the
	//   lock is free.  If not we fail.
	//
	if ( (Claim != NoThread) || (Owner != NoThread) || (Recursive != 0) )
		{ Failure( "Global lock busy in destructor for THREAD_SAFE" ); }
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\page.hpp ===
#ifndef _PAGE_HPP_
#define _PAGE_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "PublicFindList.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants exported from the class.                             */
    /*                                                                  */
    /*   The constants supplied here control the number of bits in      */
    /*   a page descriptions bit vector and its minimum size.           */
    /*                                                                  */
    /********************************************************************/

CONST SBIT32 MaxBitsPerWord			  = (sizeof(BIT32) * 8);
CONST SBIT32 MinVectorSize			  = 1;
CONST SBIT32 OverheadBits			  = 2;
CONST SBIT32 OverheadBitsPerWord	  = (MaxBitsPerWord / OverheadBits);

    /********************************************************************/
    /*                                                                  */
    /*   Class forward references.                                      */
    /*                                                                  */
    /*   We need to refer to the following classes before they are      */
    /*   fully specified so here we list them as forward references.    */
    /*                                                                  */
    /********************************************************************/

class CACHE;
class FIND;

    /********************************************************************/
    /*                                                                  */
    /*   Data structures exported from the class.                       */
    /*                                                                  */
    /*   The page descriptions supported by this class are at the       */
    /*   heart of the memory allocator.  These pages are linked in      */
    /*   various ways so they can be quickly found.  The following      */
    /*   structure contains the results of a search for a specific      */
    /*   memory address and its related page information.               */
    /*                                                                  */
    /********************************************************************/

typedef struct
	{
	VOID							  *Address;
	CACHE							  *Cache;
	BOOLEAN							  Found;
	PAGE							  *Page;

	BIT32							  AllocationMask;
	BIT32							  SubDivisionMask;
	BIT32							  *VectorWord;

	SBIT32							  ArrayOffset;
	SBIT32							  VectorOffset;
	SBIT32							  WordShift;
	}
SEARCH_PAGE;

    /********************************************************************/
    /*                                                                  */
    /*   The page allocation mechanism.                                 */
    /*                                                                  */
    /*   The memory manager allocates storage in large chunks from      */
    /*   the external memory allocator.  It then sub-divides these      */
    /*   chunks into various sized pages and keeps track of these       */
    /*   allocations using a bit vector in each page description.       */
    /*                                                                  */
    /********************************************************************/

class PAGE : public PUBLIC_FIND_LIST
    {
		//
		//   Private data.
		//
		//   The page description contains various details
		//   about the page.  The 'Address' is the starting 
		//   address of the allocation page.  The 'PageSize'
		//   is typically empty but contains a value is the 
		//   page size is weird and not realted to the
		//   assocated bucket.  The 'Version' is a unique
		//   version number and is changed everytime a new
		//   page description is created or deleted.  This
		//   version number allows a thread to see if anyone
		//   has been significantly playing with a page  
		//   description since it last held the associated lock.
		//
		CHAR                          *Address;
		SBIT32						  PageSize;
		SBIT32						  Version;

		//
		//   We keep track of the number of elements that
		//   are currently 'Allocated' and 'Available' on
		//   the page.  Additionally, 'FirstFree' is the
		//   index of the first word in the bit vector that
		//   has at least one available slot.
		//
		SBIT16                        Allocated;
		SBIT16                        Available;
		SBIT16						  FirstFree;

		//
		//   We sometimes need to interact with other classes.
		//   The 'Cache' class typically owns a number of pages
		//   and keeps all the information about this size of
		//   allocation.  The 'ParentPage' is a pointer to 
		//   another cache from where this page was sub-allocated
		//   and where the space will need to be returned when
		//   it becomes free.
		//
		CACHE						  *Cache;
		CACHE						  *ParentPage;

		//
		//   The 'Vector' is the variable sized bit vector that
		//   contains allocation information.  Each allocation
		//   is recorded using 2 bits.  The first bit indicates
		//   whether the allocation is in use and the second bit
		//   indicates whether an active allocation has been 
		//   sub-divided into smaller chunks.  Any unused bits
		//   at the end of the final word are set to zero, assumed
		//   to be zero and should never be non-zero.
		//
		BIT32                         Vector[MinVectorSize];

   public:
		//
		//   Public functions.
		//
		//   The page description contains all the information
		//   relating to an allocation.  There is no information
		//   stored with the allocation itself.  A significant
		//   portion of the external API can find its way to
		//   this class if the many layers of caches fail to
		//   deal with the request first.
		//
        PAGE
			( 
			VOID					  *NewAddress,
			CACHE					  *NewCache,
			SBIT32					  NewPageSize,
			CACHE					  *NewParentPage,
			SBIT32					  NewVersion 
			);

		SBIT32 ActualSize( VOID );

		BOOLEAN Delete( SEARCH_PAGE *Details );

		VOID DeleteAll( VOID );

		PAGE *FindPage
			( 
			VOID					  *Address,
			SEARCH_PAGE				  *Details,
			FIND					  *Find,
			BOOLEAN					  Recursive 
			);

		BOOLEAN MultipleNew
			( 
			SBIT32					  *Available, 
			VOID					  *Array[],
			SBIT32					  Requested
			);

		VOID *New( BOOLEAN SubDivided );

		BOOLEAN Walk( SEARCH_PAGE *Details,FIND *Find );

        ~PAGE( VOID );

		//
		//   Public inline functions.
		//
		//   The page class is so central to the entire memory
		//   allocator that a number of other classes need to
		//   get at certain data from time to time.  Thus, it 
		//   is necessary for both brevity and performance to
		//   provide inline function for certain critical 
		//   information relating to a page.
		//
		INLINE BOOLEAN Empty( VOID )
			{ return (Allocated <= 0); }

		INLINE BOOLEAN Full( VOID )
			{ return (Available <= 0); }

		INLINE VOID *GetAddress( VOID )
			{ return ((VOID*) Address); }

		INLINE CACHE *GetCache( VOID )
			{ return Cache; }

		INLINE SBIT32 GetPageSize( VOID )
			{ return PageSize; }

		INLINE CACHE *GetParentPage( VOID )
			{ return ParentPage; }

		INLINE SBIT32 GetVersion( VOID )
			{ return Version; }

		INLINE BOOLEAN ValidPage( VOID )
			{ return ((BOOLEAN) ~(Version & 0x1)); }

	private:
        //
        //   Disabled operations.
		//
		//   All copy constructors and class assignment 
		//   operations are disabled.
        //
        PAGE( CONST PAGE & Copy );

        VOID operator=( CONST PAGE & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\library\autolock.hpp ===
#ifndef _AUTOLOCK_HPP_
#define _AUTOLOCK_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Sharelock.hpp"
#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Automatic sharelock control.                                   */
    /*                                                                  */
    /*   We can simplify quite a bit of code using this class when we   */
    /*   only need to hold a share lock for the duration of a block     */
    /*   or a function.                                                 */
    /*                                                                  */
    /********************************************************************/

class AUTO_EXCLUSIVE_LOCK
    {
		//
		//   Private data.
		//
		SHARELOCK					  *Sharelock;

    public:
        //
        //   Public inline functions.
        //
        AUTO_EXCLUSIVE_LOCK( SHARELOCK *NewSharelock,SBIT32 Sleep = INFINITE )
			{ (Sharelock = NewSharelock) -> ClaimExclusiveLock( Sleep ); }

        ~AUTO_EXCLUSIVE_LOCK( VOID )
			{ Sharelock -> ReleaseExclusiveLock(); }

	private:
        //
        //   Disabled operations.
        //
        AUTO_EXCLUSIVE_LOCK( CONST AUTO_EXCLUSIVE_LOCK & Copy );

        VOID operator=( CONST AUTO_EXCLUSIVE_LOCK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Automatic sharelock control.                                   */
    /*                                                                  */
    /*   We can simplify quite a bit of code using this class when we   */
    /*   only need to hold a share lock for the duration of a block     */
    /*   or a function.                                                 */
    /*                                                                  */
    /********************************************************************/

class AUTO_SHARE_LOCK
    {
		//
		//   Private data.
		//
		SHARELOCK					  *Sharelock;

    public:
        //
        //   Public inline functions.
        //
        AUTO_SHARE_LOCK( SHARELOCK *NewSharelock,SBIT32 Sleep = INFINITE )
			{ (Sharelock = NewSharelock) -> ClaimShareLock( Sleep ); }

        ~AUTO_SHARE_LOCK( VOID )
			{ Sharelock -> ReleaseShareLock(); }

	private:
        //
        //   Disabled operations.
        //
        AUTO_SHARE_LOCK( CONST AUTO_SHARE_LOCK & Copy );

        VOID operator=( CONST AUTO_SHARE_LOCK & Copy );
    };

    /********************************************************************/
    /*                                                                  */
    /*   Automatic spinlock control.                                    */
    /*                                                                  */
    /*   We can simplify quite a bit of code using this class when we   */
    /*   only need to hold a spin lock for the duration of a block      */
    /*   or a function.                                                 */
    /*                                                                  */
    /********************************************************************/

class AUTO_SPIN_LOCK
    {
		//
		//   Private data.
		//
		SPINLOCK					  *Spinlock;

    public:
        //
        //   Public inline functions.
        //
        AUTO_SPIN_LOCK( SPINLOCK *NewSpinlock,SBIT32 Sleep = INFINITE )
			{ (Spinlock = NewSpinlock) -> ClaimLock( Sleep ); }

        ~AUTO_SPIN_LOCK( VOID )
			{ Spinlock -> ReleaseLock(); }

	private:
        //
        //   Disabled operations.
        //
        AUTO_SPIN_LOCK( CONST AUTO_SPIN_LOCK & Copy );

        VOID operator=( CONST AUTO_SPIN_LOCK & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\library\barrier.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "LibraryPCH.hpp"

#include "Barrier.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*   Create a new barrier and initialize it.  This call is not      */
    /*   thread safe and should only be made in a single thread         */
    /*   environment.                                                   */
    /*                                                                  */
    /********************************************************************/

BARRIER::BARRIER( VOID )
    {
    Waiting = 0;

    if ( (Semaphore = CreateSemaphore( NULL,0,MaxCpus,NULL )) == NULL)
        { Failure( "Create semaphore in constructor for BARRIER" ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Synchronize Threads.                                           */
    /*                                                                  */
    /*   Synchronize a collection of threads.                           */
    /*                                                                  */
    /********************************************************************/

VOID BARRIER::Synchronize( SBIT32 Expecting )
    {
	//
	//   We make sure we are expecting at least two threads.
	//   If not then do nothing.
	//
	if ( Expecting > 1 )
		{
		//
		//   Cliam the lock.
		//
		Spinlock.ClaimLock();

		//
		//   We see if the required number of threads has
		//   arrived.
		//
		if ( Expecting > (++ Waiting) )
			{
			//
			//   We are about to sleep so drop the lock.
			//
			Spinlock.ReleaseLock();

			//
			//   The threads sleep here waiting for everyone 
			//   else to arrive.
			//
			if 
					( 
					WaitForSingleObject( Semaphore,INFINITE ) 
						!= 
					WAIT_OBJECT_0 
					)
				{ Failure( "Sleep failed in Synchronize()" ); }
			}
		else
			{
			REGISTER SBIT32 Wakeup = (Expecting-1);

			//
			//   The count of threads that have arrived is
			//   updated and the number of threads that are
			//   about to leave is updated.
			//
			Waiting -= Expecting;

			//
			//   We are about to wake up all the sleepers so 
			//   drop the lock.
			//
			Spinlock.ReleaseLock();

			//
			//   Wakeup any sleeping threads and exit.
			//
			if ( Wakeup > 0 )
				{
				if ( ! ReleaseSemaphore( Semaphore,Wakeup,NULL ) )
					{ Failure( "Wakeup failed in Synchronize()" ); }
				}
			}
		}
    }

    /********************************************************************/
    /*                                                                  */
    /*   Class destructor.                                              */
    /*                                                                  */
    /*   Destory a barrier.  This call is not thread safe and should    */
    /*   only be made in a single thread environment.                   */
    /*                                                                  */
    /********************************************************************/

BARRIER::~BARRIER( VOID )
    {
    if ( ! CloseHandle( Semaphore ) )
        { Failure( "Close semaphore in destructor for BARRIER" ); }
    }
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\library\barrier.hpp ===
#ifndef _BARRIER_HPP_
#define _BARRIER_HPP_
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'hpp' files for this code is as        */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants exported from the class.                       */
    /*      3. Data structures exported from the class.                 */
	/*      4. Forward references to other data structures.             */
	/*      5. Class specifications (including inline functions).       */
    /*      6. Additional large inline functions.                       */
    /*                                                                  */
    /*   Any portion that is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "Global.hpp"

#include "Spinlock.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   A control barrier.                                             */
    /*                                                                  */
    /*   This class synchronizs a collection of threads.                */
    /*                                                                  */
    /********************************************************************/

class BARRIER
    {
        //
        //   Private data.
        //
        HANDLE                        Semaphore;
	    SPINLOCK					  Spinlock;
        VOLATILE LONG                 Waiting;

    public:
        //
        //   Public functions.
        //
        BARRIER( VOID );

        VOID Synchronize( SBIT32 Expecting );

        ~BARRIER( VOID );

	private:
        //
        //   Disabled operations.
        //
        BARRIER( CONST BARRIER & Copy );

        VOID operator=( CONST BARRIER & Copy );
    };
#endif
=== C:/Users/treeman/Desktop/windows nt source code\xbox\Xbox Live Source\XONLINE_MAIN\private\common\servhlp\xheap\heap\page.cpp ===
//                                        Ruler
//       1         2         3         4         5         6         7         8
//345678901234567890123456789012345678901234567890123456789012345678901234567890

    /********************************************************************/
    /*                                                                  */
    /*   The standard layout.                                           */
    /*                                                                  */
    /*   The standard layout for 'cpp' files in this code is as         */
    /*   follows:                                                       */
    /*                                                                  */
    /*      1. Include files.                                           */
    /*      2. Constants local to the class.                            */
    /*      3. Data structures local to the class.                      */
    /*      4. Data initializations.                                    */
    /*      5. Static functions.                                        */
    /*      6. Class functions.                                         */
    /*                                                                  */
    /*   The constructor is typically the first function, class         */
    /*   member functions appear in alphabetical order with the         */
    /*   destructor appearing at the end of the file.  Any section      */
    /*   or function this is not required is simply omitted.            */
    /*                                                                  */
    /********************************************************************/

#include "HeapPCH.hpp"

#include "Cache.hpp"
#include "Find.hpp"
#include "Heap.hpp"
#include "NewPage.hpp"
#include "Page.hpp"

    /********************************************************************/
    /*                                                                  */
    /*   Constants local to the class.                                  */
    /*                                                                  */
    /*   The constants supplied here allow the allocation bit vector    */
    /*   to be rapidly searched for free storage.                       */
    /*                                                                  */
    /********************************************************************/

CONST BIT32 AllocatedMask			  = 0x2;
CONST BIT32 FullSearchMask			  = 0xaaaaaaaa;
CONST BIT32 FullWordShift			  = (MaxBitsPerWord - OverheadBits);
CONST BIT32 SubDividedMask			  = 0x1;
CONST BIT32 WordSearchMask			  = (AllocatedMask << FullWordShift);

    /********************************************************************/
    /*                                                                  */
    /*   Class constructor.                                             */
    /*                                                                  */
    /*                                                                  */
    /*   All page descriptions are actually created and deleted by      */
    /*   a separate class called 'NEW_PAGE'.  Nonetheless, as a         */
    /*   step the appropriate constructors and destructors are          */
    /*   invoked to support the standard C++ programming methodology.   */
    /*                                                                  */
    /********************************************************************/

PAGE::PAGE
		( 
		VOID						  *NewAddress,
		CACHE						  *NewCache,
		SBIT32						  NewPageSize, 
		CACHE						  *NewParentPage,
		SBIT32						  NewVersion 
		)
	{
	REGISTER SBIT32 Count;
	REGISTER SBIT16 NumberOfElements = (NewCache -> GetNumberOfElements());
	REGISTER SBIT16 SizeOfElements = (NewCache -> GetSizeOfElements());

	//
	//   Create a page description.
	//
	Address = (CHAR*) NewAddress;
	PageSize = NewPageSize;
	Version = NewVersion;

	Allocated = 0;
	Available = NumberOfElements;
	FirstFree = 0;

	//
	//   Set up the pointers to related classes.
	//
	Cache = NewCache;
	ParentPage = NewParentPage;

	//
	//   Zero the bit vector.
	//
	for ( Count=0;Count < SizeOfElements;Count ++ )
		{ Vector[ Count ] = 0; }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Compute the actual size.                                       */
    /*                                                                  */
    /*   Almost all allocation sizes are derived from the associated    */
    /*   caches.  However, there are a few special pages that contain   */
    /*   a single allocation of some weird size.                        */
    /*                                                                  */
    /********************************************************************/

SBIT32 PAGE::ActualSize( VOID )
	{
	return
		(
		(ParentPage == ((CACHE*) GlobalRoot))
			? PageSize
			: (Cache -> GetAllocationSize())
		);
	}

    /********************************************************************/
    /*                                                                  */
    /*   Delete an allocation.                                          */
    /*                                                                  */
    /*   We need to delete the memory allocation described by the       */
    /*   parameters.  However, as we are of an untrusting nature        */
    /*   we carefully check the request to ensure it is valid.          */
    /*                                                                  */
    /********************************************************************/

BOOLEAN PAGE::Delete( SEARCH_PAGE *Details )
    {
	//
	//   We know that no one would deallocate memory
	//   they had not previously allocated (yea - right).
	//   So here we check for this case.
	//
	if ( (*Details -> VectorWord) & Details -> AllocationMask )
		{
		//
		//   Nasty: it is possible for the user to give us an
		//   address that points to the middle of the element
		//   to be freed instead of the beginning.  This is no
		//   problem for us but we have to ponder whether the
		//   caller knew what they were doing.  If this is the 
		//   case we fail the request.
		//
		if ( Details -> Found )
			{
			//
			//   We have found that the element is allocated
			//   (as one might expect) so lets deallocate it 
			//   and update the various counters.
			//
			(*Details -> VectorWord) &= 
				~(Details -> AllocationMask | Details -> SubDivisionMask);

			//
			//   We may need to push back the pointer to the 
			//   first free element.  This will ensure that
			//   we can quickly locate the freed element for  
			//   later so we can reuse it.
			//
			if ( FirstFree > Details -> VectorOffset )
				{ FirstFree = ((SBIT16) Details -> VectorOffset); }

			//
			//   If the page was full and now has an empty
			//   slot then add it to the bucket list so that
			//   the free space can be found.
			//
			if ( Full() )
				{ Cache -> InsertInBucketList( this ); }

			//
			//   Update the allocation information.
			//
			Allocated --;
			Available ++;

			//
			//   If the page is now empty then delete 
			//   the page to conserve space.
			//
			if ( Empty() ) 
				{
				//
				//   We immediately delete empty pages
				//   except at the top level where it is
				//   under user control.
				//
				if ( ! Cache -> TopCache() )
					{ Cache -> DeletePage( this ); }
				else
					{
					REGISTER SBIT32 MaxFreePages = 
						(Cache -> GetHeap() -> GetMaxFreePages());

					((BUCKET*) Cache) -> ReleaseSpace( MaxFreePages );
					}
				}

			return True;
			}
		}

	return False;
    }

    /********************************************************************/
    /*                                                                  */
    /*   Delete all simple allocations.                                 */
    /*                                                                  */
    /*   Although this routine may seem insignificant its effects are   */
    /*   dramatic.  When called this function deletes all the none      */
    /*   sub-allocated elements and updates the control values.         */
    /*                                                                  */
    /********************************************************************/

VOID PAGE::DeleteAll( VOID )
    {
	REGISTER BOOLEAN PageFull = Full();

	//
	//   Simply reset the allocation counts.
	//
	Allocated = 0;
	Available = (Cache -> GetNumberOfElements());
	FirstFree = 0;

	//
	//   We know that if this cache does not have any
	//   child allocations that it is safe to simply
	//   zero the bit vector.  If not we have to do it
	//   the long way.
	//
	if ( Cache -> GetNumberOfChildren() > 0 )
		{
		REGISTER SBIT32 Count;
		REGISTER SBIT16 SizeOfElements = (Cache -> GetSizeOfElements());

		//
		//   We examine each word of the bit vector 
		//   and delete all the elements that are
		//   not sub-divided into smaller sizes.
		//
		for ( Count=0;Count < SizeOfElements;Count ++ )
			{
			REGISTER BIT32 *Word = & Vector[ Count ];
			REGISTER BIT32 AllAllocations = ((*Word) & FullSearchMask);
			REGISTER BIT32 AllSubDivided = ((*Word) & (AllAllocations >> 1));
			REGISTER BIT32 FinalMask = (AllSubDivided | (AllSubDivided << 1));

			//
			//   Delete all normal allocations.
			//
			(*Word) &= FinalMask;

			//
			//   If the final mask is not zero then
			//   we still have some allocations active.
			//   We need to count these and update the
			//   control information.
			//
			if ( FinalMask != 0 )
				{
				REGISTER SBIT32 Total = 0;

				//
				//   Count the allocations.
				//
				for ( /* void */;FinalMask != 0;FinalMask >>= OverheadBits )
					{ Total += (FinalMask & 1); }

				//
				//   Update the control information.
				//
				Allocated = ((SBIT16) (Allocated + Total));
				Available = ((SBIT16) (Available - Total));
				}
			}
		}
	else
		{
		REGISTER SBIT32 Count;
		REGISTER SBIT16 SizeOfElements = (Cache -> GetSizeOfElements());

		//
		//   Zero the bit vector.
		//
		for ( Count=0;Count < SizeOfElements;Count ++ )
			{ Vector[ Count ] = 0; }
		}

	//
	//   If the page was full and now has empty
	//   slots then add it to the bucket list so 
	//   that the free space can be found.
	//
	if ( (PageFull) && (! Full()) )
		{ Cache -> InsertInBucketList( this ); }
    }

    /********************************************************************/
    /*                                                                  */
    /*   Find an allocation page.                                       */
    /*                                                                  */
    /*   When we receive a request to delete an allocation we don't     */
    /*   have a clue about where to find it.  All we have is a hash     */
    /*   table (see 'FIND') of allocated pages.  So we mask off the     */
    /*   low order bits of the address and try to find the top level    */
    /*   external allocation.  If this works we see if the area we      */
    /*   are looking at has been sub-divided and if so we try the       */
    /*   same trick again until we get the the origibal allocation      */
    /*   page.                                                          */
    /*                                                                  */
    /********************************************************************/

PAGE *PAGE::FindPage
		( 
		VOID						  *Memory,
		SEARCH_PAGE					  *Details,
		FIND						  *Find,
		BOOLEAN						  Recursive 
		)
    {
	//
	//   We navigate through the pages trying to find
	//   the allocation page associated with the address.
	//   If we find a page that has no children then 
	//   we can assume we have arrived and exit early 
	//   unless the caller has requested all the realated 
	//   details.
	//
	if ( (Cache -> GetNumberOfChildren() > 0) || (Details != NULL) )
		{
		AUTO BOOLEAN Found;
		REGISTER SBIT32 Displacement = 
			((SBIT32) (((CHAR*) Memory) - Address));
		REGISTER SBIT32 ArrayOffset = 
			(Cache -> ComputeOffset( Displacement,& Found ));
		REGISTER SBIT32 VectorOffset = 
			(ArrayOffset / OverheadBitsPerWord);
		REGISTER SBIT32 WordOffset = 
			(ArrayOffset - (VectorOffset * OverheadBitsPerWord));
		REGISTER SBIT32 WordShift = 
			(((OverheadBitsPerWord-1) - WordOffset) * OverheadBits);
		REGISTER BIT32 AllocationMask = 
			(AllocatedMask << WordShift);
		REGISTER BIT32 SubDivisionMask = 
			(SubDividedMask << WordShift);
		REGISTER BIT32 *VectorWord = 
			& Vector[ VectorOffset ];

		//
		//  We will recursively search and find the target 
		//  address if requested otherwise we will just 
		//  return the details of the next level in the tree.
		//
		if 
				(
				(Recursive)
					&&
				((*VectorWord) & AllocationMask)
					&&
				((*VectorWord) & SubDivisionMask)
				)
			{
			REGISTER PAGE *Page = (Cache -> FindChildPage( Memory,Find ));

			//
			//   We have found the element and checked it. 
			//   So lets pass this request on to the
			//   child page.  However, there is a slight
			//   chance of a race condition here.  It
			//   might be that the original page was
			//   deleted and a new page is currently
			//   being created.  If this is the case
			//   then we will not find the page in the 
			//   hash table so we just exit and fail the 
			//   call.
			//
			if ( Page != ((PAGE*) NULL) )
				{ return (Page -> FindPage( Memory,Details,Find,Recursive )); }
			else
				{ return NULL; }
			}

		//
		//   We see if the caller is interested in the
		//   details relating to this address at the
		//   current level in the tree.
		//
		if ( Details != NULL )
			{
			//
			//   We have computed the details relating
			//   to this address at the current level
			//   in the tree so load them into the
			//   caller supplied structure.
			//
			Details -> Address = Memory;
			Details -> Cache = Cache;
			D